Job Title,Salary Estimate,Job Description,Rating,Company Name,Location,Headquarters,Size,Founded,Type of ownership,Industry,Sector,Revenue,Competitors
Software Engineer - Machine Learning/Data Science,-1,"Zendesk is looking for a Software Engineer - Machine Learning/Data Science for a full time position in our Melbourne office.
As part of our engineering team, you will work at a scale where the challenges start to get seriously interesting. Our global engineering team is widely dispersed over the world, with people across nearly every continent. You will get a chance to do cool things with a diverse bunch of people while working in the Melbourne office that is home to Zendesk’s first machine learning (ML) research team.
The Data Science Team, together with Data Engineering, have built Satisfaction Prediction, Answer Bot and Content Cues — products that use Machine Learning (ML) and Artificial Intelligence (AI) to help our customers work more efficiently.
What you get to do every day:
We’re currently looking for someone to join our team as we research, develop, and productionise Machine Learning and Deep Learning models. In addition to frequenting Melbourne’s finest purveyors of coffee, ramen, and bulgogi, you may find yourself:
Building machine learning models including neural networks in TensorFlow
Writing and deploying production-grade Python
Querying and constructing datasets in AWS Athena, Spark
Evaluating and responding to real-world model performance
Scaling your ML to millions of predictions per day
Presenting your work to a broader audience
Watching your algorithm help Zendesk’s end-users
What you'll bring to the role:
A strong foundation in a quantitative discipline (e.g. machine learning, statistics, bio/eco/etc-informatics, econometrics, etc) is critical for this position. While experience in deep learning and natural language processing would be beneficial, your best qualities are:
dedication to continuous learning
collaborative work attitude
strong communication skills
You should also be comfortable with at least one programming language, such as Python, R or Scala.
Application Deadline: 18/11/2020
Job Types: Full-time, Permanent
Salary: $85,000.00 – $110,000.00 per year
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Temporarily due to COVID-19",4.5,"Zendesk
4.5",Melbourne,-1,1001 to 5000 Employees,2007,Company - Public,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),-1
Software Engineer (Machine Learning),-1,"About the Role
AdelaideMRI is building a medical reporting tool. We require an engineer to work primarily on machine learning projects to improve reporting speed and report comprehensiveness.
You will perform data analysis of medical report datasets and image datasets to infer sentence recommendations, image classifications, or other actionable results for the doctors.
Skills and Experience
Background in machine learning or image processing
Qualifications in Computer Science, Software Development or Engineering or equivalent experience
Bonus points for Python
No prior medical knowledge is required.
This position offers flexible hours and work arrangements.
Job Type: Full-time
Experience:
Software Engineering: 1 year (Preferred)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Yes",-1,Adelaide MRI,Australia,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Hey there, we’re PEXA!

We started as an idea: to deliver a single, national e-Conveyancing solution. We collaborated with the industry to create a national electronic lodgement and settlement platform: PEXA. From our humble beginnings, we’ve now grown to more than 320 employees across 5 different states. We’re still expanding at a rapid rate and constantly challenging ourselves to create great experiences for our members as they transition to fully digital conveyancing.

Why become a PEXArian?

Great question! Being a PEXArian is so much more than just a job. We are passionate, motivated & unashamedly enthusiastic at PEXA - we love what we do and we’re proud to admit it! Creating brilliant member experiences wouldn’t be possible if we didn’t also strive to create an amazing employee experience. Alongside our members, our employees are at the heart of everything we do.
Here’s a snapshot of what your life at PEXA could look like:

Your growth:
We encourage you to hit your personal and professional Learning & Development goals with our tailored programs and tools.

Your wellness:
We care about your holistic well being - a fully stocked kitchen, four wellness days, a $250 wellness subsidy as well as lunch and learn sessions to support your financial well being.

Your work/life blend:
We know that work is just one aspect of your life, we want to help you create your ideal work/life blend, rather than squeezing in life around work.

Your family:
With a range of benefits aimed at supporting your family including access to a subsidised school holiday program, extended parental leave and flexi-time to support your return to work, superannuation payments for unpaid parental leave for primary carers and a childcare allowance for pre-primary aged children, when we say, ‘welcome to the family’, we really mean it!
The impact you'd drive:
The successful candidate will be responsible for developing, and maintaining infrastructure to support the delivery of new and existing products. They will also be contributing to establish the rules and frameworks for obtaining the required approvals for new products.
On day one we’d love you to have:
Experience with Python, Spark
Event streaming/sourcing with Kafka or AWS Kinesis
Experience with data structures, formats and data security best practices
AWS experience (e.g CloudFormation, S3, ECS, Lambda, SQS, IAM, KMS, DynamoDB, Glue, Athena)
Query construction and optimisation (e.g. SQL, Elasticsearch, Splunk, DynamoDB)
Git, version control practices, and continuous integration/delivery servers
PyUnit and unit testing frameworks
Production release cycles and maintenance
Collaborating with technical and non-technical teams
Even better:
Agile methodology/delivery
GraphQL
Modern frontend technology (e.g. ReactJS, TypeScript)
Machine learning frameworks and tools (e.g. TensorFlow, PyTorch)
OAuth 2, SAML 2, JWT
Data visualisation and exploration tools (e.g. Jupyter notebooks, Tableau)
AWS SageMaker
Sounds like you?
If this role sounds like you, apply today to have your application reviewed ASAP!",3.9,"Property Exchange Australia Limited
3.9",Melbourne,-1,201 to 500 Employees,2010,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Ongoing position
Full time
Based in Sydney, NSW
Who we are
Australian Red Cross is part of the world’s largest humanitarian organisation. Our aim is to improve the lives of the most vulnerable people in Australia and across our region.
About the role
The Data Engineer role will sit within the Data and Integration Squad in IT and will own (design, implement and support) the AWS Big Data technologies such as the Data Lake and Data Warehouse and support the organisation in growing the data analytics capabilities at Red Cross. In addition to this, the data engineer role will also administer the Power BI tool and support the implementation of the data mastering capability.
What you will bring
Experience building and optimizing data pipelines, architectures and data sets.
Experience in dimensional modelling and building data vaults
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with structured, semi-structured and unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Why work for us?
Work for purpose and know that your work assists Red Cross support and empower people and communities in times of vulnerability.
Generous salary packaging options available that can increase your take home pay.
Further information
To find out more about this opportunity please see the position description below or contact Sharath Kumar Gurram on 02 8651 8839.
Position Description: Position Description - Data Engineer .pdf
Applications for this position will close at 11:55pm Thursday, 5 November 2020.",4.1,"Australian Red Cross
4.1",New South Wales,-1,1001 to 5000 Employees,-1,Nonprofit Organization,Industrial Manufacturing,Manufacturing,$500 million to $1 billion (USD),-1
Junior Fullstack Data Engineer (Python and React),-1,"Formbay is the leading Renewable Energy Certificate Trading company in Sydney. We provide Digital Workflow and Compliance solutions in the renewable energy industry and document processing.
Thanks to our meteoric growth and our commitment to be the best at all we do, we've identified the need to bring on board a new Junior Fullstack Data Engineer.
Reporting to our Principal Machine Learning Engineer, you will help build Machine Learning pipelines for our existing Digital Workflow and Compliance solutions to automate fraud detection and document processing over terabytes of photographic and documentary data – including documents, photos, GPS data and aerial/satellite photography.
Our stack is based on Python, JavaScript, Dask, Tensorflow, CUDA, Nix/NixOS, AWS, Docker, PostgreSQL and more – familiarity with these applications will give you a leg-up on the competition.
Our ideal candidate will have the following competencies:
SQL
Python
JavaScript/TypeScript
Our candidate must also be comfortable working with Linux.
Located a stone's throw away from the Queen Victoria Building in Sydney's bustling CBD, we are centrally-located with easy access to public transportation, bars, cafes and fine dining.
Formbay will provide flexible working hours, a generous remuneration package and the opportunity to work on a world-first software solution are what we can offer you. Free, twice-weekly gym sessions and really, really good coffee are also available.
No hiring/recruitment agencies need apply.",5.0,"Formbay
5.0",Sydney,-1,1 to 50 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is an experienced and qualified Data Engineer to join our IT team based in Birtinya.
Key Responsibilities:
Create and maintain data pipelines and or ETL scripts
Create and maintain data integration including API and Batch interfaces
Performed detailed data analysis
Create and maintain corporate data models
Create and maintain data visualization using Qlik.Sense , PowerBI or Simliar Toolset
Experience in defining, building and maintaining data virtualization and/or star schema data warehouses
Maintain, tune and optimise database, integration and visualisation toolsets
ABOUT YOU:
To succeed in this role, you’ll need to bring the following experience and skills:
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Excellent communication skills both oral and written, with an ability to bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking
Experience with data analysis and modelling will be beneficial

How to Apply
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kawana Waters,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Graduate Data Science / Engineer,-1,"The NRMA is an organisation looking to the future, and right now, we are on the lookout for people who can help us reach our goal: to continue to shape the way Australians move, for the next 100 years and beyond. www.mynrma.com.au.
Everyone new to the team, along with our current staff, will temporarily work from home until it is safe to return to our offices. All interviewing and on boarding will be done virtually due to COVID-19.


Your opportunity
As Graduate Data Scientist or Engineer you will be part of the Data Engineering team delivering cloud data transition program for business initiatives and supporting the entire data platform build.
Your key responsibilities will be to:
Implementing Concepts of Data Warehousing, Data Mart creations within Cloud
Use of SQL for data analysis and insights
Building AI/Machine Learning prototype for implementing and supporting existing algorithms
Data Analytical reports build, using different tool sets


Requirements for Success:
Relevant Degree - Computer Science, Computer Engineering, Software Engineering, Data Science
Excellent SQL skills and demonstrated working knowledge in Python
Demonstrated understanding in data structure and algorithms.
Knowledge and concept of data warehousing methodologies
Any reporting tools experience Tableau or Oracle Analytics Cloud, Looker is desirable
Exposure to Google/AWS/Azure/Oracle any cloud based platforms is desirable
Good communication and interpersonal skills

If you have the required skills and the passion to join our high performing team, please apply today.

Employee Benefits
To ensure our employees feel valued, empowered and celebrated we provide a range of employee benefits including:
50% discount on all NRMA insurances
Free Roadside Assistance
12 weeks paid primary and 4 weeks paid secondary parental leave
Free NRMA Blue Membership
At the NRMA Group, we are People Moving People and diversity and inclusion are part of our DNA. Together, we continue to build an inclusive culture that encourages, supports and celebrates the diverse voices of our employees. It fuels our innovation, promotes flexible ways of working and connects us closer to our members and the communities we serve.",2.5,"NRMA Motoring & Services
2.5",Sydney,-1,501 to 1000 Employees,-1,Nonprofit Organization,Casual Restaurants,"Restaurants, Bars & Food Services",$500 million to $1 billion (USD),-1
Data Centre Engineer,-1,"We are a leading world group that provides low-carbon energy and services. To tackle the climate emergency facing us all, our aim is to become the world leader in the zero-carbon energy transition ""as a service"" for our clients – particular for companies and regional authorities. We use our expertise in our key business areas (renewables, gas, services) to provide competitive and bespoke solutions.
The Data Centre Engineer will be employed as part of a 24/7 ongoing shift to coordinate and monitor third party service providers, maintain the data centre facilities and infrastructure plans, coordinate the implementation of customer requests within the data centre and monitor systems, all in accordance with the Contract KPIs and SLAs.
Coordinate and monitor third party service providers for regular maintenance & testing, service faults & call outs, ensuring works are performed in accordance with Contract SLAs
Monitor and maintain the data centre facilities and infrastructure plans and documentation, including electrical, mechanical, hydraulics, fire and BMS/EMS systems
Coordinate the implementation of internal and external customer requests within the data centre
Perform scheduled plant checks and minor maintenance works
Ensure all Work Order requests are raised and closed in a timely manner
Conduct inductions for staff, vendors and contractors
Ensure all work permits for vendor works are raised and closed
Perform inventory checks on all equipment and critical spares

Qualifications
The selected candidate must be able to demonstrate:
Electrical or HVAC background, or Graduate Electrical or Mechanical Engineer
Passionate about quality work and career minded looking for a new challenge
Can commit to a day and night shift roster (2 days of day shift, then 2 days of night shift, 4 days off)
Ideally able to commence asap
As part of carrying out the duties of this role, it is mandatory to hold Australian Citizenship.

If you are interested and meet the selection criteria apply with an up-to-date resume via the apply instructions on this website.

ENGIE Services is an EEO employer, where all applicants are treated with fairness and respect and have equal access to the opportunities available.

We will not be engaging in the services of a recruitment agency to fill this vacancy and therefore request all interested candidates apply directly to this advertisement.

Job
: Maintenance
Primary Location
: Oceania-Australia-New South Wales-Erskine Park
Organization
: ENGIE Services Australia and New Zealand
Schedule
: Full-time
Nature of Responsibility
: Senior operational / administrative role
Job Posting
: Sep 11, 2020, 6:29:59 AM",3.7,"ENGIE Services Australia & New Zealand
3.7",Sydney,-1,5001 to 10000 Employees,1995,Company - Public,Energy,"Oil, Gas, Energy & Utilities",$2 to $5 billion (USD),-1
Senior Data Engineer,-1,"Senior Data Engineer, Temporary, SYDNEY - McKell

Job Title: Senior Data Engineer

Salary: SNSW Grade 9/10 - The package includes base salary range of $111,806 to $134,667, plus employer's contribution to superannuation and annual leave loading.

Location: Head Office – Haymarket

Employment Status: Temporary through till 30th June 2021


About Service NSW:

Service NSW is making it easier for people and businesses across NSW to access government services. The role designs, builds and analyses complex data from multiple sources to identify revenue, process and business improvement opportunities; providing new information and insights to the business to inform planning, continuous improvement and performance.

About the Role

We are currently seeking to appoint a Senior Data Engineer to deliver expert advice and services in the design of a Single View of Customer and data-related services to support the achievement of business outcomes and strategic goals. We support flexible working practices with staff working remotely during this time.

In this role you will:

Design, build and support a modern data platform based in AWS and vendor technologies.
Provide expertise on data modelling for Graph data model and Customer Data Platform (CDP).
Create data pipelines, load, transformation and reporting workloads in AWS.
Work with the latest data engineering technologies like Apache Kafka, AWS Kinesis, AWS Neptune, AWS Glue and AWS Athena.
Contribute to the design and decision-making of the right tool or platform for the job according to requirements.
Provide expert advice and guidance on data quality and data engineering best practices.
Support a “bigger than you can imagine” scale of data in production environments.
Design, develop and support a metrics-driven reporting solution and a meaningful business intelligence platform.
Document the solution design and support procedures of solutions.
Produce reports, visualisations and recommendations to answer complex business problems that are presented in the most appropriate format to ensure clarity for target audience.
Analyse and define new process improvement opportunities to support continuous improvement and business outcomes; providing advice to stakeholders, on ways to improve the efficiency and reliability of data products and services.
Be very responsive to the information needs of the business by corresponding to customers in a timely manner and provide support/solutions to issues raised.
Troubleshoot and perform root cause analysis on production issues. Identify and implement long term solutions to problems. Perform scheduled maintenance, release deployment and production support activities after business hours, from time to time.
Liaise with internal and external customers to discuss and gather requirements, solutions etc. and maintain a good working relationship with the stakeholders.


Skills and Experience Required:

Solid experience with workflow technologies designing and building data pipelines, data models and data stores.
Experience working within and an understanding of Amazon AWS ecosystem, including security and performance tuning.
Hands on experience working with different types of databases, with focus on Graph and NoSQL databases.
Experience with data streaming required. Having used Kafka and related technologies is an added advantage.
Sound knowledge and experience working with batch processing, data extraction and API integration.
Hands on experience with at least one programming language: Java, Python or scripting.
Demonstrated experience working in an Agile based, fast paced, complex environment within cross-functional teams.
Experience developing systematised insights, data analytics and reporting solutions is an added advantage.
Experience with interactive visualisation of data insights is an added advantage.


Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Salary Grade 9/10, with the base salary for this role starting at 111,806 base plus superannuation

Closing Date: 6th November at 9:59am - applications will be reviewed on a rolling basis, applications may close early or extend

Please apply online, direct applications submitted via email will not be considered.

The Department of Customer Service is proud to be an EEO Employer who are fully focused on equality and believe deeply in diversity of all identities making us different and a true reflection of our NSW customers. As an inclusive workplace, we support various employee resource groups, practice flexible work and workplace adjustment.

If you do require an adjustment during the recruitment process, please notify us on your application form.",3.2,"Service NSW
3.2",Sydney,-1,501 to 1000 Employees,2012,Government,State & Regional Agencies,Government,Unknown / Non-Applicable,-1
Data Engineer - Entry / Mid Level,-1,"Work with a great team on interesting projects customers
Gain more experience in AWS, Data, DevOps cloud operations
Got a working knowledge of AWS? We will teach you the cool stuff!

Itoc is seeking an up and coming Data Engineer to join our growing Data Team in Sydney.

This is an exciting role working with databases, data lakes, data warehouses, data transformation (Python SQL) and enabling AI/ML.

You will be implementing foundational, robust and production ready data platforms to enable business data-discovery, self-service, AI/ML functions across a range of client types and industries, allowing them to do more with their data.

You'll be responsible for:

Deploying data repositories such as lakes and warehouses.
Contribute to our growing portfolio of data solutions.
Ongoing optimisation and management of data platforms.
Development of transformational logic for data pipelines
Data evangelism. We want to show our clients how to follow the best practices for data.

Desired Skills and Experience

To take up the challenge, you will have a depth of skills and experience including:

1-2+ yrs of focused data experience working with SQL and/or NoSQL solutions
A solid education in Software Engineering or equivalent industry experience.
Anything Data focused preferred.
Ability to analyse business scenarios and associated data landscape to derive potential opportunities.
Strong foundation in Python and SQL
Working knowledge of APIs
Principle knowledge of the different relational database platforms and modern data storage techniques
Knowledge of the different aspects of data environments
Collect, store, process, verify consume
Experience with version management systems (such as GIT)
Working knowledge of AWS or another cloud platform - we will teach you the cool stuff.
Great communication skills, an ability to work closely with customers, developers and engineers and the confidence to present ideas in open forums.
Relevant tertiary qualifications and/or industry certifications.
Great communication skills, an ability to work closely with clients, developers and engineers and the confidence to present ideas in open forums.

While not required, a background in consulting and professional services is highly desirable.

Itoc Description

This is an exciting and challenging career opportunity to join the growing Sydney-based Data Team of a leading cloud solution provider where you will be given support to reach your long term career goals. You will be part of a team of cloud experts and will work in an environment of continuous improvement and learning delivering innovative cloud solutions across SaaS, online business and enterprise business.

On offer is a chance to join a team with a great working environment, in an organisation that values its employees and sees the value in ensuring they are engaged. Our team are clearly passionate about what they do, that's why we won the following awards:

Customer Obsession Partner of the Year 2015: ANZ Region
Customer Obsession Leadership Partner 2015: re:Invent

As an employer of choice Itoc offers competitive remuneration, training and development programs and a great working environment. We value a healthy work life balance.

The Perks

MacBook or Dell
Continuous internal learning that will provide training and career development opportunities
Working with a collaborative, social team and leveling-up your skills faster than you will anywhere else.
Quarterly social events

Itoc

Culture and smarts are important to us. Bring your secret sauce. This is no ordinary environment, you will work along some of the Cloud’s best. All engineers at Itoc must gain at least five AWS certifications. We work hard but we have fun.

Please note you must have full working rights in Australia and be available on-shore for face to face interviews.

No recruiters please.",4.0,"Itoc
4.0",Sydney,-1,1 to 50 Employees,2013,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Date: 01-Oct-2020

Location:
Melbourne, VIC, AU

Department:Description:
Technology discounts - from Apple HP Lenovo to Windows
Flexible work arrangements - work in a way that suits you best
Salary packaging - to suit your personal and financial circumstances

Do you want to work for one of the fastest growing data teams in Australia? Do you want to work on multiple data platforms and provide new solution offerings by leveraging cloud and big data technologies?

About the team

Big data information and analytics. Three words that spark apprehension in most businesses. But our team of experts are constantly curious and excited about combining our wonderful array of technological expertise to transform data into our clients most valuable assets making their work smarter. Our data consultants are supported with resources training and tools they need to excel at their work but also the freedom and power to create their own paths forward to make a difference.

As a Senior Consultant in Big Data you will work closely with the team and stakeholders to build and deliver a Cloud based vision for a next generation Big Data analytics platform with strong focus on data quality data security and deliver the systems that process huge volumes of data.

What will you typical day look like?

You will play a pivotal role in - Designing and producing high performing and stable applications to perform complex processing of massive volumes of data in a new cloud based architecture; Building real-time data processing applications which are integrated with business systems to enable value from analytic models to drive rapid decision making; Contributing to system architecture design for a data platform (including cloud-based structures both on and off premises data warehouse components and data lakes); this could cover a range of technologies various countries/locations and lines of business; Support data strategy or technology strategy definition programs including technology stack definition and target operating model requirements

Enough about us lets talk about you:
You are someone with:
Use of traditional data analytics tools and techniques (e.g. MSSQL Oracle MySQL) and ETL software (e.g. SSIS Informatica CloverETL)
Working in large scale cloud data solutions using platforms such as AWS or Azure or GCP will be a bonus.
Experience in scripting or programming (e.g. Python Java Scala C#)
Excellent verbal and written communication skills to adapt to technical and non-technical audiences.
Educated to degree level (or have equivalent experience)
Why Deloitte?

At Deloitte we create positively differentiated work experiences that enable our people to feel valued and achieve their full potential. We value difference and embrace people with diverse backgrounds and thinking styles. Knowing that people work best in different ways we are happy to discuss alternative arrangements if the working pattern you are looking for is not specifically indicated.",3.8,"Deloitte
3.8",Melbourne,-1,10000+ Employees,1850,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Engineer,-1,"Opportunity to grow the team
Period of growth
Intuitive app
S2M are working with a FinTech who have created a unique financial product to help thousands of people better manage their finance, and is currently scaling the company to the next level!

They are looking for a Data Engineer to join, and looking for someone who wants to be hands on, with opportunity to grow the team in future.

Role:

Looking for people with strong AWS experience. You will need passion for data and a cloud, through which you will help a rapidly scaling Australian FinTech establish their data infrastructure from the ground up.
5+ years’ experience as a data engineer within the data and analytics domain
A python 3.X aficionado who is very comfortable creating and orchestrating AWS data pipelines with nothing but code
Strong project delivery toolset experience in open source data integration tools
Experience with processing large volumes of complex data including visualisation and insights generation
Ability to define and develop data integration patterns and pipelines
Ability to assess complexity of data (volume, structure, relationship etc.)
Hands on experience working with different databases (RDBMS, NoSQL, Blob storage etc)
Hands on technical expertise setting up DevOps automation
Hands on experience working technologies/platform e.g. AWS, Dockers, Containers
Experience building data profiling and data cleansing frameworks
Technical reconciliation and reporting
Knowledge and experience in end-to-end project delivery, either traditional SDLC or agile delivery methodologies (or hybrid approaches)
Exceptional communication, documentation and presentation skills
If this sounds like you, get in touch today - kate.gabb@s2m.com.au
3167410agsdf",3.1,"S2M
3.1",Sydney,-1,Unknown,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Analysts,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is seeking experienced and qualified Data Analysts to join our IT team based in our corporate office in Birtinya (Sunshine Coast) or at our meat processing facility in Kilcoy.
Key Responsibilities:
A mixture of data analysis and commercial skills to source, blend and analyse data to gain insight and answer key commercial questions
Working with strategic leaders to define and model Key Performance Indicators, and assist in building forecasting models
Working closely with data engineers and BI developers to specify data pipelines and report visualisation
Drive the creation and implementation of data quality business rule including data definition, governance and quality assurance
About You:
To succeed in this role, you’ll need to bring the following experience and skills:
Proven ability to derive insight and knowledge from data using commercial expertise is a strong requirement
Strong SQL and Excel skills are essential, along with strong data analysis and commercial insights
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Effective people communicator - engage with stakeholders on reporting needs, interpret requirements into visual solutions and train/deliver the outputs to the stakeholders getting signoff of acceptance
Bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking

How to Apply:
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kilcoy,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Network Data Engineer,-1,"Min 6+ years of experience in the relevant technologies
Australian Driving License for visiting remote locations / Data Centre for day to day technical work.
Managing Network devices (switches, routers, firewalls, load balancer, and wireless technology)
Performing MACD activities for all network devices.
Supporting BAU operation activities.
Proficient in performing in-depth details of technical troubleshooting, cause and provide recommendation to the client for incidents causing extended network outage to client’s critical locations.
Provide exceptional network services in terms of network support, break-fix, design and consulting, new projects, implementation.
Configure, administer, and document firewall infrastructure.
Manage the firewall deployment, rules migrations, and firewall administration.
Supporting Cloud Migration Activities from traditional to AWS/Azure.
Setting up VPN tunnel with Cloud and 3rd Party network devices.
Integrating and upgrading existing ISP bandwidth with support from ISP Vendor.
Setting up VPN profiles for Users.
Installing hot fix and patches to mitigate the security devices from attacks and bugs.
Reviewing and fine tuning the firewall rules and NAT rules.
Documentation and change control.
Mentoring, Motivating and Guiding support teams
Technical skills:
o LAN
o Wireless
o WAN
o MPLS
o Routing protocols (OSPF,BGP)
o DMVPN
o Azure cloud Networking
o Network Security
Fortigate Manager / Analyzer / Firewall
Cisco ASA
Firepower FTD
Cisco Any connect
Site to Site VPN
F5 Load Balancing and Scripting iRule
Job Types: Full-time, Contract
Schedule:
8 hour shift
Experience:
Scripting: 5 years (Required)
Data Network: 5 years (Required)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Required)",3.6,"Total IT Global
3.6",Sydney,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Engineer - Processing & Analysis,-1,"Job Description:
Design,build and maintain the ingestion system to support various types of data(e.g. User behavior, RDS, NoSQL db and others) to be ingested to the data warehouse more timely and accurately
Translate data requirements into scalable technical data service with low latency and high concurrency
Design,build and maintain the batch or real time data pipeline in production using Hadoop big data technology
Analyze and improve efficiency, scalability, and stability of the system
Define and manage SLA,Data quality for all data sets in allocated areas of ownership
Requirements:
Minimum B.S. degree in Computer Science or a related technical field
2+ years of working experience in programming languages,such as Java,Scala,Python
Familiar with Hadoop, Spark and Flink data processing, experience of TB data processing experience is a plus
Familiar designing and operating of a robust distributed system is a plus
Understand data mining or machine learning
Excited to work intimately with data
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"SYNOPSIS:
Lead Data Engineer
Applications close Sunday 8 November 2020
Ongoing
Contact name: Shyni Sasikala
Phone: (02) 6249 9048
Email: Shyni.Sasikala@ga.gov.au

The Data Policy and Informatics section within the Digital Science and Information branch creates, implements, and promotes policies, platforms and tools that improve and support the quality, discoverability, accessibility, and general usability of Geoscience Australia’s science data products. The section consults with internal and external research, government and industry partners to establish collaborative data frameworks, architectures and models within Geoscience Australia (GA) and across broader national and international communities of practice. The section innovates, builds and maintains tools, systems, processes and governance that enable digital data management, cataloguing and open data delivery.
GA makes accessible a wide range of geoscientific and spatial data to a wide variety of stakeholders in multiple formats, and in recent years GA's data volumes have grown exponentially. GA is focussed on making its data and metadata assets accessible so that they can be used in machine to machine interactions for data analytics and other applications in environments that range from High Performance Computing (HPC), through high-end cloud servers, to mobile devices.
We currently have two opportunities for Lead Data Engineers in the Informatics team. The Lead Data Engineer is responsible for innovating and exploring new technologies that will advance GA’s science goals and maximise the uptake and use of GA’s science data. The Lead Data Engineer reports to the team’s Assistant Director but also works closely with other developers, data scientists and engineers within the Digital Science and Innovation (DiSI) branch, as well as diverse stakeholders both within and external to GA.",3.9,"Geoscience Australia
3.9",Canberra,-1,501 to 1000 Employees,2001,Government,Federal Agencies,Government,$100 to $500 million (USD),-1
Data Engineer,-1,"The Seven Network is part of Seven West Media, one of Australia’s most prominent media companies, with a market leading presence in content across broadcast television, online and in print. Comprising some of Australia’s most renowned media brands, SWM includes not just Seven Network and its affiliate channels 7two, 7mate, 7flix and BVOD offering 7plus, but also 7NEWS.com.au, The West Australian, The Sunday Times and more.
At Seven we are here to bring all Australians closer to the moments that move us - we’re first on the scene, with our finger on the pulse, on demand, in the moment. Together, we’re responsible for creating and sustaining authentic Australian engagement.
A new and exciting opportunity has opened for a Data Engineer to join the Audience Intelligence team. Based in Sydney and reporting to the Head of Data Enablement, you’ll be responsible for:
Implementation of end to end data solutions to support Data Strategy for the SWM group.
Work closely with the Data Solution Designers to develop and maintain scalable data pipelines and build out new file and API based integrations to address requirements from the various business stakeholders.
Collaborates with engineering, analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organisation.
Work on Data Preparation for analytics and data scientist team members and assist them from an engineering perspective in building and optimising the models including building the automation of the end to end workflows
Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.
Perform data analysis required to troubleshoot data related issues and assist in the resolution of production data issues.
Work effectively with vendors for successful delivery of projects and acceptance of the solution
Work on Delivery projects using Agile Software Development methodologies
We are looking for someone who has:
Bachelor's degree in computer science, computer engineering or other technical discipline is essential
Proven experience working as a digital analytics specialist
Extensive experience with digital analytics implementation (e.g. Google Analytics, Snowplow, Adobe Analytics) and BI processes and visualisation platforms
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience in ETL and building and optimizing ‘big data’ pipelines and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Experience with big data tools: Hadoop, Spark, etc., AWS cloud services: EC2, S3, Lambda and familiar with version control systems: Git
Strong coding skills with knowledge of Unix/Linux and scripting languages such as Unix Shell scripting, Python desirable
Experience supporting and working with cross-functional teams in a fast-paced environment.
Ability to multi-task and problem solve with changing demands and priorities
Ability to work under pressure to meet deadlines and detail oriented
Your success is our success: we will provide you with opportunities for you to keep learning and growing, enabling you to challenge and develop yourself. In return, we offer a benefits program that has something in it for everyone.
Seven West Media is an equal opportunity employer and we are committed to creating a diverse and inclusive workplace.
Recruitment Agencies: Seven West Media does not accept any unsolicited agency resumes and will not be responsible for any fees related to unsolicited resumes.
Advertised: 19 Oct 2020 12:00 AM AUS Eastern Daylight Time
Applications close:

Back to search results",2.5,"Seven West Media
2.5",Sydney,-1,5001 to 10000 Employees,1956,Company - Public,TV Broadcast & Cable Networks,Media,Unknown / Non-Applicable,-1
BICON Rules Engineer,-1,"APS 5 - $73,299 - $80,410 per annum plus superannuation
Biosecurity Plant Division
Canberra, ACT
Play an active role in managing biosecurity risk to Australia
Work in a motivated and professional team with a wide range of skills and backgrounds
Full training provided

Who we are
The BICON Content Development Team maintains and improves the Biosecurity Import CONditions database (BICON) content to allow external clients to understand and comply with their biosecurity obligations and internal clients to effectively manage biosecurity risk and regulate imports. We work collaboratively with internal clients to comprehend and implement their BICON content requirements and optimise the use of BICON to publish clear import requirements and onshore management support procedures to effectively manage biosecurity risk.

The Jobs
Key duties of these positions include:

working with business content (import and permit conditions) and import programs to understand and construct decision tree structures in the BICON database, in accordance with system design and authoring conventions
executing changes to import and permit conditions in alignment with service standards while complying with system rules and authoring conventions
providing technical advice through various formats on the most appropriate means of authoring BICON content to achieve import program and stakeholder objectives
using workflow management tools to maintain detailed records of changes to import conditions and key decisions
performing administrative tasks including system reporting, data analysis and scoping tasks for the BICON content change work program
contributing to the development and maintenance of instructional material, authoring conventions and courseware
clearly documenting and reporting system issues
developing and maintaining effective working relationships with internal and external stakeholders.

What we are looking for
Knowledge and experience
Experience working with complex IT systems.
Experience working collaboratively and as part of a team.
Knowledge of the role of biosecurity is preferred but not essential.

For additional information, please read the Job Description below.
Candidate Information Package docx Opens in new window",3.9,"Department of Agriculture & Water Resources
3.9",Australia,-1,5001 to 10000 Employees,-1,Government,Federal Agencies,Government,$500 million to $1 billion (USD),-1
Cloud Data Engineer,-1,"Job no: 509605
Work type: Permanent Full Time
Location: Melbourne, Canberra, Sydney
Do you embrace digital disruption?
Do you love solving complex problems, designing sophisticated solutions and building innovative technology?
Do you believe in creating powerful actionable insights from Data and Analytics?
Do you want to work in a diverse and flexible working environment?
KPMG is one of the most trusted and respected global professional services firms. Through depth of expertise, clarity of insight and strength of purpose we help our clients solve complex challenges, steer change, strengthen, transition and grow. We are a team based practice and this extends to our clients whom we work and collaborate with, in solving complex problems. Together, we design, innovate and implement, providing enduring advice that support our clients and the services they deliver. Our clients vary in size and come from a diverse range of sectors – all sharing in a common goal: to embrace change and deliver services that make Australia a better place. We are looking for talented individuals who would like to join us on the journey.
KPMG’s Digital Delta Team
We re-imagine and re-invent organisations to become world class digital enterprises using advanced technologies, data and human insights. We help organisations to embrace Digital Strategy, Artificial Intelligence (AI) & Cognitive, the Internet of Things (IoT), Data, Analytics & Modelling, Mobile App & Web, and User Experience (UX) & User Interface (UI) and more.
We work with clients to:
Formulate strategies that re-imagine organisations
Harness innovation from the 4th industrial revolution
Actioning insights from trusted data to consistently and quickly make clear decisions
Build adaptive organisations
Thrive as a connected enterprise – front, middle and back office
This is how you’ll contribute:
We are looking for ambitious Data Engineers who are passionate about helping clients define bold ambitions and deliver on them. Joining our team will take you on a journey of personal and technical growth and provide the opportunity to inspire confidence and empower change.
As a Data Engineer you are the designer, builder and manager of the information or ""big data"" infrastructure, preparing data for analytical or operational use. You will design, construct, test and maintain a data pipeline to pull together information from different source systems; integrating, consolidating and cleansing data; and structure it for use in individual analytics applications.
The KPMG Difference
Our people are focused on creating a diverse and dynamic environment that embraces and values differences. We value the variety of unique experiences, qualities and characteristics our people possess and we share and learn from each other.
We are proud to be consistently recognised as an employer of choice for women, and for our achievements in LGBT+ workplace inclusion.
Our commitment to ‘Flexibility’ allows our people to manage the changing demands of work, personal or family life. Explore the links below to hear our people share their experience @ KPMG:
Flexibility empowers wellbeing
Flexibility enables contribution to the community
Flexibility inspires technology & innovation
Flexibility supports family

Make KPMG the clear choice for your career and be Extraordinary!

Advertised: 09 Sep 2020 AUS Eastern Standard Time
Applications close:",3.8,"KPMG
3.8",Sydney,-1,10000+ Employees,1987,Subsidiary or Business Segment,Accounting,Accounting & Legal,$2 to $5 billion (USD),-1
Computer Network and Systems Engineer,-1,"Duties Include but are not limited to:
Tasks Include:
analysing, developing, interpreting and evaluating complex system design and architecture specifications, data models and diagrams in the development, configuration and integration of computer systems
researching, analysing, evaluating and monitoring network infrastructure to ensure networks are configured to operate at optimal performance
assessing and recommending improvements to network operations and integrated hardware, software, communications and operating systems
providing specialist skills in supporting and troubleshooting network problems and emergencies
installing, configuring, testing, maintaining and administering new and upgraded networks, software database applications, servers and workstations
providing network programming in support of specific business needs and requirements
preparing and maintaining procedures and documentation for network inventory, and recording diagnosis and resolution of network faults, enhancements and modifications to networks, and maintenance instructions
monitoring network traffic, and activity, capacity and usage to ensure continued integrity and optimal network performance
Skills and Experience Required:
Must have experience working in a Managed Service environment
Demonstrated experience in IT Networks and Data Centres
Understanding of systems and architectures to meet client needs
Experience in Help Desk including break / fix
Effective and timely documentation
Effective Task Management Skills
Be solution and outcome focused and willing to learn new technologies
Excellent communication skills with staff, clients and partners
Time management, ability to prioritise and deliver to schedule
Experience with N-Able and Connectwise desired
Open Cabling license desired
Job Types: Full-time, Permanent
Salary: $30.00 per hour
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,Trans-plant training,Canberra,-1,-1,-1,-1,-1,-1,-1,-1
Software Engineer (Data),-1,"If you are looking for an opportunity to make a real impact with smart people who are genuinely doing things differently then you've come to the right place! We're growing our data engineering capabilities and are looking for awesome data engineers to join our team.
With our diverse range of clients and projects, no day will look the same - but here's a great snapshot of what you'll be doing:
Work with some of the best Data Scientists and Engineers to deliver production-grade AI and Machine Learning systems as we deliver client projects from inception to production.
Consulting with our clients and working with them to build modern data systems using the 'best of' technologies and principles.
Advising clients on data strategy, architecture and technology.
Applying best software engineering practices in coding, monitoring and alerting, using CI/CD, TDD and cloud architectures.
Working over a wide range of big data tools and environments: not limited to; Apache Kafka, Spark, Python, Scala, Hive, Airflow, AWS EMR & Glue, GCP Dataproc & Dataflow, BigQuery, Snowflake, Redshift.
Who are we?
Glad you asked! We are Eliiza. Data science. Engineered for scale.
We are a passionate team of data scientists and engineers who apply data science and machine learning to solve real-world problems. Our mission is to create a bright future for Australian businesses and society in a world increasingly influenced by intelligent technologies.
We've created a culture that values diversity where people can truly be themselves! We care a lot about growing the Australian AI community in a positive direction, and we're doing several things to try and achieve that:
We provide opportunities for underrepresented groups to work in AI through our associate and intern programmes
We organise and participate in a range of community events, reading groups and meetups
We produce the AI Australia podcast
We blog about topics we care about
We stream brown bag sessions to the broader community
We're also part of Mantel Group's 'house of brands' which means it's not just the Eliiza team you'll work with, learn from and see at social events - there's another 230 of us across DigIO, Kasna & CMD Solutions!
So you're ready for something new?
We're keen to know more about you! Our team is made up of a range of people, with different experience across a huge range of data driven skill sets.
We'd love to hear from you if you have experience with:
one (or more) core language(s), ideally Scala, Python or Java
one (or more) cloud platforms, AWS, GCP, Azure
ETL/ELT concepts and technologies e.g. Data partitioning, Hive, Spark
streaming data concepts and technologies, ideally Kafka (Kinesis, Beam or Pubsub will do)
We'd be over the moon if you:
Experience with distributed/columnar databases (e.g. Snowflake, Big query, Redshift).
Experience with any of a variety of databases e.g. RDMS, NoSql, Columar, Distributed, Time series, Graph.
Knowledge of job orchestration and scheduling. Any experience with Airflow, Luigi or Oozie.
Experience with containers and container orchestration (Docker, Docker Compose or Kubernetes).
However, we value a diversity of skill-sets, and don't necessarily require that you're skilled with all of the above. If you feel you don't fit all the experience/skills listed above we still encourage you to apply or get in touch.
What's on offer if you join us?
We make sure you're always one step ahead by investing your learning and development, every year. We build our own training where it doesn't exist yet.
We hire smart people and get out of their way. By focusing on our five principles and not getting caught up in red tape, we trust you to get the job done.
You'll get all the tools you need - a new iPhone or Google phone, a new Macbook Pro or Dell, and a lot of branded swag!
But hold on, you mentioned a house of brands?
We certainly did! Mantel Group is an Australian-owned, 'house of brands' company with four technology businesses (Eliiza being one of them!) across Melbourne and Sydney. We're building a group of companies with open borders so we can support you to take on new skills without leaving an awesome team - we understand you won't have one job for life!
We may only be just two years old but Mantel Group has already been recognised #9 in the 2020 Best Places to Work in Australia and #4 in the AFR's 2020 fastest growing new companies.
Keen to chat?
Click ""Apply"" to share your details with our talent team, and we'll be in touch.
In the meantime, check out 'how we hire' to find out what's in store if you're successful and get to know us better by visiting our website and following Eliiza on LinkedIn.",-1,Eliiza,Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Infrastructure Engineer,-1,"Job Description:
Design and grow the Shopee data platform to support a variety of big data applications using open-source technologies including Kafka, Hadoop, Presto, HBase, Spark, Hive, Druid, and our own creations. Some examples include a real-time data streaming platform, a unified query platform, a cluster management system, and a machine learning platform
Dig into the source code of some open-source big data system to get the whole control and familiar with the details, configurations, designs and source code. Develop and maintain the internal release of big data systems and components as the business requirements.
Keep close and overall monitoring for all the deployments of the systems, maintain the system’s stability, improve the performance, discover the performance bottlenecks, tracking and troubleshooting, cost optimisation.
Requirements:
B. Sci. / Ms / PhD in Computer Science or a related technical field
Familiar with at least one of these languages: Java, Scala, Python, Bash under Linux / Unix. Scala is a plus
Familiar with the use and compute logical of SQL
Knowledge about the Big Data Infrastructure system technology like Distributed File System, Distributed Computing, Distributed Database will be a plus
Hands-on experiences Hadoop, Spark, Kafka, and/or Presto will be a plus
Love to use and develop open-source technologies
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"Work on an award-winning, international technology!
Endless career opportunities
An innovative, friendly team of 300+
This role will be focused on the development of our existing ClaimLogik line of products as well as working on our new cloud-first, modern suite of applications.

Intelligent Thought, our technology business is scaling and shipping our software globally. Already profitable, part of a much larger group business, with investors such as Macquarie Capital and Envest – we are all set to deliver textbook disruption to the Insurance Industry. The growth of the platform, of our customer base, and the increasing industry demand have led to the need for this role to help the team scale.

Our Philosophy
Give each employee a sense of purpose and an environment for them to connect the importance of their role to delivering a service that matters to our customers.
Challenge the ‘why’ of traditional claims processes.
Keep it simple – do only what brings value and what matters to the customer
Enable employee decisions, empower our people
Responsibilities:
Create, extend and maintain ETL pipelines to form our data lake, data warehouse and analytics platform (currently using the Microsoft Azure set of tools and service)
Help define the optimal data pipeline architecture
Influence the tool selection, platform selection, data architecture and strategy which will transform the business to be truly data-driven
Understand, analyse and size user requirements
Work with different parts of the business to provide them with the insights they need to deliver the best results
Skills & experience:
Degree or qualification in computer science or related
Advanced knowledge of relational database, including query authoring and query optimisation (MS SQL Server and PostgreSQL).
Experience building and optimising ETL pipelines
Experience designing complex data models
Experience working with cloud platforms (Azure or AWS)
Efficient time management and organisational skills
High attention to detail and accuracy
Effective communication skills to build strong working relationships; both written and verbal
Proactive and results-driven
Why Claim Central?
Claim Central Consolidated is a global insurance industry leader across, claims management, insurance technology and data and analytics. Currently operating in the United States, Australia, South Africa, Italy and New Zealand, we have pioneered digitally connected claims management services across the globe. Claim Central is a disruptor and thought leader in the industry and we were recognised as the Australian Financial Review’s 8th Most Innovative Company in Australia in 2016. This business is in a period of unprecedented growth, transitioning our technology and services into multiple geographies at a rapid pace. Our unique culture is based on teamwork, collaboration, trust, respect and performance. We also offer many benefits apart from our exceptional team culture; including flexible work arrangements, and continued professional development.

Be a part of this journey in a career-defining role.",-1,Claim Central,Matraville,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer - AI/ML,-1,"Our client provides services to a major industry across the country. The business is still early in it's days of technology development and the environment is greenfields in nature (no pun intended), effectively working like a start-up.

Their data and analytics team have worked and built leading and bleeding-edge technologies in this space and what they have created so far may be game-changing. From a machine learning perspective, the progress they have made to the business has already seen proven success in changing the future of an industry that will have positive consequences for all those involved.

You will have previously worked in a technical capacity in the data and analytics space and have experience working with an organisation where machine learning has been implemented, not just a concept that the business talks about having or the technology team would love to have. The commercial experience you will have had in the ML field will be proven examples of where you have affected the way a business or industry used to perform, to the changes that have come about from this.

Technically, you will have extensive experience in the Microsoft space - Power BI, Azure etc and you will have previously mentored and coached junior members of the teams you have been part of.

This is a rare opportunity in Brisbane where the business has truly embraced and funded projects across the ML space and would be a great chance for those in the Data Development/Data Engineering field, who are looking to move into a Data Scientist role in the future.

Please send your application through if you would like to know more.",4.0,"Emanate Technology
4.0",Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Solution designer/ ETL Engineer & Data Modeller,-1,"We are looking for a Qualified and Experienced Solution Designer to join our client for a period of 6 months with a view to extend.
You will work closely with team members and your contribution will range across gathering and analyzing information, developing and documenting improved processes and work instructions and experienced DWH Lead with skills in requirement analysis, solution designing, developing, testing and supporting ETL solutions.
A hands-on solution designer, data modeler and ETL developer for Data Warehousing and ETL application transformation projects using Informatica PowerCenter.
Knowledge on AWS, S3, Redshift, Informatica BDM, and related technologies.
Experience working with IPython, PySparks, AuCuMo, Airflow, Jenkins, Github, Athena, JIRA, Rally, Spectrum, Glue, Flyway.
Good exposure on Oracle PL/SQL, aware of DBA activities, writing and performance tuning of complex SQL queries.
Contract length: 6 months
Job Types: Full-time, Contract
Salary: $650.00 – $800.00 per day
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,nducive,Melbourne,-1,-1,-1,-1,-1,-1,-1,-1
"Data Engineer, Wollongong NSW or Mount Waverley VIC",-1,"Company Description
BlueScope is a technically advanced supplier of steel and steel products in Australia. We are an inclusive organisation and every day we showcase our technology and expertise throughout the world.

Job Description
We are looking for two Data Engineers to join our IT team, based in Wollongong NSW or Mount Waverley VIC. Use your experience in analytics to unlock business value, enabling use of big data for insights and decision-making.
Reporting to the Data Product Owner for our Australian Steel Products (ASP) business, this position will support strategic goals related to data. This will see you:
Gather business and technical requirements with the view to deliver outcomes;
Develop and implement end-to-end data collection, consolidation, modelling and visualisation solutions;
Document metadata in a dictionary and catalogue;
Ensure consumers of such information understand its accuracy, timeliness, quality and sensitivity, so that it is used appropriately; and
Identify opportunities to enhance analytics.
What are the benefits?
Work in a supportive and collaborative team environment whilst we embark on a journey to transform the way our business uses data!
Our systems landscape is broad and diverse. You will be encouraged to think creatively to develop data solutions which solve real business problems.
Working in this role you will enjoy:
the chance to learn more about data science;
salaried remuneration with attractive superannuation options;
the opportunity to participate in a performance incentive scheme; and
access to further development and career opportunities with BlueScope.
Who are we looking for?
We welcome applications from professionals with experience in data analytics and/or programming. Supported by your knowledge of project delivery methods (e.g. Agile), you will demonstrate:
experience with data mining, wrangling, mapping and visualisation techniques (e.g. Azure Data Factory, Databricks and/or DevOps etc.);
well-developed ability in gathering business and technical requirements;
skills in developing and implementing collection, consolidation, modelling and visualisation solutions; and
a passion for sharing your knowledge and desire for ongoing professional development.

Qualifications

null

Additional Information
We're proud to have been named an Inclusive Employer for 2019–2020 by the Diversity Council of Australia. We believe that our people are our strength. Having a diverse and inclusive workplace enables us to improve our capability and ensure continued, sustainable success.
We know that workplace flexibility can mean something different to everyone. Under our B-Flex initiative all of our roles have some degree of flexibility. We encourage you to discuss your needs with us.
Applications close Sunday 25th October 2020.",3.3,"BlueScope
3.3",Wollongong,-1,201 to 500 Employees,-1,Company - Private,Construction,"Construction, Repair & Maintenance",$100 to $500 million (USD),-1
ETL Data Engineer,-1,"ETL Data Engineer

Join a team that’s changing how Australia lives, works, plays and grows
We want you to be the best version of you

Work with innovative teams and explore new technologies to help solve real-world problems.

A typical day as a Data Engineer

ETL / Big Data Engineering professionals will be responsible for guiding the full lifecycle of a Data solution, including:
Working in highly client-facing roles to contribute throughout the end-to-end delivery lifecycle of complex and large-scale digital solutions
Use case and business case development
Support existing and new applications utilizing in-depth technical and data knowledge. Troubleshooting complex issues and providing advisory services to improve the client’s data landscape
Help to streamline and simplify the clients’ complex data landscape by integrating different applications and data architectures
Implementation from requirements analysis, platform selection, digital architecture design, application design and development, testing, and deployment
Interstate travel may be required

Basic qualifications:
Bachelor’s degree
Experience across systems integration, information management, data management and architecture, and business analytics
Experience with being in a team focusing on large-scale, multi-release information centric projects
Experience with waterfall and agile delivery and run / application support functions
Part of a team working on End to end implementation of at least 1 big data project

Preferred Skills:
Hand on experience in Data warehousing using ETL tools such as DataStage, Autosys and TeraData
Hands on experience in ETL job development with multiple stages like sequential file, Transformer, Lookup, join, sort and Database stages.
Strong hand on skills in design, development and implementation of various data remediation, Data migration, data integration techniques.
Strong hand on data modelling experience.
Strong hands on experience in database performance tuning including complex query optimizations and physical database tuning using Teradata.
Understanding of architectural designs and strategy related to data migration, data cleansing, data quality and data consolidation.
Proven data analysis, requirement gathering and problem-solving skills
Exposure to Unix environment and shell scripting.
Experience in Banking and Financial services industry
Desirable: Knowledge of cloud computing infrastructure (e.g. Amazon Web Services EC2, Google Cloud, Microsoft Azure)
About Accenture

Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. We combine unmatched experience and specialized capabilities across more than 40 industries — powered by the world’s largest network of Advanced Technology and Intelligent Operations centers. With 513,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises. Visit us at www.accenture.com.

Accenture is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, marital, domestic or civil partnership status, sexual orientation, gender identity, or any other basis as protected by applicable law.

Vera Goga is the Recruiter managing this role. As the team experience high volumes of applications, we appreciate your patience to allow for a fair and timely process.",3.9,"Accenture
3.9",Sydney,-1,10000+ Employees,1989,Company - Public,Consulting,Business Services,$10+ billion (USD),-1
Student Engineer,-1,"The candidate will have the ability to:
Undertake onsite inspection to collect asset condition data based on the relevant engineering standards and technical guidelines;
Undertake desktop analysis to evaluate the condition and performance of the assets;
Provide the appropriate information, advice, engineering input and support services for the sustainable management of Council’s stormwater and transport networks.
Qualifications:
The successful candidate will be enrolled in a Bachelor of Engineering with a minimum of two years completed.
Position Number: 100678
Position Hours: Fixed term (3 months), hours will be negotiated with the successful candidate, maximum of 75 hours per fortnight.
Salary: Schedule A, Salary Point 4.0. $28.64 per hour ($55,853.45 per annum, pro-rata) in accordance with Glenorchy City Council’s Enterprise Agreement 2016
Please note that all successful applicants will be required to provide a current National Police Check prior to commencement of employment.
For further information on this position, contact Patrick Marshall, Senior Civil Engineer on (03) 6216 6800.
How to apply: Applications for this position must be lodged on this submission site or on the Glenorchy City Council website www.gcc.tas.gov.au - Careers page.
To be considered for this role, all applicants must address the key selection criteria in the and provide a current resume. A copy of the position description can be found by clicking the below hyperlink or on the Glenorchy City Council website.
Applications close at 8pm on Sunday, 1st November 2020
- Student Engineer",4.0,"Glenorchy City Council
4.0",Glenorchy,-1,501 to 1000 Employees,-1,Government,-1,-1,Less than $1 million (USD),-1
Data Engineer involving DevOps,-1,"Data Engineer involving DevOps
Axiom Technologies is an Australia based entity with the history of providing Managed IT solutions to medium to large scale enterprises globally. Please visit our website for more information about what we do at www.axiomtechnologies.com
Axiom Technologies is an Equal Opportunity Employer and encourage applicants from all backgrounds and gender to apply, including, Aboriginal and Torres Strait Islander candidates
Job Requirements:
8+ years IT experience, with at least 5+ years of “Data Engineer/Deveoper” focused titles/roles,
Data Tools: Hands on experience with Apache Beam.
Testing: Hands on experience with automated testing activities/outcomes
DevOps: Experience with the processes involving Microservices facilities for artifacts developed
Platform/OS: Mid-range/Unix
Languages: Unix (Shell) Scripting/commands, SQL, Python
File formats: Text, CSV, Parquet, JSON, XML
Scheduling: Jenkins, Airflow
Auto Scripting: Designing/creation of scripts for repetitive activity. E.g. Unix scripting/SQL
Big data: Exposure to Data Lake Concepts, Hive (Schema), HDFS
Source Control tools: GIT
Delivery Models: Agile, Scrum
Ingestion Design: Create/assess Source/Target data mapping designs
Frameworks: Development and delivery frameworks
Activity Reporting/Repository: Jira, Confluence.
Quality: Accuracy and attention to detail
Industry: Financial Services/Banking
Solutions: Define solutions from High level to detail design to address automating ingestion activity. Facilitate/confirm requirements from product owners, business team members and technical associates,
Process Automation: Automating processes in file management, testing data in files, analysis and design, configuration management.
Script Automation: Ability to design/create scripts to automate/improve data copy/migration/ETL for any repetitive activity.
Languages: Java, Python
Scheduling: Control-M
Databases: Relational. E.g. POSTGRESS, Oracle – as a ETL developer
File Formats: Mainframe – experience with referencing its data formats/copybooks
Big data: Experience referencing/using Hive (Schema) to access data in HDFS
Metadata management tools: MDM, EDC and Axon
Performance: Assess, recommend, improve mappings, SQL queries, Batch feeds
Automation Tools: Other tools that may add value to an automation program and generally support development. E.g. API, REST, JDBC, Webservices, Message Queues/Load balancer,
Cloud: Experience with processing of data files to be ingested/stored in the Cloud, preferably with AWS.
Prod Support: Experience in a production support role performing root cause / impact analysis – under time constraints
Experience in a similar role
8+ Years
What next?
If you are looking for that next challenge in your career and wish to apply for this role, please forward your resume to careers.au@axiomtechnologies.com",2.0,"Axiom Technologies
2.0",Melbourne,-1,1 to 50 Employees,-1,Company - Private,Industrial Manufacturing,Manufacturing,Less than $1 million (USD),-1
Data Engineer,-1,"About the Role
We are on an exciting digital journey so it’s a great time to join ME! We are seeking a Junior Data Engineer who enjoys rolling up their sleeves, learning and growing. As part of our Enterprise Data Team, you will ensure fit for purpose data warehouse solutions are built for use across the bank and by utilising best practise ETL standards, whilst ensuring the data is trusted by our BI developers and key business consumers. Oh, and you’ll get to work on Microsoft technology stack too!
You will be involved with investigating data issues, keeping data feeds flowing and collaborating with different projects across the bank to deliver quality data solutions. How important does that sound? What’s even more important is this role contributes directly to our overall business strategy through the provision of data to enable analytics & reporting, as well as supporting business and decision system processes.

About You
You’re naturally a highly motivated and energetic person who thrives in a dynamic, ever-changing collaborative team environment. Ideally you have previous experience as an ETL developer, Data Engineer or a BI developer, and if you have a degree in computer science or similar it would really put you ahead of the rest.

With your knowledge of SQL coding, data modelling, understanding of data warehouse concepts, plus experience of working on complex ETL solutions, you’re ready to expand your horizons and launch your career into the world of IT at ME.

About ME
We’re not like other banks.
ME was created by the industry super funds to be different from the pack – with a core purpose to help all Australians get ahead financially – no conditions, asterisks or exceptions. And we know that looking after customers starts with taking care of our people.
We believe everyone deserves the same opportunities in life, regardless of gender or identity, sexuality, ethnicity, religion or disability ‒ with internal affinity groups.
Perk ME up
Once you get your feet in the door at ME, we’ll put them both in your very own ME-branded Converse shoes. You’ll also get the following financial, health and fun perks when you join the team:
4U Extras portal (discounts and cashback on 100s of items including cinemas, shopping and gym memberships
10% Myki discount
Purchased Leave programme
Internal wellness programme (Mindfully ME)
Professional education through LinkedIn Learning
Novated Leasing
Professional membership reimbursements
Health checks
Financial education (To help you manage your money smarter)
LGBTIQ+ and Women at ME affinity groups

I want those Converse shoes (and the role)
Can’t see a closing date on the advert? That’s because we’re pretty efficient here at ME and we may start looking at applications sooner rather than later, so if this role sounds like your jam, be sure to apply by submitting your resume today.

Should an applicant be the preferred candidate, background checks (including police checks, reference checks, ASIC banned and disqualified persons and bankruptcy checks) will be completed prior to the candidate's employment being confirmed. The outcomes of the background checks do not automatically bar candidates; however will be assessed against the inherent requirements of the job.
Back Share
Apply Now",3.0,"ME Bank
3.0",Melbourne,-1,501 to 1000 Employees,-1,Company - Private,Banks & Credit Unions,Finance,$100 to $500 million (USD),-1
Software Engineer - Machine Learning/Data Science,-1,"Zendesk is looking for a Software Engineer - Machine Learning/Data Science for a full time position in our Melbourne office.
As part of our engineering team, you will work at a scale where the challenges start to get seriously interesting. Our global engineering team is widely dispersed over the world, with people across nearly every continent. You will get a chance to do cool things with a diverse bunch of people while working in the Melbourne office that is home to Zendesk’s first machine learning (ML) research team.
The Data Science Team, together with Data Engineering, have built Satisfaction Prediction, Answer Bot and Content Cues — products that use Machine Learning (ML) and Artificial Intelligence (AI) to help our customers work more efficiently.
What you get to do every day:
We’re currently looking for someone to join our team as we research, develop, and productionise Machine Learning and Deep Learning models. In addition to frequenting Melbourne’s finest purveyors of coffee, ramen, and bulgogi, you may find yourself:
Building machine learning models including neural networks in TensorFlow
Writing and deploying production-grade Python
Querying and constructing datasets in AWS Athena, Spark
Evaluating and responding to real-world model performance
Scaling your ML to millions of predictions per day
Presenting your work to a broader audience
Watching your algorithm help Zendesk’s end-users
What you'll bring to the role:
A strong foundation in a quantitative discipline (e.g. machine learning, statistics, bio/eco/etc-informatics, econometrics, etc) is critical for this position. While experience in deep learning and natural language processing would be beneficial, your best qualities are:
dedication to continuous learning
collaborative work attitude
strong communication skills
You should also be comfortable with at least one programming language, such as Python, R or Scala.
Application Deadline: 18/11/2020
Job Types: Full-time, Permanent
Salary: $85,000.00 – $110,000.00 per year
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Temporarily due to COVID-19",4.5,"Zendesk
4.5",Melbourne,-1,1001 to 5000 Employees,2007,Company - Public,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),-1
Software Engineer (Machine Learning),-1,"About the Role
AdelaideMRI is building a medical reporting tool. We require an engineer to work primarily on machine learning projects to improve reporting speed and report comprehensiveness.
You will perform data analysis of medical report datasets and image datasets to infer sentence recommendations, image classifications, or other actionable results for the doctors.
Skills and Experience
Background in machine learning or image processing
Qualifications in Computer Science, Software Development or Engineering or equivalent experience
Bonus points for Python
No prior medical knowledge is required.
This position offers flexible hours and work arrangements.
Job Type: Full-time
Experience:
Software Engineering: 1 year (Preferred)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Yes",-1,Adelaide MRI,Australia,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Hey there, we’re PEXA!

We started as an idea: to deliver a single, national e-Conveyancing solution. We collaborated with the industry to create a national electronic lodgement and settlement platform: PEXA. From our humble beginnings, we’ve now grown to more than 320 employees across 5 different states. We’re still expanding at a rapid rate and constantly challenging ourselves to create great experiences for our members as they transition to fully digital conveyancing.

Why become a PEXArian?

Great question! Being a PEXArian is so much more than just a job. We are passionate, motivated & unashamedly enthusiastic at PEXA - we love what we do and we’re proud to admit it! Creating brilliant member experiences wouldn’t be possible if we didn’t also strive to create an amazing employee experience. Alongside our members, our employees are at the heart of everything we do.
Here’s a snapshot of what your life at PEXA could look like:

Your growth:
We encourage you to hit your personal and professional Learning & Development goals with our tailored programs and tools.

Your wellness:
We care about your holistic well being - a fully stocked kitchen, four wellness days, a $250 wellness subsidy as well as lunch and learn sessions to support your financial well being.

Your work/life blend:
We know that work is just one aspect of your life, we want to help you create your ideal work/life blend, rather than squeezing in life around work.

Your family:
With a range of benefits aimed at supporting your family including access to a subsidised school holiday program, extended parental leave and flexi-time to support your return to work, superannuation payments for unpaid parental leave for primary carers and a childcare allowance for pre-primary aged children, when we say, ‘welcome to the family’, we really mean it!
The impact you'd drive:
The successful candidate will be responsible for developing, and maintaining infrastructure to support the delivery of new and existing products. They will also be contributing to establish the rules and frameworks for obtaining the required approvals for new products.
On day one we’d love you to have:
Experience with Python, Spark
Event streaming/sourcing with Kafka or AWS Kinesis
Experience with data structures, formats and data security best practices
AWS experience (e.g CloudFormation, S3, ECS, Lambda, SQS, IAM, KMS, DynamoDB, Glue, Athena)
Query construction and optimisation (e.g. SQL, Elasticsearch, Splunk, DynamoDB)
Git, version control practices, and continuous integration/delivery servers
PyUnit and unit testing frameworks
Production release cycles and maintenance
Collaborating with technical and non-technical teams
Even better:
Agile methodology/delivery
GraphQL
Modern frontend technology (e.g. ReactJS, TypeScript)
Machine learning frameworks and tools (e.g. TensorFlow, PyTorch)
OAuth 2, SAML 2, JWT
Data visualisation and exploration tools (e.g. Jupyter notebooks, Tableau)
AWS SageMaker
Sounds like you?
If this role sounds like you, apply today to have your application reviewed ASAP!",3.9,"Property Exchange Australia Limited
3.9",Melbourne,-1,201 to 500 Employees,2010,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Ongoing position
Full time
Based in Sydney, NSW
Who we are
Australian Red Cross is part of the world’s largest humanitarian organisation. Our aim is to improve the lives of the most vulnerable people in Australia and across our region.
About the role
The Data Engineer role will sit within the Data and Integration Squad in IT and will own (design, implement and support) the AWS Big Data technologies such as the Data Lake and Data Warehouse and support the organisation in growing the data analytics capabilities at Red Cross. In addition to this, the data engineer role will also administer the Power BI tool and support the implementation of the data mastering capability.
What you will bring
Experience building and optimizing data pipelines, architectures and data sets.
Experience in dimensional modelling and building data vaults
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with structured, semi-structured and unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Why work for us?
Work for purpose and know that your work assists Red Cross support and empower people and communities in times of vulnerability.
Generous salary packaging options available that can increase your take home pay.
Further information
To find out more about this opportunity please see the position description below or contact Sharath Kumar Gurram on 02 8651 8839.
Position Description: Position Description - Data Engineer .pdf
Applications for this position will close at 11:55pm Thursday, 5 November 2020.",4.1,"Australian Red Cross
4.1",New South Wales,-1,1001 to 5000 Employees,-1,Nonprofit Organization,Industrial Manufacturing,Manufacturing,$500 million to $1 billion (USD),-1
Junior Fullstack Data Engineer (Python and React),-1,"Formbay is the leading Renewable Energy Certificate Trading company in Sydney. We provide Digital Workflow and Compliance solutions in the renewable energy industry and document processing.
Thanks to our meteoric growth and our commitment to be the best at all we do, we've identified the need to bring on board a new Junior Fullstack Data Engineer.
Reporting to our Principal Machine Learning Engineer, you will help build Machine Learning pipelines for our existing Digital Workflow and Compliance solutions to automate fraud detection and document processing over terabytes of photographic and documentary data – including documents, photos, GPS data and aerial/satellite photography.
Our stack is based on Python, JavaScript, Dask, Tensorflow, CUDA, Nix/NixOS, AWS, Docker, PostgreSQL and more – familiarity with these applications will give you a leg-up on the competition.
Our ideal candidate will have the following competencies:
SQL
Python
JavaScript/TypeScript
Our candidate must also be comfortable working with Linux.
Located a stone's throw away from the Queen Victoria Building in Sydney's bustling CBD, we are centrally-located with easy access to public transportation, bars, cafes and fine dining.
Formbay will provide flexible working hours, a generous remuneration package and the opportunity to work on a world-first software solution are what we can offer you. Free, twice-weekly gym sessions and really, really good coffee are also available.
No hiring/recruitment agencies need apply.",5.0,"Formbay
5.0",Sydney,-1,1 to 50 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is an experienced and qualified Data Engineer to join our IT team based in Birtinya.
Key Responsibilities:
Create and maintain data pipelines and or ETL scripts
Create and maintain data integration including API and Batch interfaces
Performed detailed data analysis
Create and maintain corporate data models
Create and maintain data visualization using Qlik.Sense , PowerBI or Simliar Toolset
Experience in defining, building and maintaining data virtualization and/or star schema data warehouses
Maintain, tune and optimise database, integration and visualisation toolsets
ABOUT YOU:
To succeed in this role, you’ll need to bring the following experience and skills:
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Excellent communication skills both oral and written, with an ability to bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking
Experience with data analysis and modelling will be beneficial

How to Apply
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kawana Waters,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Graduate Data Science / Engineer,-1,"The NRMA is an organisation looking to the future, and right now, we are on the lookout for people who can help us reach our goal: to continue to shape the way Australians move, for the next 100 years and beyond. www.mynrma.com.au.
Everyone new to the team, along with our current staff, will temporarily work from home until it is safe to return to our offices. All interviewing and on boarding will be done virtually due to COVID-19.


Your opportunity
As Graduate Data Scientist or Engineer you will be part of the Data Engineering team delivering cloud data transition program for business initiatives and supporting the entire data platform build.
Your key responsibilities will be to:
Implementing Concepts of Data Warehousing, Data Mart creations within Cloud
Use of SQL for data analysis and insights
Building AI/Machine Learning prototype for implementing and supporting existing algorithms
Data Analytical reports build, using different tool sets


Requirements for Success:
Relevant Degree - Computer Science, Computer Engineering, Software Engineering, Data Science
Excellent SQL skills and demonstrated working knowledge in Python
Demonstrated understanding in data structure and algorithms.
Knowledge and concept of data warehousing methodologies
Any reporting tools experience Tableau or Oracle Analytics Cloud, Looker is desirable
Exposure to Google/AWS/Azure/Oracle any cloud based platforms is desirable
Good communication and interpersonal skills

If you have the required skills and the passion to join our high performing team, please apply today.

Employee Benefits
To ensure our employees feel valued, empowered and celebrated we provide a range of employee benefits including:
50% discount on all NRMA insurances
Free Roadside Assistance
12 weeks paid primary and 4 weeks paid secondary parental leave
Free NRMA Blue Membership
At the NRMA Group, we are People Moving People and diversity and inclusion are part of our DNA. Together, we continue to build an inclusive culture that encourages, supports and celebrates the diverse voices of our employees. It fuels our innovation, promotes flexible ways of working and connects us closer to our members and the communities we serve.",2.5,"NRMA Motoring & Services
2.5",Sydney,-1,501 to 1000 Employees,-1,Nonprofit Organization,Casual Restaurants,"Restaurants, Bars & Food Services",$500 million to $1 billion (USD),-1
Data Centre Engineer,-1,"We are a leading world group that provides low-carbon energy and services. To tackle the climate emergency facing us all, our aim is to become the world leader in the zero-carbon energy transition ""as a service"" for our clients – particular for companies and regional authorities. We use our expertise in our key business areas (renewables, gas, services) to provide competitive and bespoke solutions.
The Data Centre Engineer will be employed as part of a 24/7 ongoing shift to coordinate and monitor third party service providers, maintain the data centre facilities and infrastructure plans, coordinate the implementation of customer requests within the data centre and monitor systems, all in accordance with the Contract KPIs and SLAs.
Coordinate and monitor third party service providers for regular maintenance & testing, service faults & call outs, ensuring works are performed in accordance with Contract SLAs
Monitor and maintain the data centre facilities and infrastructure plans and documentation, including electrical, mechanical, hydraulics, fire and BMS/EMS systems
Coordinate the implementation of internal and external customer requests within the data centre
Perform scheduled plant checks and minor maintenance works
Ensure all Work Order requests are raised and closed in a timely manner
Conduct inductions for staff, vendors and contractors
Ensure all work permits for vendor works are raised and closed
Perform inventory checks on all equipment and critical spares

Qualifications
The selected candidate must be able to demonstrate:
Electrical or HVAC background, or Graduate Electrical or Mechanical Engineer
Passionate about quality work and career minded looking for a new challenge
Can commit to a day and night shift roster (2 days of day shift, then 2 days of night shift, 4 days off)
Ideally able to commence asap
As part of carrying out the duties of this role, it is mandatory to hold Australian Citizenship.

If you are interested and meet the selection criteria apply with an up-to-date resume via the apply instructions on this website.

ENGIE Services is an EEO employer, where all applicants are treated with fairness and respect and have equal access to the opportunities available.

We will not be engaging in the services of a recruitment agency to fill this vacancy and therefore request all interested candidates apply directly to this advertisement.

Job
: Maintenance
Primary Location
: Oceania-Australia-New South Wales-Erskine Park
Organization
: ENGIE Services Australia and New Zealand
Schedule
: Full-time
Nature of Responsibility
: Senior operational / administrative role
Job Posting
: Sep 11, 2020, 6:29:59 AM",3.7,"ENGIE Services Australia & New Zealand
3.7",Sydney,-1,5001 to 10000 Employees,1995,Company - Public,Energy,"Oil, Gas, Energy & Utilities",$2 to $5 billion (USD),-1
Senior Data Engineer,-1,"Senior Data Engineer, Temporary, SYDNEY - McKell

Job Title: Senior Data Engineer

Salary: SNSW Grade 9/10 - The package includes base salary range of $111,806 to $134,667, plus employer's contribution to superannuation and annual leave loading.

Location: Head Office – Haymarket

Employment Status: Temporary through till 30th June 2021


About Service NSW:

Service NSW is making it easier for people and businesses across NSW to access government services. The role designs, builds and analyses complex data from multiple sources to identify revenue, process and business improvement opportunities; providing new information and insights to the business to inform planning, continuous improvement and performance.

About the Role

We are currently seeking to appoint a Senior Data Engineer to deliver expert advice and services in the design of a Single View of Customer and data-related services to support the achievement of business outcomes and strategic goals. We support flexible working practices with staff working remotely during this time.

In this role you will:

Design, build and support a modern data platform based in AWS and vendor technologies.
Provide expertise on data modelling for Graph data model and Customer Data Platform (CDP).
Create data pipelines, load, transformation and reporting workloads in AWS.
Work with the latest data engineering technologies like Apache Kafka, AWS Kinesis, AWS Neptune, AWS Glue and AWS Athena.
Contribute to the design and decision-making of the right tool or platform for the job according to requirements.
Provide expert advice and guidance on data quality and data engineering best practices.
Support a “bigger than you can imagine” scale of data in production environments.
Design, develop and support a metrics-driven reporting solution and a meaningful business intelligence platform.
Document the solution design and support procedures of solutions.
Produce reports, visualisations and recommendations to answer complex business problems that are presented in the most appropriate format to ensure clarity for target audience.
Analyse and define new process improvement opportunities to support continuous improvement and business outcomes; providing advice to stakeholders, on ways to improve the efficiency and reliability of data products and services.
Be very responsive to the information needs of the business by corresponding to customers in a timely manner and provide support/solutions to issues raised.
Troubleshoot and perform root cause analysis on production issues. Identify and implement long term solutions to problems. Perform scheduled maintenance, release deployment and production support activities after business hours, from time to time.
Liaise with internal and external customers to discuss and gather requirements, solutions etc. and maintain a good working relationship with the stakeholders.


Skills and Experience Required:

Solid experience with workflow technologies designing and building data pipelines, data models and data stores.
Experience working within and an understanding of Amazon AWS ecosystem, including security and performance tuning.
Hands on experience working with different types of databases, with focus on Graph and NoSQL databases.
Experience with data streaming required. Having used Kafka and related technologies is an added advantage.
Sound knowledge and experience working with batch processing, data extraction and API integration.
Hands on experience with at least one programming language: Java, Python or scripting.
Demonstrated experience working in an Agile based, fast paced, complex environment within cross-functional teams.
Experience developing systematised insights, data analytics and reporting solutions is an added advantage.
Experience with interactive visualisation of data insights is an added advantage.


Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Salary Grade 9/10, with the base salary for this role starting at 111,806 base plus superannuation

Closing Date: 6th November at 9:59am - applications will be reviewed on a rolling basis, applications may close early or extend

Please apply online, direct applications submitted via email will not be considered.

The Department of Customer Service is proud to be an EEO Employer who are fully focused on equality and believe deeply in diversity of all identities making us different and a true reflection of our NSW customers. As an inclusive workplace, we support various employee resource groups, practice flexible work and workplace adjustment.

If you do require an adjustment during the recruitment process, please notify us on your application form.",3.2,"Service NSW
3.2",Sydney,-1,501 to 1000 Employees,2012,Government,State & Regional Agencies,Government,Unknown / Non-Applicable,-1
Data Engineer - Entry / Mid Level,-1,"Work with a great team on interesting projects customers
Gain more experience in AWS, Data, DevOps cloud operations
Got a working knowledge of AWS? We will teach you the cool stuff!

Itoc is seeking an up and coming Data Engineer to join our growing Data Team in Sydney.

This is an exciting role working with databases, data lakes, data warehouses, data transformation (Python SQL) and enabling AI/ML.

You will be implementing foundational, robust and production ready data platforms to enable business data-discovery, self-service, AI/ML functions across a range of client types and industries, allowing them to do more with their data.

You'll be responsible for:

Deploying data repositories such as lakes and warehouses.
Contribute to our growing portfolio of data solutions.
Ongoing optimisation and management of data platforms.
Development of transformational logic for data pipelines
Data evangelism. We want to show our clients how to follow the best practices for data.

Desired Skills and Experience

To take up the challenge, you will have a depth of skills and experience including:

1-2+ yrs of focused data experience working with SQL and/or NoSQL solutions
A solid education in Software Engineering or equivalent industry experience.
Anything Data focused preferred.
Ability to analyse business scenarios and associated data landscape to derive potential opportunities.
Strong foundation in Python and SQL
Working knowledge of APIs
Principle knowledge of the different relational database platforms and modern data storage techniques
Knowledge of the different aspects of data environments
Collect, store, process, verify consume
Experience with version management systems (such as GIT)
Working knowledge of AWS or another cloud platform - we will teach you the cool stuff.
Great communication skills, an ability to work closely with customers, developers and engineers and the confidence to present ideas in open forums.
Relevant tertiary qualifications and/or industry certifications.
Great communication skills, an ability to work closely with clients, developers and engineers and the confidence to present ideas in open forums.

While not required, a background in consulting and professional services is highly desirable.

Itoc Description

This is an exciting and challenging career opportunity to join the growing Sydney-based Data Team of a leading cloud solution provider where you will be given support to reach your long term career goals. You will be part of a team of cloud experts and will work in an environment of continuous improvement and learning delivering innovative cloud solutions across SaaS, online business and enterprise business.

On offer is a chance to join a team with a great working environment, in an organisation that values its employees and sees the value in ensuring they are engaged. Our team are clearly passionate about what they do, that's why we won the following awards:

Customer Obsession Partner of the Year 2015: ANZ Region
Customer Obsession Leadership Partner 2015: re:Invent

As an employer of choice Itoc offers competitive remuneration, training and development programs and a great working environment. We value a healthy work life balance.

The Perks

MacBook or Dell
Continuous internal learning that will provide training and career development opportunities
Working with a collaborative, social team and leveling-up your skills faster than you will anywhere else.
Quarterly social events

Itoc

Culture and smarts are important to us. Bring your secret sauce. This is no ordinary environment, you will work along some of the Cloud’s best. All engineers at Itoc must gain at least five AWS certifications. We work hard but we have fun.

Please note you must have full working rights in Australia and be available on-shore for face to face interviews.

No recruiters please.",4.0,"Itoc
4.0",Sydney,-1,1 to 50 Employees,2013,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Date: 01-Oct-2020

Location:
Melbourne, VIC, AU

Department:Description:
Technology discounts - from Apple HP Lenovo to Windows
Flexible work arrangements - work in a way that suits you best
Salary packaging - to suit your personal and financial circumstances

Do you want to work for one of the fastest growing data teams in Australia? Do you want to work on multiple data platforms and provide new solution offerings by leveraging cloud and big data technologies?

About the team

Big data information and analytics. Three words that spark apprehension in most businesses. But our team of experts are constantly curious and excited about combining our wonderful array of technological expertise to transform data into our clients most valuable assets making their work smarter. Our data consultants are supported with resources training and tools they need to excel at their work but also the freedom and power to create their own paths forward to make a difference.

As a Senior Consultant in Big Data you will work closely with the team and stakeholders to build and deliver a Cloud based vision for a next generation Big Data analytics platform with strong focus on data quality data security and deliver the systems that process huge volumes of data.

What will you typical day look like?

You will play a pivotal role in - Designing and producing high performing and stable applications to perform complex processing of massive volumes of data in a new cloud based architecture; Building real-time data processing applications which are integrated with business systems to enable value from analytic models to drive rapid decision making; Contributing to system architecture design for a data platform (including cloud-based structures both on and off premises data warehouse components and data lakes); this could cover a range of technologies various countries/locations and lines of business; Support data strategy or technology strategy definition programs including technology stack definition and target operating model requirements

Enough about us lets talk about you:
You are someone with:
Use of traditional data analytics tools and techniques (e.g. MSSQL Oracle MySQL) and ETL software (e.g. SSIS Informatica CloverETL)
Working in large scale cloud data solutions using platforms such as AWS or Azure or GCP will be a bonus.
Experience in scripting or programming (e.g. Python Java Scala C#)
Excellent verbal and written communication skills to adapt to technical and non-technical audiences.
Educated to degree level (or have equivalent experience)
Why Deloitte?

At Deloitte we create positively differentiated work experiences that enable our people to feel valued and achieve their full potential. We value difference and embrace people with diverse backgrounds and thinking styles. Knowing that people work best in different ways we are happy to discuss alternative arrangements if the working pattern you are looking for is not specifically indicated.",3.8,"Deloitte
3.8",Melbourne,-1,10000+ Employees,1850,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Engineer,-1,"Opportunity to grow the team
Period of growth
Intuitive app
S2M are working with a FinTech who have created a unique financial product to help thousands of people better manage their finance, and is currently scaling the company to the next level!

They are looking for a Data Engineer to join, and looking for someone who wants to be hands on, with opportunity to grow the team in future.

Role:

Looking for people with strong AWS experience. You will need passion for data and a cloud, through which you will help a rapidly scaling Australian FinTech establish their data infrastructure from the ground up.
5+ years’ experience as a data engineer within the data and analytics domain
A python 3.X aficionado who is very comfortable creating and orchestrating AWS data pipelines with nothing but code
Strong project delivery toolset experience in open source data integration tools
Experience with processing large volumes of complex data including visualisation and insights generation
Ability to define and develop data integration patterns and pipelines
Ability to assess complexity of data (volume, structure, relationship etc.)
Hands on experience working with different databases (RDBMS, NoSQL, Blob storage etc)
Hands on technical expertise setting up DevOps automation
Hands on experience working technologies/platform e.g. AWS, Dockers, Containers
Experience building data profiling and data cleansing frameworks
Technical reconciliation and reporting
Knowledge and experience in end-to-end project delivery, either traditional SDLC or agile delivery methodologies (or hybrid approaches)
Exceptional communication, documentation and presentation skills
If this sounds like you, get in touch today - kate.gabb@s2m.com.au
3167410agsdf",3.1,"S2M
3.1",Sydney,-1,Unknown,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Analysts,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is seeking experienced and qualified Data Analysts to join our IT team based in our corporate office in Birtinya (Sunshine Coast) or at our meat processing facility in Kilcoy.
Key Responsibilities:
A mixture of data analysis and commercial skills to source, blend and analyse data to gain insight and answer key commercial questions
Working with strategic leaders to define and model Key Performance Indicators, and assist in building forecasting models
Working closely with data engineers and BI developers to specify data pipelines and report visualisation
Drive the creation and implementation of data quality business rule including data definition, governance and quality assurance
About You:
To succeed in this role, you’ll need to bring the following experience and skills:
Proven ability to derive insight and knowledge from data using commercial expertise is a strong requirement
Strong SQL and Excel skills are essential, along with strong data analysis and commercial insights
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Effective people communicator - engage with stakeholders on reporting needs, interpret requirements into visual solutions and train/deliver the outputs to the stakeholders getting signoff of acceptance
Bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking

How to Apply:
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kilcoy,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Network Data Engineer,-1,"Min 6+ years of experience in the relevant technologies
Australian Driving License for visiting remote locations / Data Centre for day to day technical work.
Managing Network devices (switches, routers, firewalls, load balancer, and wireless technology)
Performing MACD activities for all network devices.
Supporting BAU operation activities.
Proficient in performing in-depth details of technical troubleshooting, cause and provide recommendation to the client for incidents causing extended network outage to client’s critical locations.
Provide exceptional network services in terms of network support, break-fix, design and consulting, new projects, implementation.
Configure, administer, and document firewall infrastructure.
Manage the firewall deployment, rules migrations, and firewall administration.
Supporting Cloud Migration Activities from traditional to AWS/Azure.
Setting up VPN tunnel with Cloud and 3rd Party network devices.
Integrating and upgrading existing ISP bandwidth with support from ISP Vendor.
Setting up VPN profiles for Users.
Installing hot fix and patches to mitigate the security devices from attacks and bugs.
Reviewing and fine tuning the firewall rules and NAT rules.
Documentation and change control.
Mentoring, Motivating and Guiding support teams
Technical skills:
o LAN
o Wireless
o WAN
o MPLS
o Routing protocols (OSPF,BGP)
o DMVPN
o Azure cloud Networking
o Network Security
Fortigate Manager / Analyzer / Firewall
Cisco ASA
Firepower FTD
Cisco Any connect
Site to Site VPN
F5 Load Balancing and Scripting iRule
Job Types: Full-time, Contract
Schedule:
8 hour shift
Experience:
Scripting: 5 years (Required)
Data Network: 5 years (Required)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Required)",3.6,"Total IT Global
3.6",Sydney,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Engineer - Processing & Analysis,-1,"Job Description:
Design,build and maintain the ingestion system to support various types of data(e.g. User behavior, RDS, NoSQL db and others) to be ingested to the data warehouse more timely and accurately
Translate data requirements into scalable technical data service with low latency and high concurrency
Design,build and maintain the batch or real time data pipeline in production using Hadoop big data technology
Analyze and improve efficiency, scalability, and stability of the system
Define and manage SLA,Data quality for all data sets in allocated areas of ownership
Requirements:
Minimum B.S. degree in Computer Science or a related technical field
2+ years of working experience in programming languages,such as Java,Scala,Python
Familiar with Hadoop, Spark and Flink data processing, experience of TB data processing experience is a plus
Familiar designing and operating of a robust distributed system is a plus
Understand data mining or machine learning
Excited to work intimately with data
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"SYNOPSIS:
Lead Data Engineer
Applications close Sunday 8 November 2020
Ongoing
Contact name: Shyni Sasikala
Phone: (02) 6249 9048
Email: Shyni.Sasikala@ga.gov.au

The Data Policy and Informatics section within the Digital Science and Information branch creates, implements, and promotes policies, platforms and tools that improve and support the quality, discoverability, accessibility, and general usability of Geoscience Australia’s science data products. The section consults with internal and external research, government and industry partners to establish collaborative data frameworks, architectures and models within Geoscience Australia (GA) and across broader national and international communities of practice. The section innovates, builds and maintains tools, systems, processes and governance that enable digital data management, cataloguing and open data delivery.
GA makes accessible a wide range of geoscientific and spatial data to a wide variety of stakeholders in multiple formats, and in recent years GA's data volumes have grown exponentially. GA is focussed on making its data and metadata assets accessible so that they can be used in machine to machine interactions for data analytics and other applications in environments that range from High Performance Computing (HPC), through high-end cloud servers, to mobile devices.
We currently have two opportunities for Lead Data Engineers in the Informatics team. The Lead Data Engineer is responsible for innovating and exploring new technologies that will advance GA’s science goals and maximise the uptake and use of GA’s science data. The Lead Data Engineer reports to the team’s Assistant Director but also works closely with other developers, data scientists and engineers within the Digital Science and Innovation (DiSI) branch, as well as diverse stakeholders both within and external to GA.",3.9,"Geoscience Australia
3.9",Canberra,-1,501 to 1000 Employees,2001,Government,Federal Agencies,Government,$100 to $500 million (USD),-1
Data Engineer,-1,"The Seven Network is part of Seven West Media, one of Australia’s most prominent media companies, with a market leading presence in content across broadcast television, online and in print. Comprising some of Australia’s most renowned media brands, SWM includes not just Seven Network and its affiliate channels 7two, 7mate, 7flix and BVOD offering 7plus, but also 7NEWS.com.au, The West Australian, The Sunday Times and more.
At Seven we are here to bring all Australians closer to the moments that move us - we’re first on the scene, with our finger on the pulse, on demand, in the moment. Together, we’re responsible for creating and sustaining authentic Australian engagement.
A new and exciting opportunity has opened for a Data Engineer to join the Audience Intelligence team. Based in Sydney and reporting to the Head of Data Enablement, you’ll be responsible for:
Implementation of end to end data solutions to support Data Strategy for the SWM group.
Work closely with the Data Solution Designers to develop and maintain scalable data pipelines and build out new file and API based integrations to address requirements from the various business stakeholders.
Collaborates with engineering, analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organisation.
Work on Data Preparation for analytics and data scientist team members and assist them from an engineering perspective in building and optimising the models including building the automation of the end to end workflows
Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.
Perform data analysis required to troubleshoot data related issues and assist in the resolution of production data issues.
Work effectively with vendors for successful delivery of projects and acceptance of the solution
Work on Delivery projects using Agile Software Development methodologies
We are looking for someone who has:
Bachelor's degree in computer science, computer engineering or other technical discipline is essential
Proven experience working as a digital analytics specialist
Extensive experience with digital analytics implementation (e.g. Google Analytics, Snowplow, Adobe Analytics) and BI processes and visualisation platforms
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience in ETL and building and optimizing ‘big data’ pipelines and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Experience with big data tools: Hadoop, Spark, etc., AWS cloud services: EC2, S3, Lambda and familiar with version control systems: Git
Strong coding skills with knowledge of Unix/Linux and scripting languages such as Unix Shell scripting, Python desirable
Experience supporting and working with cross-functional teams in a fast-paced environment.
Ability to multi-task and problem solve with changing demands and priorities
Ability to work under pressure to meet deadlines and detail oriented
Your success is our success: we will provide you with opportunities for you to keep learning and growing, enabling you to challenge and develop yourself. In return, we offer a benefits program that has something in it for everyone.
Seven West Media is an equal opportunity employer and we are committed to creating a diverse and inclusive workplace.
Recruitment Agencies: Seven West Media does not accept any unsolicited agency resumes and will not be responsible for any fees related to unsolicited resumes.
Advertised: 19 Oct 2020 12:00 AM AUS Eastern Daylight Time
Applications close:

Back to search results",2.5,"Seven West Media
2.5",Sydney,-1,5001 to 10000 Employees,1956,Company - Public,TV Broadcast & Cable Networks,Media,Unknown / Non-Applicable,-1
BICON Rules Engineer,-1,"APS 5 - $73,299 - $80,410 per annum plus superannuation
Biosecurity Plant Division
Canberra, ACT
Play an active role in managing biosecurity risk to Australia
Work in a motivated and professional team with a wide range of skills and backgrounds
Full training provided

Who we are
The BICON Content Development Team maintains and improves the Biosecurity Import CONditions database (BICON) content to allow external clients to understand and comply with their biosecurity obligations and internal clients to effectively manage biosecurity risk and regulate imports. We work collaboratively with internal clients to comprehend and implement their BICON content requirements and optimise the use of BICON to publish clear import requirements and onshore management support procedures to effectively manage biosecurity risk.

The Jobs
Key duties of these positions include:

working with business content (import and permit conditions) and import programs to understand and construct decision tree structures in the BICON database, in accordance with system design and authoring conventions
executing changes to import and permit conditions in alignment with service standards while complying with system rules and authoring conventions
providing technical advice through various formats on the most appropriate means of authoring BICON content to achieve import program and stakeholder objectives
using workflow management tools to maintain detailed records of changes to import conditions and key decisions
performing administrative tasks including system reporting, data analysis and scoping tasks for the BICON content change work program
contributing to the development and maintenance of instructional material, authoring conventions and courseware
clearly documenting and reporting system issues
developing and maintaining effective working relationships with internal and external stakeholders.

What we are looking for
Knowledge and experience
Experience working with complex IT systems.
Experience working collaboratively and as part of a team.
Knowledge of the role of biosecurity is preferred but not essential.

For additional information, please read the Job Description below.
Candidate Information Package docx Opens in new window",3.9,"Department of Agriculture & Water Resources
3.9",Australia,-1,5001 to 10000 Employees,-1,Government,Federal Agencies,Government,$500 million to $1 billion (USD),-1
Cloud Data Engineer,-1,"Job no: 509605
Work type: Permanent Full Time
Location: Melbourne, Canberra, Sydney
Do you embrace digital disruption?
Do you love solving complex problems, designing sophisticated solutions and building innovative technology?
Do you believe in creating powerful actionable insights from Data and Analytics?
Do you want to work in a diverse and flexible working environment?
KPMG is one of the most trusted and respected global professional services firms. Through depth of expertise, clarity of insight and strength of purpose we help our clients solve complex challenges, steer change, strengthen, transition and grow. We are a team based practice and this extends to our clients whom we work and collaborate with, in solving complex problems. Together, we design, innovate and implement, providing enduring advice that support our clients and the services they deliver. Our clients vary in size and come from a diverse range of sectors – all sharing in a common goal: to embrace change and deliver services that make Australia a better place. We are looking for talented individuals who would like to join us on the journey.
KPMG’s Digital Delta Team
We re-imagine and re-invent organisations to become world class digital enterprises using advanced technologies, data and human insights. We help organisations to embrace Digital Strategy, Artificial Intelligence (AI) & Cognitive, the Internet of Things (IoT), Data, Analytics & Modelling, Mobile App & Web, and User Experience (UX) & User Interface (UI) and more.
We work with clients to:
Formulate strategies that re-imagine organisations
Harness innovation from the 4th industrial revolution
Actioning insights from trusted data to consistently and quickly make clear decisions
Build adaptive organisations
Thrive as a connected enterprise – front, middle and back office
This is how you’ll contribute:
We are looking for ambitious Data Engineers who are passionate about helping clients define bold ambitions and deliver on them. Joining our team will take you on a journey of personal and technical growth and provide the opportunity to inspire confidence and empower change.
As a Data Engineer you are the designer, builder and manager of the information or ""big data"" infrastructure, preparing data for analytical or operational use. You will design, construct, test and maintain a data pipeline to pull together information from different source systems; integrating, consolidating and cleansing data; and structure it for use in individual analytics applications.
The KPMG Difference
Our people are focused on creating a diverse and dynamic environment that embraces and values differences. We value the variety of unique experiences, qualities and characteristics our people possess and we share and learn from each other.
We are proud to be consistently recognised as an employer of choice for women, and for our achievements in LGBT+ workplace inclusion.
Our commitment to ‘Flexibility’ allows our people to manage the changing demands of work, personal or family life. Explore the links below to hear our people share their experience @ KPMG:
Flexibility empowers wellbeing
Flexibility enables contribution to the community
Flexibility inspires technology & innovation
Flexibility supports family

Make KPMG the clear choice for your career and be Extraordinary!

Advertised: 09 Sep 2020 AUS Eastern Standard Time
Applications close:",3.8,"KPMG
3.8",Sydney,-1,10000+ Employees,1987,Subsidiary or Business Segment,Accounting,Accounting & Legal,$2 to $5 billion (USD),-1
Computer Network and Systems Engineer,-1,"Duties Include but are not limited to:
Tasks Include:
analysing, developing, interpreting and evaluating complex system design and architecture specifications, data models and diagrams in the development, configuration and integration of computer systems
researching, analysing, evaluating and monitoring network infrastructure to ensure networks are configured to operate at optimal performance
assessing and recommending improvements to network operations and integrated hardware, software, communications and operating systems
providing specialist skills in supporting and troubleshooting network problems and emergencies
installing, configuring, testing, maintaining and administering new and upgraded networks, software database applications, servers and workstations
providing network programming in support of specific business needs and requirements
preparing and maintaining procedures and documentation for network inventory, and recording diagnosis and resolution of network faults, enhancements and modifications to networks, and maintenance instructions
monitoring network traffic, and activity, capacity and usage to ensure continued integrity and optimal network performance
Skills and Experience Required:
Must have experience working in a Managed Service environment
Demonstrated experience in IT Networks and Data Centres
Understanding of systems and architectures to meet client needs
Experience in Help Desk including break / fix
Effective and timely documentation
Effective Task Management Skills
Be solution and outcome focused and willing to learn new technologies
Excellent communication skills with staff, clients and partners
Time management, ability to prioritise and deliver to schedule
Experience with N-Able and Connectwise desired
Open Cabling license desired
Job Types: Full-time, Permanent
Salary: $30.00 per hour
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,Trans-plant training,Canberra,-1,-1,-1,-1,-1,-1,-1,-1
Software Engineer (Data),-1,"If you are looking for an opportunity to make a real impact with smart people who are genuinely doing things differently then you've come to the right place! We're growing our data engineering capabilities and are looking for awesome data engineers to join our team.
With our diverse range of clients and projects, no day will look the same - but here's a great snapshot of what you'll be doing:
Work with some of the best Data Scientists and Engineers to deliver production-grade AI and Machine Learning systems as we deliver client projects from inception to production.
Consulting with our clients and working with them to build modern data systems using the 'best of' technologies and principles.
Advising clients on data strategy, architecture and technology.
Applying best software engineering practices in coding, monitoring and alerting, using CI/CD, TDD and cloud architectures.
Working over a wide range of big data tools and environments: not limited to; Apache Kafka, Spark, Python, Scala, Hive, Airflow, AWS EMR & Glue, GCP Dataproc & Dataflow, BigQuery, Snowflake, Redshift.
Who are we?
Glad you asked! We are Eliiza. Data science. Engineered for scale.
We are a passionate team of data scientists and engineers who apply data science and machine learning to solve real-world problems. Our mission is to create a bright future for Australian businesses and society in a world increasingly influenced by intelligent technologies.
We've created a culture that values diversity where people can truly be themselves! We care a lot about growing the Australian AI community in a positive direction, and we're doing several things to try and achieve that:
We provide opportunities for underrepresented groups to work in AI through our associate and intern programmes
We organise and participate in a range of community events, reading groups and meetups
We produce the AI Australia podcast
We blog about topics we care about
We stream brown bag sessions to the broader community
We're also part of Mantel Group's 'house of brands' which means it's not just the Eliiza team you'll work with, learn from and see at social events - there's another 230 of us across DigIO, Kasna & CMD Solutions!
So you're ready for something new?
We're keen to know more about you! Our team is made up of a range of people, with different experience across a huge range of data driven skill sets.
We'd love to hear from you if you have experience with:
one (or more) core language(s), ideally Scala, Python or Java
one (or more) cloud platforms, AWS, GCP, Azure
ETL/ELT concepts and technologies e.g. Data partitioning, Hive, Spark
streaming data concepts and technologies, ideally Kafka (Kinesis, Beam or Pubsub will do)
We'd be over the moon if you:
Experience with distributed/columnar databases (e.g. Snowflake, Big query, Redshift).
Experience with any of a variety of databases e.g. RDMS, NoSql, Columar, Distributed, Time series, Graph.
Knowledge of job orchestration and scheduling. Any experience with Airflow, Luigi or Oozie.
Experience with containers and container orchestration (Docker, Docker Compose or Kubernetes).
However, we value a diversity of skill-sets, and don't necessarily require that you're skilled with all of the above. If you feel you don't fit all the experience/skills listed above we still encourage you to apply or get in touch.
What's on offer if you join us?
We make sure you're always one step ahead by investing your learning and development, every year. We build our own training where it doesn't exist yet.
We hire smart people and get out of their way. By focusing on our five principles and not getting caught up in red tape, we trust you to get the job done.
You'll get all the tools you need - a new iPhone or Google phone, a new Macbook Pro or Dell, and a lot of branded swag!
But hold on, you mentioned a house of brands?
We certainly did! Mantel Group is an Australian-owned, 'house of brands' company with four technology businesses (Eliiza being one of them!) across Melbourne and Sydney. We're building a group of companies with open borders so we can support you to take on new skills without leaving an awesome team - we understand you won't have one job for life!
We may only be just two years old but Mantel Group has already been recognised #9 in the 2020 Best Places to Work in Australia and #4 in the AFR's 2020 fastest growing new companies.
Keen to chat?
Click ""Apply"" to share your details with our talent team, and we'll be in touch.
In the meantime, check out 'how we hire' to find out what's in store if you're successful and get to know us better by visiting our website and following Eliiza on LinkedIn.",-1,Eliiza,Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Infrastructure Engineer,-1,"Job Description:
Design and grow the Shopee data platform to support a variety of big data applications using open-source technologies including Kafka, Hadoop, Presto, HBase, Spark, Hive, Druid, and our own creations. Some examples include a real-time data streaming platform, a unified query platform, a cluster management system, and a machine learning platform
Dig into the source code of some open-source big data system to get the whole control and familiar with the details, configurations, designs and source code. Develop and maintain the internal release of big data systems and components as the business requirements.
Keep close and overall monitoring for all the deployments of the systems, maintain the system’s stability, improve the performance, discover the performance bottlenecks, tracking and troubleshooting, cost optimisation.
Requirements:
B. Sci. / Ms / PhD in Computer Science or a related technical field
Familiar with at least one of these languages: Java, Scala, Python, Bash under Linux / Unix. Scala is a plus
Familiar with the use and compute logical of SQL
Knowledge about the Big Data Infrastructure system technology like Distributed File System, Distributed Computing, Distributed Database will be a plus
Hands-on experiences Hadoop, Spark, Kafka, and/or Presto will be a plus
Love to use and develop open-source technologies
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"Work on an award-winning, international technology!
Endless career opportunities
An innovative, friendly team of 300+
This role will be focused on the development of our existing ClaimLogik line of products as well as working on our new cloud-first, modern suite of applications.

Intelligent Thought, our technology business is scaling and shipping our software globally. Already profitable, part of a much larger group business, with investors such as Macquarie Capital and Envest – we are all set to deliver textbook disruption to the Insurance Industry. The growth of the platform, of our customer base, and the increasing industry demand have led to the need for this role to help the team scale.

Our Philosophy
Give each employee a sense of purpose and an environment for them to connect the importance of their role to delivering a service that matters to our customers.
Challenge the ‘why’ of traditional claims processes.
Keep it simple – do only what brings value and what matters to the customer
Enable employee decisions, empower our people
Responsibilities:
Create, extend and maintain ETL pipelines to form our data lake, data warehouse and analytics platform (currently using the Microsoft Azure set of tools and service)
Help define the optimal data pipeline architecture
Influence the tool selection, platform selection, data architecture and strategy which will transform the business to be truly data-driven
Understand, analyse and size user requirements
Work with different parts of the business to provide them with the insights they need to deliver the best results
Skills & experience:
Degree or qualification in computer science or related
Advanced knowledge of relational database, including query authoring and query optimisation (MS SQL Server and PostgreSQL).
Experience building and optimising ETL pipelines
Experience designing complex data models
Experience working with cloud platforms (Azure or AWS)
Efficient time management and organisational skills
High attention to detail and accuracy
Effective communication skills to build strong working relationships; both written and verbal
Proactive and results-driven
Why Claim Central?
Claim Central Consolidated is a global insurance industry leader across, claims management, insurance technology and data and analytics. Currently operating in the United States, Australia, South Africa, Italy and New Zealand, we have pioneered digitally connected claims management services across the globe. Claim Central is a disruptor and thought leader in the industry and we were recognised as the Australian Financial Review’s 8th Most Innovative Company in Australia in 2016. This business is in a period of unprecedented growth, transitioning our technology and services into multiple geographies at a rapid pace. Our unique culture is based on teamwork, collaboration, trust, respect and performance. We also offer many benefits apart from our exceptional team culture; including flexible work arrangements, and continued professional development.

Be a part of this journey in a career-defining role.",-1,Claim Central,Matraville,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer - AI/ML,-1,"Our client provides services to a major industry across the country. The business is still early in it's days of technology development and the environment is greenfields in nature (no pun intended), effectively working like a start-up.

Their data and analytics team have worked and built leading and bleeding-edge technologies in this space and what they have created so far may be game-changing. From a machine learning perspective, the progress they have made to the business has already seen proven success in changing the future of an industry that will have positive consequences for all those involved.

You will have previously worked in a technical capacity in the data and analytics space and have experience working with an organisation where machine learning has been implemented, not just a concept that the business talks about having or the technology team would love to have. The commercial experience you will have had in the ML field will be proven examples of where you have affected the way a business or industry used to perform, to the changes that have come about from this.

Technically, you will have extensive experience in the Microsoft space - Power BI, Azure etc and you will have previously mentored and coached junior members of the teams you have been part of.

This is a rare opportunity in Brisbane where the business has truly embraced and funded projects across the ML space and would be a great chance for those in the Data Development/Data Engineering field, who are looking to move into a Data Scientist role in the future.

Please send your application through if you would like to know more.",4.0,"Emanate Technology
4.0",Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Solution designer/ ETL Engineer & Data Modeller,-1,"We are looking for a Qualified and Experienced Solution Designer to join our client for a period of 6 months with a view to extend.
You will work closely with team members and your contribution will range across gathering and analyzing information, developing and documenting improved processes and work instructions and experienced DWH Lead with skills in requirement analysis, solution designing, developing, testing and supporting ETL solutions.
A hands-on solution designer, data modeler and ETL developer for Data Warehousing and ETL application transformation projects using Informatica PowerCenter.
Knowledge on AWS, S3, Redshift, Informatica BDM, and related technologies.
Experience working with IPython, PySparks, AuCuMo, Airflow, Jenkins, Github, Athena, JIRA, Rally, Spectrum, Glue, Flyway.
Good exposure on Oracle PL/SQL, aware of DBA activities, writing and performance tuning of complex SQL queries.
Contract length: 6 months
Job Types: Full-time, Contract
Salary: $650.00 – $800.00 per day
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,nducive,Melbourne,-1,-1,-1,-1,-1,-1,-1,-1
"Data Engineer, Wollongong NSW or Mount Waverley VIC",-1,"Company Description
BlueScope is a technically advanced supplier of steel and steel products in Australia. We are an inclusive organisation and every day we showcase our technology and expertise throughout the world.

Job Description
We are looking for two Data Engineers to join our IT team, based in Wollongong NSW or Mount Waverley VIC. Use your experience in analytics to unlock business value, enabling use of big data for insights and decision-making.
Reporting to the Data Product Owner for our Australian Steel Products (ASP) business, this position will support strategic goals related to data. This will see you:
Gather business and technical requirements with the view to deliver outcomes;
Develop and implement end-to-end data collection, consolidation, modelling and visualisation solutions;
Document metadata in a dictionary and catalogue;
Ensure consumers of such information understand its accuracy, timeliness, quality and sensitivity, so that it is used appropriately; and
Identify opportunities to enhance analytics.
What are the benefits?
Work in a supportive and collaborative team environment whilst we embark on a journey to transform the way our business uses data!
Our systems landscape is broad and diverse. You will be encouraged to think creatively to develop data solutions which solve real business problems.
Working in this role you will enjoy:
the chance to learn more about data science;
salaried remuneration with attractive superannuation options;
the opportunity to participate in a performance incentive scheme; and
access to further development and career opportunities with BlueScope.
Who are we looking for?
We welcome applications from professionals with experience in data analytics and/or programming. Supported by your knowledge of project delivery methods (e.g. Agile), you will demonstrate:
experience with data mining, wrangling, mapping and visualisation techniques (e.g. Azure Data Factory, Databricks and/or DevOps etc.);
well-developed ability in gathering business and technical requirements;
skills in developing and implementing collection, consolidation, modelling and visualisation solutions; and
a passion for sharing your knowledge and desire for ongoing professional development.

Qualifications

null

Additional Information
We're proud to have been named an Inclusive Employer for 2019–2020 by the Diversity Council of Australia. We believe that our people are our strength. Having a diverse and inclusive workplace enables us to improve our capability and ensure continued, sustainable success.
We know that workplace flexibility can mean something different to everyone. Under our B-Flex initiative all of our roles have some degree of flexibility. We encourage you to discuss your needs with us.
Applications close Sunday 25th October 2020.",3.3,"BlueScope
3.3",Wollongong,-1,201 to 500 Employees,-1,Company - Private,Construction,"Construction, Repair & Maintenance",$100 to $500 million (USD),-1
ETL Data Engineer,-1,"ETL Data Engineer

Join a team that’s changing how Australia lives, works, plays and grows
We want you to be the best version of you

Work with innovative teams and explore new technologies to help solve real-world problems.

A typical day as a Data Engineer

ETL / Big Data Engineering professionals will be responsible for guiding the full lifecycle of a Data solution, including:
Working in highly client-facing roles to contribute throughout the end-to-end delivery lifecycle of complex and large-scale digital solutions
Use case and business case development
Support existing and new applications utilizing in-depth technical and data knowledge. Troubleshooting complex issues and providing advisory services to improve the client’s data landscape
Help to streamline and simplify the clients’ complex data landscape by integrating different applications and data architectures
Implementation from requirements analysis, platform selection, digital architecture design, application design and development, testing, and deployment
Interstate travel may be required

Basic qualifications:
Bachelor’s degree
Experience across systems integration, information management, data management and architecture, and business analytics
Experience with being in a team focusing on large-scale, multi-release information centric projects
Experience with waterfall and agile delivery and run / application support functions
Part of a team working on End to end implementation of at least 1 big data project

Preferred Skills:
Hand on experience in Data warehousing using ETL tools such as DataStage, Autosys and TeraData
Hands on experience in ETL job development with multiple stages like sequential file, Transformer, Lookup, join, sort and Database stages.
Strong hand on skills in design, development and implementation of various data remediation, Data migration, data integration techniques.
Strong hand on data modelling experience.
Strong hands on experience in database performance tuning including complex query optimizations and physical database tuning using Teradata.
Understanding of architectural designs and strategy related to data migration, data cleansing, data quality and data consolidation.
Proven data analysis, requirement gathering and problem-solving skills
Exposure to Unix environment and shell scripting.
Experience in Banking and Financial services industry
Desirable: Knowledge of cloud computing infrastructure (e.g. Amazon Web Services EC2, Google Cloud, Microsoft Azure)
About Accenture

Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. We combine unmatched experience and specialized capabilities across more than 40 industries — powered by the world’s largest network of Advanced Technology and Intelligent Operations centers. With 513,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises. Visit us at www.accenture.com.

Accenture is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, marital, domestic or civil partnership status, sexual orientation, gender identity, or any other basis as protected by applicable law.

Vera Goga is the Recruiter managing this role. As the team experience high volumes of applications, we appreciate your patience to allow for a fair and timely process.",3.9,"Accenture
3.9",Sydney,-1,10000+ Employees,1989,Company - Public,Consulting,Business Services,$10+ billion (USD),-1
Student Engineer,-1,"The candidate will have the ability to:
Undertake onsite inspection to collect asset condition data based on the relevant engineering standards and technical guidelines;
Undertake desktop analysis to evaluate the condition and performance of the assets;
Provide the appropriate information, advice, engineering input and support services for the sustainable management of Council’s stormwater and transport networks.
Qualifications:
The successful candidate will be enrolled in a Bachelor of Engineering with a minimum of two years completed.
Position Number: 100678
Position Hours: Fixed term (3 months), hours will be negotiated with the successful candidate, maximum of 75 hours per fortnight.
Salary: Schedule A, Salary Point 4.0. $28.64 per hour ($55,853.45 per annum, pro-rata) in accordance with Glenorchy City Council’s Enterprise Agreement 2016
Please note that all successful applicants will be required to provide a current National Police Check prior to commencement of employment.
For further information on this position, contact Patrick Marshall, Senior Civil Engineer on (03) 6216 6800.
How to apply: Applications for this position must be lodged on this submission site or on the Glenorchy City Council website www.gcc.tas.gov.au - Careers page.
To be considered for this role, all applicants must address the key selection criteria in the and provide a current resume. A copy of the position description can be found by clicking the below hyperlink or on the Glenorchy City Council website.
Applications close at 8pm on Sunday, 1st November 2020
- Student Engineer",4.0,"Glenorchy City Council
4.0",Glenorchy,-1,501 to 1000 Employees,-1,Government,-1,-1,Less than $1 million (USD),-1
Data Engineer involving DevOps,-1,"Data Engineer involving DevOps
Axiom Technologies is an Australia based entity with the history of providing Managed IT solutions to medium to large scale enterprises globally. Please visit our website for more information about what we do at www.axiomtechnologies.com
Axiom Technologies is an Equal Opportunity Employer and encourage applicants from all backgrounds and gender to apply, including, Aboriginal and Torres Strait Islander candidates
Job Requirements:
8+ years IT experience, with at least 5+ years of “Data Engineer/Deveoper” focused titles/roles,
Data Tools: Hands on experience with Apache Beam.
Testing: Hands on experience with automated testing activities/outcomes
DevOps: Experience with the processes involving Microservices facilities for artifacts developed
Platform/OS: Mid-range/Unix
Languages: Unix (Shell) Scripting/commands, SQL, Python
File formats: Text, CSV, Parquet, JSON, XML
Scheduling: Jenkins, Airflow
Auto Scripting: Designing/creation of scripts for repetitive activity. E.g. Unix scripting/SQL
Big data: Exposure to Data Lake Concepts, Hive (Schema), HDFS
Source Control tools: GIT
Delivery Models: Agile, Scrum
Ingestion Design: Create/assess Source/Target data mapping designs
Frameworks: Development and delivery frameworks
Activity Reporting/Repository: Jira, Confluence.
Quality: Accuracy and attention to detail
Industry: Financial Services/Banking
Solutions: Define solutions from High level to detail design to address automating ingestion activity. Facilitate/confirm requirements from product owners, business team members and technical associates,
Process Automation: Automating processes in file management, testing data in files, analysis and design, configuration management.
Script Automation: Ability to design/create scripts to automate/improve data copy/migration/ETL for any repetitive activity.
Languages: Java, Python
Scheduling: Control-M
Databases: Relational. E.g. POSTGRESS, Oracle – as a ETL developer
File Formats: Mainframe – experience with referencing its data formats/copybooks
Big data: Experience referencing/using Hive (Schema) to access data in HDFS
Metadata management tools: MDM, EDC and Axon
Performance: Assess, recommend, improve mappings, SQL queries, Batch feeds
Automation Tools: Other tools that may add value to an automation program and generally support development. E.g. API, REST, JDBC, Webservices, Message Queues/Load balancer,
Cloud: Experience with processing of data files to be ingested/stored in the Cloud, preferably with AWS.
Prod Support: Experience in a production support role performing root cause / impact analysis – under time constraints
Experience in a similar role
8+ Years
What next?
If you are looking for that next challenge in your career and wish to apply for this role, please forward your resume to careers.au@axiomtechnologies.com",2.0,"Axiom Technologies
2.0",Melbourne,-1,1 to 50 Employees,-1,Company - Private,Industrial Manufacturing,Manufacturing,Less than $1 million (USD),-1
Data Engineer,-1,"About the Role
We are on an exciting digital journey so it’s a great time to join ME! We are seeking a Junior Data Engineer who enjoys rolling up their sleeves, learning and growing. As part of our Enterprise Data Team, you will ensure fit for purpose data warehouse solutions are built for use across the bank and by utilising best practise ETL standards, whilst ensuring the data is trusted by our BI developers and key business consumers. Oh, and you’ll get to work on Microsoft technology stack too!
You will be involved with investigating data issues, keeping data feeds flowing and collaborating with different projects across the bank to deliver quality data solutions. How important does that sound? What’s even more important is this role contributes directly to our overall business strategy through the provision of data to enable analytics & reporting, as well as supporting business and decision system processes.

About You
You’re naturally a highly motivated and energetic person who thrives in a dynamic, ever-changing collaborative team environment. Ideally you have previous experience as an ETL developer, Data Engineer or a BI developer, and if you have a degree in computer science or similar it would really put you ahead of the rest.

With your knowledge of SQL coding, data modelling, understanding of data warehouse concepts, plus experience of working on complex ETL solutions, you’re ready to expand your horizons and launch your career into the world of IT at ME.

About ME
We’re not like other banks.
ME was created by the industry super funds to be different from the pack – with a core purpose to help all Australians get ahead financially – no conditions, asterisks or exceptions. And we know that looking after customers starts with taking care of our people.
We believe everyone deserves the same opportunities in life, regardless of gender or identity, sexuality, ethnicity, religion or disability ‒ with internal affinity groups.
Perk ME up
Once you get your feet in the door at ME, we’ll put them both in your very own ME-branded Converse shoes. You’ll also get the following financial, health and fun perks when you join the team:
4U Extras portal (discounts and cashback on 100s of items including cinemas, shopping and gym memberships
10% Myki discount
Purchased Leave programme
Internal wellness programme (Mindfully ME)
Professional education through LinkedIn Learning
Novated Leasing
Professional membership reimbursements
Health checks
Financial education (To help you manage your money smarter)
LGBTIQ+ and Women at ME affinity groups

I want those Converse shoes (and the role)
Can’t see a closing date on the advert? That’s because we’re pretty efficient here at ME and we may start looking at applications sooner rather than later, so if this role sounds like your jam, be sure to apply by submitting your resume today.

Should an applicant be the preferred candidate, background checks (including police checks, reference checks, ASIC banned and disqualified persons and bankruptcy checks) will be completed prior to the candidate's employment being confirmed. The outcomes of the background checks do not automatically bar candidates; however will be assessed against the inherent requirements of the job.
Back Share
Apply Now",3.0,"ME Bank
3.0",Melbourne,-1,501 to 1000 Employees,-1,Company - Private,Banks & Credit Unions,Finance,$100 to $500 million (USD),-1
Software Engineer - Machine Learning/Data Science,-1,"Zendesk is looking for a Software Engineer - Machine Learning/Data Science for a full time position in our Melbourne office.
As part of our engineering team, you will work at a scale where the challenges start to get seriously interesting. Our global engineering team is widely dispersed over the world, with people across nearly every continent. You will get a chance to do cool things with a diverse bunch of people while working in the Melbourne office that is home to Zendesk’s first machine learning (ML) research team.
The Data Science Team, together with Data Engineering, have built Satisfaction Prediction, Answer Bot and Content Cues — products that use Machine Learning (ML) and Artificial Intelligence (AI) to help our customers work more efficiently.
What you get to do every day:
We’re currently looking for someone to join our team as we research, develop, and productionise Machine Learning and Deep Learning models. In addition to frequenting Melbourne’s finest purveyors of coffee, ramen, and bulgogi, you may find yourself:
Building machine learning models including neural networks in TensorFlow
Writing and deploying production-grade Python
Querying and constructing datasets in AWS Athena, Spark
Evaluating and responding to real-world model performance
Scaling your ML to millions of predictions per day
Presenting your work to a broader audience
Watching your algorithm help Zendesk’s end-users
What you'll bring to the role:
A strong foundation in a quantitative discipline (e.g. machine learning, statistics, bio/eco/etc-informatics, econometrics, etc) is critical for this position. While experience in deep learning and natural language processing would be beneficial, your best qualities are:
dedication to continuous learning
collaborative work attitude
strong communication skills
You should also be comfortable with at least one programming language, such as Python, R or Scala.
Application Deadline: 18/11/2020
Job Types: Full-time, Permanent
Salary: $85,000.00 – $110,000.00 per year
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Temporarily due to COVID-19",4.5,"Zendesk
4.5",Melbourne,-1,1001 to 5000 Employees,2007,Company - Public,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),-1
Software Engineer (Machine Learning),-1,"About the Role
AdelaideMRI is building a medical reporting tool. We require an engineer to work primarily on machine learning projects to improve reporting speed and report comprehensiveness.
You will perform data analysis of medical report datasets and image datasets to infer sentence recommendations, image classifications, or other actionable results for the doctors.
Skills and Experience
Background in machine learning or image processing
Qualifications in Computer Science, Software Development or Engineering or equivalent experience
Bonus points for Python
No prior medical knowledge is required.
This position offers flexible hours and work arrangements.
Job Type: Full-time
Experience:
Software Engineering: 1 year (Preferred)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Yes",-1,Adelaide MRI,Australia,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Hey there, we’re PEXA!

We started as an idea: to deliver a single, national e-Conveyancing solution. We collaborated with the industry to create a national electronic lodgement and settlement platform: PEXA. From our humble beginnings, we’ve now grown to more than 320 employees across 5 different states. We’re still expanding at a rapid rate and constantly challenging ourselves to create great experiences for our members as they transition to fully digital conveyancing.

Why become a PEXArian?

Great question! Being a PEXArian is so much more than just a job. We are passionate, motivated & unashamedly enthusiastic at PEXA - we love what we do and we’re proud to admit it! Creating brilliant member experiences wouldn’t be possible if we didn’t also strive to create an amazing employee experience. Alongside our members, our employees are at the heart of everything we do.
Here’s a snapshot of what your life at PEXA could look like:

Your growth:
We encourage you to hit your personal and professional Learning & Development goals with our tailored programs and tools.

Your wellness:
We care about your holistic well being - a fully stocked kitchen, four wellness days, a $250 wellness subsidy as well as lunch and learn sessions to support your financial well being.

Your work/life blend:
We know that work is just one aspect of your life, we want to help you create your ideal work/life blend, rather than squeezing in life around work.

Your family:
With a range of benefits aimed at supporting your family including access to a subsidised school holiday program, extended parental leave and flexi-time to support your return to work, superannuation payments for unpaid parental leave for primary carers and a childcare allowance for pre-primary aged children, when we say, ‘welcome to the family’, we really mean it!
The impact you'd drive:
The successful candidate will be responsible for developing, and maintaining infrastructure to support the delivery of new and existing products. They will also be contributing to establish the rules and frameworks for obtaining the required approvals for new products.
On day one we’d love you to have:
Experience with Python, Spark
Event streaming/sourcing with Kafka or AWS Kinesis
Experience with data structures, formats and data security best practices
AWS experience (e.g CloudFormation, S3, ECS, Lambda, SQS, IAM, KMS, DynamoDB, Glue, Athena)
Query construction and optimisation (e.g. SQL, Elasticsearch, Splunk, DynamoDB)
Git, version control practices, and continuous integration/delivery servers
PyUnit and unit testing frameworks
Production release cycles and maintenance
Collaborating with technical and non-technical teams
Even better:
Agile methodology/delivery
GraphQL
Modern frontend technology (e.g. ReactJS, TypeScript)
Machine learning frameworks and tools (e.g. TensorFlow, PyTorch)
OAuth 2, SAML 2, JWT
Data visualisation and exploration tools (e.g. Jupyter notebooks, Tableau)
AWS SageMaker
Sounds like you?
If this role sounds like you, apply today to have your application reviewed ASAP!",3.9,"Property Exchange Australia Limited
3.9",Melbourne,-1,201 to 500 Employees,2010,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Ongoing position
Full time
Based in Sydney, NSW
Who we are
Australian Red Cross is part of the world’s largest humanitarian organisation. Our aim is to improve the lives of the most vulnerable people in Australia and across our region.
About the role
The Data Engineer role will sit within the Data and Integration Squad in IT and will own (design, implement and support) the AWS Big Data technologies such as the Data Lake and Data Warehouse and support the organisation in growing the data analytics capabilities at Red Cross. In addition to this, the data engineer role will also administer the Power BI tool and support the implementation of the data mastering capability.
What you will bring
Experience building and optimizing data pipelines, architectures and data sets.
Experience in dimensional modelling and building data vaults
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with structured, semi-structured and unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Why work for us?
Work for purpose and know that your work assists Red Cross support and empower people and communities in times of vulnerability.
Generous salary packaging options available that can increase your take home pay.
Further information
To find out more about this opportunity please see the position description below or contact Sharath Kumar Gurram on 02 8651 8839.
Position Description: Position Description - Data Engineer .pdf
Applications for this position will close at 11:55pm Thursday, 5 November 2020.",4.1,"Australian Red Cross
4.1",New South Wales,-1,1001 to 5000 Employees,-1,Nonprofit Organization,Industrial Manufacturing,Manufacturing,$500 million to $1 billion (USD),-1
Junior Fullstack Data Engineer (Python and React),-1,"Formbay is the leading Renewable Energy Certificate Trading company in Sydney. We provide Digital Workflow and Compliance solutions in the renewable energy industry and document processing.
Thanks to our meteoric growth and our commitment to be the best at all we do, we've identified the need to bring on board a new Junior Fullstack Data Engineer.
Reporting to our Principal Machine Learning Engineer, you will help build Machine Learning pipelines for our existing Digital Workflow and Compliance solutions to automate fraud detection and document processing over terabytes of photographic and documentary data – including documents, photos, GPS data and aerial/satellite photography.
Our stack is based on Python, JavaScript, Dask, Tensorflow, CUDA, Nix/NixOS, AWS, Docker, PostgreSQL and more – familiarity with these applications will give you a leg-up on the competition.
Our ideal candidate will have the following competencies:
SQL
Python
JavaScript/TypeScript
Our candidate must also be comfortable working with Linux.
Located a stone's throw away from the Queen Victoria Building in Sydney's bustling CBD, we are centrally-located with easy access to public transportation, bars, cafes and fine dining.
Formbay will provide flexible working hours, a generous remuneration package and the opportunity to work on a world-first software solution are what we can offer you. Free, twice-weekly gym sessions and really, really good coffee are also available.
No hiring/recruitment agencies need apply.",5.0,"Formbay
5.0",Sydney,-1,1 to 50 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is an experienced and qualified Data Engineer to join our IT team based in Birtinya.
Key Responsibilities:
Create and maintain data pipelines and or ETL scripts
Create and maintain data integration including API and Batch interfaces
Performed detailed data analysis
Create and maintain corporate data models
Create and maintain data visualization using Qlik.Sense , PowerBI or Simliar Toolset
Experience in defining, building and maintaining data virtualization and/or star schema data warehouses
Maintain, tune and optimise database, integration and visualisation toolsets
ABOUT YOU:
To succeed in this role, you’ll need to bring the following experience and skills:
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Excellent communication skills both oral and written, with an ability to bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking
Experience with data analysis and modelling will be beneficial

How to Apply
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kawana Waters,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Graduate Data Science / Engineer,-1,"The NRMA is an organisation looking to the future, and right now, we are on the lookout for people who can help us reach our goal: to continue to shape the way Australians move, for the next 100 years and beyond. www.mynrma.com.au.
Everyone new to the team, along with our current staff, will temporarily work from home until it is safe to return to our offices. All interviewing and on boarding will be done virtually due to COVID-19.


Your opportunity
As Graduate Data Scientist or Engineer you will be part of the Data Engineering team delivering cloud data transition program for business initiatives and supporting the entire data platform build.
Your key responsibilities will be to:
Implementing Concepts of Data Warehousing, Data Mart creations within Cloud
Use of SQL for data analysis and insights
Building AI/Machine Learning prototype for implementing and supporting existing algorithms
Data Analytical reports build, using different tool sets


Requirements for Success:
Relevant Degree - Computer Science, Computer Engineering, Software Engineering, Data Science
Excellent SQL skills and demonstrated working knowledge in Python
Demonstrated understanding in data structure and algorithms.
Knowledge and concept of data warehousing methodologies
Any reporting tools experience Tableau or Oracle Analytics Cloud, Looker is desirable
Exposure to Google/AWS/Azure/Oracle any cloud based platforms is desirable
Good communication and interpersonal skills

If you have the required skills and the passion to join our high performing team, please apply today.

Employee Benefits
To ensure our employees feel valued, empowered and celebrated we provide a range of employee benefits including:
50% discount on all NRMA insurances
Free Roadside Assistance
12 weeks paid primary and 4 weeks paid secondary parental leave
Free NRMA Blue Membership
At the NRMA Group, we are People Moving People and diversity and inclusion are part of our DNA. Together, we continue to build an inclusive culture that encourages, supports and celebrates the diverse voices of our employees. It fuels our innovation, promotes flexible ways of working and connects us closer to our members and the communities we serve.",2.5,"NRMA Motoring & Services
2.5",Sydney,-1,501 to 1000 Employees,-1,Nonprofit Organization,Casual Restaurants,"Restaurants, Bars & Food Services",$500 million to $1 billion (USD),-1
Data Centre Engineer,-1,"We are a leading world group that provides low-carbon energy and services. To tackle the climate emergency facing us all, our aim is to become the world leader in the zero-carbon energy transition ""as a service"" for our clients – particular for companies and regional authorities. We use our expertise in our key business areas (renewables, gas, services) to provide competitive and bespoke solutions.
The Data Centre Engineer will be employed as part of a 24/7 ongoing shift to coordinate and monitor third party service providers, maintain the data centre facilities and infrastructure plans, coordinate the implementation of customer requests within the data centre and monitor systems, all in accordance with the Contract KPIs and SLAs.
Coordinate and monitor third party service providers for regular maintenance & testing, service faults & call outs, ensuring works are performed in accordance with Contract SLAs
Monitor and maintain the data centre facilities and infrastructure plans and documentation, including electrical, mechanical, hydraulics, fire and BMS/EMS systems
Coordinate the implementation of internal and external customer requests within the data centre
Perform scheduled plant checks and minor maintenance works
Ensure all Work Order requests are raised and closed in a timely manner
Conduct inductions for staff, vendors and contractors
Ensure all work permits for vendor works are raised and closed
Perform inventory checks on all equipment and critical spares

Qualifications
The selected candidate must be able to demonstrate:
Electrical or HVAC background, or Graduate Electrical or Mechanical Engineer
Passionate about quality work and career minded looking for a new challenge
Can commit to a day and night shift roster (2 days of day shift, then 2 days of night shift, 4 days off)
Ideally able to commence asap
As part of carrying out the duties of this role, it is mandatory to hold Australian Citizenship.

If you are interested and meet the selection criteria apply with an up-to-date resume via the apply instructions on this website.

ENGIE Services is an EEO employer, where all applicants are treated with fairness and respect and have equal access to the opportunities available.

We will not be engaging in the services of a recruitment agency to fill this vacancy and therefore request all interested candidates apply directly to this advertisement.

Job
: Maintenance
Primary Location
: Oceania-Australia-New South Wales-Erskine Park
Organization
: ENGIE Services Australia and New Zealand
Schedule
: Full-time
Nature of Responsibility
: Senior operational / administrative role
Job Posting
: Sep 11, 2020, 6:29:59 AM",3.7,"ENGIE Services Australia & New Zealand
3.7",Sydney,-1,5001 to 10000 Employees,1995,Company - Public,Energy,"Oil, Gas, Energy & Utilities",$2 to $5 billion (USD),-1
Senior Data Engineer,-1,"Senior Data Engineer, Temporary, SYDNEY - McKell

Job Title: Senior Data Engineer

Salary: SNSW Grade 9/10 - The package includes base salary range of $111,806 to $134,667, plus employer's contribution to superannuation and annual leave loading.

Location: Head Office – Haymarket

Employment Status: Temporary through till 30th June 2021


About Service NSW:

Service NSW is making it easier for people and businesses across NSW to access government services. The role designs, builds and analyses complex data from multiple sources to identify revenue, process and business improvement opportunities; providing new information and insights to the business to inform planning, continuous improvement and performance.

About the Role

We are currently seeking to appoint a Senior Data Engineer to deliver expert advice and services in the design of a Single View of Customer and data-related services to support the achievement of business outcomes and strategic goals. We support flexible working practices with staff working remotely during this time.

In this role you will:

Design, build and support a modern data platform based in AWS and vendor technologies.
Provide expertise on data modelling for Graph data model and Customer Data Platform (CDP).
Create data pipelines, load, transformation and reporting workloads in AWS.
Work with the latest data engineering technologies like Apache Kafka, AWS Kinesis, AWS Neptune, AWS Glue and AWS Athena.
Contribute to the design and decision-making of the right tool or platform for the job according to requirements.
Provide expert advice and guidance on data quality and data engineering best practices.
Support a “bigger than you can imagine” scale of data in production environments.
Design, develop and support a metrics-driven reporting solution and a meaningful business intelligence platform.
Document the solution design and support procedures of solutions.
Produce reports, visualisations and recommendations to answer complex business problems that are presented in the most appropriate format to ensure clarity for target audience.
Analyse and define new process improvement opportunities to support continuous improvement and business outcomes; providing advice to stakeholders, on ways to improve the efficiency and reliability of data products and services.
Be very responsive to the information needs of the business by corresponding to customers in a timely manner and provide support/solutions to issues raised.
Troubleshoot and perform root cause analysis on production issues. Identify and implement long term solutions to problems. Perform scheduled maintenance, release deployment and production support activities after business hours, from time to time.
Liaise with internal and external customers to discuss and gather requirements, solutions etc. and maintain a good working relationship with the stakeholders.


Skills and Experience Required:

Solid experience with workflow technologies designing and building data pipelines, data models and data stores.
Experience working within and an understanding of Amazon AWS ecosystem, including security and performance tuning.
Hands on experience working with different types of databases, with focus on Graph and NoSQL databases.
Experience with data streaming required. Having used Kafka and related technologies is an added advantage.
Sound knowledge and experience working with batch processing, data extraction and API integration.
Hands on experience with at least one programming language: Java, Python or scripting.
Demonstrated experience working in an Agile based, fast paced, complex environment within cross-functional teams.
Experience developing systematised insights, data analytics and reporting solutions is an added advantage.
Experience with interactive visualisation of data insights is an added advantage.


Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Salary Grade 9/10, with the base salary for this role starting at 111,806 base plus superannuation

Closing Date: 6th November at 9:59am - applications will be reviewed on a rolling basis, applications may close early or extend

Please apply online, direct applications submitted via email will not be considered.

The Department of Customer Service is proud to be an EEO Employer who are fully focused on equality and believe deeply in diversity of all identities making us different and a true reflection of our NSW customers. As an inclusive workplace, we support various employee resource groups, practice flexible work and workplace adjustment.

If you do require an adjustment during the recruitment process, please notify us on your application form.",3.2,"Service NSW
3.2",Sydney,-1,501 to 1000 Employees,2012,Government,State & Regional Agencies,Government,Unknown / Non-Applicable,-1
Data Engineer - Entry / Mid Level,-1,"Work with a great team on interesting projects customers
Gain more experience in AWS, Data, DevOps cloud operations
Got a working knowledge of AWS? We will teach you the cool stuff!

Itoc is seeking an up and coming Data Engineer to join our growing Data Team in Sydney.

This is an exciting role working with databases, data lakes, data warehouses, data transformation (Python SQL) and enabling AI/ML.

You will be implementing foundational, robust and production ready data platforms to enable business data-discovery, self-service, AI/ML functions across a range of client types and industries, allowing them to do more with their data.

You'll be responsible for:

Deploying data repositories such as lakes and warehouses.
Contribute to our growing portfolio of data solutions.
Ongoing optimisation and management of data platforms.
Development of transformational logic for data pipelines
Data evangelism. We want to show our clients how to follow the best practices for data.

Desired Skills and Experience

To take up the challenge, you will have a depth of skills and experience including:

1-2+ yrs of focused data experience working with SQL and/or NoSQL solutions
A solid education in Software Engineering or equivalent industry experience.
Anything Data focused preferred.
Ability to analyse business scenarios and associated data landscape to derive potential opportunities.
Strong foundation in Python and SQL
Working knowledge of APIs
Principle knowledge of the different relational database platforms and modern data storage techniques
Knowledge of the different aspects of data environments
Collect, store, process, verify consume
Experience with version management systems (such as GIT)
Working knowledge of AWS or another cloud platform - we will teach you the cool stuff.
Great communication skills, an ability to work closely with customers, developers and engineers and the confidence to present ideas in open forums.
Relevant tertiary qualifications and/or industry certifications.
Great communication skills, an ability to work closely with clients, developers and engineers and the confidence to present ideas in open forums.

While not required, a background in consulting and professional services is highly desirable.

Itoc Description

This is an exciting and challenging career opportunity to join the growing Sydney-based Data Team of a leading cloud solution provider where you will be given support to reach your long term career goals. You will be part of a team of cloud experts and will work in an environment of continuous improvement and learning delivering innovative cloud solutions across SaaS, online business and enterprise business.

On offer is a chance to join a team with a great working environment, in an organisation that values its employees and sees the value in ensuring they are engaged. Our team are clearly passionate about what they do, that's why we won the following awards:

Customer Obsession Partner of the Year 2015: ANZ Region
Customer Obsession Leadership Partner 2015: re:Invent

As an employer of choice Itoc offers competitive remuneration, training and development programs and a great working environment. We value a healthy work life balance.

The Perks

MacBook or Dell
Continuous internal learning that will provide training and career development opportunities
Working with a collaborative, social team and leveling-up your skills faster than you will anywhere else.
Quarterly social events

Itoc

Culture and smarts are important to us. Bring your secret sauce. This is no ordinary environment, you will work along some of the Cloud’s best. All engineers at Itoc must gain at least five AWS certifications. We work hard but we have fun.

Please note you must have full working rights in Australia and be available on-shore for face to face interviews.

No recruiters please.",4.0,"Itoc
4.0",Sydney,-1,1 to 50 Employees,2013,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Date: 01-Oct-2020

Location:
Melbourne, VIC, AU

Department:Description:
Technology discounts - from Apple HP Lenovo to Windows
Flexible work arrangements - work in a way that suits you best
Salary packaging - to suit your personal and financial circumstances

Do you want to work for one of the fastest growing data teams in Australia? Do you want to work on multiple data platforms and provide new solution offerings by leveraging cloud and big data technologies?

About the team

Big data information and analytics. Three words that spark apprehension in most businesses. But our team of experts are constantly curious and excited about combining our wonderful array of technological expertise to transform data into our clients most valuable assets making their work smarter. Our data consultants are supported with resources training and tools they need to excel at their work but also the freedom and power to create their own paths forward to make a difference.

As a Senior Consultant in Big Data you will work closely with the team and stakeholders to build and deliver a Cloud based vision for a next generation Big Data analytics platform with strong focus on data quality data security and deliver the systems that process huge volumes of data.

What will you typical day look like?

You will play a pivotal role in - Designing and producing high performing and stable applications to perform complex processing of massive volumes of data in a new cloud based architecture; Building real-time data processing applications which are integrated with business systems to enable value from analytic models to drive rapid decision making; Contributing to system architecture design for a data platform (including cloud-based structures both on and off premises data warehouse components and data lakes); this could cover a range of technologies various countries/locations and lines of business; Support data strategy or technology strategy definition programs including technology stack definition and target operating model requirements

Enough about us lets talk about you:
You are someone with:
Use of traditional data analytics tools and techniques (e.g. MSSQL Oracle MySQL) and ETL software (e.g. SSIS Informatica CloverETL)
Working in large scale cloud data solutions using platforms such as AWS or Azure or GCP will be a bonus.
Experience in scripting or programming (e.g. Python Java Scala C#)
Excellent verbal and written communication skills to adapt to technical and non-technical audiences.
Educated to degree level (or have equivalent experience)
Why Deloitte?

At Deloitte we create positively differentiated work experiences that enable our people to feel valued and achieve their full potential. We value difference and embrace people with diverse backgrounds and thinking styles. Knowing that people work best in different ways we are happy to discuss alternative arrangements if the working pattern you are looking for is not specifically indicated.",3.8,"Deloitte
3.8",Melbourne,-1,10000+ Employees,1850,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Engineer,-1,"Opportunity to grow the team
Period of growth
Intuitive app
S2M are working with a FinTech who have created a unique financial product to help thousands of people better manage their finance, and is currently scaling the company to the next level!

They are looking for a Data Engineer to join, and looking for someone who wants to be hands on, with opportunity to grow the team in future.

Role:

Looking for people with strong AWS experience. You will need passion for data and a cloud, through which you will help a rapidly scaling Australian FinTech establish their data infrastructure from the ground up.
5+ years’ experience as a data engineer within the data and analytics domain
A python 3.X aficionado who is very comfortable creating and orchestrating AWS data pipelines with nothing but code
Strong project delivery toolset experience in open source data integration tools
Experience with processing large volumes of complex data including visualisation and insights generation
Ability to define and develop data integration patterns and pipelines
Ability to assess complexity of data (volume, structure, relationship etc.)
Hands on experience working with different databases (RDBMS, NoSQL, Blob storage etc)
Hands on technical expertise setting up DevOps automation
Hands on experience working technologies/platform e.g. AWS, Dockers, Containers
Experience building data profiling and data cleansing frameworks
Technical reconciliation and reporting
Knowledge and experience in end-to-end project delivery, either traditional SDLC or agile delivery methodologies (or hybrid approaches)
Exceptional communication, documentation and presentation skills
If this sounds like you, get in touch today - kate.gabb@s2m.com.au
3167410agsdf",3.1,"S2M
3.1",Sydney,-1,Unknown,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Analysts,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is seeking experienced and qualified Data Analysts to join our IT team based in our corporate office in Birtinya (Sunshine Coast) or at our meat processing facility in Kilcoy.
Key Responsibilities:
A mixture of data analysis and commercial skills to source, blend and analyse data to gain insight and answer key commercial questions
Working with strategic leaders to define and model Key Performance Indicators, and assist in building forecasting models
Working closely with data engineers and BI developers to specify data pipelines and report visualisation
Drive the creation and implementation of data quality business rule including data definition, governance and quality assurance
About You:
To succeed in this role, you’ll need to bring the following experience and skills:
Proven ability to derive insight and knowledge from data using commercial expertise is a strong requirement
Strong SQL and Excel skills are essential, along with strong data analysis and commercial insights
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Effective people communicator - engage with stakeholders on reporting needs, interpret requirements into visual solutions and train/deliver the outputs to the stakeholders getting signoff of acceptance
Bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking

How to Apply:
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kilcoy,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Network Data Engineer,-1,"Min 6+ years of experience in the relevant technologies
Australian Driving License for visiting remote locations / Data Centre for day to day technical work.
Managing Network devices (switches, routers, firewalls, load balancer, and wireless technology)
Performing MACD activities for all network devices.
Supporting BAU operation activities.
Proficient in performing in-depth details of technical troubleshooting, cause and provide recommendation to the client for incidents causing extended network outage to client’s critical locations.
Provide exceptional network services in terms of network support, break-fix, design and consulting, new projects, implementation.
Configure, administer, and document firewall infrastructure.
Manage the firewall deployment, rules migrations, and firewall administration.
Supporting Cloud Migration Activities from traditional to AWS/Azure.
Setting up VPN tunnel with Cloud and 3rd Party network devices.
Integrating and upgrading existing ISP bandwidth with support from ISP Vendor.
Setting up VPN profiles for Users.
Installing hot fix and patches to mitigate the security devices from attacks and bugs.
Reviewing and fine tuning the firewall rules and NAT rules.
Documentation and change control.
Mentoring, Motivating and Guiding support teams
Technical skills:
o LAN
o Wireless
o WAN
o MPLS
o Routing protocols (OSPF,BGP)
o DMVPN
o Azure cloud Networking
o Network Security
Fortigate Manager / Analyzer / Firewall
Cisco ASA
Firepower FTD
Cisco Any connect
Site to Site VPN
F5 Load Balancing and Scripting iRule
Job Types: Full-time, Contract
Schedule:
8 hour shift
Experience:
Scripting: 5 years (Required)
Data Network: 5 years (Required)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Required)",3.6,"Total IT Global
3.6",Sydney,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Engineer - Processing & Analysis,-1,"Job Description:
Design,build and maintain the ingestion system to support various types of data(e.g. User behavior, RDS, NoSQL db and others) to be ingested to the data warehouse more timely and accurately
Translate data requirements into scalable technical data service with low latency and high concurrency
Design,build and maintain the batch or real time data pipeline in production using Hadoop big data technology
Analyze and improve efficiency, scalability, and stability of the system
Define and manage SLA,Data quality for all data sets in allocated areas of ownership
Requirements:
Minimum B.S. degree in Computer Science or a related technical field
2+ years of working experience in programming languages,such as Java,Scala,Python
Familiar with Hadoop, Spark and Flink data processing, experience of TB data processing experience is a plus
Familiar designing and operating of a robust distributed system is a plus
Understand data mining or machine learning
Excited to work intimately with data
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"SYNOPSIS:
Lead Data Engineer
Applications close Sunday 8 November 2020
Ongoing
Contact name: Shyni Sasikala
Phone: (02) 6249 9048
Email: Shyni.Sasikala@ga.gov.au

The Data Policy and Informatics section within the Digital Science and Information branch creates, implements, and promotes policies, platforms and tools that improve and support the quality, discoverability, accessibility, and general usability of Geoscience Australia’s science data products. The section consults with internal and external research, government and industry partners to establish collaborative data frameworks, architectures and models within Geoscience Australia (GA) and across broader national and international communities of practice. The section innovates, builds and maintains tools, systems, processes and governance that enable digital data management, cataloguing and open data delivery.
GA makes accessible a wide range of geoscientific and spatial data to a wide variety of stakeholders in multiple formats, and in recent years GA's data volumes have grown exponentially. GA is focussed on making its data and metadata assets accessible so that they can be used in machine to machine interactions for data analytics and other applications in environments that range from High Performance Computing (HPC), through high-end cloud servers, to mobile devices.
We currently have two opportunities for Lead Data Engineers in the Informatics team. The Lead Data Engineer is responsible for innovating and exploring new technologies that will advance GA’s science goals and maximise the uptake and use of GA’s science data. The Lead Data Engineer reports to the team’s Assistant Director but also works closely with other developers, data scientists and engineers within the Digital Science and Innovation (DiSI) branch, as well as diverse stakeholders both within and external to GA.",3.9,"Geoscience Australia
3.9",Canberra,-1,501 to 1000 Employees,2001,Government,Federal Agencies,Government,$100 to $500 million (USD),-1
Data Engineer,-1,"The Seven Network is part of Seven West Media, one of Australia’s most prominent media companies, with a market leading presence in content across broadcast television, online and in print. Comprising some of Australia’s most renowned media brands, SWM includes not just Seven Network and its affiliate channels 7two, 7mate, 7flix and BVOD offering 7plus, but also 7NEWS.com.au, The West Australian, The Sunday Times and more.
At Seven we are here to bring all Australians closer to the moments that move us - we’re first on the scene, with our finger on the pulse, on demand, in the moment. Together, we’re responsible for creating and sustaining authentic Australian engagement.
A new and exciting opportunity has opened for a Data Engineer to join the Audience Intelligence team. Based in Sydney and reporting to the Head of Data Enablement, you’ll be responsible for:
Implementation of end to end data solutions to support Data Strategy for the SWM group.
Work closely with the Data Solution Designers to develop and maintain scalable data pipelines and build out new file and API based integrations to address requirements from the various business stakeholders.
Collaborates with engineering, analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organisation.
Work on Data Preparation for analytics and data scientist team members and assist them from an engineering perspective in building and optimising the models including building the automation of the end to end workflows
Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.
Perform data analysis required to troubleshoot data related issues and assist in the resolution of production data issues.
Work effectively with vendors for successful delivery of projects and acceptance of the solution
Work on Delivery projects using Agile Software Development methodologies
We are looking for someone who has:
Bachelor's degree in computer science, computer engineering or other technical discipline is essential
Proven experience working as a digital analytics specialist
Extensive experience with digital analytics implementation (e.g. Google Analytics, Snowplow, Adobe Analytics) and BI processes and visualisation platforms
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience in ETL and building and optimizing ‘big data’ pipelines and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Experience with big data tools: Hadoop, Spark, etc., AWS cloud services: EC2, S3, Lambda and familiar with version control systems: Git
Strong coding skills with knowledge of Unix/Linux and scripting languages such as Unix Shell scripting, Python desirable
Experience supporting and working with cross-functional teams in a fast-paced environment.
Ability to multi-task and problem solve with changing demands and priorities
Ability to work under pressure to meet deadlines and detail oriented
Your success is our success: we will provide you with opportunities for you to keep learning and growing, enabling you to challenge and develop yourself. In return, we offer a benefits program that has something in it for everyone.
Seven West Media is an equal opportunity employer and we are committed to creating a diverse and inclusive workplace.
Recruitment Agencies: Seven West Media does not accept any unsolicited agency resumes and will not be responsible for any fees related to unsolicited resumes.
Advertised: 19 Oct 2020 12:00 AM AUS Eastern Daylight Time
Applications close:

Back to search results",2.5,"Seven West Media
2.5",Sydney,-1,5001 to 10000 Employees,1956,Company - Public,TV Broadcast & Cable Networks,Media,Unknown / Non-Applicable,-1
BICON Rules Engineer,-1,"APS 5 - $73,299 - $80,410 per annum plus superannuation
Biosecurity Plant Division
Canberra, ACT
Play an active role in managing biosecurity risk to Australia
Work in a motivated and professional team with a wide range of skills and backgrounds
Full training provided

Who we are
The BICON Content Development Team maintains and improves the Biosecurity Import CONditions database (BICON) content to allow external clients to understand and comply with their biosecurity obligations and internal clients to effectively manage biosecurity risk and regulate imports. We work collaboratively with internal clients to comprehend and implement their BICON content requirements and optimise the use of BICON to publish clear import requirements and onshore management support procedures to effectively manage biosecurity risk.

The Jobs
Key duties of these positions include:

working with business content (import and permit conditions) and import programs to understand and construct decision tree structures in the BICON database, in accordance with system design and authoring conventions
executing changes to import and permit conditions in alignment with service standards while complying with system rules and authoring conventions
providing technical advice through various formats on the most appropriate means of authoring BICON content to achieve import program and stakeholder objectives
using workflow management tools to maintain detailed records of changes to import conditions and key decisions
performing administrative tasks including system reporting, data analysis and scoping tasks for the BICON content change work program
contributing to the development and maintenance of instructional material, authoring conventions and courseware
clearly documenting and reporting system issues
developing and maintaining effective working relationships with internal and external stakeholders.

What we are looking for
Knowledge and experience
Experience working with complex IT systems.
Experience working collaboratively and as part of a team.
Knowledge of the role of biosecurity is preferred but not essential.

For additional information, please read the Job Description below.
Candidate Information Package docx Opens in new window",3.9,"Department of Agriculture & Water Resources
3.9",Australia,-1,5001 to 10000 Employees,-1,Government,Federal Agencies,Government,$500 million to $1 billion (USD),-1
Cloud Data Engineer,-1,"Job no: 509605
Work type: Permanent Full Time
Location: Melbourne, Canberra, Sydney
Do you embrace digital disruption?
Do you love solving complex problems, designing sophisticated solutions and building innovative technology?
Do you believe in creating powerful actionable insights from Data and Analytics?
Do you want to work in a diverse and flexible working environment?
KPMG is one of the most trusted and respected global professional services firms. Through depth of expertise, clarity of insight and strength of purpose we help our clients solve complex challenges, steer change, strengthen, transition and grow. We are a team based practice and this extends to our clients whom we work and collaborate with, in solving complex problems. Together, we design, innovate and implement, providing enduring advice that support our clients and the services they deliver. Our clients vary in size and come from a diverse range of sectors – all sharing in a common goal: to embrace change and deliver services that make Australia a better place. We are looking for talented individuals who would like to join us on the journey.
KPMG’s Digital Delta Team
We re-imagine and re-invent organisations to become world class digital enterprises using advanced technologies, data and human insights. We help organisations to embrace Digital Strategy, Artificial Intelligence (AI) & Cognitive, the Internet of Things (IoT), Data, Analytics & Modelling, Mobile App & Web, and User Experience (UX) & User Interface (UI) and more.
We work with clients to:
Formulate strategies that re-imagine organisations
Harness innovation from the 4th industrial revolution
Actioning insights from trusted data to consistently and quickly make clear decisions
Build adaptive organisations
Thrive as a connected enterprise – front, middle and back office
This is how you’ll contribute:
We are looking for ambitious Data Engineers who are passionate about helping clients define bold ambitions and deliver on them. Joining our team will take you on a journey of personal and technical growth and provide the opportunity to inspire confidence and empower change.
As a Data Engineer you are the designer, builder and manager of the information or ""big data"" infrastructure, preparing data for analytical or operational use. You will design, construct, test and maintain a data pipeline to pull together information from different source systems; integrating, consolidating and cleansing data; and structure it for use in individual analytics applications.
The KPMG Difference
Our people are focused on creating a diverse and dynamic environment that embraces and values differences. We value the variety of unique experiences, qualities and characteristics our people possess and we share and learn from each other.
We are proud to be consistently recognised as an employer of choice for women, and for our achievements in LGBT+ workplace inclusion.
Our commitment to ‘Flexibility’ allows our people to manage the changing demands of work, personal or family life. Explore the links below to hear our people share their experience @ KPMG:
Flexibility empowers wellbeing
Flexibility enables contribution to the community
Flexibility inspires technology & innovation
Flexibility supports family

Make KPMG the clear choice for your career and be Extraordinary!

Advertised: 09 Sep 2020 AUS Eastern Standard Time
Applications close:",3.8,"KPMG
3.8",Sydney,-1,10000+ Employees,1987,Subsidiary or Business Segment,Accounting,Accounting & Legal,$2 to $5 billion (USD),-1
Computer Network and Systems Engineer,-1,"Duties Include but are not limited to:
Tasks Include:
analysing, developing, interpreting and evaluating complex system design and architecture specifications, data models and diagrams in the development, configuration and integration of computer systems
researching, analysing, evaluating and monitoring network infrastructure to ensure networks are configured to operate at optimal performance
assessing and recommending improvements to network operations and integrated hardware, software, communications and operating systems
providing specialist skills in supporting and troubleshooting network problems and emergencies
installing, configuring, testing, maintaining and administering new and upgraded networks, software database applications, servers and workstations
providing network programming in support of specific business needs and requirements
preparing and maintaining procedures and documentation for network inventory, and recording diagnosis and resolution of network faults, enhancements and modifications to networks, and maintenance instructions
monitoring network traffic, and activity, capacity and usage to ensure continued integrity and optimal network performance
Skills and Experience Required:
Must have experience working in a Managed Service environment
Demonstrated experience in IT Networks and Data Centres
Understanding of systems and architectures to meet client needs
Experience in Help Desk including break / fix
Effective and timely documentation
Effective Task Management Skills
Be solution and outcome focused and willing to learn new technologies
Excellent communication skills with staff, clients and partners
Time management, ability to prioritise and deliver to schedule
Experience with N-Able and Connectwise desired
Open Cabling license desired
Job Types: Full-time, Permanent
Salary: $30.00 per hour
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,Trans-plant training,Canberra,-1,-1,-1,-1,-1,-1,-1,-1
Software Engineer (Data),-1,"If you are looking for an opportunity to make a real impact with smart people who are genuinely doing things differently then you've come to the right place! We're growing our data engineering capabilities and are looking for awesome data engineers to join our team.
With our diverse range of clients and projects, no day will look the same - but here's a great snapshot of what you'll be doing:
Work with some of the best Data Scientists and Engineers to deliver production-grade AI and Machine Learning systems as we deliver client projects from inception to production.
Consulting with our clients and working with them to build modern data systems using the 'best of' technologies and principles.
Advising clients on data strategy, architecture and technology.
Applying best software engineering practices in coding, monitoring and alerting, using CI/CD, TDD and cloud architectures.
Working over a wide range of big data tools and environments: not limited to; Apache Kafka, Spark, Python, Scala, Hive, Airflow, AWS EMR & Glue, GCP Dataproc & Dataflow, BigQuery, Snowflake, Redshift.
Who are we?
Glad you asked! We are Eliiza. Data science. Engineered for scale.
We are a passionate team of data scientists and engineers who apply data science and machine learning to solve real-world problems. Our mission is to create a bright future for Australian businesses and society in a world increasingly influenced by intelligent technologies.
We've created a culture that values diversity where people can truly be themselves! We care a lot about growing the Australian AI community in a positive direction, and we're doing several things to try and achieve that:
We provide opportunities for underrepresented groups to work in AI through our associate and intern programmes
We organise and participate in a range of community events, reading groups and meetups
We produce the AI Australia podcast
We blog about topics we care about
We stream brown bag sessions to the broader community
We're also part of Mantel Group's 'house of brands' which means it's not just the Eliiza team you'll work with, learn from and see at social events - there's another 230 of us across DigIO, Kasna & CMD Solutions!
So you're ready for something new?
We're keen to know more about you! Our team is made up of a range of people, with different experience across a huge range of data driven skill sets.
We'd love to hear from you if you have experience with:
one (or more) core language(s), ideally Scala, Python or Java
one (or more) cloud platforms, AWS, GCP, Azure
ETL/ELT concepts and technologies e.g. Data partitioning, Hive, Spark
streaming data concepts and technologies, ideally Kafka (Kinesis, Beam or Pubsub will do)
We'd be over the moon if you:
Experience with distributed/columnar databases (e.g. Snowflake, Big query, Redshift).
Experience with any of a variety of databases e.g. RDMS, NoSql, Columar, Distributed, Time series, Graph.
Knowledge of job orchestration and scheduling. Any experience with Airflow, Luigi or Oozie.
Experience with containers and container orchestration (Docker, Docker Compose or Kubernetes).
However, we value a diversity of skill-sets, and don't necessarily require that you're skilled with all of the above. If you feel you don't fit all the experience/skills listed above we still encourage you to apply or get in touch.
What's on offer if you join us?
We make sure you're always one step ahead by investing your learning and development, every year. We build our own training where it doesn't exist yet.
We hire smart people and get out of their way. By focusing on our five principles and not getting caught up in red tape, we trust you to get the job done.
You'll get all the tools you need - a new iPhone or Google phone, a new Macbook Pro or Dell, and a lot of branded swag!
But hold on, you mentioned a house of brands?
We certainly did! Mantel Group is an Australian-owned, 'house of brands' company with four technology businesses (Eliiza being one of them!) across Melbourne and Sydney. We're building a group of companies with open borders so we can support you to take on new skills without leaving an awesome team - we understand you won't have one job for life!
We may only be just two years old but Mantel Group has already been recognised #9 in the 2020 Best Places to Work in Australia and #4 in the AFR's 2020 fastest growing new companies.
Keen to chat?
Click ""Apply"" to share your details with our talent team, and we'll be in touch.
In the meantime, check out 'how we hire' to find out what's in store if you're successful and get to know us better by visiting our website and following Eliiza on LinkedIn.",-1,Eliiza,Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Infrastructure Engineer,-1,"Job Description:
Design and grow the Shopee data platform to support a variety of big data applications using open-source technologies including Kafka, Hadoop, Presto, HBase, Spark, Hive, Druid, and our own creations. Some examples include a real-time data streaming platform, a unified query platform, a cluster management system, and a machine learning platform
Dig into the source code of some open-source big data system to get the whole control and familiar with the details, configurations, designs and source code. Develop and maintain the internal release of big data systems and components as the business requirements.
Keep close and overall monitoring for all the deployments of the systems, maintain the system’s stability, improve the performance, discover the performance bottlenecks, tracking and troubleshooting, cost optimisation.
Requirements:
B. Sci. / Ms / PhD in Computer Science or a related technical field
Familiar with at least one of these languages: Java, Scala, Python, Bash under Linux / Unix. Scala is a plus
Familiar with the use and compute logical of SQL
Knowledge about the Big Data Infrastructure system technology like Distributed File System, Distributed Computing, Distributed Database will be a plus
Hands-on experiences Hadoop, Spark, Kafka, and/or Presto will be a plus
Love to use and develop open-source technologies
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"Work on an award-winning, international technology!
Endless career opportunities
An innovative, friendly team of 300+
This role will be focused on the development of our existing ClaimLogik line of products as well as working on our new cloud-first, modern suite of applications.

Intelligent Thought, our technology business is scaling and shipping our software globally. Already profitable, part of a much larger group business, with investors such as Macquarie Capital and Envest – we are all set to deliver textbook disruption to the Insurance Industry. The growth of the platform, of our customer base, and the increasing industry demand have led to the need for this role to help the team scale.

Our Philosophy
Give each employee a sense of purpose and an environment for them to connect the importance of their role to delivering a service that matters to our customers.
Challenge the ‘why’ of traditional claims processes.
Keep it simple – do only what brings value and what matters to the customer
Enable employee decisions, empower our people
Responsibilities:
Create, extend and maintain ETL pipelines to form our data lake, data warehouse and analytics platform (currently using the Microsoft Azure set of tools and service)
Help define the optimal data pipeline architecture
Influence the tool selection, platform selection, data architecture and strategy which will transform the business to be truly data-driven
Understand, analyse and size user requirements
Work with different parts of the business to provide them with the insights they need to deliver the best results
Skills & experience:
Degree or qualification in computer science or related
Advanced knowledge of relational database, including query authoring and query optimisation (MS SQL Server and PostgreSQL).
Experience building and optimising ETL pipelines
Experience designing complex data models
Experience working with cloud platforms (Azure or AWS)
Efficient time management and organisational skills
High attention to detail and accuracy
Effective communication skills to build strong working relationships; both written and verbal
Proactive and results-driven
Why Claim Central?
Claim Central Consolidated is a global insurance industry leader across, claims management, insurance technology and data and analytics. Currently operating in the United States, Australia, South Africa, Italy and New Zealand, we have pioneered digitally connected claims management services across the globe. Claim Central is a disruptor and thought leader in the industry and we were recognised as the Australian Financial Review’s 8th Most Innovative Company in Australia in 2016. This business is in a period of unprecedented growth, transitioning our technology and services into multiple geographies at a rapid pace. Our unique culture is based on teamwork, collaboration, trust, respect and performance. We also offer many benefits apart from our exceptional team culture; including flexible work arrangements, and continued professional development.

Be a part of this journey in a career-defining role.",-1,Claim Central,Matraville,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer - AI/ML,-1,"Our client provides services to a major industry across the country. The business is still early in it's days of technology development and the environment is greenfields in nature (no pun intended), effectively working like a start-up.

Their data and analytics team have worked and built leading and bleeding-edge technologies in this space and what they have created so far may be game-changing. From a machine learning perspective, the progress they have made to the business has already seen proven success in changing the future of an industry that will have positive consequences for all those involved.

You will have previously worked in a technical capacity in the data and analytics space and have experience working with an organisation where machine learning has been implemented, not just a concept that the business talks about having or the technology team would love to have. The commercial experience you will have had in the ML field will be proven examples of where you have affected the way a business or industry used to perform, to the changes that have come about from this.

Technically, you will have extensive experience in the Microsoft space - Power BI, Azure etc and you will have previously mentored and coached junior members of the teams you have been part of.

This is a rare opportunity in Brisbane where the business has truly embraced and funded projects across the ML space and would be a great chance for those in the Data Development/Data Engineering field, who are looking to move into a Data Scientist role in the future.

Please send your application through if you would like to know more.",4.0,"Emanate Technology
4.0",Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Solution designer/ ETL Engineer & Data Modeller,-1,"We are looking for a Qualified and Experienced Solution Designer to join our client for a period of 6 months with a view to extend.
You will work closely with team members and your contribution will range across gathering and analyzing information, developing and documenting improved processes and work instructions and experienced DWH Lead with skills in requirement analysis, solution designing, developing, testing and supporting ETL solutions.
A hands-on solution designer, data modeler and ETL developer for Data Warehousing and ETL application transformation projects using Informatica PowerCenter.
Knowledge on AWS, S3, Redshift, Informatica BDM, and related technologies.
Experience working with IPython, PySparks, AuCuMo, Airflow, Jenkins, Github, Athena, JIRA, Rally, Spectrum, Glue, Flyway.
Good exposure on Oracle PL/SQL, aware of DBA activities, writing and performance tuning of complex SQL queries.
Contract length: 6 months
Job Types: Full-time, Contract
Salary: $650.00 – $800.00 per day
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,nducive,Melbourne,-1,-1,-1,-1,-1,-1,-1,-1
"Data Engineer, Wollongong NSW or Mount Waverley VIC",-1,"Company Description
BlueScope is a technically advanced supplier of steel and steel products in Australia. We are an inclusive organisation and every day we showcase our technology and expertise throughout the world.

Job Description
We are looking for two Data Engineers to join our IT team, based in Wollongong NSW or Mount Waverley VIC. Use your experience in analytics to unlock business value, enabling use of big data for insights and decision-making.
Reporting to the Data Product Owner for our Australian Steel Products (ASP) business, this position will support strategic goals related to data. This will see you:
Gather business and technical requirements with the view to deliver outcomes;
Develop and implement end-to-end data collection, consolidation, modelling and visualisation solutions;
Document metadata in a dictionary and catalogue;
Ensure consumers of such information understand its accuracy, timeliness, quality and sensitivity, so that it is used appropriately; and
Identify opportunities to enhance analytics.
What are the benefits?
Work in a supportive and collaborative team environment whilst we embark on a journey to transform the way our business uses data!
Our systems landscape is broad and diverse. You will be encouraged to think creatively to develop data solutions which solve real business problems.
Working in this role you will enjoy:
the chance to learn more about data science;
salaried remuneration with attractive superannuation options;
the opportunity to participate in a performance incentive scheme; and
access to further development and career opportunities with BlueScope.
Who are we looking for?
We welcome applications from professionals with experience in data analytics and/or programming. Supported by your knowledge of project delivery methods (e.g. Agile), you will demonstrate:
experience with data mining, wrangling, mapping and visualisation techniques (e.g. Azure Data Factory, Databricks and/or DevOps etc.);
well-developed ability in gathering business and technical requirements;
skills in developing and implementing collection, consolidation, modelling and visualisation solutions; and
a passion for sharing your knowledge and desire for ongoing professional development.

Qualifications

null

Additional Information
We're proud to have been named an Inclusive Employer for 2019–2020 by the Diversity Council of Australia. We believe that our people are our strength. Having a diverse and inclusive workplace enables us to improve our capability and ensure continued, sustainable success.
We know that workplace flexibility can mean something different to everyone. Under our B-Flex initiative all of our roles have some degree of flexibility. We encourage you to discuss your needs with us.
Applications close Sunday 25th October 2020.",3.3,"BlueScope
3.3",Wollongong,-1,201 to 500 Employees,-1,Company - Private,Construction,"Construction, Repair & Maintenance",$100 to $500 million (USD),-1
ETL Data Engineer,-1,"ETL Data Engineer

Join a team that’s changing how Australia lives, works, plays and grows
We want you to be the best version of you

Work with innovative teams and explore new technologies to help solve real-world problems.

A typical day as a Data Engineer

ETL / Big Data Engineering professionals will be responsible for guiding the full lifecycle of a Data solution, including:
Working in highly client-facing roles to contribute throughout the end-to-end delivery lifecycle of complex and large-scale digital solutions
Use case and business case development
Support existing and new applications utilizing in-depth technical and data knowledge. Troubleshooting complex issues and providing advisory services to improve the client’s data landscape
Help to streamline and simplify the clients’ complex data landscape by integrating different applications and data architectures
Implementation from requirements analysis, platform selection, digital architecture design, application design and development, testing, and deployment
Interstate travel may be required

Basic qualifications:
Bachelor’s degree
Experience across systems integration, information management, data management and architecture, and business analytics
Experience with being in a team focusing on large-scale, multi-release information centric projects
Experience with waterfall and agile delivery and run / application support functions
Part of a team working on End to end implementation of at least 1 big data project

Preferred Skills:
Hand on experience in Data warehousing using ETL tools such as DataStage, Autosys and TeraData
Hands on experience in ETL job development with multiple stages like sequential file, Transformer, Lookup, join, sort and Database stages.
Strong hand on skills in design, development and implementation of various data remediation, Data migration, data integration techniques.
Strong hand on data modelling experience.
Strong hands on experience in database performance tuning including complex query optimizations and physical database tuning using Teradata.
Understanding of architectural designs and strategy related to data migration, data cleansing, data quality and data consolidation.
Proven data analysis, requirement gathering and problem-solving skills
Exposure to Unix environment and shell scripting.
Experience in Banking and Financial services industry
Desirable: Knowledge of cloud computing infrastructure (e.g. Amazon Web Services EC2, Google Cloud, Microsoft Azure)
About Accenture

Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. We combine unmatched experience and specialized capabilities across more than 40 industries — powered by the world’s largest network of Advanced Technology and Intelligent Operations centers. With 513,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises. Visit us at www.accenture.com.

Accenture is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, marital, domestic or civil partnership status, sexual orientation, gender identity, or any other basis as protected by applicable law.

Vera Goga is the Recruiter managing this role. As the team experience high volumes of applications, we appreciate your patience to allow for a fair and timely process.",3.9,"Accenture
3.9",Sydney,-1,10000+ Employees,1989,Company - Public,Consulting,Business Services,$10+ billion (USD),-1
Student Engineer,-1,"The candidate will have the ability to:
Undertake onsite inspection to collect asset condition data based on the relevant engineering standards and technical guidelines;
Undertake desktop analysis to evaluate the condition and performance of the assets;
Provide the appropriate information, advice, engineering input and support services for the sustainable management of Council’s stormwater and transport networks.
Qualifications:
The successful candidate will be enrolled in a Bachelor of Engineering with a minimum of two years completed.
Position Number: 100678
Position Hours: Fixed term (3 months), hours will be negotiated with the successful candidate, maximum of 75 hours per fortnight.
Salary: Schedule A, Salary Point 4.0. $28.64 per hour ($55,853.45 per annum, pro-rata) in accordance with Glenorchy City Council’s Enterprise Agreement 2016
Please note that all successful applicants will be required to provide a current National Police Check prior to commencement of employment.
For further information on this position, contact Patrick Marshall, Senior Civil Engineer on (03) 6216 6800.
How to apply: Applications for this position must be lodged on this submission site or on the Glenorchy City Council website www.gcc.tas.gov.au - Careers page.
To be considered for this role, all applicants must address the key selection criteria in the and provide a current resume. A copy of the position description can be found by clicking the below hyperlink or on the Glenorchy City Council website.
Applications close at 8pm on Sunday, 1st November 2020
- Student Engineer",4.0,"Glenorchy City Council
4.0",Glenorchy,-1,501 to 1000 Employees,-1,Government,-1,-1,Less than $1 million (USD),-1
Data Engineer involving DevOps,-1,"Data Engineer involving DevOps
Axiom Technologies is an Australia based entity with the history of providing Managed IT solutions to medium to large scale enterprises globally. Please visit our website for more information about what we do at www.axiomtechnologies.com
Axiom Technologies is an Equal Opportunity Employer and encourage applicants from all backgrounds and gender to apply, including, Aboriginal and Torres Strait Islander candidates
Job Requirements:
8+ years IT experience, with at least 5+ years of “Data Engineer/Deveoper” focused titles/roles,
Data Tools: Hands on experience with Apache Beam.
Testing: Hands on experience with automated testing activities/outcomes
DevOps: Experience with the processes involving Microservices facilities for artifacts developed
Platform/OS: Mid-range/Unix
Languages: Unix (Shell) Scripting/commands, SQL, Python
File formats: Text, CSV, Parquet, JSON, XML
Scheduling: Jenkins, Airflow
Auto Scripting: Designing/creation of scripts for repetitive activity. E.g. Unix scripting/SQL
Big data: Exposure to Data Lake Concepts, Hive (Schema), HDFS
Source Control tools: GIT
Delivery Models: Agile, Scrum
Ingestion Design: Create/assess Source/Target data mapping designs
Frameworks: Development and delivery frameworks
Activity Reporting/Repository: Jira, Confluence.
Quality: Accuracy and attention to detail
Industry: Financial Services/Banking
Solutions: Define solutions from High level to detail design to address automating ingestion activity. Facilitate/confirm requirements from product owners, business team members and technical associates,
Process Automation: Automating processes in file management, testing data in files, analysis and design, configuration management.
Script Automation: Ability to design/create scripts to automate/improve data copy/migration/ETL for any repetitive activity.
Languages: Java, Python
Scheduling: Control-M
Databases: Relational. E.g. POSTGRESS, Oracle – as a ETL developer
File Formats: Mainframe – experience with referencing its data formats/copybooks
Big data: Experience referencing/using Hive (Schema) to access data in HDFS
Metadata management tools: MDM, EDC and Axon
Performance: Assess, recommend, improve mappings, SQL queries, Batch feeds
Automation Tools: Other tools that may add value to an automation program and generally support development. E.g. API, REST, JDBC, Webservices, Message Queues/Load balancer,
Cloud: Experience with processing of data files to be ingested/stored in the Cloud, preferably with AWS.
Prod Support: Experience in a production support role performing root cause / impact analysis – under time constraints
Experience in a similar role
8+ Years
What next?
If you are looking for that next challenge in your career and wish to apply for this role, please forward your resume to careers.au@axiomtechnologies.com",2.0,"Axiom Technologies
2.0",Melbourne,-1,1 to 50 Employees,-1,Company - Private,Industrial Manufacturing,Manufacturing,Less than $1 million (USD),-1
Data Engineer,-1,"About the Role
We are on an exciting digital journey so it’s a great time to join ME! We are seeking a Junior Data Engineer who enjoys rolling up their sleeves, learning and growing. As part of our Enterprise Data Team, you will ensure fit for purpose data warehouse solutions are built for use across the bank and by utilising best practise ETL standards, whilst ensuring the data is trusted by our BI developers and key business consumers. Oh, and you’ll get to work on Microsoft technology stack too!
You will be involved with investigating data issues, keeping data feeds flowing and collaborating with different projects across the bank to deliver quality data solutions. How important does that sound? What’s even more important is this role contributes directly to our overall business strategy through the provision of data to enable analytics & reporting, as well as supporting business and decision system processes.

About You
You’re naturally a highly motivated and energetic person who thrives in a dynamic, ever-changing collaborative team environment. Ideally you have previous experience as an ETL developer, Data Engineer or a BI developer, and if you have a degree in computer science or similar it would really put you ahead of the rest.

With your knowledge of SQL coding, data modelling, understanding of data warehouse concepts, plus experience of working on complex ETL solutions, you’re ready to expand your horizons and launch your career into the world of IT at ME.

About ME
We’re not like other banks.
ME was created by the industry super funds to be different from the pack – with a core purpose to help all Australians get ahead financially – no conditions, asterisks or exceptions. And we know that looking after customers starts with taking care of our people.
We believe everyone deserves the same opportunities in life, regardless of gender or identity, sexuality, ethnicity, religion or disability ‒ with internal affinity groups.
Perk ME up
Once you get your feet in the door at ME, we’ll put them both in your very own ME-branded Converse shoes. You’ll also get the following financial, health and fun perks when you join the team:
4U Extras portal (discounts and cashback on 100s of items including cinemas, shopping and gym memberships
10% Myki discount
Purchased Leave programme
Internal wellness programme (Mindfully ME)
Professional education through LinkedIn Learning
Novated Leasing
Professional membership reimbursements
Health checks
Financial education (To help you manage your money smarter)
LGBTIQ+ and Women at ME affinity groups

I want those Converse shoes (and the role)
Can’t see a closing date on the advert? That’s because we’re pretty efficient here at ME and we may start looking at applications sooner rather than later, so if this role sounds like your jam, be sure to apply by submitting your resume today.

Should an applicant be the preferred candidate, background checks (including police checks, reference checks, ASIC banned and disqualified persons and bankruptcy checks) will be completed prior to the candidate's employment being confirmed. The outcomes of the background checks do not automatically bar candidates; however will be assessed against the inherent requirements of the job.
Back Share
Apply Now",3.0,"ME Bank
3.0",Melbourne,-1,501 to 1000 Employees,-1,Company - Private,Banks & Credit Unions,Finance,$100 to $500 million (USD),-1
Software Engineer - Machine Learning/Data Science,-1,"Zendesk is looking for a Software Engineer - Machine Learning/Data Science for a full time position in our Melbourne office.
As part of our engineering team, you will work at a scale where the challenges start to get seriously interesting. Our global engineering team is widely dispersed over the world, with people across nearly every continent. You will get a chance to do cool things with a diverse bunch of people while working in the Melbourne office that is home to Zendesk’s first machine learning (ML) research team.
The Data Science Team, together with Data Engineering, have built Satisfaction Prediction, Answer Bot and Content Cues — products that use Machine Learning (ML) and Artificial Intelligence (AI) to help our customers work more efficiently.
What you get to do every day:
We’re currently looking for someone to join our team as we research, develop, and productionise Machine Learning and Deep Learning models. In addition to frequenting Melbourne’s finest purveyors of coffee, ramen, and bulgogi, you may find yourself:
Building machine learning models including neural networks in TensorFlow
Writing and deploying production-grade Python
Querying and constructing datasets in AWS Athena, Spark
Evaluating and responding to real-world model performance
Scaling your ML to millions of predictions per day
Presenting your work to a broader audience
Watching your algorithm help Zendesk’s end-users
What you'll bring to the role:
A strong foundation in a quantitative discipline (e.g. machine learning, statistics, bio/eco/etc-informatics, econometrics, etc) is critical for this position. While experience in deep learning and natural language processing would be beneficial, your best qualities are:
dedication to continuous learning
collaborative work attitude
strong communication skills
You should also be comfortable with at least one programming language, such as Python, R or Scala.
Application Deadline: 18/11/2020
Job Types: Full-time, Permanent
Salary: $85,000.00 – $110,000.00 per year
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Temporarily due to COVID-19",4.5,"Zendesk
4.5",Melbourne,-1,1001 to 5000 Employees,2007,Company - Public,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),-1
Software Engineer (Machine Learning),-1,"About the Role
AdelaideMRI is building a medical reporting tool. We require an engineer to work primarily on machine learning projects to improve reporting speed and report comprehensiveness.
You will perform data analysis of medical report datasets and image datasets to infer sentence recommendations, image classifications, or other actionable results for the doctors.
Skills and Experience
Background in machine learning or image processing
Qualifications in Computer Science, Software Development or Engineering or equivalent experience
Bonus points for Python
No prior medical knowledge is required.
This position offers flexible hours and work arrangements.
Job Type: Full-time
Experience:
Software Engineering: 1 year (Preferred)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Yes",-1,Adelaide MRI,Australia,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Hey there, we’re PEXA!

We started as an idea: to deliver a single, national e-Conveyancing solution. We collaborated with the industry to create a national electronic lodgement and settlement platform: PEXA. From our humble beginnings, we’ve now grown to more than 320 employees across 5 different states. We’re still expanding at a rapid rate and constantly challenging ourselves to create great experiences for our members as they transition to fully digital conveyancing.

Why become a PEXArian?

Great question! Being a PEXArian is so much more than just a job. We are passionate, motivated & unashamedly enthusiastic at PEXA - we love what we do and we’re proud to admit it! Creating brilliant member experiences wouldn’t be possible if we didn’t also strive to create an amazing employee experience. Alongside our members, our employees are at the heart of everything we do.
Here’s a snapshot of what your life at PEXA could look like:

Your growth:
We encourage you to hit your personal and professional Learning & Development goals with our tailored programs and tools.

Your wellness:
We care about your holistic well being - a fully stocked kitchen, four wellness days, a $250 wellness subsidy as well as lunch and learn sessions to support your financial well being.

Your work/life blend:
We know that work is just one aspect of your life, we want to help you create your ideal work/life blend, rather than squeezing in life around work.

Your family:
With a range of benefits aimed at supporting your family including access to a subsidised school holiday program, extended parental leave and flexi-time to support your return to work, superannuation payments for unpaid parental leave for primary carers and a childcare allowance for pre-primary aged children, when we say, ‘welcome to the family’, we really mean it!
The impact you'd drive:
The successful candidate will be responsible for developing, and maintaining infrastructure to support the delivery of new and existing products. They will also be contributing to establish the rules and frameworks for obtaining the required approvals for new products.
On day one we’d love you to have:
Experience with Python, Spark
Event streaming/sourcing with Kafka or AWS Kinesis
Experience with data structures, formats and data security best practices
AWS experience (e.g CloudFormation, S3, ECS, Lambda, SQS, IAM, KMS, DynamoDB, Glue, Athena)
Query construction and optimisation (e.g. SQL, Elasticsearch, Splunk, DynamoDB)
Git, version control practices, and continuous integration/delivery servers
PyUnit and unit testing frameworks
Production release cycles and maintenance
Collaborating with technical and non-technical teams
Even better:
Agile methodology/delivery
GraphQL
Modern frontend technology (e.g. ReactJS, TypeScript)
Machine learning frameworks and tools (e.g. TensorFlow, PyTorch)
OAuth 2, SAML 2, JWT
Data visualisation and exploration tools (e.g. Jupyter notebooks, Tableau)
AWS SageMaker
Sounds like you?
If this role sounds like you, apply today to have your application reviewed ASAP!",3.9,"Property Exchange Australia Limited
3.9",Melbourne,-1,201 to 500 Employees,2010,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Ongoing position
Full time
Based in Sydney, NSW
Who we are
Australian Red Cross is part of the world’s largest humanitarian organisation. Our aim is to improve the lives of the most vulnerable people in Australia and across our region.
About the role
The Data Engineer role will sit within the Data and Integration Squad in IT and will own (design, implement and support) the AWS Big Data technologies such as the Data Lake and Data Warehouse and support the organisation in growing the data analytics capabilities at Red Cross. In addition to this, the data engineer role will also administer the Power BI tool and support the implementation of the data mastering capability.
What you will bring
Experience building and optimizing data pipelines, architectures and data sets.
Experience in dimensional modelling and building data vaults
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with structured, semi-structured and unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Why work for us?
Work for purpose and know that your work assists Red Cross support and empower people and communities in times of vulnerability.
Generous salary packaging options available that can increase your take home pay.
Further information
To find out more about this opportunity please see the position description below or contact Sharath Kumar Gurram on 02 8651 8839.
Position Description: Position Description - Data Engineer .pdf
Applications for this position will close at 11:55pm Thursday, 5 November 2020.",4.1,"Australian Red Cross
4.1",New South Wales,-1,1001 to 5000 Employees,-1,Nonprofit Organization,Industrial Manufacturing,Manufacturing,$500 million to $1 billion (USD),-1
Junior Fullstack Data Engineer (Python and React),-1,"Formbay is the leading Renewable Energy Certificate Trading company in Sydney. We provide Digital Workflow and Compliance solutions in the renewable energy industry and document processing.
Thanks to our meteoric growth and our commitment to be the best at all we do, we've identified the need to bring on board a new Junior Fullstack Data Engineer.
Reporting to our Principal Machine Learning Engineer, you will help build Machine Learning pipelines for our existing Digital Workflow and Compliance solutions to automate fraud detection and document processing over terabytes of photographic and documentary data – including documents, photos, GPS data and aerial/satellite photography.
Our stack is based on Python, JavaScript, Dask, Tensorflow, CUDA, Nix/NixOS, AWS, Docker, PostgreSQL and more – familiarity with these applications will give you a leg-up on the competition.
Our ideal candidate will have the following competencies:
SQL
Python
JavaScript/TypeScript
Our candidate must also be comfortable working with Linux.
Located a stone's throw away from the Queen Victoria Building in Sydney's bustling CBD, we are centrally-located with easy access to public transportation, bars, cafes and fine dining.
Formbay will provide flexible working hours, a generous remuneration package and the opportunity to work on a world-first software solution are what we can offer you. Free, twice-weekly gym sessions and really, really good coffee are also available.
No hiring/recruitment agencies need apply.",5.0,"Formbay
5.0",Sydney,-1,1 to 50 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is an experienced and qualified Data Engineer to join our IT team based in Birtinya.
Key Responsibilities:
Create and maintain data pipelines and or ETL scripts
Create and maintain data integration including API and Batch interfaces
Performed detailed data analysis
Create and maintain corporate data models
Create and maintain data visualization using Qlik.Sense , PowerBI or Simliar Toolset
Experience in defining, building and maintaining data virtualization and/or star schema data warehouses
Maintain, tune and optimise database, integration and visualisation toolsets
ABOUT YOU:
To succeed in this role, you’ll need to bring the following experience and skills:
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Excellent communication skills both oral and written, with an ability to bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking
Experience with data analysis and modelling will be beneficial

How to Apply
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kawana Waters,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Graduate Data Science / Engineer,-1,"The NRMA is an organisation looking to the future, and right now, we are on the lookout for people who can help us reach our goal: to continue to shape the way Australians move, for the next 100 years and beyond. www.mynrma.com.au.
Everyone new to the team, along with our current staff, will temporarily work from home until it is safe to return to our offices. All interviewing and on boarding will be done virtually due to COVID-19.


Your opportunity
As Graduate Data Scientist or Engineer you will be part of the Data Engineering team delivering cloud data transition program for business initiatives and supporting the entire data platform build.
Your key responsibilities will be to:
Implementing Concepts of Data Warehousing, Data Mart creations within Cloud
Use of SQL for data analysis and insights
Building AI/Machine Learning prototype for implementing and supporting existing algorithms
Data Analytical reports build, using different tool sets


Requirements for Success:
Relevant Degree - Computer Science, Computer Engineering, Software Engineering, Data Science
Excellent SQL skills and demonstrated working knowledge in Python
Demonstrated understanding in data structure and algorithms.
Knowledge and concept of data warehousing methodologies
Any reporting tools experience Tableau or Oracle Analytics Cloud, Looker is desirable
Exposure to Google/AWS/Azure/Oracle any cloud based platforms is desirable
Good communication and interpersonal skills

If you have the required skills and the passion to join our high performing team, please apply today.

Employee Benefits
To ensure our employees feel valued, empowered and celebrated we provide a range of employee benefits including:
50% discount on all NRMA insurances
Free Roadside Assistance
12 weeks paid primary and 4 weeks paid secondary parental leave
Free NRMA Blue Membership
At the NRMA Group, we are People Moving People and diversity and inclusion are part of our DNA. Together, we continue to build an inclusive culture that encourages, supports and celebrates the diverse voices of our employees. It fuels our innovation, promotes flexible ways of working and connects us closer to our members and the communities we serve.",2.5,"NRMA Motoring & Services
2.5",Sydney,-1,501 to 1000 Employees,-1,Nonprofit Organization,Casual Restaurants,"Restaurants, Bars & Food Services",$500 million to $1 billion (USD),-1
Data Centre Engineer,-1,"We are a leading world group that provides low-carbon energy and services. To tackle the climate emergency facing us all, our aim is to become the world leader in the zero-carbon energy transition ""as a service"" for our clients – particular for companies and regional authorities. We use our expertise in our key business areas (renewables, gas, services) to provide competitive and bespoke solutions.
The Data Centre Engineer will be employed as part of a 24/7 ongoing shift to coordinate and monitor third party service providers, maintain the data centre facilities and infrastructure plans, coordinate the implementation of customer requests within the data centre and monitor systems, all in accordance with the Contract KPIs and SLAs.
Coordinate and monitor third party service providers for regular maintenance & testing, service faults & call outs, ensuring works are performed in accordance with Contract SLAs
Monitor and maintain the data centre facilities and infrastructure plans and documentation, including electrical, mechanical, hydraulics, fire and BMS/EMS systems
Coordinate the implementation of internal and external customer requests within the data centre
Perform scheduled plant checks and minor maintenance works
Ensure all Work Order requests are raised and closed in a timely manner
Conduct inductions for staff, vendors and contractors
Ensure all work permits for vendor works are raised and closed
Perform inventory checks on all equipment and critical spares

Qualifications
The selected candidate must be able to demonstrate:
Electrical or HVAC background, or Graduate Electrical or Mechanical Engineer
Passionate about quality work and career minded looking for a new challenge
Can commit to a day and night shift roster (2 days of day shift, then 2 days of night shift, 4 days off)
Ideally able to commence asap
As part of carrying out the duties of this role, it is mandatory to hold Australian Citizenship.

If you are interested and meet the selection criteria apply with an up-to-date resume via the apply instructions on this website.

ENGIE Services is an EEO employer, where all applicants are treated with fairness and respect and have equal access to the opportunities available.

We will not be engaging in the services of a recruitment agency to fill this vacancy and therefore request all interested candidates apply directly to this advertisement.

Job
: Maintenance
Primary Location
: Oceania-Australia-New South Wales-Erskine Park
Organization
: ENGIE Services Australia and New Zealand
Schedule
: Full-time
Nature of Responsibility
: Senior operational / administrative role
Job Posting
: Sep 11, 2020, 6:29:59 AM",3.7,"ENGIE Services Australia & New Zealand
3.7",Sydney,-1,5001 to 10000 Employees,1995,Company - Public,Energy,"Oil, Gas, Energy & Utilities",$2 to $5 billion (USD),-1
Senior Data Engineer,-1,"Senior Data Engineer, Temporary, SYDNEY - McKell

Job Title: Senior Data Engineer

Salary: SNSW Grade 9/10 - The package includes base salary range of $111,806 to $134,667, plus employer's contribution to superannuation and annual leave loading.

Location: Head Office – Haymarket

Employment Status: Temporary through till 30th June 2021


About Service NSW:

Service NSW is making it easier for people and businesses across NSW to access government services. The role designs, builds and analyses complex data from multiple sources to identify revenue, process and business improvement opportunities; providing new information and insights to the business to inform planning, continuous improvement and performance.

About the Role

We are currently seeking to appoint a Senior Data Engineer to deliver expert advice and services in the design of a Single View of Customer and data-related services to support the achievement of business outcomes and strategic goals. We support flexible working practices with staff working remotely during this time.

In this role you will:

Design, build and support a modern data platform based in AWS and vendor technologies.
Provide expertise on data modelling for Graph data model and Customer Data Platform (CDP).
Create data pipelines, load, transformation and reporting workloads in AWS.
Work with the latest data engineering technologies like Apache Kafka, AWS Kinesis, AWS Neptune, AWS Glue and AWS Athena.
Contribute to the design and decision-making of the right tool or platform for the job according to requirements.
Provide expert advice and guidance on data quality and data engineering best practices.
Support a “bigger than you can imagine” scale of data in production environments.
Design, develop and support a metrics-driven reporting solution and a meaningful business intelligence platform.
Document the solution design and support procedures of solutions.
Produce reports, visualisations and recommendations to answer complex business problems that are presented in the most appropriate format to ensure clarity for target audience.
Analyse and define new process improvement opportunities to support continuous improvement and business outcomes; providing advice to stakeholders, on ways to improve the efficiency and reliability of data products and services.
Be very responsive to the information needs of the business by corresponding to customers in a timely manner and provide support/solutions to issues raised.
Troubleshoot and perform root cause analysis on production issues. Identify and implement long term solutions to problems. Perform scheduled maintenance, release deployment and production support activities after business hours, from time to time.
Liaise with internal and external customers to discuss and gather requirements, solutions etc. and maintain a good working relationship with the stakeholders.


Skills and Experience Required:

Solid experience with workflow technologies designing and building data pipelines, data models and data stores.
Experience working within and an understanding of Amazon AWS ecosystem, including security and performance tuning.
Hands on experience working with different types of databases, with focus on Graph and NoSQL databases.
Experience with data streaming required. Having used Kafka and related technologies is an added advantage.
Sound knowledge and experience working with batch processing, data extraction and API integration.
Hands on experience with at least one programming language: Java, Python or scripting.
Demonstrated experience working in an Agile based, fast paced, complex environment within cross-functional teams.
Experience developing systematised insights, data analytics and reporting solutions is an added advantage.
Experience with interactive visualisation of data insights is an added advantage.


Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Salary Grade 9/10, with the base salary for this role starting at 111,806 base plus superannuation

Closing Date: 6th November at 9:59am - applications will be reviewed on a rolling basis, applications may close early or extend

Please apply online, direct applications submitted via email will not be considered.

The Department of Customer Service is proud to be an EEO Employer who are fully focused on equality and believe deeply in diversity of all identities making us different and a true reflection of our NSW customers. As an inclusive workplace, we support various employee resource groups, practice flexible work and workplace adjustment.

If you do require an adjustment during the recruitment process, please notify us on your application form.",3.2,"Service NSW
3.2",Sydney,-1,501 to 1000 Employees,2012,Government,State & Regional Agencies,Government,Unknown / Non-Applicable,-1
Data Engineer - Entry / Mid Level,-1,"Work with a great team on interesting projects customers
Gain more experience in AWS, Data, DevOps cloud operations
Got a working knowledge of AWS? We will teach you the cool stuff!

Itoc is seeking an up and coming Data Engineer to join our growing Data Team in Sydney.

This is an exciting role working with databases, data lakes, data warehouses, data transformation (Python SQL) and enabling AI/ML.

You will be implementing foundational, robust and production ready data platforms to enable business data-discovery, self-service, AI/ML functions across a range of client types and industries, allowing them to do more with their data.

You'll be responsible for:

Deploying data repositories such as lakes and warehouses.
Contribute to our growing portfolio of data solutions.
Ongoing optimisation and management of data platforms.
Development of transformational logic for data pipelines
Data evangelism. We want to show our clients how to follow the best practices for data.

Desired Skills and Experience

To take up the challenge, you will have a depth of skills and experience including:

1-2+ yrs of focused data experience working with SQL and/or NoSQL solutions
A solid education in Software Engineering or equivalent industry experience.
Anything Data focused preferred.
Ability to analyse business scenarios and associated data landscape to derive potential opportunities.
Strong foundation in Python and SQL
Working knowledge of APIs
Principle knowledge of the different relational database platforms and modern data storage techniques
Knowledge of the different aspects of data environments
Collect, store, process, verify consume
Experience with version management systems (such as GIT)
Working knowledge of AWS or another cloud platform - we will teach you the cool stuff.
Great communication skills, an ability to work closely with customers, developers and engineers and the confidence to present ideas in open forums.
Relevant tertiary qualifications and/or industry certifications.
Great communication skills, an ability to work closely with clients, developers and engineers and the confidence to present ideas in open forums.

While not required, a background in consulting and professional services is highly desirable.

Itoc Description

This is an exciting and challenging career opportunity to join the growing Sydney-based Data Team of a leading cloud solution provider where you will be given support to reach your long term career goals. You will be part of a team of cloud experts and will work in an environment of continuous improvement and learning delivering innovative cloud solutions across SaaS, online business and enterprise business.

On offer is a chance to join a team with a great working environment, in an organisation that values its employees and sees the value in ensuring they are engaged. Our team are clearly passionate about what they do, that's why we won the following awards:

Customer Obsession Partner of the Year 2015: ANZ Region
Customer Obsession Leadership Partner 2015: re:Invent

As an employer of choice Itoc offers competitive remuneration, training and development programs and a great working environment. We value a healthy work life balance.

The Perks

MacBook or Dell
Continuous internal learning that will provide training and career development opportunities
Working with a collaborative, social team and leveling-up your skills faster than you will anywhere else.
Quarterly social events

Itoc

Culture and smarts are important to us. Bring your secret sauce. This is no ordinary environment, you will work along some of the Cloud’s best. All engineers at Itoc must gain at least five AWS certifications. We work hard but we have fun.

Please note you must have full working rights in Australia and be available on-shore for face to face interviews.

No recruiters please.",4.0,"Itoc
4.0",Sydney,-1,1 to 50 Employees,2013,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Date: 01-Oct-2020

Location:
Melbourne, VIC, AU

Department:Description:
Technology discounts - from Apple HP Lenovo to Windows
Flexible work arrangements - work in a way that suits you best
Salary packaging - to suit your personal and financial circumstances

Do you want to work for one of the fastest growing data teams in Australia? Do you want to work on multiple data platforms and provide new solution offerings by leveraging cloud and big data technologies?

About the team

Big data information and analytics. Three words that spark apprehension in most businesses. But our team of experts are constantly curious and excited about combining our wonderful array of technological expertise to transform data into our clients most valuable assets making their work smarter. Our data consultants are supported with resources training and tools they need to excel at their work but also the freedom and power to create their own paths forward to make a difference.

As a Senior Consultant in Big Data you will work closely with the team and stakeholders to build and deliver a Cloud based vision for a next generation Big Data analytics platform with strong focus on data quality data security and deliver the systems that process huge volumes of data.

What will you typical day look like?

You will play a pivotal role in - Designing and producing high performing and stable applications to perform complex processing of massive volumes of data in a new cloud based architecture; Building real-time data processing applications which are integrated with business systems to enable value from analytic models to drive rapid decision making; Contributing to system architecture design for a data platform (including cloud-based structures both on and off premises data warehouse components and data lakes); this could cover a range of technologies various countries/locations and lines of business; Support data strategy or technology strategy definition programs including technology stack definition and target operating model requirements

Enough about us lets talk about you:
You are someone with:
Use of traditional data analytics tools and techniques (e.g. MSSQL Oracle MySQL) and ETL software (e.g. SSIS Informatica CloverETL)
Working in large scale cloud data solutions using platforms such as AWS or Azure or GCP will be a bonus.
Experience in scripting or programming (e.g. Python Java Scala C#)
Excellent verbal and written communication skills to adapt to technical and non-technical audiences.
Educated to degree level (or have equivalent experience)
Why Deloitte?

At Deloitte we create positively differentiated work experiences that enable our people to feel valued and achieve their full potential. We value difference and embrace people with diverse backgrounds and thinking styles. Knowing that people work best in different ways we are happy to discuss alternative arrangements if the working pattern you are looking for is not specifically indicated.",3.8,"Deloitte
3.8",Melbourne,-1,10000+ Employees,1850,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Engineer,-1,"Opportunity to grow the team
Period of growth
Intuitive app
S2M are working with a FinTech who have created a unique financial product to help thousands of people better manage their finance, and is currently scaling the company to the next level!

They are looking for a Data Engineer to join, and looking for someone who wants to be hands on, with opportunity to grow the team in future.

Role:

Looking for people with strong AWS experience. You will need passion for data and a cloud, through which you will help a rapidly scaling Australian FinTech establish their data infrastructure from the ground up.
5+ years’ experience as a data engineer within the data and analytics domain
A python 3.X aficionado who is very comfortable creating and orchestrating AWS data pipelines with nothing but code
Strong project delivery toolset experience in open source data integration tools
Experience with processing large volumes of complex data including visualisation and insights generation
Ability to define and develop data integration patterns and pipelines
Ability to assess complexity of data (volume, structure, relationship etc.)
Hands on experience working with different databases (RDBMS, NoSQL, Blob storage etc)
Hands on technical expertise setting up DevOps automation
Hands on experience working technologies/platform e.g. AWS, Dockers, Containers
Experience building data profiling and data cleansing frameworks
Technical reconciliation and reporting
Knowledge and experience in end-to-end project delivery, either traditional SDLC or agile delivery methodologies (or hybrid approaches)
Exceptional communication, documentation and presentation skills
If this sounds like you, get in touch today - kate.gabb@s2m.com.au
3167410agsdf",3.1,"S2M
3.1",Sydney,-1,Unknown,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Analysts,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is seeking experienced and qualified Data Analysts to join our IT team based in our corporate office in Birtinya (Sunshine Coast) or at our meat processing facility in Kilcoy.
Key Responsibilities:
A mixture of data analysis and commercial skills to source, blend and analyse data to gain insight and answer key commercial questions
Working with strategic leaders to define and model Key Performance Indicators, and assist in building forecasting models
Working closely with data engineers and BI developers to specify data pipelines and report visualisation
Drive the creation and implementation of data quality business rule including data definition, governance and quality assurance
About You:
To succeed in this role, you’ll need to bring the following experience and skills:
Proven ability to derive insight and knowledge from data using commercial expertise is a strong requirement
Strong SQL and Excel skills are essential, along with strong data analysis and commercial insights
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Effective people communicator - engage with stakeholders on reporting needs, interpret requirements into visual solutions and train/deliver the outputs to the stakeholders getting signoff of acceptance
Bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking

How to Apply:
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kilcoy,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Network Data Engineer,-1,"Min 6+ years of experience in the relevant technologies
Australian Driving License for visiting remote locations / Data Centre for day to day technical work.
Managing Network devices (switches, routers, firewalls, load balancer, and wireless technology)
Performing MACD activities for all network devices.
Supporting BAU operation activities.
Proficient in performing in-depth details of technical troubleshooting, cause and provide recommendation to the client for incidents causing extended network outage to client’s critical locations.
Provide exceptional network services in terms of network support, break-fix, design and consulting, new projects, implementation.
Configure, administer, and document firewall infrastructure.
Manage the firewall deployment, rules migrations, and firewall administration.
Supporting Cloud Migration Activities from traditional to AWS/Azure.
Setting up VPN tunnel with Cloud and 3rd Party network devices.
Integrating and upgrading existing ISP bandwidth with support from ISP Vendor.
Setting up VPN profiles for Users.
Installing hot fix and patches to mitigate the security devices from attacks and bugs.
Reviewing and fine tuning the firewall rules and NAT rules.
Documentation and change control.
Mentoring, Motivating and Guiding support teams
Technical skills:
o LAN
o Wireless
o WAN
o MPLS
o Routing protocols (OSPF,BGP)
o DMVPN
o Azure cloud Networking
o Network Security
Fortigate Manager / Analyzer / Firewall
Cisco ASA
Firepower FTD
Cisco Any connect
Site to Site VPN
F5 Load Balancing and Scripting iRule
Job Types: Full-time, Contract
Schedule:
8 hour shift
Experience:
Scripting: 5 years (Required)
Data Network: 5 years (Required)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Required)",3.6,"Total IT Global
3.6",Sydney,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Engineer - Processing & Analysis,-1,"Job Description:
Design,build and maintain the ingestion system to support various types of data(e.g. User behavior, RDS, NoSQL db and others) to be ingested to the data warehouse more timely and accurately
Translate data requirements into scalable technical data service with low latency and high concurrency
Design,build and maintain the batch or real time data pipeline in production using Hadoop big data technology
Analyze and improve efficiency, scalability, and stability of the system
Define and manage SLA,Data quality for all data sets in allocated areas of ownership
Requirements:
Minimum B.S. degree in Computer Science or a related technical field
2+ years of working experience in programming languages,such as Java,Scala,Python
Familiar with Hadoop, Spark and Flink data processing, experience of TB data processing experience is a plus
Familiar designing and operating of a robust distributed system is a plus
Understand data mining or machine learning
Excited to work intimately with data
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"SYNOPSIS:
Lead Data Engineer
Applications close Sunday 8 November 2020
Ongoing
Contact name: Shyni Sasikala
Phone: (02) 6249 9048
Email: Shyni.Sasikala@ga.gov.au

The Data Policy and Informatics section within the Digital Science and Information branch creates, implements, and promotes policies, platforms and tools that improve and support the quality, discoverability, accessibility, and general usability of Geoscience Australia’s science data products. The section consults with internal and external research, government and industry partners to establish collaborative data frameworks, architectures and models within Geoscience Australia (GA) and across broader national and international communities of practice. The section innovates, builds and maintains tools, systems, processes and governance that enable digital data management, cataloguing and open data delivery.
GA makes accessible a wide range of geoscientific and spatial data to a wide variety of stakeholders in multiple formats, and in recent years GA's data volumes have grown exponentially. GA is focussed on making its data and metadata assets accessible so that they can be used in machine to machine interactions for data analytics and other applications in environments that range from High Performance Computing (HPC), through high-end cloud servers, to mobile devices.
We currently have two opportunities for Lead Data Engineers in the Informatics team. The Lead Data Engineer is responsible for innovating and exploring new technologies that will advance GA’s science goals and maximise the uptake and use of GA’s science data. The Lead Data Engineer reports to the team’s Assistant Director but also works closely with other developers, data scientists and engineers within the Digital Science and Innovation (DiSI) branch, as well as diverse stakeholders both within and external to GA.",3.9,"Geoscience Australia
3.9",Canberra,-1,501 to 1000 Employees,2001,Government,Federal Agencies,Government,$100 to $500 million (USD),-1
Data Engineer,-1,"The Seven Network is part of Seven West Media, one of Australia’s most prominent media companies, with a market leading presence in content across broadcast television, online and in print. Comprising some of Australia’s most renowned media brands, SWM includes not just Seven Network and its affiliate channels 7two, 7mate, 7flix and BVOD offering 7plus, but also 7NEWS.com.au, The West Australian, The Sunday Times and more.
At Seven we are here to bring all Australians closer to the moments that move us - we’re first on the scene, with our finger on the pulse, on demand, in the moment. Together, we’re responsible for creating and sustaining authentic Australian engagement.
A new and exciting opportunity has opened for a Data Engineer to join the Audience Intelligence team. Based in Sydney and reporting to the Head of Data Enablement, you’ll be responsible for:
Implementation of end to end data solutions to support Data Strategy for the SWM group.
Work closely with the Data Solution Designers to develop and maintain scalable data pipelines and build out new file and API based integrations to address requirements from the various business stakeholders.
Collaborates with engineering, analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organisation.
Work on Data Preparation for analytics and data scientist team members and assist them from an engineering perspective in building and optimising the models including building the automation of the end to end workflows
Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.
Perform data analysis required to troubleshoot data related issues and assist in the resolution of production data issues.
Work effectively with vendors for successful delivery of projects and acceptance of the solution
Work on Delivery projects using Agile Software Development methodologies
We are looking for someone who has:
Bachelor's degree in computer science, computer engineering or other technical discipline is essential
Proven experience working as a digital analytics specialist
Extensive experience with digital analytics implementation (e.g. Google Analytics, Snowplow, Adobe Analytics) and BI processes and visualisation platforms
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience in ETL and building and optimizing ‘big data’ pipelines and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Experience with big data tools: Hadoop, Spark, etc., AWS cloud services: EC2, S3, Lambda and familiar with version control systems: Git
Strong coding skills with knowledge of Unix/Linux and scripting languages such as Unix Shell scripting, Python desirable
Experience supporting and working with cross-functional teams in a fast-paced environment.
Ability to multi-task and problem solve with changing demands and priorities
Ability to work under pressure to meet deadlines and detail oriented
Your success is our success: we will provide you with opportunities for you to keep learning and growing, enabling you to challenge and develop yourself. In return, we offer a benefits program that has something in it for everyone.
Seven West Media is an equal opportunity employer and we are committed to creating a diverse and inclusive workplace.
Recruitment Agencies: Seven West Media does not accept any unsolicited agency resumes and will not be responsible for any fees related to unsolicited resumes.
Advertised: 19 Oct 2020 12:00 AM AUS Eastern Daylight Time
Applications close:

Back to search results",2.5,"Seven West Media
2.5",Sydney,-1,5001 to 10000 Employees,1956,Company - Public,TV Broadcast & Cable Networks,Media,Unknown / Non-Applicable,-1
BICON Rules Engineer,-1,"APS 5 - $73,299 - $80,410 per annum plus superannuation
Biosecurity Plant Division
Canberra, ACT
Play an active role in managing biosecurity risk to Australia
Work in a motivated and professional team with a wide range of skills and backgrounds
Full training provided

Who we are
The BICON Content Development Team maintains and improves the Biosecurity Import CONditions database (BICON) content to allow external clients to understand and comply with their biosecurity obligations and internal clients to effectively manage biosecurity risk and regulate imports. We work collaboratively with internal clients to comprehend and implement their BICON content requirements and optimise the use of BICON to publish clear import requirements and onshore management support procedures to effectively manage biosecurity risk.

The Jobs
Key duties of these positions include:

working with business content (import and permit conditions) and import programs to understand and construct decision tree structures in the BICON database, in accordance with system design and authoring conventions
executing changes to import and permit conditions in alignment with service standards while complying with system rules and authoring conventions
providing technical advice through various formats on the most appropriate means of authoring BICON content to achieve import program and stakeholder objectives
using workflow management tools to maintain detailed records of changes to import conditions and key decisions
performing administrative tasks including system reporting, data analysis and scoping tasks for the BICON content change work program
contributing to the development and maintenance of instructional material, authoring conventions and courseware
clearly documenting and reporting system issues
developing and maintaining effective working relationships with internal and external stakeholders.

What we are looking for
Knowledge and experience
Experience working with complex IT systems.
Experience working collaboratively and as part of a team.
Knowledge of the role of biosecurity is preferred but not essential.

For additional information, please read the Job Description below.
Candidate Information Package docx Opens in new window",3.9,"Department of Agriculture & Water Resources
3.9",Australia,-1,5001 to 10000 Employees,-1,Government,Federal Agencies,Government,$500 million to $1 billion (USD),-1
Cloud Data Engineer,-1,"Job no: 509605
Work type: Permanent Full Time
Location: Melbourne, Canberra, Sydney
Do you embrace digital disruption?
Do you love solving complex problems, designing sophisticated solutions and building innovative technology?
Do you believe in creating powerful actionable insights from Data and Analytics?
Do you want to work in a diverse and flexible working environment?
KPMG is one of the most trusted and respected global professional services firms. Through depth of expertise, clarity of insight and strength of purpose we help our clients solve complex challenges, steer change, strengthen, transition and grow. We are a team based practice and this extends to our clients whom we work and collaborate with, in solving complex problems. Together, we design, innovate and implement, providing enduring advice that support our clients and the services they deliver. Our clients vary in size and come from a diverse range of sectors – all sharing in a common goal: to embrace change and deliver services that make Australia a better place. We are looking for talented individuals who would like to join us on the journey.
KPMG’s Digital Delta Team
We re-imagine and re-invent organisations to become world class digital enterprises using advanced technologies, data and human insights. We help organisations to embrace Digital Strategy, Artificial Intelligence (AI) & Cognitive, the Internet of Things (IoT), Data, Analytics & Modelling, Mobile App & Web, and User Experience (UX) & User Interface (UI) and more.
We work with clients to:
Formulate strategies that re-imagine organisations
Harness innovation from the 4th industrial revolution
Actioning insights from trusted data to consistently and quickly make clear decisions
Build adaptive organisations
Thrive as a connected enterprise – front, middle and back office
This is how you’ll contribute:
We are looking for ambitious Data Engineers who are passionate about helping clients define bold ambitions and deliver on them. Joining our team will take you on a journey of personal and technical growth and provide the opportunity to inspire confidence and empower change.
As a Data Engineer you are the designer, builder and manager of the information or ""big data"" infrastructure, preparing data for analytical or operational use. You will design, construct, test and maintain a data pipeline to pull together information from different source systems; integrating, consolidating and cleansing data; and structure it for use in individual analytics applications.
The KPMG Difference
Our people are focused on creating a diverse and dynamic environment that embraces and values differences. We value the variety of unique experiences, qualities and characteristics our people possess and we share and learn from each other.
We are proud to be consistently recognised as an employer of choice for women, and for our achievements in LGBT+ workplace inclusion.
Our commitment to ‘Flexibility’ allows our people to manage the changing demands of work, personal or family life. Explore the links below to hear our people share their experience @ KPMG:
Flexibility empowers wellbeing
Flexibility enables contribution to the community
Flexibility inspires technology & innovation
Flexibility supports family

Make KPMG the clear choice for your career and be Extraordinary!

Advertised: 09 Sep 2020 AUS Eastern Standard Time
Applications close:",3.8,"KPMG
3.8",Sydney,-1,10000+ Employees,1987,Subsidiary or Business Segment,Accounting,Accounting & Legal,$2 to $5 billion (USD),-1
Computer Network and Systems Engineer,-1,"Duties Include but are not limited to:
Tasks Include:
analysing, developing, interpreting and evaluating complex system design and architecture specifications, data models and diagrams in the development, configuration and integration of computer systems
researching, analysing, evaluating and monitoring network infrastructure to ensure networks are configured to operate at optimal performance
assessing and recommending improvements to network operations and integrated hardware, software, communications and operating systems
providing specialist skills in supporting and troubleshooting network problems and emergencies
installing, configuring, testing, maintaining and administering new and upgraded networks, software database applications, servers and workstations
providing network programming in support of specific business needs and requirements
preparing and maintaining procedures and documentation for network inventory, and recording diagnosis and resolution of network faults, enhancements and modifications to networks, and maintenance instructions
monitoring network traffic, and activity, capacity and usage to ensure continued integrity and optimal network performance
Skills and Experience Required:
Must have experience working in a Managed Service environment
Demonstrated experience in IT Networks and Data Centres
Understanding of systems and architectures to meet client needs
Experience in Help Desk including break / fix
Effective and timely documentation
Effective Task Management Skills
Be solution and outcome focused and willing to learn new technologies
Excellent communication skills with staff, clients and partners
Time management, ability to prioritise and deliver to schedule
Experience with N-Able and Connectwise desired
Open Cabling license desired
Job Types: Full-time, Permanent
Salary: $30.00 per hour
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,Trans-plant training,Canberra,-1,-1,-1,-1,-1,-1,-1,-1
Software Engineer (Data),-1,"If you are looking for an opportunity to make a real impact with smart people who are genuinely doing things differently then you've come to the right place! We're growing our data engineering capabilities and are looking for awesome data engineers to join our team.
With our diverse range of clients and projects, no day will look the same - but here's a great snapshot of what you'll be doing:
Work with some of the best Data Scientists and Engineers to deliver production-grade AI and Machine Learning systems as we deliver client projects from inception to production.
Consulting with our clients and working with them to build modern data systems using the 'best of' technologies and principles.
Advising clients on data strategy, architecture and technology.
Applying best software engineering practices in coding, monitoring and alerting, using CI/CD, TDD and cloud architectures.
Working over a wide range of big data tools and environments: not limited to; Apache Kafka, Spark, Python, Scala, Hive, Airflow, AWS EMR & Glue, GCP Dataproc & Dataflow, BigQuery, Snowflake, Redshift.
Who are we?
Glad you asked! We are Eliiza. Data science. Engineered for scale.
We are a passionate team of data scientists and engineers who apply data science and machine learning to solve real-world problems. Our mission is to create a bright future for Australian businesses and society in a world increasingly influenced by intelligent technologies.
We've created a culture that values diversity where people can truly be themselves! We care a lot about growing the Australian AI community in a positive direction, and we're doing several things to try and achieve that:
We provide opportunities for underrepresented groups to work in AI through our associate and intern programmes
We organise and participate in a range of community events, reading groups and meetups
We produce the AI Australia podcast
We blog about topics we care about
We stream brown bag sessions to the broader community
We're also part of Mantel Group's 'house of brands' which means it's not just the Eliiza team you'll work with, learn from and see at social events - there's another 230 of us across DigIO, Kasna & CMD Solutions!
So you're ready for something new?
We're keen to know more about you! Our team is made up of a range of people, with different experience across a huge range of data driven skill sets.
We'd love to hear from you if you have experience with:
one (or more) core language(s), ideally Scala, Python or Java
one (or more) cloud platforms, AWS, GCP, Azure
ETL/ELT concepts and technologies e.g. Data partitioning, Hive, Spark
streaming data concepts and technologies, ideally Kafka (Kinesis, Beam or Pubsub will do)
We'd be over the moon if you:
Experience with distributed/columnar databases (e.g. Snowflake, Big query, Redshift).
Experience with any of a variety of databases e.g. RDMS, NoSql, Columar, Distributed, Time series, Graph.
Knowledge of job orchestration and scheduling. Any experience with Airflow, Luigi or Oozie.
Experience with containers and container orchestration (Docker, Docker Compose or Kubernetes).
However, we value a diversity of skill-sets, and don't necessarily require that you're skilled with all of the above. If you feel you don't fit all the experience/skills listed above we still encourage you to apply or get in touch.
What's on offer if you join us?
We make sure you're always one step ahead by investing your learning and development, every year. We build our own training where it doesn't exist yet.
We hire smart people and get out of their way. By focusing on our five principles and not getting caught up in red tape, we trust you to get the job done.
You'll get all the tools you need - a new iPhone or Google phone, a new Macbook Pro or Dell, and a lot of branded swag!
But hold on, you mentioned a house of brands?
We certainly did! Mantel Group is an Australian-owned, 'house of brands' company with four technology businesses (Eliiza being one of them!) across Melbourne and Sydney. We're building a group of companies with open borders so we can support you to take on new skills without leaving an awesome team - we understand you won't have one job for life!
We may only be just two years old but Mantel Group has already been recognised #9 in the 2020 Best Places to Work in Australia and #4 in the AFR's 2020 fastest growing new companies.
Keen to chat?
Click ""Apply"" to share your details with our talent team, and we'll be in touch.
In the meantime, check out 'how we hire' to find out what's in store if you're successful and get to know us better by visiting our website and following Eliiza on LinkedIn.",-1,Eliiza,Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Infrastructure Engineer,-1,"Job Description:
Design and grow the Shopee data platform to support a variety of big data applications using open-source technologies including Kafka, Hadoop, Presto, HBase, Spark, Hive, Druid, and our own creations. Some examples include a real-time data streaming platform, a unified query platform, a cluster management system, and a machine learning platform
Dig into the source code of some open-source big data system to get the whole control and familiar with the details, configurations, designs and source code. Develop and maintain the internal release of big data systems and components as the business requirements.
Keep close and overall monitoring for all the deployments of the systems, maintain the system’s stability, improve the performance, discover the performance bottlenecks, tracking and troubleshooting, cost optimisation.
Requirements:
B. Sci. / Ms / PhD in Computer Science or a related technical field
Familiar with at least one of these languages: Java, Scala, Python, Bash under Linux / Unix. Scala is a plus
Familiar with the use and compute logical of SQL
Knowledge about the Big Data Infrastructure system technology like Distributed File System, Distributed Computing, Distributed Database will be a plus
Hands-on experiences Hadoop, Spark, Kafka, and/or Presto will be a plus
Love to use and develop open-source technologies
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"Work on an award-winning, international technology!
Endless career opportunities
An innovative, friendly team of 300+
This role will be focused on the development of our existing ClaimLogik line of products as well as working on our new cloud-first, modern suite of applications.

Intelligent Thought, our technology business is scaling and shipping our software globally. Already profitable, part of a much larger group business, with investors such as Macquarie Capital and Envest – we are all set to deliver textbook disruption to the Insurance Industry. The growth of the platform, of our customer base, and the increasing industry demand have led to the need for this role to help the team scale.

Our Philosophy
Give each employee a sense of purpose and an environment for them to connect the importance of their role to delivering a service that matters to our customers.
Challenge the ‘why’ of traditional claims processes.
Keep it simple – do only what brings value and what matters to the customer
Enable employee decisions, empower our people
Responsibilities:
Create, extend and maintain ETL pipelines to form our data lake, data warehouse and analytics platform (currently using the Microsoft Azure set of tools and service)
Help define the optimal data pipeline architecture
Influence the tool selection, platform selection, data architecture and strategy which will transform the business to be truly data-driven
Understand, analyse and size user requirements
Work with different parts of the business to provide them with the insights they need to deliver the best results
Skills & experience:
Degree or qualification in computer science or related
Advanced knowledge of relational database, including query authoring and query optimisation (MS SQL Server and PostgreSQL).
Experience building and optimising ETL pipelines
Experience designing complex data models
Experience working with cloud platforms (Azure or AWS)
Efficient time management and organisational skills
High attention to detail and accuracy
Effective communication skills to build strong working relationships; both written and verbal
Proactive and results-driven
Why Claim Central?
Claim Central Consolidated is a global insurance industry leader across, claims management, insurance technology and data and analytics. Currently operating in the United States, Australia, South Africa, Italy and New Zealand, we have pioneered digitally connected claims management services across the globe. Claim Central is a disruptor and thought leader in the industry and we were recognised as the Australian Financial Review’s 8th Most Innovative Company in Australia in 2016. This business is in a period of unprecedented growth, transitioning our technology and services into multiple geographies at a rapid pace. Our unique culture is based on teamwork, collaboration, trust, respect and performance. We also offer many benefits apart from our exceptional team culture; including flexible work arrangements, and continued professional development.

Be a part of this journey in a career-defining role.",-1,Claim Central,Matraville,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer - AI/ML,-1,"Our client provides services to a major industry across the country. The business is still early in it's days of technology development and the environment is greenfields in nature (no pun intended), effectively working like a start-up.

Their data and analytics team have worked and built leading and bleeding-edge technologies in this space and what they have created so far may be game-changing. From a machine learning perspective, the progress they have made to the business has already seen proven success in changing the future of an industry that will have positive consequences for all those involved.

You will have previously worked in a technical capacity in the data and analytics space and have experience working with an organisation where machine learning has been implemented, not just a concept that the business talks about having or the technology team would love to have. The commercial experience you will have had in the ML field will be proven examples of where you have affected the way a business or industry used to perform, to the changes that have come about from this.

Technically, you will have extensive experience in the Microsoft space - Power BI, Azure etc and you will have previously mentored and coached junior members of the teams you have been part of.

This is a rare opportunity in Brisbane where the business has truly embraced and funded projects across the ML space and would be a great chance for those in the Data Development/Data Engineering field, who are looking to move into a Data Scientist role in the future.

Please send your application through if you would like to know more.",4.0,"Emanate Technology
4.0",Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Solution designer/ ETL Engineer & Data Modeller,-1,"We are looking for a Qualified and Experienced Solution Designer to join our client for a period of 6 months with a view to extend.
You will work closely with team members and your contribution will range across gathering and analyzing information, developing and documenting improved processes and work instructions and experienced DWH Lead with skills in requirement analysis, solution designing, developing, testing and supporting ETL solutions.
A hands-on solution designer, data modeler and ETL developer for Data Warehousing and ETL application transformation projects using Informatica PowerCenter.
Knowledge on AWS, S3, Redshift, Informatica BDM, and related technologies.
Experience working with IPython, PySparks, AuCuMo, Airflow, Jenkins, Github, Athena, JIRA, Rally, Spectrum, Glue, Flyway.
Good exposure on Oracle PL/SQL, aware of DBA activities, writing and performance tuning of complex SQL queries.
Contract length: 6 months
Job Types: Full-time, Contract
Salary: $650.00 – $800.00 per day
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,nducive,Melbourne,-1,-1,-1,-1,-1,-1,-1,-1
"Data Engineer, Wollongong NSW or Mount Waverley VIC",-1,"Company Description
BlueScope is a technically advanced supplier of steel and steel products in Australia. We are an inclusive organisation and every day we showcase our technology and expertise throughout the world.

Job Description
We are looking for two Data Engineers to join our IT team, based in Wollongong NSW or Mount Waverley VIC. Use your experience in analytics to unlock business value, enabling use of big data for insights and decision-making.
Reporting to the Data Product Owner for our Australian Steel Products (ASP) business, this position will support strategic goals related to data. This will see you:
Gather business and technical requirements with the view to deliver outcomes;
Develop and implement end-to-end data collection, consolidation, modelling and visualisation solutions;
Document metadata in a dictionary and catalogue;
Ensure consumers of such information understand its accuracy, timeliness, quality and sensitivity, so that it is used appropriately; and
Identify opportunities to enhance analytics.
What are the benefits?
Work in a supportive and collaborative team environment whilst we embark on a journey to transform the way our business uses data!
Our systems landscape is broad and diverse. You will be encouraged to think creatively to develop data solutions which solve real business problems.
Working in this role you will enjoy:
the chance to learn more about data science;
salaried remuneration with attractive superannuation options;
the opportunity to participate in a performance incentive scheme; and
access to further development and career opportunities with BlueScope.
Who are we looking for?
We welcome applications from professionals with experience in data analytics and/or programming. Supported by your knowledge of project delivery methods (e.g. Agile), you will demonstrate:
experience with data mining, wrangling, mapping and visualisation techniques (e.g. Azure Data Factory, Databricks and/or DevOps etc.);
well-developed ability in gathering business and technical requirements;
skills in developing and implementing collection, consolidation, modelling and visualisation solutions; and
a passion for sharing your knowledge and desire for ongoing professional development.

Qualifications

null

Additional Information
We're proud to have been named an Inclusive Employer for 2019–2020 by the Diversity Council of Australia. We believe that our people are our strength. Having a diverse and inclusive workplace enables us to improve our capability and ensure continued, sustainable success.
We know that workplace flexibility can mean something different to everyone. Under our B-Flex initiative all of our roles have some degree of flexibility. We encourage you to discuss your needs with us.
Applications close Sunday 25th October 2020.",3.3,"BlueScope
3.3",Wollongong,-1,201 to 500 Employees,-1,Company - Private,Construction,"Construction, Repair & Maintenance",$100 to $500 million (USD),-1
ETL Data Engineer,-1,"ETL Data Engineer

Join a team that’s changing how Australia lives, works, plays and grows
We want you to be the best version of you

Work with innovative teams and explore new technologies to help solve real-world problems.

A typical day as a Data Engineer

ETL / Big Data Engineering professionals will be responsible for guiding the full lifecycle of a Data solution, including:
Working in highly client-facing roles to contribute throughout the end-to-end delivery lifecycle of complex and large-scale digital solutions
Use case and business case development
Support existing and new applications utilizing in-depth technical and data knowledge. Troubleshooting complex issues and providing advisory services to improve the client’s data landscape
Help to streamline and simplify the clients’ complex data landscape by integrating different applications and data architectures
Implementation from requirements analysis, platform selection, digital architecture design, application design and development, testing, and deployment
Interstate travel may be required

Basic qualifications:
Bachelor’s degree
Experience across systems integration, information management, data management and architecture, and business analytics
Experience with being in a team focusing on large-scale, multi-release information centric projects
Experience with waterfall and agile delivery and run / application support functions
Part of a team working on End to end implementation of at least 1 big data project

Preferred Skills:
Hand on experience in Data warehousing using ETL tools such as DataStage, Autosys and TeraData
Hands on experience in ETL job development with multiple stages like sequential file, Transformer, Lookup, join, sort and Database stages.
Strong hand on skills in design, development and implementation of various data remediation, Data migration, data integration techniques.
Strong hand on data modelling experience.
Strong hands on experience in database performance tuning including complex query optimizations and physical database tuning using Teradata.
Understanding of architectural designs and strategy related to data migration, data cleansing, data quality and data consolidation.
Proven data analysis, requirement gathering and problem-solving skills
Exposure to Unix environment and shell scripting.
Experience in Banking and Financial services industry
Desirable: Knowledge of cloud computing infrastructure (e.g. Amazon Web Services EC2, Google Cloud, Microsoft Azure)
About Accenture

Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. We combine unmatched experience and specialized capabilities across more than 40 industries — powered by the world’s largest network of Advanced Technology and Intelligent Operations centers. With 513,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises. Visit us at www.accenture.com.

Accenture is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, marital, domestic or civil partnership status, sexual orientation, gender identity, or any other basis as protected by applicable law.

Vera Goga is the Recruiter managing this role. As the team experience high volumes of applications, we appreciate your patience to allow for a fair and timely process.",3.9,"Accenture
3.9",Sydney,-1,10000+ Employees,1989,Company - Public,Consulting,Business Services,$10+ billion (USD),-1
Student Engineer,-1,"The candidate will have the ability to:
Undertake onsite inspection to collect asset condition data based on the relevant engineering standards and technical guidelines;
Undertake desktop analysis to evaluate the condition and performance of the assets;
Provide the appropriate information, advice, engineering input and support services for the sustainable management of Council’s stormwater and transport networks.
Qualifications:
The successful candidate will be enrolled in a Bachelor of Engineering with a minimum of two years completed.
Position Number: 100678
Position Hours: Fixed term (3 months), hours will be negotiated with the successful candidate, maximum of 75 hours per fortnight.
Salary: Schedule A, Salary Point 4.0. $28.64 per hour ($55,853.45 per annum, pro-rata) in accordance with Glenorchy City Council’s Enterprise Agreement 2016
Please note that all successful applicants will be required to provide a current National Police Check prior to commencement of employment.
For further information on this position, contact Patrick Marshall, Senior Civil Engineer on (03) 6216 6800.
How to apply: Applications for this position must be lodged on this submission site or on the Glenorchy City Council website www.gcc.tas.gov.au - Careers page.
To be considered for this role, all applicants must address the key selection criteria in the and provide a current resume. A copy of the position description can be found by clicking the below hyperlink or on the Glenorchy City Council website.
Applications close at 8pm on Sunday, 1st November 2020
- Student Engineer",4.0,"Glenorchy City Council
4.0",Glenorchy,-1,501 to 1000 Employees,-1,Government,-1,-1,Less than $1 million (USD),-1
Data Engineer involving DevOps,-1,"Data Engineer involving DevOps
Axiom Technologies is an Australia based entity with the history of providing Managed IT solutions to medium to large scale enterprises globally. Please visit our website for more information about what we do at www.axiomtechnologies.com
Axiom Technologies is an Equal Opportunity Employer and encourage applicants from all backgrounds and gender to apply, including, Aboriginal and Torres Strait Islander candidates
Job Requirements:
8+ years IT experience, with at least 5+ years of “Data Engineer/Deveoper” focused titles/roles,
Data Tools: Hands on experience with Apache Beam.
Testing: Hands on experience with automated testing activities/outcomes
DevOps: Experience with the processes involving Microservices facilities for artifacts developed
Platform/OS: Mid-range/Unix
Languages: Unix (Shell) Scripting/commands, SQL, Python
File formats: Text, CSV, Parquet, JSON, XML
Scheduling: Jenkins, Airflow
Auto Scripting: Designing/creation of scripts for repetitive activity. E.g. Unix scripting/SQL
Big data: Exposure to Data Lake Concepts, Hive (Schema), HDFS
Source Control tools: GIT
Delivery Models: Agile, Scrum
Ingestion Design: Create/assess Source/Target data mapping designs
Frameworks: Development and delivery frameworks
Activity Reporting/Repository: Jira, Confluence.
Quality: Accuracy and attention to detail
Industry: Financial Services/Banking
Solutions: Define solutions from High level to detail design to address automating ingestion activity. Facilitate/confirm requirements from product owners, business team members and technical associates,
Process Automation: Automating processes in file management, testing data in files, analysis and design, configuration management.
Script Automation: Ability to design/create scripts to automate/improve data copy/migration/ETL for any repetitive activity.
Languages: Java, Python
Scheduling: Control-M
Databases: Relational. E.g. POSTGRESS, Oracle – as a ETL developer
File Formats: Mainframe – experience with referencing its data formats/copybooks
Big data: Experience referencing/using Hive (Schema) to access data in HDFS
Metadata management tools: MDM, EDC and Axon
Performance: Assess, recommend, improve mappings, SQL queries, Batch feeds
Automation Tools: Other tools that may add value to an automation program and generally support development. E.g. API, REST, JDBC, Webservices, Message Queues/Load balancer,
Cloud: Experience with processing of data files to be ingested/stored in the Cloud, preferably with AWS.
Prod Support: Experience in a production support role performing root cause / impact analysis – under time constraints
Experience in a similar role
8+ Years
What next?
If you are looking for that next challenge in your career and wish to apply for this role, please forward your resume to careers.au@axiomtechnologies.com",2.0,"Axiom Technologies
2.0",Melbourne,-1,1 to 50 Employees,-1,Company - Private,Industrial Manufacturing,Manufacturing,Less than $1 million (USD),-1
Data Engineer,-1,"About the Role
We are on an exciting digital journey so it’s a great time to join ME! We are seeking a Junior Data Engineer who enjoys rolling up their sleeves, learning and growing. As part of our Enterprise Data Team, you will ensure fit for purpose data warehouse solutions are built for use across the bank and by utilising best practise ETL standards, whilst ensuring the data is trusted by our BI developers and key business consumers. Oh, and you’ll get to work on Microsoft technology stack too!
You will be involved with investigating data issues, keeping data feeds flowing and collaborating with different projects across the bank to deliver quality data solutions. How important does that sound? What’s even more important is this role contributes directly to our overall business strategy through the provision of data to enable analytics & reporting, as well as supporting business and decision system processes.

About You
You’re naturally a highly motivated and energetic person who thrives in a dynamic, ever-changing collaborative team environment. Ideally you have previous experience as an ETL developer, Data Engineer or a BI developer, and if you have a degree in computer science or similar it would really put you ahead of the rest.

With your knowledge of SQL coding, data modelling, understanding of data warehouse concepts, plus experience of working on complex ETL solutions, you’re ready to expand your horizons and launch your career into the world of IT at ME.

About ME
We’re not like other banks.
ME was created by the industry super funds to be different from the pack – with a core purpose to help all Australians get ahead financially – no conditions, asterisks or exceptions. And we know that looking after customers starts with taking care of our people.
We believe everyone deserves the same opportunities in life, regardless of gender or identity, sexuality, ethnicity, religion or disability ‒ with internal affinity groups.
Perk ME up
Once you get your feet in the door at ME, we’ll put them both in your very own ME-branded Converse shoes. You’ll also get the following financial, health and fun perks when you join the team:
4U Extras portal (discounts and cashback on 100s of items including cinemas, shopping and gym memberships
10% Myki discount
Purchased Leave programme
Internal wellness programme (Mindfully ME)
Professional education through LinkedIn Learning
Novated Leasing
Professional membership reimbursements
Health checks
Financial education (To help you manage your money smarter)
LGBTIQ+ and Women at ME affinity groups

I want those Converse shoes (and the role)
Can’t see a closing date on the advert? That’s because we’re pretty efficient here at ME and we may start looking at applications sooner rather than later, so if this role sounds like your jam, be sure to apply by submitting your resume today.

Should an applicant be the preferred candidate, background checks (including police checks, reference checks, ASIC banned and disqualified persons and bankruptcy checks) will be completed prior to the candidate's employment being confirmed. The outcomes of the background checks do not automatically bar candidates; however will be assessed against the inherent requirements of the job.
Back Share
Apply Now",3.0,"ME Bank
3.0",Melbourne,-1,501 to 1000 Employees,-1,Company - Private,Banks & Credit Unions,Finance,$100 to $500 million (USD),-1
Software Engineer - Machine Learning/Data Science,-1,"Zendesk is looking for a Software Engineer - Machine Learning/Data Science for a full time position in our Melbourne office.
As part of our engineering team, you will work at a scale where the challenges start to get seriously interesting. Our global engineering team is widely dispersed over the world, with people across nearly every continent. You will get a chance to do cool things with a diverse bunch of people while working in the Melbourne office that is home to Zendesk’s first machine learning (ML) research team.
The Data Science Team, together with Data Engineering, have built Satisfaction Prediction, Answer Bot and Content Cues — products that use Machine Learning (ML) and Artificial Intelligence (AI) to help our customers work more efficiently.
What you get to do every day:
We’re currently looking for someone to join our team as we research, develop, and productionise Machine Learning and Deep Learning models. In addition to frequenting Melbourne’s finest purveyors of coffee, ramen, and bulgogi, you may find yourself:
Building machine learning models including neural networks in TensorFlow
Writing and deploying production-grade Python
Querying and constructing datasets in AWS Athena, Spark
Evaluating and responding to real-world model performance
Scaling your ML to millions of predictions per day
Presenting your work to a broader audience
Watching your algorithm help Zendesk’s end-users
What you'll bring to the role:
A strong foundation in a quantitative discipline (e.g. machine learning, statistics, bio/eco/etc-informatics, econometrics, etc) is critical for this position. While experience in deep learning and natural language processing would be beneficial, your best qualities are:
dedication to continuous learning
collaborative work attitude
strong communication skills
You should also be comfortable with at least one programming language, such as Python, R or Scala.
Application Deadline: 18/11/2020
Job Types: Full-time, Permanent
Salary: $85,000.00 – $110,000.00 per year
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Temporarily due to COVID-19",4.5,"Zendesk
4.5",Melbourne,-1,1001 to 5000 Employees,2007,Company - Public,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),-1
Software Engineer (Machine Learning),-1,"About the Role
AdelaideMRI is building a medical reporting tool. We require an engineer to work primarily on machine learning projects to improve reporting speed and report comprehensiveness.
You will perform data analysis of medical report datasets and image datasets to infer sentence recommendations, image classifications, or other actionable results for the doctors.
Skills and Experience
Background in machine learning or image processing
Qualifications in Computer Science, Software Development or Engineering or equivalent experience
Bonus points for Python
No prior medical knowledge is required.
This position offers flexible hours and work arrangements.
Job Type: Full-time
Experience:
Software Engineering: 1 year (Preferred)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Yes",-1,Adelaide MRI,Australia,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Hey there, we’re PEXA!

We started as an idea: to deliver a single, national e-Conveyancing solution. We collaborated with the industry to create a national electronic lodgement and settlement platform: PEXA. From our humble beginnings, we’ve now grown to more than 320 employees across 5 different states. We’re still expanding at a rapid rate and constantly challenging ourselves to create great experiences for our members as they transition to fully digital conveyancing.

Why become a PEXArian?

Great question! Being a PEXArian is so much more than just a job. We are passionate, motivated & unashamedly enthusiastic at PEXA - we love what we do and we’re proud to admit it! Creating brilliant member experiences wouldn’t be possible if we didn’t also strive to create an amazing employee experience. Alongside our members, our employees are at the heart of everything we do.
Here’s a snapshot of what your life at PEXA could look like:

Your growth:
We encourage you to hit your personal and professional Learning & Development goals with our tailored programs and tools.

Your wellness:
We care about your holistic well being - a fully stocked kitchen, four wellness days, a $250 wellness subsidy as well as lunch and learn sessions to support your financial well being.

Your work/life blend:
We know that work is just one aspect of your life, we want to help you create your ideal work/life blend, rather than squeezing in life around work.

Your family:
With a range of benefits aimed at supporting your family including access to a subsidised school holiday program, extended parental leave and flexi-time to support your return to work, superannuation payments for unpaid parental leave for primary carers and a childcare allowance for pre-primary aged children, when we say, ‘welcome to the family’, we really mean it!
The impact you'd drive:
The successful candidate will be responsible for developing, and maintaining infrastructure to support the delivery of new and existing products. They will also be contributing to establish the rules and frameworks for obtaining the required approvals for new products.
On day one we’d love you to have:
Experience with Python, Spark
Event streaming/sourcing with Kafka or AWS Kinesis
Experience with data structures, formats and data security best practices
AWS experience (e.g CloudFormation, S3, ECS, Lambda, SQS, IAM, KMS, DynamoDB, Glue, Athena)
Query construction and optimisation (e.g. SQL, Elasticsearch, Splunk, DynamoDB)
Git, version control practices, and continuous integration/delivery servers
PyUnit and unit testing frameworks
Production release cycles and maintenance
Collaborating with technical and non-technical teams
Even better:
Agile methodology/delivery
GraphQL
Modern frontend technology (e.g. ReactJS, TypeScript)
Machine learning frameworks and tools (e.g. TensorFlow, PyTorch)
OAuth 2, SAML 2, JWT
Data visualisation and exploration tools (e.g. Jupyter notebooks, Tableau)
AWS SageMaker
Sounds like you?
If this role sounds like you, apply today to have your application reviewed ASAP!",3.9,"Property Exchange Australia Limited
3.9",Melbourne,-1,201 to 500 Employees,2010,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Ongoing position
Full time
Based in Sydney, NSW
Who we are
Australian Red Cross is part of the world’s largest humanitarian organisation. Our aim is to improve the lives of the most vulnerable people in Australia and across our region.
About the role
The Data Engineer role will sit within the Data and Integration Squad in IT and will own (design, implement and support) the AWS Big Data technologies such as the Data Lake and Data Warehouse and support the organisation in growing the data analytics capabilities at Red Cross. In addition to this, the data engineer role will also administer the Power BI tool and support the implementation of the data mastering capability.
What you will bring
Experience building and optimizing data pipelines, architectures and data sets.
Experience in dimensional modelling and building data vaults
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with structured, semi-structured and unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Why work for us?
Work for purpose and know that your work assists Red Cross support and empower people and communities in times of vulnerability.
Generous salary packaging options available that can increase your take home pay.
Further information
To find out more about this opportunity please see the position description below or contact Sharath Kumar Gurram on 02 8651 8839.
Position Description: Position Description - Data Engineer .pdf
Applications for this position will close at 11:55pm Thursday, 5 November 2020.",4.1,"Australian Red Cross
4.1",New South Wales,-1,1001 to 5000 Employees,-1,Nonprofit Organization,Industrial Manufacturing,Manufacturing,$500 million to $1 billion (USD),-1
Junior Fullstack Data Engineer (Python and React),-1,"Formbay is the leading Renewable Energy Certificate Trading company in Sydney. We provide Digital Workflow and Compliance solutions in the renewable energy industry and document processing.
Thanks to our meteoric growth and our commitment to be the best at all we do, we've identified the need to bring on board a new Junior Fullstack Data Engineer.
Reporting to our Principal Machine Learning Engineer, you will help build Machine Learning pipelines for our existing Digital Workflow and Compliance solutions to automate fraud detection and document processing over terabytes of photographic and documentary data – including documents, photos, GPS data and aerial/satellite photography.
Our stack is based on Python, JavaScript, Dask, Tensorflow, CUDA, Nix/NixOS, AWS, Docker, PostgreSQL and more – familiarity with these applications will give you a leg-up on the competition.
Our ideal candidate will have the following competencies:
SQL
Python
JavaScript/TypeScript
Our candidate must also be comfortable working with Linux.
Located a stone's throw away from the Queen Victoria Building in Sydney's bustling CBD, we are centrally-located with easy access to public transportation, bars, cafes and fine dining.
Formbay will provide flexible working hours, a generous remuneration package and the opportunity to work on a world-first software solution are what we can offer you. Free, twice-weekly gym sessions and really, really good coffee are also available.
No hiring/recruitment agencies need apply.",5.0,"Formbay
5.0",Sydney,-1,1 to 50 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is an experienced and qualified Data Engineer to join our IT team based in Birtinya.
Key Responsibilities:
Create and maintain data pipelines and or ETL scripts
Create and maintain data integration including API and Batch interfaces
Performed detailed data analysis
Create and maintain corporate data models
Create and maintain data visualization using Qlik.Sense , PowerBI or Simliar Toolset
Experience in defining, building and maintaining data virtualization and/or star schema data warehouses
Maintain, tune and optimise database, integration and visualisation toolsets
ABOUT YOU:
To succeed in this role, you’ll need to bring the following experience and skills:
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Excellent communication skills both oral and written, with an ability to bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking
Experience with data analysis and modelling will be beneficial

How to Apply
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kawana Waters,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Graduate Data Science / Engineer,-1,"The NRMA is an organisation looking to the future, and right now, we are on the lookout for people who can help us reach our goal: to continue to shape the way Australians move, for the next 100 years and beyond. www.mynrma.com.au.
Everyone new to the team, along with our current staff, will temporarily work from home until it is safe to return to our offices. All interviewing and on boarding will be done virtually due to COVID-19.


Your opportunity
As Graduate Data Scientist or Engineer you will be part of the Data Engineering team delivering cloud data transition program for business initiatives and supporting the entire data platform build.
Your key responsibilities will be to:
Implementing Concepts of Data Warehousing, Data Mart creations within Cloud
Use of SQL for data analysis and insights
Building AI/Machine Learning prototype for implementing and supporting existing algorithms
Data Analytical reports build, using different tool sets


Requirements for Success:
Relevant Degree - Computer Science, Computer Engineering, Software Engineering, Data Science
Excellent SQL skills and demonstrated working knowledge in Python
Demonstrated understanding in data structure and algorithms.
Knowledge and concept of data warehousing methodologies
Any reporting tools experience Tableau or Oracle Analytics Cloud, Looker is desirable
Exposure to Google/AWS/Azure/Oracle any cloud based platforms is desirable
Good communication and interpersonal skills

If you have the required skills and the passion to join our high performing team, please apply today.

Employee Benefits
To ensure our employees feel valued, empowered and celebrated we provide a range of employee benefits including:
50% discount on all NRMA insurances
Free Roadside Assistance
12 weeks paid primary and 4 weeks paid secondary parental leave
Free NRMA Blue Membership
At the NRMA Group, we are People Moving People and diversity and inclusion are part of our DNA. Together, we continue to build an inclusive culture that encourages, supports and celebrates the diverse voices of our employees. It fuels our innovation, promotes flexible ways of working and connects us closer to our members and the communities we serve.",2.5,"NRMA Motoring & Services
2.5",Sydney,-1,501 to 1000 Employees,-1,Nonprofit Organization,Casual Restaurants,"Restaurants, Bars & Food Services",$500 million to $1 billion (USD),-1
Data Centre Engineer,-1,"We are a leading world group that provides low-carbon energy and services. To tackle the climate emergency facing us all, our aim is to become the world leader in the zero-carbon energy transition ""as a service"" for our clients – particular for companies and regional authorities. We use our expertise in our key business areas (renewables, gas, services) to provide competitive and bespoke solutions.
The Data Centre Engineer will be employed as part of a 24/7 ongoing shift to coordinate and monitor third party service providers, maintain the data centre facilities and infrastructure plans, coordinate the implementation of customer requests within the data centre and monitor systems, all in accordance with the Contract KPIs and SLAs.
Coordinate and monitor third party service providers for regular maintenance & testing, service faults & call outs, ensuring works are performed in accordance with Contract SLAs
Monitor and maintain the data centre facilities and infrastructure plans and documentation, including electrical, mechanical, hydraulics, fire and BMS/EMS systems
Coordinate the implementation of internal and external customer requests within the data centre
Perform scheduled plant checks and minor maintenance works
Ensure all Work Order requests are raised and closed in a timely manner
Conduct inductions for staff, vendors and contractors
Ensure all work permits for vendor works are raised and closed
Perform inventory checks on all equipment and critical spares

Qualifications
The selected candidate must be able to demonstrate:
Electrical or HVAC background, or Graduate Electrical or Mechanical Engineer
Passionate about quality work and career minded looking for a new challenge
Can commit to a day and night shift roster (2 days of day shift, then 2 days of night shift, 4 days off)
Ideally able to commence asap
As part of carrying out the duties of this role, it is mandatory to hold Australian Citizenship.

If you are interested and meet the selection criteria apply with an up-to-date resume via the apply instructions on this website.

ENGIE Services is an EEO employer, where all applicants are treated with fairness and respect and have equal access to the opportunities available.

We will not be engaging in the services of a recruitment agency to fill this vacancy and therefore request all interested candidates apply directly to this advertisement.

Job
: Maintenance
Primary Location
: Oceania-Australia-New South Wales-Erskine Park
Organization
: ENGIE Services Australia and New Zealand
Schedule
: Full-time
Nature of Responsibility
: Senior operational / administrative role
Job Posting
: Sep 11, 2020, 6:29:59 AM",3.7,"ENGIE Services Australia & New Zealand
3.7",Sydney,-1,5001 to 10000 Employees,1995,Company - Public,Energy,"Oil, Gas, Energy & Utilities",$2 to $5 billion (USD),-1
Senior Data Engineer,-1,"Senior Data Engineer, Temporary, SYDNEY - McKell

Job Title: Senior Data Engineer

Salary: SNSW Grade 9/10 - The package includes base salary range of $111,806 to $134,667, plus employer's contribution to superannuation and annual leave loading.

Location: Head Office – Haymarket

Employment Status: Temporary through till 30th June 2021


About Service NSW:

Service NSW is making it easier for people and businesses across NSW to access government services. The role designs, builds and analyses complex data from multiple sources to identify revenue, process and business improvement opportunities; providing new information and insights to the business to inform planning, continuous improvement and performance.

About the Role

We are currently seeking to appoint a Senior Data Engineer to deliver expert advice and services in the design of a Single View of Customer and data-related services to support the achievement of business outcomes and strategic goals. We support flexible working practices with staff working remotely during this time.

In this role you will:

Design, build and support a modern data platform based in AWS and vendor technologies.
Provide expertise on data modelling for Graph data model and Customer Data Platform (CDP).
Create data pipelines, load, transformation and reporting workloads in AWS.
Work with the latest data engineering technologies like Apache Kafka, AWS Kinesis, AWS Neptune, AWS Glue and AWS Athena.
Contribute to the design and decision-making of the right tool or platform for the job according to requirements.
Provide expert advice and guidance on data quality and data engineering best practices.
Support a “bigger than you can imagine” scale of data in production environments.
Design, develop and support a metrics-driven reporting solution and a meaningful business intelligence platform.
Document the solution design and support procedures of solutions.
Produce reports, visualisations and recommendations to answer complex business problems that are presented in the most appropriate format to ensure clarity for target audience.
Analyse and define new process improvement opportunities to support continuous improvement and business outcomes; providing advice to stakeholders, on ways to improve the efficiency and reliability of data products and services.
Be very responsive to the information needs of the business by corresponding to customers in a timely manner and provide support/solutions to issues raised.
Troubleshoot and perform root cause analysis on production issues. Identify and implement long term solutions to problems. Perform scheduled maintenance, release deployment and production support activities after business hours, from time to time.
Liaise with internal and external customers to discuss and gather requirements, solutions etc. and maintain a good working relationship with the stakeholders.


Skills and Experience Required:

Solid experience with workflow technologies designing and building data pipelines, data models and data stores.
Experience working within and an understanding of Amazon AWS ecosystem, including security and performance tuning.
Hands on experience working with different types of databases, with focus on Graph and NoSQL databases.
Experience with data streaming required. Having used Kafka and related technologies is an added advantage.
Sound knowledge and experience working with batch processing, data extraction and API integration.
Hands on experience with at least one programming language: Java, Python or scripting.
Demonstrated experience working in an Agile based, fast paced, complex environment within cross-functional teams.
Experience developing systematised insights, data analytics and reporting solutions is an added advantage.
Experience with interactive visualisation of data insights is an added advantage.


Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Salary Grade 9/10, with the base salary for this role starting at 111,806 base plus superannuation

Closing Date: 6th November at 9:59am - applications will be reviewed on a rolling basis, applications may close early or extend

Please apply online, direct applications submitted via email will not be considered.

The Department of Customer Service is proud to be an EEO Employer who are fully focused on equality and believe deeply in diversity of all identities making us different and a true reflection of our NSW customers. As an inclusive workplace, we support various employee resource groups, practice flexible work and workplace adjustment.

If you do require an adjustment during the recruitment process, please notify us on your application form.",3.2,"Service NSW
3.2",Sydney,-1,501 to 1000 Employees,2012,Government,State & Regional Agencies,Government,Unknown / Non-Applicable,-1
Data Engineer - Entry / Mid Level,-1,"Work with a great team on interesting projects customers
Gain more experience in AWS, Data, DevOps cloud operations
Got a working knowledge of AWS? We will teach you the cool stuff!

Itoc is seeking an up and coming Data Engineer to join our growing Data Team in Sydney.

This is an exciting role working with databases, data lakes, data warehouses, data transformation (Python SQL) and enabling AI/ML.

You will be implementing foundational, robust and production ready data platforms to enable business data-discovery, self-service, AI/ML functions across a range of client types and industries, allowing them to do more with their data.

You'll be responsible for:

Deploying data repositories such as lakes and warehouses.
Contribute to our growing portfolio of data solutions.
Ongoing optimisation and management of data platforms.
Development of transformational logic for data pipelines
Data evangelism. We want to show our clients how to follow the best practices for data.

Desired Skills and Experience

To take up the challenge, you will have a depth of skills and experience including:

1-2+ yrs of focused data experience working with SQL and/or NoSQL solutions
A solid education in Software Engineering or equivalent industry experience.
Anything Data focused preferred.
Ability to analyse business scenarios and associated data landscape to derive potential opportunities.
Strong foundation in Python and SQL
Working knowledge of APIs
Principle knowledge of the different relational database platforms and modern data storage techniques
Knowledge of the different aspects of data environments
Collect, store, process, verify consume
Experience with version management systems (such as GIT)
Working knowledge of AWS or another cloud platform - we will teach you the cool stuff.
Great communication skills, an ability to work closely with customers, developers and engineers and the confidence to present ideas in open forums.
Relevant tertiary qualifications and/or industry certifications.
Great communication skills, an ability to work closely with clients, developers and engineers and the confidence to present ideas in open forums.

While not required, a background in consulting and professional services is highly desirable.

Itoc Description

This is an exciting and challenging career opportunity to join the growing Sydney-based Data Team of a leading cloud solution provider where you will be given support to reach your long term career goals. You will be part of a team of cloud experts and will work in an environment of continuous improvement and learning delivering innovative cloud solutions across SaaS, online business and enterprise business.

On offer is a chance to join a team with a great working environment, in an organisation that values its employees and sees the value in ensuring they are engaged. Our team are clearly passionate about what they do, that's why we won the following awards:

Customer Obsession Partner of the Year 2015: ANZ Region
Customer Obsession Leadership Partner 2015: re:Invent

As an employer of choice Itoc offers competitive remuneration, training and development programs and a great working environment. We value a healthy work life balance.

The Perks

MacBook or Dell
Continuous internal learning that will provide training and career development opportunities
Working with a collaborative, social team and leveling-up your skills faster than you will anywhere else.
Quarterly social events

Itoc

Culture and smarts are important to us. Bring your secret sauce. This is no ordinary environment, you will work along some of the Cloud’s best. All engineers at Itoc must gain at least five AWS certifications. We work hard but we have fun.

Please note you must have full working rights in Australia and be available on-shore for face to face interviews.

No recruiters please.",4.0,"Itoc
4.0",Sydney,-1,1 to 50 Employees,2013,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Date: 01-Oct-2020

Location:
Melbourne, VIC, AU

Department:Description:
Technology discounts - from Apple HP Lenovo to Windows
Flexible work arrangements - work in a way that suits you best
Salary packaging - to suit your personal and financial circumstances

Do you want to work for one of the fastest growing data teams in Australia? Do you want to work on multiple data platforms and provide new solution offerings by leveraging cloud and big data technologies?

About the team

Big data information and analytics. Three words that spark apprehension in most businesses. But our team of experts are constantly curious and excited about combining our wonderful array of technological expertise to transform data into our clients most valuable assets making their work smarter. Our data consultants are supported with resources training and tools they need to excel at their work but also the freedom and power to create their own paths forward to make a difference.

As a Senior Consultant in Big Data you will work closely with the team and stakeholders to build and deliver a Cloud based vision for a next generation Big Data analytics platform with strong focus on data quality data security and deliver the systems that process huge volumes of data.

What will you typical day look like?

You will play a pivotal role in - Designing and producing high performing and stable applications to perform complex processing of massive volumes of data in a new cloud based architecture; Building real-time data processing applications which are integrated with business systems to enable value from analytic models to drive rapid decision making; Contributing to system architecture design for a data platform (including cloud-based structures both on and off premises data warehouse components and data lakes); this could cover a range of technologies various countries/locations and lines of business; Support data strategy or technology strategy definition programs including technology stack definition and target operating model requirements

Enough about us lets talk about you:
You are someone with:
Use of traditional data analytics tools and techniques (e.g. MSSQL Oracle MySQL) and ETL software (e.g. SSIS Informatica CloverETL)
Working in large scale cloud data solutions using platforms such as AWS or Azure or GCP will be a bonus.
Experience in scripting or programming (e.g. Python Java Scala C#)
Excellent verbal and written communication skills to adapt to technical and non-technical audiences.
Educated to degree level (or have equivalent experience)
Why Deloitte?

At Deloitte we create positively differentiated work experiences that enable our people to feel valued and achieve their full potential. We value difference and embrace people with diverse backgrounds and thinking styles. Knowing that people work best in different ways we are happy to discuss alternative arrangements if the working pattern you are looking for is not specifically indicated.",3.8,"Deloitte
3.8",Melbourne,-1,10000+ Employees,1850,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Engineer,-1,"Opportunity to grow the team
Period of growth
Intuitive app
S2M are working with a FinTech who have created a unique financial product to help thousands of people better manage their finance, and is currently scaling the company to the next level!

They are looking for a Data Engineer to join, and looking for someone who wants to be hands on, with opportunity to grow the team in future.

Role:

Looking for people with strong AWS experience. You will need passion for data and a cloud, through which you will help a rapidly scaling Australian FinTech establish their data infrastructure from the ground up.
5+ years’ experience as a data engineer within the data and analytics domain
A python 3.X aficionado who is very comfortable creating and orchestrating AWS data pipelines with nothing but code
Strong project delivery toolset experience in open source data integration tools
Experience with processing large volumes of complex data including visualisation and insights generation
Ability to define and develop data integration patterns and pipelines
Ability to assess complexity of data (volume, structure, relationship etc.)
Hands on experience working with different databases (RDBMS, NoSQL, Blob storage etc)
Hands on technical expertise setting up DevOps automation
Hands on experience working technologies/platform e.g. AWS, Dockers, Containers
Experience building data profiling and data cleansing frameworks
Technical reconciliation and reporting
Knowledge and experience in end-to-end project delivery, either traditional SDLC or agile delivery methodologies (or hybrid approaches)
Exceptional communication, documentation and presentation skills
If this sounds like you, get in touch today - kate.gabb@s2m.com.au
3167410agsdf",3.1,"S2M
3.1",Sydney,-1,Unknown,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Analysts,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is seeking experienced and qualified Data Analysts to join our IT team based in our corporate office in Birtinya (Sunshine Coast) or at our meat processing facility in Kilcoy.
Key Responsibilities:
A mixture of data analysis and commercial skills to source, blend and analyse data to gain insight and answer key commercial questions
Working with strategic leaders to define and model Key Performance Indicators, and assist in building forecasting models
Working closely with data engineers and BI developers to specify data pipelines and report visualisation
Drive the creation and implementation of data quality business rule including data definition, governance and quality assurance
About You:
To succeed in this role, you’ll need to bring the following experience and skills:
Proven ability to derive insight and knowledge from data using commercial expertise is a strong requirement
Strong SQL and Excel skills are essential, along with strong data analysis and commercial insights
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Effective people communicator - engage with stakeholders on reporting needs, interpret requirements into visual solutions and train/deliver the outputs to the stakeholders getting signoff of acceptance
Bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking

How to Apply:
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kilcoy,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Network Data Engineer,-1,"Min 6+ years of experience in the relevant technologies
Australian Driving License for visiting remote locations / Data Centre for day to day technical work.
Managing Network devices (switches, routers, firewalls, load balancer, and wireless technology)
Performing MACD activities for all network devices.
Supporting BAU operation activities.
Proficient in performing in-depth details of technical troubleshooting, cause and provide recommendation to the client for incidents causing extended network outage to client’s critical locations.
Provide exceptional network services in terms of network support, break-fix, design and consulting, new projects, implementation.
Configure, administer, and document firewall infrastructure.
Manage the firewall deployment, rules migrations, and firewall administration.
Supporting Cloud Migration Activities from traditional to AWS/Azure.
Setting up VPN tunnel with Cloud and 3rd Party network devices.
Integrating and upgrading existing ISP bandwidth with support from ISP Vendor.
Setting up VPN profiles for Users.
Installing hot fix and patches to mitigate the security devices from attacks and bugs.
Reviewing and fine tuning the firewall rules and NAT rules.
Documentation and change control.
Mentoring, Motivating and Guiding support teams
Technical skills:
o LAN
o Wireless
o WAN
o MPLS
o Routing protocols (OSPF,BGP)
o DMVPN
o Azure cloud Networking
o Network Security
Fortigate Manager / Analyzer / Firewall
Cisco ASA
Firepower FTD
Cisco Any connect
Site to Site VPN
F5 Load Balancing and Scripting iRule
Job Types: Full-time, Contract
Schedule:
8 hour shift
Experience:
Scripting: 5 years (Required)
Data Network: 5 years (Required)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Required)",3.6,"Total IT Global
3.6",Sydney,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Engineer - Processing & Analysis,-1,"Job Description:
Design,build and maintain the ingestion system to support various types of data(e.g. User behavior, RDS, NoSQL db and others) to be ingested to the data warehouse more timely and accurately
Translate data requirements into scalable technical data service with low latency and high concurrency
Design,build and maintain the batch or real time data pipeline in production using Hadoop big data technology
Analyze and improve efficiency, scalability, and stability of the system
Define and manage SLA,Data quality for all data sets in allocated areas of ownership
Requirements:
Minimum B.S. degree in Computer Science or a related technical field
2+ years of working experience in programming languages,such as Java,Scala,Python
Familiar with Hadoop, Spark and Flink data processing, experience of TB data processing experience is a plus
Familiar designing and operating of a robust distributed system is a plus
Understand data mining or machine learning
Excited to work intimately with data
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"SYNOPSIS:
Lead Data Engineer
Applications close Sunday 8 November 2020
Ongoing
Contact name: Shyni Sasikala
Phone: (02) 6249 9048
Email: Shyni.Sasikala@ga.gov.au

The Data Policy and Informatics section within the Digital Science and Information branch creates, implements, and promotes policies, platforms and tools that improve and support the quality, discoverability, accessibility, and general usability of Geoscience Australia’s science data products. The section consults with internal and external research, government and industry partners to establish collaborative data frameworks, architectures and models within Geoscience Australia (GA) and across broader national and international communities of practice. The section innovates, builds and maintains tools, systems, processes and governance that enable digital data management, cataloguing and open data delivery.
GA makes accessible a wide range of geoscientific and spatial data to a wide variety of stakeholders in multiple formats, and in recent years GA's data volumes have grown exponentially. GA is focussed on making its data and metadata assets accessible so that they can be used in machine to machine interactions for data analytics and other applications in environments that range from High Performance Computing (HPC), through high-end cloud servers, to mobile devices.
We currently have two opportunities for Lead Data Engineers in the Informatics team. The Lead Data Engineer is responsible for innovating and exploring new technologies that will advance GA’s science goals and maximise the uptake and use of GA’s science data. The Lead Data Engineer reports to the team’s Assistant Director but also works closely with other developers, data scientists and engineers within the Digital Science and Innovation (DiSI) branch, as well as diverse stakeholders both within and external to GA.",3.9,"Geoscience Australia
3.9",Canberra,-1,501 to 1000 Employees,2001,Government,Federal Agencies,Government,$100 to $500 million (USD),-1
Data Engineer,-1,"The Seven Network is part of Seven West Media, one of Australia’s most prominent media companies, with a market leading presence in content across broadcast television, online and in print. Comprising some of Australia’s most renowned media brands, SWM includes not just Seven Network and its affiliate channels 7two, 7mate, 7flix and BVOD offering 7plus, but also 7NEWS.com.au, The West Australian, The Sunday Times and more.
At Seven we are here to bring all Australians closer to the moments that move us - we’re first on the scene, with our finger on the pulse, on demand, in the moment. Together, we’re responsible for creating and sustaining authentic Australian engagement.
A new and exciting opportunity has opened for a Data Engineer to join the Audience Intelligence team. Based in Sydney and reporting to the Head of Data Enablement, you’ll be responsible for:
Implementation of end to end data solutions to support Data Strategy for the SWM group.
Work closely with the Data Solution Designers to develop and maintain scalable data pipelines and build out new file and API based integrations to address requirements from the various business stakeholders.
Collaborates with engineering, analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organisation.
Work on Data Preparation for analytics and data scientist team members and assist them from an engineering perspective in building and optimising the models including building the automation of the end to end workflows
Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.
Perform data analysis required to troubleshoot data related issues and assist in the resolution of production data issues.
Work effectively with vendors for successful delivery of projects and acceptance of the solution
Work on Delivery projects using Agile Software Development methodologies
We are looking for someone who has:
Bachelor's degree in computer science, computer engineering or other technical discipline is essential
Proven experience working as a digital analytics specialist
Extensive experience with digital analytics implementation (e.g. Google Analytics, Snowplow, Adobe Analytics) and BI processes and visualisation platforms
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience in ETL and building and optimizing ‘big data’ pipelines and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Experience with big data tools: Hadoop, Spark, etc., AWS cloud services: EC2, S3, Lambda and familiar with version control systems: Git
Strong coding skills with knowledge of Unix/Linux and scripting languages such as Unix Shell scripting, Python desirable
Experience supporting and working with cross-functional teams in a fast-paced environment.
Ability to multi-task and problem solve with changing demands and priorities
Ability to work under pressure to meet deadlines and detail oriented
Your success is our success: we will provide you with opportunities for you to keep learning and growing, enabling you to challenge and develop yourself. In return, we offer a benefits program that has something in it for everyone.
Seven West Media is an equal opportunity employer and we are committed to creating a diverse and inclusive workplace.
Recruitment Agencies: Seven West Media does not accept any unsolicited agency resumes and will not be responsible for any fees related to unsolicited resumes.
Advertised: 19 Oct 2020 12:00 AM AUS Eastern Daylight Time
Applications close:

Back to search results",2.5,"Seven West Media
2.5",Sydney,-1,5001 to 10000 Employees,1956,Company - Public,TV Broadcast & Cable Networks,Media,Unknown / Non-Applicable,-1
BICON Rules Engineer,-1,"APS 5 - $73,299 - $80,410 per annum plus superannuation
Biosecurity Plant Division
Canberra, ACT
Play an active role in managing biosecurity risk to Australia
Work in a motivated and professional team with a wide range of skills and backgrounds
Full training provided

Who we are
The BICON Content Development Team maintains and improves the Biosecurity Import CONditions database (BICON) content to allow external clients to understand and comply with their biosecurity obligations and internal clients to effectively manage biosecurity risk and regulate imports. We work collaboratively with internal clients to comprehend and implement their BICON content requirements and optimise the use of BICON to publish clear import requirements and onshore management support procedures to effectively manage biosecurity risk.

The Jobs
Key duties of these positions include:

working with business content (import and permit conditions) and import programs to understand and construct decision tree structures in the BICON database, in accordance with system design and authoring conventions
executing changes to import and permit conditions in alignment with service standards while complying with system rules and authoring conventions
providing technical advice through various formats on the most appropriate means of authoring BICON content to achieve import program and stakeholder objectives
using workflow management tools to maintain detailed records of changes to import conditions and key decisions
performing administrative tasks including system reporting, data analysis and scoping tasks for the BICON content change work program
contributing to the development and maintenance of instructional material, authoring conventions and courseware
clearly documenting and reporting system issues
developing and maintaining effective working relationships with internal and external stakeholders.

What we are looking for
Knowledge and experience
Experience working with complex IT systems.
Experience working collaboratively and as part of a team.
Knowledge of the role of biosecurity is preferred but not essential.

For additional information, please read the Job Description below.
Candidate Information Package docx Opens in new window",3.9,"Department of Agriculture & Water Resources
3.9",Australia,-1,5001 to 10000 Employees,-1,Government,Federal Agencies,Government,$500 million to $1 billion (USD),-1
Cloud Data Engineer,-1,"Job no: 509605
Work type: Permanent Full Time
Location: Melbourne, Canberra, Sydney
Do you embrace digital disruption?
Do you love solving complex problems, designing sophisticated solutions and building innovative technology?
Do you believe in creating powerful actionable insights from Data and Analytics?
Do you want to work in a diverse and flexible working environment?
KPMG is one of the most trusted and respected global professional services firms. Through depth of expertise, clarity of insight and strength of purpose we help our clients solve complex challenges, steer change, strengthen, transition and grow. We are a team based practice and this extends to our clients whom we work and collaborate with, in solving complex problems. Together, we design, innovate and implement, providing enduring advice that support our clients and the services they deliver. Our clients vary in size and come from a diverse range of sectors – all sharing in a common goal: to embrace change and deliver services that make Australia a better place. We are looking for talented individuals who would like to join us on the journey.
KPMG’s Digital Delta Team
We re-imagine and re-invent organisations to become world class digital enterprises using advanced technologies, data and human insights. We help organisations to embrace Digital Strategy, Artificial Intelligence (AI) & Cognitive, the Internet of Things (IoT), Data, Analytics & Modelling, Mobile App & Web, and User Experience (UX) & User Interface (UI) and more.
We work with clients to:
Formulate strategies that re-imagine organisations
Harness innovation from the 4th industrial revolution
Actioning insights from trusted data to consistently and quickly make clear decisions
Build adaptive organisations
Thrive as a connected enterprise – front, middle and back office
This is how you’ll contribute:
We are looking for ambitious Data Engineers who are passionate about helping clients define bold ambitions and deliver on them. Joining our team will take you on a journey of personal and technical growth and provide the opportunity to inspire confidence and empower change.
As a Data Engineer you are the designer, builder and manager of the information or ""big data"" infrastructure, preparing data for analytical or operational use. You will design, construct, test and maintain a data pipeline to pull together information from different source systems; integrating, consolidating and cleansing data; and structure it for use in individual analytics applications.
The KPMG Difference
Our people are focused on creating a diverse and dynamic environment that embraces and values differences. We value the variety of unique experiences, qualities and characteristics our people possess and we share and learn from each other.
We are proud to be consistently recognised as an employer of choice for women, and for our achievements in LGBT+ workplace inclusion.
Our commitment to ‘Flexibility’ allows our people to manage the changing demands of work, personal or family life. Explore the links below to hear our people share their experience @ KPMG:
Flexibility empowers wellbeing
Flexibility enables contribution to the community
Flexibility inspires technology & innovation
Flexibility supports family

Make KPMG the clear choice for your career and be Extraordinary!

Advertised: 09 Sep 2020 AUS Eastern Standard Time
Applications close:",3.8,"KPMG
3.8",Sydney,-1,10000+ Employees,1987,Subsidiary or Business Segment,Accounting,Accounting & Legal,$2 to $5 billion (USD),-1
Computer Network and Systems Engineer,-1,"Duties Include but are not limited to:
Tasks Include:
analysing, developing, interpreting and evaluating complex system design and architecture specifications, data models and diagrams in the development, configuration and integration of computer systems
researching, analysing, evaluating and monitoring network infrastructure to ensure networks are configured to operate at optimal performance
assessing and recommending improvements to network operations and integrated hardware, software, communications and operating systems
providing specialist skills in supporting and troubleshooting network problems and emergencies
installing, configuring, testing, maintaining and administering new and upgraded networks, software database applications, servers and workstations
providing network programming in support of specific business needs and requirements
preparing and maintaining procedures and documentation for network inventory, and recording diagnosis and resolution of network faults, enhancements and modifications to networks, and maintenance instructions
monitoring network traffic, and activity, capacity and usage to ensure continued integrity and optimal network performance
Skills and Experience Required:
Must have experience working in a Managed Service environment
Demonstrated experience in IT Networks and Data Centres
Understanding of systems and architectures to meet client needs
Experience in Help Desk including break / fix
Effective and timely documentation
Effective Task Management Skills
Be solution and outcome focused and willing to learn new technologies
Excellent communication skills with staff, clients and partners
Time management, ability to prioritise and deliver to schedule
Experience with N-Able and Connectwise desired
Open Cabling license desired
Job Types: Full-time, Permanent
Salary: $30.00 per hour
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,Trans-plant training,Canberra,-1,-1,-1,-1,-1,-1,-1,-1
Software Engineer (Data),-1,"If you are looking for an opportunity to make a real impact with smart people who are genuinely doing things differently then you've come to the right place! We're growing our data engineering capabilities and are looking for awesome data engineers to join our team.
With our diverse range of clients and projects, no day will look the same - but here's a great snapshot of what you'll be doing:
Work with some of the best Data Scientists and Engineers to deliver production-grade AI and Machine Learning systems as we deliver client projects from inception to production.
Consulting with our clients and working with them to build modern data systems using the 'best of' technologies and principles.
Advising clients on data strategy, architecture and technology.
Applying best software engineering practices in coding, monitoring and alerting, using CI/CD, TDD and cloud architectures.
Working over a wide range of big data tools and environments: not limited to; Apache Kafka, Spark, Python, Scala, Hive, Airflow, AWS EMR & Glue, GCP Dataproc & Dataflow, BigQuery, Snowflake, Redshift.
Who are we?
Glad you asked! We are Eliiza. Data science. Engineered for scale.
We are a passionate team of data scientists and engineers who apply data science and machine learning to solve real-world problems. Our mission is to create a bright future for Australian businesses and society in a world increasingly influenced by intelligent technologies.
We've created a culture that values diversity where people can truly be themselves! We care a lot about growing the Australian AI community in a positive direction, and we're doing several things to try and achieve that:
We provide opportunities for underrepresented groups to work in AI through our associate and intern programmes
We organise and participate in a range of community events, reading groups and meetups
We produce the AI Australia podcast
We blog about topics we care about
We stream brown bag sessions to the broader community
We're also part of Mantel Group's 'house of brands' which means it's not just the Eliiza team you'll work with, learn from and see at social events - there's another 230 of us across DigIO, Kasna & CMD Solutions!
So you're ready for something new?
We're keen to know more about you! Our team is made up of a range of people, with different experience across a huge range of data driven skill sets.
We'd love to hear from you if you have experience with:
one (or more) core language(s), ideally Scala, Python or Java
one (or more) cloud platforms, AWS, GCP, Azure
ETL/ELT concepts and technologies e.g. Data partitioning, Hive, Spark
streaming data concepts and technologies, ideally Kafka (Kinesis, Beam or Pubsub will do)
We'd be over the moon if you:
Experience with distributed/columnar databases (e.g. Snowflake, Big query, Redshift).
Experience with any of a variety of databases e.g. RDMS, NoSql, Columar, Distributed, Time series, Graph.
Knowledge of job orchestration and scheduling. Any experience with Airflow, Luigi or Oozie.
Experience with containers and container orchestration (Docker, Docker Compose or Kubernetes).
However, we value a diversity of skill-sets, and don't necessarily require that you're skilled with all of the above. If you feel you don't fit all the experience/skills listed above we still encourage you to apply or get in touch.
What's on offer if you join us?
We make sure you're always one step ahead by investing your learning and development, every year. We build our own training where it doesn't exist yet.
We hire smart people and get out of their way. By focusing on our five principles and not getting caught up in red tape, we trust you to get the job done.
You'll get all the tools you need - a new iPhone or Google phone, a new Macbook Pro or Dell, and a lot of branded swag!
But hold on, you mentioned a house of brands?
We certainly did! Mantel Group is an Australian-owned, 'house of brands' company with four technology businesses (Eliiza being one of them!) across Melbourne and Sydney. We're building a group of companies with open borders so we can support you to take on new skills without leaving an awesome team - we understand you won't have one job for life!
We may only be just two years old but Mantel Group has already been recognised #9 in the 2020 Best Places to Work in Australia and #4 in the AFR's 2020 fastest growing new companies.
Keen to chat?
Click ""Apply"" to share your details with our talent team, and we'll be in touch.
In the meantime, check out 'how we hire' to find out what's in store if you're successful and get to know us better by visiting our website and following Eliiza on LinkedIn.",-1,Eliiza,Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Infrastructure Engineer,-1,"Job Description:
Design and grow the Shopee data platform to support a variety of big data applications using open-source technologies including Kafka, Hadoop, Presto, HBase, Spark, Hive, Druid, and our own creations. Some examples include a real-time data streaming platform, a unified query platform, a cluster management system, and a machine learning platform
Dig into the source code of some open-source big data system to get the whole control and familiar with the details, configurations, designs and source code. Develop and maintain the internal release of big data systems and components as the business requirements.
Keep close and overall monitoring for all the deployments of the systems, maintain the system’s stability, improve the performance, discover the performance bottlenecks, tracking and troubleshooting, cost optimisation.
Requirements:
B. Sci. / Ms / PhD in Computer Science or a related technical field
Familiar with at least one of these languages: Java, Scala, Python, Bash under Linux / Unix. Scala is a plus
Familiar with the use and compute logical of SQL
Knowledge about the Big Data Infrastructure system technology like Distributed File System, Distributed Computing, Distributed Database will be a plus
Hands-on experiences Hadoop, Spark, Kafka, and/or Presto will be a plus
Love to use and develop open-source technologies
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"Work on an award-winning, international technology!
Endless career opportunities
An innovative, friendly team of 300+
This role will be focused on the development of our existing ClaimLogik line of products as well as working on our new cloud-first, modern suite of applications.

Intelligent Thought, our technology business is scaling and shipping our software globally. Already profitable, part of a much larger group business, with investors such as Macquarie Capital and Envest – we are all set to deliver textbook disruption to the Insurance Industry. The growth of the platform, of our customer base, and the increasing industry demand have led to the need for this role to help the team scale.

Our Philosophy
Give each employee a sense of purpose and an environment for them to connect the importance of their role to delivering a service that matters to our customers.
Challenge the ‘why’ of traditional claims processes.
Keep it simple – do only what brings value and what matters to the customer
Enable employee decisions, empower our people
Responsibilities:
Create, extend and maintain ETL pipelines to form our data lake, data warehouse and analytics platform (currently using the Microsoft Azure set of tools and service)
Help define the optimal data pipeline architecture
Influence the tool selection, platform selection, data architecture and strategy which will transform the business to be truly data-driven
Understand, analyse and size user requirements
Work with different parts of the business to provide them with the insights they need to deliver the best results
Skills & experience:
Degree or qualification in computer science or related
Advanced knowledge of relational database, including query authoring and query optimisation (MS SQL Server and PostgreSQL).
Experience building and optimising ETL pipelines
Experience designing complex data models
Experience working with cloud platforms (Azure or AWS)
Efficient time management and organisational skills
High attention to detail and accuracy
Effective communication skills to build strong working relationships; both written and verbal
Proactive and results-driven
Why Claim Central?
Claim Central Consolidated is a global insurance industry leader across, claims management, insurance technology and data and analytics. Currently operating in the United States, Australia, South Africa, Italy and New Zealand, we have pioneered digitally connected claims management services across the globe. Claim Central is a disruptor and thought leader in the industry and we were recognised as the Australian Financial Review’s 8th Most Innovative Company in Australia in 2016. This business is in a period of unprecedented growth, transitioning our technology and services into multiple geographies at a rapid pace. Our unique culture is based on teamwork, collaboration, trust, respect and performance. We also offer many benefits apart from our exceptional team culture; including flexible work arrangements, and continued professional development.

Be a part of this journey in a career-defining role.",-1,Claim Central,Matraville,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer - AI/ML,-1,"Our client provides services to a major industry across the country. The business is still early in it's days of technology development and the environment is greenfields in nature (no pun intended), effectively working like a start-up.

Their data and analytics team have worked and built leading and bleeding-edge technologies in this space and what they have created so far may be game-changing. From a machine learning perspective, the progress they have made to the business has already seen proven success in changing the future of an industry that will have positive consequences for all those involved.

You will have previously worked in a technical capacity in the data and analytics space and have experience working with an organisation where machine learning has been implemented, not just a concept that the business talks about having or the technology team would love to have. The commercial experience you will have had in the ML field will be proven examples of where you have affected the way a business or industry used to perform, to the changes that have come about from this.

Technically, you will have extensive experience in the Microsoft space - Power BI, Azure etc and you will have previously mentored and coached junior members of the teams you have been part of.

This is a rare opportunity in Brisbane where the business has truly embraced and funded projects across the ML space and would be a great chance for those in the Data Development/Data Engineering field, who are looking to move into a Data Scientist role in the future.

Please send your application through if you would like to know more.",4.0,"Emanate Technology
4.0",Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Solution designer/ ETL Engineer & Data Modeller,-1,"We are looking for a Qualified and Experienced Solution Designer to join our client for a period of 6 months with a view to extend.
You will work closely with team members and your contribution will range across gathering and analyzing information, developing and documenting improved processes and work instructions and experienced DWH Lead with skills in requirement analysis, solution designing, developing, testing and supporting ETL solutions.
A hands-on solution designer, data modeler and ETL developer for Data Warehousing and ETL application transformation projects using Informatica PowerCenter.
Knowledge on AWS, S3, Redshift, Informatica BDM, and related technologies.
Experience working with IPython, PySparks, AuCuMo, Airflow, Jenkins, Github, Athena, JIRA, Rally, Spectrum, Glue, Flyway.
Good exposure on Oracle PL/SQL, aware of DBA activities, writing and performance tuning of complex SQL queries.
Contract length: 6 months
Job Types: Full-time, Contract
Salary: $650.00 – $800.00 per day
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,nducive,Melbourne,-1,-1,-1,-1,-1,-1,-1,-1
"Data Engineer, Wollongong NSW or Mount Waverley VIC",-1,"Company Description
BlueScope is a technically advanced supplier of steel and steel products in Australia. We are an inclusive organisation and every day we showcase our technology and expertise throughout the world.

Job Description
We are looking for two Data Engineers to join our IT team, based in Wollongong NSW or Mount Waverley VIC. Use your experience in analytics to unlock business value, enabling use of big data for insights and decision-making.
Reporting to the Data Product Owner for our Australian Steel Products (ASP) business, this position will support strategic goals related to data. This will see you:
Gather business and technical requirements with the view to deliver outcomes;
Develop and implement end-to-end data collection, consolidation, modelling and visualisation solutions;
Document metadata in a dictionary and catalogue;
Ensure consumers of such information understand its accuracy, timeliness, quality and sensitivity, so that it is used appropriately; and
Identify opportunities to enhance analytics.
What are the benefits?
Work in a supportive and collaborative team environment whilst we embark on a journey to transform the way our business uses data!
Our systems landscape is broad and diverse. You will be encouraged to think creatively to develop data solutions which solve real business problems.
Working in this role you will enjoy:
the chance to learn more about data science;
salaried remuneration with attractive superannuation options;
the opportunity to participate in a performance incentive scheme; and
access to further development and career opportunities with BlueScope.
Who are we looking for?
We welcome applications from professionals with experience in data analytics and/or programming. Supported by your knowledge of project delivery methods (e.g. Agile), you will demonstrate:
experience with data mining, wrangling, mapping and visualisation techniques (e.g. Azure Data Factory, Databricks and/or DevOps etc.);
well-developed ability in gathering business and technical requirements;
skills in developing and implementing collection, consolidation, modelling and visualisation solutions; and
a passion for sharing your knowledge and desire for ongoing professional development.

Qualifications

null

Additional Information
We're proud to have been named an Inclusive Employer for 2019–2020 by the Diversity Council of Australia. We believe that our people are our strength. Having a diverse and inclusive workplace enables us to improve our capability and ensure continued, sustainable success.
We know that workplace flexibility can mean something different to everyone. Under our B-Flex initiative all of our roles have some degree of flexibility. We encourage you to discuss your needs with us.
Applications close Sunday 25th October 2020.",3.3,"BlueScope
3.3",Wollongong,-1,201 to 500 Employees,-1,Company - Private,Construction,"Construction, Repair & Maintenance",$100 to $500 million (USD),-1
ETL Data Engineer,-1,"ETL Data Engineer

Join a team that’s changing how Australia lives, works, plays and grows
We want you to be the best version of you

Work with innovative teams and explore new technologies to help solve real-world problems.

A typical day as a Data Engineer

ETL / Big Data Engineering professionals will be responsible for guiding the full lifecycle of a Data solution, including:
Working in highly client-facing roles to contribute throughout the end-to-end delivery lifecycle of complex and large-scale digital solutions
Use case and business case development
Support existing and new applications utilizing in-depth technical and data knowledge. Troubleshooting complex issues and providing advisory services to improve the client’s data landscape
Help to streamline and simplify the clients’ complex data landscape by integrating different applications and data architectures
Implementation from requirements analysis, platform selection, digital architecture design, application design and development, testing, and deployment
Interstate travel may be required

Basic qualifications:
Bachelor’s degree
Experience across systems integration, information management, data management and architecture, and business analytics
Experience with being in a team focusing on large-scale, multi-release information centric projects
Experience with waterfall and agile delivery and run / application support functions
Part of a team working on End to end implementation of at least 1 big data project

Preferred Skills:
Hand on experience in Data warehousing using ETL tools such as DataStage, Autosys and TeraData
Hands on experience in ETL job development with multiple stages like sequential file, Transformer, Lookup, join, sort and Database stages.
Strong hand on skills in design, development and implementation of various data remediation, Data migration, data integration techniques.
Strong hand on data modelling experience.
Strong hands on experience in database performance tuning including complex query optimizations and physical database tuning using Teradata.
Understanding of architectural designs and strategy related to data migration, data cleansing, data quality and data consolidation.
Proven data analysis, requirement gathering and problem-solving skills
Exposure to Unix environment and shell scripting.
Experience in Banking and Financial services industry
Desirable: Knowledge of cloud computing infrastructure (e.g. Amazon Web Services EC2, Google Cloud, Microsoft Azure)
About Accenture

Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. We combine unmatched experience and specialized capabilities across more than 40 industries — powered by the world’s largest network of Advanced Technology and Intelligent Operations centers. With 513,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises. Visit us at www.accenture.com.

Accenture is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, marital, domestic or civil partnership status, sexual orientation, gender identity, or any other basis as protected by applicable law.

Vera Goga is the Recruiter managing this role. As the team experience high volumes of applications, we appreciate your patience to allow for a fair and timely process.",3.9,"Accenture
3.9",Sydney,-1,10000+ Employees,1989,Company - Public,Consulting,Business Services,$10+ billion (USD),-1
Student Engineer,-1,"The candidate will have the ability to:
Undertake onsite inspection to collect asset condition data based on the relevant engineering standards and technical guidelines;
Undertake desktop analysis to evaluate the condition and performance of the assets;
Provide the appropriate information, advice, engineering input and support services for the sustainable management of Council’s stormwater and transport networks.
Qualifications:
The successful candidate will be enrolled in a Bachelor of Engineering with a minimum of two years completed.
Position Number: 100678
Position Hours: Fixed term (3 months), hours will be negotiated with the successful candidate, maximum of 75 hours per fortnight.
Salary: Schedule A, Salary Point 4.0. $28.64 per hour ($55,853.45 per annum, pro-rata) in accordance with Glenorchy City Council’s Enterprise Agreement 2016
Please note that all successful applicants will be required to provide a current National Police Check prior to commencement of employment.
For further information on this position, contact Patrick Marshall, Senior Civil Engineer on (03) 6216 6800.
How to apply: Applications for this position must be lodged on this submission site or on the Glenorchy City Council website www.gcc.tas.gov.au - Careers page.
To be considered for this role, all applicants must address the key selection criteria in the and provide a current resume. A copy of the position description can be found by clicking the below hyperlink or on the Glenorchy City Council website.
Applications close at 8pm on Sunday, 1st November 2020
- Student Engineer",4.0,"Glenorchy City Council
4.0",Glenorchy,-1,501 to 1000 Employees,-1,Government,-1,-1,Less than $1 million (USD),-1
Data Engineer involving DevOps,-1,"Data Engineer involving DevOps
Axiom Technologies is an Australia based entity with the history of providing Managed IT solutions to medium to large scale enterprises globally. Please visit our website for more information about what we do at www.axiomtechnologies.com
Axiom Technologies is an Equal Opportunity Employer and encourage applicants from all backgrounds and gender to apply, including, Aboriginal and Torres Strait Islander candidates
Job Requirements:
8+ years IT experience, with at least 5+ years of “Data Engineer/Deveoper” focused titles/roles,
Data Tools: Hands on experience with Apache Beam.
Testing: Hands on experience with automated testing activities/outcomes
DevOps: Experience with the processes involving Microservices facilities for artifacts developed
Platform/OS: Mid-range/Unix
Languages: Unix (Shell) Scripting/commands, SQL, Python
File formats: Text, CSV, Parquet, JSON, XML
Scheduling: Jenkins, Airflow
Auto Scripting: Designing/creation of scripts for repetitive activity. E.g. Unix scripting/SQL
Big data: Exposure to Data Lake Concepts, Hive (Schema), HDFS
Source Control tools: GIT
Delivery Models: Agile, Scrum
Ingestion Design: Create/assess Source/Target data mapping designs
Frameworks: Development and delivery frameworks
Activity Reporting/Repository: Jira, Confluence.
Quality: Accuracy and attention to detail
Industry: Financial Services/Banking
Solutions: Define solutions from High level to detail design to address automating ingestion activity. Facilitate/confirm requirements from product owners, business team members and technical associates,
Process Automation: Automating processes in file management, testing data in files, analysis and design, configuration management.
Script Automation: Ability to design/create scripts to automate/improve data copy/migration/ETL for any repetitive activity.
Languages: Java, Python
Scheduling: Control-M
Databases: Relational. E.g. POSTGRESS, Oracle – as a ETL developer
File Formats: Mainframe – experience with referencing its data formats/copybooks
Big data: Experience referencing/using Hive (Schema) to access data in HDFS
Metadata management tools: MDM, EDC and Axon
Performance: Assess, recommend, improve mappings, SQL queries, Batch feeds
Automation Tools: Other tools that may add value to an automation program and generally support development. E.g. API, REST, JDBC, Webservices, Message Queues/Load balancer,
Cloud: Experience with processing of data files to be ingested/stored in the Cloud, preferably with AWS.
Prod Support: Experience in a production support role performing root cause / impact analysis – under time constraints
Experience in a similar role
8+ Years
What next?
If you are looking for that next challenge in your career and wish to apply for this role, please forward your resume to careers.au@axiomtechnologies.com",2.0,"Axiom Technologies
2.0",Melbourne,-1,1 to 50 Employees,-1,Company - Private,Industrial Manufacturing,Manufacturing,Less than $1 million (USD),-1
Data Engineer,-1,"About the Role
We are on an exciting digital journey so it’s a great time to join ME! We are seeking a Junior Data Engineer who enjoys rolling up their sleeves, learning and growing. As part of our Enterprise Data Team, you will ensure fit for purpose data warehouse solutions are built for use across the bank and by utilising best practise ETL standards, whilst ensuring the data is trusted by our BI developers and key business consumers. Oh, and you’ll get to work on Microsoft technology stack too!
You will be involved with investigating data issues, keeping data feeds flowing and collaborating with different projects across the bank to deliver quality data solutions. How important does that sound? What’s even more important is this role contributes directly to our overall business strategy through the provision of data to enable analytics & reporting, as well as supporting business and decision system processes.

About You
You’re naturally a highly motivated and energetic person who thrives in a dynamic, ever-changing collaborative team environment. Ideally you have previous experience as an ETL developer, Data Engineer or a BI developer, and if you have a degree in computer science or similar it would really put you ahead of the rest.

With your knowledge of SQL coding, data modelling, understanding of data warehouse concepts, plus experience of working on complex ETL solutions, you’re ready to expand your horizons and launch your career into the world of IT at ME.

About ME
We’re not like other banks.
ME was created by the industry super funds to be different from the pack – with a core purpose to help all Australians get ahead financially – no conditions, asterisks or exceptions. And we know that looking after customers starts with taking care of our people.
We believe everyone deserves the same opportunities in life, regardless of gender or identity, sexuality, ethnicity, religion or disability ‒ with internal affinity groups.
Perk ME up
Once you get your feet in the door at ME, we’ll put them both in your very own ME-branded Converse shoes. You’ll also get the following financial, health and fun perks when you join the team:
4U Extras portal (discounts and cashback on 100s of items including cinemas, shopping and gym memberships
10% Myki discount
Purchased Leave programme
Internal wellness programme (Mindfully ME)
Professional education through LinkedIn Learning
Novated Leasing
Professional membership reimbursements
Health checks
Financial education (To help you manage your money smarter)
LGBTIQ+ and Women at ME affinity groups

I want those Converse shoes (and the role)
Can’t see a closing date on the advert? That’s because we’re pretty efficient here at ME and we may start looking at applications sooner rather than later, so if this role sounds like your jam, be sure to apply by submitting your resume today.

Should an applicant be the preferred candidate, background checks (including police checks, reference checks, ASIC banned and disqualified persons and bankruptcy checks) will be completed prior to the candidate's employment being confirmed. The outcomes of the background checks do not automatically bar candidates; however will be assessed against the inherent requirements of the job.
Back Share
Apply Now",3.0,"ME Bank
3.0",Melbourne,-1,501 to 1000 Employees,-1,Company - Private,Banks & Credit Unions,Finance,$100 to $500 million (USD),-1
Software Engineer - Machine Learning/Data Science,-1,"Zendesk is looking for a Software Engineer - Machine Learning/Data Science for a full time position in our Melbourne office.
As part of our engineering team, you will work at a scale where the challenges start to get seriously interesting. Our global engineering team is widely dispersed over the world, with people across nearly every continent. You will get a chance to do cool things with a diverse bunch of people while working in the Melbourne office that is home to Zendesk’s first machine learning (ML) research team.
The Data Science Team, together with Data Engineering, have built Satisfaction Prediction, Answer Bot and Content Cues — products that use Machine Learning (ML) and Artificial Intelligence (AI) to help our customers work more efficiently.
What you get to do every day:
We’re currently looking for someone to join our team as we research, develop, and productionise Machine Learning and Deep Learning models. In addition to frequenting Melbourne’s finest purveyors of coffee, ramen, and bulgogi, you may find yourself:
Building machine learning models including neural networks in TensorFlow
Writing and deploying production-grade Python
Querying and constructing datasets in AWS Athena, Spark
Evaluating and responding to real-world model performance
Scaling your ML to millions of predictions per day
Presenting your work to a broader audience
Watching your algorithm help Zendesk’s end-users
What you'll bring to the role:
A strong foundation in a quantitative discipline (e.g. machine learning, statistics, bio/eco/etc-informatics, econometrics, etc) is critical for this position. While experience in deep learning and natural language processing would be beneficial, your best qualities are:
dedication to continuous learning
collaborative work attitude
strong communication skills
You should also be comfortable with at least one programming language, such as Python, R or Scala.
Application Deadline: 18/11/2020
Job Types: Full-time, Permanent
Salary: $85,000.00 – $110,000.00 per year
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Temporarily due to COVID-19",4.5,"Zendesk
4.5",Melbourne,-1,1001 to 5000 Employees,2007,Company - Public,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),-1
Software Engineer (Machine Learning),-1,"About the Role
AdelaideMRI is building a medical reporting tool. We require an engineer to work primarily on machine learning projects to improve reporting speed and report comprehensiveness.
You will perform data analysis of medical report datasets and image datasets to infer sentence recommendations, image classifications, or other actionable results for the doctors.
Skills and Experience
Background in machine learning or image processing
Qualifications in Computer Science, Software Development or Engineering or equivalent experience
Bonus points for Python
No prior medical knowledge is required.
This position offers flexible hours and work arrangements.
Job Type: Full-time
Experience:
Software Engineering: 1 year (Preferred)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Yes",-1,Adelaide MRI,Australia,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Hey there, we’re PEXA!

We started as an idea: to deliver a single, national e-Conveyancing solution. We collaborated with the industry to create a national electronic lodgement and settlement platform: PEXA. From our humble beginnings, we’ve now grown to more than 320 employees across 5 different states. We’re still expanding at a rapid rate and constantly challenging ourselves to create great experiences for our members as they transition to fully digital conveyancing.

Why become a PEXArian?

Great question! Being a PEXArian is so much more than just a job. We are passionate, motivated & unashamedly enthusiastic at PEXA - we love what we do and we’re proud to admit it! Creating brilliant member experiences wouldn’t be possible if we didn’t also strive to create an amazing employee experience. Alongside our members, our employees are at the heart of everything we do.
Here’s a snapshot of what your life at PEXA could look like:

Your growth:
We encourage you to hit your personal and professional Learning & Development goals with our tailored programs and tools.

Your wellness:
We care about your holistic well being - a fully stocked kitchen, four wellness days, a $250 wellness subsidy as well as lunch and learn sessions to support your financial well being.

Your work/life blend:
We know that work is just one aspect of your life, we want to help you create your ideal work/life blend, rather than squeezing in life around work.

Your family:
With a range of benefits aimed at supporting your family including access to a subsidised school holiday program, extended parental leave and flexi-time to support your return to work, superannuation payments for unpaid parental leave for primary carers and a childcare allowance for pre-primary aged children, when we say, ‘welcome to the family’, we really mean it!
The impact you'd drive:
The successful candidate will be responsible for developing, and maintaining infrastructure to support the delivery of new and existing products. They will also be contributing to establish the rules and frameworks for obtaining the required approvals for new products.
On day one we’d love you to have:
Experience with Python, Spark
Event streaming/sourcing with Kafka or AWS Kinesis
Experience with data structures, formats and data security best practices
AWS experience (e.g CloudFormation, S3, ECS, Lambda, SQS, IAM, KMS, DynamoDB, Glue, Athena)
Query construction and optimisation (e.g. SQL, Elasticsearch, Splunk, DynamoDB)
Git, version control practices, and continuous integration/delivery servers
PyUnit and unit testing frameworks
Production release cycles and maintenance
Collaborating with technical and non-technical teams
Even better:
Agile methodology/delivery
GraphQL
Modern frontend technology (e.g. ReactJS, TypeScript)
Machine learning frameworks and tools (e.g. TensorFlow, PyTorch)
OAuth 2, SAML 2, JWT
Data visualisation and exploration tools (e.g. Jupyter notebooks, Tableau)
AWS SageMaker
Sounds like you?
If this role sounds like you, apply today to have your application reviewed ASAP!",3.9,"Property Exchange Australia Limited
3.9",Melbourne,-1,201 to 500 Employees,2010,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Ongoing position
Full time
Based in Sydney, NSW
Who we are
Australian Red Cross is part of the world’s largest humanitarian organisation. Our aim is to improve the lives of the most vulnerable people in Australia and across our region.
About the role
The Data Engineer role will sit within the Data and Integration Squad in IT and will own (design, implement and support) the AWS Big Data technologies such as the Data Lake and Data Warehouse and support the organisation in growing the data analytics capabilities at Red Cross. In addition to this, the data engineer role will also administer the Power BI tool and support the implementation of the data mastering capability.
What you will bring
Experience building and optimizing data pipelines, architectures and data sets.
Experience in dimensional modelling and building data vaults
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with structured, semi-structured and unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Why work for us?
Work for purpose and know that your work assists Red Cross support and empower people and communities in times of vulnerability.
Generous salary packaging options available that can increase your take home pay.
Further information
To find out more about this opportunity please see the position description below or contact Sharath Kumar Gurram on 02 8651 8839.
Position Description: Position Description - Data Engineer .pdf
Applications for this position will close at 11:55pm Thursday, 5 November 2020.",4.1,"Australian Red Cross
4.1",New South Wales,-1,1001 to 5000 Employees,-1,Nonprofit Organization,Industrial Manufacturing,Manufacturing,$500 million to $1 billion (USD),-1
Junior Fullstack Data Engineer (Python and React),-1,"Formbay is the leading Renewable Energy Certificate Trading company in Sydney. We provide Digital Workflow and Compliance solutions in the renewable energy industry and document processing.
Thanks to our meteoric growth and our commitment to be the best at all we do, we've identified the need to bring on board a new Junior Fullstack Data Engineer.
Reporting to our Principal Machine Learning Engineer, you will help build Machine Learning pipelines for our existing Digital Workflow and Compliance solutions to automate fraud detection and document processing over terabytes of photographic and documentary data – including documents, photos, GPS data and aerial/satellite photography.
Our stack is based on Python, JavaScript, Dask, Tensorflow, CUDA, Nix/NixOS, AWS, Docker, PostgreSQL and more – familiarity with these applications will give you a leg-up on the competition.
Our ideal candidate will have the following competencies:
SQL
Python
JavaScript/TypeScript
Our candidate must also be comfortable working with Linux.
Located a stone's throw away from the Queen Victoria Building in Sydney's bustling CBD, we are centrally-located with easy access to public transportation, bars, cafes and fine dining.
Formbay will provide flexible working hours, a generous remuneration package and the opportunity to work on a world-first software solution are what we can offer you. Free, twice-weekly gym sessions and really, really good coffee are also available.
No hiring/recruitment agencies need apply.",5.0,"Formbay
5.0",Sydney,-1,1 to 50 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is an experienced and qualified Data Engineer to join our IT team based in Birtinya.
Key Responsibilities:
Create and maintain data pipelines and or ETL scripts
Create and maintain data integration including API and Batch interfaces
Performed detailed data analysis
Create and maintain corporate data models
Create and maintain data visualization using Qlik.Sense , PowerBI or Simliar Toolset
Experience in defining, building and maintaining data virtualization and/or star schema data warehouses
Maintain, tune and optimise database, integration and visualisation toolsets
ABOUT YOU:
To succeed in this role, you’ll need to bring the following experience and skills:
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Excellent communication skills both oral and written, with an ability to bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking
Experience with data analysis and modelling will be beneficial

How to Apply
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kawana Waters,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Graduate Data Science / Engineer,-1,"The NRMA is an organisation looking to the future, and right now, we are on the lookout for people who can help us reach our goal: to continue to shape the way Australians move, for the next 100 years and beyond. www.mynrma.com.au.
Everyone new to the team, along with our current staff, will temporarily work from home until it is safe to return to our offices. All interviewing and on boarding will be done virtually due to COVID-19.


Your opportunity
As Graduate Data Scientist or Engineer you will be part of the Data Engineering team delivering cloud data transition program for business initiatives and supporting the entire data platform build.
Your key responsibilities will be to:
Implementing Concepts of Data Warehousing, Data Mart creations within Cloud
Use of SQL for data analysis and insights
Building AI/Machine Learning prototype for implementing and supporting existing algorithms
Data Analytical reports build, using different tool sets


Requirements for Success:
Relevant Degree - Computer Science, Computer Engineering, Software Engineering, Data Science
Excellent SQL skills and demonstrated working knowledge in Python
Demonstrated understanding in data structure and algorithms.
Knowledge and concept of data warehousing methodologies
Any reporting tools experience Tableau or Oracle Analytics Cloud, Looker is desirable
Exposure to Google/AWS/Azure/Oracle any cloud based platforms is desirable
Good communication and interpersonal skills

If you have the required skills and the passion to join our high performing team, please apply today.

Employee Benefits
To ensure our employees feel valued, empowered and celebrated we provide a range of employee benefits including:
50% discount on all NRMA insurances
Free Roadside Assistance
12 weeks paid primary and 4 weeks paid secondary parental leave
Free NRMA Blue Membership
At the NRMA Group, we are People Moving People and diversity and inclusion are part of our DNA. Together, we continue to build an inclusive culture that encourages, supports and celebrates the diverse voices of our employees. It fuels our innovation, promotes flexible ways of working and connects us closer to our members and the communities we serve.",2.5,"NRMA Motoring & Services
2.5",Sydney,-1,501 to 1000 Employees,-1,Nonprofit Organization,Casual Restaurants,"Restaurants, Bars & Food Services",$500 million to $1 billion (USD),-1
Data Centre Engineer,-1,"We are a leading world group that provides low-carbon energy and services. To tackle the climate emergency facing us all, our aim is to become the world leader in the zero-carbon energy transition ""as a service"" for our clients – particular for companies and regional authorities. We use our expertise in our key business areas (renewables, gas, services) to provide competitive and bespoke solutions.
The Data Centre Engineer will be employed as part of a 24/7 ongoing shift to coordinate and monitor third party service providers, maintain the data centre facilities and infrastructure plans, coordinate the implementation of customer requests within the data centre and monitor systems, all in accordance with the Contract KPIs and SLAs.
Coordinate and monitor third party service providers for regular maintenance & testing, service faults & call outs, ensuring works are performed in accordance with Contract SLAs
Monitor and maintain the data centre facilities and infrastructure plans and documentation, including electrical, mechanical, hydraulics, fire and BMS/EMS systems
Coordinate the implementation of internal and external customer requests within the data centre
Perform scheduled plant checks and minor maintenance works
Ensure all Work Order requests are raised and closed in a timely manner
Conduct inductions for staff, vendors and contractors
Ensure all work permits for vendor works are raised and closed
Perform inventory checks on all equipment and critical spares

Qualifications
The selected candidate must be able to demonstrate:
Electrical or HVAC background, or Graduate Electrical or Mechanical Engineer
Passionate about quality work and career minded looking for a new challenge
Can commit to a day and night shift roster (2 days of day shift, then 2 days of night shift, 4 days off)
Ideally able to commence asap
As part of carrying out the duties of this role, it is mandatory to hold Australian Citizenship.

If you are interested and meet the selection criteria apply with an up-to-date resume via the apply instructions on this website.

ENGIE Services is an EEO employer, where all applicants are treated with fairness and respect and have equal access to the opportunities available.

We will not be engaging in the services of a recruitment agency to fill this vacancy and therefore request all interested candidates apply directly to this advertisement.

Job
: Maintenance
Primary Location
: Oceania-Australia-New South Wales-Erskine Park
Organization
: ENGIE Services Australia and New Zealand
Schedule
: Full-time
Nature of Responsibility
: Senior operational / administrative role
Job Posting
: Sep 11, 2020, 6:29:59 AM",3.7,"ENGIE Services Australia & New Zealand
3.7",Sydney,-1,5001 to 10000 Employees,1995,Company - Public,Energy,"Oil, Gas, Energy & Utilities",$2 to $5 billion (USD),-1
Senior Data Engineer,-1,"Senior Data Engineer, Temporary, SYDNEY - McKell

Job Title: Senior Data Engineer

Salary: SNSW Grade 9/10 - The package includes base salary range of $111,806 to $134,667, plus employer's contribution to superannuation and annual leave loading.

Location: Head Office – Haymarket

Employment Status: Temporary through till 30th June 2021


About Service NSW:

Service NSW is making it easier for people and businesses across NSW to access government services. The role designs, builds and analyses complex data from multiple sources to identify revenue, process and business improvement opportunities; providing new information and insights to the business to inform planning, continuous improvement and performance.

About the Role

We are currently seeking to appoint a Senior Data Engineer to deliver expert advice and services in the design of a Single View of Customer and data-related services to support the achievement of business outcomes and strategic goals. We support flexible working practices with staff working remotely during this time.

In this role you will:

Design, build and support a modern data platform based in AWS and vendor technologies.
Provide expertise on data modelling for Graph data model and Customer Data Platform (CDP).
Create data pipelines, load, transformation and reporting workloads in AWS.
Work with the latest data engineering technologies like Apache Kafka, AWS Kinesis, AWS Neptune, AWS Glue and AWS Athena.
Contribute to the design and decision-making of the right tool or platform for the job according to requirements.
Provide expert advice and guidance on data quality and data engineering best practices.
Support a “bigger than you can imagine” scale of data in production environments.
Design, develop and support a metrics-driven reporting solution and a meaningful business intelligence platform.
Document the solution design and support procedures of solutions.
Produce reports, visualisations and recommendations to answer complex business problems that are presented in the most appropriate format to ensure clarity for target audience.
Analyse and define new process improvement opportunities to support continuous improvement and business outcomes; providing advice to stakeholders, on ways to improve the efficiency and reliability of data products and services.
Be very responsive to the information needs of the business by corresponding to customers in a timely manner and provide support/solutions to issues raised.
Troubleshoot and perform root cause analysis on production issues. Identify and implement long term solutions to problems. Perform scheduled maintenance, release deployment and production support activities after business hours, from time to time.
Liaise with internal and external customers to discuss and gather requirements, solutions etc. and maintain a good working relationship with the stakeholders.


Skills and Experience Required:

Solid experience with workflow technologies designing and building data pipelines, data models and data stores.
Experience working within and an understanding of Amazon AWS ecosystem, including security and performance tuning.
Hands on experience working with different types of databases, with focus on Graph and NoSQL databases.
Experience with data streaming required. Having used Kafka and related technologies is an added advantage.
Sound knowledge and experience working with batch processing, data extraction and API integration.
Hands on experience with at least one programming language: Java, Python or scripting.
Demonstrated experience working in an Agile based, fast paced, complex environment within cross-functional teams.
Experience developing systematised insights, data analytics and reporting solutions is an added advantage.
Experience with interactive visualisation of data insights is an added advantage.


Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Salary Grade 9/10, with the base salary for this role starting at 111,806 base plus superannuation

Closing Date: 6th November at 9:59am - applications will be reviewed on a rolling basis, applications may close early or extend

Please apply online, direct applications submitted via email will not be considered.

The Department of Customer Service is proud to be an EEO Employer who are fully focused on equality and believe deeply in diversity of all identities making us different and a true reflection of our NSW customers. As an inclusive workplace, we support various employee resource groups, practice flexible work and workplace adjustment.

If you do require an adjustment during the recruitment process, please notify us on your application form.",3.2,"Service NSW
3.2",Sydney,-1,501 to 1000 Employees,2012,Government,State & Regional Agencies,Government,Unknown / Non-Applicable,-1
Data Engineer - Entry / Mid Level,-1,"Work with a great team on interesting projects customers
Gain more experience in AWS, Data, DevOps cloud operations
Got a working knowledge of AWS? We will teach you the cool stuff!

Itoc is seeking an up and coming Data Engineer to join our growing Data Team in Sydney.

This is an exciting role working with databases, data lakes, data warehouses, data transformation (Python SQL) and enabling AI/ML.

You will be implementing foundational, robust and production ready data platforms to enable business data-discovery, self-service, AI/ML functions across a range of client types and industries, allowing them to do more with their data.

You'll be responsible for:

Deploying data repositories such as lakes and warehouses.
Contribute to our growing portfolio of data solutions.
Ongoing optimisation and management of data platforms.
Development of transformational logic for data pipelines
Data evangelism. We want to show our clients how to follow the best practices for data.

Desired Skills and Experience

To take up the challenge, you will have a depth of skills and experience including:

1-2+ yrs of focused data experience working with SQL and/or NoSQL solutions
A solid education in Software Engineering or equivalent industry experience.
Anything Data focused preferred.
Ability to analyse business scenarios and associated data landscape to derive potential opportunities.
Strong foundation in Python and SQL
Working knowledge of APIs
Principle knowledge of the different relational database platforms and modern data storage techniques
Knowledge of the different aspects of data environments
Collect, store, process, verify consume
Experience with version management systems (such as GIT)
Working knowledge of AWS or another cloud platform - we will teach you the cool stuff.
Great communication skills, an ability to work closely with customers, developers and engineers and the confidence to present ideas in open forums.
Relevant tertiary qualifications and/or industry certifications.
Great communication skills, an ability to work closely with clients, developers and engineers and the confidence to present ideas in open forums.

While not required, a background in consulting and professional services is highly desirable.

Itoc Description

This is an exciting and challenging career opportunity to join the growing Sydney-based Data Team of a leading cloud solution provider where you will be given support to reach your long term career goals. You will be part of a team of cloud experts and will work in an environment of continuous improvement and learning delivering innovative cloud solutions across SaaS, online business and enterprise business.

On offer is a chance to join a team with a great working environment, in an organisation that values its employees and sees the value in ensuring they are engaged. Our team are clearly passionate about what they do, that's why we won the following awards:

Customer Obsession Partner of the Year 2015: ANZ Region
Customer Obsession Leadership Partner 2015: re:Invent

As an employer of choice Itoc offers competitive remuneration, training and development programs and a great working environment. We value a healthy work life balance.

The Perks

MacBook or Dell
Continuous internal learning that will provide training and career development opportunities
Working with a collaborative, social team and leveling-up your skills faster than you will anywhere else.
Quarterly social events

Itoc

Culture and smarts are important to us. Bring your secret sauce. This is no ordinary environment, you will work along some of the Cloud’s best. All engineers at Itoc must gain at least five AWS certifications. We work hard but we have fun.

Please note you must have full working rights in Australia and be available on-shore for face to face interviews.

No recruiters please.",4.0,"Itoc
4.0",Sydney,-1,1 to 50 Employees,2013,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Date: 01-Oct-2020

Location:
Melbourne, VIC, AU

Department:Description:
Technology discounts - from Apple HP Lenovo to Windows
Flexible work arrangements - work in a way that suits you best
Salary packaging - to suit your personal and financial circumstances

Do you want to work for one of the fastest growing data teams in Australia? Do you want to work on multiple data platforms and provide new solution offerings by leveraging cloud and big data technologies?

About the team

Big data information and analytics. Three words that spark apprehension in most businesses. But our team of experts are constantly curious and excited about combining our wonderful array of technological expertise to transform data into our clients most valuable assets making their work smarter. Our data consultants are supported with resources training and tools they need to excel at their work but also the freedom and power to create their own paths forward to make a difference.

As a Senior Consultant in Big Data you will work closely with the team and stakeholders to build and deliver a Cloud based vision for a next generation Big Data analytics platform with strong focus on data quality data security and deliver the systems that process huge volumes of data.

What will you typical day look like?

You will play a pivotal role in - Designing and producing high performing and stable applications to perform complex processing of massive volumes of data in a new cloud based architecture; Building real-time data processing applications which are integrated with business systems to enable value from analytic models to drive rapid decision making; Contributing to system architecture design for a data platform (including cloud-based structures both on and off premises data warehouse components and data lakes); this could cover a range of technologies various countries/locations and lines of business; Support data strategy or technology strategy definition programs including technology stack definition and target operating model requirements

Enough about us lets talk about you:
You are someone with:
Use of traditional data analytics tools and techniques (e.g. MSSQL Oracle MySQL) and ETL software (e.g. SSIS Informatica CloverETL)
Working in large scale cloud data solutions using platforms such as AWS or Azure or GCP will be a bonus.
Experience in scripting or programming (e.g. Python Java Scala C#)
Excellent verbal and written communication skills to adapt to technical and non-technical audiences.
Educated to degree level (or have equivalent experience)
Why Deloitte?

At Deloitte we create positively differentiated work experiences that enable our people to feel valued and achieve their full potential. We value difference and embrace people with diverse backgrounds and thinking styles. Knowing that people work best in different ways we are happy to discuss alternative arrangements if the working pattern you are looking for is not specifically indicated.",3.8,"Deloitte
3.8",Melbourne,-1,10000+ Employees,1850,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Engineer,-1,"Opportunity to grow the team
Period of growth
Intuitive app
S2M are working with a FinTech who have created a unique financial product to help thousands of people better manage their finance, and is currently scaling the company to the next level!

They are looking for a Data Engineer to join, and looking for someone who wants to be hands on, with opportunity to grow the team in future.

Role:

Looking for people with strong AWS experience. You will need passion for data and a cloud, through which you will help a rapidly scaling Australian FinTech establish their data infrastructure from the ground up.
5+ years’ experience as a data engineer within the data and analytics domain
A python 3.X aficionado who is very comfortable creating and orchestrating AWS data pipelines with nothing but code
Strong project delivery toolset experience in open source data integration tools
Experience with processing large volumes of complex data including visualisation and insights generation
Ability to define and develop data integration patterns and pipelines
Ability to assess complexity of data (volume, structure, relationship etc.)
Hands on experience working with different databases (RDBMS, NoSQL, Blob storage etc)
Hands on technical expertise setting up DevOps automation
Hands on experience working technologies/platform e.g. AWS, Dockers, Containers
Experience building data profiling and data cleansing frameworks
Technical reconciliation and reporting
Knowledge and experience in end-to-end project delivery, either traditional SDLC or agile delivery methodologies (or hybrid approaches)
Exceptional communication, documentation and presentation skills
If this sounds like you, get in touch today - kate.gabb@s2m.com.au
3167410agsdf",3.1,"S2M
3.1",Sydney,-1,Unknown,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Analysts,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is seeking experienced and qualified Data Analysts to join our IT team based in our corporate office in Birtinya (Sunshine Coast) or at our meat processing facility in Kilcoy.
Key Responsibilities:
A mixture of data analysis and commercial skills to source, blend and analyse data to gain insight and answer key commercial questions
Working with strategic leaders to define and model Key Performance Indicators, and assist in building forecasting models
Working closely with data engineers and BI developers to specify data pipelines and report visualisation
Drive the creation and implementation of data quality business rule including data definition, governance and quality assurance
About You:
To succeed in this role, you’ll need to bring the following experience and skills:
Proven ability to derive insight and knowledge from data using commercial expertise is a strong requirement
Strong SQL and Excel skills are essential, along with strong data analysis and commercial insights
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Effective people communicator - engage with stakeholders on reporting needs, interpret requirements into visual solutions and train/deliver the outputs to the stakeholders getting signoff of acceptance
Bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking

How to Apply:
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kilcoy,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Network Data Engineer,-1,"Min 6+ years of experience in the relevant technologies
Australian Driving License for visiting remote locations / Data Centre for day to day technical work.
Managing Network devices (switches, routers, firewalls, load balancer, and wireless technology)
Performing MACD activities for all network devices.
Supporting BAU operation activities.
Proficient in performing in-depth details of technical troubleshooting, cause and provide recommendation to the client for incidents causing extended network outage to client’s critical locations.
Provide exceptional network services in terms of network support, break-fix, design and consulting, new projects, implementation.
Configure, administer, and document firewall infrastructure.
Manage the firewall deployment, rules migrations, and firewall administration.
Supporting Cloud Migration Activities from traditional to AWS/Azure.
Setting up VPN tunnel with Cloud and 3rd Party network devices.
Integrating and upgrading existing ISP bandwidth with support from ISP Vendor.
Setting up VPN profiles for Users.
Installing hot fix and patches to mitigate the security devices from attacks and bugs.
Reviewing and fine tuning the firewall rules and NAT rules.
Documentation and change control.
Mentoring, Motivating and Guiding support teams
Technical skills:
o LAN
o Wireless
o WAN
o MPLS
o Routing protocols (OSPF,BGP)
o DMVPN
o Azure cloud Networking
o Network Security
Fortigate Manager / Analyzer / Firewall
Cisco ASA
Firepower FTD
Cisco Any connect
Site to Site VPN
F5 Load Balancing and Scripting iRule
Job Types: Full-time, Contract
Schedule:
8 hour shift
Experience:
Scripting: 5 years (Required)
Data Network: 5 years (Required)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Required)",3.6,"Total IT Global
3.6",Sydney,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Engineer - Processing & Analysis,-1,"Job Description:
Design,build and maintain the ingestion system to support various types of data(e.g. User behavior, RDS, NoSQL db and others) to be ingested to the data warehouse more timely and accurately
Translate data requirements into scalable technical data service with low latency and high concurrency
Design,build and maintain the batch or real time data pipeline in production using Hadoop big data technology
Analyze and improve efficiency, scalability, and stability of the system
Define and manage SLA,Data quality for all data sets in allocated areas of ownership
Requirements:
Minimum B.S. degree in Computer Science or a related technical field
2+ years of working experience in programming languages,such as Java,Scala,Python
Familiar with Hadoop, Spark and Flink data processing, experience of TB data processing experience is a plus
Familiar designing and operating of a robust distributed system is a plus
Understand data mining or machine learning
Excited to work intimately with data
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"SYNOPSIS:
Lead Data Engineer
Applications close Sunday 8 November 2020
Ongoing
Contact name: Shyni Sasikala
Phone: (02) 6249 9048
Email: Shyni.Sasikala@ga.gov.au

The Data Policy and Informatics section within the Digital Science and Information branch creates, implements, and promotes policies, platforms and tools that improve and support the quality, discoverability, accessibility, and general usability of Geoscience Australia’s science data products. The section consults with internal and external research, government and industry partners to establish collaborative data frameworks, architectures and models within Geoscience Australia (GA) and across broader national and international communities of practice. The section innovates, builds and maintains tools, systems, processes and governance that enable digital data management, cataloguing and open data delivery.
GA makes accessible a wide range of geoscientific and spatial data to a wide variety of stakeholders in multiple formats, and in recent years GA's data volumes have grown exponentially. GA is focussed on making its data and metadata assets accessible so that they can be used in machine to machine interactions for data analytics and other applications in environments that range from High Performance Computing (HPC), through high-end cloud servers, to mobile devices.
We currently have two opportunities for Lead Data Engineers in the Informatics team. The Lead Data Engineer is responsible for innovating and exploring new technologies that will advance GA’s science goals and maximise the uptake and use of GA’s science data. The Lead Data Engineer reports to the team’s Assistant Director but also works closely with other developers, data scientists and engineers within the Digital Science and Innovation (DiSI) branch, as well as diverse stakeholders both within and external to GA.",3.9,"Geoscience Australia
3.9",Canberra,-1,501 to 1000 Employees,2001,Government,Federal Agencies,Government,$100 to $500 million (USD),-1
Data Engineer,-1,"The Seven Network is part of Seven West Media, one of Australia’s most prominent media companies, with a market leading presence in content across broadcast television, online and in print. Comprising some of Australia’s most renowned media brands, SWM includes not just Seven Network and its affiliate channels 7two, 7mate, 7flix and BVOD offering 7plus, but also 7NEWS.com.au, The West Australian, The Sunday Times and more.
At Seven we are here to bring all Australians closer to the moments that move us - we’re first on the scene, with our finger on the pulse, on demand, in the moment. Together, we’re responsible for creating and sustaining authentic Australian engagement.
A new and exciting opportunity has opened for a Data Engineer to join the Audience Intelligence team. Based in Sydney and reporting to the Head of Data Enablement, you’ll be responsible for:
Implementation of end to end data solutions to support Data Strategy for the SWM group.
Work closely with the Data Solution Designers to develop and maintain scalable data pipelines and build out new file and API based integrations to address requirements from the various business stakeholders.
Collaborates with engineering, analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organisation.
Work on Data Preparation for analytics and data scientist team members and assist them from an engineering perspective in building and optimising the models including building the automation of the end to end workflows
Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.
Perform data analysis required to troubleshoot data related issues and assist in the resolution of production data issues.
Work effectively with vendors for successful delivery of projects and acceptance of the solution
Work on Delivery projects using Agile Software Development methodologies
We are looking for someone who has:
Bachelor's degree in computer science, computer engineering or other technical discipline is essential
Proven experience working as a digital analytics specialist
Extensive experience with digital analytics implementation (e.g. Google Analytics, Snowplow, Adobe Analytics) and BI processes and visualisation platforms
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience in ETL and building and optimizing ‘big data’ pipelines and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Experience with big data tools: Hadoop, Spark, etc., AWS cloud services: EC2, S3, Lambda and familiar with version control systems: Git
Strong coding skills with knowledge of Unix/Linux and scripting languages such as Unix Shell scripting, Python desirable
Experience supporting and working with cross-functional teams in a fast-paced environment.
Ability to multi-task and problem solve with changing demands and priorities
Ability to work under pressure to meet deadlines and detail oriented
Your success is our success: we will provide you with opportunities for you to keep learning and growing, enabling you to challenge and develop yourself. In return, we offer a benefits program that has something in it for everyone.
Seven West Media is an equal opportunity employer and we are committed to creating a diverse and inclusive workplace.
Recruitment Agencies: Seven West Media does not accept any unsolicited agency resumes and will not be responsible for any fees related to unsolicited resumes.
Advertised: 19 Oct 2020 12:00 AM AUS Eastern Daylight Time
Applications close:

Back to search results",2.5,"Seven West Media
2.5",Sydney,-1,5001 to 10000 Employees,1956,Company - Public,TV Broadcast & Cable Networks,Media,Unknown / Non-Applicable,-1
BICON Rules Engineer,-1,"APS 5 - $73,299 - $80,410 per annum plus superannuation
Biosecurity Plant Division
Canberra, ACT
Play an active role in managing biosecurity risk to Australia
Work in a motivated and professional team with a wide range of skills and backgrounds
Full training provided

Who we are
The BICON Content Development Team maintains and improves the Biosecurity Import CONditions database (BICON) content to allow external clients to understand and comply with their biosecurity obligations and internal clients to effectively manage biosecurity risk and regulate imports. We work collaboratively with internal clients to comprehend and implement their BICON content requirements and optimise the use of BICON to publish clear import requirements and onshore management support procedures to effectively manage biosecurity risk.

The Jobs
Key duties of these positions include:

working with business content (import and permit conditions) and import programs to understand and construct decision tree structures in the BICON database, in accordance with system design and authoring conventions
executing changes to import and permit conditions in alignment with service standards while complying with system rules and authoring conventions
providing technical advice through various formats on the most appropriate means of authoring BICON content to achieve import program and stakeholder objectives
using workflow management tools to maintain detailed records of changes to import conditions and key decisions
performing administrative tasks including system reporting, data analysis and scoping tasks for the BICON content change work program
contributing to the development and maintenance of instructional material, authoring conventions and courseware
clearly documenting and reporting system issues
developing and maintaining effective working relationships with internal and external stakeholders.

What we are looking for
Knowledge and experience
Experience working with complex IT systems.
Experience working collaboratively and as part of a team.
Knowledge of the role of biosecurity is preferred but not essential.

For additional information, please read the Job Description below.
Candidate Information Package docx Opens in new window",3.9,"Department of Agriculture & Water Resources
3.9",Australia,-1,5001 to 10000 Employees,-1,Government,Federal Agencies,Government,$500 million to $1 billion (USD),-1
Cloud Data Engineer,-1,"Job no: 509605
Work type: Permanent Full Time
Location: Melbourne, Canberra, Sydney
Do you embrace digital disruption?
Do you love solving complex problems, designing sophisticated solutions and building innovative technology?
Do you believe in creating powerful actionable insights from Data and Analytics?
Do you want to work in a diverse and flexible working environment?
KPMG is one of the most trusted and respected global professional services firms. Through depth of expertise, clarity of insight and strength of purpose we help our clients solve complex challenges, steer change, strengthen, transition and grow. We are a team based practice and this extends to our clients whom we work and collaborate with, in solving complex problems. Together, we design, innovate and implement, providing enduring advice that support our clients and the services they deliver. Our clients vary in size and come from a diverse range of sectors – all sharing in a common goal: to embrace change and deliver services that make Australia a better place. We are looking for talented individuals who would like to join us on the journey.
KPMG’s Digital Delta Team
We re-imagine and re-invent organisations to become world class digital enterprises using advanced technologies, data and human insights. We help organisations to embrace Digital Strategy, Artificial Intelligence (AI) & Cognitive, the Internet of Things (IoT), Data, Analytics & Modelling, Mobile App & Web, and User Experience (UX) & User Interface (UI) and more.
We work with clients to:
Formulate strategies that re-imagine organisations
Harness innovation from the 4th industrial revolution
Actioning insights from trusted data to consistently and quickly make clear decisions
Build adaptive organisations
Thrive as a connected enterprise – front, middle and back office
This is how you’ll contribute:
We are looking for ambitious Data Engineers who are passionate about helping clients define bold ambitions and deliver on them. Joining our team will take you on a journey of personal and technical growth and provide the opportunity to inspire confidence and empower change.
As a Data Engineer you are the designer, builder and manager of the information or ""big data"" infrastructure, preparing data for analytical or operational use. You will design, construct, test and maintain a data pipeline to pull together information from different source systems; integrating, consolidating and cleansing data; and structure it for use in individual analytics applications.
The KPMG Difference
Our people are focused on creating a diverse and dynamic environment that embraces and values differences. We value the variety of unique experiences, qualities and characteristics our people possess and we share and learn from each other.
We are proud to be consistently recognised as an employer of choice for women, and for our achievements in LGBT+ workplace inclusion.
Our commitment to ‘Flexibility’ allows our people to manage the changing demands of work, personal or family life. Explore the links below to hear our people share their experience @ KPMG:
Flexibility empowers wellbeing
Flexibility enables contribution to the community
Flexibility inspires technology & innovation
Flexibility supports family

Make KPMG the clear choice for your career and be Extraordinary!

Advertised: 09 Sep 2020 AUS Eastern Standard Time
Applications close:",3.8,"KPMG
3.8",Sydney,-1,10000+ Employees,1987,Subsidiary or Business Segment,Accounting,Accounting & Legal,$2 to $5 billion (USD),-1
Computer Network and Systems Engineer,-1,"Duties Include but are not limited to:
Tasks Include:
analysing, developing, interpreting and evaluating complex system design and architecture specifications, data models and diagrams in the development, configuration and integration of computer systems
researching, analysing, evaluating and monitoring network infrastructure to ensure networks are configured to operate at optimal performance
assessing and recommending improvements to network operations and integrated hardware, software, communications and operating systems
providing specialist skills in supporting and troubleshooting network problems and emergencies
installing, configuring, testing, maintaining and administering new and upgraded networks, software database applications, servers and workstations
providing network programming in support of specific business needs and requirements
preparing and maintaining procedures and documentation for network inventory, and recording diagnosis and resolution of network faults, enhancements and modifications to networks, and maintenance instructions
monitoring network traffic, and activity, capacity and usage to ensure continued integrity and optimal network performance
Skills and Experience Required:
Must have experience working in a Managed Service environment
Demonstrated experience in IT Networks and Data Centres
Understanding of systems and architectures to meet client needs
Experience in Help Desk including break / fix
Effective and timely documentation
Effective Task Management Skills
Be solution and outcome focused and willing to learn new technologies
Excellent communication skills with staff, clients and partners
Time management, ability to prioritise and deliver to schedule
Experience with N-Able and Connectwise desired
Open Cabling license desired
Job Types: Full-time, Permanent
Salary: $30.00 per hour
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,Trans-plant training,Canberra,-1,-1,-1,-1,-1,-1,-1,-1
Software Engineer (Data),-1,"If you are looking for an opportunity to make a real impact with smart people who are genuinely doing things differently then you've come to the right place! We're growing our data engineering capabilities and are looking for awesome data engineers to join our team.
With our diverse range of clients and projects, no day will look the same - but here's a great snapshot of what you'll be doing:
Work with some of the best Data Scientists and Engineers to deliver production-grade AI and Machine Learning systems as we deliver client projects from inception to production.
Consulting with our clients and working with them to build modern data systems using the 'best of' technologies and principles.
Advising clients on data strategy, architecture and technology.
Applying best software engineering practices in coding, monitoring and alerting, using CI/CD, TDD and cloud architectures.
Working over a wide range of big data tools and environments: not limited to; Apache Kafka, Spark, Python, Scala, Hive, Airflow, AWS EMR & Glue, GCP Dataproc & Dataflow, BigQuery, Snowflake, Redshift.
Who are we?
Glad you asked! We are Eliiza. Data science. Engineered for scale.
We are a passionate team of data scientists and engineers who apply data science and machine learning to solve real-world problems. Our mission is to create a bright future for Australian businesses and society in a world increasingly influenced by intelligent technologies.
We've created a culture that values diversity where people can truly be themselves! We care a lot about growing the Australian AI community in a positive direction, and we're doing several things to try and achieve that:
We provide opportunities for underrepresented groups to work in AI through our associate and intern programmes
We organise and participate in a range of community events, reading groups and meetups
We produce the AI Australia podcast
We blog about topics we care about
We stream brown bag sessions to the broader community
We're also part of Mantel Group's 'house of brands' which means it's not just the Eliiza team you'll work with, learn from and see at social events - there's another 230 of us across DigIO, Kasna & CMD Solutions!
So you're ready for something new?
We're keen to know more about you! Our team is made up of a range of people, with different experience across a huge range of data driven skill sets.
We'd love to hear from you if you have experience with:
one (or more) core language(s), ideally Scala, Python or Java
one (or more) cloud platforms, AWS, GCP, Azure
ETL/ELT concepts and technologies e.g. Data partitioning, Hive, Spark
streaming data concepts and technologies, ideally Kafka (Kinesis, Beam or Pubsub will do)
We'd be over the moon if you:
Experience with distributed/columnar databases (e.g. Snowflake, Big query, Redshift).
Experience with any of a variety of databases e.g. RDMS, NoSql, Columar, Distributed, Time series, Graph.
Knowledge of job orchestration and scheduling. Any experience with Airflow, Luigi or Oozie.
Experience with containers and container orchestration (Docker, Docker Compose or Kubernetes).
However, we value a diversity of skill-sets, and don't necessarily require that you're skilled with all of the above. If you feel you don't fit all the experience/skills listed above we still encourage you to apply or get in touch.
What's on offer if you join us?
We make sure you're always one step ahead by investing your learning and development, every year. We build our own training where it doesn't exist yet.
We hire smart people and get out of their way. By focusing on our five principles and not getting caught up in red tape, we trust you to get the job done.
You'll get all the tools you need - a new iPhone or Google phone, a new Macbook Pro or Dell, and a lot of branded swag!
But hold on, you mentioned a house of brands?
We certainly did! Mantel Group is an Australian-owned, 'house of brands' company with four technology businesses (Eliiza being one of them!) across Melbourne and Sydney. We're building a group of companies with open borders so we can support you to take on new skills without leaving an awesome team - we understand you won't have one job for life!
We may only be just two years old but Mantel Group has already been recognised #9 in the 2020 Best Places to Work in Australia and #4 in the AFR's 2020 fastest growing new companies.
Keen to chat?
Click ""Apply"" to share your details with our talent team, and we'll be in touch.
In the meantime, check out 'how we hire' to find out what's in store if you're successful and get to know us better by visiting our website and following Eliiza on LinkedIn.",-1,Eliiza,Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Infrastructure Engineer,-1,"Job Description:
Design and grow the Shopee data platform to support a variety of big data applications using open-source technologies including Kafka, Hadoop, Presto, HBase, Spark, Hive, Druid, and our own creations. Some examples include a real-time data streaming platform, a unified query platform, a cluster management system, and a machine learning platform
Dig into the source code of some open-source big data system to get the whole control and familiar with the details, configurations, designs and source code. Develop and maintain the internal release of big data systems and components as the business requirements.
Keep close and overall monitoring for all the deployments of the systems, maintain the system’s stability, improve the performance, discover the performance bottlenecks, tracking and troubleshooting, cost optimisation.
Requirements:
B. Sci. / Ms / PhD in Computer Science or a related technical field
Familiar with at least one of these languages: Java, Scala, Python, Bash under Linux / Unix. Scala is a plus
Familiar with the use and compute logical of SQL
Knowledge about the Big Data Infrastructure system technology like Distributed File System, Distributed Computing, Distributed Database will be a plus
Hands-on experiences Hadoop, Spark, Kafka, and/or Presto will be a plus
Love to use and develop open-source technologies
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"Work on an award-winning, international technology!
Endless career opportunities
An innovative, friendly team of 300+
This role will be focused on the development of our existing ClaimLogik line of products as well as working on our new cloud-first, modern suite of applications.

Intelligent Thought, our technology business is scaling and shipping our software globally. Already profitable, part of a much larger group business, with investors such as Macquarie Capital and Envest – we are all set to deliver textbook disruption to the Insurance Industry. The growth of the platform, of our customer base, and the increasing industry demand have led to the need for this role to help the team scale.

Our Philosophy
Give each employee a sense of purpose and an environment for them to connect the importance of their role to delivering a service that matters to our customers.
Challenge the ‘why’ of traditional claims processes.
Keep it simple – do only what brings value and what matters to the customer
Enable employee decisions, empower our people
Responsibilities:
Create, extend and maintain ETL pipelines to form our data lake, data warehouse and analytics platform (currently using the Microsoft Azure set of tools and service)
Help define the optimal data pipeline architecture
Influence the tool selection, platform selection, data architecture and strategy which will transform the business to be truly data-driven
Understand, analyse and size user requirements
Work with different parts of the business to provide them with the insights they need to deliver the best results
Skills & experience:
Degree or qualification in computer science or related
Advanced knowledge of relational database, including query authoring and query optimisation (MS SQL Server and PostgreSQL).
Experience building and optimising ETL pipelines
Experience designing complex data models
Experience working with cloud platforms (Azure or AWS)
Efficient time management and organisational skills
High attention to detail and accuracy
Effective communication skills to build strong working relationships; both written and verbal
Proactive and results-driven
Why Claim Central?
Claim Central Consolidated is a global insurance industry leader across, claims management, insurance technology and data and analytics. Currently operating in the United States, Australia, South Africa, Italy and New Zealand, we have pioneered digitally connected claims management services across the globe. Claim Central is a disruptor and thought leader in the industry and we were recognised as the Australian Financial Review’s 8th Most Innovative Company in Australia in 2016. This business is in a period of unprecedented growth, transitioning our technology and services into multiple geographies at a rapid pace. Our unique culture is based on teamwork, collaboration, trust, respect and performance. We also offer many benefits apart from our exceptional team culture; including flexible work arrangements, and continued professional development.

Be a part of this journey in a career-defining role.",-1,Claim Central,Matraville,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer - AI/ML,-1,"Our client provides services to a major industry across the country. The business is still early in it's days of technology development and the environment is greenfields in nature (no pun intended), effectively working like a start-up.

Their data and analytics team have worked and built leading and bleeding-edge technologies in this space and what they have created so far may be game-changing. From a machine learning perspective, the progress they have made to the business has already seen proven success in changing the future of an industry that will have positive consequences for all those involved.

You will have previously worked in a technical capacity in the data and analytics space and have experience working with an organisation where machine learning has been implemented, not just a concept that the business talks about having or the technology team would love to have. The commercial experience you will have had in the ML field will be proven examples of where you have affected the way a business or industry used to perform, to the changes that have come about from this.

Technically, you will have extensive experience in the Microsoft space - Power BI, Azure etc and you will have previously mentored and coached junior members of the teams you have been part of.

This is a rare opportunity in Brisbane where the business has truly embraced and funded projects across the ML space and would be a great chance for those in the Data Development/Data Engineering field, who are looking to move into a Data Scientist role in the future.

Please send your application through if you would like to know more.",4.0,"Emanate Technology
4.0",Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Solution designer/ ETL Engineer & Data Modeller,-1,"We are looking for a Qualified and Experienced Solution Designer to join our client for a period of 6 months with a view to extend.
You will work closely with team members and your contribution will range across gathering and analyzing information, developing and documenting improved processes and work instructions and experienced DWH Lead with skills in requirement analysis, solution designing, developing, testing and supporting ETL solutions.
A hands-on solution designer, data modeler and ETL developer for Data Warehousing and ETL application transformation projects using Informatica PowerCenter.
Knowledge on AWS, S3, Redshift, Informatica BDM, and related technologies.
Experience working with IPython, PySparks, AuCuMo, Airflow, Jenkins, Github, Athena, JIRA, Rally, Spectrum, Glue, Flyway.
Good exposure on Oracle PL/SQL, aware of DBA activities, writing and performance tuning of complex SQL queries.
Contract length: 6 months
Job Types: Full-time, Contract
Salary: $650.00 – $800.00 per day
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,nducive,Melbourne,-1,-1,-1,-1,-1,-1,-1,-1
"Data Engineer, Wollongong NSW or Mount Waverley VIC",-1,"Company Description
BlueScope is a technically advanced supplier of steel and steel products in Australia. We are an inclusive organisation and every day we showcase our technology and expertise throughout the world.

Job Description
We are looking for two Data Engineers to join our IT team, based in Wollongong NSW or Mount Waverley VIC. Use your experience in analytics to unlock business value, enabling use of big data for insights and decision-making.
Reporting to the Data Product Owner for our Australian Steel Products (ASP) business, this position will support strategic goals related to data. This will see you:
Gather business and technical requirements with the view to deliver outcomes;
Develop and implement end-to-end data collection, consolidation, modelling and visualisation solutions;
Document metadata in a dictionary and catalogue;
Ensure consumers of such information understand its accuracy, timeliness, quality and sensitivity, so that it is used appropriately; and
Identify opportunities to enhance analytics.
What are the benefits?
Work in a supportive and collaborative team environment whilst we embark on a journey to transform the way our business uses data!
Our systems landscape is broad and diverse. You will be encouraged to think creatively to develop data solutions which solve real business problems.
Working in this role you will enjoy:
the chance to learn more about data science;
salaried remuneration with attractive superannuation options;
the opportunity to participate in a performance incentive scheme; and
access to further development and career opportunities with BlueScope.
Who are we looking for?
We welcome applications from professionals with experience in data analytics and/or programming. Supported by your knowledge of project delivery methods (e.g. Agile), you will demonstrate:
experience with data mining, wrangling, mapping and visualisation techniques (e.g. Azure Data Factory, Databricks and/or DevOps etc.);
well-developed ability in gathering business and technical requirements;
skills in developing and implementing collection, consolidation, modelling and visualisation solutions; and
a passion for sharing your knowledge and desire for ongoing professional development.

Qualifications

null

Additional Information
We're proud to have been named an Inclusive Employer for 2019–2020 by the Diversity Council of Australia. We believe that our people are our strength. Having a diverse and inclusive workplace enables us to improve our capability and ensure continued, sustainable success.
We know that workplace flexibility can mean something different to everyone. Under our B-Flex initiative all of our roles have some degree of flexibility. We encourage you to discuss your needs with us.
Applications close Sunday 25th October 2020.",3.3,"BlueScope
3.3",Wollongong,-1,201 to 500 Employees,-1,Company - Private,Construction,"Construction, Repair & Maintenance",$100 to $500 million (USD),-1
ETL Data Engineer,-1,"ETL Data Engineer

Join a team that’s changing how Australia lives, works, plays and grows
We want you to be the best version of you

Work with innovative teams and explore new technologies to help solve real-world problems.

A typical day as a Data Engineer

ETL / Big Data Engineering professionals will be responsible for guiding the full lifecycle of a Data solution, including:
Working in highly client-facing roles to contribute throughout the end-to-end delivery lifecycle of complex and large-scale digital solutions
Use case and business case development
Support existing and new applications utilizing in-depth technical and data knowledge. Troubleshooting complex issues and providing advisory services to improve the client’s data landscape
Help to streamline and simplify the clients’ complex data landscape by integrating different applications and data architectures
Implementation from requirements analysis, platform selection, digital architecture design, application design and development, testing, and deployment
Interstate travel may be required

Basic qualifications:
Bachelor’s degree
Experience across systems integration, information management, data management and architecture, and business analytics
Experience with being in a team focusing on large-scale, multi-release information centric projects
Experience with waterfall and agile delivery and run / application support functions
Part of a team working on End to end implementation of at least 1 big data project

Preferred Skills:
Hand on experience in Data warehousing using ETL tools such as DataStage, Autosys and TeraData
Hands on experience in ETL job development with multiple stages like sequential file, Transformer, Lookup, join, sort and Database stages.
Strong hand on skills in design, development and implementation of various data remediation, Data migration, data integration techniques.
Strong hand on data modelling experience.
Strong hands on experience in database performance tuning including complex query optimizations and physical database tuning using Teradata.
Understanding of architectural designs and strategy related to data migration, data cleansing, data quality and data consolidation.
Proven data analysis, requirement gathering and problem-solving skills
Exposure to Unix environment and shell scripting.
Experience in Banking and Financial services industry
Desirable: Knowledge of cloud computing infrastructure (e.g. Amazon Web Services EC2, Google Cloud, Microsoft Azure)
About Accenture

Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. We combine unmatched experience and specialized capabilities across more than 40 industries — powered by the world’s largest network of Advanced Technology and Intelligent Operations centers. With 513,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises. Visit us at www.accenture.com.

Accenture is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, marital, domestic or civil partnership status, sexual orientation, gender identity, or any other basis as protected by applicable law.

Vera Goga is the Recruiter managing this role. As the team experience high volumes of applications, we appreciate your patience to allow for a fair and timely process.",3.9,"Accenture
3.9",Sydney,-1,10000+ Employees,1989,Company - Public,Consulting,Business Services,$10+ billion (USD),-1
Student Engineer,-1,"The candidate will have the ability to:
Undertake onsite inspection to collect asset condition data based on the relevant engineering standards and technical guidelines;
Undertake desktop analysis to evaluate the condition and performance of the assets;
Provide the appropriate information, advice, engineering input and support services for the sustainable management of Council’s stormwater and transport networks.
Qualifications:
The successful candidate will be enrolled in a Bachelor of Engineering with a minimum of two years completed.
Position Number: 100678
Position Hours: Fixed term (3 months), hours will be negotiated with the successful candidate, maximum of 75 hours per fortnight.
Salary: Schedule A, Salary Point 4.0. $28.64 per hour ($55,853.45 per annum, pro-rata) in accordance with Glenorchy City Council’s Enterprise Agreement 2016
Please note that all successful applicants will be required to provide a current National Police Check prior to commencement of employment.
For further information on this position, contact Patrick Marshall, Senior Civil Engineer on (03) 6216 6800.
How to apply: Applications for this position must be lodged on this submission site or on the Glenorchy City Council website www.gcc.tas.gov.au - Careers page.
To be considered for this role, all applicants must address the key selection criteria in the and provide a current resume. A copy of the position description can be found by clicking the below hyperlink or on the Glenorchy City Council website.
Applications close at 8pm on Sunday, 1st November 2020
- Student Engineer",4.0,"Glenorchy City Council
4.0",Glenorchy,-1,501 to 1000 Employees,-1,Government,-1,-1,Less than $1 million (USD),-1
Data Engineer involving DevOps,-1,"Data Engineer involving DevOps
Axiom Technologies is an Australia based entity with the history of providing Managed IT solutions to medium to large scale enterprises globally. Please visit our website for more information about what we do at www.axiomtechnologies.com
Axiom Technologies is an Equal Opportunity Employer and encourage applicants from all backgrounds and gender to apply, including, Aboriginal and Torres Strait Islander candidates
Job Requirements:
8+ years IT experience, with at least 5+ years of “Data Engineer/Deveoper” focused titles/roles,
Data Tools: Hands on experience with Apache Beam.
Testing: Hands on experience with automated testing activities/outcomes
DevOps: Experience with the processes involving Microservices facilities for artifacts developed
Platform/OS: Mid-range/Unix
Languages: Unix (Shell) Scripting/commands, SQL, Python
File formats: Text, CSV, Parquet, JSON, XML
Scheduling: Jenkins, Airflow
Auto Scripting: Designing/creation of scripts for repetitive activity. E.g. Unix scripting/SQL
Big data: Exposure to Data Lake Concepts, Hive (Schema), HDFS
Source Control tools: GIT
Delivery Models: Agile, Scrum
Ingestion Design: Create/assess Source/Target data mapping designs
Frameworks: Development and delivery frameworks
Activity Reporting/Repository: Jira, Confluence.
Quality: Accuracy and attention to detail
Industry: Financial Services/Banking
Solutions: Define solutions from High level to detail design to address automating ingestion activity. Facilitate/confirm requirements from product owners, business team members and technical associates,
Process Automation: Automating processes in file management, testing data in files, analysis and design, configuration management.
Script Automation: Ability to design/create scripts to automate/improve data copy/migration/ETL for any repetitive activity.
Languages: Java, Python
Scheduling: Control-M
Databases: Relational. E.g. POSTGRESS, Oracle – as a ETL developer
File Formats: Mainframe – experience with referencing its data formats/copybooks
Big data: Experience referencing/using Hive (Schema) to access data in HDFS
Metadata management tools: MDM, EDC and Axon
Performance: Assess, recommend, improve mappings, SQL queries, Batch feeds
Automation Tools: Other tools that may add value to an automation program and generally support development. E.g. API, REST, JDBC, Webservices, Message Queues/Load balancer,
Cloud: Experience with processing of data files to be ingested/stored in the Cloud, preferably with AWS.
Prod Support: Experience in a production support role performing root cause / impact analysis – under time constraints
Experience in a similar role
8+ Years
What next?
If you are looking for that next challenge in your career and wish to apply for this role, please forward your resume to careers.au@axiomtechnologies.com",2.0,"Axiom Technologies
2.0",Melbourne,-1,1 to 50 Employees,-1,Company - Private,Industrial Manufacturing,Manufacturing,Less than $1 million (USD),-1
Data Engineer,-1,"About the Role
We are on an exciting digital journey so it’s a great time to join ME! We are seeking a Junior Data Engineer who enjoys rolling up their sleeves, learning and growing. As part of our Enterprise Data Team, you will ensure fit for purpose data warehouse solutions are built for use across the bank and by utilising best practise ETL standards, whilst ensuring the data is trusted by our BI developers and key business consumers. Oh, and you’ll get to work on Microsoft technology stack too!
You will be involved with investigating data issues, keeping data feeds flowing and collaborating with different projects across the bank to deliver quality data solutions. How important does that sound? What’s even more important is this role contributes directly to our overall business strategy through the provision of data to enable analytics & reporting, as well as supporting business and decision system processes.

About You
You’re naturally a highly motivated and energetic person who thrives in a dynamic, ever-changing collaborative team environment. Ideally you have previous experience as an ETL developer, Data Engineer or a BI developer, and if you have a degree in computer science or similar it would really put you ahead of the rest.

With your knowledge of SQL coding, data modelling, understanding of data warehouse concepts, plus experience of working on complex ETL solutions, you’re ready to expand your horizons and launch your career into the world of IT at ME.

About ME
We’re not like other banks.
ME was created by the industry super funds to be different from the pack – with a core purpose to help all Australians get ahead financially – no conditions, asterisks or exceptions. And we know that looking after customers starts with taking care of our people.
We believe everyone deserves the same opportunities in life, regardless of gender or identity, sexuality, ethnicity, religion or disability ‒ with internal affinity groups.
Perk ME up
Once you get your feet in the door at ME, we’ll put them both in your very own ME-branded Converse shoes. You’ll also get the following financial, health and fun perks when you join the team:
4U Extras portal (discounts and cashback on 100s of items including cinemas, shopping and gym memberships
10% Myki discount
Purchased Leave programme
Internal wellness programme (Mindfully ME)
Professional education through LinkedIn Learning
Novated Leasing
Professional membership reimbursements
Health checks
Financial education (To help you manage your money smarter)
LGBTIQ+ and Women at ME affinity groups

I want those Converse shoes (and the role)
Can’t see a closing date on the advert? That’s because we’re pretty efficient here at ME and we may start looking at applications sooner rather than later, so if this role sounds like your jam, be sure to apply by submitting your resume today.

Should an applicant be the preferred candidate, background checks (including police checks, reference checks, ASIC banned and disqualified persons and bankruptcy checks) will be completed prior to the candidate's employment being confirmed. The outcomes of the background checks do not automatically bar candidates; however will be assessed against the inherent requirements of the job.
Back Share
Apply Now",3.0,"ME Bank
3.0",Melbourne,-1,501 to 1000 Employees,-1,Company - Private,Banks & Credit Unions,Finance,$100 to $500 million (USD),-1
Software Engineer - Machine Learning/Data Science,-1,"Zendesk is looking for a Software Engineer - Machine Learning/Data Science for a full time position in our Melbourne office.
As part of our engineering team, you will work at a scale where the challenges start to get seriously interesting. Our global engineering team is widely dispersed over the world, with people across nearly every continent. You will get a chance to do cool things with a diverse bunch of people while working in the Melbourne office that is home to Zendesk’s first machine learning (ML) research team.
The Data Science Team, together with Data Engineering, have built Satisfaction Prediction, Answer Bot and Content Cues — products that use Machine Learning (ML) and Artificial Intelligence (AI) to help our customers work more efficiently.
What you get to do every day:
We’re currently looking for someone to join our team as we research, develop, and productionise Machine Learning and Deep Learning models. In addition to frequenting Melbourne’s finest purveyors of coffee, ramen, and bulgogi, you may find yourself:
Building machine learning models including neural networks in TensorFlow
Writing and deploying production-grade Python
Querying and constructing datasets in AWS Athena, Spark
Evaluating and responding to real-world model performance
Scaling your ML to millions of predictions per day
Presenting your work to a broader audience
Watching your algorithm help Zendesk’s end-users
What you'll bring to the role:
A strong foundation in a quantitative discipline (e.g. machine learning, statistics, bio/eco/etc-informatics, econometrics, etc) is critical for this position. While experience in deep learning and natural language processing would be beneficial, your best qualities are:
dedication to continuous learning
collaborative work attitude
strong communication skills
You should also be comfortable with at least one programming language, such as Python, R or Scala.
Application Deadline: 18/11/2020
Job Types: Full-time, Permanent
Salary: $85,000.00 – $110,000.00 per year
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Temporarily due to COVID-19",4.5,"Zendesk
4.5",Melbourne,-1,1001 to 5000 Employees,2007,Company - Public,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),-1
Software Engineer (Machine Learning),-1,"About the Role
AdelaideMRI is building a medical reporting tool. We require an engineer to work primarily on machine learning projects to improve reporting speed and report comprehensiveness.
You will perform data analysis of medical report datasets and image datasets to infer sentence recommendations, image classifications, or other actionable results for the doctors.
Skills and Experience
Background in machine learning or image processing
Qualifications in Computer Science, Software Development or Engineering or equivalent experience
Bonus points for Python
No prior medical knowledge is required.
This position offers flexible hours and work arrangements.
Job Type: Full-time
Experience:
Software Engineering: 1 year (Preferred)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Yes",-1,Adelaide MRI,Australia,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Hey there, we’re PEXA!

We started as an idea: to deliver a single, national e-Conveyancing solution. We collaborated with the industry to create a national electronic lodgement and settlement platform: PEXA. From our humble beginnings, we’ve now grown to more than 320 employees across 5 different states. We’re still expanding at a rapid rate and constantly challenging ourselves to create great experiences for our members as they transition to fully digital conveyancing.

Why become a PEXArian?

Great question! Being a PEXArian is so much more than just a job. We are passionate, motivated & unashamedly enthusiastic at PEXA - we love what we do and we’re proud to admit it! Creating brilliant member experiences wouldn’t be possible if we didn’t also strive to create an amazing employee experience. Alongside our members, our employees are at the heart of everything we do.
Here’s a snapshot of what your life at PEXA could look like:

Your growth:
We encourage you to hit your personal and professional Learning & Development goals with our tailored programs and tools.

Your wellness:
We care about your holistic well being - a fully stocked kitchen, four wellness days, a $250 wellness subsidy as well as lunch and learn sessions to support your financial well being.

Your work/life blend:
We know that work is just one aspect of your life, we want to help you create your ideal work/life blend, rather than squeezing in life around work.

Your family:
With a range of benefits aimed at supporting your family including access to a subsidised school holiday program, extended parental leave and flexi-time to support your return to work, superannuation payments for unpaid parental leave for primary carers and a childcare allowance for pre-primary aged children, when we say, ‘welcome to the family’, we really mean it!
The impact you'd drive:
The successful candidate will be responsible for developing, and maintaining infrastructure to support the delivery of new and existing products. They will also be contributing to establish the rules and frameworks for obtaining the required approvals for new products.
On day one we’d love you to have:
Experience with Python, Spark
Event streaming/sourcing with Kafka or AWS Kinesis
Experience with data structures, formats and data security best practices
AWS experience (e.g CloudFormation, S3, ECS, Lambda, SQS, IAM, KMS, DynamoDB, Glue, Athena)
Query construction and optimisation (e.g. SQL, Elasticsearch, Splunk, DynamoDB)
Git, version control practices, and continuous integration/delivery servers
PyUnit and unit testing frameworks
Production release cycles and maintenance
Collaborating with technical and non-technical teams
Even better:
Agile methodology/delivery
GraphQL
Modern frontend technology (e.g. ReactJS, TypeScript)
Machine learning frameworks and tools (e.g. TensorFlow, PyTorch)
OAuth 2, SAML 2, JWT
Data visualisation and exploration tools (e.g. Jupyter notebooks, Tableau)
AWS SageMaker
Sounds like you?
If this role sounds like you, apply today to have your application reviewed ASAP!",3.9,"Property Exchange Australia Limited
3.9",Melbourne,-1,201 to 500 Employees,2010,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Ongoing position
Full time
Based in Sydney, NSW
Who we are
Australian Red Cross is part of the world’s largest humanitarian organisation. Our aim is to improve the lives of the most vulnerable people in Australia and across our region.
About the role
The Data Engineer role will sit within the Data and Integration Squad in IT and will own (design, implement and support) the AWS Big Data technologies such as the Data Lake and Data Warehouse and support the organisation in growing the data analytics capabilities at Red Cross. In addition to this, the data engineer role will also administer the Power BI tool and support the implementation of the data mastering capability.
What you will bring
Experience building and optimizing data pipelines, architectures and data sets.
Experience in dimensional modelling and building data vaults
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with structured, semi-structured and unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Why work for us?
Work for purpose and know that your work assists Red Cross support and empower people and communities in times of vulnerability.
Generous salary packaging options available that can increase your take home pay.
Further information
To find out more about this opportunity please see the position description below or contact Sharath Kumar Gurram on 02 8651 8839.
Position Description: Position Description - Data Engineer .pdf
Applications for this position will close at 11:55pm Thursday, 5 November 2020.",4.1,"Australian Red Cross
4.1",New South Wales,-1,1001 to 5000 Employees,-1,Nonprofit Organization,Industrial Manufacturing,Manufacturing,$500 million to $1 billion (USD),-1
Junior Fullstack Data Engineer (Python and React),-1,"Formbay is the leading Renewable Energy Certificate Trading company in Sydney. We provide Digital Workflow and Compliance solutions in the renewable energy industry and document processing.
Thanks to our meteoric growth and our commitment to be the best at all we do, we've identified the need to bring on board a new Junior Fullstack Data Engineer.
Reporting to our Principal Machine Learning Engineer, you will help build Machine Learning pipelines for our existing Digital Workflow and Compliance solutions to automate fraud detection and document processing over terabytes of photographic and documentary data – including documents, photos, GPS data and aerial/satellite photography.
Our stack is based on Python, JavaScript, Dask, Tensorflow, CUDA, Nix/NixOS, AWS, Docker, PostgreSQL and more – familiarity with these applications will give you a leg-up on the competition.
Our ideal candidate will have the following competencies:
SQL
Python
JavaScript/TypeScript
Our candidate must also be comfortable working with Linux.
Located a stone's throw away from the Queen Victoria Building in Sydney's bustling CBD, we are centrally-located with easy access to public transportation, bars, cafes and fine dining.
Formbay will provide flexible working hours, a generous remuneration package and the opportunity to work on a world-first software solution are what we can offer you. Free, twice-weekly gym sessions and really, really good coffee are also available.
No hiring/recruitment agencies need apply.",5.0,"Formbay
5.0",Sydney,-1,1 to 50 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is an experienced and qualified Data Engineer to join our IT team based in Birtinya.
Key Responsibilities:
Create and maintain data pipelines and or ETL scripts
Create and maintain data integration including API and Batch interfaces
Performed detailed data analysis
Create and maintain corporate data models
Create and maintain data visualization using Qlik.Sense , PowerBI or Simliar Toolset
Experience in defining, building and maintaining data virtualization and/or star schema data warehouses
Maintain, tune and optimise database, integration and visualisation toolsets
ABOUT YOU:
To succeed in this role, you’ll need to bring the following experience and skills:
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Excellent communication skills both oral and written, with an ability to bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking
Experience with data analysis and modelling will be beneficial

How to Apply
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kawana Waters,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Graduate Data Science / Engineer,-1,"The NRMA is an organisation looking to the future, and right now, we are on the lookout for people who can help us reach our goal: to continue to shape the way Australians move, for the next 100 years and beyond. www.mynrma.com.au.
Everyone new to the team, along with our current staff, will temporarily work from home until it is safe to return to our offices. All interviewing and on boarding will be done virtually due to COVID-19.


Your opportunity
As Graduate Data Scientist or Engineer you will be part of the Data Engineering team delivering cloud data transition program for business initiatives and supporting the entire data platform build.
Your key responsibilities will be to:
Implementing Concepts of Data Warehousing, Data Mart creations within Cloud
Use of SQL for data analysis and insights
Building AI/Machine Learning prototype for implementing and supporting existing algorithms
Data Analytical reports build, using different tool sets


Requirements for Success:
Relevant Degree - Computer Science, Computer Engineering, Software Engineering, Data Science
Excellent SQL skills and demonstrated working knowledge in Python
Demonstrated understanding in data structure and algorithms.
Knowledge and concept of data warehousing methodologies
Any reporting tools experience Tableau or Oracle Analytics Cloud, Looker is desirable
Exposure to Google/AWS/Azure/Oracle any cloud based platforms is desirable
Good communication and interpersonal skills

If you have the required skills and the passion to join our high performing team, please apply today.

Employee Benefits
To ensure our employees feel valued, empowered and celebrated we provide a range of employee benefits including:
50% discount on all NRMA insurances
Free Roadside Assistance
12 weeks paid primary and 4 weeks paid secondary parental leave
Free NRMA Blue Membership
At the NRMA Group, we are People Moving People and diversity and inclusion are part of our DNA. Together, we continue to build an inclusive culture that encourages, supports and celebrates the diverse voices of our employees. It fuels our innovation, promotes flexible ways of working and connects us closer to our members and the communities we serve.",2.5,"NRMA Motoring & Services
2.5",Sydney,-1,501 to 1000 Employees,-1,Nonprofit Organization,Casual Restaurants,"Restaurants, Bars & Food Services",$500 million to $1 billion (USD),-1
Data Centre Engineer,-1,"We are a leading world group that provides low-carbon energy and services. To tackle the climate emergency facing us all, our aim is to become the world leader in the zero-carbon energy transition ""as a service"" for our clients – particular for companies and regional authorities. We use our expertise in our key business areas (renewables, gas, services) to provide competitive and bespoke solutions.
The Data Centre Engineer will be employed as part of a 24/7 ongoing shift to coordinate and monitor third party service providers, maintain the data centre facilities and infrastructure plans, coordinate the implementation of customer requests within the data centre and monitor systems, all in accordance with the Contract KPIs and SLAs.
Coordinate and monitor third party service providers for regular maintenance & testing, service faults & call outs, ensuring works are performed in accordance with Contract SLAs
Monitor and maintain the data centre facilities and infrastructure plans and documentation, including electrical, mechanical, hydraulics, fire and BMS/EMS systems
Coordinate the implementation of internal and external customer requests within the data centre
Perform scheduled plant checks and minor maintenance works
Ensure all Work Order requests are raised and closed in a timely manner
Conduct inductions for staff, vendors and contractors
Ensure all work permits for vendor works are raised and closed
Perform inventory checks on all equipment and critical spares

Qualifications
The selected candidate must be able to demonstrate:
Electrical or HVAC background, or Graduate Electrical or Mechanical Engineer
Passionate about quality work and career minded looking for a new challenge
Can commit to a day and night shift roster (2 days of day shift, then 2 days of night shift, 4 days off)
Ideally able to commence asap
As part of carrying out the duties of this role, it is mandatory to hold Australian Citizenship.

If you are interested and meet the selection criteria apply with an up-to-date resume via the apply instructions on this website.

ENGIE Services is an EEO employer, where all applicants are treated with fairness and respect and have equal access to the opportunities available.

We will not be engaging in the services of a recruitment agency to fill this vacancy and therefore request all interested candidates apply directly to this advertisement.

Job
: Maintenance
Primary Location
: Oceania-Australia-New South Wales-Erskine Park
Organization
: ENGIE Services Australia and New Zealand
Schedule
: Full-time
Nature of Responsibility
: Senior operational / administrative role
Job Posting
: Sep 11, 2020, 6:29:59 AM",3.7,"ENGIE Services Australia & New Zealand
3.7",Sydney,-1,5001 to 10000 Employees,1995,Company - Public,Energy,"Oil, Gas, Energy & Utilities",$2 to $5 billion (USD),-1
Senior Data Engineer,-1,"Senior Data Engineer, Temporary, SYDNEY - McKell

Job Title: Senior Data Engineer

Salary: SNSW Grade 9/10 - The package includes base salary range of $111,806 to $134,667, plus employer's contribution to superannuation and annual leave loading.

Location: Head Office – Haymarket

Employment Status: Temporary through till 30th June 2021


About Service NSW:

Service NSW is making it easier for people and businesses across NSW to access government services. The role designs, builds and analyses complex data from multiple sources to identify revenue, process and business improvement opportunities; providing new information and insights to the business to inform planning, continuous improvement and performance.

About the Role

We are currently seeking to appoint a Senior Data Engineer to deliver expert advice and services in the design of a Single View of Customer and data-related services to support the achievement of business outcomes and strategic goals. We support flexible working practices with staff working remotely during this time.

In this role you will:

Design, build and support a modern data platform based in AWS and vendor technologies.
Provide expertise on data modelling for Graph data model and Customer Data Platform (CDP).
Create data pipelines, load, transformation and reporting workloads in AWS.
Work with the latest data engineering technologies like Apache Kafka, AWS Kinesis, AWS Neptune, AWS Glue and AWS Athena.
Contribute to the design and decision-making of the right tool or platform for the job according to requirements.
Provide expert advice and guidance on data quality and data engineering best practices.
Support a “bigger than you can imagine” scale of data in production environments.
Design, develop and support a metrics-driven reporting solution and a meaningful business intelligence platform.
Document the solution design and support procedures of solutions.
Produce reports, visualisations and recommendations to answer complex business problems that are presented in the most appropriate format to ensure clarity for target audience.
Analyse and define new process improvement opportunities to support continuous improvement and business outcomes; providing advice to stakeholders, on ways to improve the efficiency and reliability of data products and services.
Be very responsive to the information needs of the business by corresponding to customers in a timely manner and provide support/solutions to issues raised.
Troubleshoot and perform root cause analysis on production issues. Identify and implement long term solutions to problems. Perform scheduled maintenance, release deployment and production support activities after business hours, from time to time.
Liaise with internal and external customers to discuss and gather requirements, solutions etc. and maintain a good working relationship with the stakeholders.


Skills and Experience Required:

Solid experience with workflow technologies designing and building data pipelines, data models and data stores.
Experience working within and an understanding of Amazon AWS ecosystem, including security and performance tuning.
Hands on experience working with different types of databases, with focus on Graph and NoSQL databases.
Experience with data streaming required. Having used Kafka and related technologies is an added advantage.
Sound knowledge and experience working with batch processing, data extraction and API integration.
Hands on experience with at least one programming language: Java, Python or scripting.
Demonstrated experience working in an Agile based, fast paced, complex environment within cross-functional teams.
Experience developing systematised insights, data analytics and reporting solutions is an added advantage.
Experience with interactive visualisation of data insights is an added advantage.


Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Salary Grade 9/10, with the base salary for this role starting at 111,806 base plus superannuation

Closing Date: 6th November at 9:59am - applications will be reviewed on a rolling basis, applications may close early or extend

Please apply online, direct applications submitted via email will not be considered.

The Department of Customer Service is proud to be an EEO Employer who are fully focused on equality and believe deeply in diversity of all identities making us different and a true reflection of our NSW customers. As an inclusive workplace, we support various employee resource groups, practice flexible work and workplace adjustment.

If you do require an adjustment during the recruitment process, please notify us on your application form.",3.2,"Service NSW
3.2",Sydney,-1,501 to 1000 Employees,2012,Government,State & Regional Agencies,Government,Unknown / Non-Applicable,-1
Data Engineer - Entry / Mid Level,-1,"Work with a great team on interesting projects customers
Gain more experience in AWS, Data, DevOps cloud operations
Got a working knowledge of AWS? We will teach you the cool stuff!

Itoc is seeking an up and coming Data Engineer to join our growing Data Team in Sydney.

This is an exciting role working with databases, data lakes, data warehouses, data transformation (Python SQL) and enabling AI/ML.

You will be implementing foundational, robust and production ready data platforms to enable business data-discovery, self-service, AI/ML functions across a range of client types and industries, allowing them to do more with their data.

You'll be responsible for:

Deploying data repositories such as lakes and warehouses.
Contribute to our growing portfolio of data solutions.
Ongoing optimisation and management of data platforms.
Development of transformational logic for data pipelines
Data evangelism. We want to show our clients how to follow the best practices for data.

Desired Skills and Experience

To take up the challenge, you will have a depth of skills and experience including:

1-2+ yrs of focused data experience working with SQL and/or NoSQL solutions
A solid education in Software Engineering or equivalent industry experience.
Anything Data focused preferred.
Ability to analyse business scenarios and associated data landscape to derive potential opportunities.
Strong foundation in Python and SQL
Working knowledge of APIs
Principle knowledge of the different relational database platforms and modern data storage techniques
Knowledge of the different aspects of data environments
Collect, store, process, verify consume
Experience with version management systems (such as GIT)
Working knowledge of AWS or another cloud platform - we will teach you the cool stuff.
Great communication skills, an ability to work closely with customers, developers and engineers and the confidence to present ideas in open forums.
Relevant tertiary qualifications and/or industry certifications.
Great communication skills, an ability to work closely with clients, developers and engineers and the confidence to present ideas in open forums.

While not required, a background in consulting and professional services is highly desirable.

Itoc Description

This is an exciting and challenging career opportunity to join the growing Sydney-based Data Team of a leading cloud solution provider where you will be given support to reach your long term career goals. You will be part of a team of cloud experts and will work in an environment of continuous improvement and learning delivering innovative cloud solutions across SaaS, online business and enterprise business.

On offer is a chance to join a team with a great working environment, in an organisation that values its employees and sees the value in ensuring they are engaged. Our team are clearly passionate about what they do, that's why we won the following awards:

Customer Obsession Partner of the Year 2015: ANZ Region
Customer Obsession Leadership Partner 2015: re:Invent

As an employer of choice Itoc offers competitive remuneration, training and development programs and a great working environment. We value a healthy work life balance.

The Perks

MacBook or Dell
Continuous internal learning that will provide training and career development opportunities
Working with a collaborative, social team and leveling-up your skills faster than you will anywhere else.
Quarterly social events

Itoc

Culture and smarts are important to us. Bring your secret sauce. This is no ordinary environment, you will work along some of the Cloud’s best. All engineers at Itoc must gain at least five AWS certifications. We work hard but we have fun.

Please note you must have full working rights in Australia and be available on-shore for face to face interviews.

No recruiters please.",4.0,"Itoc
4.0",Sydney,-1,1 to 50 Employees,2013,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Date: 01-Oct-2020

Location:
Melbourne, VIC, AU

Department:Description:
Technology discounts - from Apple HP Lenovo to Windows
Flexible work arrangements - work in a way that suits you best
Salary packaging - to suit your personal and financial circumstances

Do you want to work for one of the fastest growing data teams in Australia? Do you want to work on multiple data platforms and provide new solution offerings by leveraging cloud and big data technologies?

About the team

Big data information and analytics. Three words that spark apprehension in most businesses. But our team of experts are constantly curious and excited about combining our wonderful array of technological expertise to transform data into our clients most valuable assets making their work smarter. Our data consultants are supported with resources training and tools they need to excel at their work but also the freedom and power to create their own paths forward to make a difference.

As a Senior Consultant in Big Data you will work closely with the team and stakeholders to build and deliver a Cloud based vision for a next generation Big Data analytics platform with strong focus on data quality data security and deliver the systems that process huge volumes of data.

What will you typical day look like?

You will play a pivotal role in - Designing and producing high performing and stable applications to perform complex processing of massive volumes of data in a new cloud based architecture; Building real-time data processing applications which are integrated with business systems to enable value from analytic models to drive rapid decision making; Contributing to system architecture design for a data platform (including cloud-based structures both on and off premises data warehouse components and data lakes); this could cover a range of technologies various countries/locations and lines of business; Support data strategy or technology strategy definition programs including technology stack definition and target operating model requirements

Enough about us lets talk about you:
You are someone with:
Use of traditional data analytics tools and techniques (e.g. MSSQL Oracle MySQL) and ETL software (e.g. SSIS Informatica CloverETL)
Working in large scale cloud data solutions using platforms such as AWS or Azure or GCP will be a bonus.
Experience in scripting or programming (e.g. Python Java Scala C#)
Excellent verbal and written communication skills to adapt to technical and non-technical audiences.
Educated to degree level (or have equivalent experience)
Why Deloitte?

At Deloitte we create positively differentiated work experiences that enable our people to feel valued and achieve their full potential. We value difference and embrace people with diverse backgrounds and thinking styles. Knowing that people work best in different ways we are happy to discuss alternative arrangements if the working pattern you are looking for is not specifically indicated.",3.8,"Deloitte
3.8",Melbourne,-1,10000+ Employees,1850,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Engineer,-1,"Opportunity to grow the team
Period of growth
Intuitive app
S2M are working with a FinTech who have created a unique financial product to help thousands of people better manage their finance, and is currently scaling the company to the next level!

They are looking for a Data Engineer to join, and looking for someone who wants to be hands on, with opportunity to grow the team in future.

Role:

Looking for people with strong AWS experience. You will need passion for data and a cloud, through which you will help a rapidly scaling Australian FinTech establish their data infrastructure from the ground up.
5+ years’ experience as a data engineer within the data and analytics domain
A python 3.X aficionado who is very comfortable creating and orchestrating AWS data pipelines with nothing but code
Strong project delivery toolset experience in open source data integration tools
Experience with processing large volumes of complex data including visualisation and insights generation
Ability to define and develop data integration patterns and pipelines
Ability to assess complexity of data (volume, structure, relationship etc.)
Hands on experience working with different databases (RDBMS, NoSQL, Blob storage etc)
Hands on technical expertise setting up DevOps automation
Hands on experience working technologies/platform e.g. AWS, Dockers, Containers
Experience building data profiling and data cleansing frameworks
Technical reconciliation and reporting
Knowledge and experience in end-to-end project delivery, either traditional SDLC or agile delivery methodologies (or hybrid approaches)
Exceptional communication, documentation and presentation skills
If this sounds like you, get in touch today - kate.gabb@s2m.com.au
3167410agsdf",3.1,"S2M
3.1",Sydney,-1,Unknown,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Analysts,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is seeking experienced and qualified Data Analysts to join our IT team based in our corporate office in Birtinya (Sunshine Coast) or at our meat processing facility in Kilcoy.
Key Responsibilities:
A mixture of data analysis and commercial skills to source, blend and analyse data to gain insight and answer key commercial questions
Working with strategic leaders to define and model Key Performance Indicators, and assist in building forecasting models
Working closely with data engineers and BI developers to specify data pipelines and report visualisation
Drive the creation and implementation of data quality business rule including data definition, governance and quality assurance
About You:
To succeed in this role, you’ll need to bring the following experience and skills:
Proven ability to derive insight and knowledge from data using commercial expertise is a strong requirement
Strong SQL and Excel skills are essential, along with strong data analysis and commercial insights
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Effective people communicator - engage with stakeholders on reporting needs, interpret requirements into visual solutions and train/deliver the outputs to the stakeholders getting signoff of acceptance
Bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking

How to Apply:
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kilcoy,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Network Data Engineer,-1,"Min 6+ years of experience in the relevant technologies
Australian Driving License for visiting remote locations / Data Centre for day to day technical work.
Managing Network devices (switches, routers, firewalls, load balancer, and wireless technology)
Performing MACD activities for all network devices.
Supporting BAU operation activities.
Proficient in performing in-depth details of technical troubleshooting, cause and provide recommendation to the client for incidents causing extended network outage to client’s critical locations.
Provide exceptional network services in terms of network support, break-fix, design and consulting, new projects, implementation.
Configure, administer, and document firewall infrastructure.
Manage the firewall deployment, rules migrations, and firewall administration.
Supporting Cloud Migration Activities from traditional to AWS/Azure.
Setting up VPN tunnel with Cloud and 3rd Party network devices.
Integrating and upgrading existing ISP bandwidth with support from ISP Vendor.
Setting up VPN profiles for Users.
Installing hot fix and patches to mitigate the security devices from attacks and bugs.
Reviewing and fine tuning the firewall rules and NAT rules.
Documentation and change control.
Mentoring, Motivating and Guiding support teams
Technical skills:
o LAN
o Wireless
o WAN
o MPLS
o Routing protocols (OSPF,BGP)
o DMVPN
o Azure cloud Networking
o Network Security
Fortigate Manager / Analyzer / Firewall
Cisco ASA
Firepower FTD
Cisco Any connect
Site to Site VPN
F5 Load Balancing and Scripting iRule
Job Types: Full-time, Contract
Schedule:
8 hour shift
Experience:
Scripting: 5 years (Required)
Data Network: 5 years (Required)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Required)",3.6,"Total IT Global
3.6",Sydney,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Engineer - Processing & Analysis,-1,"Job Description:
Design,build and maintain the ingestion system to support various types of data(e.g. User behavior, RDS, NoSQL db and others) to be ingested to the data warehouse more timely and accurately
Translate data requirements into scalable technical data service with low latency and high concurrency
Design,build and maintain the batch or real time data pipeline in production using Hadoop big data technology
Analyze and improve efficiency, scalability, and stability of the system
Define and manage SLA,Data quality for all data sets in allocated areas of ownership
Requirements:
Minimum B.S. degree in Computer Science or a related technical field
2+ years of working experience in programming languages,such as Java,Scala,Python
Familiar with Hadoop, Spark and Flink data processing, experience of TB data processing experience is a plus
Familiar designing and operating of a robust distributed system is a plus
Understand data mining or machine learning
Excited to work intimately with data
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"SYNOPSIS:
Lead Data Engineer
Applications close Sunday 8 November 2020
Ongoing
Contact name: Shyni Sasikala
Phone: (02) 6249 9048
Email: Shyni.Sasikala@ga.gov.au

The Data Policy and Informatics section within the Digital Science and Information branch creates, implements, and promotes policies, platforms and tools that improve and support the quality, discoverability, accessibility, and general usability of Geoscience Australia’s science data products. The section consults with internal and external research, government and industry partners to establish collaborative data frameworks, architectures and models within Geoscience Australia (GA) and across broader national and international communities of practice. The section innovates, builds and maintains tools, systems, processes and governance that enable digital data management, cataloguing and open data delivery.
GA makes accessible a wide range of geoscientific and spatial data to a wide variety of stakeholders in multiple formats, and in recent years GA's data volumes have grown exponentially. GA is focussed on making its data and metadata assets accessible so that they can be used in machine to machine interactions for data analytics and other applications in environments that range from High Performance Computing (HPC), through high-end cloud servers, to mobile devices.
We currently have two opportunities for Lead Data Engineers in the Informatics team. The Lead Data Engineer is responsible for innovating and exploring new technologies that will advance GA’s science goals and maximise the uptake and use of GA’s science data. The Lead Data Engineer reports to the team’s Assistant Director but also works closely with other developers, data scientists and engineers within the Digital Science and Innovation (DiSI) branch, as well as diverse stakeholders both within and external to GA.",3.9,"Geoscience Australia
3.9",Canberra,-1,501 to 1000 Employees,2001,Government,Federal Agencies,Government,$100 to $500 million (USD),-1
Data Engineer,-1,"The Seven Network is part of Seven West Media, one of Australia’s most prominent media companies, with a market leading presence in content across broadcast television, online and in print. Comprising some of Australia’s most renowned media brands, SWM includes not just Seven Network and its affiliate channels 7two, 7mate, 7flix and BVOD offering 7plus, but also 7NEWS.com.au, The West Australian, The Sunday Times and more.
At Seven we are here to bring all Australians closer to the moments that move us - we’re first on the scene, with our finger on the pulse, on demand, in the moment. Together, we’re responsible for creating and sustaining authentic Australian engagement.
A new and exciting opportunity has opened for a Data Engineer to join the Audience Intelligence team. Based in Sydney and reporting to the Head of Data Enablement, you’ll be responsible for:
Implementation of end to end data solutions to support Data Strategy for the SWM group.
Work closely with the Data Solution Designers to develop and maintain scalable data pipelines and build out new file and API based integrations to address requirements from the various business stakeholders.
Collaborates with engineering, analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organisation.
Work on Data Preparation for analytics and data scientist team members and assist them from an engineering perspective in building and optimising the models including building the automation of the end to end workflows
Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.
Perform data analysis required to troubleshoot data related issues and assist in the resolution of production data issues.
Work effectively with vendors for successful delivery of projects and acceptance of the solution
Work on Delivery projects using Agile Software Development methodologies
We are looking for someone who has:
Bachelor's degree in computer science, computer engineering or other technical discipline is essential
Proven experience working as a digital analytics specialist
Extensive experience with digital analytics implementation (e.g. Google Analytics, Snowplow, Adobe Analytics) and BI processes and visualisation platforms
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience in ETL and building and optimizing ‘big data’ pipelines and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Experience with big data tools: Hadoop, Spark, etc., AWS cloud services: EC2, S3, Lambda and familiar with version control systems: Git
Strong coding skills with knowledge of Unix/Linux and scripting languages such as Unix Shell scripting, Python desirable
Experience supporting and working with cross-functional teams in a fast-paced environment.
Ability to multi-task and problem solve with changing demands and priorities
Ability to work under pressure to meet deadlines and detail oriented
Your success is our success: we will provide you with opportunities for you to keep learning and growing, enabling you to challenge and develop yourself. In return, we offer a benefits program that has something in it for everyone.
Seven West Media is an equal opportunity employer and we are committed to creating a diverse and inclusive workplace.
Recruitment Agencies: Seven West Media does not accept any unsolicited agency resumes and will not be responsible for any fees related to unsolicited resumes.
Advertised: 19 Oct 2020 12:00 AM AUS Eastern Daylight Time
Applications close:

Back to search results",2.5,"Seven West Media
2.5",Sydney,-1,5001 to 10000 Employees,1956,Company - Public,TV Broadcast & Cable Networks,Media,Unknown / Non-Applicable,-1
BICON Rules Engineer,-1,"APS 5 - $73,299 - $80,410 per annum plus superannuation
Biosecurity Plant Division
Canberra, ACT
Play an active role in managing biosecurity risk to Australia
Work in a motivated and professional team with a wide range of skills and backgrounds
Full training provided

Who we are
The BICON Content Development Team maintains and improves the Biosecurity Import CONditions database (BICON) content to allow external clients to understand and comply with their biosecurity obligations and internal clients to effectively manage biosecurity risk and regulate imports. We work collaboratively with internal clients to comprehend and implement their BICON content requirements and optimise the use of BICON to publish clear import requirements and onshore management support procedures to effectively manage biosecurity risk.

The Jobs
Key duties of these positions include:

working with business content (import and permit conditions) and import programs to understand and construct decision tree structures in the BICON database, in accordance with system design and authoring conventions
executing changes to import and permit conditions in alignment with service standards while complying with system rules and authoring conventions
providing technical advice through various formats on the most appropriate means of authoring BICON content to achieve import program and stakeholder objectives
using workflow management tools to maintain detailed records of changes to import conditions and key decisions
performing administrative tasks including system reporting, data analysis and scoping tasks for the BICON content change work program
contributing to the development and maintenance of instructional material, authoring conventions and courseware
clearly documenting and reporting system issues
developing and maintaining effective working relationships with internal and external stakeholders.

What we are looking for
Knowledge and experience
Experience working with complex IT systems.
Experience working collaboratively and as part of a team.
Knowledge of the role of biosecurity is preferred but not essential.

For additional information, please read the Job Description below.
Candidate Information Package docx Opens in new window",3.9,"Department of Agriculture & Water Resources
3.9",Australia,-1,5001 to 10000 Employees,-1,Government,Federal Agencies,Government,$500 million to $1 billion (USD),-1
Cloud Data Engineer,-1,"Job no: 509605
Work type: Permanent Full Time
Location: Melbourne, Canberra, Sydney
Do you embrace digital disruption?
Do you love solving complex problems, designing sophisticated solutions and building innovative technology?
Do you believe in creating powerful actionable insights from Data and Analytics?
Do you want to work in a diverse and flexible working environment?
KPMG is one of the most trusted and respected global professional services firms. Through depth of expertise, clarity of insight and strength of purpose we help our clients solve complex challenges, steer change, strengthen, transition and grow. We are a team based practice and this extends to our clients whom we work and collaborate with, in solving complex problems. Together, we design, innovate and implement, providing enduring advice that support our clients and the services they deliver. Our clients vary in size and come from a diverse range of sectors – all sharing in a common goal: to embrace change and deliver services that make Australia a better place. We are looking for talented individuals who would like to join us on the journey.
KPMG’s Digital Delta Team
We re-imagine and re-invent organisations to become world class digital enterprises using advanced technologies, data and human insights. We help organisations to embrace Digital Strategy, Artificial Intelligence (AI) & Cognitive, the Internet of Things (IoT), Data, Analytics & Modelling, Mobile App & Web, and User Experience (UX) & User Interface (UI) and more.
We work with clients to:
Formulate strategies that re-imagine organisations
Harness innovation from the 4th industrial revolution
Actioning insights from trusted data to consistently and quickly make clear decisions
Build adaptive organisations
Thrive as a connected enterprise – front, middle and back office
This is how you’ll contribute:
We are looking for ambitious Data Engineers who are passionate about helping clients define bold ambitions and deliver on them. Joining our team will take you on a journey of personal and technical growth and provide the opportunity to inspire confidence and empower change.
As a Data Engineer you are the designer, builder and manager of the information or ""big data"" infrastructure, preparing data for analytical or operational use. You will design, construct, test and maintain a data pipeline to pull together information from different source systems; integrating, consolidating and cleansing data; and structure it for use in individual analytics applications.
The KPMG Difference
Our people are focused on creating a diverse and dynamic environment that embraces and values differences. We value the variety of unique experiences, qualities and characteristics our people possess and we share and learn from each other.
We are proud to be consistently recognised as an employer of choice for women, and for our achievements in LGBT+ workplace inclusion.
Our commitment to ‘Flexibility’ allows our people to manage the changing demands of work, personal or family life. Explore the links below to hear our people share their experience @ KPMG:
Flexibility empowers wellbeing
Flexibility enables contribution to the community
Flexibility inspires technology & innovation
Flexibility supports family

Make KPMG the clear choice for your career and be Extraordinary!

Advertised: 09 Sep 2020 AUS Eastern Standard Time
Applications close:",3.8,"KPMG
3.8",Sydney,-1,10000+ Employees,1987,Subsidiary or Business Segment,Accounting,Accounting & Legal,$2 to $5 billion (USD),-1
Computer Network and Systems Engineer,-1,"Duties Include but are not limited to:
Tasks Include:
analysing, developing, interpreting and evaluating complex system design and architecture specifications, data models and diagrams in the development, configuration and integration of computer systems
researching, analysing, evaluating and monitoring network infrastructure to ensure networks are configured to operate at optimal performance
assessing and recommending improvements to network operations and integrated hardware, software, communications and operating systems
providing specialist skills in supporting and troubleshooting network problems and emergencies
installing, configuring, testing, maintaining and administering new and upgraded networks, software database applications, servers and workstations
providing network programming in support of specific business needs and requirements
preparing and maintaining procedures and documentation for network inventory, and recording diagnosis and resolution of network faults, enhancements and modifications to networks, and maintenance instructions
monitoring network traffic, and activity, capacity and usage to ensure continued integrity and optimal network performance
Skills and Experience Required:
Must have experience working in a Managed Service environment
Demonstrated experience in IT Networks and Data Centres
Understanding of systems and architectures to meet client needs
Experience in Help Desk including break / fix
Effective and timely documentation
Effective Task Management Skills
Be solution and outcome focused and willing to learn new technologies
Excellent communication skills with staff, clients and partners
Time management, ability to prioritise and deliver to schedule
Experience with N-Able and Connectwise desired
Open Cabling license desired
Job Types: Full-time, Permanent
Salary: $30.00 per hour
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,Trans-plant training,Canberra,-1,-1,-1,-1,-1,-1,-1,-1
Software Engineer (Data),-1,"If you are looking for an opportunity to make a real impact with smart people who are genuinely doing things differently then you've come to the right place! We're growing our data engineering capabilities and are looking for awesome data engineers to join our team.
With our diverse range of clients and projects, no day will look the same - but here's a great snapshot of what you'll be doing:
Work with some of the best Data Scientists and Engineers to deliver production-grade AI and Machine Learning systems as we deliver client projects from inception to production.
Consulting with our clients and working with them to build modern data systems using the 'best of' technologies and principles.
Advising clients on data strategy, architecture and technology.
Applying best software engineering practices in coding, monitoring and alerting, using CI/CD, TDD and cloud architectures.
Working over a wide range of big data tools and environments: not limited to; Apache Kafka, Spark, Python, Scala, Hive, Airflow, AWS EMR & Glue, GCP Dataproc & Dataflow, BigQuery, Snowflake, Redshift.
Who are we?
Glad you asked! We are Eliiza. Data science. Engineered for scale.
We are a passionate team of data scientists and engineers who apply data science and machine learning to solve real-world problems. Our mission is to create a bright future for Australian businesses and society in a world increasingly influenced by intelligent technologies.
We've created a culture that values diversity where people can truly be themselves! We care a lot about growing the Australian AI community in a positive direction, and we're doing several things to try and achieve that:
We provide opportunities for underrepresented groups to work in AI through our associate and intern programmes
We organise and participate in a range of community events, reading groups and meetups
We produce the AI Australia podcast
We blog about topics we care about
We stream brown bag sessions to the broader community
We're also part of Mantel Group's 'house of brands' which means it's not just the Eliiza team you'll work with, learn from and see at social events - there's another 230 of us across DigIO, Kasna & CMD Solutions!
So you're ready for something new?
We're keen to know more about you! Our team is made up of a range of people, with different experience across a huge range of data driven skill sets.
We'd love to hear from you if you have experience with:
one (or more) core language(s), ideally Scala, Python or Java
one (or more) cloud platforms, AWS, GCP, Azure
ETL/ELT concepts and technologies e.g. Data partitioning, Hive, Spark
streaming data concepts and technologies, ideally Kafka (Kinesis, Beam or Pubsub will do)
We'd be over the moon if you:
Experience with distributed/columnar databases (e.g. Snowflake, Big query, Redshift).
Experience with any of a variety of databases e.g. RDMS, NoSql, Columar, Distributed, Time series, Graph.
Knowledge of job orchestration and scheduling. Any experience with Airflow, Luigi or Oozie.
Experience with containers and container orchestration (Docker, Docker Compose or Kubernetes).
However, we value a diversity of skill-sets, and don't necessarily require that you're skilled with all of the above. If you feel you don't fit all the experience/skills listed above we still encourage you to apply or get in touch.
What's on offer if you join us?
We make sure you're always one step ahead by investing your learning and development, every year. We build our own training where it doesn't exist yet.
We hire smart people and get out of their way. By focusing on our five principles and not getting caught up in red tape, we trust you to get the job done.
You'll get all the tools you need - a new iPhone or Google phone, a new Macbook Pro or Dell, and a lot of branded swag!
But hold on, you mentioned a house of brands?
We certainly did! Mantel Group is an Australian-owned, 'house of brands' company with four technology businesses (Eliiza being one of them!) across Melbourne and Sydney. We're building a group of companies with open borders so we can support you to take on new skills without leaving an awesome team - we understand you won't have one job for life!
We may only be just two years old but Mantel Group has already been recognised #9 in the 2020 Best Places to Work in Australia and #4 in the AFR's 2020 fastest growing new companies.
Keen to chat?
Click ""Apply"" to share your details with our talent team, and we'll be in touch.
In the meantime, check out 'how we hire' to find out what's in store if you're successful and get to know us better by visiting our website and following Eliiza on LinkedIn.",-1,Eliiza,Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Infrastructure Engineer,-1,"Job Description:
Design and grow the Shopee data platform to support a variety of big data applications using open-source technologies including Kafka, Hadoop, Presto, HBase, Spark, Hive, Druid, and our own creations. Some examples include a real-time data streaming platform, a unified query platform, a cluster management system, and a machine learning platform
Dig into the source code of some open-source big data system to get the whole control and familiar with the details, configurations, designs and source code. Develop and maintain the internal release of big data systems and components as the business requirements.
Keep close and overall monitoring for all the deployments of the systems, maintain the system’s stability, improve the performance, discover the performance bottlenecks, tracking and troubleshooting, cost optimisation.
Requirements:
B. Sci. / Ms / PhD in Computer Science or a related technical field
Familiar with at least one of these languages: Java, Scala, Python, Bash under Linux / Unix. Scala is a plus
Familiar with the use and compute logical of SQL
Knowledge about the Big Data Infrastructure system technology like Distributed File System, Distributed Computing, Distributed Database will be a plus
Hands-on experiences Hadoop, Spark, Kafka, and/or Presto will be a plus
Love to use and develop open-source technologies
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"Work on an award-winning, international technology!
Endless career opportunities
An innovative, friendly team of 300+
This role will be focused on the development of our existing ClaimLogik line of products as well as working on our new cloud-first, modern suite of applications.

Intelligent Thought, our technology business is scaling and shipping our software globally. Already profitable, part of a much larger group business, with investors such as Macquarie Capital and Envest – we are all set to deliver textbook disruption to the Insurance Industry. The growth of the platform, of our customer base, and the increasing industry demand have led to the need for this role to help the team scale.

Our Philosophy
Give each employee a sense of purpose and an environment for them to connect the importance of their role to delivering a service that matters to our customers.
Challenge the ‘why’ of traditional claims processes.
Keep it simple – do only what brings value and what matters to the customer
Enable employee decisions, empower our people
Responsibilities:
Create, extend and maintain ETL pipelines to form our data lake, data warehouse and analytics platform (currently using the Microsoft Azure set of tools and service)
Help define the optimal data pipeline architecture
Influence the tool selection, platform selection, data architecture and strategy which will transform the business to be truly data-driven
Understand, analyse and size user requirements
Work with different parts of the business to provide them with the insights they need to deliver the best results
Skills & experience:
Degree or qualification in computer science or related
Advanced knowledge of relational database, including query authoring and query optimisation (MS SQL Server and PostgreSQL).
Experience building and optimising ETL pipelines
Experience designing complex data models
Experience working with cloud platforms (Azure or AWS)
Efficient time management and organisational skills
High attention to detail and accuracy
Effective communication skills to build strong working relationships; both written and verbal
Proactive and results-driven
Why Claim Central?
Claim Central Consolidated is a global insurance industry leader across, claims management, insurance technology and data and analytics. Currently operating in the United States, Australia, South Africa, Italy and New Zealand, we have pioneered digitally connected claims management services across the globe. Claim Central is a disruptor and thought leader in the industry and we were recognised as the Australian Financial Review’s 8th Most Innovative Company in Australia in 2016. This business is in a period of unprecedented growth, transitioning our technology and services into multiple geographies at a rapid pace. Our unique culture is based on teamwork, collaboration, trust, respect and performance. We also offer many benefits apart from our exceptional team culture; including flexible work arrangements, and continued professional development.

Be a part of this journey in a career-defining role.",-1,Claim Central,Matraville,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer - AI/ML,-1,"Our client provides services to a major industry across the country. The business is still early in it's days of technology development and the environment is greenfields in nature (no pun intended), effectively working like a start-up.

Their data and analytics team have worked and built leading and bleeding-edge technologies in this space and what they have created so far may be game-changing. From a machine learning perspective, the progress they have made to the business has already seen proven success in changing the future of an industry that will have positive consequences for all those involved.

You will have previously worked in a technical capacity in the data and analytics space and have experience working with an organisation where machine learning has been implemented, not just a concept that the business talks about having or the technology team would love to have. The commercial experience you will have had in the ML field will be proven examples of where you have affected the way a business or industry used to perform, to the changes that have come about from this.

Technically, you will have extensive experience in the Microsoft space - Power BI, Azure etc and you will have previously mentored and coached junior members of the teams you have been part of.

This is a rare opportunity in Brisbane where the business has truly embraced and funded projects across the ML space and would be a great chance for those in the Data Development/Data Engineering field, who are looking to move into a Data Scientist role in the future.

Please send your application through if you would like to know more.",4.0,"Emanate Technology
4.0",Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Solution designer/ ETL Engineer & Data Modeller,-1,"We are looking for a Qualified and Experienced Solution Designer to join our client for a period of 6 months with a view to extend.
You will work closely with team members and your contribution will range across gathering and analyzing information, developing and documenting improved processes and work instructions and experienced DWH Lead with skills in requirement analysis, solution designing, developing, testing and supporting ETL solutions.
A hands-on solution designer, data modeler and ETL developer for Data Warehousing and ETL application transformation projects using Informatica PowerCenter.
Knowledge on AWS, S3, Redshift, Informatica BDM, and related technologies.
Experience working with IPython, PySparks, AuCuMo, Airflow, Jenkins, Github, Athena, JIRA, Rally, Spectrum, Glue, Flyway.
Good exposure on Oracle PL/SQL, aware of DBA activities, writing and performance tuning of complex SQL queries.
Contract length: 6 months
Job Types: Full-time, Contract
Salary: $650.00 – $800.00 per day
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,nducive,Melbourne,-1,-1,-1,-1,-1,-1,-1,-1
"Data Engineer, Wollongong NSW or Mount Waverley VIC",-1,"Company Description
BlueScope is a technically advanced supplier of steel and steel products in Australia. We are an inclusive organisation and every day we showcase our technology and expertise throughout the world.

Job Description
We are looking for two Data Engineers to join our IT team, based in Wollongong NSW or Mount Waverley VIC. Use your experience in analytics to unlock business value, enabling use of big data for insights and decision-making.
Reporting to the Data Product Owner for our Australian Steel Products (ASP) business, this position will support strategic goals related to data. This will see you:
Gather business and technical requirements with the view to deliver outcomes;
Develop and implement end-to-end data collection, consolidation, modelling and visualisation solutions;
Document metadata in a dictionary and catalogue;
Ensure consumers of such information understand its accuracy, timeliness, quality and sensitivity, so that it is used appropriately; and
Identify opportunities to enhance analytics.
What are the benefits?
Work in a supportive and collaborative team environment whilst we embark on a journey to transform the way our business uses data!
Our systems landscape is broad and diverse. You will be encouraged to think creatively to develop data solutions which solve real business problems.
Working in this role you will enjoy:
the chance to learn more about data science;
salaried remuneration with attractive superannuation options;
the opportunity to participate in a performance incentive scheme; and
access to further development and career opportunities with BlueScope.
Who are we looking for?
We welcome applications from professionals with experience in data analytics and/or programming. Supported by your knowledge of project delivery methods (e.g. Agile), you will demonstrate:
experience with data mining, wrangling, mapping and visualisation techniques (e.g. Azure Data Factory, Databricks and/or DevOps etc.);
well-developed ability in gathering business and technical requirements;
skills in developing and implementing collection, consolidation, modelling and visualisation solutions; and
a passion for sharing your knowledge and desire for ongoing professional development.

Qualifications

null

Additional Information
We're proud to have been named an Inclusive Employer for 2019–2020 by the Diversity Council of Australia. We believe that our people are our strength. Having a diverse and inclusive workplace enables us to improve our capability and ensure continued, sustainable success.
We know that workplace flexibility can mean something different to everyone. Under our B-Flex initiative all of our roles have some degree of flexibility. We encourage you to discuss your needs with us.
Applications close Sunday 25th October 2020.",3.3,"BlueScope
3.3",Wollongong,-1,201 to 500 Employees,-1,Company - Private,Construction,"Construction, Repair & Maintenance",$100 to $500 million (USD),-1
ETL Data Engineer,-1,"ETL Data Engineer

Join a team that’s changing how Australia lives, works, plays and grows
We want you to be the best version of you

Work with innovative teams and explore new technologies to help solve real-world problems.

A typical day as a Data Engineer

ETL / Big Data Engineering professionals will be responsible for guiding the full lifecycle of a Data solution, including:
Working in highly client-facing roles to contribute throughout the end-to-end delivery lifecycle of complex and large-scale digital solutions
Use case and business case development
Support existing and new applications utilizing in-depth technical and data knowledge. Troubleshooting complex issues and providing advisory services to improve the client’s data landscape
Help to streamline and simplify the clients’ complex data landscape by integrating different applications and data architectures
Implementation from requirements analysis, platform selection, digital architecture design, application design and development, testing, and deployment
Interstate travel may be required

Basic qualifications:
Bachelor’s degree
Experience across systems integration, information management, data management and architecture, and business analytics
Experience with being in a team focusing on large-scale, multi-release information centric projects
Experience with waterfall and agile delivery and run / application support functions
Part of a team working on End to end implementation of at least 1 big data project

Preferred Skills:
Hand on experience in Data warehousing using ETL tools such as DataStage, Autosys and TeraData
Hands on experience in ETL job development with multiple stages like sequential file, Transformer, Lookup, join, sort and Database stages.
Strong hand on skills in design, development and implementation of various data remediation, Data migration, data integration techniques.
Strong hand on data modelling experience.
Strong hands on experience in database performance tuning including complex query optimizations and physical database tuning using Teradata.
Understanding of architectural designs and strategy related to data migration, data cleansing, data quality and data consolidation.
Proven data analysis, requirement gathering and problem-solving skills
Exposure to Unix environment and shell scripting.
Experience in Banking and Financial services industry
Desirable: Knowledge of cloud computing infrastructure (e.g. Amazon Web Services EC2, Google Cloud, Microsoft Azure)
About Accenture

Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. We combine unmatched experience and specialized capabilities across more than 40 industries — powered by the world’s largest network of Advanced Technology and Intelligent Operations centers. With 513,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises. Visit us at www.accenture.com.

Accenture is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, marital, domestic or civil partnership status, sexual orientation, gender identity, or any other basis as protected by applicable law.

Vera Goga is the Recruiter managing this role. As the team experience high volumes of applications, we appreciate your patience to allow for a fair and timely process.",3.9,"Accenture
3.9",Sydney,-1,10000+ Employees,1989,Company - Public,Consulting,Business Services,$10+ billion (USD),-1
Student Engineer,-1,"The candidate will have the ability to:
Undertake onsite inspection to collect asset condition data based on the relevant engineering standards and technical guidelines;
Undertake desktop analysis to evaluate the condition and performance of the assets;
Provide the appropriate information, advice, engineering input and support services for the sustainable management of Council’s stormwater and transport networks.
Qualifications:
The successful candidate will be enrolled in a Bachelor of Engineering with a minimum of two years completed.
Position Number: 100678
Position Hours: Fixed term (3 months), hours will be negotiated with the successful candidate, maximum of 75 hours per fortnight.
Salary: Schedule A, Salary Point 4.0. $28.64 per hour ($55,853.45 per annum, pro-rata) in accordance with Glenorchy City Council’s Enterprise Agreement 2016
Please note that all successful applicants will be required to provide a current National Police Check prior to commencement of employment.
For further information on this position, contact Patrick Marshall, Senior Civil Engineer on (03) 6216 6800.
How to apply: Applications for this position must be lodged on this submission site or on the Glenorchy City Council website www.gcc.tas.gov.au - Careers page.
To be considered for this role, all applicants must address the key selection criteria in the and provide a current resume. A copy of the position description can be found by clicking the below hyperlink or on the Glenorchy City Council website.
Applications close at 8pm on Sunday, 1st November 2020
- Student Engineer",4.0,"Glenorchy City Council
4.0",Glenorchy,-1,501 to 1000 Employees,-1,Government,-1,-1,Less than $1 million (USD),-1
Data Engineer involving DevOps,-1,"Data Engineer involving DevOps
Axiom Technologies is an Australia based entity with the history of providing Managed IT solutions to medium to large scale enterprises globally. Please visit our website for more information about what we do at www.axiomtechnologies.com
Axiom Technologies is an Equal Opportunity Employer and encourage applicants from all backgrounds and gender to apply, including, Aboriginal and Torres Strait Islander candidates
Job Requirements:
8+ years IT experience, with at least 5+ years of “Data Engineer/Deveoper” focused titles/roles,
Data Tools: Hands on experience with Apache Beam.
Testing: Hands on experience with automated testing activities/outcomes
DevOps: Experience with the processes involving Microservices facilities for artifacts developed
Platform/OS: Mid-range/Unix
Languages: Unix (Shell) Scripting/commands, SQL, Python
File formats: Text, CSV, Parquet, JSON, XML
Scheduling: Jenkins, Airflow
Auto Scripting: Designing/creation of scripts for repetitive activity. E.g. Unix scripting/SQL
Big data: Exposure to Data Lake Concepts, Hive (Schema), HDFS
Source Control tools: GIT
Delivery Models: Agile, Scrum
Ingestion Design: Create/assess Source/Target data mapping designs
Frameworks: Development and delivery frameworks
Activity Reporting/Repository: Jira, Confluence.
Quality: Accuracy and attention to detail
Industry: Financial Services/Banking
Solutions: Define solutions from High level to detail design to address automating ingestion activity. Facilitate/confirm requirements from product owners, business team members and technical associates,
Process Automation: Automating processes in file management, testing data in files, analysis and design, configuration management.
Script Automation: Ability to design/create scripts to automate/improve data copy/migration/ETL for any repetitive activity.
Languages: Java, Python
Scheduling: Control-M
Databases: Relational. E.g. POSTGRESS, Oracle – as a ETL developer
File Formats: Mainframe – experience with referencing its data formats/copybooks
Big data: Experience referencing/using Hive (Schema) to access data in HDFS
Metadata management tools: MDM, EDC and Axon
Performance: Assess, recommend, improve mappings, SQL queries, Batch feeds
Automation Tools: Other tools that may add value to an automation program and generally support development. E.g. API, REST, JDBC, Webservices, Message Queues/Load balancer,
Cloud: Experience with processing of data files to be ingested/stored in the Cloud, preferably with AWS.
Prod Support: Experience in a production support role performing root cause / impact analysis – under time constraints
Experience in a similar role
8+ Years
What next?
If you are looking for that next challenge in your career and wish to apply for this role, please forward your resume to careers.au@axiomtechnologies.com",2.0,"Axiom Technologies
2.0",Melbourne,-1,1 to 50 Employees,-1,Company - Private,Industrial Manufacturing,Manufacturing,Less than $1 million (USD),-1
Data Engineer,-1,"About the Role
We are on an exciting digital journey so it’s a great time to join ME! We are seeking a Junior Data Engineer who enjoys rolling up their sleeves, learning and growing. As part of our Enterprise Data Team, you will ensure fit for purpose data warehouse solutions are built for use across the bank and by utilising best practise ETL standards, whilst ensuring the data is trusted by our BI developers and key business consumers. Oh, and you’ll get to work on Microsoft technology stack too!
You will be involved with investigating data issues, keeping data feeds flowing and collaborating with different projects across the bank to deliver quality data solutions. How important does that sound? What’s even more important is this role contributes directly to our overall business strategy through the provision of data to enable analytics & reporting, as well as supporting business and decision system processes.

About You
You’re naturally a highly motivated and energetic person who thrives in a dynamic, ever-changing collaborative team environment. Ideally you have previous experience as an ETL developer, Data Engineer or a BI developer, and if you have a degree in computer science or similar it would really put you ahead of the rest.

With your knowledge of SQL coding, data modelling, understanding of data warehouse concepts, plus experience of working on complex ETL solutions, you’re ready to expand your horizons and launch your career into the world of IT at ME.

About ME
We’re not like other banks.
ME was created by the industry super funds to be different from the pack – with a core purpose to help all Australians get ahead financially – no conditions, asterisks or exceptions. And we know that looking after customers starts with taking care of our people.
We believe everyone deserves the same opportunities in life, regardless of gender or identity, sexuality, ethnicity, religion or disability ‒ with internal affinity groups.
Perk ME up
Once you get your feet in the door at ME, we’ll put them both in your very own ME-branded Converse shoes. You’ll also get the following financial, health and fun perks when you join the team:
4U Extras portal (discounts and cashback on 100s of items including cinemas, shopping and gym memberships
10% Myki discount
Purchased Leave programme
Internal wellness programme (Mindfully ME)
Professional education through LinkedIn Learning
Novated Leasing
Professional membership reimbursements
Health checks
Financial education (To help you manage your money smarter)
LGBTIQ+ and Women at ME affinity groups

I want those Converse shoes (and the role)
Can’t see a closing date on the advert? That’s because we’re pretty efficient here at ME and we may start looking at applications sooner rather than later, so if this role sounds like your jam, be sure to apply by submitting your resume today.

Should an applicant be the preferred candidate, background checks (including police checks, reference checks, ASIC banned and disqualified persons and bankruptcy checks) will be completed prior to the candidate's employment being confirmed. The outcomes of the background checks do not automatically bar candidates; however will be assessed against the inherent requirements of the job.
Back Share
Apply Now",3.0,"ME Bank
3.0",Melbourne,-1,501 to 1000 Employees,-1,Company - Private,Banks & Credit Unions,Finance,$100 to $500 million (USD),-1
Software Engineer - Machine Learning/Data Science,-1,"Zendesk is looking for a Software Engineer - Machine Learning/Data Science for a full time position in our Melbourne office.
As part of our engineering team, you will work at a scale where the challenges start to get seriously interesting. Our global engineering team is widely dispersed over the world, with people across nearly every continent. You will get a chance to do cool things with a diverse bunch of people while working in the Melbourne office that is home to Zendesk’s first machine learning (ML) research team.
The Data Science Team, together with Data Engineering, have built Satisfaction Prediction, Answer Bot and Content Cues — products that use Machine Learning (ML) and Artificial Intelligence (AI) to help our customers work more efficiently.
What you get to do every day:
We’re currently looking for someone to join our team as we research, develop, and productionise Machine Learning and Deep Learning models. In addition to frequenting Melbourne’s finest purveyors of coffee, ramen, and bulgogi, you may find yourself:
Building machine learning models including neural networks in TensorFlow
Writing and deploying production-grade Python
Querying and constructing datasets in AWS Athena, Spark
Evaluating and responding to real-world model performance
Scaling your ML to millions of predictions per day
Presenting your work to a broader audience
Watching your algorithm help Zendesk’s end-users
What you'll bring to the role:
A strong foundation in a quantitative discipline (e.g. machine learning, statistics, bio/eco/etc-informatics, econometrics, etc) is critical for this position. While experience in deep learning and natural language processing would be beneficial, your best qualities are:
dedication to continuous learning
collaborative work attitude
strong communication skills
You should also be comfortable with at least one programming language, such as Python, R or Scala.
Application Deadline: 18/11/2020
Job Types: Full-time, Permanent
Salary: $85,000.00 – $110,000.00 per year
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Temporarily due to COVID-19",4.5,"Zendesk
4.5",Melbourne,-1,1001 to 5000 Employees,2007,Company - Public,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),-1
Software Engineer (Machine Learning),-1,"About the Role
AdelaideMRI is building a medical reporting tool. We require an engineer to work primarily on machine learning projects to improve reporting speed and report comprehensiveness.
You will perform data analysis of medical report datasets and image datasets to infer sentence recommendations, image classifications, or other actionable results for the doctors.
Skills and Experience
Background in machine learning or image processing
Qualifications in Computer Science, Software Development or Engineering or equivalent experience
Bonus points for Python
No prior medical knowledge is required.
This position offers flexible hours and work arrangements.
Job Type: Full-time
Experience:
Software Engineering: 1 year (Preferred)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Yes",-1,Adelaide MRI,Australia,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Hey there, we’re PEXA!

We started as an idea: to deliver a single, national e-Conveyancing solution. We collaborated with the industry to create a national electronic lodgement and settlement platform: PEXA. From our humble beginnings, we’ve now grown to more than 320 employees across 5 different states. We’re still expanding at a rapid rate and constantly challenging ourselves to create great experiences for our members as they transition to fully digital conveyancing.

Why become a PEXArian?

Great question! Being a PEXArian is so much more than just a job. We are passionate, motivated & unashamedly enthusiastic at PEXA - we love what we do and we’re proud to admit it! Creating brilliant member experiences wouldn’t be possible if we didn’t also strive to create an amazing employee experience. Alongside our members, our employees are at the heart of everything we do.
Here’s a snapshot of what your life at PEXA could look like:

Your growth:
We encourage you to hit your personal and professional Learning & Development goals with our tailored programs and tools.

Your wellness:
We care about your holistic well being - a fully stocked kitchen, four wellness days, a $250 wellness subsidy as well as lunch and learn sessions to support your financial well being.

Your work/life blend:
We know that work is just one aspect of your life, we want to help you create your ideal work/life blend, rather than squeezing in life around work.

Your family:
With a range of benefits aimed at supporting your family including access to a subsidised school holiday program, extended parental leave and flexi-time to support your return to work, superannuation payments for unpaid parental leave for primary carers and a childcare allowance for pre-primary aged children, when we say, ‘welcome to the family’, we really mean it!
The impact you'd drive:
The successful candidate will be responsible for developing, and maintaining infrastructure to support the delivery of new and existing products. They will also be contributing to establish the rules and frameworks for obtaining the required approvals for new products.
On day one we’d love you to have:
Experience with Python, Spark
Event streaming/sourcing with Kafka or AWS Kinesis
Experience with data structures, formats and data security best practices
AWS experience (e.g CloudFormation, S3, ECS, Lambda, SQS, IAM, KMS, DynamoDB, Glue, Athena)
Query construction and optimisation (e.g. SQL, Elasticsearch, Splunk, DynamoDB)
Git, version control practices, and continuous integration/delivery servers
PyUnit and unit testing frameworks
Production release cycles and maintenance
Collaborating with technical and non-technical teams
Even better:
Agile methodology/delivery
GraphQL
Modern frontend technology (e.g. ReactJS, TypeScript)
Machine learning frameworks and tools (e.g. TensorFlow, PyTorch)
OAuth 2, SAML 2, JWT
Data visualisation and exploration tools (e.g. Jupyter notebooks, Tableau)
AWS SageMaker
Sounds like you?
If this role sounds like you, apply today to have your application reviewed ASAP!",3.9,"Property Exchange Australia Limited
3.9",Melbourne,-1,201 to 500 Employees,2010,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Ongoing position
Full time
Based in Sydney, NSW
Who we are
Australian Red Cross is part of the world’s largest humanitarian organisation. Our aim is to improve the lives of the most vulnerable people in Australia and across our region.
About the role
The Data Engineer role will sit within the Data and Integration Squad in IT and will own (design, implement and support) the AWS Big Data technologies such as the Data Lake and Data Warehouse and support the organisation in growing the data analytics capabilities at Red Cross. In addition to this, the data engineer role will also administer the Power BI tool and support the implementation of the data mastering capability.
What you will bring
Experience building and optimizing data pipelines, architectures and data sets.
Experience in dimensional modelling and building data vaults
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with structured, semi-structured and unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Why work for us?
Work for purpose and know that your work assists Red Cross support and empower people and communities in times of vulnerability.
Generous salary packaging options available that can increase your take home pay.
Further information
To find out more about this opportunity please see the position description below or contact Sharath Kumar Gurram on 02 8651 8839.
Position Description: Position Description - Data Engineer .pdf
Applications for this position will close at 11:55pm Thursday, 5 November 2020.",4.1,"Australian Red Cross
4.1",New South Wales,-1,1001 to 5000 Employees,-1,Nonprofit Organization,Industrial Manufacturing,Manufacturing,$500 million to $1 billion (USD),-1
Junior Fullstack Data Engineer (Python and React),-1,"Formbay is the leading Renewable Energy Certificate Trading company in Sydney. We provide Digital Workflow and Compliance solutions in the renewable energy industry and document processing.
Thanks to our meteoric growth and our commitment to be the best at all we do, we've identified the need to bring on board a new Junior Fullstack Data Engineer.
Reporting to our Principal Machine Learning Engineer, you will help build Machine Learning pipelines for our existing Digital Workflow and Compliance solutions to automate fraud detection and document processing over terabytes of photographic and documentary data – including documents, photos, GPS data and aerial/satellite photography.
Our stack is based on Python, JavaScript, Dask, Tensorflow, CUDA, Nix/NixOS, AWS, Docker, PostgreSQL and more – familiarity with these applications will give you a leg-up on the competition.
Our ideal candidate will have the following competencies:
SQL
Python
JavaScript/TypeScript
Our candidate must also be comfortable working with Linux.
Located a stone's throw away from the Queen Victoria Building in Sydney's bustling CBD, we are centrally-located with easy access to public transportation, bars, cafes and fine dining.
Formbay will provide flexible working hours, a generous remuneration package and the opportunity to work on a world-first software solution are what we can offer you. Free, twice-weekly gym sessions and really, really good coffee are also available.
No hiring/recruitment agencies need apply.",5.0,"Formbay
5.0",Sydney,-1,1 to 50 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is an experienced and qualified Data Engineer to join our IT team based in Birtinya.
Key Responsibilities:
Create and maintain data pipelines and or ETL scripts
Create and maintain data integration including API and Batch interfaces
Performed detailed data analysis
Create and maintain corporate data models
Create and maintain data visualization using Qlik.Sense , PowerBI or Simliar Toolset
Experience in defining, building and maintaining data virtualization and/or star schema data warehouses
Maintain, tune and optimise database, integration and visualisation toolsets
ABOUT YOU:
To succeed in this role, you’ll need to bring the following experience and skills:
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Excellent communication skills both oral and written, with an ability to bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking
Experience with data analysis and modelling will be beneficial

How to Apply
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kawana Waters,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Graduate Data Science / Engineer,-1,"The NRMA is an organisation looking to the future, and right now, we are on the lookout for people who can help us reach our goal: to continue to shape the way Australians move, for the next 100 years and beyond. www.mynrma.com.au.
Everyone new to the team, along with our current staff, will temporarily work from home until it is safe to return to our offices. All interviewing and on boarding will be done virtually due to COVID-19.


Your opportunity
As Graduate Data Scientist or Engineer you will be part of the Data Engineering team delivering cloud data transition program for business initiatives and supporting the entire data platform build.
Your key responsibilities will be to:
Implementing Concepts of Data Warehousing, Data Mart creations within Cloud
Use of SQL for data analysis and insights
Building AI/Machine Learning prototype for implementing and supporting existing algorithms
Data Analytical reports build, using different tool sets


Requirements for Success:
Relevant Degree - Computer Science, Computer Engineering, Software Engineering, Data Science
Excellent SQL skills and demonstrated working knowledge in Python
Demonstrated understanding in data structure and algorithms.
Knowledge and concept of data warehousing methodologies
Any reporting tools experience Tableau or Oracle Analytics Cloud, Looker is desirable
Exposure to Google/AWS/Azure/Oracle any cloud based platforms is desirable
Good communication and interpersonal skills

If you have the required skills and the passion to join our high performing team, please apply today.

Employee Benefits
To ensure our employees feel valued, empowered and celebrated we provide a range of employee benefits including:
50% discount on all NRMA insurances
Free Roadside Assistance
12 weeks paid primary and 4 weeks paid secondary parental leave
Free NRMA Blue Membership
At the NRMA Group, we are People Moving People and diversity and inclusion are part of our DNA. Together, we continue to build an inclusive culture that encourages, supports and celebrates the diverse voices of our employees. It fuels our innovation, promotes flexible ways of working and connects us closer to our members and the communities we serve.",2.5,"NRMA Motoring & Services
2.5",Sydney,-1,501 to 1000 Employees,-1,Nonprofit Organization,Casual Restaurants,"Restaurants, Bars & Food Services",$500 million to $1 billion (USD),-1
Data Centre Engineer,-1,"We are a leading world group that provides low-carbon energy and services. To tackle the climate emergency facing us all, our aim is to become the world leader in the zero-carbon energy transition ""as a service"" for our clients – particular for companies and regional authorities. We use our expertise in our key business areas (renewables, gas, services) to provide competitive and bespoke solutions.
The Data Centre Engineer will be employed as part of a 24/7 ongoing shift to coordinate and monitor third party service providers, maintain the data centre facilities and infrastructure plans, coordinate the implementation of customer requests within the data centre and monitor systems, all in accordance with the Contract KPIs and SLAs.
Coordinate and monitor third party service providers for regular maintenance & testing, service faults & call outs, ensuring works are performed in accordance with Contract SLAs
Monitor and maintain the data centre facilities and infrastructure plans and documentation, including electrical, mechanical, hydraulics, fire and BMS/EMS systems
Coordinate the implementation of internal and external customer requests within the data centre
Perform scheduled plant checks and minor maintenance works
Ensure all Work Order requests are raised and closed in a timely manner
Conduct inductions for staff, vendors and contractors
Ensure all work permits for vendor works are raised and closed
Perform inventory checks on all equipment and critical spares

Qualifications
The selected candidate must be able to demonstrate:
Electrical or HVAC background, or Graduate Electrical or Mechanical Engineer
Passionate about quality work and career minded looking for a new challenge
Can commit to a day and night shift roster (2 days of day shift, then 2 days of night shift, 4 days off)
Ideally able to commence asap
As part of carrying out the duties of this role, it is mandatory to hold Australian Citizenship.

If you are interested and meet the selection criteria apply with an up-to-date resume via the apply instructions on this website.

ENGIE Services is an EEO employer, where all applicants are treated with fairness and respect and have equal access to the opportunities available.

We will not be engaging in the services of a recruitment agency to fill this vacancy and therefore request all interested candidates apply directly to this advertisement.

Job
: Maintenance
Primary Location
: Oceania-Australia-New South Wales-Erskine Park
Organization
: ENGIE Services Australia and New Zealand
Schedule
: Full-time
Nature of Responsibility
: Senior operational / administrative role
Job Posting
: Sep 11, 2020, 6:29:59 AM",3.7,"ENGIE Services Australia & New Zealand
3.7",Sydney,-1,5001 to 10000 Employees,1995,Company - Public,Energy,"Oil, Gas, Energy & Utilities",$2 to $5 billion (USD),-1
Senior Data Engineer,-1,"Senior Data Engineer, Temporary, SYDNEY - McKell

Job Title: Senior Data Engineer

Salary: SNSW Grade 9/10 - The package includes base salary range of $111,806 to $134,667, plus employer's contribution to superannuation and annual leave loading.

Location: Head Office – Haymarket

Employment Status: Temporary through till 30th June 2021


About Service NSW:

Service NSW is making it easier for people and businesses across NSW to access government services. The role designs, builds and analyses complex data from multiple sources to identify revenue, process and business improvement opportunities; providing new information and insights to the business to inform planning, continuous improvement and performance.

About the Role

We are currently seeking to appoint a Senior Data Engineer to deliver expert advice and services in the design of a Single View of Customer and data-related services to support the achievement of business outcomes and strategic goals. We support flexible working practices with staff working remotely during this time.

In this role you will:

Design, build and support a modern data platform based in AWS and vendor technologies.
Provide expertise on data modelling for Graph data model and Customer Data Platform (CDP).
Create data pipelines, load, transformation and reporting workloads in AWS.
Work with the latest data engineering technologies like Apache Kafka, AWS Kinesis, AWS Neptune, AWS Glue and AWS Athena.
Contribute to the design and decision-making of the right tool or platform for the job according to requirements.
Provide expert advice and guidance on data quality and data engineering best practices.
Support a “bigger than you can imagine” scale of data in production environments.
Design, develop and support a metrics-driven reporting solution and a meaningful business intelligence platform.
Document the solution design and support procedures of solutions.
Produce reports, visualisations and recommendations to answer complex business problems that are presented in the most appropriate format to ensure clarity for target audience.
Analyse and define new process improvement opportunities to support continuous improvement and business outcomes; providing advice to stakeholders, on ways to improve the efficiency and reliability of data products and services.
Be very responsive to the information needs of the business by corresponding to customers in a timely manner and provide support/solutions to issues raised.
Troubleshoot and perform root cause analysis on production issues. Identify and implement long term solutions to problems. Perform scheduled maintenance, release deployment and production support activities after business hours, from time to time.
Liaise with internal and external customers to discuss and gather requirements, solutions etc. and maintain a good working relationship with the stakeholders.


Skills and Experience Required:

Solid experience with workflow technologies designing and building data pipelines, data models and data stores.
Experience working within and an understanding of Amazon AWS ecosystem, including security and performance tuning.
Hands on experience working with different types of databases, with focus on Graph and NoSQL databases.
Experience with data streaming required. Having used Kafka and related technologies is an added advantage.
Sound knowledge and experience working with batch processing, data extraction and API integration.
Hands on experience with at least one programming language: Java, Python or scripting.
Demonstrated experience working in an Agile based, fast paced, complex environment within cross-functional teams.
Experience developing systematised insights, data analytics and reporting solutions is an added advantage.
Experience with interactive visualisation of data insights is an added advantage.


Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Salary Grade 9/10, with the base salary for this role starting at 111,806 base plus superannuation

Closing Date: 6th November at 9:59am - applications will be reviewed on a rolling basis, applications may close early or extend

Please apply online, direct applications submitted via email will not be considered.

The Department of Customer Service is proud to be an EEO Employer who are fully focused on equality and believe deeply in diversity of all identities making us different and a true reflection of our NSW customers. As an inclusive workplace, we support various employee resource groups, practice flexible work and workplace adjustment.

If you do require an adjustment during the recruitment process, please notify us on your application form.",3.2,"Service NSW
3.2",Sydney,-1,501 to 1000 Employees,2012,Government,State & Regional Agencies,Government,Unknown / Non-Applicable,-1
Data Engineer - Entry / Mid Level,-1,"Work with a great team on interesting projects customers
Gain more experience in AWS, Data, DevOps cloud operations
Got a working knowledge of AWS? We will teach you the cool stuff!

Itoc is seeking an up and coming Data Engineer to join our growing Data Team in Sydney.

This is an exciting role working with databases, data lakes, data warehouses, data transformation (Python SQL) and enabling AI/ML.

You will be implementing foundational, robust and production ready data platforms to enable business data-discovery, self-service, AI/ML functions across a range of client types and industries, allowing them to do more with their data.

You'll be responsible for:

Deploying data repositories such as lakes and warehouses.
Contribute to our growing portfolio of data solutions.
Ongoing optimisation and management of data platforms.
Development of transformational logic for data pipelines
Data evangelism. We want to show our clients how to follow the best practices for data.

Desired Skills and Experience

To take up the challenge, you will have a depth of skills and experience including:

1-2+ yrs of focused data experience working with SQL and/or NoSQL solutions
A solid education in Software Engineering or equivalent industry experience.
Anything Data focused preferred.
Ability to analyse business scenarios and associated data landscape to derive potential opportunities.
Strong foundation in Python and SQL
Working knowledge of APIs
Principle knowledge of the different relational database platforms and modern data storage techniques
Knowledge of the different aspects of data environments
Collect, store, process, verify consume
Experience with version management systems (such as GIT)
Working knowledge of AWS or another cloud platform - we will teach you the cool stuff.
Great communication skills, an ability to work closely with customers, developers and engineers and the confidence to present ideas in open forums.
Relevant tertiary qualifications and/or industry certifications.
Great communication skills, an ability to work closely with clients, developers and engineers and the confidence to present ideas in open forums.

While not required, a background in consulting and professional services is highly desirable.

Itoc Description

This is an exciting and challenging career opportunity to join the growing Sydney-based Data Team of a leading cloud solution provider where you will be given support to reach your long term career goals. You will be part of a team of cloud experts and will work in an environment of continuous improvement and learning delivering innovative cloud solutions across SaaS, online business and enterprise business.

On offer is a chance to join a team with a great working environment, in an organisation that values its employees and sees the value in ensuring they are engaged. Our team are clearly passionate about what they do, that's why we won the following awards:

Customer Obsession Partner of the Year 2015: ANZ Region
Customer Obsession Leadership Partner 2015: re:Invent

As an employer of choice Itoc offers competitive remuneration, training and development programs and a great working environment. We value a healthy work life balance.

The Perks

MacBook or Dell
Continuous internal learning that will provide training and career development opportunities
Working with a collaborative, social team and leveling-up your skills faster than you will anywhere else.
Quarterly social events

Itoc

Culture and smarts are important to us. Bring your secret sauce. This is no ordinary environment, you will work along some of the Cloud’s best. All engineers at Itoc must gain at least five AWS certifications. We work hard but we have fun.

Please note you must have full working rights in Australia and be available on-shore for face to face interviews.

No recruiters please.",4.0,"Itoc
4.0",Sydney,-1,1 to 50 Employees,2013,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Date: 01-Oct-2020

Location:
Melbourne, VIC, AU

Department:Description:
Technology discounts - from Apple HP Lenovo to Windows
Flexible work arrangements - work in a way that suits you best
Salary packaging - to suit your personal and financial circumstances

Do you want to work for one of the fastest growing data teams in Australia? Do you want to work on multiple data platforms and provide new solution offerings by leveraging cloud and big data technologies?

About the team

Big data information and analytics. Three words that spark apprehension in most businesses. But our team of experts are constantly curious and excited about combining our wonderful array of technological expertise to transform data into our clients most valuable assets making their work smarter. Our data consultants are supported with resources training and tools they need to excel at their work but also the freedom and power to create their own paths forward to make a difference.

As a Senior Consultant in Big Data you will work closely with the team and stakeholders to build and deliver a Cloud based vision for a next generation Big Data analytics platform with strong focus on data quality data security and deliver the systems that process huge volumes of data.

What will you typical day look like?

You will play a pivotal role in - Designing and producing high performing and stable applications to perform complex processing of massive volumes of data in a new cloud based architecture; Building real-time data processing applications which are integrated with business systems to enable value from analytic models to drive rapid decision making; Contributing to system architecture design for a data platform (including cloud-based structures both on and off premises data warehouse components and data lakes); this could cover a range of technologies various countries/locations and lines of business; Support data strategy or technology strategy definition programs including technology stack definition and target operating model requirements

Enough about us lets talk about you:
You are someone with:
Use of traditional data analytics tools and techniques (e.g. MSSQL Oracle MySQL) and ETL software (e.g. SSIS Informatica CloverETL)
Working in large scale cloud data solutions using platforms such as AWS or Azure or GCP will be a bonus.
Experience in scripting or programming (e.g. Python Java Scala C#)
Excellent verbal and written communication skills to adapt to technical and non-technical audiences.
Educated to degree level (or have equivalent experience)
Why Deloitte?

At Deloitte we create positively differentiated work experiences that enable our people to feel valued and achieve their full potential. We value difference and embrace people with diverse backgrounds and thinking styles. Knowing that people work best in different ways we are happy to discuss alternative arrangements if the working pattern you are looking for is not specifically indicated.",3.8,"Deloitte
3.8",Melbourne,-1,10000+ Employees,1850,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Engineer,-1,"Opportunity to grow the team
Period of growth
Intuitive app
S2M are working with a FinTech who have created a unique financial product to help thousands of people better manage their finance, and is currently scaling the company to the next level!

They are looking for a Data Engineer to join, and looking for someone who wants to be hands on, with opportunity to grow the team in future.

Role:

Looking for people with strong AWS experience. You will need passion for data and a cloud, through which you will help a rapidly scaling Australian FinTech establish their data infrastructure from the ground up.
5+ years’ experience as a data engineer within the data and analytics domain
A python 3.X aficionado who is very comfortable creating and orchestrating AWS data pipelines with nothing but code
Strong project delivery toolset experience in open source data integration tools
Experience with processing large volumes of complex data including visualisation and insights generation
Ability to define and develop data integration patterns and pipelines
Ability to assess complexity of data (volume, structure, relationship etc.)
Hands on experience working with different databases (RDBMS, NoSQL, Blob storage etc)
Hands on technical expertise setting up DevOps automation
Hands on experience working technologies/platform e.g. AWS, Dockers, Containers
Experience building data profiling and data cleansing frameworks
Technical reconciliation and reporting
Knowledge and experience in end-to-end project delivery, either traditional SDLC or agile delivery methodologies (or hybrid approaches)
Exceptional communication, documentation and presentation skills
If this sounds like you, get in touch today - kate.gabb@s2m.com.au
3167410agsdf",3.1,"S2M
3.1",Sydney,-1,Unknown,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Analysts,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is seeking experienced and qualified Data Analysts to join our IT team based in our corporate office in Birtinya (Sunshine Coast) or at our meat processing facility in Kilcoy.
Key Responsibilities:
A mixture of data analysis and commercial skills to source, blend and analyse data to gain insight and answer key commercial questions
Working with strategic leaders to define and model Key Performance Indicators, and assist in building forecasting models
Working closely with data engineers and BI developers to specify data pipelines and report visualisation
Drive the creation and implementation of data quality business rule including data definition, governance and quality assurance
About You:
To succeed in this role, you’ll need to bring the following experience and skills:
Proven ability to derive insight and knowledge from data using commercial expertise is a strong requirement
Strong SQL and Excel skills are essential, along with strong data analysis and commercial insights
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Effective people communicator - engage with stakeholders on reporting needs, interpret requirements into visual solutions and train/deliver the outputs to the stakeholders getting signoff of acceptance
Bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking

How to Apply:
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kilcoy,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Network Data Engineer,-1,"Min 6+ years of experience in the relevant technologies
Australian Driving License for visiting remote locations / Data Centre for day to day technical work.
Managing Network devices (switches, routers, firewalls, load balancer, and wireless technology)
Performing MACD activities for all network devices.
Supporting BAU operation activities.
Proficient in performing in-depth details of technical troubleshooting, cause and provide recommendation to the client for incidents causing extended network outage to client’s critical locations.
Provide exceptional network services in terms of network support, break-fix, design and consulting, new projects, implementation.
Configure, administer, and document firewall infrastructure.
Manage the firewall deployment, rules migrations, and firewall administration.
Supporting Cloud Migration Activities from traditional to AWS/Azure.
Setting up VPN tunnel with Cloud and 3rd Party network devices.
Integrating and upgrading existing ISP bandwidth with support from ISP Vendor.
Setting up VPN profiles for Users.
Installing hot fix and patches to mitigate the security devices from attacks and bugs.
Reviewing and fine tuning the firewall rules and NAT rules.
Documentation and change control.
Mentoring, Motivating and Guiding support teams
Technical skills:
o LAN
o Wireless
o WAN
o MPLS
o Routing protocols (OSPF,BGP)
o DMVPN
o Azure cloud Networking
o Network Security
Fortigate Manager / Analyzer / Firewall
Cisco ASA
Firepower FTD
Cisco Any connect
Site to Site VPN
F5 Load Balancing and Scripting iRule
Job Types: Full-time, Contract
Schedule:
8 hour shift
Experience:
Scripting: 5 years (Required)
Data Network: 5 years (Required)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Required)",3.6,"Total IT Global
3.6",Sydney,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Engineer - Processing & Analysis,-1,"Job Description:
Design,build and maintain the ingestion system to support various types of data(e.g. User behavior, RDS, NoSQL db and others) to be ingested to the data warehouse more timely and accurately
Translate data requirements into scalable technical data service with low latency and high concurrency
Design,build and maintain the batch or real time data pipeline in production using Hadoop big data technology
Analyze and improve efficiency, scalability, and stability of the system
Define and manage SLA,Data quality for all data sets in allocated areas of ownership
Requirements:
Minimum B.S. degree in Computer Science or a related technical field
2+ years of working experience in programming languages,such as Java,Scala,Python
Familiar with Hadoop, Spark and Flink data processing, experience of TB data processing experience is a plus
Familiar designing and operating of a robust distributed system is a plus
Understand data mining or machine learning
Excited to work intimately with data
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"SYNOPSIS:
Lead Data Engineer
Applications close Sunday 8 November 2020
Ongoing
Contact name: Shyni Sasikala
Phone: (02) 6249 9048
Email: Shyni.Sasikala@ga.gov.au

The Data Policy and Informatics section within the Digital Science and Information branch creates, implements, and promotes policies, platforms and tools that improve and support the quality, discoverability, accessibility, and general usability of Geoscience Australia’s science data products. The section consults with internal and external research, government and industry partners to establish collaborative data frameworks, architectures and models within Geoscience Australia (GA) and across broader national and international communities of practice. The section innovates, builds and maintains tools, systems, processes and governance that enable digital data management, cataloguing and open data delivery.
GA makes accessible a wide range of geoscientific and spatial data to a wide variety of stakeholders in multiple formats, and in recent years GA's data volumes have grown exponentially. GA is focussed on making its data and metadata assets accessible so that they can be used in machine to machine interactions for data analytics and other applications in environments that range from High Performance Computing (HPC), through high-end cloud servers, to mobile devices.
We currently have two opportunities for Lead Data Engineers in the Informatics team. The Lead Data Engineer is responsible for innovating and exploring new technologies that will advance GA’s science goals and maximise the uptake and use of GA’s science data. The Lead Data Engineer reports to the team’s Assistant Director but also works closely with other developers, data scientists and engineers within the Digital Science and Innovation (DiSI) branch, as well as diverse stakeholders both within and external to GA.",3.9,"Geoscience Australia
3.9",Canberra,-1,501 to 1000 Employees,2001,Government,Federal Agencies,Government,$100 to $500 million (USD),-1
Data Engineer,-1,"The Seven Network is part of Seven West Media, one of Australia’s most prominent media companies, with a market leading presence in content across broadcast television, online and in print. Comprising some of Australia’s most renowned media brands, SWM includes not just Seven Network and its affiliate channels 7two, 7mate, 7flix and BVOD offering 7plus, but also 7NEWS.com.au, The West Australian, The Sunday Times and more.
At Seven we are here to bring all Australians closer to the moments that move us - we’re first on the scene, with our finger on the pulse, on demand, in the moment. Together, we’re responsible for creating and sustaining authentic Australian engagement.
A new and exciting opportunity has opened for a Data Engineer to join the Audience Intelligence team. Based in Sydney and reporting to the Head of Data Enablement, you’ll be responsible for:
Implementation of end to end data solutions to support Data Strategy for the SWM group.
Work closely with the Data Solution Designers to develop and maintain scalable data pipelines and build out new file and API based integrations to address requirements from the various business stakeholders.
Collaborates with engineering, analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organisation.
Work on Data Preparation for analytics and data scientist team members and assist them from an engineering perspective in building and optimising the models including building the automation of the end to end workflows
Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.
Perform data analysis required to troubleshoot data related issues and assist in the resolution of production data issues.
Work effectively with vendors for successful delivery of projects and acceptance of the solution
Work on Delivery projects using Agile Software Development methodologies
We are looking for someone who has:
Bachelor's degree in computer science, computer engineering or other technical discipline is essential
Proven experience working as a digital analytics specialist
Extensive experience with digital analytics implementation (e.g. Google Analytics, Snowplow, Adobe Analytics) and BI processes and visualisation platforms
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience in ETL and building and optimizing ‘big data’ pipelines and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Experience with big data tools: Hadoop, Spark, etc., AWS cloud services: EC2, S3, Lambda and familiar with version control systems: Git
Strong coding skills with knowledge of Unix/Linux and scripting languages such as Unix Shell scripting, Python desirable
Experience supporting and working with cross-functional teams in a fast-paced environment.
Ability to multi-task and problem solve with changing demands and priorities
Ability to work under pressure to meet deadlines and detail oriented
Your success is our success: we will provide you with opportunities for you to keep learning and growing, enabling you to challenge and develop yourself. In return, we offer a benefits program that has something in it for everyone.
Seven West Media is an equal opportunity employer and we are committed to creating a diverse and inclusive workplace.
Recruitment Agencies: Seven West Media does not accept any unsolicited agency resumes and will not be responsible for any fees related to unsolicited resumes.
Advertised: 19 Oct 2020 12:00 AM AUS Eastern Daylight Time
Applications close:

Back to search results",2.5,"Seven West Media
2.5",Sydney,-1,5001 to 10000 Employees,1956,Company - Public,TV Broadcast & Cable Networks,Media,Unknown / Non-Applicable,-1
BICON Rules Engineer,-1,"APS 5 - $73,299 - $80,410 per annum plus superannuation
Biosecurity Plant Division
Canberra, ACT
Play an active role in managing biosecurity risk to Australia
Work in a motivated and professional team with a wide range of skills and backgrounds
Full training provided

Who we are
The BICON Content Development Team maintains and improves the Biosecurity Import CONditions database (BICON) content to allow external clients to understand and comply with their biosecurity obligations and internal clients to effectively manage biosecurity risk and regulate imports. We work collaboratively with internal clients to comprehend and implement their BICON content requirements and optimise the use of BICON to publish clear import requirements and onshore management support procedures to effectively manage biosecurity risk.

The Jobs
Key duties of these positions include:

working with business content (import and permit conditions) and import programs to understand and construct decision tree structures in the BICON database, in accordance with system design and authoring conventions
executing changes to import and permit conditions in alignment with service standards while complying with system rules and authoring conventions
providing technical advice through various formats on the most appropriate means of authoring BICON content to achieve import program and stakeholder objectives
using workflow management tools to maintain detailed records of changes to import conditions and key decisions
performing administrative tasks including system reporting, data analysis and scoping tasks for the BICON content change work program
contributing to the development and maintenance of instructional material, authoring conventions and courseware
clearly documenting and reporting system issues
developing and maintaining effective working relationships with internal and external stakeholders.

What we are looking for
Knowledge and experience
Experience working with complex IT systems.
Experience working collaboratively and as part of a team.
Knowledge of the role of biosecurity is preferred but not essential.

For additional information, please read the Job Description below.
Candidate Information Package docx Opens in new window",3.9,"Department of Agriculture & Water Resources
3.9",Australia,-1,5001 to 10000 Employees,-1,Government,Federal Agencies,Government,$500 million to $1 billion (USD),-1
Cloud Data Engineer,-1,"Job no: 509605
Work type: Permanent Full Time
Location: Melbourne, Canberra, Sydney
Do you embrace digital disruption?
Do you love solving complex problems, designing sophisticated solutions and building innovative technology?
Do you believe in creating powerful actionable insights from Data and Analytics?
Do you want to work in a diverse and flexible working environment?
KPMG is one of the most trusted and respected global professional services firms. Through depth of expertise, clarity of insight and strength of purpose we help our clients solve complex challenges, steer change, strengthen, transition and grow. We are a team based practice and this extends to our clients whom we work and collaborate with, in solving complex problems. Together, we design, innovate and implement, providing enduring advice that support our clients and the services they deliver. Our clients vary in size and come from a diverse range of sectors – all sharing in a common goal: to embrace change and deliver services that make Australia a better place. We are looking for talented individuals who would like to join us on the journey.
KPMG’s Digital Delta Team
We re-imagine and re-invent organisations to become world class digital enterprises using advanced technologies, data and human insights. We help organisations to embrace Digital Strategy, Artificial Intelligence (AI) & Cognitive, the Internet of Things (IoT), Data, Analytics & Modelling, Mobile App & Web, and User Experience (UX) & User Interface (UI) and more.
We work with clients to:
Formulate strategies that re-imagine organisations
Harness innovation from the 4th industrial revolution
Actioning insights from trusted data to consistently and quickly make clear decisions
Build adaptive organisations
Thrive as a connected enterprise – front, middle and back office
This is how you’ll contribute:
We are looking for ambitious Data Engineers who are passionate about helping clients define bold ambitions and deliver on them. Joining our team will take you on a journey of personal and technical growth and provide the opportunity to inspire confidence and empower change.
As a Data Engineer you are the designer, builder and manager of the information or ""big data"" infrastructure, preparing data for analytical or operational use. You will design, construct, test and maintain a data pipeline to pull together information from different source systems; integrating, consolidating and cleansing data; and structure it for use in individual analytics applications.
The KPMG Difference
Our people are focused on creating a diverse and dynamic environment that embraces and values differences. We value the variety of unique experiences, qualities and characteristics our people possess and we share and learn from each other.
We are proud to be consistently recognised as an employer of choice for women, and for our achievements in LGBT+ workplace inclusion.
Our commitment to ‘Flexibility’ allows our people to manage the changing demands of work, personal or family life. Explore the links below to hear our people share their experience @ KPMG:
Flexibility empowers wellbeing
Flexibility enables contribution to the community
Flexibility inspires technology & innovation
Flexibility supports family

Make KPMG the clear choice for your career and be Extraordinary!

Advertised: 09 Sep 2020 AUS Eastern Standard Time
Applications close:",3.8,"KPMG
3.8",Sydney,-1,10000+ Employees,1987,Subsidiary or Business Segment,Accounting,Accounting & Legal,$2 to $5 billion (USD),-1
Computer Network and Systems Engineer,-1,"Duties Include but are not limited to:
Tasks Include:
analysing, developing, interpreting and evaluating complex system design and architecture specifications, data models and diagrams in the development, configuration and integration of computer systems
researching, analysing, evaluating and monitoring network infrastructure to ensure networks are configured to operate at optimal performance
assessing and recommending improvements to network operations and integrated hardware, software, communications and operating systems
providing specialist skills in supporting and troubleshooting network problems and emergencies
installing, configuring, testing, maintaining and administering new and upgraded networks, software database applications, servers and workstations
providing network programming in support of specific business needs and requirements
preparing and maintaining procedures and documentation for network inventory, and recording diagnosis and resolution of network faults, enhancements and modifications to networks, and maintenance instructions
monitoring network traffic, and activity, capacity and usage to ensure continued integrity and optimal network performance
Skills and Experience Required:
Must have experience working in a Managed Service environment
Demonstrated experience in IT Networks and Data Centres
Understanding of systems and architectures to meet client needs
Experience in Help Desk including break / fix
Effective and timely documentation
Effective Task Management Skills
Be solution and outcome focused and willing to learn new technologies
Excellent communication skills with staff, clients and partners
Time management, ability to prioritise and deliver to schedule
Experience with N-Able and Connectwise desired
Open Cabling license desired
Job Types: Full-time, Permanent
Salary: $30.00 per hour
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,Trans-plant training,Canberra,-1,-1,-1,-1,-1,-1,-1,-1
Software Engineer (Data),-1,"If you are looking for an opportunity to make a real impact with smart people who are genuinely doing things differently then you've come to the right place! We're growing our data engineering capabilities and are looking for awesome data engineers to join our team.
With our diverse range of clients and projects, no day will look the same - but here's a great snapshot of what you'll be doing:
Work with some of the best Data Scientists and Engineers to deliver production-grade AI and Machine Learning systems as we deliver client projects from inception to production.
Consulting with our clients and working with them to build modern data systems using the 'best of' technologies and principles.
Advising clients on data strategy, architecture and technology.
Applying best software engineering practices in coding, monitoring and alerting, using CI/CD, TDD and cloud architectures.
Working over a wide range of big data tools and environments: not limited to; Apache Kafka, Spark, Python, Scala, Hive, Airflow, AWS EMR & Glue, GCP Dataproc & Dataflow, BigQuery, Snowflake, Redshift.
Who are we?
Glad you asked! We are Eliiza. Data science. Engineered for scale.
We are a passionate team of data scientists and engineers who apply data science and machine learning to solve real-world problems. Our mission is to create a bright future for Australian businesses and society in a world increasingly influenced by intelligent technologies.
We've created a culture that values diversity where people can truly be themselves! We care a lot about growing the Australian AI community in a positive direction, and we're doing several things to try and achieve that:
We provide opportunities for underrepresented groups to work in AI through our associate and intern programmes
We organise and participate in a range of community events, reading groups and meetups
We produce the AI Australia podcast
We blog about topics we care about
We stream brown bag sessions to the broader community
We're also part of Mantel Group's 'house of brands' which means it's not just the Eliiza team you'll work with, learn from and see at social events - there's another 230 of us across DigIO, Kasna & CMD Solutions!
So you're ready for something new?
We're keen to know more about you! Our team is made up of a range of people, with different experience across a huge range of data driven skill sets.
We'd love to hear from you if you have experience with:
one (or more) core language(s), ideally Scala, Python or Java
one (or more) cloud platforms, AWS, GCP, Azure
ETL/ELT concepts and technologies e.g. Data partitioning, Hive, Spark
streaming data concepts and technologies, ideally Kafka (Kinesis, Beam or Pubsub will do)
We'd be over the moon if you:
Experience with distributed/columnar databases (e.g. Snowflake, Big query, Redshift).
Experience with any of a variety of databases e.g. RDMS, NoSql, Columar, Distributed, Time series, Graph.
Knowledge of job orchestration and scheduling. Any experience with Airflow, Luigi or Oozie.
Experience with containers and container orchestration (Docker, Docker Compose or Kubernetes).
However, we value a diversity of skill-sets, and don't necessarily require that you're skilled with all of the above. If you feel you don't fit all the experience/skills listed above we still encourage you to apply or get in touch.
What's on offer if you join us?
We make sure you're always one step ahead by investing your learning and development, every year. We build our own training where it doesn't exist yet.
We hire smart people and get out of their way. By focusing on our five principles and not getting caught up in red tape, we trust you to get the job done.
You'll get all the tools you need - a new iPhone or Google phone, a new Macbook Pro or Dell, and a lot of branded swag!
But hold on, you mentioned a house of brands?
We certainly did! Mantel Group is an Australian-owned, 'house of brands' company with four technology businesses (Eliiza being one of them!) across Melbourne and Sydney. We're building a group of companies with open borders so we can support you to take on new skills without leaving an awesome team - we understand you won't have one job for life!
We may only be just two years old but Mantel Group has already been recognised #9 in the 2020 Best Places to Work in Australia and #4 in the AFR's 2020 fastest growing new companies.
Keen to chat?
Click ""Apply"" to share your details with our talent team, and we'll be in touch.
In the meantime, check out 'how we hire' to find out what's in store if you're successful and get to know us better by visiting our website and following Eliiza on LinkedIn.",-1,Eliiza,Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Infrastructure Engineer,-1,"Job Description:
Design and grow the Shopee data platform to support a variety of big data applications using open-source technologies including Kafka, Hadoop, Presto, HBase, Spark, Hive, Druid, and our own creations. Some examples include a real-time data streaming platform, a unified query platform, a cluster management system, and a machine learning platform
Dig into the source code of some open-source big data system to get the whole control and familiar with the details, configurations, designs and source code. Develop and maintain the internal release of big data systems and components as the business requirements.
Keep close and overall monitoring for all the deployments of the systems, maintain the system’s stability, improve the performance, discover the performance bottlenecks, tracking and troubleshooting, cost optimisation.
Requirements:
B. Sci. / Ms / PhD in Computer Science or a related technical field
Familiar with at least one of these languages: Java, Scala, Python, Bash under Linux / Unix. Scala is a plus
Familiar with the use and compute logical of SQL
Knowledge about the Big Data Infrastructure system technology like Distributed File System, Distributed Computing, Distributed Database will be a plus
Hands-on experiences Hadoop, Spark, Kafka, and/or Presto will be a plus
Love to use and develop open-source technologies
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"Work on an award-winning, international technology!
Endless career opportunities
An innovative, friendly team of 300+
This role will be focused on the development of our existing ClaimLogik line of products as well as working on our new cloud-first, modern suite of applications.

Intelligent Thought, our technology business is scaling and shipping our software globally. Already profitable, part of a much larger group business, with investors such as Macquarie Capital and Envest – we are all set to deliver textbook disruption to the Insurance Industry. The growth of the platform, of our customer base, and the increasing industry demand have led to the need for this role to help the team scale.

Our Philosophy
Give each employee a sense of purpose and an environment for them to connect the importance of their role to delivering a service that matters to our customers.
Challenge the ‘why’ of traditional claims processes.
Keep it simple – do only what brings value and what matters to the customer
Enable employee decisions, empower our people
Responsibilities:
Create, extend and maintain ETL pipelines to form our data lake, data warehouse and analytics platform (currently using the Microsoft Azure set of tools and service)
Help define the optimal data pipeline architecture
Influence the tool selection, platform selection, data architecture and strategy which will transform the business to be truly data-driven
Understand, analyse and size user requirements
Work with different parts of the business to provide them with the insights they need to deliver the best results
Skills & experience:
Degree or qualification in computer science or related
Advanced knowledge of relational database, including query authoring and query optimisation (MS SQL Server and PostgreSQL).
Experience building and optimising ETL pipelines
Experience designing complex data models
Experience working with cloud platforms (Azure or AWS)
Efficient time management and organisational skills
High attention to detail and accuracy
Effective communication skills to build strong working relationships; both written and verbal
Proactive and results-driven
Why Claim Central?
Claim Central Consolidated is a global insurance industry leader across, claims management, insurance technology and data and analytics. Currently operating in the United States, Australia, South Africa, Italy and New Zealand, we have pioneered digitally connected claims management services across the globe. Claim Central is a disruptor and thought leader in the industry and we were recognised as the Australian Financial Review’s 8th Most Innovative Company in Australia in 2016. This business is in a period of unprecedented growth, transitioning our technology and services into multiple geographies at a rapid pace. Our unique culture is based on teamwork, collaboration, trust, respect and performance. We also offer many benefits apart from our exceptional team culture; including flexible work arrangements, and continued professional development.

Be a part of this journey in a career-defining role.",-1,Claim Central,Matraville,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer - AI/ML,-1,"Our client provides services to a major industry across the country. The business is still early in it's days of technology development and the environment is greenfields in nature (no pun intended), effectively working like a start-up.

Their data and analytics team have worked and built leading and bleeding-edge technologies in this space and what they have created so far may be game-changing. From a machine learning perspective, the progress they have made to the business has already seen proven success in changing the future of an industry that will have positive consequences for all those involved.

You will have previously worked in a technical capacity in the data and analytics space and have experience working with an organisation where machine learning has been implemented, not just a concept that the business talks about having or the technology team would love to have. The commercial experience you will have had in the ML field will be proven examples of where you have affected the way a business or industry used to perform, to the changes that have come about from this.

Technically, you will have extensive experience in the Microsoft space - Power BI, Azure etc and you will have previously mentored and coached junior members of the teams you have been part of.

This is a rare opportunity in Brisbane where the business has truly embraced and funded projects across the ML space and would be a great chance for those in the Data Development/Data Engineering field, who are looking to move into a Data Scientist role in the future.

Please send your application through if you would like to know more.",4.0,"Emanate Technology
4.0",Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Solution designer/ ETL Engineer & Data Modeller,-1,"We are looking for a Qualified and Experienced Solution Designer to join our client for a period of 6 months with a view to extend.
You will work closely with team members and your contribution will range across gathering and analyzing information, developing and documenting improved processes and work instructions and experienced DWH Lead with skills in requirement analysis, solution designing, developing, testing and supporting ETL solutions.
A hands-on solution designer, data modeler and ETL developer for Data Warehousing and ETL application transformation projects using Informatica PowerCenter.
Knowledge on AWS, S3, Redshift, Informatica BDM, and related technologies.
Experience working with IPython, PySparks, AuCuMo, Airflow, Jenkins, Github, Athena, JIRA, Rally, Spectrum, Glue, Flyway.
Good exposure on Oracle PL/SQL, aware of DBA activities, writing and performance tuning of complex SQL queries.
Contract length: 6 months
Job Types: Full-time, Contract
Salary: $650.00 – $800.00 per day
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,nducive,Melbourne,-1,-1,-1,-1,-1,-1,-1,-1
"Data Engineer, Wollongong NSW or Mount Waverley VIC",-1,"Company Description
BlueScope is a technically advanced supplier of steel and steel products in Australia. We are an inclusive organisation and every day we showcase our technology and expertise throughout the world.

Job Description
We are looking for two Data Engineers to join our IT team, based in Wollongong NSW or Mount Waverley VIC. Use your experience in analytics to unlock business value, enabling use of big data for insights and decision-making.
Reporting to the Data Product Owner for our Australian Steel Products (ASP) business, this position will support strategic goals related to data. This will see you:
Gather business and technical requirements with the view to deliver outcomes;
Develop and implement end-to-end data collection, consolidation, modelling and visualisation solutions;
Document metadata in a dictionary and catalogue;
Ensure consumers of such information understand its accuracy, timeliness, quality and sensitivity, so that it is used appropriately; and
Identify opportunities to enhance analytics.
What are the benefits?
Work in a supportive and collaborative team environment whilst we embark on a journey to transform the way our business uses data!
Our systems landscape is broad and diverse. You will be encouraged to think creatively to develop data solutions which solve real business problems.
Working in this role you will enjoy:
the chance to learn more about data science;
salaried remuneration with attractive superannuation options;
the opportunity to participate in a performance incentive scheme; and
access to further development and career opportunities with BlueScope.
Who are we looking for?
We welcome applications from professionals with experience in data analytics and/or programming. Supported by your knowledge of project delivery methods (e.g. Agile), you will demonstrate:
experience with data mining, wrangling, mapping and visualisation techniques (e.g. Azure Data Factory, Databricks and/or DevOps etc.);
well-developed ability in gathering business and technical requirements;
skills in developing and implementing collection, consolidation, modelling and visualisation solutions; and
a passion for sharing your knowledge and desire for ongoing professional development.

Qualifications

null

Additional Information
We're proud to have been named an Inclusive Employer for 2019–2020 by the Diversity Council of Australia. We believe that our people are our strength. Having a diverse and inclusive workplace enables us to improve our capability and ensure continued, sustainable success.
We know that workplace flexibility can mean something different to everyone. Under our B-Flex initiative all of our roles have some degree of flexibility. We encourage you to discuss your needs with us.
Applications close Sunday 25th October 2020.",3.3,"BlueScope
3.3",Wollongong,-1,201 to 500 Employees,-1,Company - Private,Construction,"Construction, Repair & Maintenance",$100 to $500 million (USD),-1
ETL Data Engineer,-1,"ETL Data Engineer

Join a team that’s changing how Australia lives, works, plays and grows
We want you to be the best version of you

Work with innovative teams and explore new technologies to help solve real-world problems.

A typical day as a Data Engineer

ETL / Big Data Engineering professionals will be responsible for guiding the full lifecycle of a Data solution, including:
Working in highly client-facing roles to contribute throughout the end-to-end delivery lifecycle of complex and large-scale digital solutions
Use case and business case development
Support existing and new applications utilizing in-depth technical and data knowledge. Troubleshooting complex issues and providing advisory services to improve the client’s data landscape
Help to streamline and simplify the clients’ complex data landscape by integrating different applications and data architectures
Implementation from requirements analysis, platform selection, digital architecture design, application design and development, testing, and deployment
Interstate travel may be required

Basic qualifications:
Bachelor’s degree
Experience across systems integration, information management, data management and architecture, and business analytics
Experience with being in a team focusing on large-scale, multi-release information centric projects
Experience with waterfall and agile delivery and run / application support functions
Part of a team working on End to end implementation of at least 1 big data project

Preferred Skills:
Hand on experience in Data warehousing using ETL tools such as DataStage, Autosys and TeraData
Hands on experience in ETL job development with multiple stages like sequential file, Transformer, Lookup, join, sort and Database stages.
Strong hand on skills in design, development and implementation of various data remediation, Data migration, data integration techniques.
Strong hand on data modelling experience.
Strong hands on experience in database performance tuning including complex query optimizations and physical database tuning using Teradata.
Understanding of architectural designs and strategy related to data migration, data cleansing, data quality and data consolidation.
Proven data analysis, requirement gathering and problem-solving skills
Exposure to Unix environment and shell scripting.
Experience in Banking and Financial services industry
Desirable: Knowledge of cloud computing infrastructure (e.g. Amazon Web Services EC2, Google Cloud, Microsoft Azure)
About Accenture

Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. We combine unmatched experience and specialized capabilities across more than 40 industries — powered by the world’s largest network of Advanced Technology and Intelligent Operations centers. With 513,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises. Visit us at www.accenture.com.

Accenture is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, marital, domestic or civil partnership status, sexual orientation, gender identity, or any other basis as protected by applicable law.

Vera Goga is the Recruiter managing this role. As the team experience high volumes of applications, we appreciate your patience to allow for a fair and timely process.",3.9,"Accenture
3.9",Sydney,-1,10000+ Employees,1989,Company - Public,Consulting,Business Services,$10+ billion (USD),-1
Student Engineer,-1,"The candidate will have the ability to:
Undertake onsite inspection to collect asset condition data based on the relevant engineering standards and technical guidelines;
Undertake desktop analysis to evaluate the condition and performance of the assets;
Provide the appropriate information, advice, engineering input and support services for the sustainable management of Council’s stormwater and transport networks.
Qualifications:
The successful candidate will be enrolled in a Bachelor of Engineering with a minimum of two years completed.
Position Number: 100678
Position Hours: Fixed term (3 months), hours will be negotiated with the successful candidate, maximum of 75 hours per fortnight.
Salary: Schedule A, Salary Point 4.0. $28.64 per hour ($55,853.45 per annum, pro-rata) in accordance with Glenorchy City Council’s Enterprise Agreement 2016
Please note that all successful applicants will be required to provide a current National Police Check prior to commencement of employment.
For further information on this position, contact Patrick Marshall, Senior Civil Engineer on (03) 6216 6800.
How to apply: Applications for this position must be lodged on this submission site or on the Glenorchy City Council website www.gcc.tas.gov.au - Careers page.
To be considered for this role, all applicants must address the key selection criteria in the and provide a current resume. A copy of the position description can be found by clicking the below hyperlink or on the Glenorchy City Council website.
Applications close at 8pm on Sunday, 1st November 2020
- Student Engineer",4.0,"Glenorchy City Council
4.0",Glenorchy,-1,501 to 1000 Employees,-1,Government,-1,-1,Less than $1 million (USD),-1
Data Engineer involving DevOps,-1,"Data Engineer involving DevOps
Axiom Technologies is an Australia based entity with the history of providing Managed IT solutions to medium to large scale enterprises globally. Please visit our website for more information about what we do at www.axiomtechnologies.com
Axiom Technologies is an Equal Opportunity Employer and encourage applicants from all backgrounds and gender to apply, including, Aboriginal and Torres Strait Islander candidates
Job Requirements:
8+ years IT experience, with at least 5+ years of “Data Engineer/Deveoper” focused titles/roles,
Data Tools: Hands on experience with Apache Beam.
Testing: Hands on experience with automated testing activities/outcomes
DevOps: Experience with the processes involving Microservices facilities for artifacts developed
Platform/OS: Mid-range/Unix
Languages: Unix (Shell) Scripting/commands, SQL, Python
File formats: Text, CSV, Parquet, JSON, XML
Scheduling: Jenkins, Airflow
Auto Scripting: Designing/creation of scripts for repetitive activity. E.g. Unix scripting/SQL
Big data: Exposure to Data Lake Concepts, Hive (Schema), HDFS
Source Control tools: GIT
Delivery Models: Agile, Scrum
Ingestion Design: Create/assess Source/Target data mapping designs
Frameworks: Development and delivery frameworks
Activity Reporting/Repository: Jira, Confluence.
Quality: Accuracy and attention to detail
Industry: Financial Services/Banking
Solutions: Define solutions from High level to detail design to address automating ingestion activity. Facilitate/confirm requirements from product owners, business team members and technical associates,
Process Automation: Automating processes in file management, testing data in files, analysis and design, configuration management.
Script Automation: Ability to design/create scripts to automate/improve data copy/migration/ETL for any repetitive activity.
Languages: Java, Python
Scheduling: Control-M
Databases: Relational. E.g. POSTGRESS, Oracle – as a ETL developer
File Formats: Mainframe – experience with referencing its data formats/copybooks
Big data: Experience referencing/using Hive (Schema) to access data in HDFS
Metadata management tools: MDM, EDC and Axon
Performance: Assess, recommend, improve mappings, SQL queries, Batch feeds
Automation Tools: Other tools that may add value to an automation program and generally support development. E.g. API, REST, JDBC, Webservices, Message Queues/Load balancer,
Cloud: Experience with processing of data files to be ingested/stored in the Cloud, preferably with AWS.
Prod Support: Experience in a production support role performing root cause / impact analysis – under time constraints
Experience in a similar role
8+ Years
What next?
If you are looking for that next challenge in your career and wish to apply for this role, please forward your resume to careers.au@axiomtechnologies.com",2.0,"Axiom Technologies
2.0",Melbourne,-1,1 to 50 Employees,-1,Company - Private,Industrial Manufacturing,Manufacturing,Less than $1 million (USD),-1
Data Engineer,-1,"About the Role
We are on an exciting digital journey so it’s a great time to join ME! We are seeking a Junior Data Engineer who enjoys rolling up their sleeves, learning and growing. As part of our Enterprise Data Team, you will ensure fit for purpose data warehouse solutions are built for use across the bank and by utilising best practise ETL standards, whilst ensuring the data is trusted by our BI developers and key business consumers. Oh, and you’ll get to work on Microsoft technology stack too!
You will be involved with investigating data issues, keeping data feeds flowing and collaborating with different projects across the bank to deliver quality data solutions. How important does that sound? What’s even more important is this role contributes directly to our overall business strategy through the provision of data to enable analytics & reporting, as well as supporting business and decision system processes.

About You
You’re naturally a highly motivated and energetic person who thrives in a dynamic, ever-changing collaborative team environment. Ideally you have previous experience as an ETL developer, Data Engineer or a BI developer, and if you have a degree in computer science or similar it would really put you ahead of the rest.

With your knowledge of SQL coding, data modelling, understanding of data warehouse concepts, plus experience of working on complex ETL solutions, you’re ready to expand your horizons and launch your career into the world of IT at ME.

About ME
We’re not like other banks.
ME was created by the industry super funds to be different from the pack – with a core purpose to help all Australians get ahead financially – no conditions, asterisks or exceptions. And we know that looking after customers starts with taking care of our people.
We believe everyone deserves the same opportunities in life, regardless of gender or identity, sexuality, ethnicity, religion or disability ‒ with internal affinity groups.
Perk ME up
Once you get your feet in the door at ME, we’ll put them both in your very own ME-branded Converse shoes. You’ll also get the following financial, health and fun perks when you join the team:
4U Extras portal (discounts and cashback on 100s of items including cinemas, shopping and gym memberships
10% Myki discount
Purchased Leave programme
Internal wellness programme (Mindfully ME)
Professional education through LinkedIn Learning
Novated Leasing
Professional membership reimbursements
Health checks
Financial education (To help you manage your money smarter)
LGBTIQ+ and Women at ME affinity groups

I want those Converse shoes (and the role)
Can’t see a closing date on the advert? That’s because we’re pretty efficient here at ME and we may start looking at applications sooner rather than later, so if this role sounds like your jam, be sure to apply by submitting your resume today.

Should an applicant be the preferred candidate, background checks (including police checks, reference checks, ASIC banned and disqualified persons and bankruptcy checks) will be completed prior to the candidate's employment being confirmed. The outcomes of the background checks do not automatically bar candidates; however will be assessed against the inherent requirements of the job.
Back Share
Apply Now",3.0,"ME Bank
3.0",Melbourne,-1,501 to 1000 Employees,-1,Company - Private,Banks & Credit Unions,Finance,$100 to $500 million (USD),-1
Software Engineer - Machine Learning/Data Science,-1,"Zendesk is looking for a Software Engineer - Machine Learning/Data Science for a full time position in our Melbourne office.
As part of our engineering team, you will work at a scale where the challenges start to get seriously interesting. Our global engineering team is widely dispersed over the world, with people across nearly every continent. You will get a chance to do cool things with a diverse bunch of people while working in the Melbourne office that is home to Zendesk’s first machine learning (ML) research team.
The Data Science Team, together with Data Engineering, have built Satisfaction Prediction, Answer Bot and Content Cues — products that use Machine Learning (ML) and Artificial Intelligence (AI) to help our customers work more efficiently.
What you get to do every day:
We’re currently looking for someone to join our team as we research, develop, and productionise Machine Learning and Deep Learning models. In addition to frequenting Melbourne’s finest purveyors of coffee, ramen, and bulgogi, you may find yourself:
Building machine learning models including neural networks in TensorFlow
Writing and deploying production-grade Python
Querying and constructing datasets in AWS Athena, Spark
Evaluating and responding to real-world model performance
Scaling your ML to millions of predictions per day
Presenting your work to a broader audience
Watching your algorithm help Zendesk’s end-users
What you'll bring to the role:
A strong foundation in a quantitative discipline (e.g. machine learning, statistics, bio/eco/etc-informatics, econometrics, etc) is critical for this position. While experience in deep learning and natural language processing would be beneficial, your best qualities are:
dedication to continuous learning
collaborative work attitude
strong communication skills
You should also be comfortable with at least one programming language, such as Python, R or Scala.
Application Deadline: 18/11/2020
Job Types: Full-time, Permanent
Salary: $85,000.00 – $110,000.00 per year
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Temporarily due to COVID-19",4.5,"Zendesk
4.5",Melbourne,-1,1001 to 5000 Employees,2007,Company - Public,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),-1
Software Engineer (Machine Learning),-1,"About the Role
AdelaideMRI is building a medical reporting tool. We require an engineer to work primarily on machine learning projects to improve reporting speed and report comprehensiveness.
You will perform data analysis of medical report datasets and image datasets to infer sentence recommendations, image classifications, or other actionable results for the doctors.
Skills and Experience
Background in machine learning or image processing
Qualifications in Computer Science, Software Development or Engineering or equivalent experience
Bonus points for Python
No prior medical knowledge is required.
This position offers flexible hours and work arrangements.
Job Type: Full-time
Experience:
Software Engineering: 1 year (Preferred)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Yes",-1,Adelaide MRI,Australia,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Hey there, we’re PEXA!

We started as an idea: to deliver a single, national e-Conveyancing solution. We collaborated with the industry to create a national electronic lodgement and settlement platform: PEXA. From our humble beginnings, we’ve now grown to more than 320 employees across 5 different states. We’re still expanding at a rapid rate and constantly challenging ourselves to create great experiences for our members as they transition to fully digital conveyancing.

Why become a PEXArian?

Great question! Being a PEXArian is so much more than just a job. We are passionate, motivated & unashamedly enthusiastic at PEXA - we love what we do and we’re proud to admit it! Creating brilliant member experiences wouldn’t be possible if we didn’t also strive to create an amazing employee experience. Alongside our members, our employees are at the heart of everything we do.
Here’s a snapshot of what your life at PEXA could look like:

Your growth:
We encourage you to hit your personal and professional Learning & Development goals with our tailored programs and tools.

Your wellness:
We care about your holistic well being - a fully stocked kitchen, four wellness days, a $250 wellness subsidy as well as lunch and learn sessions to support your financial well being.

Your work/life blend:
We know that work is just one aspect of your life, we want to help you create your ideal work/life blend, rather than squeezing in life around work.

Your family:
With a range of benefits aimed at supporting your family including access to a subsidised school holiday program, extended parental leave and flexi-time to support your return to work, superannuation payments for unpaid parental leave for primary carers and a childcare allowance for pre-primary aged children, when we say, ‘welcome to the family’, we really mean it!
The impact you'd drive:
The successful candidate will be responsible for developing, and maintaining infrastructure to support the delivery of new and existing products. They will also be contributing to establish the rules and frameworks for obtaining the required approvals for new products.
On day one we’d love you to have:
Experience with Python, Spark
Event streaming/sourcing with Kafka or AWS Kinesis
Experience with data structures, formats and data security best practices
AWS experience (e.g CloudFormation, S3, ECS, Lambda, SQS, IAM, KMS, DynamoDB, Glue, Athena)
Query construction and optimisation (e.g. SQL, Elasticsearch, Splunk, DynamoDB)
Git, version control practices, and continuous integration/delivery servers
PyUnit and unit testing frameworks
Production release cycles and maintenance
Collaborating with technical and non-technical teams
Even better:
Agile methodology/delivery
GraphQL
Modern frontend technology (e.g. ReactJS, TypeScript)
Machine learning frameworks and tools (e.g. TensorFlow, PyTorch)
OAuth 2, SAML 2, JWT
Data visualisation and exploration tools (e.g. Jupyter notebooks, Tableau)
AWS SageMaker
Sounds like you?
If this role sounds like you, apply today to have your application reviewed ASAP!",3.9,"Property Exchange Australia Limited
3.9",Melbourne,-1,201 to 500 Employees,2010,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Ongoing position
Full time
Based in Sydney, NSW
Who we are
Australian Red Cross is part of the world’s largest humanitarian organisation. Our aim is to improve the lives of the most vulnerable people in Australia and across our region.
About the role
The Data Engineer role will sit within the Data and Integration Squad in IT and will own (design, implement and support) the AWS Big Data technologies such as the Data Lake and Data Warehouse and support the organisation in growing the data analytics capabilities at Red Cross. In addition to this, the data engineer role will also administer the Power BI tool and support the implementation of the data mastering capability.
What you will bring
Experience building and optimizing data pipelines, architectures and data sets.
Experience in dimensional modelling and building data vaults
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with structured, semi-structured and unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Why work for us?
Work for purpose and know that your work assists Red Cross support and empower people and communities in times of vulnerability.
Generous salary packaging options available that can increase your take home pay.
Further information
To find out more about this opportunity please see the position description below or contact Sharath Kumar Gurram on 02 8651 8839.
Position Description: Position Description - Data Engineer .pdf
Applications for this position will close at 11:55pm Thursday, 5 November 2020.",4.1,"Australian Red Cross
4.1",New South Wales,-1,1001 to 5000 Employees,-1,Nonprofit Organization,Industrial Manufacturing,Manufacturing,$500 million to $1 billion (USD),-1
Junior Fullstack Data Engineer (Python and React),-1,"Formbay is the leading Renewable Energy Certificate Trading company in Sydney. We provide Digital Workflow and Compliance solutions in the renewable energy industry and document processing.
Thanks to our meteoric growth and our commitment to be the best at all we do, we've identified the need to bring on board a new Junior Fullstack Data Engineer.
Reporting to our Principal Machine Learning Engineer, you will help build Machine Learning pipelines for our existing Digital Workflow and Compliance solutions to automate fraud detection and document processing over terabytes of photographic and documentary data – including documents, photos, GPS data and aerial/satellite photography.
Our stack is based on Python, JavaScript, Dask, Tensorflow, CUDA, Nix/NixOS, AWS, Docker, PostgreSQL and more – familiarity with these applications will give you a leg-up on the competition.
Our ideal candidate will have the following competencies:
SQL
Python
JavaScript/TypeScript
Our candidate must also be comfortable working with Linux.
Located a stone's throw away from the Queen Victoria Building in Sydney's bustling CBD, we are centrally-located with easy access to public transportation, bars, cafes and fine dining.
Formbay will provide flexible working hours, a generous remuneration package and the opportunity to work on a world-first software solution are what we can offer you. Free, twice-weekly gym sessions and really, really good coffee are also available.
No hiring/recruitment agencies need apply.",5.0,"Formbay
5.0",Sydney,-1,1 to 50 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is an experienced and qualified Data Engineer to join our IT team based in Birtinya.
Key Responsibilities:
Create and maintain data pipelines and or ETL scripts
Create and maintain data integration including API and Batch interfaces
Performed detailed data analysis
Create and maintain corporate data models
Create and maintain data visualization using Qlik.Sense , PowerBI or Simliar Toolset
Experience in defining, building and maintaining data virtualization and/or star schema data warehouses
Maintain, tune and optimise database, integration and visualisation toolsets
ABOUT YOU:
To succeed in this role, you’ll need to bring the following experience and skills:
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Excellent communication skills both oral and written, with an ability to bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking
Experience with data analysis and modelling will be beneficial

How to Apply
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kawana Waters,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Graduate Data Science / Engineer,-1,"The NRMA is an organisation looking to the future, and right now, we are on the lookout for people who can help us reach our goal: to continue to shape the way Australians move, for the next 100 years and beyond. www.mynrma.com.au.
Everyone new to the team, along with our current staff, will temporarily work from home until it is safe to return to our offices. All interviewing and on boarding will be done virtually due to COVID-19.


Your opportunity
As Graduate Data Scientist or Engineer you will be part of the Data Engineering team delivering cloud data transition program for business initiatives and supporting the entire data platform build.
Your key responsibilities will be to:
Implementing Concepts of Data Warehousing, Data Mart creations within Cloud
Use of SQL for data analysis and insights
Building AI/Machine Learning prototype for implementing and supporting existing algorithms
Data Analytical reports build, using different tool sets


Requirements for Success:
Relevant Degree - Computer Science, Computer Engineering, Software Engineering, Data Science
Excellent SQL skills and demonstrated working knowledge in Python
Demonstrated understanding in data structure and algorithms.
Knowledge and concept of data warehousing methodologies
Any reporting tools experience Tableau or Oracle Analytics Cloud, Looker is desirable
Exposure to Google/AWS/Azure/Oracle any cloud based platforms is desirable
Good communication and interpersonal skills

If you have the required skills and the passion to join our high performing team, please apply today.

Employee Benefits
To ensure our employees feel valued, empowered and celebrated we provide a range of employee benefits including:
50% discount on all NRMA insurances
Free Roadside Assistance
12 weeks paid primary and 4 weeks paid secondary parental leave
Free NRMA Blue Membership
At the NRMA Group, we are People Moving People and diversity and inclusion are part of our DNA. Together, we continue to build an inclusive culture that encourages, supports and celebrates the diverse voices of our employees. It fuels our innovation, promotes flexible ways of working and connects us closer to our members and the communities we serve.",2.5,"NRMA Motoring & Services
2.5",Sydney,-1,501 to 1000 Employees,-1,Nonprofit Organization,Casual Restaurants,"Restaurants, Bars & Food Services",$500 million to $1 billion (USD),-1
Data Centre Engineer,-1,"We are a leading world group that provides low-carbon energy and services. To tackle the climate emergency facing us all, our aim is to become the world leader in the zero-carbon energy transition ""as a service"" for our clients – particular for companies and regional authorities. We use our expertise in our key business areas (renewables, gas, services) to provide competitive and bespoke solutions.
The Data Centre Engineer will be employed as part of a 24/7 ongoing shift to coordinate and monitor third party service providers, maintain the data centre facilities and infrastructure plans, coordinate the implementation of customer requests within the data centre and monitor systems, all in accordance with the Contract KPIs and SLAs.
Coordinate and monitor third party service providers for regular maintenance & testing, service faults & call outs, ensuring works are performed in accordance with Contract SLAs
Monitor and maintain the data centre facilities and infrastructure plans and documentation, including electrical, mechanical, hydraulics, fire and BMS/EMS systems
Coordinate the implementation of internal and external customer requests within the data centre
Perform scheduled plant checks and minor maintenance works
Ensure all Work Order requests are raised and closed in a timely manner
Conduct inductions for staff, vendors and contractors
Ensure all work permits for vendor works are raised and closed
Perform inventory checks on all equipment and critical spares

Qualifications
The selected candidate must be able to demonstrate:
Electrical or HVAC background, or Graduate Electrical or Mechanical Engineer
Passionate about quality work and career minded looking for a new challenge
Can commit to a day and night shift roster (2 days of day shift, then 2 days of night shift, 4 days off)
Ideally able to commence asap
As part of carrying out the duties of this role, it is mandatory to hold Australian Citizenship.

If you are interested and meet the selection criteria apply with an up-to-date resume via the apply instructions on this website.

ENGIE Services is an EEO employer, where all applicants are treated with fairness and respect and have equal access to the opportunities available.

We will not be engaging in the services of a recruitment agency to fill this vacancy and therefore request all interested candidates apply directly to this advertisement.

Job
: Maintenance
Primary Location
: Oceania-Australia-New South Wales-Erskine Park
Organization
: ENGIE Services Australia and New Zealand
Schedule
: Full-time
Nature of Responsibility
: Senior operational / administrative role
Job Posting
: Sep 11, 2020, 6:29:59 AM",3.7,"ENGIE Services Australia & New Zealand
3.7",Sydney,-1,5001 to 10000 Employees,1995,Company - Public,Energy,"Oil, Gas, Energy & Utilities",$2 to $5 billion (USD),-1
Senior Data Engineer,-1,"Senior Data Engineer, Temporary, SYDNEY - McKell

Job Title: Senior Data Engineer

Salary: SNSW Grade 9/10 - The package includes base salary range of $111,806 to $134,667, plus employer's contribution to superannuation and annual leave loading.

Location: Head Office – Haymarket

Employment Status: Temporary through till 30th June 2021


About Service NSW:

Service NSW is making it easier for people and businesses across NSW to access government services. The role designs, builds and analyses complex data from multiple sources to identify revenue, process and business improvement opportunities; providing new information and insights to the business to inform planning, continuous improvement and performance.

About the Role

We are currently seeking to appoint a Senior Data Engineer to deliver expert advice and services in the design of a Single View of Customer and data-related services to support the achievement of business outcomes and strategic goals. We support flexible working practices with staff working remotely during this time.

In this role you will:

Design, build and support a modern data platform based in AWS and vendor technologies.
Provide expertise on data modelling for Graph data model and Customer Data Platform (CDP).
Create data pipelines, load, transformation and reporting workloads in AWS.
Work with the latest data engineering technologies like Apache Kafka, AWS Kinesis, AWS Neptune, AWS Glue and AWS Athena.
Contribute to the design and decision-making of the right tool or platform for the job according to requirements.
Provide expert advice and guidance on data quality and data engineering best practices.
Support a “bigger than you can imagine” scale of data in production environments.
Design, develop and support a metrics-driven reporting solution and a meaningful business intelligence platform.
Document the solution design and support procedures of solutions.
Produce reports, visualisations and recommendations to answer complex business problems that are presented in the most appropriate format to ensure clarity for target audience.
Analyse and define new process improvement opportunities to support continuous improvement and business outcomes; providing advice to stakeholders, on ways to improve the efficiency and reliability of data products and services.
Be very responsive to the information needs of the business by corresponding to customers in a timely manner and provide support/solutions to issues raised.
Troubleshoot and perform root cause analysis on production issues. Identify and implement long term solutions to problems. Perform scheduled maintenance, release deployment and production support activities after business hours, from time to time.
Liaise with internal and external customers to discuss and gather requirements, solutions etc. and maintain a good working relationship with the stakeholders.


Skills and Experience Required:

Solid experience with workflow technologies designing and building data pipelines, data models and data stores.
Experience working within and an understanding of Amazon AWS ecosystem, including security and performance tuning.
Hands on experience working with different types of databases, with focus on Graph and NoSQL databases.
Experience with data streaming required. Having used Kafka and related technologies is an added advantage.
Sound knowledge and experience working with batch processing, data extraction and API integration.
Hands on experience with at least one programming language: Java, Python or scripting.
Demonstrated experience working in an Agile based, fast paced, complex environment within cross-functional teams.
Experience developing systematised insights, data analytics and reporting solutions is an added advantage.
Experience with interactive visualisation of data insights is an added advantage.


Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Salary Grade 9/10, with the base salary for this role starting at 111,806 base plus superannuation

Closing Date: 6th November at 9:59am - applications will be reviewed on a rolling basis, applications may close early or extend

Please apply online, direct applications submitted via email will not be considered.

The Department of Customer Service is proud to be an EEO Employer who are fully focused on equality and believe deeply in diversity of all identities making us different and a true reflection of our NSW customers. As an inclusive workplace, we support various employee resource groups, practice flexible work and workplace adjustment.

If you do require an adjustment during the recruitment process, please notify us on your application form.",3.2,"Service NSW
3.2",Sydney,-1,501 to 1000 Employees,2012,Government,State & Regional Agencies,Government,Unknown / Non-Applicable,-1
Data Engineer - Entry / Mid Level,-1,"Work with a great team on interesting projects customers
Gain more experience in AWS, Data, DevOps cloud operations
Got a working knowledge of AWS? We will teach you the cool stuff!

Itoc is seeking an up and coming Data Engineer to join our growing Data Team in Sydney.

This is an exciting role working with databases, data lakes, data warehouses, data transformation (Python SQL) and enabling AI/ML.

You will be implementing foundational, robust and production ready data platforms to enable business data-discovery, self-service, AI/ML functions across a range of client types and industries, allowing them to do more with their data.

You'll be responsible for:

Deploying data repositories such as lakes and warehouses.
Contribute to our growing portfolio of data solutions.
Ongoing optimisation and management of data platforms.
Development of transformational logic for data pipelines
Data evangelism. We want to show our clients how to follow the best practices for data.

Desired Skills and Experience

To take up the challenge, you will have a depth of skills and experience including:

1-2+ yrs of focused data experience working with SQL and/or NoSQL solutions
A solid education in Software Engineering or equivalent industry experience.
Anything Data focused preferred.
Ability to analyse business scenarios and associated data landscape to derive potential opportunities.
Strong foundation in Python and SQL
Working knowledge of APIs
Principle knowledge of the different relational database platforms and modern data storage techniques
Knowledge of the different aspects of data environments
Collect, store, process, verify consume
Experience with version management systems (such as GIT)
Working knowledge of AWS or another cloud platform - we will teach you the cool stuff.
Great communication skills, an ability to work closely with customers, developers and engineers and the confidence to present ideas in open forums.
Relevant tertiary qualifications and/or industry certifications.
Great communication skills, an ability to work closely with clients, developers and engineers and the confidence to present ideas in open forums.

While not required, a background in consulting and professional services is highly desirable.

Itoc Description

This is an exciting and challenging career opportunity to join the growing Sydney-based Data Team of a leading cloud solution provider where you will be given support to reach your long term career goals. You will be part of a team of cloud experts and will work in an environment of continuous improvement and learning delivering innovative cloud solutions across SaaS, online business and enterprise business.

On offer is a chance to join a team with a great working environment, in an organisation that values its employees and sees the value in ensuring they are engaged. Our team are clearly passionate about what they do, that's why we won the following awards:

Customer Obsession Partner of the Year 2015: ANZ Region
Customer Obsession Leadership Partner 2015: re:Invent

As an employer of choice Itoc offers competitive remuneration, training and development programs and a great working environment. We value a healthy work life balance.

The Perks

MacBook or Dell
Continuous internal learning that will provide training and career development opportunities
Working with a collaborative, social team and leveling-up your skills faster than you will anywhere else.
Quarterly social events

Itoc

Culture and smarts are important to us. Bring your secret sauce. This is no ordinary environment, you will work along some of the Cloud’s best. All engineers at Itoc must gain at least five AWS certifications. We work hard but we have fun.

Please note you must have full working rights in Australia and be available on-shore for face to face interviews.

No recruiters please.",4.0,"Itoc
4.0",Sydney,-1,1 to 50 Employees,2013,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Date: 01-Oct-2020

Location:
Melbourne, VIC, AU

Department:Description:
Technology discounts - from Apple HP Lenovo to Windows
Flexible work arrangements - work in a way that suits you best
Salary packaging - to suit your personal and financial circumstances

Do you want to work for one of the fastest growing data teams in Australia? Do you want to work on multiple data platforms and provide new solution offerings by leveraging cloud and big data technologies?

About the team

Big data information and analytics. Three words that spark apprehension in most businesses. But our team of experts are constantly curious and excited about combining our wonderful array of technological expertise to transform data into our clients most valuable assets making their work smarter. Our data consultants are supported with resources training and tools they need to excel at their work but also the freedom and power to create their own paths forward to make a difference.

As a Senior Consultant in Big Data you will work closely with the team and stakeholders to build and deliver a Cloud based vision for a next generation Big Data analytics platform with strong focus on data quality data security and deliver the systems that process huge volumes of data.

What will you typical day look like?

You will play a pivotal role in - Designing and producing high performing and stable applications to perform complex processing of massive volumes of data in a new cloud based architecture; Building real-time data processing applications which are integrated with business systems to enable value from analytic models to drive rapid decision making; Contributing to system architecture design for a data platform (including cloud-based structures both on and off premises data warehouse components and data lakes); this could cover a range of technologies various countries/locations and lines of business; Support data strategy or technology strategy definition programs including technology stack definition and target operating model requirements

Enough about us lets talk about you:
You are someone with:
Use of traditional data analytics tools and techniques (e.g. MSSQL Oracle MySQL) and ETL software (e.g. SSIS Informatica CloverETL)
Working in large scale cloud data solutions using platforms such as AWS or Azure or GCP will be a bonus.
Experience in scripting or programming (e.g. Python Java Scala C#)
Excellent verbal and written communication skills to adapt to technical and non-technical audiences.
Educated to degree level (or have equivalent experience)
Why Deloitte?

At Deloitte we create positively differentiated work experiences that enable our people to feel valued and achieve their full potential. We value difference and embrace people with diverse backgrounds and thinking styles. Knowing that people work best in different ways we are happy to discuss alternative arrangements if the working pattern you are looking for is not specifically indicated.",3.8,"Deloitte
3.8",Melbourne,-1,10000+ Employees,1850,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Engineer,-1,"Opportunity to grow the team
Period of growth
Intuitive app
S2M are working with a FinTech who have created a unique financial product to help thousands of people better manage their finance, and is currently scaling the company to the next level!

They are looking for a Data Engineer to join, and looking for someone who wants to be hands on, with opportunity to grow the team in future.

Role:

Looking for people with strong AWS experience. You will need passion for data and a cloud, through which you will help a rapidly scaling Australian FinTech establish their data infrastructure from the ground up.
5+ years’ experience as a data engineer within the data and analytics domain
A python 3.X aficionado who is very comfortable creating and orchestrating AWS data pipelines with nothing but code
Strong project delivery toolset experience in open source data integration tools
Experience with processing large volumes of complex data including visualisation and insights generation
Ability to define and develop data integration patterns and pipelines
Ability to assess complexity of data (volume, structure, relationship etc.)
Hands on experience working with different databases (RDBMS, NoSQL, Blob storage etc)
Hands on technical expertise setting up DevOps automation
Hands on experience working technologies/platform e.g. AWS, Dockers, Containers
Experience building data profiling and data cleansing frameworks
Technical reconciliation and reporting
Knowledge and experience in end-to-end project delivery, either traditional SDLC or agile delivery methodologies (or hybrid approaches)
Exceptional communication, documentation and presentation skills
If this sounds like you, get in touch today - kate.gabb@s2m.com.au
3167410agsdf",3.1,"S2M
3.1",Sydney,-1,Unknown,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Analysts,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is seeking experienced and qualified Data Analysts to join our IT team based in our corporate office in Birtinya (Sunshine Coast) or at our meat processing facility in Kilcoy.
Key Responsibilities:
A mixture of data analysis and commercial skills to source, blend and analyse data to gain insight and answer key commercial questions
Working with strategic leaders to define and model Key Performance Indicators, and assist in building forecasting models
Working closely with data engineers and BI developers to specify data pipelines and report visualisation
Drive the creation and implementation of data quality business rule including data definition, governance and quality assurance
About You:
To succeed in this role, you’ll need to bring the following experience and skills:
Proven ability to derive insight and knowledge from data using commercial expertise is a strong requirement
Strong SQL and Excel skills are essential, along with strong data analysis and commercial insights
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Effective people communicator - engage with stakeholders on reporting needs, interpret requirements into visual solutions and train/deliver the outputs to the stakeholders getting signoff of acceptance
Bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking

How to Apply:
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kilcoy,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Network Data Engineer,-1,"Min 6+ years of experience in the relevant technologies
Australian Driving License for visiting remote locations / Data Centre for day to day technical work.
Managing Network devices (switches, routers, firewalls, load balancer, and wireless technology)
Performing MACD activities for all network devices.
Supporting BAU operation activities.
Proficient in performing in-depth details of technical troubleshooting, cause and provide recommendation to the client for incidents causing extended network outage to client’s critical locations.
Provide exceptional network services in terms of network support, break-fix, design and consulting, new projects, implementation.
Configure, administer, and document firewall infrastructure.
Manage the firewall deployment, rules migrations, and firewall administration.
Supporting Cloud Migration Activities from traditional to AWS/Azure.
Setting up VPN tunnel with Cloud and 3rd Party network devices.
Integrating and upgrading existing ISP bandwidth with support from ISP Vendor.
Setting up VPN profiles for Users.
Installing hot fix and patches to mitigate the security devices from attacks and bugs.
Reviewing and fine tuning the firewall rules and NAT rules.
Documentation and change control.
Mentoring, Motivating and Guiding support teams
Technical skills:
o LAN
o Wireless
o WAN
o MPLS
o Routing protocols (OSPF,BGP)
o DMVPN
o Azure cloud Networking
o Network Security
Fortigate Manager / Analyzer / Firewall
Cisco ASA
Firepower FTD
Cisco Any connect
Site to Site VPN
F5 Load Balancing and Scripting iRule
Job Types: Full-time, Contract
Schedule:
8 hour shift
Experience:
Scripting: 5 years (Required)
Data Network: 5 years (Required)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Required)",3.6,"Total IT Global
3.6",Sydney,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Engineer - Processing & Analysis,-1,"Job Description:
Design,build and maintain the ingestion system to support various types of data(e.g. User behavior, RDS, NoSQL db and others) to be ingested to the data warehouse more timely and accurately
Translate data requirements into scalable technical data service with low latency and high concurrency
Design,build and maintain the batch or real time data pipeline in production using Hadoop big data technology
Analyze and improve efficiency, scalability, and stability of the system
Define and manage SLA,Data quality for all data sets in allocated areas of ownership
Requirements:
Minimum B.S. degree in Computer Science or a related technical field
2+ years of working experience in programming languages,such as Java,Scala,Python
Familiar with Hadoop, Spark and Flink data processing, experience of TB data processing experience is a plus
Familiar designing and operating of a robust distributed system is a plus
Understand data mining or machine learning
Excited to work intimately with data
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"SYNOPSIS:
Lead Data Engineer
Applications close Sunday 8 November 2020
Ongoing
Contact name: Shyni Sasikala
Phone: (02) 6249 9048
Email: Shyni.Sasikala@ga.gov.au

The Data Policy and Informatics section within the Digital Science and Information branch creates, implements, and promotes policies, platforms and tools that improve and support the quality, discoverability, accessibility, and general usability of Geoscience Australia’s science data products. The section consults with internal and external research, government and industry partners to establish collaborative data frameworks, architectures and models within Geoscience Australia (GA) and across broader national and international communities of practice. The section innovates, builds and maintains tools, systems, processes and governance that enable digital data management, cataloguing and open data delivery.
GA makes accessible a wide range of geoscientific and spatial data to a wide variety of stakeholders in multiple formats, and in recent years GA's data volumes have grown exponentially. GA is focussed on making its data and metadata assets accessible so that they can be used in machine to machine interactions for data analytics and other applications in environments that range from High Performance Computing (HPC), through high-end cloud servers, to mobile devices.
We currently have two opportunities for Lead Data Engineers in the Informatics team. The Lead Data Engineer is responsible for innovating and exploring new technologies that will advance GA’s science goals and maximise the uptake and use of GA’s science data. The Lead Data Engineer reports to the team’s Assistant Director but also works closely with other developers, data scientists and engineers within the Digital Science and Innovation (DiSI) branch, as well as diverse stakeholders both within and external to GA.",3.9,"Geoscience Australia
3.9",Canberra,-1,501 to 1000 Employees,2001,Government,Federal Agencies,Government,$100 to $500 million (USD),-1
Data Engineer,-1,"The Seven Network is part of Seven West Media, one of Australia’s most prominent media companies, with a market leading presence in content across broadcast television, online and in print. Comprising some of Australia’s most renowned media brands, SWM includes not just Seven Network and its affiliate channels 7two, 7mate, 7flix and BVOD offering 7plus, but also 7NEWS.com.au, The West Australian, The Sunday Times and more.
At Seven we are here to bring all Australians closer to the moments that move us - we’re first on the scene, with our finger on the pulse, on demand, in the moment. Together, we’re responsible for creating and sustaining authentic Australian engagement.
A new and exciting opportunity has opened for a Data Engineer to join the Audience Intelligence team. Based in Sydney and reporting to the Head of Data Enablement, you’ll be responsible for:
Implementation of end to end data solutions to support Data Strategy for the SWM group.
Work closely with the Data Solution Designers to develop and maintain scalable data pipelines and build out new file and API based integrations to address requirements from the various business stakeholders.
Collaborates with engineering, analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organisation.
Work on Data Preparation for analytics and data scientist team members and assist them from an engineering perspective in building and optimising the models including building the automation of the end to end workflows
Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.
Perform data analysis required to troubleshoot data related issues and assist in the resolution of production data issues.
Work effectively with vendors for successful delivery of projects and acceptance of the solution
Work on Delivery projects using Agile Software Development methodologies
We are looking for someone who has:
Bachelor's degree in computer science, computer engineering or other technical discipline is essential
Proven experience working as a digital analytics specialist
Extensive experience with digital analytics implementation (e.g. Google Analytics, Snowplow, Adobe Analytics) and BI processes and visualisation platforms
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience in ETL and building and optimizing ‘big data’ pipelines and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Experience with big data tools: Hadoop, Spark, etc., AWS cloud services: EC2, S3, Lambda and familiar with version control systems: Git
Strong coding skills with knowledge of Unix/Linux and scripting languages such as Unix Shell scripting, Python desirable
Experience supporting and working with cross-functional teams in a fast-paced environment.
Ability to multi-task and problem solve with changing demands and priorities
Ability to work under pressure to meet deadlines and detail oriented
Your success is our success: we will provide you with opportunities for you to keep learning and growing, enabling you to challenge and develop yourself. In return, we offer a benefits program that has something in it for everyone.
Seven West Media is an equal opportunity employer and we are committed to creating a diverse and inclusive workplace.
Recruitment Agencies: Seven West Media does not accept any unsolicited agency resumes and will not be responsible for any fees related to unsolicited resumes.
Advertised: 19 Oct 2020 12:00 AM AUS Eastern Daylight Time
Applications close:

Back to search results",2.5,"Seven West Media
2.5",Sydney,-1,5001 to 10000 Employees,1956,Company - Public,TV Broadcast & Cable Networks,Media,Unknown / Non-Applicable,-1
BICON Rules Engineer,-1,"APS 5 - $73,299 - $80,410 per annum plus superannuation
Biosecurity Plant Division
Canberra, ACT
Play an active role in managing biosecurity risk to Australia
Work in a motivated and professional team with a wide range of skills and backgrounds
Full training provided

Who we are
The BICON Content Development Team maintains and improves the Biosecurity Import CONditions database (BICON) content to allow external clients to understand and comply with their biosecurity obligations and internal clients to effectively manage biosecurity risk and regulate imports. We work collaboratively with internal clients to comprehend and implement their BICON content requirements and optimise the use of BICON to publish clear import requirements and onshore management support procedures to effectively manage biosecurity risk.

The Jobs
Key duties of these positions include:

working with business content (import and permit conditions) and import programs to understand and construct decision tree structures in the BICON database, in accordance with system design and authoring conventions
executing changes to import and permit conditions in alignment with service standards while complying with system rules and authoring conventions
providing technical advice through various formats on the most appropriate means of authoring BICON content to achieve import program and stakeholder objectives
using workflow management tools to maintain detailed records of changes to import conditions and key decisions
performing administrative tasks including system reporting, data analysis and scoping tasks for the BICON content change work program
contributing to the development and maintenance of instructional material, authoring conventions and courseware
clearly documenting and reporting system issues
developing and maintaining effective working relationships with internal and external stakeholders.

What we are looking for
Knowledge and experience
Experience working with complex IT systems.
Experience working collaboratively and as part of a team.
Knowledge of the role of biosecurity is preferred but not essential.

For additional information, please read the Job Description below.
Candidate Information Package docx Opens in new window",3.9,"Department of Agriculture & Water Resources
3.9",Australia,-1,5001 to 10000 Employees,-1,Government,Federal Agencies,Government,$500 million to $1 billion (USD),-1
Cloud Data Engineer,-1,"Job no: 509605
Work type: Permanent Full Time
Location: Melbourne, Canberra, Sydney
Do you embrace digital disruption?
Do you love solving complex problems, designing sophisticated solutions and building innovative technology?
Do you believe in creating powerful actionable insights from Data and Analytics?
Do you want to work in a diverse and flexible working environment?
KPMG is one of the most trusted and respected global professional services firms. Through depth of expertise, clarity of insight and strength of purpose we help our clients solve complex challenges, steer change, strengthen, transition and grow. We are a team based practice and this extends to our clients whom we work and collaborate with, in solving complex problems. Together, we design, innovate and implement, providing enduring advice that support our clients and the services they deliver. Our clients vary in size and come from a diverse range of sectors – all sharing in a common goal: to embrace change and deliver services that make Australia a better place. We are looking for talented individuals who would like to join us on the journey.
KPMG’s Digital Delta Team
We re-imagine and re-invent organisations to become world class digital enterprises using advanced technologies, data and human insights. We help organisations to embrace Digital Strategy, Artificial Intelligence (AI) & Cognitive, the Internet of Things (IoT), Data, Analytics & Modelling, Mobile App & Web, and User Experience (UX) & User Interface (UI) and more.
We work with clients to:
Formulate strategies that re-imagine organisations
Harness innovation from the 4th industrial revolution
Actioning insights from trusted data to consistently and quickly make clear decisions
Build adaptive organisations
Thrive as a connected enterprise – front, middle and back office
This is how you’ll contribute:
We are looking for ambitious Data Engineers who are passionate about helping clients define bold ambitions and deliver on them. Joining our team will take you on a journey of personal and technical growth and provide the opportunity to inspire confidence and empower change.
As a Data Engineer you are the designer, builder and manager of the information or ""big data"" infrastructure, preparing data for analytical or operational use. You will design, construct, test and maintain a data pipeline to pull together information from different source systems; integrating, consolidating and cleansing data; and structure it for use in individual analytics applications.
The KPMG Difference
Our people are focused on creating a diverse and dynamic environment that embraces and values differences. We value the variety of unique experiences, qualities and characteristics our people possess and we share and learn from each other.
We are proud to be consistently recognised as an employer of choice for women, and for our achievements in LGBT+ workplace inclusion.
Our commitment to ‘Flexibility’ allows our people to manage the changing demands of work, personal or family life. Explore the links below to hear our people share their experience @ KPMG:
Flexibility empowers wellbeing
Flexibility enables contribution to the community
Flexibility inspires technology & innovation
Flexibility supports family

Make KPMG the clear choice for your career and be Extraordinary!

Advertised: 09 Sep 2020 AUS Eastern Standard Time
Applications close:",3.8,"KPMG
3.8",Sydney,-1,10000+ Employees,1987,Subsidiary or Business Segment,Accounting,Accounting & Legal,$2 to $5 billion (USD),-1
Computer Network and Systems Engineer,-1,"Duties Include but are not limited to:
Tasks Include:
analysing, developing, interpreting and evaluating complex system design and architecture specifications, data models and diagrams in the development, configuration and integration of computer systems
researching, analysing, evaluating and monitoring network infrastructure to ensure networks are configured to operate at optimal performance
assessing and recommending improvements to network operations and integrated hardware, software, communications and operating systems
providing specialist skills in supporting and troubleshooting network problems and emergencies
installing, configuring, testing, maintaining and administering new and upgraded networks, software database applications, servers and workstations
providing network programming in support of specific business needs and requirements
preparing and maintaining procedures and documentation for network inventory, and recording diagnosis and resolution of network faults, enhancements and modifications to networks, and maintenance instructions
monitoring network traffic, and activity, capacity and usage to ensure continued integrity and optimal network performance
Skills and Experience Required:
Must have experience working in a Managed Service environment
Demonstrated experience in IT Networks and Data Centres
Understanding of systems and architectures to meet client needs
Experience in Help Desk including break / fix
Effective and timely documentation
Effective Task Management Skills
Be solution and outcome focused and willing to learn new technologies
Excellent communication skills with staff, clients and partners
Time management, ability to prioritise and deliver to schedule
Experience with N-Able and Connectwise desired
Open Cabling license desired
Job Types: Full-time, Permanent
Salary: $30.00 per hour
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,Trans-plant training,Canberra,-1,-1,-1,-1,-1,-1,-1,-1
Software Engineer (Data),-1,"If you are looking for an opportunity to make a real impact with smart people who are genuinely doing things differently then you've come to the right place! We're growing our data engineering capabilities and are looking for awesome data engineers to join our team.
With our diverse range of clients and projects, no day will look the same - but here's a great snapshot of what you'll be doing:
Work with some of the best Data Scientists and Engineers to deliver production-grade AI and Machine Learning systems as we deliver client projects from inception to production.
Consulting with our clients and working with them to build modern data systems using the 'best of' technologies and principles.
Advising clients on data strategy, architecture and technology.
Applying best software engineering practices in coding, monitoring and alerting, using CI/CD, TDD and cloud architectures.
Working over a wide range of big data tools and environments: not limited to; Apache Kafka, Spark, Python, Scala, Hive, Airflow, AWS EMR & Glue, GCP Dataproc & Dataflow, BigQuery, Snowflake, Redshift.
Who are we?
Glad you asked! We are Eliiza. Data science. Engineered for scale.
We are a passionate team of data scientists and engineers who apply data science and machine learning to solve real-world problems. Our mission is to create a bright future for Australian businesses and society in a world increasingly influenced by intelligent technologies.
We've created a culture that values diversity where people can truly be themselves! We care a lot about growing the Australian AI community in a positive direction, and we're doing several things to try and achieve that:
We provide opportunities for underrepresented groups to work in AI through our associate and intern programmes
We organise and participate in a range of community events, reading groups and meetups
We produce the AI Australia podcast
We blog about topics we care about
We stream brown bag sessions to the broader community
We're also part of Mantel Group's 'house of brands' which means it's not just the Eliiza team you'll work with, learn from and see at social events - there's another 230 of us across DigIO, Kasna & CMD Solutions!
So you're ready for something new?
We're keen to know more about you! Our team is made up of a range of people, with different experience across a huge range of data driven skill sets.
We'd love to hear from you if you have experience with:
one (or more) core language(s), ideally Scala, Python or Java
one (or more) cloud platforms, AWS, GCP, Azure
ETL/ELT concepts and technologies e.g. Data partitioning, Hive, Spark
streaming data concepts and technologies, ideally Kafka (Kinesis, Beam or Pubsub will do)
We'd be over the moon if you:
Experience with distributed/columnar databases (e.g. Snowflake, Big query, Redshift).
Experience with any of a variety of databases e.g. RDMS, NoSql, Columar, Distributed, Time series, Graph.
Knowledge of job orchestration and scheduling. Any experience with Airflow, Luigi or Oozie.
Experience with containers and container orchestration (Docker, Docker Compose or Kubernetes).
However, we value a diversity of skill-sets, and don't necessarily require that you're skilled with all of the above. If you feel you don't fit all the experience/skills listed above we still encourage you to apply or get in touch.
What's on offer if you join us?
We make sure you're always one step ahead by investing your learning and development, every year. We build our own training where it doesn't exist yet.
We hire smart people and get out of their way. By focusing on our five principles and not getting caught up in red tape, we trust you to get the job done.
You'll get all the tools you need - a new iPhone or Google phone, a new Macbook Pro or Dell, and a lot of branded swag!
But hold on, you mentioned a house of brands?
We certainly did! Mantel Group is an Australian-owned, 'house of brands' company with four technology businesses (Eliiza being one of them!) across Melbourne and Sydney. We're building a group of companies with open borders so we can support you to take on new skills without leaving an awesome team - we understand you won't have one job for life!
We may only be just two years old but Mantel Group has already been recognised #9 in the 2020 Best Places to Work in Australia and #4 in the AFR's 2020 fastest growing new companies.
Keen to chat?
Click ""Apply"" to share your details with our talent team, and we'll be in touch.
In the meantime, check out 'how we hire' to find out what's in store if you're successful and get to know us better by visiting our website and following Eliiza on LinkedIn.",-1,Eliiza,Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Infrastructure Engineer,-1,"Job Description:
Design and grow the Shopee data platform to support a variety of big data applications using open-source technologies including Kafka, Hadoop, Presto, HBase, Spark, Hive, Druid, and our own creations. Some examples include a real-time data streaming platform, a unified query platform, a cluster management system, and a machine learning platform
Dig into the source code of some open-source big data system to get the whole control and familiar with the details, configurations, designs and source code. Develop and maintain the internal release of big data systems and components as the business requirements.
Keep close and overall monitoring for all the deployments of the systems, maintain the system’s stability, improve the performance, discover the performance bottlenecks, tracking and troubleshooting, cost optimisation.
Requirements:
B. Sci. / Ms / PhD in Computer Science or a related technical field
Familiar with at least one of these languages: Java, Scala, Python, Bash under Linux / Unix. Scala is a plus
Familiar with the use and compute logical of SQL
Knowledge about the Big Data Infrastructure system technology like Distributed File System, Distributed Computing, Distributed Database will be a plus
Hands-on experiences Hadoop, Spark, Kafka, and/or Presto will be a plus
Love to use and develop open-source technologies
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"Work on an award-winning, international technology!
Endless career opportunities
An innovative, friendly team of 300+
This role will be focused on the development of our existing ClaimLogik line of products as well as working on our new cloud-first, modern suite of applications.

Intelligent Thought, our technology business is scaling and shipping our software globally. Already profitable, part of a much larger group business, with investors such as Macquarie Capital and Envest – we are all set to deliver textbook disruption to the Insurance Industry. The growth of the platform, of our customer base, and the increasing industry demand have led to the need for this role to help the team scale.

Our Philosophy
Give each employee a sense of purpose and an environment for them to connect the importance of their role to delivering a service that matters to our customers.
Challenge the ‘why’ of traditional claims processes.
Keep it simple – do only what brings value and what matters to the customer
Enable employee decisions, empower our people
Responsibilities:
Create, extend and maintain ETL pipelines to form our data lake, data warehouse and analytics platform (currently using the Microsoft Azure set of tools and service)
Help define the optimal data pipeline architecture
Influence the tool selection, platform selection, data architecture and strategy which will transform the business to be truly data-driven
Understand, analyse and size user requirements
Work with different parts of the business to provide them with the insights they need to deliver the best results
Skills & experience:
Degree or qualification in computer science or related
Advanced knowledge of relational database, including query authoring and query optimisation (MS SQL Server and PostgreSQL).
Experience building and optimising ETL pipelines
Experience designing complex data models
Experience working with cloud platforms (Azure or AWS)
Efficient time management and organisational skills
High attention to detail and accuracy
Effective communication skills to build strong working relationships; both written and verbal
Proactive and results-driven
Why Claim Central?
Claim Central Consolidated is a global insurance industry leader across, claims management, insurance technology and data and analytics. Currently operating in the United States, Australia, South Africa, Italy and New Zealand, we have pioneered digitally connected claims management services across the globe. Claim Central is a disruptor and thought leader in the industry and we were recognised as the Australian Financial Review’s 8th Most Innovative Company in Australia in 2016. This business is in a period of unprecedented growth, transitioning our technology and services into multiple geographies at a rapid pace. Our unique culture is based on teamwork, collaboration, trust, respect and performance. We also offer many benefits apart from our exceptional team culture; including flexible work arrangements, and continued professional development.

Be a part of this journey in a career-defining role.",-1,Claim Central,Matraville,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer - AI/ML,-1,"Our client provides services to a major industry across the country. The business is still early in it's days of technology development and the environment is greenfields in nature (no pun intended), effectively working like a start-up.

Their data and analytics team have worked and built leading and bleeding-edge technologies in this space and what they have created so far may be game-changing. From a machine learning perspective, the progress they have made to the business has already seen proven success in changing the future of an industry that will have positive consequences for all those involved.

You will have previously worked in a technical capacity in the data and analytics space and have experience working with an organisation where machine learning has been implemented, not just a concept that the business talks about having or the technology team would love to have. The commercial experience you will have had in the ML field will be proven examples of where you have affected the way a business or industry used to perform, to the changes that have come about from this.

Technically, you will have extensive experience in the Microsoft space - Power BI, Azure etc and you will have previously mentored and coached junior members of the teams you have been part of.

This is a rare opportunity in Brisbane where the business has truly embraced and funded projects across the ML space and would be a great chance for those in the Data Development/Data Engineering field, who are looking to move into a Data Scientist role in the future.

Please send your application through if you would like to know more.",4.0,"Emanate Technology
4.0",Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Solution designer/ ETL Engineer & Data Modeller,-1,"We are looking for a Qualified and Experienced Solution Designer to join our client for a period of 6 months with a view to extend.
You will work closely with team members and your contribution will range across gathering and analyzing information, developing and documenting improved processes and work instructions and experienced DWH Lead with skills in requirement analysis, solution designing, developing, testing and supporting ETL solutions.
A hands-on solution designer, data modeler and ETL developer for Data Warehousing and ETL application transformation projects using Informatica PowerCenter.
Knowledge on AWS, S3, Redshift, Informatica BDM, and related technologies.
Experience working with IPython, PySparks, AuCuMo, Airflow, Jenkins, Github, Athena, JIRA, Rally, Spectrum, Glue, Flyway.
Good exposure on Oracle PL/SQL, aware of DBA activities, writing and performance tuning of complex SQL queries.
Contract length: 6 months
Job Types: Full-time, Contract
Salary: $650.00 – $800.00 per day
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,nducive,Melbourne,-1,-1,-1,-1,-1,-1,-1,-1
"Data Engineer, Wollongong NSW or Mount Waverley VIC",-1,"Company Description
BlueScope is a technically advanced supplier of steel and steel products in Australia. We are an inclusive organisation and every day we showcase our technology and expertise throughout the world.

Job Description
We are looking for two Data Engineers to join our IT team, based in Wollongong NSW or Mount Waverley VIC. Use your experience in analytics to unlock business value, enabling use of big data for insights and decision-making.
Reporting to the Data Product Owner for our Australian Steel Products (ASP) business, this position will support strategic goals related to data. This will see you:
Gather business and technical requirements with the view to deliver outcomes;
Develop and implement end-to-end data collection, consolidation, modelling and visualisation solutions;
Document metadata in a dictionary and catalogue;
Ensure consumers of such information understand its accuracy, timeliness, quality and sensitivity, so that it is used appropriately; and
Identify opportunities to enhance analytics.
What are the benefits?
Work in a supportive and collaborative team environment whilst we embark on a journey to transform the way our business uses data!
Our systems landscape is broad and diverse. You will be encouraged to think creatively to develop data solutions which solve real business problems.
Working in this role you will enjoy:
the chance to learn more about data science;
salaried remuneration with attractive superannuation options;
the opportunity to participate in a performance incentive scheme; and
access to further development and career opportunities with BlueScope.
Who are we looking for?
We welcome applications from professionals with experience in data analytics and/or programming. Supported by your knowledge of project delivery methods (e.g. Agile), you will demonstrate:
experience with data mining, wrangling, mapping and visualisation techniques (e.g. Azure Data Factory, Databricks and/or DevOps etc.);
well-developed ability in gathering business and technical requirements;
skills in developing and implementing collection, consolidation, modelling and visualisation solutions; and
a passion for sharing your knowledge and desire for ongoing professional development.

Qualifications

null

Additional Information
We're proud to have been named an Inclusive Employer for 2019–2020 by the Diversity Council of Australia. We believe that our people are our strength. Having a diverse and inclusive workplace enables us to improve our capability and ensure continued, sustainable success.
We know that workplace flexibility can mean something different to everyone. Under our B-Flex initiative all of our roles have some degree of flexibility. We encourage you to discuss your needs with us.
Applications close Sunday 25th October 2020.",3.3,"BlueScope
3.3",Wollongong,-1,201 to 500 Employees,-1,Company - Private,Construction,"Construction, Repair & Maintenance",$100 to $500 million (USD),-1
ETL Data Engineer,-1,"ETL Data Engineer

Join a team that’s changing how Australia lives, works, plays and grows
We want you to be the best version of you

Work with innovative teams and explore new technologies to help solve real-world problems.

A typical day as a Data Engineer

ETL / Big Data Engineering professionals will be responsible for guiding the full lifecycle of a Data solution, including:
Working in highly client-facing roles to contribute throughout the end-to-end delivery lifecycle of complex and large-scale digital solutions
Use case and business case development
Support existing and new applications utilizing in-depth technical and data knowledge. Troubleshooting complex issues and providing advisory services to improve the client’s data landscape
Help to streamline and simplify the clients’ complex data landscape by integrating different applications and data architectures
Implementation from requirements analysis, platform selection, digital architecture design, application design and development, testing, and deployment
Interstate travel may be required

Basic qualifications:
Bachelor’s degree
Experience across systems integration, information management, data management and architecture, and business analytics
Experience with being in a team focusing on large-scale, multi-release information centric projects
Experience with waterfall and agile delivery and run / application support functions
Part of a team working on End to end implementation of at least 1 big data project

Preferred Skills:
Hand on experience in Data warehousing using ETL tools such as DataStage, Autosys and TeraData
Hands on experience in ETL job development with multiple stages like sequential file, Transformer, Lookup, join, sort and Database stages.
Strong hand on skills in design, development and implementation of various data remediation, Data migration, data integration techniques.
Strong hand on data modelling experience.
Strong hands on experience in database performance tuning including complex query optimizations and physical database tuning using Teradata.
Understanding of architectural designs and strategy related to data migration, data cleansing, data quality and data consolidation.
Proven data analysis, requirement gathering and problem-solving skills
Exposure to Unix environment and shell scripting.
Experience in Banking and Financial services industry
Desirable: Knowledge of cloud computing infrastructure (e.g. Amazon Web Services EC2, Google Cloud, Microsoft Azure)
About Accenture

Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. We combine unmatched experience and specialized capabilities across more than 40 industries — powered by the world’s largest network of Advanced Technology and Intelligent Operations centers. With 513,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises. Visit us at www.accenture.com.

Accenture is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, marital, domestic or civil partnership status, sexual orientation, gender identity, or any other basis as protected by applicable law.

Vera Goga is the Recruiter managing this role. As the team experience high volumes of applications, we appreciate your patience to allow for a fair and timely process.",3.9,"Accenture
3.9",Sydney,-1,10000+ Employees,1989,Company - Public,Consulting,Business Services,$10+ billion (USD),-1
Student Engineer,-1,"The candidate will have the ability to:
Undertake onsite inspection to collect asset condition data based on the relevant engineering standards and technical guidelines;
Undertake desktop analysis to evaluate the condition and performance of the assets;
Provide the appropriate information, advice, engineering input and support services for the sustainable management of Council’s stormwater and transport networks.
Qualifications:
The successful candidate will be enrolled in a Bachelor of Engineering with a minimum of two years completed.
Position Number: 100678
Position Hours: Fixed term (3 months), hours will be negotiated with the successful candidate, maximum of 75 hours per fortnight.
Salary: Schedule A, Salary Point 4.0. $28.64 per hour ($55,853.45 per annum, pro-rata) in accordance with Glenorchy City Council’s Enterprise Agreement 2016
Please note that all successful applicants will be required to provide a current National Police Check prior to commencement of employment.
For further information on this position, contact Patrick Marshall, Senior Civil Engineer on (03) 6216 6800.
How to apply: Applications for this position must be lodged on this submission site or on the Glenorchy City Council website www.gcc.tas.gov.au - Careers page.
To be considered for this role, all applicants must address the key selection criteria in the and provide a current resume. A copy of the position description can be found by clicking the below hyperlink or on the Glenorchy City Council website.
Applications close at 8pm on Sunday, 1st November 2020
- Student Engineer",4.0,"Glenorchy City Council
4.0",Glenorchy,-1,501 to 1000 Employees,-1,Government,-1,-1,Less than $1 million (USD),-1
Data Engineer involving DevOps,-1,"Data Engineer involving DevOps
Axiom Technologies is an Australia based entity with the history of providing Managed IT solutions to medium to large scale enterprises globally. Please visit our website for more information about what we do at www.axiomtechnologies.com
Axiom Technologies is an Equal Opportunity Employer and encourage applicants from all backgrounds and gender to apply, including, Aboriginal and Torres Strait Islander candidates
Job Requirements:
8+ years IT experience, with at least 5+ years of “Data Engineer/Deveoper” focused titles/roles,
Data Tools: Hands on experience with Apache Beam.
Testing: Hands on experience with automated testing activities/outcomes
DevOps: Experience with the processes involving Microservices facilities for artifacts developed
Platform/OS: Mid-range/Unix
Languages: Unix (Shell) Scripting/commands, SQL, Python
File formats: Text, CSV, Parquet, JSON, XML
Scheduling: Jenkins, Airflow
Auto Scripting: Designing/creation of scripts for repetitive activity. E.g. Unix scripting/SQL
Big data: Exposure to Data Lake Concepts, Hive (Schema), HDFS
Source Control tools: GIT
Delivery Models: Agile, Scrum
Ingestion Design: Create/assess Source/Target data mapping designs
Frameworks: Development and delivery frameworks
Activity Reporting/Repository: Jira, Confluence.
Quality: Accuracy and attention to detail
Industry: Financial Services/Banking
Solutions: Define solutions from High level to detail design to address automating ingestion activity. Facilitate/confirm requirements from product owners, business team members and technical associates,
Process Automation: Automating processes in file management, testing data in files, analysis and design, configuration management.
Script Automation: Ability to design/create scripts to automate/improve data copy/migration/ETL for any repetitive activity.
Languages: Java, Python
Scheduling: Control-M
Databases: Relational. E.g. POSTGRESS, Oracle – as a ETL developer
File Formats: Mainframe – experience with referencing its data formats/copybooks
Big data: Experience referencing/using Hive (Schema) to access data in HDFS
Metadata management tools: MDM, EDC and Axon
Performance: Assess, recommend, improve mappings, SQL queries, Batch feeds
Automation Tools: Other tools that may add value to an automation program and generally support development. E.g. API, REST, JDBC, Webservices, Message Queues/Load balancer,
Cloud: Experience with processing of data files to be ingested/stored in the Cloud, preferably with AWS.
Prod Support: Experience in a production support role performing root cause / impact analysis – under time constraints
Experience in a similar role
8+ Years
What next?
If you are looking for that next challenge in your career and wish to apply for this role, please forward your resume to careers.au@axiomtechnologies.com",2.0,"Axiom Technologies
2.0",Melbourne,-1,1 to 50 Employees,-1,Company - Private,Industrial Manufacturing,Manufacturing,Less than $1 million (USD),-1
Data Engineer,-1,"About the Role
We are on an exciting digital journey so it’s a great time to join ME! We are seeking a Junior Data Engineer who enjoys rolling up their sleeves, learning and growing. As part of our Enterprise Data Team, you will ensure fit for purpose data warehouse solutions are built for use across the bank and by utilising best practise ETL standards, whilst ensuring the data is trusted by our BI developers and key business consumers. Oh, and you’ll get to work on Microsoft technology stack too!
You will be involved with investigating data issues, keeping data feeds flowing and collaborating with different projects across the bank to deliver quality data solutions. How important does that sound? What’s even more important is this role contributes directly to our overall business strategy through the provision of data to enable analytics & reporting, as well as supporting business and decision system processes.

About You
You’re naturally a highly motivated and energetic person who thrives in a dynamic, ever-changing collaborative team environment. Ideally you have previous experience as an ETL developer, Data Engineer or a BI developer, and if you have a degree in computer science or similar it would really put you ahead of the rest.

With your knowledge of SQL coding, data modelling, understanding of data warehouse concepts, plus experience of working on complex ETL solutions, you’re ready to expand your horizons and launch your career into the world of IT at ME.

About ME
We’re not like other banks.
ME was created by the industry super funds to be different from the pack – with a core purpose to help all Australians get ahead financially – no conditions, asterisks or exceptions. And we know that looking after customers starts with taking care of our people.
We believe everyone deserves the same opportunities in life, regardless of gender or identity, sexuality, ethnicity, religion or disability ‒ with internal affinity groups.
Perk ME up
Once you get your feet in the door at ME, we’ll put them both in your very own ME-branded Converse shoes. You’ll also get the following financial, health and fun perks when you join the team:
4U Extras portal (discounts and cashback on 100s of items including cinemas, shopping and gym memberships
10% Myki discount
Purchased Leave programme
Internal wellness programme (Mindfully ME)
Professional education through LinkedIn Learning
Novated Leasing
Professional membership reimbursements
Health checks
Financial education (To help you manage your money smarter)
LGBTIQ+ and Women at ME affinity groups

I want those Converse shoes (and the role)
Can’t see a closing date on the advert? That’s because we’re pretty efficient here at ME and we may start looking at applications sooner rather than later, so if this role sounds like your jam, be sure to apply by submitting your resume today.

Should an applicant be the preferred candidate, background checks (including police checks, reference checks, ASIC banned and disqualified persons and bankruptcy checks) will be completed prior to the candidate's employment being confirmed. The outcomes of the background checks do not automatically bar candidates; however will be assessed against the inherent requirements of the job.
Back Share
Apply Now",3.0,"ME Bank
3.0",Melbourne,-1,501 to 1000 Employees,-1,Company - Private,Banks & Credit Unions,Finance,$100 to $500 million (USD),-1
Software Engineer - Machine Learning/Data Science,-1,"Zendesk is looking for a Software Engineer - Machine Learning/Data Science for a full time position in our Melbourne office.
As part of our engineering team, you will work at a scale where the challenges start to get seriously interesting. Our global engineering team is widely dispersed over the world, with people across nearly every continent. You will get a chance to do cool things with a diverse bunch of people while working in the Melbourne office that is home to Zendesk’s first machine learning (ML) research team.
The Data Science Team, together with Data Engineering, have built Satisfaction Prediction, Answer Bot and Content Cues — products that use Machine Learning (ML) and Artificial Intelligence (AI) to help our customers work more efficiently.
What you get to do every day:
We’re currently looking for someone to join our team as we research, develop, and productionise Machine Learning and Deep Learning models. In addition to frequenting Melbourne’s finest purveyors of coffee, ramen, and bulgogi, you may find yourself:
Building machine learning models including neural networks in TensorFlow
Writing and deploying production-grade Python
Querying and constructing datasets in AWS Athena, Spark
Evaluating and responding to real-world model performance
Scaling your ML to millions of predictions per day
Presenting your work to a broader audience
Watching your algorithm help Zendesk’s end-users
What you'll bring to the role:
A strong foundation in a quantitative discipline (e.g. machine learning, statistics, bio/eco/etc-informatics, econometrics, etc) is critical for this position. While experience in deep learning and natural language processing would be beneficial, your best qualities are:
dedication to continuous learning
collaborative work attitude
strong communication skills
You should also be comfortable with at least one programming language, such as Python, R or Scala.
Application Deadline: 18/11/2020
Job Types: Full-time, Permanent
Salary: $85,000.00 – $110,000.00 per year
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Temporarily due to COVID-19",4.5,"Zendesk
4.5",Melbourne,-1,1001 to 5000 Employees,2007,Company - Public,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),-1
Software Engineer (Machine Learning),-1,"About the Role
AdelaideMRI is building a medical reporting tool. We require an engineer to work primarily on machine learning projects to improve reporting speed and report comprehensiveness.
You will perform data analysis of medical report datasets and image datasets to infer sentence recommendations, image classifications, or other actionable results for the doctors.
Skills and Experience
Background in machine learning or image processing
Qualifications in Computer Science, Software Development or Engineering or equivalent experience
Bonus points for Python
No prior medical knowledge is required.
This position offers flexible hours and work arrangements.
Job Type: Full-time
Experience:
Software Engineering: 1 year (Preferred)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Yes",-1,Adelaide MRI,Australia,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Hey there, we’re PEXA!

We started as an idea: to deliver a single, national e-Conveyancing solution. We collaborated with the industry to create a national electronic lodgement and settlement platform: PEXA. From our humble beginnings, we’ve now grown to more than 320 employees across 5 different states. We’re still expanding at a rapid rate and constantly challenging ourselves to create great experiences for our members as they transition to fully digital conveyancing.

Why become a PEXArian?

Great question! Being a PEXArian is so much more than just a job. We are passionate, motivated & unashamedly enthusiastic at PEXA - we love what we do and we’re proud to admit it! Creating brilliant member experiences wouldn’t be possible if we didn’t also strive to create an amazing employee experience. Alongside our members, our employees are at the heart of everything we do.
Here’s a snapshot of what your life at PEXA could look like:

Your growth:
We encourage you to hit your personal and professional Learning & Development goals with our tailored programs and tools.

Your wellness:
We care about your holistic well being - a fully stocked kitchen, four wellness days, a $250 wellness subsidy as well as lunch and learn sessions to support your financial well being.

Your work/life blend:
We know that work is just one aspect of your life, we want to help you create your ideal work/life blend, rather than squeezing in life around work.

Your family:
With a range of benefits aimed at supporting your family including access to a subsidised school holiday program, extended parental leave and flexi-time to support your return to work, superannuation payments for unpaid parental leave for primary carers and a childcare allowance for pre-primary aged children, when we say, ‘welcome to the family’, we really mean it!
The impact you'd drive:
The successful candidate will be responsible for developing, and maintaining infrastructure to support the delivery of new and existing products. They will also be contributing to establish the rules and frameworks for obtaining the required approvals for new products.
On day one we’d love you to have:
Experience with Python, Spark
Event streaming/sourcing with Kafka or AWS Kinesis
Experience with data structures, formats and data security best practices
AWS experience (e.g CloudFormation, S3, ECS, Lambda, SQS, IAM, KMS, DynamoDB, Glue, Athena)
Query construction and optimisation (e.g. SQL, Elasticsearch, Splunk, DynamoDB)
Git, version control practices, and continuous integration/delivery servers
PyUnit and unit testing frameworks
Production release cycles and maintenance
Collaborating with technical and non-technical teams
Even better:
Agile methodology/delivery
GraphQL
Modern frontend technology (e.g. ReactJS, TypeScript)
Machine learning frameworks and tools (e.g. TensorFlow, PyTorch)
OAuth 2, SAML 2, JWT
Data visualisation and exploration tools (e.g. Jupyter notebooks, Tableau)
AWS SageMaker
Sounds like you?
If this role sounds like you, apply today to have your application reviewed ASAP!",3.9,"Property Exchange Australia Limited
3.9",Melbourne,-1,201 to 500 Employees,2010,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Ongoing position
Full time
Based in Sydney, NSW
Who we are
Australian Red Cross is part of the world’s largest humanitarian organisation. Our aim is to improve the lives of the most vulnerable people in Australia and across our region.
About the role
The Data Engineer role will sit within the Data and Integration Squad in IT and will own (design, implement and support) the AWS Big Data technologies such as the Data Lake and Data Warehouse and support the organisation in growing the data analytics capabilities at Red Cross. In addition to this, the data engineer role will also administer the Power BI tool and support the implementation of the data mastering capability.
What you will bring
Experience building and optimizing data pipelines, architectures and data sets.
Experience in dimensional modelling and building data vaults
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with structured, semi-structured and unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Why work for us?
Work for purpose and know that your work assists Red Cross support and empower people and communities in times of vulnerability.
Generous salary packaging options available that can increase your take home pay.
Further information
To find out more about this opportunity please see the position description below or contact Sharath Kumar Gurram on 02 8651 8839.
Position Description: Position Description - Data Engineer .pdf
Applications for this position will close at 11:55pm Thursday, 5 November 2020.",4.1,"Australian Red Cross
4.1",New South Wales,-1,1001 to 5000 Employees,-1,Nonprofit Organization,Industrial Manufacturing,Manufacturing,$500 million to $1 billion (USD),-1
Junior Fullstack Data Engineer (Python and React),-1,"Formbay is the leading Renewable Energy Certificate Trading company in Sydney. We provide Digital Workflow and Compliance solutions in the renewable energy industry and document processing.
Thanks to our meteoric growth and our commitment to be the best at all we do, we've identified the need to bring on board a new Junior Fullstack Data Engineer.
Reporting to our Principal Machine Learning Engineer, you will help build Machine Learning pipelines for our existing Digital Workflow and Compliance solutions to automate fraud detection and document processing over terabytes of photographic and documentary data – including documents, photos, GPS data and aerial/satellite photography.
Our stack is based on Python, JavaScript, Dask, Tensorflow, CUDA, Nix/NixOS, AWS, Docker, PostgreSQL and more – familiarity with these applications will give you a leg-up on the competition.
Our ideal candidate will have the following competencies:
SQL
Python
JavaScript/TypeScript
Our candidate must also be comfortable working with Linux.
Located a stone's throw away from the Queen Victoria Building in Sydney's bustling CBD, we are centrally-located with easy access to public transportation, bars, cafes and fine dining.
Formbay will provide flexible working hours, a generous remuneration package and the opportunity to work on a world-first software solution are what we can offer you. Free, twice-weekly gym sessions and really, really good coffee are also available.
No hiring/recruitment agencies need apply.",5.0,"Formbay
5.0",Sydney,-1,1 to 50 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is an experienced and qualified Data Engineer to join our IT team based in Birtinya.
Key Responsibilities:
Create and maintain data pipelines and or ETL scripts
Create and maintain data integration including API and Batch interfaces
Performed detailed data analysis
Create and maintain corporate data models
Create and maintain data visualization using Qlik.Sense , PowerBI or Simliar Toolset
Experience in defining, building and maintaining data virtualization and/or star schema data warehouses
Maintain, tune and optimise database, integration and visualisation toolsets
ABOUT YOU:
To succeed in this role, you’ll need to bring the following experience and skills:
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Excellent communication skills both oral and written, with an ability to bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking
Experience with data analysis and modelling will be beneficial

How to Apply
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kawana Waters,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Graduate Data Science / Engineer,-1,"The NRMA is an organisation looking to the future, and right now, we are on the lookout for people who can help us reach our goal: to continue to shape the way Australians move, for the next 100 years and beyond. www.mynrma.com.au.
Everyone new to the team, along with our current staff, will temporarily work from home until it is safe to return to our offices. All interviewing and on boarding will be done virtually due to COVID-19.


Your opportunity
As Graduate Data Scientist or Engineer you will be part of the Data Engineering team delivering cloud data transition program for business initiatives and supporting the entire data platform build.
Your key responsibilities will be to:
Implementing Concepts of Data Warehousing, Data Mart creations within Cloud
Use of SQL for data analysis and insights
Building AI/Machine Learning prototype for implementing and supporting existing algorithms
Data Analytical reports build, using different tool sets


Requirements for Success:
Relevant Degree - Computer Science, Computer Engineering, Software Engineering, Data Science
Excellent SQL skills and demonstrated working knowledge in Python
Demonstrated understanding in data structure and algorithms.
Knowledge and concept of data warehousing methodologies
Any reporting tools experience Tableau or Oracle Analytics Cloud, Looker is desirable
Exposure to Google/AWS/Azure/Oracle any cloud based platforms is desirable
Good communication and interpersonal skills

If you have the required skills and the passion to join our high performing team, please apply today.

Employee Benefits
To ensure our employees feel valued, empowered and celebrated we provide a range of employee benefits including:
50% discount on all NRMA insurances
Free Roadside Assistance
12 weeks paid primary and 4 weeks paid secondary parental leave
Free NRMA Blue Membership
At the NRMA Group, we are People Moving People and diversity and inclusion are part of our DNA. Together, we continue to build an inclusive culture that encourages, supports and celebrates the diverse voices of our employees. It fuels our innovation, promotes flexible ways of working and connects us closer to our members and the communities we serve.",2.5,"NRMA Motoring & Services
2.5",Sydney,-1,501 to 1000 Employees,-1,Nonprofit Organization,Casual Restaurants,"Restaurants, Bars & Food Services",$500 million to $1 billion (USD),-1
Data Centre Engineer,-1,"We are a leading world group that provides low-carbon energy and services. To tackle the climate emergency facing us all, our aim is to become the world leader in the zero-carbon energy transition ""as a service"" for our clients – particular for companies and regional authorities. We use our expertise in our key business areas (renewables, gas, services) to provide competitive and bespoke solutions.
The Data Centre Engineer will be employed as part of a 24/7 ongoing shift to coordinate and monitor third party service providers, maintain the data centre facilities and infrastructure plans, coordinate the implementation of customer requests within the data centre and monitor systems, all in accordance with the Contract KPIs and SLAs.
Coordinate and monitor third party service providers for regular maintenance & testing, service faults & call outs, ensuring works are performed in accordance with Contract SLAs
Monitor and maintain the data centre facilities and infrastructure plans and documentation, including electrical, mechanical, hydraulics, fire and BMS/EMS systems
Coordinate the implementation of internal and external customer requests within the data centre
Perform scheduled plant checks and minor maintenance works
Ensure all Work Order requests are raised and closed in a timely manner
Conduct inductions for staff, vendors and contractors
Ensure all work permits for vendor works are raised and closed
Perform inventory checks on all equipment and critical spares

Qualifications
The selected candidate must be able to demonstrate:
Electrical or HVAC background, or Graduate Electrical or Mechanical Engineer
Passionate about quality work and career minded looking for a new challenge
Can commit to a day and night shift roster (2 days of day shift, then 2 days of night shift, 4 days off)
Ideally able to commence asap
As part of carrying out the duties of this role, it is mandatory to hold Australian Citizenship.

If you are interested and meet the selection criteria apply with an up-to-date resume via the apply instructions on this website.

ENGIE Services is an EEO employer, where all applicants are treated with fairness and respect and have equal access to the opportunities available.

We will not be engaging in the services of a recruitment agency to fill this vacancy and therefore request all interested candidates apply directly to this advertisement.

Job
: Maintenance
Primary Location
: Oceania-Australia-New South Wales-Erskine Park
Organization
: ENGIE Services Australia and New Zealand
Schedule
: Full-time
Nature of Responsibility
: Senior operational / administrative role
Job Posting
: Sep 11, 2020, 6:29:59 AM",3.7,"ENGIE Services Australia & New Zealand
3.7",Sydney,-1,5001 to 10000 Employees,1995,Company - Public,Energy,"Oil, Gas, Energy & Utilities",$2 to $5 billion (USD),-1
Senior Data Engineer,-1,"Senior Data Engineer, Temporary, SYDNEY - McKell

Job Title: Senior Data Engineer

Salary: SNSW Grade 9/10 - The package includes base salary range of $111,806 to $134,667, plus employer's contribution to superannuation and annual leave loading.

Location: Head Office – Haymarket

Employment Status: Temporary through till 30th June 2021


About Service NSW:

Service NSW is making it easier for people and businesses across NSW to access government services. The role designs, builds and analyses complex data from multiple sources to identify revenue, process and business improvement opportunities; providing new information and insights to the business to inform planning, continuous improvement and performance.

About the Role

We are currently seeking to appoint a Senior Data Engineer to deliver expert advice and services in the design of a Single View of Customer and data-related services to support the achievement of business outcomes and strategic goals. We support flexible working practices with staff working remotely during this time.

In this role you will:

Design, build and support a modern data platform based in AWS and vendor technologies.
Provide expertise on data modelling for Graph data model and Customer Data Platform (CDP).
Create data pipelines, load, transformation and reporting workloads in AWS.
Work with the latest data engineering technologies like Apache Kafka, AWS Kinesis, AWS Neptune, AWS Glue and AWS Athena.
Contribute to the design and decision-making of the right tool or platform for the job according to requirements.
Provide expert advice and guidance on data quality and data engineering best practices.
Support a “bigger than you can imagine” scale of data in production environments.
Design, develop and support a metrics-driven reporting solution and a meaningful business intelligence platform.
Document the solution design and support procedures of solutions.
Produce reports, visualisations and recommendations to answer complex business problems that are presented in the most appropriate format to ensure clarity for target audience.
Analyse and define new process improvement opportunities to support continuous improvement and business outcomes; providing advice to stakeholders, on ways to improve the efficiency and reliability of data products and services.
Be very responsive to the information needs of the business by corresponding to customers in a timely manner and provide support/solutions to issues raised.
Troubleshoot and perform root cause analysis on production issues. Identify and implement long term solutions to problems. Perform scheduled maintenance, release deployment and production support activities after business hours, from time to time.
Liaise with internal and external customers to discuss and gather requirements, solutions etc. and maintain a good working relationship with the stakeholders.


Skills and Experience Required:

Solid experience with workflow technologies designing and building data pipelines, data models and data stores.
Experience working within and an understanding of Amazon AWS ecosystem, including security and performance tuning.
Hands on experience working with different types of databases, with focus on Graph and NoSQL databases.
Experience with data streaming required. Having used Kafka and related technologies is an added advantage.
Sound knowledge and experience working with batch processing, data extraction and API integration.
Hands on experience with at least one programming language: Java, Python or scripting.
Demonstrated experience working in an Agile based, fast paced, complex environment within cross-functional teams.
Experience developing systematised insights, data analytics and reporting solutions is an added advantage.
Experience with interactive visualisation of data insights is an added advantage.


Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Salary Grade 9/10, with the base salary for this role starting at 111,806 base plus superannuation

Closing Date: 6th November at 9:59am - applications will be reviewed on a rolling basis, applications may close early or extend

Please apply online, direct applications submitted via email will not be considered.

The Department of Customer Service is proud to be an EEO Employer who are fully focused on equality and believe deeply in diversity of all identities making us different and a true reflection of our NSW customers. As an inclusive workplace, we support various employee resource groups, practice flexible work and workplace adjustment.

If you do require an adjustment during the recruitment process, please notify us on your application form.",3.2,"Service NSW
3.2",Sydney,-1,501 to 1000 Employees,2012,Government,State & Regional Agencies,Government,Unknown / Non-Applicable,-1
Data Engineer - Entry / Mid Level,-1,"Work with a great team on interesting projects customers
Gain more experience in AWS, Data, DevOps cloud operations
Got a working knowledge of AWS? We will teach you the cool stuff!

Itoc is seeking an up and coming Data Engineer to join our growing Data Team in Sydney.

This is an exciting role working with databases, data lakes, data warehouses, data transformation (Python SQL) and enabling AI/ML.

You will be implementing foundational, robust and production ready data platforms to enable business data-discovery, self-service, AI/ML functions across a range of client types and industries, allowing them to do more with their data.

You'll be responsible for:

Deploying data repositories such as lakes and warehouses.
Contribute to our growing portfolio of data solutions.
Ongoing optimisation and management of data platforms.
Development of transformational logic for data pipelines
Data evangelism. We want to show our clients how to follow the best practices for data.

Desired Skills and Experience

To take up the challenge, you will have a depth of skills and experience including:

1-2+ yrs of focused data experience working with SQL and/or NoSQL solutions
A solid education in Software Engineering or equivalent industry experience.
Anything Data focused preferred.
Ability to analyse business scenarios and associated data landscape to derive potential opportunities.
Strong foundation in Python and SQL
Working knowledge of APIs
Principle knowledge of the different relational database platforms and modern data storage techniques
Knowledge of the different aspects of data environments
Collect, store, process, verify consume
Experience with version management systems (such as GIT)
Working knowledge of AWS or another cloud platform - we will teach you the cool stuff.
Great communication skills, an ability to work closely with customers, developers and engineers and the confidence to present ideas in open forums.
Relevant tertiary qualifications and/or industry certifications.
Great communication skills, an ability to work closely with clients, developers and engineers and the confidence to present ideas in open forums.

While not required, a background in consulting and professional services is highly desirable.

Itoc Description

This is an exciting and challenging career opportunity to join the growing Sydney-based Data Team of a leading cloud solution provider where you will be given support to reach your long term career goals. You will be part of a team of cloud experts and will work in an environment of continuous improvement and learning delivering innovative cloud solutions across SaaS, online business and enterprise business.

On offer is a chance to join a team with a great working environment, in an organisation that values its employees and sees the value in ensuring they are engaged. Our team are clearly passionate about what they do, that's why we won the following awards:

Customer Obsession Partner of the Year 2015: ANZ Region
Customer Obsession Leadership Partner 2015: re:Invent

As an employer of choice Itoc offers competitive remuneration, training and development programs and a great working environment. We value a healthy work life balance.

The Perks

MacBook or Dell
Continuous internal learning that will provide training and career development opportunities
Working with a collaborative, social team and leveling-up your skills faster than you will anywhere else.
Quarterly social events

Itoc

Culture and smarts are important to us. Bring your secret sauce. This is no ordinary environment, you will work along some of the Cloud’s best. All engineers at Itoc must gain at least five AWS certifications. We work hard but we have fun.

Please note you must have full working rights in Australia and be available on-shore for face to face interviews.

No recruiters please.",4.0,"Itoc
4.0",Sydney,-1,1 to 50 Employees,2013,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Date: 01-Oct-2020

Location:
Melbourne, VIC, AU

Department:Description:
Technology discounts - from Apple HP Lenovo to Windows
Flexible work arrangements - work in a way that suits you best
Salary packaging - to suit your personal and financial circumstances

Do you want to work for one of the fastest growing data teams in Australia? Do you want to work on multiple data platforms and provide new solution offerings by leveraging cloud and big data technologies?

About the team

Big data information and analytics. Three words that spark apprehension in most businesses. But our team of experts are constantly curious and excited about combining our wonderful array of technological expertise to transform data into our clients most valuable assets making their work smarter. Our data consultants are supported with resources training and tools they need to excel at their work but also the freedom and power to create their own paths forward to make a difference.

As a Senior Consultant in Big Data you will work closely with the team and stakeholders to build and deliver a Cloud based vision for a next generation Big Data analytics platform with strong focus on data quality data security and deliver the systems that process huge volumes of data.

What will you typical day look like?

You will play a pivotal role in - Designing and producing high performing and stable applications to perform complex processing of massive volumes of data in a new cloud based architecture; Building real-time data processing applications which are integrated with business systems to enable value from analytic models to drive rapid decision making; Contributing to system architecture design for a data platform (including cloud-based structures both on and off premises data warehouse components and data lakes); this could cover a range of technologies various countries/locations and lines of business; Support data strategy or technology strategy definition programs including technology stack definition and target operating model requirements

Enough about us lets talk about you:
You are someone with:
Use of traditional data analytics tools and techniques (e.g. MSSQL Oracle MySQL) and ETL software (e.g. SSIS Informatica CloverETL)
Working in large scale cloud data solutions using platforms such as AWS or Azure or GCP will be a bonus.
Experience in scripting or programming (e.g. Python Java Scala C#)
Excellent verbal and written communication skills to adapt to technical and non-technical audiences.
Educated to degree level (or have equivalent experience)
Why Deloitte?

At Deloitte we create positively differentiated work experiences that enable our people to feel valued and achieve their full potential. We value difference and embrace people with diverse backgrounds and thinking styles. Knowing that people work best in different ways we are happy to discuss alternative arrangements if the working pattern you are looking for is not specifically indicated.",3.8,"Deloitte
3.8",Melbourne,-1,10000+ Employees,1850,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Engineer,-1,"Opportunity to grow the team
Period of growth
Intuitive app
S2M are working with a FinTech who have created a unique financial product to help thousands of people better manage their finance, and is currently scaling the company to the next level!

They are looking for a Data Engineer to join, and looking for someone who wants to be hands on, with opportunity to grow the team in future.

Role:

Looking for people with strong AWS experience. You will need passion for data and a cloud, through which you will help a rapidly scaling Australian FinTech establish their data infrastructure from the ground up.
5+ years’ experience as a data engineer within the data and analytics domain
A python 3.X aficionado who is very comfortable creating and orchestrating AWS data pipelines with nothing but code
Strong project delivery toolset experience in open source data integration tools
Experience with processing large volumes of complex data including visualisation and insights generation
Ability to define and develop data integration patterns and pipelines
Ability to assess complexity of data (volume, structure, relationship etc.)
Hands on experience working with different databases (RDBMS, NoSQL, Blob storage etc)
Hands on technical expertise setting up DevOps automation
Hands on experience working technologies/platform e.g. AWS, Dockers, Containers
Experience building data profiling and data cleansing frameworks
Technical reconciliation and reporting
Knowledge and experience in end-to-end project delivery, either traditional SDLC or agile delivery methodologies (or hybrid approaches)
Exceptional communication, documentation and presentation skills
If this sounds like you, get in touch today - kate.gabb@s2m.com.au
3167410agsdf",3.1,"S2M
3.1",Sydney,-1,Unknown,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Analysts,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is seeking experienced and qualified Data Analysts to join our IT team based in our corporate office in Birtinya (Sunshine Coast) or at our meat processing facility in Kilcoy.
Key Responsibilities:
A mixture of data analysis and commercial skills to source, blend and analyse data to gain insight and answer key commercial questions
Working with strategic leaders to define and model Key Performance Indicators, and assist in building forecasting models
Working closely with data engineers and BI developers to specify data pipelines and report visualisation
Drive the creation and implementation of data quality business rule including data definition, governance and quality assurance
About You:
To succeed in this role, you’ll need to bring the following experience and skills:
Proven ability to derive insight and knowledge from data using commercial expertise is a strong requirement
Strong SQL and Excel skills are essential, along with strong data analysis and commercial insights
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Effective people communicator - engage with stakeholders on reporting needs, interpret requirements into visual solutions and train/deliver the outputs to the stakeholders getting signoff of acceptance
Bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking

How to Apply:
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kilcoy,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Network Data Engineer,-1,"Min 6+ years of experience in the relevant technologies
Australian Driving License for visiting remote locations / Data Centre for day to day technical work.
Managing Network devices (switches, routers, firewalls, load balancer, and wireless technology)
Performing MACD activities for all network devices.
Supporting BAU operation activities.
Proficient in performing in-depth details of technical troubleshooting, cause and provide recommendation to the client for incidents causing extended network outage to client’s critical locations.
Provide exceptional network services in terms of network support, break-fix, design and consulting, new projects, implementation.
Configure, administer, and document firewall infrastructure.
Manage the firewall deployment, rules migrations, and firewall administration.
Supporting Cloud Migration Activities from traditional to AWS/Azure.
Setting up VPN tunnel with Cloud and 3rd Party network devices.
Integrating and upgrading existing ISP bandwidth with support from ISP Vendor.
Setting up VPN profiles for Users.
Installing hot fix and patches to mitigate the security devices from attacks and bugs.
Reviewing and fine tuning the firewall rules and NAT rules.
Documentation and change control.
Mentoring, Motivating and Guiding support teams
Technical skills:
o LAN
o Wireless
o WAN
o MPLS
o Routing protocols (OSPF,BGP)
o DMVPN
o Azure cloud Networking
o Network Security
Fortigate Manager / Analyzer / Firewall
Cisco ASA
Firepower FTD
Cisco Any connect
Site to Site VPN
F5 Load Balancing and Scripting iRule
Job Types: Full-time, Contract
Schedule:
8 hour shift
Experience:
Scripting: 5 years (Required)
Data Network: 5 years (Required)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Required)",3.6,"Total IT Global
3.6",Sydney,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Engineer - Processing & Analysis,-1,"Job Description:
Design,build and maintain the ingestion system to support various types of data(e.g. User behavior, RDS, NoSQL db and others) to be ingested to the data warehouse more timely and accurately
Translate data requirements into scalable technical data service with low latency and high concurrency
Design,build and maintain the batch or real time data pipeline in production using Hadoop big data technology
Analyze and improve efficiency, scalability, and stability of the system
Define and manage SLA,Data quality for all data sets in allocated areas of ownership
Requirements:
Minimum B.S. degree in Computer Science or a related technical field
2+ years of working experience in programming languages,such as Java,Scala,Python
Familiar with Hadoop, Spark and Flink data processing, experience of TB data processing experience is a plus
Familiar designing and operating of a robust distributed system is a plus
Understand data mining or machine learning
Excited to work intimately with data
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"SYNOPSIS:
Lead Data Engineer
Applications close Sunday 8 November 2020
Ongoing
Contact name: Shyni Sasikala
Phone: (02) 6249 9048
Email: Shyni.Sasikala@ga.gov.au

The Data Policy and Informatics section within the Digital Science and Information branch creates, implements, and promotes policies, platforms and tools that improve and support the quality, discoverability, accessibility, and general usability of Geoscience Australia’s science data products. The section consults with internal and external research, government and industry partners to establish collaborative data frameworks, architectures and models within Geoscience Australia (GA) and across broader national and international communities of practice. The section innovates, builds and maintains tools, systems, processes and governance that enable digital data management, cataloguing and open data delivery.
GA makes accessible a wide range of geoscientific and spatial data to a wide variety of stakeholders in multiple formats, and in recent years GA's data volumes have grown exponentially. GA is focussed on making its data and metadata assets accessible so that they can be used in machine to machine interactions for data analytics and other applications in environments that range from High Performance Computing (HPC), through high-end cloud servers, to mobile devices.
We currently have two opportunities for Lead Data Engineers in the Informatics team. The Lead Data Engineer is responsible for innovating and exploring new technologies that will advance GA’s science goals and maximise the uptake and use of GA’s science data. The Lead Data Engineer reports to the team’s Assistant Director but also works closely with other developers, data scientists and engineers within the Digital Science and Innovation (DiSI) branch, as well as diverse stakeholders both within and external to GA.",3.9,"Geoscience Australia
3.9",Canberra,-1,501 to 1000 Employees,2001,Government,Federal Agencies,Government,$100 to $500 million (USD),-1
Data Engineer,-1,"The Seven Network is part of Seven West Media, one of Australia’s most prominent media companies, with a market leading presence in content across broadcast television, online and in print. Comprising some of Australia’s most renowned media brands, SWM includes not just Seven Network and its affiliate channels 7two, 7mate, 7flix and BVOD offering 7plus, but also 7NEWS.com.au, The West Australian, The Sunday Times and more.
At Seven we are here to bring all Australians closer to the moments that move us - we’re first on the scene, with our finger on the pulse, on demand, in the moment. Together, we’re responsible for creating and sustaining authentic Australian engagement.
A new and exciting opportunity has opened for a Data Engineer to join the Audience Intelligence team. Based in Sydney and reporting to the Head of Data Enablement, you’ll be responsible for:
Implementation of end to end data solutions to support Data Strategy for the SWM group.
Work closely with the Data Solution Designers to develop and maintain scalable data pipelines and build out new file and API based integrations to address requirements from the various business stakeholders.
Collaborates with engineering, analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organisation.
Work on Data Preparation for analytics and data scientist team members and assist them from an engineering perspective in building and optimising the models including building the automation of the end to end workflows
Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.
Perform data analysis required to troubleshoot data related issues and assist in the resolution of production data issues.
Work effectively with vendors for successful delivery of projects and acceptance of the solution
Work on Delivery projects using Agile Software Development methodologies
We are looking for someone who has:
Bachelor's degree in computer science, computer engineering or other technical discipline is essential
Proven experience working as a digital analytics specialist
Extensive experience with digital analytics implementation (e.g. Google Analytics, Snowplow, Adobe Analytics) and BI processes and visualisation platforms
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience in ETL and building and optimizing ‘big data’ pipelines and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Experience with big data tools: Hadoop, Spark, etc., AWS cloud services: EC2, S3, Lambda and familiar with version control systems: Git
Strong coding skills with knowledge of Unix/Linux and scripting languages such as Unix Shell scripting, Python desirable
Experience supporting and working with cross-functional teams in a fast-paced environment.
Ability to multi-task and problem solve with changing demands and priorities
Ability to work under pressure to meet deadlines and detail oriented
Your success is our success: we will provide you with opportunities for you to keep learning and growing, enabling you to challenge and develop yourself. In return, we offer a benefits program that has something in it for everyone.
Seven West Media is an equal opportunity employer and we are committed to creating a diverse and inclusive workplace.
Recruitment Agencies: Seven West Media does not accept any unsolicited agency resumes and will not be responsible for any fees related to unsolicited resumes.
Advertised: 19 Oct 2020 12:00 AM AUS Eastern Daylight Time
Applications close:

Back to search results",2.5,"Seven West Media
2.5",Sydney,-1,5001 to 10000 Employees,1956,Company - Public,TV Broadcast & Cable Networks,Media,Unknown / Non-Applicable,-1
BICON Rules Engineer,-1,"APS 5 - $73,299 - $80,410 per annum plus superannuation
Biosecurity Plant Division
Canberra, ACT
Play an active role in managing biosecurity risk to Australia
Work in a motivated and professional team with a wide range of skills and backgrounds
Full training provided

Who we are
The BICON Content Development Team maintains and improves the Biosecurity Import CONditions database (BICON) content to allow external clients to understand and comply with their biosecurity obligations and internal clients to effectively manage biosecurity risk and regulate imports. We work collaboratively with internal clients to comprehend and implement their BICON content requirements and optimise the use of BICON to publish clear import requirements and onshore management support procedures to effectively manage biosecurity risk.

The Jobs
Key duties of these positions include:

working with business content (import and permit conditions) and import programs to understand and construct decision tree structures in the BICON database, in accordance with system design and authoring conventions
executing changes to import and permit conditions in alignment with service standards while complying with system rules and authoring conventions
providing technical advice through various formats on the most appropriate means of authoring BICON content to achieve import program and stakeholder objectives
using workflow management tools to maintain detailed records of changes to import conditions and key decisions
performing administrative tasks including system reporting, data analysis and scoping tasks for the BICON content change work program
contributing to the development and maintenance of instructional material, authoring conventions and courseware
clearly documenting and reporting system issues
developing and maintaining effective working relationships with internal and external stakeholders.

What we are looking for
Knowledge and experience
Experience working with complex IT systems.
Experience working collaboratively and as part of a team.
Knowledge of the role of biosecurity is preferred but not essential.

For additional information, please read the Job Description below.
Candidate Information Package docx Opens in new window",3.9,"Department of Agriculture & Water Resources
3.9",Australia,-1,5001 to 10000 Employees,-1,Government,Federal Agencies,Government,$500 million to $1 billion (USD),-1
Cloud Data Engineer,-1,"Job no: 509605
Work type: Permanent Full Time
Location: Melbourne, Canberra, Sydney
Do you embrace digital disruption?
Do you love solving complex problems, designing sophisticated solutions and building innovative technology?
Do you believe in creating powerful actionable insights from Data and Analytics?
Do you want to work in a diverse and flexible working environment?
KPMG is one of the most trusted and respected global professional services firms. Through depth of expertise, clarity of insight and strength of purpose we help our clients solve complex challenges, steer change, strengthen, transition and grow. We are a team based practice and this extends to our clients whom we work and collaborate with, in solving complex problems. Together, we design, innovate and implement, providing enduring advice that support our clients and the services they deliver. Our clients vary in size and come from a diverse range of sectors – all sharing in a common goal: to embrace change and deliver services that make Australia a better place. We are looking for talented individuals who would like to join us on the journey.
KPMG’s Digital Delta Team
We re-imagine and re-invent organisations to become world class digital enterprises using advanced technologies, data and human insights. We help organisations to embrace Digital Strategy, Artificial Intelligence (AI) & Cognitive, the Internet of Things (IoT), Data, Analytics & Modelling, Mobile App & Web, and User Experience (UX) & User Interface (UI) and more.
We work with clients to:
Formulate strategies that re-imagine organisations
Harness innovation from the 4th industrial revolution
Actioning insights from trusted data to consistently and quickly make clear decisions
Build adaptive organisations
Thrive as a connected enterprise – front, middle and back office
This is how you’ll contribute:
We are looking for ambitious Data Engineers who are passionate about helping clients define bold ambitions and deliver on them. Joining our team will take you on a journey of personal and technical growth and provide the opportunity to inspire confidence and empower change.
As a Data Engineer you are the designer, builder and manager of the information or ""big data"" infrastructure, preparing data for analytical or operational use. You will design, construct, test and maintain a data pipeline to pull together information from different source systems; integrating, consolidating and cleansing data; and structure it for use in individual analytics applications.
The KPMG Difference
Our people are focused on creating a diverse and dynamic environment that embraces and values differences. We value the variety of unique experiences, qualities and characteristics our people possess and we share and learn from each other.
We are proud to be consistently recognised as an employer of choice for women, and for our achievements in LGBT+ workplace inclusion.
Our commitment to ‘Flexibility’ allows our people to manage the changing demands of work, personal or family life. Explore the links below to hear our people share their experience @ KPMG:
Flexibility empowers wellbeing
Flexibility enables contribution to the community
Flexibility inspires technology & innovation
Flexibility supports family

Make KPMG the clear choice for your career and be Extraordinary!

Advertised: 09 Sep 2020 AUS Eastern Standard Time
Applications close:",3.8,"KPMG
3.8",Sydney,-1,10000+ Employees,1987,Subsidiary or Business Segment,Accounting,Accounting & Legal,$2 to $5 billion (USD),-1
Computer Network and Systems Engineer,-1,"Duties Include but are not limited to:
Tasks Include:
analysing, developing, interpreting and evaluating complex system design and architecture specifications, data models and diagrams in the development, configuration and integration of computer systems
researching, analysing, evaluating and monitoring network infrastructure to ensure networks are configured to operate at optimal performance
assessing and recommending improvements to network operations and integrated hardware, software, communications and operating systems
providing specialist skills in supporting and troubleshooting network problems and emergencies
installing, configuring, testing, maintaining and administering new and upgraded networks, software database applications, servers and workstations
providing network programming in support of specific business needs and requirements
preparing and maintaining procedures and documentation for network inventory, and recording diagnosis and resolution of network faults, enhancements and modifications to networks, and maintenance instructions
monitoring network traffic, and activity, capacity and usage to ensure continued integrity and optimal network performance
Skills and Experience Required:
Must have experience working in a Managed Service environment
Demonstrated experience in IT Networks and Data Centres
Understanding of systems and architectures to meet client needs
Experience in Help Desk including break / fix
Effective and timely documentation
Effective Task Management Skills
Be solution and outcome focused and willing to learn new technologies
Excellent communication skills with staff, clients and partners
Time management, ability to prioritise and deliver to schedule
Experience with N-Able and Connectwise desired
Open Cabling license desired
Job Types: Full-time, Permanent
Salary: $30.00 per hour
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,Trans-plant training,Canberra,-1,-1,-1,-1,-1,-1,-1,-1
Software Engineer (Data),-1,"If you are looking for an opportunity to make a real impact with smart people who are genuinely doing things differently then you've come to the right place! We're growing our data engineering capabilities and are looking for awesome data engineers to join our team.
With our diverse range of clients and projects, no day will look the same - but here's a great snapshot of what you'll be doing:
Work with some of the best Data Scientists and Engineers to deliver production-grade AI and Machine Learning systems as we deliver client projects from inception to production.
Consulting with our clients and working with them to build modern data systems using the 'best of' technologies and principles.
Advising clients on data strategy, architecture and technology.
Applying best software engineering practices in coding, monitoring and alerting, using CI/CD, TDD and cloud architectures.
Working over a wide range of big data tools and environments: not limited to; Apache Kafka, Spark, Python, Scala, Hive, Airflow, AWS EMR & Glue, GCP Dataproc & Dataflow, BigQuery, Snowflake, Redshift.
Who are we?
Glad you asked! We are Eliiza. Data science. Engineered for scale.
We are a passionate team of data scientists and engineers who apply data science and machine learning to solve real-world problems. Our mission is to create a bright future for Australian businesses and society in a world increasingly influenced by intelligent technologies.
We've created a culture that values diversity where people can truly be themselves! We care a lot about growing the Australian AI community in a positive direction, and we're doing several things to try and achieve that:
We provide opportunities for underrepresented groups to work in AI through our associate and intern programmes
We organise and participate in a range of community events, reading groups and meetups
We produce the AI Australia podcast
We blog about topics we care about
We stream brown bag sessions to the broader community
We're also part of Mantel Group's 'house of brands' which means it's not just the Eliiza team you'll work with, learn from and see at social events - there's another 230 of us across DigIO, Kasna & CMD Solutions!
So you're ready for something new?
We're keen to know more about you! Our team is made up of a range of people, with different experience across a huge range of data driven skill sets.
We'd love to hear from you if you have experience with:
one (or more) core language(s), ideally Scala, Python or Java
one (or more) cloud platforms, AWS, GCP, Azure
ETL/ELT concepts and technologies e.g. Data partitioning, Hive, Spark
streaming data concepts and technologies, ideally Kafka (Kinesis, Beam or Pubsub will do)
We'd be over the moon if you:
Experience with distributed/columnar databases (e.g. Snowflake, Big query, Redshift).
Experience with any of a variety of databases e.g. RDMS, NoSql, Columar, Distributed, Time series, Graph.
Knowledge of job orchestration and scheduling. Any experience with Airflow, Luigi or Oozie.
Experience with containers and container orchestration (Docker, Docker Compose or Kubernetes).
However, we value a diversity of skill-sets, and don't necessarily require that you're skilled with all of the above. If you feel you don't fit all the experience/skills listed above we still encourage you to apply or get in touch.
What's on offer if you join us?
We make sure you're always one step ahead by investing your learning and development, every year. We build our own training where it doesn't exist yet.
We hire smart people and get out of their way. By focusing on our five principles and not getting caught up in red tape, we trust you to get the job done.
You'll get all the tools you need - a new iPhone or Google phone, a new Macbook Pro or Dell, and a lot of branded swag!
But hold on, you mentioned a house of brands?
We certainly did! Mantel Group is an Australian-owned, 'house of brands' company with four technology businesses (Eliiza being one of them!) across Melbourne and Sydney. We're building a group of companies with open borders so we can support you to take on new skills without leaving an awesome team - we understand you won't have one job for life!
We may only be just two years old but Mantel Group has already been recognised #9 in the 2020 Best Places to Work in Australia and #4 in the AFR's 2020 fastest growing new companies.
Keen to chat?
Click ""Apply"" to share your details with our talent team, and we'll be in touch.
In the meantime, check out 'how we hire' to find out what's in store if you're successful and get to know us better by visiting our website and following Eliiza on LinkedIn.",-1,Eliiza,Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Infrastructure Engineer,-1,"Job Description:
Design and grow the Shopee data platform to support a variety of big data applications using open-source technologies including Kafka, Hadoop, Presto, HBase, Spark, Hive, Druid, and our own creations. Some examples include a real-time data streaming platform, a unified query platform, a cluster management system, and a machine learning platform
Dig into the source code of some open-source big data system to get the whole control and familiar with the details, configurations, designs and source code. Develop and maintain the internal release of big data systems and components as the business requirements.
Keep close and overall monitoring for all the deployments of the systems, maintain the system’s stability, improve the performance, discover the performance bottlenecks, tracking and troubleshooting, cost optimisation.
Requirements:
B. Sci. / Ms / PhD in Computer Science or a related technical field
Familiar with at least one of these languages: Java, Scala, Python, Bash under Linux / Unix. Scala is a plus
Familiar with the use and compute logical of SQL
Knowledge about the Big Data Infrastructure system technology like Distributed File System, Distributed Computing, Distributed Database will be a plus
Hands-on experiences Hadoop, Spark, Kafka, and/or Presto will be a plus
Love to use and develop open-source technologies
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"Work on an award-winning, international technology!
Endless career opportunities
An innovative, friendly team of 300+
This role will be focused on the development of our existing ClaimLogik line of products as well as working on our new cloud-first, modern suite of applications.

Intelligent Thought, our technology business is scaling and shipping our software globally. Already profitable, part of a much larger group business, with investors such as Macquarie Capital and Envest – we are all set to deliver textbook disruption to the Insurance Industry. The growth of the platform, of our customer base, and the increasing industry demand have led to the need for this role to help the team scale.

Our Philosophy
Give each employee a sense of purpose and an environment for them to connect the importance of their role to delivering a service that matters to our customers.
Challenge the ‘why’ of traditional claims processes.
Keep it simple – do only what brings value and what matters to the customer
Enable employee decisions, empower our people
Responsibilities:
Create, extend and maintain ETL pipelines to form our data lake, data warehouse and analytics platform (currently using the Microsoft Azure set of tools and service)
Help define the optimal data pipeline architecture
Influence the tool selection, platform selection, data architecture and strategy which will transform the business to be truly data-driven
Understand, analyse and size user requirements
Work with different parts of the business to provide them with the insights they need to deliver the best results
Skills & experience:
Degree or qualification in computer science or related
Advanced knowledge of relational database, including query authoring and query optimisation (MS SQL Server and PostgreSQL).
Experience building and optimising ETL pipelines
Experience designing complex data models
Experience working with cloud platforms (Azure or AWS)
Efficient time management and organisational skills
High attention to detail and accuracy
Effective communication skills to build strong working relationships; both written and verbal
Proactive and results-driven
Why Claim Central?
Claim Central Consolidated is a global insurance industry leader across, claims management, insurance technology and data and analytics. Currently operating in the United States, Australia, South Africa, Italy and New Zealand, we have pioneered digitally connected claims management services across the globe. Claim Central is a disruptor and thought leader in the industry and we were recognised as the Australian Financial Review’s 8th Most Innovative Company in Australia in 2016. This business is in a period of unprecedented growth, transitioning our technology and services into multiple geographies at a rapid pace. Our unique culture is based on teamwork, collaboration, trust, respect and performance. We also offer many benefits apart from our exceptional team culture; including flexible work arrangements, and continued professional development.

Be a part of this journey in a career-defining role.",-1,Claim Central,Matraville,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer - AI/ML,-1,"Our client provides services to a major industry across the country. The business is still early in it's days of technology development and the environment is greenfields in nature (no pun intended), effectively working like a start-up.

Their data and analytics team have worked and built leading and bleeding-edge technologies in this space and what they have created so far may be game-changing. From a machine learning perspective, the progress they have made to the business has already seen proven success in changing the future of an industry that will have positive consequences for all those involved.

You will have previously worked in a technical capacity in the data and analytics space and have experience working with an organisation where machine learning has been implemented, not just a concept that the business talks about having or the technology team would love to have. The commercial experience you will have had in the ML field will be proven examples of where you have affected the way a business or industry used to perform, to the changes that have come about from this.

Technically, you will have extensive experience in the Microsoft space - Power BI, Azure etc and you will have previously mentored and coached junior members of the teams you have been part of.

This is a rare opportunity in Brisbane where the business has truly embraced and funded projects across the ML space and would be a great chance for those in the Data Development/Data Engineering field, who are looking to move into a Data Scientist role in the future.

Please send your application through if you would like to know more.",4.0,"Emanate Technology
4.0",Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Solution designer/ ETL Engineer & Data Modeller,-1,"We are looking for a Qualified and Experienced Solution Designer to join our client for a period of 6 months with a view to extend.
You will work closely with team members and your contribution will range across gathering and analyzing information, developing and documenting improved processes and work instructions and experienced DWH Lead with skills in requirement analysis, solution designing, developing, testing and supporting ETL solutions.
A hands-on solution designer, data modeler and ETL developer for Data Warehousing and ETL application transformation projects using Informatica PowerCenter.
Knowledge on AWS, S3, Redshift, Informatica BDM, and related technologies.
Experience working with IPython, PySparks, AuCuMo, Airflow, Jenkins, Github, Athena, JIRA, Rally, Spectrum, Glue, Flyway.
Good exposure on Oracle PL/SQL, aware of DBA activities, writing and performance tuning of complex SQL queries.
Contract length: 6 months
Job Types: Full-time, Contract
Salary: $650.00 – $800.00 per day
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,nducive,Melbourne,-1,-1,-1,-1,-1,-1,-1,-1
"Data Engineer, Wollongong NSW or Mount Waverley VIC",-1,"Company Description
BlueScope is a technically advanced supplier of steel and steel products in Australia. We are an inclusive organisation and every day we showcase our technology and expertise throughout the world.

Job Description
We are looking for two Data Engineers to join our IT team, based in Wollongong NSW or Mount Waverley VIC. Use your experience in analytics to unlock business value, enabling use of big data for insights and decision-making.
Reporting to the Data Product Owner for our Australian Steel Products (ASP) business, this position will support strategic goals related to data. This will see you:
Gather business and technical requirements with the view to deliver outcomes;
Develop and implement end-to-end data collection, consolidation, modelling and visualisation solutions;
Document metadata in a dictionary and catalogue;
Ensure consumers of such information understand its accuracy, timeliness, quality and sensitivity, so that it is used appropriately; and
Identify opportunities to enhance analytics.
What are the benefits?
Work in a supportive and collaborative team environment whilst we embark on a journey to transform the way our business uses data!
Our systems landscape is broad and diverse. You will be encouraged to think creatively to develop data solutions which solve real business problems.
Working in this role you will enjoy:
the chance to learn more about data science;
salaried remuneration with attractive superannuation options;
the opportunity to participate in a performance incentive scheme; and
access to further development and career opportunities with BlueScope.
Who are we looking for?
We welcome applications from professionals with experience in data analytics and/or programming. Supported by your knowledge of project delivery methods (e.g. Agile), you will demonstrate:
experience with data mining, wrangling, mapping and visualisation techniques (e.g. Azure Data Factory, Databricks and/or DevOps etc.);
well-developed ability in gathering business and technical requirements;
skills in developing and implementing collection, consolidation, modelling and visualisation solutions; and
a passion for sharing your knowledge and desire for ongoing professional development.

Qualifications

null

Additional Information
We're proud to have been named an Inclusive Employer for 2019–2020 by the Diversity Council of Australia. We believe that our people are our strength. Having a diverse and inclusive workplace enables us to improve our capability and ensure continued, sustainable success.
We know that workplace flexibility can mean something different to everyone. Under our B-Flex initiative all of our roles have some degree of flexibility. We encourage you to discuss your needs with us.
Applications close Sunday 25th October 2020.",3.3,"BlueScope
3.3",Wollongong,-1,201 to 500 Employees,-1,Company - Private,Construction,"Construction, Repair & Maintenance",$100 to $500 million (USD),-1
ETL Data Engineer,-1,"ETL Data Engineer

Join a team that’s changing how Australia lives, works, plays and grows
We want you to be the best version of you

Work with innovative teams and explore new technologies to help solve real-world problems.

A typical day as a Data Engineer

ETL / Big Data Engineering professionals will be responsible for guiding the full lifecycle of a Data solution, including:
Working in highly client-facing roles to contribute throughout the end-to-end delivery lifecycle of complex and large-scale digital solutions
Use case and business case development
Support existing and new applications utilizing in-depth technical and data knowledge. Troubleshooting complex issues and providing advisory services to improve the client’s data landscape
Help to streamline and simplify the clients’ complex data landscape by integrating different applications and data architectures
Implementation from requirements analysis, platform selection, digital architecture design, application design and development, testing, and deployment
Interstate travel may be required

Basic qualifications:
Bachelor’s degree
Experience across systems integration, information management, data management and architecture, and business analytics
Experience with being in a team focusing on large-scale, multi-release information centric projects
Experience with waterfall and agile delivery and run / application support functions
Part of a team working on End to end implementation of at least 1 big data project

Preferred Skills:
Hand on experience in Data warehousing using ETL tools such as DataStage, Autosys and TeraData
Hands on experience in ETL job development with multiple stages like sequential file, Transformer, Lookup, join, sort and Database stages.
Strong hand on skills in design, development and implementation of various data remediation, Data migration, data integration techniques.
Strong hand on data modelling experience.
Strong hands on experience in database performance tuning including complex query optimizations and physical database tuning using Teradata.
Understanding of architectural designs and strategy related to data migration, data cleansing, data quality and data consolidation.
Proven data analysis, requirement gathering and problem-solving skills
Exposure to Unix environment and shell scripting.
Experience in Banking and Financial services industry
Desirable: Knowledge of cloud computing infrastructure (e.g. Amazon Web Services EC2, Google Cloud, Microsoft Azure)
About Accenture

Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. We combine unmatched experience and specialized capabilities across more than 40 industries — powered by the world’s largest network of Advanced Technology and Intelligent Operations centers. With 513,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises. Visit us at www.accenture.com.

Accenture is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, marital, domestic or civil partnership status, sexual orientation, gender identity, or any other basis as protected by applicable law.

Vera Goga is the Recruiter managing this role. As the team experience high volumes of applications, we appreciate your patience to allow for a fair and timely process.",3.9,"Accenture
3.9",Sydney,-1,10000+ Employees,1989,Company - Public,Consulting,Business Services,$10+ billion (USD),-1
Student Engineer,-1,"The candidate will have the ability to:
Undertake onsite inspection to collect asset condition data based on the relevant engineering standards and technical guidelines;
Undertake desktop analysis to evaluate the condition and performance of the assets;
Provide the appropriate information, advice, engineering input and support services for the sustainable management of Council’s stormwater and transport networks.
Qualifications:
The successful candidate will be enrolled in a Bachelor of Engineering with a minimum of two years completed.
Position Number: 100678
Position Hours: Fixed term (3 months), hours will be negotiated with the successful candidate, maximum of 75 hours per fortnight.
Salary: Schedule A, Salary Point 4.0. $28.64 per hour ($55,853.45 per annum, pro-rata) in accordance with Glenorchy City Council’s Enterprise Agreement 2016
Please note that all successful applicants will be required to provide a current National Police Check prior to commencement of employment.
For further information on this position, contact Patrick Marshall, Senior Civil Engineer on (03) 6216 6800.
How to apply: Applications for this position must be lodged on this submission site or on the Glenorchy City Council website www.gcc.tas.gov.au - Careers page.
To be considered for this role, all applicants must address the key selection criteria in the and provide a current resume. A copy of the position description can be found by clicking the below hyperlink or on the Glenorchy City Council website.
Applications close at 8pm on Sunday, 1st November 2020
- Student Engineer",4.0,"Glenorchy City Council
4.0",Glenorchy,-1,501 to 1000 Employees,-1,Government,-1,-1,Less than $1 million (USD),-1
Data Engineer involving DevOps,-1,"Data Engineer involving DevOps
Axiom Technologies is an Australia based entity with the history of providing Managed IT solutions to medium to large scale enterprises globally. Please visit our website for more information about what we do at www.axiomtechnologies.com
Axiom Technologies is an Equal Opportunity Employer and encourage applicants from all backgrounds and gender to apply, including, Aboriginal and Torres Strait Islander candidates
Job Requirements:
8+ years IT experience, with at least 5+ years of “Data Engineer/Deveoper” focused titles/roles,
Data Tools: Hands on experience with Apache Beam.
Testing: Hands on experience with automated testing activities/outcomes
DevOps: Experience with the processes involving Microservices facilities for artifacts developed
Platform/OS: Mid-range/Unix
Languages: Unix (Shell) Scripting/commands, SQL, Python
File formats: Text, CSV, Parquet, JSON, XML
Scheduling: Jenkins, Airflow
Auto Scripting: Designing/creation of scripts for repetitive activity. E.g. Unix scripting/SQL
Big data: Exposure to Data Lake Concepts, Hive (Schema), HDFS
Source Control tools: GIT
Delivery Models: Agile, Scrum
Ingestion Design: Create/assess Source/Target data mapping designs
Frameworks: Development and delivery frameworks
Activity Reporting/Repository: Jira, Confluence.
Quality: Accuracy and attention to detail
Industry: Financial Services/Banking
Solutions: Define solutions from High level to detail design to address automating ingestion activity. Facilitate/confirm requirements from product owners, business team members and technical associates,
Process Automation: Automating processes in file management, testing data in files, analysis and design, configuration management.
Script Automation: Ability to design/create scripts to automate/improve data copy/migration/ETL for any repetitive activity.
Languages: Java, Python
Scheduling: Control-M
Databases: Relational. E.g. POSTGRESS, Oracle – as a ETL developer
File Formats: Mainframe – experience with referencing its data formats/copybooks
Big data: Experience referencing/using Hive (Schema) to access data in HDFS
Metadata management tools: MDM, EDC and Axon
Performance: Assess, recommend, improve mappings, SQL queries, Batch feeds
Automation Tools: Other tools that may add value to an automation program and generally support development. E.g. API, REST, JDBC, Webservices, Message Queues/Load balancer,
Cloud: Experience with processing of data files to be ingested/stored in the Cloud, preferably with AWS.
Prod Support: Experience in a production support role performing root cause / impact analysis – under time constraints
Experience in a similar role
8+ Years
What next?
If you are looking for that next challenge in your career and wish to apply for this role, please forward your resume to careers.au@axiomtechnologies.com",2.0,"Axiom Technologies
2.0",Melbourne,-1,1 to 50 Employees,-1,Company - Private,Industrial Manufacturing,Manufacturing,Less than $1 million (USD),-1
Data Engineer,-1,"About the Role
We are on an exciting digital journey so it’s a great time to join ME! We are seeking a Junior Data Engineer who enjoys rolling up their sleeves, learning and growing. As part of our Enterprise Data Team, you will ensure fit for purpose data warehouse solutions are built for use across the bank and by utilising best practise ETL standards, whilst ensuring the data is trusted by our BI developers and key business consumers. Oh, and you’ll get to work on Microsoft technology stack too!
You will be involved with investigating data issues, keeping data feeds flowing and collaborating with different projects across the bank to deliver quality data solutions. How important does that sound? What’s even more important is this role contributes directly to our overall business strategy through the provision of data to enable analytics & reporting, as well as supporting business and decision system processes.

About You
You’re naturally a highly motivated and energetic person who thrives in a dynamic, ever-changing collaborative team environment. Ideally you have previous experience as an ETL developer, Data Engineer or a BI developer, and if you have a degree in computer science or similar it would really put you ahead of the rest.

With your knowledge of SQL coding, data modelling, understanding of data warehouse concepts, plus experience of working on complex ETL solutions, you’re ready to expand your horizons and launch your career into the world of IT at ME.

About ME
We’re not like other banks.
ME was created by the industry super funds to be different from the pack – with a core purpose to help all Australians get ahead financially – no conditions, asterisks or exceptions. And we know that looking after customers starts with taking care of our people.
We believe everyone deserves the same opportunities in life, regardless of gender or identity, sexuality, ethnicity, religion or disability ‒ with internal affinity groups.
Perk ME up
Once you get your feet in the door at ME, we’ll put them both in your very own ME-branded Converse shoes. You’ll also get the following financial, health and fun perks when you join the team:
4U Extras portal (discounts and cashback on 100s of items including cinemas, shopping and gym memberships
10% Myki discount
Purchased Leave programme
Internal wellness programme (Mindfully ME)
Professional education through LinkedIn Learning
Novated Leasing
Professional membership reimbursements
Health checks
Financial education (To help you manage your money smarter)
LGBTIQ+ and Women at ME affinity groups

I want those Converse shoes (and the role)
Can’t see a closing date on the advert? That’s because we’re pretty efficient here at ME and we may start looking at applications sooner rather than later, so if this role sounds like your jam, be sure to apply by submitting your resume today.

Should an applicant be the preferred candidate, background checks (including police checks, reference checks, ASIC banned and disqualified persons and bankruptcy checks) will be completed prior to the candidate's employment being confirmed. The outcomes of the background checks do not automatically bar candidates; however will be assessed against the inherent requirements of the job.
Back Share
Apply Now",3.0,"ME Bank
3.0",Melbourne,-1,501 to 1000 Employees,-1,Company - Private,Banks & Credit Unions,Finance,$100 to $500 million (USD),-1
Software Engineer - Machine Learning/Data Science,-1,"Zendesk is looking for a Software Engineer - Machine Learning/Data Science for a full time position in our Melbourne office.
As part of our engineering team, you will work at a scale where the challenges start to get seriously interesting. Our global engineering team is widely dispersed over the world, with people across nearly every continent. You will get a chance to do cool things with a diverse bunch of people while working in the Melbourne office that is home to Zendesk’s first machine learning (ML) research team.
The Data Science Team, together with Data Engineering, have built Satisfaction Prediction, Answer Bot and Content Cues — products that use Machine Learning (ML) and Artificial Intelligence (AI) to help our customers work more efficiently.
What you get to do every day:
We’re currently looking for someone to join our team as we research, develop, and productionise Machine Learning and Deep Learning models. In addition to frequenting Melbourne’s finest purveyors of coffee, ramen, and bulgogi, you may find yourself:
Building machine learning models including neural networks in TensorFlow
Writing and deploying production-grade Python
Querying and constructing datasets in AWS Athena, Spark
Evaluating and responding to real-world model performance
Scaling your ML to millions of predictions per day
Presenting your work to a broader audience
Watching your algorithm help Zendesk’s end-users
What you'll bring to the role:
A strong foundation in a quantitative discipline (e.g. machine learning, statistics, bio/eco/etc-informatics, econometrics, etc) is critical for this position. While experience in deep learning and natural language processing would be beneficial, your best qualities are:
dedication to continuous learning
collaborative work attitude
strong communication skills
You should also be comfortable with at least one programming language, such as Python, R or Scala.
Application Deadline: 18/11/2020
Job Types: Full-time, Permanent
Salary: $85,000.00 – $110,000.00 per year
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Temporarily due to COVID-19",4.5,"Zendesk
4.5",Melbourne,-1,1001 to 5000 Employees,2007,Company - Public,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),-1
Software Engineer (Machine Learning),-1,"About the Role
AdelaideMRI is building a medical reporting tool. We require an engineer to work primarily on machine learning projects to improve reporting speed and report comprehensiveness.
You will perform data analysis of medical report datasets and image datasets to infer sentence recommendations, image classifications, or other actionable results for the doctors.
Skills and Experience
Background in machine learning or image processing
Qualifications in Computer Science, Software Development or Engineering or equivalent experience
Bonus points for Python
No prior medical knowledge is required.
This position offers flexible hours and work arrangements.
Job Type: Full-time
Experience:
Software Engineering: 1 year (Preferred)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Yes",-1,Adelaide MRI,Australia,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Hey there, we’re PEXA!

We started as an idea: to deliver a single, national e-Conveyancing solution. We collaborated with the industry to create a national electronic lodgement and settlement platform: PEXA. From our humble beginnings, we’ve now grown to more than 320 employees across 5 different states. We’re still expanding at a rapid rate and constantly challenging ourselves to create great experiences for our members as they transition to fully digital conveyancing.

Why become a PEXArian?

Great question! Being a PEXArian is so much more than just a job. We are passionate, motivated & unashamedly enthusiastic at PEXA - we love what we do and we’re proud to admit it! Creating brilliant member experiences wouldn’t be possible if we didn’t also strive to create an amazing employee experience. Alongside our members, our employees are at the heart of everything we do.
Here’s a snapshot of what your life at PEXA could look like:

Your growth:
We encourage you to hit your personal and professional Learning & Development goals with our tailored programs and tools.

Your wellness:
We care about your holistic well being - a fully stocked kitchen, four wellness days, a $250 wellness subsidy as well as lunch and learn sessions to support your financial well being.

Your work/life blend:
We know that work is just one aspect of your life, we want to help you create your ideal work/life blend, rather than squeezing in life around work.

Your family:
With a range of benefits aimed at supporting your family including access to a subsidised school holiday program, extended parental leave and flexi-time to support your return to work, superannuation payments for unpaid parental leave for primary carers and a childcare allowance for pre-primary aged children, when we say, ‘welcome to the family’, we really mean it!
The impact you'd drive:
The successful candidate will be responsible for developing, and maintaining infrastructure to support the delivery of new and existing products. They will also be contributing to establish the rules and frameworks for obtaining the required approvals for new products.
On day one we’d love you to have:
Experience with Python, Spark
Event streaming/sourcing with Kafka or AWS Kinesis
Experience with data structures, formats and data security best practices
AWS experience (e.g CloudFormation, S3, ECS, Lambda, SQS, IAM, KMS, DynamoDB, Glue, Athena)
Query construction and optimisation (e.g. SQL, Elasticsearch, Splunk, DynamoDB)
Git, version control practices, and continuous integration/delivery servers
PyUnit and unit testing frameworks
Production release cycles and maintenance
Collaborating with technical and non-technical teams
Even better:
Agile methodology/delivery
GraphQL
Modern frontend technology (e.g. ReactJS, TypeScript)
Machine learning frameworks and tools (e.g. TensorFlow, PyTorch)
OAuth 2, SAML 2, JWT
Data visualisation and exploration tools (e.g. Jupyter notebooks, Tableau)
AWS SageMaker
Sounds like you?
If this role sounds like you, apply today to have your application reviewed ASAP!",3.9,"Property Exchange Australia Limited
3.9",Melbourne,-1,201 to 500 Employees,2010,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Ongoing position
Full time
Based in Sydney, NSW
Who we are
Australian Red Cross is part of the world’s largest humanitarian organisation. Our aim is to improve the lives of the most vulnerable people in Australia and across our region.
About the role
The Data Engineer role will sit within the Data and Integration Squad in IT and will own (design, implement and support) the AWS Big Data technologies such as the Data Lake and Data Warehouse and support the organisation in growing the data analytics capabilities at Red Cross. In addition to this, the data engineer role will also administer the Power BI tool and support the implementation of the data mastering capability.
What you will bring
Experience building and optimizing data pipelines, architectures and data sets.
Experience in dimensional modelling and building data vaults
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with structured, semi-structured and unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Why work for us?
Work for purpose and know that your work assists Red Cross support and empower people and communities in times of vulnerability.
Generous salary packaging options available that can increase your take home pay.
Further information
To find out more about this opportunity please see the position description below or contact Sharath Kumar Gurram on 02 8651 8839.
Position Description: Position Description - Data Engineer .pdf
Applications for this position will close at 11:55pm Thursday, 5 November 2020.",4.1,"Australian Red Cross
4.1",New South Wales,-1,1001 to 5000 Employees,-1,Nonprofit Organization,Industrial Manufacturing,Manufacturing,$500 million to $1 billion (USD),-1
Junior Fullstack Data Engineer (Python and React),-1,"Formbay is the leading Renewable Energy Certificate Trading company in Sydney. We provide Digital Workflow and Compliance solutions in the renewable energy industry and document processing.
Thanks to our meteoric growth and our commitment to be the best at all we do, we've identified the need to bring on board a new Junior Fullstack Data Engineer.
Reporting to our Principal Machine Learning Engineer, you will help build Machine Learning pipelines for our existing Digital Workflow and Compliance solutions to automate fraud detection and document processing over terabytes of photographic and documentary data – including documents, photos, GPS data and aerial/satellite photography.
Our stack is based on Python, JavaScript, Dask, Tensorflow, CUDA, Nix/NixOS, AWS, Docker, PostgreSQL and more – familiarity with these applications will give you a leg-up on the competition.
Our ideal candidate will have the following competencies:
SQL
Python
JavaScript/TypeScript
Our candidate must also be comfortable working with Linux.
Located a stone's throw away from the Queen Victoria Building in Sydney's bustling CBD, we are centrally-located with easy access to public transportation, bars, cafes and fine dining.
Formbay will provide flexible working hours, a generous remuneration package and the opportunity to work on a world-first software solution are what we can offer you. Free, twice-weekly gym sessions and really, really good coffee are also available.
No hiring/recruitment agencies need apply.",5.0,"Formbay
5.0",Sydney,-1,1 to 50 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is an experienced and qualified Data Engineer to join our IT team based in Birtinya.
Key Responsibilities:
Create and maintain data pipelines and or ETL scripts
Create and maintain data integration including API and Batch interfaces
Performed detailed data analysis
Create and maintain corporate data models
Create and maintain data visualization using Qlik.Sense , PowerBI or Simliar Toolset
Experience in defining, building and maintaining data virtualization and/or star schema data warehouses
Maintain, tune and optimise database, integration and visualisation toolsets
ABOUT YOU:
To succeed in this role, you’ll need to bring the following experience and skills:
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Excellent communication skills both oral and written, with an ability to bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking
Experience with data analysis and modelling will be beneficial

How to Apply
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kawana Waters,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Graduate Data Science / Engineer,-1,"The NRMA is an organisation looking to the future, and right now, we are on the lookout for people who can help us reach our goal: to continue to shape the way Australians move, for the next 100 years and beyond. www.mynrma.com.au.
Everyone new to the team, along with our current staff, will temporarily work from home until it is safe to return to our offices. All interviewing and on boarding will be done virtually due to COVID-19.


Your opportunity
As Graduate Data Scientist or Engineer you will be part of the Data Engineering team delivering cloud data transition program for business initiatives and supporting the entire data platform build.
Your key responsibilities will be to:
Implementing Concepts of Data Warehousing, Data Mart creations within Cloud
Use of SQL for data analysis and insights
Building AI/Machine Learning prototype for implementing and supporting existing algorithms
Data Analytical reports build, using different tool sets


Requirements for Success:
Relevant Degree - Computer Science, Computer Engineering, Software Engineering, Data Science
Excellent SQL skills and demonstrated working knowledge in Python
Demonstrated understanding in data structure and algorithms.
Knowledge and concept of data warehousing methodologies
Any reporting tools experience Tableau or Oracle Analytics Cloud, Looker is desirable
Exposure to Google/AWS/Azure/Oracle any cloud based platforms is desirable
Good communication and interpersonal skills

If you have the required skills and the passion to join our high performing team, please apply today.

Employee Benefits
To ensure our employees feel valued, empowered and celebrated we provide a range of employee benefits including:
50% discount on all NRMA insurances
Free Roadside Assistance
12 weeks paid primary and 4 weeks paid secondary parental leave
Free NRMA Blue Membership
At the NRMA Group, we are People Moving People and diversity and inclusion are part of our DNA. Together, we continue to build an inclusive culture that encourages, supports and celebrates the diverse voices of our employees. It fuels our innovation, promotes flexible ways of working and connects us closer to our members and the communities we serve.",2.5,"NRMA Motoring & Services
2.5",Sydney,-1,501 to 1000 Employees,-1,Nonprofit Organization,Casual Restaurants,"Restaurants, Bars & Food Services",$500 million to $1 billion (USD),-1
Data Centre Engineer,-1,"We are a leading world group that provides low-carbon energy and services. To tackle the climate emergency facing us all, our aim is to become the world leader in the zero-carbon energy transition ""as a service"" for our clients – particular for companies and regional authorities. We use our expertise in our key business areas (renewables, gas, services) to provide competitive and bespoke solutions.
The Data Centre Engineer will be employed as part of a 24/7 ongoing shift to coordinate and monitor third party service providers, maintain the data centre facilities and infrastructure plans, coordinate the implementation of customer requests within the data centre and monitor systems, all in accordance with the Contract KPIs and SLAs.
Coordinate and monitor third party service providers for regular maintenance & testing, service faults & call outs, ensuring works are performed in accordance with Contract SLAs
Monitor and maintain the data centre facilities and infrastructure plans and documentation, including electrical, mechanical, hydraulics, fire and BMS/EMS systems
Coordinate the implementation of internal and external customer requests within the data centre
Perform scheduled plant checks and minor maintenance works
Ensure all Work Order requests are raised and closed in a timely manner
Conduct inductions for staff, vendors and contractors
Ensure all work permits for vendor works are raised and closed
Perform inventory checks on all equipment and critical spares

Qualifications
The selected candidate must be able to demonstrate:
Electrical or HVAC background, or Graduate Electrical or Mechanical Engineer
Passionate about quality work and career minded looking for a new challenge
Can commit to a day and night shift roster (2 days of day shift, then 2 days of night shift, 4 days off)
Ideally able to commence asap
As part of carrying out the duties of this role, it is mandatory to hold Australian Citizenship.

If you are interested and meet the selection criteria apply with an up-to-date resume via the apply instructions on this website.

ENGIE Services is an EEO employer, where all applicants are treated with fairness and respect and have equal access to the opportunities available.

We will not be engaging in the services of a recruitment agency to fill this vacancy and therefore request all interested candidates apply directly to this advertisement.

Job
: Maintenance
Primary Location
: Oceania-Australia-New South Wales-Erskine Park
Organization
: ENGIE Services Australia and New Zealand
Schedule
: Full-time
Nature of Responsibility
: Senior operational / administrative role
Job Posting
: Sep 11, 2020, 6:29:59 AM",3.7,"ENGIE Services Australia & New Zealand
3.7",Sydney,-1,5001 to 10000 Employees,1995,Company - Public,Energy,"Oil, Gas, Energy & Utilities",$2 to $5 billion (USD),-1
Senior Data Engineer,-1,"Senior Data Engineer, Temporary, SYDNEY - McKell

Job Title: Senior Data Engineer

Salary: SNSW Grade 9/10 - The package includes base salary range of $111,806 to $134,667, plus employer's contribution to superannuation and annual leave loading.

Location: Head Office – Haymarket

Employment Status: Temporary through till 30th June 2021


About Service NSW:

Service NSW is making it easier for people and businesses across NSW to access government services. The role designs, builds and analyses complex data from multiple sources to identify revenue, process and business improvement opportunities; providing new information and insights to the business to inform planning, continuous improvement and performance.

About the Role

We are currently seeking to appoint a Senior Data Engineer to deliver expert advice and services in the design of a Single View of Customer and data-related services to support the achievement of business outcomes and strategic goals. We support flexible working practices with staff working remotely during this time.

In this role you will:

Design, build and support a modern data platform based in AWS and vendor technologies.
Provide expertise on data modelling for Graph data model and Customer Data Platform (CDP).
Create data pipelines, load, transformation and reporting workloads in AWS.
Work with the latest data engineering technologies like Apache Kafka, AWS Kinesis, AWS Neptune, AWS Glue and AWS Athena.
Contribute to the design and decision-making of the right tool or platform for the job according to requirements.
Provide expert advice and guidance on data quality and data engineering best practices.
Support a “bigger than you can imagine” scale of data in production environments.
Design, develop and support a metrics-driven reporting solution and a meaningful business intelligence platform.
Document the solution design and support procedures of solutions.
Produce reports, visualisations and recommendations to answer complex business problems that are presented in the most appropriate format to ensure clarity for target audience.
Analyse and define new process improvement opportunities to support continuous improvement and business outcomes; providing advice to stakeholders, on ways to improve the efficiency and reliability of data products and services.
Be very responsive to the information needs of the business by corresponding to customers in a timely manner and provide support/solutions to issues raised.
Troubleshoot and perform root cause analysis on production issues. Identify and implement long term solutions to problems. Perform scheduled maintenance, release deployment and production support activities after business hours, from time to time.
Liaise with internal and external customers to discuss and gather requirements, solutions etc. and maintain a good working relationship with the stakeholders.


Skills and Experience Required:

Solid experience with workflow technologies designing and building data pipelines, data models and data stores.
Experience working within and an understanding of Amazon AWS ecosystem, including security and performance tuning.
Hands on experience working with different types of databases, with focus on Graph and NoSQL databases.
Experience with data streaming required. Having used Kafka and related technologies is an added advantage.
Sound knowledge and experience working with batch processing, data extraction and API integration.
Hands on experience with at least one programming language: Java, Python or scripting.
Demonstrated experience working in an Agile based, fast paced, complex environment within cross-functional teams.
Experience developing systematised insights, data analytics and reporting solutions is an added advantage.
Experience with interactive visualisation of data insights is an added advantage.


Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Salary Grade 9/10, with the base salary for this role starting at 111,806 base plus superannuation

Closing Date: 6th November at 9:59am - applications will be reviewed on a rolling basis, applications may close early or extend

Please apply online, direct applications submitted via email will not be considered.

The Department of Customer Service is proud to be an EEO Employer who are fully focused on equality and believe deeply in diversity of all identities making us different and a true reflection of our NSW customers. As an inclusive workplace, we support various employee resource groups, practice flexible work and workplace adjustment.

If you do require an adjustment during the recruitment process, please notify us on your application form.",3.2,"Service NSW
3.2",Sydney,-1,501 to 1000 Employees,2012,Government,State & Regional Agencies,Government,Unknown / Non-Applicable,-1
Data Engineer - Entry / Mid Level,-1,"Work with a great team on interesting projects customers
Gain more experience in AWS, Data, DevOps cloud operations
Got a working knowledge of AWS? We will teach you the cool stuff!

Itoc is seeking an up and coming Data Engineer to join our growing Data Team in Sydney.

This is an exciting role working with databases, data lakes, data warehouses, data transformation (Python SQL) and enabling AI/ML.

You will be implementing foundational, robust and production ready data platforms to enable business data-discovery, self-service, AI/ML functions across a range of client types and industries, allowing them to do more with their data.

You'll be responsible for:

Deploying data repositories such as lakes and warehouses.
Contribute to our growing portfolio of data solutions.
Ongoing optimisation and management of data platforms.
Development of transformational logic for data pipelines
Data evangelism. We want to show our clients how to follow the best practices for data.

Desired Skills and Experience

To take up the challenge, you will have a depth of skills and experience including:

1-2+ yrs of focused data experience working with SQL and/or NoSQL solutions
A solid education in Software Engineering or equivalent industry experience.
Anything Data focused preferred.
Ability to analyse business scenarios and associated data landscape to derive potential opportunities.
Strong foundation in Python and SQL
Working knowledge of APIs
Principle knowledge of the different relational database platforms and modern data storage techniques
Knowledge of the different aspects of data environments
Collect, store, process, verify consume
Experience with version management systems (such as GIT)
Working knowledge of AWS or another cloud platform - we will teach you the cool stuff.
Great communication skills, an ability to work closely with customers, developers and engineers and the confidence to present ideas in open forums.
Relevant tertiary qualifications and/or industry certifications.
Great communication skills, an ability to work closely with clients, developers and engineers and the confidence to present ideas in open forums.

While not required, a background in consulting and professional services is highly desirable.

Itoc Description

This is an exciting and challenging career opportunity to join the growing Sydney-based Data Team of a leading cloud solution provider where you will be given support to reach your long term career goals. You will be part of a team of cloud experts and will work in an environment of continuous improvement and learning delivering innovative cloud solutions across SaaS, online business and enterprise business.

On offer is a chance to join a team with a great working environment, in an organisation that values its employees and sees the value in ensuring they are engaged. Our team are clearly passionate about what they do, that's why we won the following awards:

Customer Obsession Partner of the Year 2015: ANZ Region
Customer Obsession Leadership Partner 2015: re:Invent

As an employer of choice Itoc offers competitive remuneration, training and development programs and a great working environment. We value a healthy work life balance.

The Perks

MacBook or Dell
Continuous internal learning that will provide training and career development opportunities
Working with a collaborative, social team and leveling-up your skills faster than you will anywhere else.
Quarterly social events

Itoc

Culture and smarts are important to us. Bring your secret sauce. This is no ordinary environment, you will work along some of the Cloud’s best. All engineers at Itoc must gain at least five AWS certifications. We work hard but we have fun.

Please note you must have full working rights in Australia and be available on-shore for face to face interviews.

No recruiters please.",4.0,"Itoc
4.0",Sydney,-1,1 to 50 Employees,2013,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Date: 01-Oct-2020

Location:
Melbourne, VIC, AU

Department:Description:
Technology discounts - from Apple HP Lenovo to Windows
Flexible work arrangements - work in a way that suits you best
Salary packaging - to suit your personal and financial circumstances

Do you want to work for one of the fastest growing data teams in Australia? Do you want to work on multiple data platforms and provide new solution offerings by leveraging cloud and big data technologies?

About the team

Big data information and analytics. Three words that spark apprehension in most businesses. But our team of experts are constantly curious and excited about combining our wonderful array of technological expertise to transform data into our clients most valuable assets making their work smarter. Our data consultants are supported with resources training and tools they need to excel at their work but also the freedom and power to create their own paths forward to make a difference.

As a Senior Consultant in Big Data you will work closely with the team and stakeholders to build and deliver a Cloud based vision for a next generation Big Data analytics platform with strong focus on data quality data security and deliver the systems that process huge volumes of data.

What will you typical day look like?

You will play a pivotal role in - Designing and producing high performing and stable applications to perform complex processing of massive volumes of data in a new cloud based architecture; Building real-time data processing applications which are integrated with business systems to enable value from analytic models to drive rapid decision making; Contributing to system architecture design for a data platform (including cloud-based structures both on and off premises data warehouse components and data lakes); this could cover a range of technologies various countries/locations and lines of business; Support data strategy or technology strategy definition programs including technology stack definition and target operating model requirements

Enough about us lets talk about you:
You are someone with:
Use of traditional data analytics tools and techniques (e.g. MSSQL Oracle MySQL) and ETL software (e.g. SSIS Informatica CloverETL)
Working in large scale cloud data solutions using platforms such as AWS or Azure or GCP will be a bonus.
Experience in scripting or programming (e.g. Python Java Scala C#)
Excellent verbal and written communication skills to adapt to technical and non-technical audiences.
Educated to degree level (or have equivalent experience)
Why Deloitte?

At Deloitte we create positively differentiated work experiences that enable our people to feel valued and achieve their full potential. We value difference and embrace people with diverse backgrounds and thinking styles. Knowing that people work best in different ways we are happy to discuss alternative arrangements if the working pattern you are looking for is not specifically indicated.",3.8,"Deloitte
3.8",Melbourne,-1,10000+ Employees,1850,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Engineer,-1,"Opportunity to grow the team
Period of growth
Intuitive app
S2M are working with a FinTech who have created a unique financial product to help thousands of people better manage their finance, and is currently scaling the company to the next level!

They are looking for a Data Engineer to join, and looking for someone who wants to be hands on, with opportunity to grow the team in future.

Role:

Looking for people with strong AWS experience. You will need passion for data and a cloud, through which you will help a rapidly scaling Australian FinTech establish their data infrastructure from the ground up.
5+ years’ experience as a data engineer within the data and analytics domain
A python 3.X aficionado who is very comfortable creating and orchestrating AWS data pipelines with nothing but code
Strong project delivery toolset experience in open source data integration tools
Experience with processing large volumes of complex data including visualisation and insights generation
Ability to define and develop data integration patterns and pipelines
Ability to assess complexity of data (volume, structure, relationship etc.)
Hands on experience working with different databases (RDBMS, NoSQL, Blob storage etc)
Hands on technical expertise setting up DevOps automation
Hands on experience working technologies/platform e.g. AWS, Dockers, Containers
Experience building data profiling and data cleansing frameworks
Technical reconciliation and reporting
Knowledge and experience in end-to-end project delivery, either traditional SDLC or agile delivery methodologies (or hybrid approaches)
Exceptional communication, documentation and presentation skills
If this sounds like you, get in touch today - kate.gabb@s2m.com.au
3167410agsdf",3.1,"S2M
3.1",Sydney,-1,Unknown,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Analysts,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is seeking experienced and qualified Data Analysts to join our IT team based in our corporate office in Birtinya (Sunshine Coast) or at our meat processing facility in Kilcoy.
Key Responsibilities:
A mixture of data analysis and commercial skills to source, blend and analyse data to gain insight and answer key commercial questions
Working with strategic leaders to define and model Key Performance Indicators, and assist in building forecasting models
Working closely with data engineers and BI developers to specify data pipelines and report visualisation
Drive the creation and implementation of data quality business rule including data definition, governance and quality assurance
About You:
To succeed in this role, you’ll need to bring the following experience and skills:
Proven ability to derive insight and knowledge from data using commercial expertise is a strong requirement
Strong SQL and Excel skills are essential, along with strong data analysis and commercial insights
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Effective people communicator - engage with stakeholders on reporting needs, interpret requirements into visual solutions and train/deliver the outputs to the stakeholders getting signoff of acceptance
Bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking

How to Apply:
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kilcoy,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Network Data Engineer,-1,"Min 6+ years of experience in the relevant technologies
Australian Driving License for visiting remote locations / Data Centre for day to day technical work.
Managing Network devices (switches, routers, firewalls, load balancer, and wireless technology)
Performing MACD activities for all network devices.
Supporting BAU operation activities.
Proficient in performing in-depth details of technical troubleshooting, cause and provide recommendation to the client for incidents causing extended network outage to client’s critical locations.
Provide exceptional network services in terms of network support, break-fix, design and consulting, new projects, implementation.
Configure, administer, and document firewall infrastructure.
Manage the firewall deployment, rules migrations, and firewall administration.
Supporting Cloud Migration Activities from traditional to AWS/Azure.
Setting up VPN tunnel with Cloud and 3rd Party network devices.
Integrating and upgrading existing ISP bandwidth with support from ISP Vendor.
Setting up VPN profiles for Users.
Installing hot fix and patches to mitigate the security devices from attacks and bugs.
Reviewing and fine tuning the firewall rules and NAT rules.
Documentation and change control.
Mentoring, Motivating and Guiding support teams
Technical skills:
o LAN
o Wireless
o WAN
o MPLS
o Routing protocols (OSPF,BGP)
o DMVPN
o Azure cloud Networking
o Network Security
Fortigate Manager / Analyzer / Firewall
Cisco ASA
Firepower FTD
Cisco Any connect
Site to Site VPN
F5 Load Balancing and Scripting iRule
Job Types: Full-time, Contract
Schedule:
8 hour shift
Experience:
Scripting: 5 years (Required)
Data Network: 5 years (Required)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Required)",3.6,"Total IT Global
3.6",Sydney,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Engineer - Processing & Analysis,-1,"Job Description:
Design,build and maintain the ingestion system to support various types of data(e.g. User behavior, RDS, NoSQL db and others) to be ingested to the data warehouse more timely and accurately
Translate data requirements into scalable technical data service with low latency and high concurrency
Design,build and maintain the batch or real time data pipeline in production using Hadoop big data technology
Analyze and improve efficiency, scalability, and stability of the system
Define and manage SLA,Data quality for all data sets in allocated areas of ownership
Requirements:
Minimum B.S. degree in Computer Science or a related technical field
2+ years of working experience in programming languages,such as Java,Scala,Python
Familiar with Hadoop, Spark and Flink data processing, experience of TB data processing experience is a plus
Familiar designing and operating of a robust distributed system is a plus
Understand data mining or machine learning
Excited to work intimately with data
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"SYNOPSIS:
Lead Data Engineer
Applications close Sunday 8 November 2020
Ongoing
Contact name: Shyni Sasikala
Phone: (02) 6249 9048
Email: Shyni.Sasikala@ga.gov.au

The Data Policy and Informatics section within the Digital Science and Information branch creates, implements, and promotes policies, platforms and tools that improve and support the quality, discoverability, accessibility, and general usability of Geoscience Australia’s science data products. The section consults with internal and external research, government and industry partners to establish collaborative data frameworks, architectures and models within Geoscience Australia (GA) and across broader national and international communities of practice. The section innovates, builds and maintains tools, systems, processes and governance that enable digital data management, cataloguing and open data delivery.
GA makes accessible a wide range of geoscientific and spatial data to a wide variety of stakeholders in multiple formats, and in recent years GA's data volumes have grown exponentially. GA is focussed on making its data and metadata assets accessible so that they can be used in machine to machine interactions for data analytics and other applications in environments that range from High Performance Computing (HPC), through high-end cloud servers, to mobile devices.
We currently have two opportunities for Lead Data Engineers in the Informatics team. The Lead Data Engineer is responsible for innovating and exploring new technologies that will advance GA’s science goals and maximise the uptake and use of GA’s science data. The Lead Data Engineer reports to the team’s Assistant Director but also works closely with other developers, data scientists and engineers within the Digital Science and Innovation (DiSI) branch, as well as diverse stakeholders both within and external to GA.",3.9,"Geoscience Australia
3.9",Canberra,-1,501 to 1000 Employees,2001,Government,Federal Agencies,Government,$100 to $500 million (USD),-1
Data Engineer,-1,"The Seven Network is part of Seven West Media, one of Australia’s most prominent media companies, with a market leading presence in content across broadcast television, online and in print. Comprising some of Australia’s most renowned media brands, SWM includes not just Seven Network and its affiliate channels 7two, 7mate, 7flix and BVOD offering 7plus, but also 7NEWS.com.au, The West Australian, The Sunday Times and more.
At Seven we are here to bring all Australians closer to the moments that move us - we’re first on the scene, with our finger on the pulse, on demand, in the moment. Together, we’re responsible for creating and sustaining authentic Australian engagement.
A new and exciting opportunity has opened for a Data Engineer to join the Audience Intelligence team. Based in Sydney and reporting to the Head of Data Enablement, you’ll be responsible for:
Implementation of end to end data solutions to support Data Strategy for the SWM group.
Work closely with the Data Solution Designers to develop and maintain scalable data pipelines and build out new file and API based integrations to address requirements from the various business stakeholders.
Collaborates with engineering, analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organisation.
Work on Data Preparation for analytics and data scientist team members and assist them from an engineering perspective in building and optimising the models including building the automation of the end to end workflows
Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.
Perform data analysis required to troubleshoot data related issues and assist in the resolution of production data issues.
Work effectively with vendors for successful delivery of projects and acceptance of the solution
Work on Delivery projects using Agile Software Development methodologies
We are looking for someone who has:
Bachelor's degree in computer science, computer engineering or other technical discipline is essential
Proven experience working as a digital analytics specialist
Extensive experience with digital analytics implementation (e.g. Google Analytics, Snowplow, Adobe Analytics) and BI processes and visualisation platforms
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience in ETL and building and optimizing ‘big data’ pipelines and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Experience with big data tools: Hadoop, Spark, etc., AWS cloud services: EC2, S3, Lambda and familiar with version control systems: Git
Strong coding skills with knowledge of Unix/Linux and scripting languages such as Unix Shell scripting, Python desirable
Experience supporting and working with cross-functional teams in a fast-paced environment.
Ability to multi-task and problem solve with changing demands and priorities
Ability to work under pressure to meet deadlines and detail oriented
Your success is our success: we will provide you with opportunities for you to keep learning and growing, enabling you to challenge and develop yourself. In return, we offer a benefits program that has something in it for everyone.
Seven West Media is an equal opportunity employer and we are committed to creating a diverse and inclusive workplace.
Recruitment Agencies: Seven West Media does not accept any unsolicited agency resumes and will not be responsible for any fees related to unsolicited resumes.
Advertised: 19 Oct 2020 12:00 AM AUS Eastern Daylight Time
Applications close:

Back to search results",2.5,"Seven West Media
2.5",Sydney,-1,5001 to 10000 Employees,1956,Company - Public,TV Broadcast & Cable Networks,Media,Unknown / Non-Applicable,-1
BICON Rules Engineer,-1,"APS 5 - $73,299 - $80,410 per annum plus superannuation
Biosecurity Plant Division
Canberra, ACT
Play an active role in managing biosecurity risk to Australia
Work in a motivated and professional team with a wide range of skills and backgrounds
Full training provided

Who we are
The BICON Content Development Team maintains and improves the Biosecurity Import CONditions database (BICON) content to allow external clients to understand and comply with their biosecurity obligations and internal clients to effectively manage biosecurity risk and regulate imports. We work collaboratively with internal clients to comprehend and implement their BICON content requirements and optimise the use of BICON to publish clear import requirements and onshore management support procedures to effectively manage biosecurity risk.

The Jobs
Key duties of these positions include:

working with business content (import and permit conditions) and import programs to understand and construct decision tree structures in the BICON database, in accordance with system design and authoring conventions
executing changes to import and permit conditions in alignment with service standards while complying with system rules and authoring conventions
providing technical advice through various formats on the most appropriate means of authoring BICON content to achieve import program and stakeholder objectives
using workflow management tools to maintain detailed records of changes to import conditions and key decisions
performing administrative tasks including system reporting, data analysis and scoping tasks for the BICON content change work program
contributing to the development and maintenance of instructional material, authoring conventions and courseware
clearly documenting and reporting system issues
developing and maintaining effective working relationships with internal and external stakeholders.

What we are looking for
Knowledge and experience
Experience working with complex IT systems.
Experience working collaboratively and as part of a team.
Knowledge of the role of biosecurity is preferred but not essential.

For additional information, please read the Job Description below.
Candidate Information Package docx Opens in new window",3.9,"Department of Agriculture & Water Resources
3.9",Australia,-1,5001 to 10000 Employees,-1,Government,Federal Agencies,Government,$500 million to $1 billion (USD),-1
Cloud Data Engineer,-1,"Job no: 509605
Work type: Permanent Full Time
Location: Melbourne, Canberra, Sydney
Do you embrace digital disruption?
Do you love solving complex problems, designing sophisticated solutions and building innovative technology?
Do you believe in creating powerful actionable insights from Data and Analytics?
Do you want to work in a diverse and flexible working environment?
KPMG is one of the most trusted and respected global professional services firms. Through depth of expertise, clarity of insight and strength of purpose we help our clients solve complex challenges, steer change, strengthen, transition and grow. We are a team based practice and this extends to our clients whom we work and collaborate with, in solving complex problems. Together, we design, innovate and implement, providing enduring advice that support our clients and the services they deliver. Our clients vary in size and come from a diverse range of sectors – all sharing in a common goal: to embrace change and deliver services that make Australia a better place. We are looking for talented individuals who would like to join us on the journey.
KPMG’s Digital Delta Team
We re-imagine and re-invent organisations to become world class digital enterprises using advanced technologies, data and human insights. We help organisations to embrace Digital Strategy, Artificial Intelligence (AI) & Cognitive, the Internet of Things (IoT), Data, Analytics & Modelling, Mobile App & Web, and User Experience (UX) & User Interface (UI) and more.
We work with clients to:
Formulate strategies that re-imagine organisations
Harness innovation from the 4th industrial revolution
Actioning insights from trusted data to consistently and quickly make clear decisions
Build adaptive organisations
Thrive as a connected enterprise – front, middle and back office
This is how you’ll contribute:
We are looking for ambitious Data Engineers who are passionate about helping clients define bold ambitions and deliver on them. Joining our team will take you on a journey of personal and technical growth and provide the opportunity to inspire confidence and empower change.
As a Data Engineer you are the designer, builder and manager of the information or ""big data"" infrastructure, preparing data for analytical or operational use. You will design, construct, test and maintain a data pipeline to pull together information from different source systems; integrating, consolidating and cleansing data; and structure it for use in individual analytics applications.
The KPMG Difference
Our people are focused on creating a diverse and dynamic environment that embraces and values differences. We value the variety of unique experiences, qualities and characteristics our people possess and we share and learn from each other.
We are proud to be consistently recognised as an employer of choice for women, and for our achievements in LGBT+ workplace inclusion.
Our commitment to ‘Flexibility’ allows our people to manage the changing demands of work, personal or family life. Explore the links below to hear our people share their experience @ KPMG:
Flexibility empowers wellbeing
Flexibility enables contribution to the community
Flexibility inspires technology & innovation
Flexibility supports family

Make KPMG the clear choice for your career and be Extraordinary!

Advertised: 09 Sep 2020 AUS Eastern Standard Time
Applications close:",3.8,"KPMG
3.8",Sydney,-1,10000+ Employees,1987,Subsidiary or Business Segment,Accounting,Accounting & Legal,$2 to $5 billion (USD),-1
Computer Network and Systems Engineer,-1,"Duties Include but are not limited to:
Tasks Include:
analysing, developing, interpreting and evaluating complex system design and architecture specifications, data models and diagrams in the development, configuration and integration of computer systems
researching, analysing, evaluating and monitoring network infrastructure to ensure networks are configured to operate at optimal performance
assessing and recommending improvements to network operations and integrated hardware, software, communications and operating systems
providing specialist skills in supporting and troubleshooting network problems and emergencies
installing, configuring, testing, maintaining and administering new and upgraded networks, software database applications, servers and workstations
providing network programming in support of specific business needs and requirements
preparing and maintaining procedures and documentation for network inventory, and recording diagnosis and resolution of network faults, enhancements and modifications to networks, and maintenance instructions
monitoring network traffic, and activity, capacity and usage to ensure continued integrity and optimal network performance
Skills and Experience Required:
Must have experience working in a Managed Service environment
Demonstrated experience in IT Networks and Data Centres
Understanding of systems and architectures to meet client needs
Experience in Help Desk including break / fix
Effective and timely documentation
Effective Task Management Skills
Be solution and outcome focused and willing to learn new technologies
Excellent communication skills with staff, clients and partners
Time management, ability to prioritise and deliver to schedule
Experience with N-Able and Connectwise desired
Open Cabling license desired
Job Types: Full-time, Permanent
Salary: $30.00 per hour
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,Trans-plant training,Canberra,-1,-1,-1,-1,-1,-1,-1,-1
Software Engineer (Data),-1,"If you are looking for an opportunity to make a real impact with smart people who are genuinely doing things differently then you've come to the right place! We're growing our data engineering capabilities and are looking for awesome data engineers to join our team.
With our diverse range of clients and projects, no day will look the same - but here's a great snapshot of what you'll be doing:
Work with some of the best Data Scientists and Engineers to deliver production-grade AI and Machine Learning systems as we deliver client projects from inception to production.
Consulting with our clients and working with them to build modern data systems using the 'best of' technologies and principles.
Advising clients on data strategy, architecture and technology.
Applying best software engineering practices in coding, monitoring and alerting, using CI/CD, TDD and cloud architectures.
Working over a wide range of big data tools and environments: not limited to; Apache Kafka, Spark, Python, Scala, Hive, Airflow, AWS EMR & Glue, GCP Dataproc & Dataflow, BigQuery, Snowflake, Redshift.
Who are we?
Glad you asked! We are Eliiza. Data science. Engineered for scale.
We are a passionate team of data scientists and engineers who apply data science and machine learning to solve real-world problems. Our mission is to create a bright future for Australian businesses and society in a world increasingly influenced by intelligent technologies.
We've created a culture that values diversity where people can truly be themselves! We care a lot about growing the Australian AI community in a positive direction, and we're doing several things to try and achieve that:
We provide opportunities for underrepresented groups to work in AI through our associate and intern programmes
We organise and participate in a range of community events, reading groups and meetups
We produce the AI Australia podcast
We blog about topics we care about
We stream brown bag sessions to the broader community
We're also part of Mantel Group's 'house of brands' which means it's not just the Eliiza team you'll work with, learn from and see at social events - there's another 230 of us across DigIO, Kasna & CMD Solutions!
So you're ready for something new?
We're keen to know more about you! Our team is made up of a range of people, with different experience across a huge range of data driven skill sets.
We'd love to hear from you if you have experience with:
one (or more) core language(s), ideally Scala, Python or Java
one (or more) cloud platforms, AWS, GCP, Azure
ETL/ELT concepts and technologies e.g. Data partitioning, Hive, Spark
streaming data concepts and technologies, ideally Kafka (Kinesis, Beam or Pubsub will do)
We'd be over the moon if you:
Experience with distributed/columnar databases (e.g. Snowflake, Big query, Redshift).
Experience with any of a variety of databases e.g. RDMS, NoSql, Columar, Distributed, Time series, Graph.
Knowledge of job orchestration and scheduling. Any experience with Airflow, Luigi or Oozie.
Experience with containers and container orchestration (Docker, Docker Compose or Kubernetes).
However, we value a diversity of skill-sets, and don't necessarily require that you're skilled with all of the above. If you feel you don't fit all the experience/skills listed above we still encourage you to apply or get in touch.
What's on offer if you join us?
We make sure you're always one step ahead by investing your learning and development, every year. We build our own training where it doesn't exist yet.
We hire smart people and get out of their way. By focusing on our five principles and not getting caught up in red tape, we trust you to get the job done.
You'll get all the tools you need - a new iPhone or Google phone, a new Macbook Pro or Dell, and a lot of branded swag!
But hold on, you mentioned a house of brands?
We certainly did! Mantel Group is an Australian-owned, 'house of brands' company with four technology businesses (Eliiza being one of them!) across Melbourne and Sydney. We're building a group of companies with open borders so we can support you to take on new skills without leaving an awesome team - we understand you won't have one job for life!
We may only be just two years old but Mantel Group has already been recognised #9 in the 2020 Best Places to Work in Australia and #4 in the AFR's 2020 fastest growing new companies.
Keen to chat?
Click ""Apply"" to share your details with our talent team, and we'll be in touch.
In the meantime, check out 'how we hire' to find out what's in store if you're successful and get to know us better by visiting our website and following Eliiza on LinkedIn.",-1,Eliiza,Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Infrastructure Engineer,-1,"Job Description:
Design and grow the Shopee data platform to support a variety of big data applications using open-source technologies including Kafka, Hadoop, Presto, HBase, Spark, Hive, Druid, and our own creations. Some examples include a real-time data streaming platform, a unified query platform, a cluster management system, and a machine learning platform
Dig into the source code of some open-source big data system to get the whole control and familiar with the details, configurations, designs and source code. Develop and maintain the internal release of big data systems and components as the business requirements.
Keep close and overall monitoring for all the deployments of the systems, maintain the system’s stability, improve the performance, discover the performance bottlenecks, tracking and troubleshooting, cost optimisation.
Requirements:
B. Sci. / Ms / PhD in Computer Science or a related technical field
Familiar with at least one of these languages: Java, Scala, Python, Bash under Linux / Unix. Scala is a plus
Familiar with the use and compute logical of SQL
Knowledge about the Big Data Infrastructure system technology like Distributed File System, Distributed Computing, Distributed Database will be a plus
Hands-on experiences Hadoop, Spark, Kafka, and/or Presto will be a plus
Love to use and develop open-source technologies
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"Work on an award-winning, international technology!
Endless career opportunities
An innovative, friendly team of 300+
This role will be focused on the development of our existing ClaimLogik line of products as well as working on our new cloud-first, modern suite of applications.

Intelligent Thought, our technology business is scaling and shipping our software globally. Already profitable, part of a much larger group business, with investors such as Macquarie Capital and Envest – we are all set to deliver textbook disruption to the Insurance Industry. The growth of the platform, of our customer base, and the increasing industry demand have led to the need for this role to help the team scale.

Our Philosophy
Give each employee a sense of purpose and an environment for them to connect the importance of their role to delivering a service that matters to our customers.
Challenge the ‘why’ of traditional claims processes.
Keep it simple – do only what brings value and what matters to the customer
Enable employee decisions, empower our people
Responsibilities:
Create, extend and maintain ETL pipelines to form our data lake, data warehouse and analytics platform (currently using the Microsoft Azure set of tools and service)
Help define the optimal data pipeline architecture
Influence the tool selection, platform selection, data architecture and strategy which will transform the business to be truly data-driven
Understand, analyse and size user requirements
Work with different parts of the business to provide them with the insights they need to deliver the best results
Skills & experience:
Degree or qualification in computer science or related
Advanced knowledge of relational database, including query authoring and query optimisation (MS SQL Server and PostgreSQL).
Experience building and optimising ETL pipelines
Experience designing complex data models
Experience working with cloud platforms (Azure or AWS)
Efficient time management and organisational skills
High attention to detail and accuracy
Effective communication skills to build strong working relationships; both written and verbal
Proactive and results-driven
Why Claim Central?
Claim Central Consolidated is a global insurance industry leader across, claims management, insurance technology and data and analytics. Currently operating in the United States, Australia, South Africa, Italy and New Zealand, we have pioneered digitally connected claims management services across the globe. Claim Central is a disruptor and thought leader in the industry and we were recognised as the Australian Financial Review’s 8th Most Innovative Company in Australia in 2016. This business is in a period of unprecedented growth, transitioning our technology and services into multiple geographies at a rapid pace. Our unique culture is based on teamwork, collaboration, trust, respect and performance. We also offer many benefits apart from our exceptional team culture; including flexible work arrangements, and continued professional development.

Be a part of this journey in a career-defining role.",-1,Claim Central,Matraville,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer - AI/ML,-1,"Our client provides services to a major industry across the country. The business is still early in it's days of technology development and the environment is greenfields in nature (no pun intended), effectively working like a start-up.

Their data and analytics team have worked and built leading and bleeding-edge technologies in this space and what they have created so far may be game-changing. From a machine learning perspective, the progress they have made to the business has already seen proven success in changing the future of an industry that will have positive consequences for all those involved.

You will have previously worked in a technical capacity in the data and analytics space and have experience working with an organisation where machine learning has been implemented, not just a concept that the business talks about having or the technology team would love to have. The commercial experience you will have had in the ML field will be proven examples of where you have affected the way a business or industry used to perform, to the changes that have come about from this.

Technically, you will have extensive experience in the Microsoft space - Power BI, Azure etc and you will have previously mentored and coached junior members of the teams you have been part of.

This is a rare opportunity in Brisbane where the business has truly embraced and funded projects across the ML space and would be a great chance for those in the Data Development/Data Engineering field, who are looking to move into a Data Scientist role in the future.

Please send your application through if you would like to know more.",4.0,"Emanate Technology
4.0",Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Solution designer/ ETL Engineer & Data Modeller,-1,"We are looking for a Qualified and Experienced Solution Designer to join our client for a period of 6 months with a view to extend.
You will work closely with team members and your contribution will range across gathering and analyzing information, developing and documenting improved processes and work instructions and experienced DWH Lead with skills in requirement analysis, solution designing, developing, testing and supporting ETL solutions.
A hands-on solution designer, data modeler and ETL developer for Data Warehousing and ETL application transformation projects using Informatica PowerCenter.
Knowledge on AWS, S3, Redshift, Informatica BDM, and related technologies.
Experience working with IPython, PySparks, AuCuMo, Airflow, Jenkins, Github, Athena, JIRA, Rally, Spectrum, Glue, Flyway.
Good exposure on Oracle PL/SQL, aware of DBA activities, writing and performance tuning of complex SQL queries.
Contract length: 6 months
Job Types: Full-time, Contract
Salary: $650.00 – $800.00 per day
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,nducive,Melbourne,-1,-1,-1,-1,-1,-1,-1,-1
"Data Engineer, Wollongong NSW or Mount Waverley VIC",-1,"Company Description
BlueScope is a technically advanced supplier of steel and steel products in Australia. We are an inclusive organisation and every day we showcase our technology and expertise throughout the world.

Job Description
We are looking for two Data Engineers to join our IT team, based in Wollongong NSW or Mount Waverley VIC. Use your experience in analytics to unlock business value, enabling use of big data for insights and decision-making.
Reporting to the Data Product Owner for our Australian Steel Products (ASP) business, this position will support strategic goals related to data. This will see you:
Gather business and technical requirements with the view to deliver outcomes;
Develop and implement end-to-end data collection, consolidation, modelling and visualisation solutions;
Document metadata in a dictionary and catalogue;
Ensure consumers of such information understand its accuracy, timeliness, quality and sensitivity, so that it is used appropriately; and
Identify opportunities to enhance analytics.
What are the benefits?
Work in a supportive and collaborative team environment whilst we embark on a journey to transform the way our business uses data!
Our systems landscape is broad and diverse. You will be encouraged to think creatively to develop data solutions which solve real business problems.
Working in this role you will enjoy:
the chance to learn more about data science;
salaried remuneration with attractive superannuation options;
the opportunity to participate in a performance incentive scheme; and
access to further development and career opportunities with BlueScope.
Who are we looking for?
We welcome applications from professionals with experience in data analytics and/or programming. Supported by your knowledge of project delivery methods (e.g. Agile), you will demonstrate:
experience with data mining, wrangling, mapping and visualisation techniques (e.g. Azure Data Factory, Databricks and/or DevOps etc.);
well-developed ability in gathering business and technical requirements;
skills in developing and implementing collection, consolidation, modelling and visualisation solutions; and
a passion for sharing your knowledge and desire for ongoing professional development.

Qualifications

null

Additional Information
We're proud to have been named an Inclusive Employer for 2019–2020 by the Diversity Council of Australia. We believe that our people are our strength. Having a diverse and inclusive workplace enables us to improve our capability and ensure continued, sustainable success.
We know that workplace flexibility can mean something different to everyone. Under our B-Flex initiative all of our roles have some degree of flexibility. We encourage you to discuss your needs with us.
Applications close Sunday 25th October 2020.",3.3,"BlueScope
3.3",Wollongong,-1,201 to 500 Employees,-1,Company - Private,Construction,"Construction, Repair & Maintenance",$100 to $500 million (USD),-1
ETL Data Engineer,-1,"ETL Data Engineer

Join a team that’s changing how Australia lives, works, plays and grows
We want you to be the best version of you

Work with innovative teams and explore new technologies to help solve real-world problems.

A typical day as a Data Engineer

ETL / Big Data Engineering professionals will be responsible for guiding the full lifecycle of a Data solution, including:
Working in highly client-facing roles to contribute throughout the end-to-end delivery lifecycle of complex and large-scale digital solutions
Use case and business case development
Support existing and new applications utilizing in-depth technical and data knowledge. Troubleshooting complex issues and providing advisory services to improve the client’s data landscape
Help to streamline and simplify the clients’ complex data landscape by integrating different applications and data architectures
Implementation from requirements analysis, platform selection, digital architecture design, application design and development, testing, and deployment
Interstate travel may be required

Basic qualifications:
Bachelor’s degree
Experience across systems integration, information management, data management and architecture, and business analytics
Experience with being in a team focusing on large-scale, multi-release information centric projects
Experience with waterfall and agile delivery and run / application support functions
Part of a team working on End to end implementation of at least 1 big data project

Preferred Skills:
Hand on experience in Data warehousing using ETL tools such as DataStage, Autosys and TeraData
Hands on experience in ETL job development with multiple stages like sequential file, Transformer, Lookup, join, sort and Database stages.
Strong hand on skills in design, development and implementation of various data remediation, Data migration, data integration techniques.
Strong hand on data modelling experience.
Strong hands on experience in database performance tuning including complex query optimizations and physical database tuning using Teradata.
Understanding of architectural designs and strategy related to data migration, data cleansing, data quality and data consolidation.
Proven data analysis, requirement gathering and problem-solving skills
Exposure to Unix environment and shell scripting.
Experience in Banking and Financial services industry
Desirable: Knowledge of cloud computing infrastructure (e.g. Amazon Web Services EC2, Google Cloud, Microsoft Azure)
About Accenture

Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. We combine unmatched experience and specialized capabilities across more than 40 industries — powered by the world’s largest network of Advanced Technology and Intelligent Operations centers. With 513,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises. Visit us at www.accenture.com.

Accenture is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, marital, domestic or civil partnership status, sexual orientation, gender identity, or any other basis as protected by applicable law.

Vera Goga is the Recruiter managing this role. As the team experience high volumes of applications, we appreciate your patience to allow for a fair and timely process.",3.9,"Accenture
3.9",Sydney,-1,10000+ Employees,1989,Company - Public,Consulting,Business Services,$10+ billion (USD),-1
Student Engineer,-1,"The candidate will have the ability to:
Undertake onsite inspection to collect asset condition data based on the relevant engineering standards and technical guidelines;
Undertake desktop analysis to evaluate the condition and performance of the assets;
Provide the appropriate information, advice, engineering input and support services for the sustainable management of Council’s stormwater and transport networks.
Qualifications:
The successful candidate will be enrolled in a Bachelor of Engineering with a minimum of two years completed.
Position Number: 100678
Position Hours: Fixed term (3 months), hours will be negotiated with the successful candidate, maximum of 75 hours per fortnight.
Salary: Schedule A, Salary Point 4.0. $28.64 per hour ($55,853.45 per annum, pro-rata) in accordance with Glenorchy City Council’s Enterprise Agreement 2016
Please note that all successful applicants will be required to provide a current National Police Check prior to commencement of employment.
For further information on this position, contact Patrick Marshall, Senior Civil Engineer on (03) 6216 6800.
How to apply: Applications for this position must be lodged on this submission site or on the Glenorchy City Council website www.gcc.tas.gov.au - Careers page.
To be considered for this role, all applicants must address the key selection criteria in the and provide a current resume. A copy of the position description can be found by clicking the below hyperlink or on the Glenorchy City Council website.
Applications close at 8pm on Sunday, 1st November 2020
- Student Engineer",4.0,"Glenorchy City Council
4.0",Glenorchy,-1,501 to 1000 Employees,-1,Government,-1,-1,Less than $1 million (USD),-1
Data Engineer involving DevOps,-1,"Data Engineer involving DevOps
Axiom Technologies is an Australia based entity with the history of providing Managed IT solutions to medium to large scale enterprises globally. Please visit our website for more information about what we do at www.axiomtechnologies.com
Axiom Technologies is an Equal Opportunity Employer and encourage applicants from all backgrounds and gender to apply, including, Aboriginal and Torres Strait Islander candidates
Job Requirements:
8+ years IT experience, with at least 5+ years of “Data Engineer/Deveoper” focused titles/roles,
Data Tools: Hands on experience with Apache Beam.
Testing: Hands on experience with automated testing activities/outcomes
DevOps: Experience with the processes involving Microservices facilities for artifacts developed
Platform/OS: Mid-range/Unix
Languages: Unix (Shell) Scripting/commands, SQL, Python
File formats: Text, CSV, Parquet, JSON, XML
Scheduling: Jenkins, Airflow
Auto Scripting: Designing/creation of scripts for repetitive activity. E.g. Unix scripting/SQL
Big data: Exposure to Data Lake Concepts, Hive (Schema), HDFS
Source Control tools: GIT
Delivery Models: Agile, Scrum
Ingestion Design: Create/assess Source/Target data mapping designs
Frameworks: Development and delivery frameworks
Activity Reporting/Repository: Jira, Confluence.
Quality: Accuracy and attention to detail
Industry: Financial Services/Banking
Solutions: Define solutions from High level to detail design to address automating ingestion activity. Facilitate/confirm requirements from product owners, business team members and technical associates,
Process Automation: Automating processes in file management, testing data in files, analysis and design, configuration management.
Script Automation: Ability to design/create scripts to automate/improve data copy/migration/ETL for any repetitive activity.
Languages: Java, Python
Scheduling: Control-M
Databases: Relational. E.g. POSTGRESS, Oracle – as a ETL developer
File Formats: Mainframe – experience with referencing its data formats/copybooks
Big data: Experience referencing/using Hive (Schema) to access data in HDFS
Metadata management tools: MDM, EDC and Axon
Performance: Assess, recommend, improve mappings, SQL queries, Batch feeds
Automation Tools: Other tools that may add value to an automation program and generally support development. E.g. API, REST, JDBC, Webservices, Message Queues/Load balancer,
Cloud: Experience with processing of data files to be ingested/stored in the Cloud, preferably with AWS.
Prod Support: Experience in a production support role performing root cause / impact analysis – under time constraints
Experience in a similar role
8+ Years
What next?
If you are looking for that next challenge in your career and wish to apply for this role, please forward your resume to careers.au@axiomtechnologies.com",2.0,"Axiom Technologies
2.0",Melbourne,-1,1 to 50 Employees,-1,Company - Private,Industrial Manufacturing,Manufacturing,Less than $1 million (USD),-1
Data Engineer,-1,"About the Role
We are on an exciting digital journey so it’s a great time to join ME! We are seeking a Junior Data Engineer who enjoys rolling up their sleeves, learning and growing. As part of our Enterprise Data Team, you will ensure fit for purpose data warehouse solutions are built for use across the bank and by utilising best practise ETL standards, whilst ensuring the data is trusted by our BI developers and key business consumers. Oh, and you’ll get to work on Microsoft technology stack too!
You will be involved with investigating data issues, keeping data feeds flowing and collaborating with different projects across the bank to deliver quality data solutions. How important does that sound? What’s even more important is this role contributes directly to our overall business strategy through the provision of data to enable analytics & reporting, as well as supporting business and decision system processes.

About You
You’re naturally a highly motivated and energetic person who thrives in a dynamic, ever-changing collaborative team environment. Ideally you have previous experience as an ETL developer, Data Engineer or a BI developer, and if you have a degree in computer science or similar it would really put you ahead of the rest.

With your knowledge of SQL coding, data modelling, understanding of data warehouse concepts, plus experience of working on complex ETL solutions, you’re ready to expand your horizons and launch your career into the world of IT at ME.

About ME
We’re not like other banks.
ME was created by the industry super funds to be different from the pack – with a core purpose to help all Australians get ahead financially – no conditions, asterisks or exceptions. And we know that looking after customers starts with taking care of our people.
We believe everyone deserves the same opportunities in life, regardless of gender or identity, sexuality, ethnicity, religion or disability ‒ with internal affinity groups.
Perk ME up
Once you get your feet in the door at ME, we’ll put them both in your very own ME-branded Converse shoes. You’ll also get the following financial, health and fun perks when you join the team:
4U Extras portal (discounts and cashback on 100s of items including cinemas, shopping and gym memberships
10% Myki discount
Purchased Leave programme
Internal wellness programme (Mindfully ME)
Professional education through LinkedIn Learning
Novated Leasing
Professional membership reimbursements
Health checks
Financial education (To help you manage your money smarter)
LGBTIQ+ and Women at ME affinity groups

I want those Converse shoes (and the role)
Can’t see a closing date on the advert? That’s because we’re pretty efficient here at ME and we may start looking at applications sooner rather than later, so if this role sounds like your jam, be sure to apply by submitting your resume today.

Should an applicant be the preferred candidate, background checks (including police checks, reference checks, ASIC banned and disqualified persons and bankruptcy checks) will be completed prior to the candidate's employment being confirmed. The outcomes of the background checks do not automatically bar candidates; however will be assessed against the inherent requirements of the job.
Back Share
Apply Now",3.0,"ME Bank
3.0",Melbourne,-1,501 to 1000 Employees,-1,Company - Private,Banks & Credit Unions,Finance,$100 to $500 million (USD),-1
Software Engineer - Machine Learning/Data Science,-1,"Zendesk is looking for a Software Engineer - Machine Learning/Data Science for a full time position in our Melbourne office.
As part of our engineering team, you will work at a scale where the challenges start to get seriously interesting. Our global engineering team is widely dispersed over the world, with people across nearly every continent. You will get a chance to do cool things with a diverse bunch of people while working in the Melbourne office that is home to Zendesk’s first machine learning (ML) research team.
The Data Science Team, together with Data Engineering, have built Satisfaction Prediction, Answer Bot and Content Cues — products that use Machine Learning (ML) and Artificial Intelligence (AI) to help our customers work more efficiently.
What you get to do every day:
We’re currently looking for someone to join our team as we research, develop, and productionise Machine Learning and Deep Learning models. In addition to frequenting Melbourne’s finest purveyors of coffee, ramen, and bulgogi, you may find yourself:
Building machine learning models including neural networks in TensorFlow
Writing and deploying production-grade Python
Querying and constructing datasets in AWS Athena, Spark
Evaluating and responding to real-world model performance
Scaling your ML to millions of predictions per day
Presenting your work to a broader audience
Watching your algorithm help Zendesk’s end-users
What you'll bring to the role:
A strong foundation in a quantitative discipline (e.g. machine learning, statistics, bio/eco/etc-informatics, econometrics, etc) is critical for this position. While experience in deep learning and natural language processing would be beneficial, your best qualities are:
dedication to continuous learning
collaborative work attitude
strong communication skills
You should also be comfortable with at least one programming language, such as Python, R or Scala.
Application Deadline: 18/11/2020
Job Types: Full-time, Permanent
Salary: $85,000.00 – $110,000.00 per year
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Temporarily due to COVID-19",4.5,"Zendesk
4.5",Melbourne,-1,1001 to 5000 Employees,2007,Company - Public,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),-1
Software Engineer (Machine Learning),-1,"About the Role
AdelaideMRI is building a medical reporting tool. We require an engineer to work primarily on machine learning projects to improve reporting speed and report comprehensiveness.
You will perform data analysis of medical report datasets and image datasets to infer sentence recommendations, image classifications, or other actionable results for the doctors.
Skills and Experience
Background in machine learning or image processing
Qualifications in Computer Science, Software Development or Engineering or equivalent experience
Bonus points for Python
No prior medical knowledge is required.
This position offers flexible hours and work arrangements.
Job Type: Full-time
Experience:
Software Engineering: 1 year (Preferred)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Yes",-1,Adelaide MRI,Australia,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Hey there, we’re PEXA!

We started as an idea: to deliver a single, national e-Conveyancing solution. We collaborated with the industry to create a national electronic lodgement and settlement platform: PEXA. From our humble beginnings, we’ve now grown to more than 320 employees across 5 different states. We’re still expanding at a rapid rate and constantly challenging ourselves to create great experiences for our members as they transition to fully digital conveyancing.

Why become a PEXArian?

Great question! Being a PEXArian is so much more than just a job. We are passionate, motivated & unashamedly enthusiastic at PEXA - we love what we do and we’re proud to admit it! Creating brilliant member experiences wouldn’t be possible if we didn’t also strive to create an amazing employee experience. Alongside our members, our employees are at the heart of everything we do.
Here’s a snapshot of what your life at PEXA could look like:

Your growth:
We encourage you to hit your personal and professional Learning & Development goals with our tailored programs and tools.

Your wellness:
We care about your holistic well being - a fully stocked kitchen, four wellness days, a $250 wellness subsidy as well as lunch and learn sessions to support your financial well being.

Your work/life blend:
We know that work is just one aspect of your life, we want to help you create your ideal work/life blend, rather than squeezing in life around work.

Your family:
With a range of benefits aimed at supporting your family including access to a subsidised school holiday program, extended parental leave and flexi-time to support your return to work, superannuation payments for unpaid parental leave for primary carers and a childcare allowance for pre-primary aged children, when we say, ‘welcome to the family’, we really mean it!
The impact you'd drive:
The successful candidate will be responsible for developing, and maintaining infrastructure to support the delivery of new and existing products. They will also be contributing to establish the rules and frameworks for obtaining the required approvals for new products.
On day one we’d love you to have:
Experience with Python, Spark
Event streaming/sourcing with Kafka or AWS Kinesis
Experience with data structures, formats and data security best practices
AWS experience (e.g CloudFormation, S3, ECS, Lambda, SQS, IAM, KMS, DynamoDB, Glue, Athena)
Query construction and optimisation (e.g. SQL, Elasticsearch, Splunk, DynamoDB)
Git, version control practices, and continuous integration/delivery servers
PyUnit and unit testing frameworks
Production release cycles and maintenance
Collaborating with technical and non-technical teams
Even better:
Agile methodology/delivery
GraphQL
Modern frontend technology (e.g. ReactJS, TypeScript)
Machine learning frameworks and tools (e.g. TensorFlow, PyTorch)
OAuth 2, SAML 2, JWT
Data visualisation and exploration tools (e.g. Jupyter notebooks, Tableau)
AWS SageMaker
Sounds like you?
If this role sounds like you, apply today to have your application reviewed ASAP!",3.9,"Property Exchange Australia Limited
3.9",Melbourne,-1,201 to 500 Employees,2010,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Ongoing position
Full time
Based in Sydney, NSW
Who we are
Australian Red Cross is part of the world’s largest humanitarian organisation. Our aim is to improve the lives of the most vulnerable people in Australia and across our region.
About the role
The Data Engineer role will sit within the Data and Integration Squad in IT and will own (design, implement and support) the AWS Big Data technologies such as the Data Lake and Data Warehouse and support the organisation in growing the data analytics capabilities at Red Cross. In addition to this, the data engineer role will also administer the Power BI tool and support the implementation of the data mastering capability.
What you will bring
Experience building and optimizing data pipelines, architectures and data sets.
Experience in dimensional modelling and building data vaults
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with structured, semi-structured and unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Why work for us?
Work for purpose and know that your work assists Red Cross support and empower people and communities in times of vulnerability.
Generous salary packaging options available that can increase your take home pay.
Further information
To find out more about this opportunity please see the position description below or contact Sharath Kumar Gurram on 02 8651 8839.
Position Description: Position Description - Data Engineer .pdf
Applications for this position will close at 11:55pm Thursday, 5 November 2020.",4.1,"Australian Red Cross
4.1",New South Wales,-1,1001 to 5000 Employees,-1,Nonprofit Organization,Industrial Manufacturing,Manufacturing,$500 million to $1 billion (USD),-1
Junior Fullstack Data Engineer (Python and React),-1,"Formbay is the leading Renewable Energy Certificate Trading company in Sydney. We provide Digital Workflow and Compliance solutions in the renewable energy industry and document processing.
Thanks to our meteoric growth and our commitment to be the best at all we do, we've identified the need to bring on board a new Junior Fullstack Data Engineer.
Reporting to our Principal Machine Learning Engineer, you will help build Machine Learning pipelines for our existing Digital Workflow and Compliance solutions to automate fraud detection and document processing over terabytes of photographic and documentary data – including documents, photos, GPS data and aerial/satellite photography.
Our stack is based on Python, JavaScript, Dask, Tensorflow, CUDA, Nix/NixOS, AWS, Docker, PostgreSQL and more – familiarity with these applications will give you a leg-up on the competition.
Our ideal candidate will have the following competencies:
SQL
Python
JavaScript/TypeScript
Our candidate must also be comfortable working with Linux.
Located a stone's throw away from the Queen Victoria Building in Sydney's bustling CBD, we are centrally-located with easy access to public transportation, bars, cafes and fine dining.
Formbay will provide flexible working hours, a generous remuneration package and the opportunity to work on a world-first software solution are what we can offer you. Free, twice-weekly gym sessions and really, really good coffee are also available.
No hiring/recruitment agencies need apply.",5.0,"Formbay
5.0",Sydney,-1,1 to 50 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is an experienced and qualified Data Engineer to join our IT team based in Birtinya.
Key Responsibilities:
Create and maintain data pipelines and or ETL scripts
Create and maintain data integration including API and Batch interfaces
Performed detailed data analysis
Create and maintain corporate data models
Create and maintain data visualization using Qlik.Sense , PowerBI or Simliar Toolset
Experience in defining, building and maintaining data virtualization and/or star schema data warehouses
Maintain, tune and optimise database, integration and visualisation toolsets
ABOUT YOU:
To succeed in this role, you’ll need to bring the following experience and skills:
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Excellent communication skills both oral and written, with an ability to bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking
Experience with data analysis and modelling will be beneficial

How to Apply
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kawana Waters,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Graduate Data Science / Engineer,-1,"The NRMA is an organisation looking to the future, and right now, we are on the lookout for people who can help us reach our goal: to continue to shape the way Australians move, for the next 100 years and beyond. www.mynrma.com.au.
Everyone new to the team, along with our current staff, will temporarily work from home until it is safe to return to our offices. All interviewing and on boarding will be done virtually due to COVID-19.


Your opportunity
As Graduate Data Scientist or Engineer you will be part of the Data Engineering team delivering cloud data transition program for business initiatives and supporting the entire data platform build.
Your key responsibilities will be to:
Implementing Concepts of Data Warehousing, Data Mart creations within Cloud
Use of SQL for data analysis and insights
Building AI/Machine Learning prototype for implementing and supporting existing algorithms
Data Analytical reports build, using different tool sets


Requirements for Success:
Relevant Degree - Computer Science, Computer Engineering, Software Engineering, Data Science
Excellent SQL skills and demonstrated working knowledge in Python
Demonstrated understanding in data structure and algorithms.
Knowledge and concept of data warehousing methodologies
Any reporting tools experience Tableau or Oracle Analytics Cloud, Looker is desirable
Exposure to Google/AWS/Azure/Oracle any cloud based platforms is desirable
Good communication and interpersonal skills

If you have the required skills and the passion to join our high performing team, please apply today.

Employee Benefits
To ensure our employees feel valued, empowered and celebrated we provide a range of employee benefits including:
50% discount on all NRMA insurances
Free Roadside Assistance
12 weeks paid primary and 4 weeks paid secondary parental leave
Free NRMA Blue Membership
At the NRMA Group, we are People Moving People and diversity and inclusion are part of our DNA. Together, we continue to build an inclusive culture that encourages, supports and celebrates the diverse voices of our employees. It fuels our innovation, promotes flexible ways of working and connects us closer to our members and the communities we serve.",2.5,"NRMA Motoring & Services
2.5",Sydney,-1,501 to 1000 Employees,-1,Nonprofit Organization,Casual Restaurants,"Restaurants, Bars & Food Services",$500 million to $1 billion (USD),-1
Data Centre Engineer,-1,"We are a leading world group that provides low-carbon energy and services. To tackle the climate emergency facing us all, our aim is to become the world leader in the zero-carbon energy transition ""as a service"" for our clients – particular for companies and regional authorities. We use our expertise in our key business areas (renewables, gas, services) to provide competitive and bespoke solutions.
The Data Centre Engineer will be employed as part of a 24/7 ongoing shift to coordinate and monitor third party service providers, maintain the data centre facilities and infrastructure plans, coordinate the implementation of customer requests within the data centre and monitor systems, all in accordance with the Contract KPIs and SLAs.
Coordinate and monitor third party service providers for regular maintenance & testing, service faults & call outs, ensuring works are performed in accordance with Contract SLAs
Monitor and maintain the data centre facilities and infrastructure plans and documentation, including electrical, mechanical, hydraulics, fire and BMS/EMS systems
Coordinate the implementation of internal and external customer requests within the data centre
Perform scheduled plant checks and minor maintenance works
Ensure all Work Order requests are raised and closed in a timely manner
Conduct inductions for staff, vendors and contractors
Ensure all work permits for vendor works are raised and closed
Perform inventory checks on all equipment and critical spares

Qualifications
The selected candidate must be able to demonstrate:
Electrical or HVAC background, or Graduate Electrical or Mechanical Engineer
Passionate about quality work and career minded looking for a new challenge
Can commit to a day and night shift roster (2 days of day shift, then 2 days of night shift, 4 days off)
Ideally able to commence asap
As part of carrying out the duties of this role, it is mandatory to hold Australian Citizenship.

If you are interested and meet the selection criteria apply with an up-to-date resume via the apply instructions on this website.

ENGIE Services is an EEO employer, where all applicants are treated with fairness and respect and have equal access to the opportunities available.

We will not be engaging in the services of a recruitment agency to fill this vacancy and therefore request all interested candidates apply directly to this advertisement.

Job
: Maintenance
Primary Location
: Oceania-Australia-New South Wales-Erskine Park
Organization
: ENGIE Services Australia and New Zealand
Schedule
: Full-time
Nature of Responsibility
: Senior operational / administrative role
Job Posting
: Sep 11, 2020, 6:29:59 AM",3.7,"ENGIE Services Australia & New Zealand
3.7",Sydney,-1,5001 to 10000 Employees,1995,Company - Public,Energy,"Oil, Gas, Energy & Utilities",$2 to $5 billion (USD),-1
Senior Data Engineer,-1,"Senior Data Engineer, Temporary, SYDNEY - McKell

Job Title: Senior Data Engineer

Salary: SNSW Grade 9/10 - The package includes base salary range of $111,806 to $134,667, plus employer's contribution to superannuation and annual leave loading.

Location: Head Office – Haymarket

Employment Status: Temporary through till 30th June 2021


About Service NSW:

Service NSW is making it easier for people and businesses across NSW to access government services. The role designs, builds and analyses complex data from multiple sources to identify revenue, process and business improvement opportunities; providing new information and insights to the business to inform planning, continuous improvement and performance.

About the Role

We are currently seeking to appoint a Senior Data Engineer to deliver expert advice and services in the design of a Single View of Customer and data-related services to support the achievement of business outcomes and strategic goals. We support flexible working practices with staff working remotely during this time.

In this role you will:

Design, build and support a modern data platform based in AWS and vendor technologies.
Provide expertise on data modelling for Graph data model and Customer Data Platform (CDP).
Create data pipelines, load, transformation and reporting workloads in AWS.
Work with the latest data engineering technologies like Apache Kafka, AWS Kinesis, AWS Neptune, AWS Glue and AWS Athena.
Contribute to the design and decision-making of the right tool or platform for the job according to requirements.
Provide expert advice and guidance on data quality and data engineering best practices.
Support a “bigger than you can imagine” scale of data in production environments.
Design, develop and support a metrics-driven reporting solution and a meaningful business intelligence platform.
Document the solution design and support procedures of solutions.
Produce reports, visualisations and recommendations to answer complex business problems that are presented in the most appropriate format to ensure clarity for target audience.
Analyse and define new process improvement opportunities to support continuous improvement and business outcomes; providing advice to stakeholders, on ways to improve the efficiency and reliability of data products and services.
Be very responsive to the information needs of the business by corresponding to customers in a timely manner and provide support/solutions to issues raised.
Troubleshoot and perform root cause analysis on production issues. Identify and implement long term solutions to problems. Perform scheduled maintenance, release deployment and production support activities after business hours, from time to time.
Liaise with internal and external customers to discuss and gather requirements, solutions etc. and maintain a good working relationship with the stakeholders.


Skills and Experience Required:

Solid experience with workflow technologies designing and building data pipelines, data models and data stores.
Experience working within and an understanding of Amazon AWS ecosystem, including security and performance tuning.
Hands on experience working with different types of databases, with focus on Graph and NoSQL databases.
Experience with data streaming required. Having used Kafka and related technologies is an added advantage.
Sound knowledge and experience working with batch processing, data extraction and API integration.
Hands on experience with at least one programming language: Java, Python or scripting.
Demonstrated experience working in an Agile based, fast paced, complex environment within cross-functional teams.
Experience developing systematised insights, data analytics and reporting solutions is an added advantage.
Experience with interactive visualisation of data insights is an added advantage.


Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Salary Grade 9/10, with the base salary for this role starting at 111,806 base plus superannuation

Closing Date: 6th November at 9:59am - applications will be reviewed on a rolling basis, applications may close early or extend

Please apply online, direct applications submitted via email will not be considered.

The Department of Customer Service is proud to be an EEO Employer who are fully focused on equality and believe deeply in diversity of all identities making us different and a true reflection of our NSW customers. As an inclusive workplace, we support various employee resource groups, practice flexible work and workplace adjustment.

If you do require an adjustment during the recruitment process, please notify us on your application form.",3.2,"Service NSW
3.2",Sydney,-1,501 to 1000 Employees,2012,Government,State & Regional Agencies,Government,Unknown / Non-Applicable,-1
Data Engineer - Entry / Mid Level,-1,"Work with a great team on interesting projects customers
Gain more experience in AWS, Data, DevOps cloud operations
Got a working knowledge of AWS? We will teach you the cool stuff!

Itoc is seeking an up and coming Data Engineer to join our growing Data Team in Sydney.

This is an exciting role working with databases, data lakes, data warehouses, data transformation (Python SQL) and enabling AI/ML.

You will be implementing foundational, robust and production ready data platforms to enable business data-discovery, self-service, AI/ML functions across a range of client types and industries, allowing them to do more with their data.

You'll be responsible for:

Deploying data repositories such as lakes and warehouses.
Contribute to our growing portfolio of data solutions.
Ongoing optimisation and management of data platforms.
Development of transformational logic for data pipelines
Data evangelism. We want to show our clients how to follow the best practices for data.

Desired Skills and Experience

To take up the challenge, you will have a depth of skills and experience including:

1-2+ yrs of focused data experience working with SQL and/or NoSQL solutions
A solid education in Software Engineering or equivalent industry experience.
Anything Data focused preferred.
Ability to analyse business scenarios and associated data landscape to derive potential opportunities.
Strong foundation in Python and SQL
Working knowledge of APIs
Principle knowledge of the different relational database platforms and modern data storage techniques
Knowledge of the different aspects of data environments
Collect, store, process, verify consume
Experience with version management systems (such as GIT)
Working knowledge of AWS or another cloud platform - we will teach you the cool stuff.
Great communication skills, an ability to work closely with customers, developers and engineers and the confidence to present ideas in open forums.
Relevant tertiary qualifications and/or industry certifications.
Great communication skills, an ability to work closely with clients, developers and engineers and the confidence to present ideas in open forums.

While not required, a background in consulting and professional services is highly desirable.

Itoc Description

This is an exciting and challenging career opportunity to join the growing Sydney-based Data Team of a leading cloud solution provider where you will be given support to reach your long term career goals. You will be part of a team of cloud experts and will work in an environment of continuous improvement and learning delivering innovative cloud solutions across SaaS, online business and enterprise business.

On offer is a chance to join a team with a great working environment, in an organisation that values its employees and sees the value in ensuring they are engaged. Our team are clearly passionate about what they do, that's why we won the following awards:

Customer Obsession Partner of the Year 2015: ANZ Region
Customer Obsession Leadership Partner 2015: re:Invent

As an employer of choice Itoc offers competitive remuneration, training and development programs and a great working environment. We value a healthy work life balance.

The Perks

MacBook or Dell
Continuous internal learning that will provide training and career development opportunities
Working with a collaborative, social team and leveling-up your skills faster than you will anywhere else.
Quarterly social events

Itoc

Culture and smarts are important to us. Bring your secret sauce. This is no ordinary environment, you will work along some of the Cloud’s best. All engineers at Itoc must gain at least five AWS certifications. We work hard but we have fun.

Please note you must have full working rights in Australia and be available on-shore for face to face interviews.

No recruiters please.",4.0,"Itoc
4.0",Sydney,-1,1 to 50 Employees,2013,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Date: 01-Oct-2020

Location:
Melbourne, VIC, AU

Department:Description:
Technology discounts - from Apple HP Lenovo to Windows
Flexible work arrangements - work in a way that suits you best
Salary packaging - to suit your personal and financial circumstances

Do you want to work for one of the fastest growing data teams in Australia? Do you want to work on multiple data platforms and provide new solution offerings by leveraging cloud and big data technologies?

About the team

Big data information and analytics. Three words that spark apprehension in most businesses. But our team of experts are constantly curious and excited about combining our wonderful array of technological expertise to transform data into our clients most valuable assets making their work smarter. Our data consultants are supported with resources training and tools they need to excel at their work but also the freedom and power to create their own paths forward to make a difference.

As a Senior Consultant in Big Data you will work closely with the team and stakeholders to build and deliver a Cloud based vision for a next generation Big Data analytics platform with strong focus on data quality data security and deliver the systems that process huge volumes of data.

What will you typical day look like?

You will play a pivotal role in - Designing and producing high performing and stable applications to perform complex processing of massive volumes of data in a new cloud based architecture; Building real-time data processing applications which are integrated with business systems to enable value from analytic models to drive rapid decision making; Contributing to system architecture design for a data platform (including cloud-based structures both on and off premises data warehouse components and data lakes); this could cover a range of technologies various countries/locations and lines of business; Support data strategy or technology strategy definition programs including technology stack definition and target operating model requirements

Enough about us lets talk about you:
You are someone with:
Use of traditional data analytics tools and techniques (e.g. MSSQL Oracle MySQL) and ETL software (e.g. SSIS Informatica CloverETL)
Working in large scale cloud data solutions using platforms such as AWS or Azure or GCP will be a bonus.
Experience in scripting or programming (e.g. Python Java Scala C#)
Excellent verbal and written communication skills to adapt to technical and non-technical audiences.
Educated to degree level (or have equivalent experience)
Why Deloitte?

At Deloitte we create positively differentiated work experiences that enable our people to feel valued and achieve their full potential. We value difference and embrace people with diverse backgrounds and thinking styles. Knowing that people work best in different ways we are happy to discuss alternative arrangements if the working pattern you are looking for is not specifically indicated.",3.8,"Deloitte
3.8",Melbourne,-1,10000+ Employees,1850,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Engineer,-1,"Opportunity to grow the team
Period of growth
Intuitive app
S2M are working with a FinTech who have created a unique financial product to help thousands of people better manage their finance, and is currently scaling the company to the next level!

They are looking for a Data Engineer to join, and looking for someone who wants to be hands on, with opportunity to grow the team in future.

Role:

Looking for people with strong AWS experience. You will need passion for data and a cloud, through which you will help a rapidly scaling Australian FinTech establish their data infrastructure from the ground up.
5+ years’ experience as a data engineer within the data and analytics domain
A python 3.X aficionado who is very comfortable creating and orchestrating AWS data pipelines with nothing but code
Strong project delivery toolset experience in open source data integration tools
Experience with processing large volumes of complex data including visualisation and insights generation
Ability to define and develop data integration patterns and pipelines
Ability to assess complexity of data (volume, structure, relationship etc.)
Hands on experience working with different databases (RDBMS, NoSQL, Blob storage etc)
Hands on technical expertise setting up DevOps automation
Hands on experience working technologies/platform e.g. AWS, Dockers, Containers
Experience building data profiling and data cleansing frameworks
Technical reconciliation and reporting
Knowledge and experience in end-to-end project delivery, either traditional SDLC or agile delivery methodologies (or hybrid approaches)
Exceptional communication, documentation and presentation skills
If this sounds like you, get in touch today - kate.gabb@s2m.com.au
3167410agsdf",3.1,"S2M
3.1",Sydney,-1,Unknown,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Analysts,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is seeking experienced and qualified Data Analysts to join our IT team based in our corporate office in Birtinya (Sunshine Coast) or at our meat processing facility in Kilcoy.
Key Responsibilities:
A mixture of data analysis and commercial skills to source, blend and analyse data to gain insight and answer key commercial questions
Working with strategic leaders to define and model Key Performance Indicators, and assist in building forecasting models
Working closely with data engineers and BI developers to specify data pipelines and report visualisation
Drive the creation and implementation of data quality business rule including data definition, governance and quality assurance
About You:
To succeed in this role, you’ll need to bring the following experience and skills:
Proven ability to derive insight and knowledge from data using commercial expertise is a strong requirement
Strong SQL and Excel skills are essential, along with strong data analysis and commercial insights
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Effective people communicator - engage with stakeholders on reporting needs, interpret requirements into visual solutions and train/deliver the outputs to the stakeholders getting signoff of acceptance
Bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking

How to Apply:
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kilcoy,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Network Data Engineer,-1,"Min 6+ years of experience in the relevant technologies
Australian Driving License for visiting remote locations / Data Centre for day to day technical work.
Managing Network devices (switches, routers, firewalls, load balancer, and wireless technology)
Performing MACD activities for all network devices.
Supporting BAU operation activities.
Proficient in performing in-depth details of technical troubleshooting, cause and provide recommendation to the client for incidents causing extended network outage to client’s critical locations.
Provide exceptional network services in terms of network support, break-fix, design and consulting, new projects, implementation.
Configure, administer, and document firewall infrastructure.
Manage the firewall deployment, rules migrations, and firewall administration.
Supporting Cloud Migration Activities from traditional to AWS/Azure.
Setting up VPN tunnel with Cloud and 3rd Party network devices.
Integrating and upgrading existing ISP bandwidth with support from ISP Vendor.
Setting up VPN profiles for Users.
Installing hot fix and patches to mitigate the security devices from attacks and bugs.
Reviewing and fine tuning the firewall rules and NAT rules.
Documentation and change control.
Mentoring, Motivating and Guiding support teams
Technical skills:
o LAN
o Wireless
o WAN
o MPLS
o Routing protocols (OSPF,BGP)
o DMVPN
o Azure cloud Networking
o Network Security
Fortigate Manager / Analyzer / Firewall
Cisco ASA
Firepower FTD
Cisco Any connect
Site to Site VPN
F5 Load Balancing and Scripting iRule
Job Types: Full-time, Contract
Schedule:
8 hour shift
Experience:
Scripting: 5 years (Required)
Data Network: 5 years (Required)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Required)",3.6,"Total IT Global
3.6",Sydney,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Engineer - Processing & Analysis,-1,"Job Description:
Design,build and maintain the ingestion system to support various types of data(e.g. User behavior, RDS, NoSQL db and others) to be ingested to the data warehouse more timely and accurately
Translate data requirements into scalable technical data service with low latency and high concurrency
Design,build and maintain the batch or real time data pipeline in production using Hadoop big data technology
Analyze and improve efficiency, scalability, and stability of the system
Define and manage SLA,Data quality for all data sets in allocated areas of ownership
Requirements:
Minimum B.S. degree in Computer Science or a related technical field
2+ years of working experience in programming languages,such as Java,Scala,Python
Familiar with Hadoop, Spark and Flink data processing, experience of TB data processing experience is a plus
Familiar designing and operating of a robust distributed system is a plus
Understand data mining or machine learning
Excited to work intimately with data
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"SYNOPSIS:
Lead Data Engineer
Applications close Sunday 8 November 2020
Ongoing
Contact name: Shyni Sasikala
Phone: (02) 6249 9048
Email: Shyni.Sasikala@ga.gov.au

The Data Policy and Informatics section within the Digital Science and Information branch creates, implements, and promotes policies, platforms and tools that improve and support the quality, discoverability, accessibility, and general usability of Geoscience Australia’s science data products. The section consults with internal and external research, government and industry partners to establish collaborative data frameworks, architectures and models within Geoscience Australia (GA) and across broader national and international communities of practice. The section innovates, builds and maintains tools, systems, processes and governance that enable digital data management, cataloguing and open data delivery.
GA makes accessible a wide range of geoscientific and spatial data to a wide variety of stakeholders in multiple formats, and in recent years GA's data volumes have grown exponentially. GA is focussed on making its data and metadata assets accessible so that they can be used in machine to machine interactions for data analytics and other applications in environments that range from High Performance Computing (HPC), through high-end cloud servers, to mobile devices.
We currently have two opportunities for Lead Data Engineers in the Informatics team. The Lead Data Engineer is responsible for innovating and exploring new technologies that will advance GA’s science goals and maximise the uptake and use of GA’s science data. The Lead Data Engineer reports to the team’s Assistant Director but also works closely with other developers, data scientists and engineers within the Digital Science and Innovation (DiSI) branch, as well as diverse stakeholders both within and external to GA.",3.9,"Geoscience Australia
3.9",Canberra,-1,501 to 1000 Employees,2001,Government,Federal Agencies,Government,$100 to $500 million (USD),-1
Data Engineer,-1,"The Seven Network is part of Seven West Media, one of Australia’s most prominent media companies, with a market leading presence in content across broadcast television, online and in print. Comprising some of Australia’s most renowned media brands, SWM includes not just Seven Network and its affiliate channels 7two, 7mate, 7flix and BVOD offering 7plus, but also 7NEWS.com.au, The West Australian, The Sunday Times and more.
At Seven we are here to bring all Australians closer to the moments that move us - we’re first on the scene, with our finger on the pulse, on demand, in the moment. Together, we’re responsible for creating and sustaining authentic Australian engagement.
A new and exciting opportunity has opened for a Data Engineer to join the Audience Intelligence team. Based in Sydney and reporting to the Head of Data Enablement, you’ll be responsible for:
Implementation of end to end data solutions to support Data Strategy for the SWM group.
Work closely with the Data Solution Designers to develop and maintain scalable data pipelines and build out new file and API based integrations to address requirements from the various business stakeholders.
Collaborates with engineering, analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organisation.
Work on Data Preparation for analytics and data scientist team members and assist them from an engineering perspective in building and optimising the models including building the automation of the end to end workflows
Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.
Perform data analysis required to troubleshoot data related issues and assist in the resolution of production data issues.
Work effectively with vendors for successful delivery of projects and acceptance of the solution
Work on Delivery projects using Agile Software Development methodologies
We are looking for someone who has:
Bachelor's degree in computer science, computer engineering or other technical discipline is essential
Proven experience working as a digital analytics specialist
Extensive experience with digital analytics implementation (e.g. Google Analytics, Snowplow, Adobe Analytics) and BI processes and visualisation platforms
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience in ETL and building and optimizing ‘big data’ pipelines and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Experience with big data tools: Hadoop, Spark, etc., AWS cloud services: EC2, S3, Lambda and familiar with version control systems: Git
Strong coding skills with knowledge of Unix/Linux and scripting languages such as Unix Shell scripting, Python desirable
Experience supporting and working with cross-functional teams in a fast-paced environment.
Ability to multi-task and problem solve with changing demands and priorities
Ability to work under pressure to meet deadlines and detail oriented
Your success is our success: we will provide you with opportunities for you to keep learning and growing, enabling you to challenge and develop yourself. In return, we offer a benefits program that has something in it for everyone.
Seven West Media is an equal opportunity employer and we are committed to creating a diverse and inclusive workplace.
Recruitment Agencies: Seven West Media does not accept any unsolicited agency resumes and will not be responsible for any fees related to unsolicited resumes.
Advertised: 19 Oct 2020 12:00 AM AUS Eastern Daylight Time
Applications close:

Back to search results",2.5,"Seven West Media
2.5",Sydney,-1,5001 to 10000 Employees,1956,Company - Public,TV Broadcast & Cable Networks,Media,Unknown / Non-Applicable,-1
BICON Rules Engineer,-1,"APS 5 - $73,299 - $80,410 per annum plus superannuation
Biosecurity Plant Division
Canberra, ACT
Play an active role in managing biosecurity risk to Australia
Work in a motivated and professional team with a wide range of skills and backgrounds
Full training provided

Who we are
The BICON Content Development Team maintains and improves the Biosecurity Import CONditions database (BICON) content to allow external clients to understand and comply with their biosecurity obligations and internal clients to effectively manage biosecurity risk and regulate imports. We work collaboratively with internal clients to comprehend and implement their BICON content requirements and optimise the use of BICON to publish clear import requirements and onshore management support procedures to effectively manage biosecurity risk.

The Jobs
Key duties of these positions include:

working with business content (import and permit conditions) and import programs to understand and construct decision tree structures in the BICON database, in accordance with system design and authoring conventions
executing changes to import and permit conditions in alignment with service standards while complying with system rules and authoring conventions
providing technical advice through various formats on the most appropriate means of authoring BICON content to achieve import program and stakeholder objectives
using workflow management tools to maintain detailed records of changes to import conditions and key decisions
performing administrative tasks including system reporting, data analysis and scoping tasks for the BICON content change work program
contributing to the development and maintenance of instructional material, authoring conventions and courseware
clearly documenting and reporting system issues
developing and maintaining effective working relationships with internal and external stakeholders.

What we are looking for
Knowledge and experience
Experience working with complex IT systems.
Experience working collaboratively and as part of a team.
Knowledge of the role of biosecurity is preferred but not essential.

For additional information, please read the Job Description below.
Candidate Information Package docx Opens in new window",3.9,"Department of Agriculture & Water Resources
3.9",Australia,-1,5001 to 10000 Employees,-1,Government,Federal Agencies,Government,$500 million to $1 billion (USD),-1
Cloud Data Engineer,-1,"Job no: 509605
Work type: Permanent Full Time
Location: Melbourne, Canberra, Sydney
Do you embrace digital disruption?
Do you love solving complex problems, designing sophisticated solutions and building innovative technology?
Do you believe in creating powerful actionable insights from Data and Analytics?
Do you want to work in a diverse and flexible working environment?
KPMG is one of the most trusted and respected global professional services firms. Through depth of expertise, clarity of insight and strength of purpose we help our clients solve complex challenges, steer change, strengthen, transition and grow. We are a team based practice and this extends to our clients whom we work and collaborate with, in solving complex problems. Together, we design, innovate and implement, providing enduring advice that support our clients and the services they deliver. Our clients vary in size and come from a diverse range of sectors – all sharing in a common goal: to embrace change and deliver services that make Australia a better place. We are looking for talented individuals who would like to join us on the journey.
KPMG’s Digital Delta Team
We re-imagine and re-invent organisations to become world class digital enterprises using advanced technologies, data and human insights. We help organisations to embrace Digital Strategy, Artificial Intelligence (AI) & Cognitive, the Internet of Things (IoT), Data, Analytics & Modelling, Mobile App & Web, and User Experience (UX) & User Interface (UI) and more.
We work with clients to:
Formulate strategies that re-imagine organisations
Harness innovation from the 4th industrial revolution
Actioning insights from trusted data to consistently and quickly make clear decisions
Build adaptive organisations
Thrive as a connected enterprise – front, middle and back office
This is how you’ll contribute:
We are looking for ambitious Data Engineers who are passionate about helping clients define bold ambitions and deliver on them. Joining our team will take you on a journey of personal and technical growth and provide the opportunity to inspire confidence and empower change.
As a Data Engineer you are the designer, builder and manager of the information or ""big data"" infrastructure, preparing data for analytical or operational use. You will design, construct, test and maintain a data pipeline to pull together information from different source systems; integrating, consolidating and cleansing data; and structure it for use in individual analytics applications.
The KPMG Difference
Our people are focused on creating a diverse and dynamic environment that embraces and values differences. We value the variety of unique experiences, qualities and characteristics our people possess and we share and learn from each other.
We are proud to be consistently recognised as an employer of choice for women, and for our achievements in LGBT+ workplace inclusion.
Our commitment to ‘Flexibility’ allows our people to manage the changing demands of work, personal or family life. Explore the links below to hear our people share their experience @ KPMG:
Flexibility empowers wellbeing
Flexibility enables contribution to the community
Flexibility inspires technology & innovation
Flexibility supports family

Make KPMG the clear choice for your career and be Extraordinary!

Advertised: 09 Sep 2020 AUS Eastern Standard Time
Applications close:",3.8,"KPMG
3.8",Sydney,-1,10000+ Employees,1987,Subsidiary or Business Segment,Accounting,Accounting & Legal,$2 to $5 billion (USD),-1
Computer Network and Systems Engineer,-1,"Duties Include but are not limited to:
Tasks Include:
analysing, developing, interpreting and evaluating complex system design and architecture specifications, data models and diagrams in the development, configuration and integration of computer systems
researching, analysing, evaluating and monitoring network infrastructure to ensure networks are configured to operate at optimal performance
assessing and recommending improvements to network operations and integrated hardware, software, communications and operating systems
providing specialist skills in supporting and troubleshooting network problems and emergencies
installing, configuring, testing, maintaining and administering new and upgraded networks, software database applications, servers and workstations
providing network programming in support of specific business needs and requirements
preparing and maintaining procedures and documentation for network inventory, and recording diagnosis and resolution of network faults, enhancements and modifications to networks, and maintenance instructions
monitoring network traffic, and activity, capacity and usage to ensure continued integrity and optimal network performance
Skills and Experience Required:
Must have experience working in a Managed Service environment
Demonstrated experience in IT Networks and Data Centres
Understanding of systems and architectures to meet client needs
Experience in Help Desk including break / fix
Effective and timely documentation
Effective Task Management Skills
Be solution and outcome focused and willing to learn new technologies
Excellent communication skills with staff, clients and partners
Time management, ability to prioritise and deliver to schedule
Experience with N-Able and Connectwise desired
Open Cabling license desired
Job Types: Full-time, Permanent
Salary: $30.00 per hour
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,Trans-plant training,Canberra,-1,-1,-1,-1,-1,-1,-1,-1
Software Engineer (Data),-1,"If you are looking for an opportunity to make a real impact with smart people who are genuinely doing things differently then you've come to the right place! We're growing our data engineering capabilities and are looking for awesome data engineers to join our team.
With our diverse range of clients and projects, no day will look the same - but here's a great snapshot of what you'll be doing:
Work with some of the best Data Scientists and Engineers to deliver production-grade AI and Machine Learning systems as we deliver client projects from inception to production.
Consulting with our clients and working with them to build modern data systems using the 'best of' technologies and principles.
Advising clients on data strategy, architecture and technology.
Applying best software engineering practices in coding, monitoring and alerting, using CI/CD, TDD and cloud architectures.
Working over a wide range of big data tools and environments: not limited to; Apache Kafka, Spark, Python, Scala, Hive, Airflow, AWS EMR & Glue, GCP Dataproc & Dataflow, BigQuery, Snowflake, Redshift.
Who are we?
Glad you asked! We are Eliiza. Data science. Engineered for scale.
We are a passionate team of data scientists and engineers who apply data science and machine learning to solve real-world problems. Our mission is to create a bright future for Australian businesses and society in a world increasingly influenced by intelligent technologies.
We've created a culture that values diversity where people can truly be themselves! We care a lot about growing the Australian AI community in a positive direction, and we're doing several things to try and achieve that:
We provide opportunities for underrepresented groups to work in AI through our associate and intern programmes
We organise and participate in a range of community events, reading groups and meetups
We produce the AI Australia podcast
We blog about topics we care about
We stream brown bag sessions to the broader community
We're also part of Mantel Group's 'house of brands' which means it's not just the Eliiza team you'll work with, learn from and see at social events - there's another 230 of us across DigIO, Kasna & CMD Solutions!
So you're ready for something new?
We're keen to know more about you! Our team is made up of a range of people, with different experience across a huge range of data driven skill sets.
We'd love to hear from you if you have experience with:
one (or more) core language(s), ideally Scala, Python or Java
one (or more) cloud platforms, AWS, GCP, Azure
ETL/ELT concepts and technologies e.g. Data partitioning, Hive, Spark
streaming data concepts and technologies, ideally Kafka (Kinesis, Beam or Pubsub will do)
We'd be over the moon if you:
Experience with distributed/columnar databases (e.g. Snowflake, Big query, Redshift).
Experience with any of a variety of databases e.g. RDMS, NoSql, Columar, Distributed, Time series, Graph.
Knowledge of job orchestration and scheduling. Any experience with Airflow, Luigi or Oozie.
Experience with containers and container orchestration (Docker, Docker Compose or Kubernetes).
However, we value a diversity of skill-sets, and don't necessarily require that you're skilled with all of the above. If you feel you don't fit all the experience/skills listed above we still encourage you to apply or get in touch.
What's on offer if you join us?
We make sure you're always one step ahead by investing your learning and development, every year. We build our own training where it doesn't exist yet.
We hire smart people and get out of their way. By focusing on our five principles and not getting caught up in red tape, we trust you to get the job done.
You'll get all the tools you need - a new iPhone or Google phone, a new Macbook Pro or Dell, and a lot of branded swag!
But hold on, you mentioned a house of brands?
We certainly did! Mantel Group is an Australian-owned, 'house of brands' company with four technology businesses (Eliiza being one of them!) across Melbourne and Sydney. We're building a group of companies with open borders so we can support you to take on new skills without leaving an awesome team - we understand you won't have one job for life!
We may only be just two years old but Mantel Group has already been recognised #9 in the 2020 Best Places to Work in Australia and #4 in the AFR's 2020 fastest growing new companies.
Keen to chat?
Click ""Apply"" to share your details with our talent team, and we'll be in touch.
In the meantime, check out 'how we hire' to find out what's in store if you're successful and get to know us better by visiting our website and following Eliiza on LinkedIn.",-1,Eliiza,Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Infrastructure Engineer,-1,"Job Description:
Design and grow the Shopee data platform to support a variety of big data applications using open-source technologies including Kafka, Hadoop, Presto, HBase, Spark, Hive, Druid, and our own creations. Some examples include a real-time data streaming platform, a unified query platform, a cluster management system, and a machine learning platform
Dig into the source code of some open-source big data system to get the whole control and familiar with the details, configurations, designs and source code. Develop and maintain the internal release of big data systems and components as the business requirements.
Keep close and overall monitoring for all the deployments of the systems, maintain the system’s stability, improve the performance, discover the performance bottlenecks, tracking and troubleshooting, cost optimisation.
Requirements:
B. Sci. / Ms / PhD in Computer Science or a related technical field
Familiar with at least one of these languages: Java, Scala, Python, Bash under Linux / Unix. Scala is a plus
Familiar with the use and compute logical of SQL
Knowledge about the Big Data Infrastructure system technology like Distributed File System, Distributed Computing, Distributed Database will be a plus
Hands-on experiences Hadoop, Spark, Kafka, and/or Presto will be a plus
Love to use and develop open-source technologies
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"Work on an award-winning, international technology!
Endless career opportunities
An innovative, friendly team of 300+
This role will be focused on the development of our existing ClaimLogik line of products as well as working on our new cloud-first, modern suite of applications.

Intelligent Thought, our technology business is scaling and shipping our software globally. Already profitable, part of a much larger group business, with investors such as Macquarie Capital and Envest – we are all set to deliver textbook disruption to the Insurance Industry. The growth of the platform, of our customer base, and the increasing industry demand have led to the need for this role to help the team scale.

Our Philosophy
Give each employee a sense of purpose and an environment for them to connect the importance of their role to delivering a service that matters to our customers.
Challenge the ‘why’ of traditional claims processes.
Keep it simple – do only what brings value and what matters to the customer
Enable employee decisions, empower our people
Responsibilities:
Create, extend and maintain ETL pipelines to form our data lake, data warehouse and analytics platform (currently using the Microsoft Azure set of tools and service)
Help define the optimal data pipeline architecture
Influence the tool selection, platform selection, data architecture and strategy which will transform the business to be truly data-driven
Understand, analyse and size user requirements
Work with different parts of the business to provide them with the insights they need to deliver the best results
Skills & experience:
Degree or qualification in computer science or related
Advanced knowledge of relational database, including query authoring and query optimisation (MS SQL Server and PostgreSQL).
Experience building and optimising ETL pipelines
Experience designing complex data models
Experience working with cloud platforms (Azure or AWS)
Efficient time management and organisational skills
High attention to detail and accuracy
Effective communication skills to build strong working relationships; both written and verbal
Proactive and results-driven
Why Claim Central?
Claim Central Consolidated is a global insurance industry leader across, claims management, insurance technology and data and analytics. Currently operating in the United States, Australia, South Africa, Italy and New Zealand, we have pioneered digitally connected claims management services across the globe. Claim Central is a disruptor and thought leader in the industry and we were recognised as the Australian Financial Review’s 8th Most Innovative Company in Australia in 2016. This business is in a period of unprecedented growth, transitioning our technology and services into multiple geographies at a rapid pace. Our unique culture is based on teamwork, collaboration, trust, respect and performance. We also offer many benefits apart from our exceptional team culture; including flexible work arrangements, and continued professional development.

Be a part of this journey in a career-defining role.",-1,Claim Central,Matraville,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer - AI/ML,-1,"Our client provides services to a major industry across the country. The business is still early in it's days of technology development and the environment is greenfields in nature (no pun intended), effectively working like a start-up.

Their data and analytics team have worked and built leading and bleeding-edge technologies in this space and what they have created so far may be game-changing. From a machine learning perspective, the progress they have made to the business has already seen proven success in changing the future of an industry that will have positive consequences for all those involved.

You will have previously worked in a technical capacity in the data and analytics space and have experience working with an organisation where machine learning has been implemented, not just a concept that the business talks about having or the technology team would love to have. The commercial experience you will have had in the ML field will be proven examples of where you have affected the way a business or industry used to perform, to the changes that have come about from this.

Technically, you will have extensive experience in the Microsoft space - Power BI, Azure etc and you will have previously mentored and coached junior members of the teams you have been part of.

This is a rare opportunity in Brisbane where the business has truly embraced and funded projects across the ML space and would be a great chance for those in the Data Development/Data Engineering field, who are looking to move into a Data Scientist role in the future.

Please send your application through if you would like to know more.",4.0,"Emanate Technology
4.0",Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Solution designer/ ETL Engineer & Data Modeller,-1,"We are looking for a Qualified and Experienced Solution Designer to join our client for a period of 6 months with a view to extend.
You will work closely with team members and your contribution will range across gathering and analyzing information, developing and documenting improved processes and work instructions and experienced DWH Lead with skills in requirement analysis, solution designing, developing, testing and supporting ETL solutions.
A hands-on solution designer, data modeler and ETL developer for Data Warehousing and ETL application transformation projects using Informatica PowerCenter.
Knowledge on AWS, S3, Redshift, Informatica BDM, and related technologies.
Experience working with IPython, PySparks, AuCuMo, Airflow, Jenkins, Github, Athena, JIRA, Rally, Spectrum, Glue, Flyway.
Good exposure on Oracle PL/SQL, aware of DBA activities, writing and performance tuning of complex SQL queries.
Contract length: 6 months
Job Types: Full-time, Contract
Salary: $650.00 – $800.00 per day
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,nducive,Melbourne,-1,-1,-1,-1,-1,-1,-1,-1
"Data Engineer, Wollongong NSW or Mount Waverley VIC",-1,"Company Description
BlueScope is a technically advanced supplier of steel and steel products in Australia. We are an inclusive organisation and every day we showcase our technology and expertise throughout the world.

Job Description
We are looking for two Data Engineers to join our IT team, based in Wollongong NSW or Mount Waverley VIC. Use your experience in analytics to unlock business value, enabling use of big data for insights and decision-making.
Reporting to the Data Product Owner for our Australian Steel Products (ASP) business, this position will support strategic goals related to data. This will see you:
Gather business and technical requirements with the view to deliver outcomes;
Develop and implement end-to-end data collection, consolidation, modelling and visualisation solutions;
Document metadata in a dictionary and catalogue;
Ensure consumers of such information understand its accuracy, timeliness, quality and sensitivity, so that it is used appropriately; and
Identify opportunities to enhance analytics.
What are the benefits?
Work in a supportive and collaborative team environment whilst we embark on a journey to transform the way our business uses data!
Our systems landscape is broad and diverse. You will be encouraged to think creatively to develop data solutions which solve real business problems.
Working in this role you will enjoy:
the chance to learn more about data science;
salaried remuneration with attractive superannuation options;
the opportunity to participate in a performance incentive scheme; and
access to further development and career opportunities with BlueScope.
Who are we looking for?
We welcome applications from professionals with experience in data analytics and/or programming. Supported by your knowledge of project delivery methods (e.g. Agile), you will demonstrate:
experience with data mining, wrangling, mapping and visualisation techniques (e.g. Azure Data Factory, Databricks and/or DevOps etc.);
well-developed ability in gathering business and technical requirements;
skills in developing and implementing collection, consolidation, modelling and visualisation solutions; and
a passion for sharing your knowledge and desire for ongoing professional development.

Qualifications

null

Additional Information
We're proud to have been named an Inclusive Employer for 2019–2020 by the Diversity Council of Australia. We believe that our people are our strength. Having a diverse and inclusive workplace enables us to improve our capability and ensure continued, sustainable success.
We know that workplace flexibility can mean something different to everyone. Under our B-Flex initiative all of our roles have some degree of flexibility. We encourage you to discuss your needs with us.
Applications close Sunday 25th October 2020.",3.3,"BlueScope
3.3",Wollongong,-1,201 to 500 Employees,-1,Company - Private,Construction,"Construction, Repair & Maintenance",$100 to $500 million (USD),-1
ETL Data Engineer,-1,"ETL Data Engineer

Join a team that’s changing how Australia lives, works, plays and grows
We want you to be the best version of you

Work with innovative teams and explore new technologies to help solve real-world problems.

A typical day as a Data Engineer

ETL / Big Data Engineering professionals will be responsible for guiding the full lifecycle of a Data solution, including:
Working in highly client-facing roles to contribute throughout the end-to-end delivery lifecycle of complex and large-scale digital solutions
Use case and business case development
Support existing and new applications utilizing in-depth technical and data knowledge. Troubleshooting complex issues and providing advisory services to improve the client’s data landscape
Help to streamline and simplify the clients’ complex data landscape by integrating different applications and data architectures
Implementation from requirements analysis, platform selection, digital architecture design, application design and development, testing, and deployment
Interstate travel may be required

Basic qualifications:
Bachelor’s degree
Experience across systems integration, information management, data management and architecture, and business analytics
Experience with being in a team focusing on large-scale, multi-release information centric projects
Experience with waterfall and agile delivery and run / application support functions
Part of a team working on End to end implementation of at least 1 big data project

Preferred Skills:
Hand on experience in Data warehousing using ETL tools such as DataStage, Autosys and TeraData
Hands on experience in ETL job development with multiple stages like sequential file, Transformer, Lookup, join, sort and Database stages.
Strong hand on skills in design, development and implementation of various data remediation, Data migration, data integration techniques.
Strong hand on data modelling experience.
Strong hands on experience in database performance tuning including complex query optimizations and physical database tuning using Teradata.
Understanding of architectural designs and strategy related to data migration, data cleansing, data quality and data consolidation.
Proven data analysis, requirement gathering and problem-solving skills
Exposure to Unix environment and shell scripting.
Experience in Banking and Financial services industry
Desirable: Knowledge of cloud computing infrastructure (e.g. Amazon Web Services EC2, Google Cloud, Microsoft Azure)
About Accenture

Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. We combine unmatched experience and specialized capabilities across more than 40 industries — powered by the world’s largest network of Advanced Technology and Intelligent Operations centers. With 513,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises. Visit us at www.accenture.com.

Accenture is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, marital, domestic or civil partnership status, sexual orientation, gender identity, or any other basis as protected by applicable law.

Vera Goga is the Recruiter managing this role. As the team experience high volumes of applications, we appreciate your patience to allow for a fair and timely process.",3.9,"Accenture
3.9",Sydney,-1,10000+ Employees,1989,Company - Public,Consulting,Business Services,$10+ billion (USD),-1
Student Engineer,-1,"The candidate will have the ability to:
Undertake onsite inspection to collect asset condition data based on the relevant engineering standards and technical guidelines;
Undertake desktop analysis to evaluate the condition and performance of the assets;
Provide the appropriate information, advice, engineering input and support services for the sustainable management of Council’s stormwater and transport networks.
Qualifications:
The successful candidate will be enrolled in a Bachelor of Engineering with a minimum of two years completed.
Position Number: 100678
Position Hours: Fixed term (3 months), hours will be negotiated with the successful candidate, maximum of 75 hours per fortnight.
Salary: Schedule A, Salary Point 4.0. $28.64 per hour ($55,853.45 per annum, pro-rata) in accordance with Glenorchy City Council’s Enterprise Agreement 2016
Please note that all successful applicants will be required to provide a current National Police Check prior to commencement of employment.
For further information on this position, contact Patrick Marshall, Senior Civil Engineer on (03) 6216 6800.
How to apply: Applications for this position must be lodged on this submission site or on the Glenorchy City Council website www.gcc.tas.gov.au - Careers page.
To be considered for this role, all applicants must address the key selection criteria in the and provide a current resume. A copy of the position description can be found by clicking the below hyperlink or on the Glenorchy City Council website.
Applications close at 8pm on Sunday, 1st November 2020
- Student Engineer",4.0,"Glenorchy City Council
4.0",Glenorchy,-1,501 to 1000 Employees,-1,Government,-1,-1,Less than $1 million (USD),-1
Data Engineer involving DevOps,-1,"Data Engineer involving DevOps
Axiom Technologies is an Australia based entity with the history of providing Managed IT solutions to medium to large scale enterprises globally. Please visit our website for more information about what we do at www.axiomtechnologies.com
Axiom Technologies is an Equal Opportunity Employer and encourage applicants from all backgrounds and gender to apply, including, Aboriginal and Torres Strait Islander candidates
Job Requirements:
8+ years IT experience, with at least 5+ years of “Data Engineer/Deveoper” focused titles/roles,
Data Tools: Hands on experience with Apache Beam.
Testing: Hands on experience with automated testing activities/outcomes
DevOps: Experience with the processes involving Microservices facilities for artifacts developed
Platform/OS: Mid-range/Unix
Languages: Unix (Shell) Scripting/commands, SQL, Python
File formats: Text, CSV, Parquet, JSON, XML
Scheduling: Jenkins, Airflow
Auto Scripting: Designing/creation of scripts for repetitive activity. E.g. Unix scripting/SQL
Big data: Exposure to Data Lake Concepts, Hive (Schema), HDFS
Source Control tools: GIT
Delivery Models: Agile, Scrum
Ingestion Design: Create/assess Source/Target data mapping designs
Frameworks: Development and delivery frameworks
Activity Reporting/Repository: Jira, Confluence.
Quality: Accuracy and attention to detail
Industry: Financial Services/Banking
Solutions: Define solutions from High level to detail design to address automating ingestion activity. Facilitate/confirm requirements from product owners, business team members and technical associates,
Process Automation: Automating processes in file management, testing data in files, analysis and design, configuration management.
Script Automation: Ability to design/create scripts to automate/improve data copy/migration/ETL for any repetitive activity.
Languages: Java, Python
Scheduling: Control-M
Databases: Relational. E.g. POSTGRESS, Oracle – as a ETL developer
File Formats: Mainframe – experience with referencing its data formats/copybooks
Big data: Experience referencing/using Hive (Schema) to access data in HDFS
Metadata management tools: MDM, EDC and Axon
Performance: Assess, recommend, improve mappings, SQL queries, Batch feeds
Automation Tools: Other tools that may add value to an automation program and generally support development. E.g. API, REST, JDBC, Webservices, Message Queues/Load balancer,
Cloud: Experience with processing of data files to be ingested/stored in the Cloud, preferably with AWS.
Prod Support: Experience in a production support role performing root cause / impact analysis – under time constraints
Experience in a similar role
8+ Years
What next?
If you are looking for that next challenge in your career and wish to apply for this role, please forward your resume to careers.au@axiomtechnologies.com",2.0,"Axiom Technologies
2.0",Melbourne,-1,1 to 50 Employees,-1,Company - Private,Industrial Manufacturing,Manufacturing,Less than $1 million (USD),-1
Data Engineer,-1,"About the Role
We are on an exciting digital journey so it’s a great time to join ME! We are seeking a Junior Data Engineer who enjoys rolling up their sleeves, learning and growing. As part of our Enterprise Data Team, you will ensure fit for purpose data warehouse solutions are built for use across the bank and by utilising best practise ETL standards, whilst ensuring the data is trusted by our BI developers and key business consumers. Oh, and you’ll get to work on Microsoft technology stack too!
You will be involved with investigating data issues, keeping data feeds flowing and collaborating with different projects across the bank to deliver quality data solutions. How important does that sound? What’s even more important is this role contributes directly to our overall business strategy through the provision of data to enable analytics & reporting, as well as supporting business and decision system processes.

About You
You’re naturally a highly motivated and energetic person who thrives in a dynamic, ever-changing collaborative team environment. Ideally you have previous experience as an ETL developer, Data Engineer or a BI developer, and if you have a degree in computer science or similar it would really put you ahead of the rest.

With your knowledge of SQL coding, data modelling, understanding of data warehouse concepts, plus experience of working on complex ETL solutions, you’re ready to expand your horizons and launch your career into the world of IT at ME.

About ME
We’re not like other banks.
ME was created by the industry super funds to be different from the pack – with a core purpose to help all Australians get ahead financially – no conditions, asterisks or exceptions. And we know that looking after customers starts with taking care of our people.
We believe everyone deserves the same opportunities in life, regardless of gender or identity, sexuality, ethnicity, religion or disability ‒ with internal affinity groups.
Perk ME up
Once you get your feet in the door at ME, we’ll put them both in your very own ME-branded Converse shoes. You’ll also get the following financial, health and fun perks when you join the team:
4U Extras portal (discounts and cashback on 100s of items including cinemas, shopping and gym memberships
10% Myki discount
Purchased Leave programme
Internal wellness programme (Mindfully ME)
Professional education through LinkedIn Learning
Novated Leasing
Professional membership reimbursements
Health checks
Financial education (To help you manage your money smarter)
LGBTIQ+ and Women at ME affinity groups

I want those Converse shoes (and the role)
Can’t see a closing date on the advert? That’s because we’re pretty efficient here at ME and we may start looking at applications sooner rather than later, so if this role sounds like your jam, be sure to apply by submitting your resume today.

Should an applicant be the preferred candidate, background checks (including police checks, reference checks, ASIC banned and disqualified persons and bankruptcy checks) will be completed prior to the candidate's employment being confirmed. The outcomes of the background checks do not automatically bar candidates; however will be assessed against the inherent requirements of the job.
Back Share
Apply Now",3.0,"ME Bank
3.0",Melbourne,-1,501 to 1000 Employees,-1,Company - Private,Banks & Credit Unions,Finance,$100 to $500 million (USD),-1
Software Engineer - Machine Learning/Data Science,-1,"Zendesk is looking for a Software Engineer - Machine Learning/Data Science for a full time position in our Melbourne office.
As part of our engineering team, you will work at a scale where the challenges start to get seriously interesting. Our global engineering team is widely dispersed over the world, with people across nearly every continent. You will get a chance to do cool things with a diverse bunch of people while working in the Melbourne office that is home to Zendesk’s first machine learning (ML) research team.
The Data Science Team, together with Data Engineering, have built Satisfaction Prediction, Answer Bot and Content Cues — products that use Machine Learning (ML) and Artificial Intelligence (AI) to help our customers work more efficiently.
What you get to do every day:
We’re currently looking for someone to join our team as we research, develop, and productionise Machine Learning and Deep Learning models. In addition to frequenting Melbourne’s finest purveyors of coffee, ramen, and bulgogi, you may find yourself:
Building machine learning models including neural networks in TensorFlow
Writing and deploying production-grade Python
Querying and constructing datasets in AWS Athena, Spark
Evaluating and responding to real-world model performance
Scaling your ML to millions of predictions per day
Presenting your work to a broader audience
Watching your algorithm help Zendesk’s end-users
What you'll bring to the role:
A strong foundation in a quantitative discipline (e.g. machine learning, statistics, bio/eco/etc-informatics, econometrics, etc) is critical for this position. While experience in deep learning and natural language processing would be beneficial, your best qualities are:
dedication to continuous learning
collaborative work attitude
strong communication skills
You should also be comfortable with at least one programming language, such as Python, R or Scala.
Application Deadline: 18/11/2020
Job Types: Full-time, Permanent
Salary: $85,000.00 – $110,000.00 per year
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Temporarily due to COVID-19",4.5,"Zendesk
4.5",Melbourne,-1,1001 to 5000 Employees,2007,Company - Public,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),-1
Software Engineer (Machine Learning),-1,"About the Role
AdelaideMRI is building a medical reporting tool. We require an engineer to work primarily on machine learning projects to improve reporting speed and report comprehensiveness.
You will perform data analysis of medical report datasets and image datasets to infer sentence recommendations, image classifications, or other actionable results for the doctors.
Skills and Experience
Background in machine learning or image processing
Qualifications in Computer Science, Software Development or Engineering or equivalent experience
Bonus points for Python
No prior medical knowledge is required.
This position offers flexible hours and work arrangements.
Job Type: Full-time
Experience:
Software Engineering: 1 year (Preferred)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Yes",-1,Adelaide MRI,Australia,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Hey there, we’re PEXA!

We started as an idea: to deliver a single, national e-Conveyancing solution. We collaborated with the industry to create a national electronic lodgement and settlement platform: PEXA. From our humble beginnings, we’ve now grown to more than 320 employees across 5 different states. We’re still expanding at a rapid rate and constantly challenging ourselves to create great experiences for our members as they transition to fully digital conveyancing.

Why become a PEXArian?

Great question! Being a PEXArian is so much more than just a job. We are passionate, motivated & unashamedly enthusiastic at PEXA - we love what we do and we’re proud to admit it! Creating brilliant member experiences wouldn’t be possible if we didn’t also strive to create an amazing employee experience. Alongside our members, our employees are at the heart of everything we do.
Here’s a snapshot of what your life at PEXA could look like:

Your growth:
We encourage you to hit your personal and professional Learning & Development goals with our tailored programs and tools.

Your wellness:
We care about your holistic well being - a fully stocked kitchen, four wellness days, a $250 wellness subsidy as well as lunch and learn sessions to support your financial well being.

Your work/life blend:
We know that work is just one aspect of your life, we want to help you create your ideal work/life blend, rather than squeezing in life around work.

Your family:
With a range of benefits aimed at supporting your family including access to a subsidised school holiday program, extended parental leave and flexi-time to support your return to work, superannuation payments for unpaid parental leave for primary carers and a childcare allowance for pre-primary aged children, when we say, ‘welcome to the family’, we really mean it!
The impact you'd drive:
The successful candidate will be responsible for developing, and maintaining infrastructure to support the delivery of new and existing products. They will also be contributing to establish the rules and frameworks for obtaining the required approvals for new products.
On day one we’d love you to have:
Experience with Python, Spark
Event streaming/sourcing with Kafka or AWS Kinesis
Experience with data structures, formats and data security best practices
AWS experience (e.g CloudFormation, S3, ECS, Lambda, SQS, IAM, KMS, DynamoDB, Glue, Athena)
Query construction and optimisation (e.g. SQL, Elasticsearch, Splunk, DynamoDB)
Git, version control practices, and continuous integration/delivery servers
PyUnit and unit testing frameworks
Production release cycles and maintenance
Collaborating with technical and non-technical teams
Even better:
Agile methodology/delivery
GraphQL
Modern frontend technology (e.g. ReactJS, TypeScript)
Machine learning frameworks and tools (e.g. TensorFlow, PyTorch)
OAuth 2, SAML 2, JWT
Data visualisation and exploration tools (e.g. Jupyter notebooks, Tableau)
AWS SageMaker
Sounds like you?
If this role sounds like you, apply today to have your application reviewed ASAP!",3.9,"Property Exchange Australia Limited
3.9",Melbourne,-1,201 to 500 Employees,2010,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Ongoing position
Full time
Based in Sydney, NSW
Who we are
Australian Red Cross is part of the world’s largest humanitarian organisation. Our aim is to improve the lives of the most vulnerable people in Australia and across our region.
About the role
The Data Engineer role will sit within the Data and Integration Squad in IT and will own (design, implement and support) the AWS Big Data technologies such as the Data Lake and Data Warehouse and support the organisation in growing the data analytics capabilities at Red Cross. In addition to this, the data engineer role will also administer the Power BI tool and support the implementation of the data mastering capability.
What you will bring
Experience building and optimizing data pipelines, architectures and data sets.
Experience in dimensional modelling and building data vaults
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with structured, semi-structured and unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Why work for us?
Work for purpose and know that your work assists Red Cross support and empower people and communities in times of vulnerability.
Generous salary packaging options available that can increase your take home pay.
Further information
To find out more about this opportunity please see the position description below or contact Sharath Kumar Gurram on 02 8651 8839.
Position Description: Position Description - Data Engineer .pdf
Applications for this position will close at 11:55pm Thursday, 5 November 2020.",4.1,"Australian Red Cross
4.1",New South Wales,-1,1001 to 5000 Employees,-1,Nonprofit Organization,Industrial Manufacturing,Manufacturing,$500 million to $1 billion (USD),-1
Junior Fullstack Data Engineer (Python and React),-1,"Formbay is the leading Renewable Energy Certificate Trading company in Sydney. We provide Digital Workflow and Compliance solutions in the renewable energy industry and document processing.
Thanks to our meteoric growth and our commitment to be the best at all we do, we've identified the need to bring on board a new Junior Fullstack Data Engineer.
Reporting to our Principal Machine Learning Engineer, you will help build Machine Learning pipelines for our existing Digital Workflow and Compliance solutions to automate fraud detection and document processing over terabytes of photographic and documentary data – including documents, photos, GPS data and aerial/satellite photography.
Our stack is based on Python, JavaScript, Dask, Tensorflow, CUDA, Nix/NixOS, AWS, Docker, PostgreSQL and more – familiarity with these applications will give you a leg-up on the competition.
Our ideal candidate will have the following competencies:
SQL
Python
JavaScript/TypeScript
Our candidate must also be comfortable working with Linux.
Located a stone's throw away from the Queen Victoria Building in Sydney's bustling CBD, we are centrally-located with easy access to public transportation, bars, cafes and fine dining.
Formbay will provide flexible working hours, a generous remuneration package and the opportunity to work on a world-first software solution are what we can offer you. Free, twice-weekly gym sessions and really, really good coffee are also available.
No hiring/recruitment agencies need apply.",5.0,"Formbay
5.0",Sydney,-1,1 to 50 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is an experienced and qualified Data Engineer to join our IT team based in Birtinya.
Key Responsibilities:
Create and maintain data pipelines and or ETL scripts
Create and maintain data integration including API and Batch interfaces
Performed detailed data analysis
Create and maintain corporate data models
Create and maintain data visualization using Qlik.Sense , PowerBI or Simliar Toolset
Experience in defining, building and maintaining data virtualization and/or star schema data warehouses
Maintain, tune and optimise database, integration and visualisation toolsets
ABOUT YOU:
To succeed in this role, you’ll need to bring the following experience and skills:
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Excellent communication skills both oral and written, with an ability to bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking
Experience with data analysis and modelling will be beneficial

How to Apply
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kawana Waters,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Graduate Data Science / Engineer,-1,"The NRMA is an organisation looking to the future, and right now, we are on the lookout for people who can help us reach our goal: to continue to shape the way Australians move, for the next 100 years and beyond. www.mynrma.com.au.
Everyone new to the team, along with our current staff, will temporarily work from home until it is safe to return to our offices. All interviewing and on boarding will be done virtually due to COVID-19.


Your opportunity
As Graduate Data Scientist or Engineer you will be part of the Data Engineering team delivering cloud data transition program for business initiatives and supporting the entire data platform build.
Your key responsibilities will be to:
Implementing Concepts of Data Warehousing, Data Mart creations within Cloud
Use of SQL for data analysis and insights
Building AI/Machine Learning prototype for implementing and supporting existing algorithms
Data Analytical reports build, using different tool sets


Requirements for Success:
Relevant Degree - Computer Science, Computer Engineering, Software Engineering, Data Science
Excellent SQL skills and demonstrated working knowledge in Python
Demonstrated understanding in data structure and algorithms.
Knowledge and concept of data warehousing methodologies
Any reporting tools experience Tableau or Oracle Analytics Cloud, Looker is desirable
Exposure to Google/AWS/Azure/Oracle any cloud based platforms is desirable
Good communication and interpersonal skills

If you have the required skills and the passion to join our high performing team, please apply today.

Employee Benefits
To ensure our employees feel valued, empowered and celebrated we provide a range of employee benefits including:
50% discount on all NRMA insurances
Free Roadside Assistance
12 weeks paid primary and 4 weeks paid secondary parental leave
Free NRMA Blue Membership
At the NRMA Group, we are People Moving People and diversity and inclusion are part of our DNA. Together, we continue to build an inclusive culture that encourages, supports and celebrates the diverse voices of our employees. It fuels our innovation, promotes flexible ways of working and connects us closer to our members and the communities we serve.",2.5,"NRMA Motoring & Services
2.5",Sydney,-1,501 to 1000 Employees,-1,Nonprofit Organization,Casual Restaurants,"Restaurants, Bars & Food Services",$500 million to $1 billion (USD),-1
Data Centre Engineer,-1,"We are a leading world group that provides low-carbon energy and services. To tackle the climate emergency facing us all, our aim is to become the world leader in the zero-carbon energy transition ""as a service"" for our clients – particular for companies and regional authorities. We use our expertise in our key business areas (renewables, gas, services) to provide competitive and bespoke solutions.
The Data Centre Engineer will be employed as part of a 24/7 ongoing shift to coordinate and monitor third party service providers, maintain the data centre facilities and infrastructure plans, coordinate the implementation of customer requests within the data centre and monitor systems, all in accordance with the Contract KPIs and SLAs.
Coordinate and monitor third party service providers for regular maintenance & testing, service faults & call outs, ensuring works are performed in accordance with Contract SLAs
Monitor and maintain the data centre facilities and infrastructure plans and documentation, including electrical, mechanical, hydraulics, fire and BMS/EMS systems
Coordinate the implementation of internal and external customer requests within the data centre
Perform scheduled plant checks and minor maintenance works
Ensure all Work Order requests are raised and closed in a timely manner
Conduct inductions for staff, vendors and contractors
Ensure all work permits for vendor works are raised and closed
Perform inventory checks on all equipment and critical spares

Qualifications
The selected candidate must be able to demonstrate:
Electrical or HVAC background, or Graduate Electrical or Mechanical Engineer
Passionate about quality work and career minded looking for a new challenge
Can commit to a day and night shift roster (2 days of day shift, then 2 days of night shift, 4 days off)
Ideally able to commence asap
As part of carrying out the duties of this role, it is mandatory to hold Australian Citizenship.

If you are interested and meet the selection criteria apply with an up-to-date resume via the apply instructions on this website.

ENGIE Services is an EEO employer, where all applicants are treated with fairness and respect and have equal access to the opportunities available.

We will not be engaging in the services of a recruitment agency to fill this vacancy and therefore request all interested candidates apply directly to this advertisement.

Job
: Maintenance
Primary Location
: Oceania-Australia-New South Wales-Erskine Park
Organization
: ENGIE Services Australia and New Zealand
Schedule
: Full-time
Nature of Responsibility
: Senior operational / administrative role
Job Posting
: Sep 11, 2020, 6:29:59 AM",3.7,"ENGIE Services Australia & New Zealand
3.7",Sydney,-1,5001 to 10000 Employees,1995,Company - Public,Energy,"Oil, Gas, Energy & Utilities",$2 to $5 billion (USD),-1
Senior Data Engineer,-1,"Senior Data Engineer, Temporary, SYDNEY - McKell

Job Title: Senior Data Engineer

Salary: SNSW Grade 9/10 - The package includes base salary range of $111,806 to $134,667, plus employer's contribution to superannuation and annual leave loading.

Location: Head Office – Haymarket

Employment Status: Temporary through till 30th June 2021


About Service NSW:

Service NSW is making it easier for people and businesses across NSW to access government services. The role designs, builds and analyses complex data from multiple sources to identify revenue, process and business improvement opportunities; providing new information and insights to the business to inform planning, continuous improvement and performance.

About the Role

We are currently seeking to appoint a Senior Data Engineer to deliver expert advice and services in the design of a Single View of Customer and data-related services to support the achievement of business outcomes and strategic goals. We support flexible working practices with staff working remotely during this time.

In this role you will:

Design, build and support a modern data platform based in AWS and vendor technologies.
Provide expertise on data modelling for Graph data model and Customer Data Platform (CDP).
Create data pipelines, load, transformation and reporting workloads in AWS.
Work with the latest data engineering technologies like Apache Kafka, AWS Kinesis, AWS Neptune, AWS Glue and AWS Athena.
Contribute to the design and decision-making of the right tool or platform for the job according to requirements.
Provide expert advice and guidance on data quality and data engineering best practices.
Support a “bigger than you can imagine” scale of data in production environments.
Design, develop and support a metrics-driven reporting solution and a meaningful business intelligence platform.
Document the solution design and support procedures of solutions.
Produce reports, visualisations and recommendations to answer complex business problems that are presented in the most appropriate format to ensure clarity for target audience.
Analyse and define new process improvement opportunities to support continuous improvement and business outcomes; providing advice to stakeholders, on ways to improve the efficiency and reliability of data products and services.
Be very responsive to the information needs of the business by corresponding to customers in a timely manner and provide support/solutions to issues raised.
Troubleshoot and perform root cause analysis on production issues. Identify and implement long term solutions to problems. Perform scheduled maintenance, release deployment and production support activities after business hours, from time to time.
Liaise with internal and external customers to discuss and gather requirements, solutions etc. and maintain a good working relationship with the stakeholders.


Skills and Experience Required:

Solid experience with workflow technologies designing and building data pipelines, data models and data stores.
Experience working within and an understanding of Amazon AWS ecosystem, including security and performance tuning.
Hands on experience working with different types of databases, with focus on Graph and NoSQL databases.
Experience with data streaming required. Having used Kafka and related technologies is an added advantage.
Sound knowledge and experience working with batch processing, data extraction and API integration.
Hands on experience with at least one programming language: Java, Python or scripting.
Demonstrated experience working in an Agile based, fast paced, complex environment within cross-functional teams.
Experience developing systematised insights, data analytics and reporting solutions is an added advantage.
Experience with interactive visualisation of data insights is an added advantage.


Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Salary Grade 9/10, with the base salary for this role starting at 111,806 base plus superannuation

Closing Date: 6th November at 9:59am - applications will be reviewed on a rolling basis, applications may close early or extend

Please apply online, direct applications submitted via email will not be considered.

The Department of Customer Service is proud to be an EEO Employer who are fully focused on equality and believe deeply in diversity of all identities making us different and a true reflection of our NSW customers. As an inclusive workplace, we support various employee resource groups, practice flexible work and workplace adjustment.

If you do require an adjustment during the recruitment process, please notify us on your application form.",3.2,"Service NSW
3.2",Sydney,-1,501 to 1000 Employees,2012,Government,State & Regional Agencies,Government,Unknown / Non-Applicable,-1
Data Engineer - Entry / Mid Level,-1,"Work with a great team on interesting projects customers
Gain more experience in AWS, Data, DevOps cloud operations
Got a working knowledge of AWS? We will teach you the cool stuff!

Itoc is seeking an up and coming Data Engineer to join our growing Data Team in Sydney.

This is an exciting role working with databases, data lakes, data warehouses, data transformation (Python SQL) and enabling AI/ML.

You will be implementing foundational, robust and production ready data platforms to enable business data-discovery, self-service, AI/ML functions across a range of client types and industries, allowing them to do more with their data.

You'll be responsible for:

Deploying data repositories such as lakes and warehouses.
Contribute to our growing portfolio of data solutions.
Ongoing optimisation and management of data platforms.
Development of transformational logic for data pipelines
Data evangelism. We want to show our clients how to follow the best practices for data.

Desired Skills and Experience

To take up the challenge, you will have a depth of skills and experience including:

1-2+ yrs of focused data experience working with SQL and/or NoSQL solutions
A solid education in Software Engineering or equivalent industry experience.
Anything Data focused preferred.
Ability to analyse business scenarios and associated data landscape to derive potential opportunities.
Strong foundation in Python and SQL
Working knowledge of APIs
Principle knowledge of the different relational database platforms and modern data storage techniques
Knowledge of the different aspects of data environments
Collect, store, process, verify consume
Experience with version management systems (such as GIT)
Working knowledge of AWS or another cloud platform - we will teach you the cool stuff.
Great communication skills, an ability to work closely with customers, developers and engineers and the confidence to present ideas in open forums.
Relevant tertiary qualifications and/or industry certifications.
Great communication skills, an ability to work closely with clients, developers and engineers and the confidence to present ideas in open forums.

While not required, a background in consulting and professional services is highly desirable.

Itoc Description

This is an exciting and challenging career opportunity to join the growing Sydney-based Data Team of a leading cloud solution provider where you will be given support to reach your long term career goals. You will be part of a team of cloud experts and will work in an environment of continuous improvement and learning delivering innovative cloud solutions across SaaS, online business and enterprise business.

On offer is a chance to join a team with a great working environment, in an organisation that values its employees and sees the value in ensuring they are engaged. Our team are clearly passionate about what they do, that's why we won the following awards:

Customer Obsession Partner of the Year 2015: ANZ Region
Customer Obsession Leadership Partner 2015: re:Invent

As an employer of choice Itoc offers competitive remuneration, training and development programs and a great working environment. We value a healthy work life balance.

The Perks

MacBook or Dell
Continuous internal learning that will provide training and career development opportunities
Working with a collaborative, social team and leveling-up your skills faster than you will anywhere else.
Quarterly social events

Itoc

Culture and smarts are important to us. Bring your secret sauce. This is no ordinary environment, you will work along some of the Cloud’s best. All engineers at Itoc must gain at least five AWS certifications. We work hard but we have fun.

Please note you must have full working rights in Australia and be available on-shore for face to face interviews.

No recruiters please.",4.0,"Itoc
4.0",Sydney,-1,1 to 50 Employees,2013,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Date: 01-Oct-2020

Location:
Melbourne, VIC, AU

Department:Description:
Technology discounts - from Apple HP Lenovo to Windows
Flexible work arrangements - work in a way that suits you best
Salary packaging - to suit your personal and financial circumstances

Do you want to work for one of the fastest growing data teams in Australia? Do you want to work on multiple data platforms and provide new solution offerings by leveraging cloud and big data technologies?

About the team

Big data information and analytics. Three words that spark apprehension in most businesses. But our team of experts are constantly curious and excited about combining our wonderful array of technological expertise to transform data into our clients most valuable assets making their work smarter. Our data consultants are supported with resources training and tools they need to excel at their work but also the freedom and power to create their own paths forward to make a difference.

As a Senior Consultant in Big Data you will work closely with the team and stakeholders to build and deliver a Cloud based vision for a next generation Big Data analytics platform with strong focus on data quality data security and deliver the systems that process huge volumes of data.

What will you typical day look like?

You will play a pivotal role in - Designing and producing high performing and stable applications to perform complex processing of massive volumes of data in a new cloud based architecture; Building real-time data processing applications which are integrated with business systems to enable value from analytic models to drive rapid decision making; Contributing to system architecture design for a data platform (including cloud-based structures both on and off premises data warehouse components and data lakes); this could cover a range of technologies various countries/locations and lines of business; Support data strategy or technology strategy definition programs including technology stack definition and target operating model requirements

Enough about us lets talk about you:
You are someone with:
Use of traditional data analytics tools and techniques (e.g. MSSQL Oracle MySQL) and ETL software (e.g. SSIS Informatica CloverETL)
Working in large scale cloud data solutions using platforms such as AWS or Azure or GCP will be a bonus.
Experience in scripting or programming (e.g. Python Java Scala C#)
Excellent verbal and written communication skills to adapt to technical and non-technical audiences.
Educated to degree level (or have equivalent experience)
Why Deloitte?

At Deloitte we create positively differentiated work experiences that enable our people to feel valued and achieve their full potential. We value difference and embrace people with diverse backgrounds and thinking styles. Knowing that people work best in different ways we are happy to discuss alternative arrangements if the working pattern you are looking for is not specifically indicated.",3.8,"Deloitte
3.8",Melbourne,-1,10000+ Employees,1850,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Engineer,-1,"Opportunity to grow the team
Period of growth
Intuitive app
S2M are working with a FinTech who have created a unique financial product to help thousands of people better manage their finance, and is currently scaling the company to the next level!

They are looking for a Data Engineer to join, and looking for someone who wants to be hands on, with opportunity to grow the team in future.

Role:

Looking for people with strong AWS experience. You will need passion for data and a cloud, through which you will help a rapidly scaling Australian FinTech establish their data infrastructure from the ground up.
5+ years’ experience as a data engineer within the data and analytics domain
A python 3.X aficionado who is very comfortable creating and orchestrating AWS data pipelines with nothing but code
Strong project delivery toolset experience in open source data integration tools
Experience with processing large volumes of complex data including visualisation and insights generation
Ability to define and develop data integration patterns and pipelines
Ability to assess complexity of data (volume, structure, relationship etc.)
Hands on experience working with different databases (RDBMS, NoSQL, Blob storage etc)
Hands on technical expertise setting up DevOps automation
Hands on experience working technologies/platform e.g. AWS, Dockers, Containers
Experience building data profiling and data cleansing frameworks
Technical reconciliation and reporting
Knowledge and experience in end-to-end project delivery, either traditional SDLC or agile delivery methodologies (or hybrid approaches)
Exceptional communication, documentation and presentation skills
If this sounds like you, get in touch today - kate.gabb@s2m.com.au
3167410agsdf",3.1,"S2M
3.1",Sydney,-1,Unknown,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Analysts,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is seeking experienced and qualified Data Analysts to join our IT team based in our corporate office in Birtinya (Sunshine Coast) or at our meat processing facility in Kilcoy.
Key Responsibilities:
A mixture of data analysis and commercial skills to source, blend and analyse data to gain insight and answer key commercial questions
Working with strategic leaders to define and model Key Performance Indicators, and assist in building forecasting models
Working closely with data engineers and BI developers to specify data pipelines and report visualisation
Drive the creation and implementation of data quality business rule including data definition, governance and quality assurance
About You:
To succeed in this role, you’ll need to bring the following experience and skills:
Proven ability to derive insight and knowledge from data using commercial expertise is a strong requirement
Strong SQL and Excel skills are essential, along with strong data analysis and commercial insights
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Effective people communicator - engage with stakeholders on reporting needs, interpret requirements into visual solutions and train/deliver the outputs to the stakeholders getting signoff of acceptance
Bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking

How to Apply:
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kilcoy,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Network Data Engineer,-1,"Min 6+ years of experience in the relevant technologies
Australian Driving License for visiting remote locations / Data Centre for day to day technical work.
Managing Network devices (switches, routers, firewalls, load balancer, and wireless technology)
Performing MACD activities for all network devices.
Supporting BAU operation activities.
Proficient in performing in-depth details of technical troubleshooting, cause and provide recommendation to the client for incidents causing extended network outage to client’s critical locations.
Provide exceptional network services in terms of network support, break-fix, design and consulting, new projects, implementation.
Configure, administer, and document firewall infrastructure.
Manage the firewall deployment, rules migrations, and firewall administration.
Supporting Cloud Migration Activities from traditional to AWS/Azure.
Setting up VPN tunnel with Cloud and 3rd Party network devices.
Integrating and upgrading existing ISP bandwidth with support from ISP Vendor.
Setting up VPN profiles for Users.
Installing hot fix and patches to mitigate the security devices from attacks and bugs.
Reviewing and fine tuning the firewall rules and NAT rules.
Documentation and change control.
Mentoring, Motivating and Guiding support teams
Technical skills:
o LAN
o Wireless
o WAN
o MPLS
o Routing protocols (OSPF,BGP)
o DMVPN
o Azure cloud Networking
o Network Security
Fortigate Manager / Analyzer / Firewall
Cisco ASA
Firepower FTD
Cisco Any connect
Site to Site VPN
F5 Load Balancing and Scripting iRule
Job Types: Full-time, Contract
Schedule:
8 hour shift
Experience:
Scripting: 5 years (Required)
Data Network: 5 years (Required)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Required)",3.6,"Total IT Global
3.6",Sydney,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Engineer - Processing & Analysis,-1,"Job Description:
Design,build and maintain the ingestion system to support various types of data(e.g. User behavior, RDS, NoSQL db and others) to be ingested to the data warehouse more timely and accurately
Translate data requirements into scalable technical data service with low latency and high concurrency
Design,build and maintain the batch or real time data pipeline in production using Hadoop big data technology
Analyze and improve efficiency, scalability, and stability of the system
Define and manage SLA,Data quality for all data sets in allocated areas of ownership
Requirements:
Minimum B.S. degree in Computer Science or a related technical field
2+ years of working experience in programming languages,such as Java,Scala,Python
Familiar with Hadoop, Spark and Flink data processing, experience of TB data processing experience is a plus
Familiar designing and operating of a robust distributed system is a plus
Understand data mining or machine learning
Excited to work intimately with data
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"SYNOPSIS:
Lead Data Engineer
Applications close Sunday 8 November 2020
Ongoing
Contact name: Shyni Sasikala
Phone: (02) 6249 9048
Email: Shyni.Sasikala@ga.gov.au

The Data Policy and Informatics section within the Digital Science and Information branch creates, implements, and promotes policies, platforms and tools that improve and support the quality, discoverability, accessibility, and general usability of Geoscience Australia’s science data products. The section consults with internal and external research, government and industry partners to establish collaborative data frameworks, architectures and models within Geoscience Australia (GA) and across broader national and international communities of practice. The section innovates, builds and maintains tools, systems, processes and governance that enable digital data management, cataloguing and open data delivery.
GA makes accessible a wide range of geoscientific and spatial data to a wide variety of stakeholders in multiple formats, and in recent years GA's data volumes have grown exponentially. GA is focussed on making its data and metadata assets accessible so that they can be used in machine to machine interactions for data analytics and other applications in environments that range from High Performance Computing (HPC), through high-end cloud servers, to mobile devices.
We currently have two opportunities for Lead Data Engineers in the Informatics team. The Lead Data Engineer is responsible for innovating and exploring new technologies that will advance GA’s science goals and maximise the uptake and use of GA’s science data. The Lead Data Engineer reports to the team’s Assistant Director but also works closely with other developers, data scientists and engineers within the Digital Science and Innovation (DiSI) branch, as well as diverse stakeholders both within and external to GA.",3.9,"Geoscience Australia
3.9",Canberra,-1,501 to 1000 Employees,2001,Government,Federal Agencies,Government,$100 to $500 million (USD),-1
Data Engineer,-1,"The Seven Network is part of Seven West Media, one of Australia’s most prominent media companies, with a market leading presence in content across broadcast television, online and in print. Comprising some of Australia’s most renowned media brands, SWM includes not just Seven Network and its affiliate channels 7two, 7mate, 7flix and BVOD offering 7plus, but also 7NEWS.com.au, The West Australian, The Sunday Times and more.
At Seven we are here to bring all Australians closer to the moments that move us - we’re first on the scene, with our finger on the pulse, on demand, in the moment. Together, we’re responsible for creating and sustaining authentic Australian engagement.
A new and exciting opportunity has opened for a Data Engineer to join the Audience Intelligence team. Based in Sydney and reporting to the Head of Data Enablement, you’ll be responsible for:
Implementation of end to end data solutions to support Data Strategy for the SWM group.
Work closely with the Data Solution Designers to develop and maintain scalable data pipelines and build out new file and API based integrations to address requirements from the various business stakeholders.
Collaborates with engineering, analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organisation.
Work on Data Preparation for analytics and data scientist team members and assist them from an engineering perspective in building and optimising the models including building the automation of the end to end workflows
Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.
Perform data analysis required to troubleshoot data related issues and assist in the resolution of production data issues.
Work effectively with vendors for successful delivery of projects and acceptance of the solution
Work on Delivery projects using Agile Software Development methodologies
We are looking for someone who has:
Bachelor's degree in computer science, computer engineering or other technical discipline is essential
Proven experience working as a digital analytics specialist
Extensive experience with digital analytics implementation (e.g. Google Analytics, Snowplow, Adobe Analytics) and BI processes and visualisation platforms
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience in ETL and building and optimizing ‘big data’ pipelines and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Experience with big data tools: Hadoop, Spark, etc., AWS cloud services: EC2, S3, Lambda and familiar with version control systems: Git
Strong coding skills with knowledge of Unix/Linux and scripting languages such as Unix Shell scripting, Python desirable
Experience supporting and working with cross-functional teams in a fast-paced environment.
Ability to multi-task and problem solve with changing demands and priorities
Ability to work under pressure to meet deadlines and detail oriented
Your success is our success: we will provide you with opportunities for you to keep learning and growing, enabling you to challenge and develop yourself. In return, we offer a benefits program that has something in it for everyone.
Seven West Media is an equal opportunity employer and we are committed to creating a diverse and inclusive workplace.
Recruitment Agencies: Seven West Media does not accept any unsolicited agency resumes and will not be responsible for any fees related to unsolicited resumes.
Advertised: 19 Oct 2020 12:00 AM AUS Eastern Daylight Time
Applications close:

Back to search results",2.5,"Seven West Media
2.5",Sydney,-1,5001 to 10000 Employees,1956,Company - Public,TV Broadcast & Cable Networks,Media,Unknown / Non-Applicable,-1
BICON Rules Engineer,-1,"APS 5 - $73,299 - $80,410 per annum plus superannuation
Biosecurity Plant Division
Canberra, ACT
Play an active role in managing biosecurity risk to Australia
Work in a motivated and professional team with a wide range of skills and backgrounds
Full training provided

Who we are
The BICON Content Development Team maintains and improves the Biosecurity Import CONditions database (BICON) content to allow external clients to understand and comply with their biosecurity obligations and internal clients to effectively manage biosecurity risk and regulate imports. We work collaboratively with internal clients to comprehend and implement their BICON content requirements and optimise the use of BICON to publish clear import requirements and onshore management support procedures to effectively manage biosecurity risk.

The Jobs
Key duties of these positions include:

working with business content (import and permit conditions) and import programs to understand and construct decision tree structures in the BICON database, in accordance with system design and authoring conventions
executing changes to import and permit conditions in alignment with service standards while complying with system rules and authoring conventions
providing technical advice through various formats on the most appropriate means of authoring BICON content to achieve import program and stakeholder objectives
using workflow management tools to maintain detailed records of changes to import conditions and key decisions
performing administrative tasks including system reporting, data analysis and scoping tasks for the BICON content change work program
contributing to the development and maintenance of instructional material, authoring conventions and courseware
clearly documenting and reporting system issues
developing and maintaining effective working relationships with internal and external stakeholders.

What we are looking for
Knowledge and experience
Experience working with complex IT systems.
Experience working collaboratively and as part of a team.
Knowledge of the role of biosecurity is preferred but not essential.

For additional information, please read the Job Description below.
Candidate Information Package docx Opens in new window",3.9,"Department of Agriculture & Water Resources
3.9",Australia,-1,5001 to 10000 Employees,-1,Government,Federal Agencies,Government,$500 million to $1 billion (USD),-1
Cloud Data Engineer,-1,"Job no: 509605
Work type: Permanent Full Time
Location: Melbourne, Canberra, Sydney
Do you embrace digital disruption?
Do you love solving complex problems, designing sophisticated solutions and building innovative technology?
Do you believe in creating powerful actionable insights from Data and Analytics?
Do you want to work in a diverse and flexible working environment?
KPMG is one of the most trusted and respected global professional services firms. Through depth of expertise, clarity of insight and strength of purpose we help our clients solve complex challenges, steer change, strengthen, transition and grow. We are a team based practice and this extends to our clients whom we work and collaborate with, in solving complex problems. Together, we design, innovate and implement, providing enduring advice that support our clients and the services they deliver. Our clients vary in size and come from a diverse range of sectors – all sharing in a common goal: to embrace change and deliver services that make Australia a better place. We are looking for talented individuals who would like to join us on the journey.
KPMG’s Digital Delta Team
We re-imagine and re-invent organisations to become world class digital enterprises using advanced technologies, data and human insights. We help organisations to embrace Digital Strategy, Artificial Intelligence (AI) & Cognitive, the Internet of Things (IoT), Data, Analytics & Modelling, Mobile App & Web, and User Experience (UX) & User Interface (UI) and more.
We work with clients to:
Formulate strategies that re-imagine organisations
Harness innovation from the 4th industrial revolution
Actioning insights from trusted data to consistently and quickly make clear decisions
Build adaptive organisations
Thrive as a connected enterprise – front, middle and back office
This is how you’ll contribute:
We are looking for ambitious Data Engineers who are passionate about helping clients define bold ambitions and deliver on them. Joining our team will take you on a journey of personal and technical growth and provide the opportunity to inspire confidence and empower change.
As a Data Engineer you are the designer, builder and manager of the information or ""big data"" infrastructure, preparing data for analytical or operational use. You will design, construct, test and maintain a data pipeline to pull together information from different source systems; integrating, consolidating and cleansing data; and structure it for use in individual analytics applications.
The KPMG Difference
Our people are focused on creating a diverse and dynamic environment that embraces and values differences. We value the variety of unique experiences, qualities and characteristics our people possess and we share and learn from each other.
We are proud to be consistently recognised as an employer of choice for women, and for our achievements in LGBT+ workplace inclusion.
Our commitment to ‘Flexibility’ allows our people to manage the changing demands of work, personal or family life. Explore the links below to hear our people share their experience @ KPMG:
Flexibility empowers wellbeing
Flexibility enables contribution to the community
Flexibility inspires technology & innovation
Flexibility supports family

Make KPMG the clear choice for your career and be Extraordinary!

Advertised: 09 Sep 2020 AUS Eastern Standard Time
Applications close:",3.8,"KPMG
3.8",Sydney,-1,10000+ Employees,1987,Subsidiary or Business Segment,Accounting,Accounting & Legal,$2 to $5 billion (USD),-1
Computer Network and Systems Engineer,-1,"Duties Include but are not limited to:
Tasks Include:
analysing, developing, interpreting and evaluating complex system design and architecture specifications, data models and diagrams in the development, configuration and integration of computer systems
researching, analysing, evaluating and monitoring network infrastructure to ensure networks are configured to operate at optimal performance
assessing and recommending improvements to network operations and integrated hardware, software, communications and operating systems
providing specialist skills in supporting and troubleshooting network problems and emergencies
installing, configuring, testing, maintaining and administering new and upgraded networks, software database applications, servers and workstations
providing network programming in support of specific business needs and requirements
preparing and maintaining procedures and documentation for network inventory, and recording diagnosis and resolution of network faults, enhancements and modifications to networks, and maintenance instructions
monitoring network traffic, and activity, capacity and usage to ensure continued integrity and optimal network performance
Skills and Experience Required:
Must have experience working in a Managed Service environment
Demonstrated experience in IT Networks and Data Centres
Understanding of systems and architectures to meet client needs
Experience in Help Desk including break / fix
Effective and timely documentation
Effective Task Management Skills
Be solution and outcome focused and willing to learn new technologies
Excellent communication skills with staff, clients and partners
Time management, ability to prioritise and deliver to schedule
Experience with N-Able and Connectwise desired
Open Cabling license desired
Job Types: Full-time, Permanent
Salary: $30.00 per hour
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,Trans-plant training,Canberra,-1,-1,-1,-1,-1,-1,-1,-1
Software Engineer (Data),-1,"If you are looking for an opportunity to make a real impact with smart people who are genuinely doing things differently then you've come to the right place! We're growing our data engineering capabilities and are looking for awesome data engineers to join our team.
With our diverse range of clients and projects, no day will look the same - but here's a great snapshot of what you'll be doing:
Work with some of the best Data Scientists and Engineers to deliver production-grade AI and Machine Learning systems as we deliver client projects from inception to production.
Consulting with our clients and working with them to build modern data systems using the 'best of' technologies and principles.
Advising clients on data strategy, architecture and technology.
Applying best software engineering practices in coding, monitoring and alerting, using CI/CD, TDD and cloud architectures.
Working over a wide range of big data tools and environments: not limited to; Apache Kafka, Spark, Python, Scala, Hive, Airflow, AWS EMR & Glue, GCP Dataproc & Dataflow, BigQuery, Snowflake, Redshift.
Who are we?
Glad you asked! We are Eliiza. Data science. Engineered for scale.
We are a passionate team of data scientists and engineers who apply data science and machine learning to solve real-world problems. Our mission is to create a bright future for Australian businesses and society in a world increasingly influenced by intelligent technologies.
We've created a culture that values diversity where people can truly be themselves! We care a lot about growing the Australian AI community in a positive direction, and we're doing several things to try and achieve that:
We provide opportunities for underrepresented groups to work in AI through our associate and intern programmes
We organise and participate in a range of community events, reading groups and meetups
We produce the AI Australia podcast
We blog about topics we care about
We stream brown bag sessions to the broader community
We're also part of Mantel Group's 'house of brands' which means it's not just the Eliiza team you'll work with, learn from and see at social events - there's another 230 of us across DigIO, Kasna & CMD Solutions!
So you're ready for something new?
We're keen to know more about you! Our team is made up of a range of people, with different experience across a huge range of data driven skill sets.
We'd love to hear from you if you have experience with:
one (or more) core language(s), ideally Scala, Python or Java
one (or more) cloud platforms, AWS, GCP, Azure
ETL/ELT concepts and technologies e.g. Data partitioning, Hive, Spark
streaming data concepts and technologies, ideally Kafka (Kinesis, Beam or Pubsub will do)
We'd be over the moon if you:
Experience with distributed/columnar databases (e.g. Snowflake, Big query, Redshift).
Experience with any of a variety of databases e.g. RDMS, NoSql, Columar, Distributed, Time series, Graph.
Knowledge of job orchestration and scheduling. Any experience with Airflow, Luigi or Oozie.
Experience with containers and container orchestration (Docker, Docker Compose or Kubernetes).
However, we value a diversity of skill-sets, and don't necessarily require that you're skilled with all of the above. If you feel you don't fit all the experience/skills listed above we still encourage you to apply or get in touch.
What's on offer if you join us?
We make sure you're always one step ahead by investing your learning and development, every year. We build our own training where it doesn't exist yet.
We hire smart people and get out of their way. By focusing on our five principles and not getting caught up in red tape, we trust you to get the job done.
You'll get all the tools you need - a new iPhone or Google phone, a new Macbook Pro or Dell, and a lot of branded swag!
But hold on, you mentioned a house of brands?
We certainly did! Mantel Group is an Australian-owned, 'house of brands' company with four technology businesses (Eliiza being one of them!) across Melbourne and Sydney. We're building a group of companies with open borders so we can support you to take on new skills without leaving an awesome team - we understand you won't have one job for life!
We may only be just two years old but Mantel Group has already been recognised #9 in the 2020 Best Places to Work in Australia and #4 in the AFR's 2020 fastest growing new companies.
Keen to chat?
Click ""Apply"" to share your details with our talent team, and we'll be in touch.
In the meantime, check out 'how we hire' to find out what's in store if you're successful and get to know us better by visiting our website and following Eliiza on LinkedIn.",-1,Eliiza,Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Infrastructure Engineer,-1,"Job Description:
Design and grow the Shopee data platform to support a variety of big data applications using open-source technologies including Kafka, Hadoop, Presto, HBase, Spark, Hive, Druid, and our own creations. Some examples include a real-time data streaming platform, a unified query platform, a cluster management system, and a machine learning platform
Dig into the source code of some open-source big data system to get the whole control and familiar with the details, configurations, designs and source code. Develop and maintain the internal release of big data systems and components as the business requirements.
Keep close and overall monitoring for all the deployments of the systems, maintain the system’s stability, improve the performance, discover the performance bottlenecks, tracking and troubleshooting, cost optimisation.
Requirements:
B. Sci. / Ms / PhD in Computer Science or a related technical field
Familiar with at least one of these languages: Java, Scala, Python, Bash under Linux / Unix. Scala is a plus
Familiar with the use and compute logical of SQL
Knowledge about the Big Data Infrastructure system technology like Distributed File System, Distributed Computing, Distributed Database will be a plus
Hands-on experiences Hadoop, Spark, Kafka, and/or Presto will be a plus
Love to use and develop open-source technologies
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"Work on an award-winning, international technology!
Endless career opportunities
An innovative, friendly team of 300+
This role will be focused on the development of our existing ClaimLogik line of products as well as working on our new cloud-first, modern suite of applications.

Intelligent Thought, our technology business is scaling and shipping our software globally. Already profitable, part of a much larger group business, with investors such as Macquarie Capital and Envest – we are all set to deliver textbook disruption to the Insurance Industry. The growth of the platform, of our customer base, and the increasing industry demand have led to the need for this role to help the team scale.

Our Philosophy
Give each employee a sense of purpose and an environment for them to connect the importance of their role to delivering a service that matters to our customers.
Challenge the ‘why’ of traditional claims processes.
Keep it simple – do only what brings value and what matters to the customer
Enable employee decisions, empower our people
Responsibilities:
Create, extend and maintain ETL pipelines to form our data lake, data warehouse and analytics platform (currently using the Microsoft Azure set of tools and service)
Help define the optimal data pipeline architecture
Influence the tool selection, platform selection, data architecture and strategy which will transform the business to be truly data-driven
Understand, analyse and size user requirements
Work with different parts of the business to provide them with the insights they need to deliver the best results
Skills & experience:
Degree or qualification in computer science or related
Advanced knowledge of relational database, including query authoring and query optimisation (MS SQL Server and PostgreSQL).
Experience building and optimising ETL pipelines
Experience designing complex data models
Experience working with cloud platforms (Azure or AWS)
Efficient time management and organisational skills
High attention to detail and accuracy
Effective communication skills to build strong working relationships; both written and verbal
Proactive and results-driven
Why Claim Central?
Claim Central Consolidated is a global insurance industry leader across, claims management, insurance technology and data and analytics. Currently operating in the United States, Australia, South Africa, Italy and New Zealand, we have pioneered digitally connected claims management services across the globe. Claim Central is a disruptor and thought leader in the industry and we were recognised as the Australian Financial Review’s 8th Most Innovative Company in Australia in 2016. This business is in a period of unprecedented growth, transitioning our technology and services into multiple geographies at a rapid pace. Our unique culture is based on teamwork, collaboration, trust, respect and performance. We also offer many benefits apart from our exceptional team culture; including flexible work arrangements, and continued professional development.

Be a part of this journey in a career-defining role.",-1,Claim Central,Matraville,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer - AI/ML,-1,"Our client provides services to a major industry across the country. The business is still early in it's days of technology development and the environment is greenfields in nature (no pun intended), effectively working like a start-up.

Their data and analytics team have worked and built leading and bleeding-edge technologies in this space and what they have created so far may be game-changing. From a machine learning perspective, the progress they have made to the business has already seen proven success in changing the future of an industry that will have positive consequences for all those involved.

You will have previously worked in a technical capacity in the data and analytics space and have experience working with an organisation where machine learning has been implemented, not just a concept that the business talks about having or the technology team would love to have. The commercial experience you will have had in the ML field will be proven examples of where you have affected the way a business or industry used to perform, to the changes that have come about from this.

Technically, you will have extensive experience in the Microsoft space - Power BI, Azure etc and you will have previously mentored and coached junior members of the teams you have been part of.

This is a rare opportunity in Brisbane where the business has truly embraced and funded projects across the ML space and would be a great chance for those in the Data Development/Data Engineering field, who are looking to move into a Data Scientist role in the future.

Please send your application through if you would like to know more.",4.0,"Emanate Technology
4.0",Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Solution designer/ ETL Engineer & Data Modeller,-1,"We are looking for a Qualified and Experienced Solution Designer to join our client for a period of 6 months with a view to extend.
You will work closely with team members and your contribution will range across gathering and analyzing information, developing and documenting improved processes and work instructions and experienced DWH Lead with skills in requirement analysis, solution designing, developing, testing and supporting ETL solutions.
A hands-on solution designer, data modeler and ETL developer for Data Warehousing and ETL application transformation projects using Informatica PowerCenter.
Knowledge on AWS, S3, Redshift, Informatica BDM, and related technologies.
Experience working with IPython, PySparks, AuCuMo, Airflow, Jenkins, Github, Athena, JIRA, Rally, Spectrum, Glue, Flyway.
Good exposure on Oracle PL/SQL, aware of DBA activities, writing and performance tuning of complex SQL queries.
Contract length: 6 months
Job Types: Full-time, Contract
Salary: $650.00 – $800.00 per day
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,nducive,Melbourne,-1,-1,-1,-1,-1,-1,-1,-1
"Data Engineer, Wollongong NSW or Mount Waverley VIC",-1,"Company Description
BlueScope is a technically advanced supplier of steel and steel products in Australia. We are an inclusive organisation and every day we showcase our technology and expertise throughout the world.

Job Description
We are looking for two Data Engineers to join our IT team, based in Wollongong NSW or Mount Waverley VIC. Use your experience in analytics to unlock business value, enabling use of big data for insights and decision-making.
Reporting to the Data Product Owner for our Australian Steel Products (ASP) business, this position will support strategic goals related to data. This will see you:
Gather business and technical requirements with the view to deliver outcomes;
Develop and implement end-to-end data collection, consolidation, modelling and visualisation solutions;
Document metadata in a dictionary and catalogue;
Ensure consumers of such information understand its accuracy, timeliness, quality and sensitivity, so that it is used appropriately; and
Identify opportunities to enhance analytics.
What are the benefits?
Work in a supportive and collaborative team environment whilst we embark on a journey to transform the way our business uses data!
Our systems landscape is broad and diverse. You will be encouraged to think creatively to develop data solutions which solve real business problems.
Working in this role you will enjoy:
the chance to learn more about data science;
salaried remuneration with attractive superannuation options;
the opportunity to participate in a performance incentive scheme; and
access to further development and career opportunities with BlueScope.
Who are we looking for?
We welcome applications from professionals with experience in data analytics and/or programming. Supported by your knowledge of project delivery methods (e.g. Agile), you will demonstrate:
experience with data mining, wrangling, mapping and visualisation techniques (e.g. Azure Data Factory, Databricks and/or DevOps etc.);
well-developed ability in gathering business and technical requirements;
skills in developing and implementing collection, consolidation, modelling and visualisation solutions; and
a passion for sharing your knowledge and desire for ongoing professional development.

Qualifications

null

Additional Information
We're proud to have been named an Inclusive Employer for 2019–2020 by the Diversity Council of Australia. We believe that our people are our strength. Having a diverse and inclusive workplace enables us to improve our capability and ensure continued, sustainable success.
We know that workplace flexibility can mean something different to everyone. Under our B-Flex initiative all of our roles have some degree of flexibility. We encourage you to discuss your needs with us.
Applications close Sunday 25th October 2020.",3.3,"BlueScope
3.3",Wollongong,-1,201 to 500 Employees,-1,Company - Private,Construction,"Construction, Repair & Maintenance",$100 to $500 million (USD),-1
ETL Data Engineer,-1,"ETL Data Engineer

Join a team that’s changing how Australia lives, works, plays and grows
We want you to be the best version of you

Work with innovative teams and explore new technologies to help solve real-world problems.

A typical day as a Data Engineer

ETL / Big Data Engineering professionals will be responsible for guiding the full lifecycle of a Data solution, including:
Working in highly client-facing roles to contribute throughout the end-to-end delivery lifecycle of complex and large-scale digital solutions
Use case and business case development
Support existing and new applications utilizing in-depth technical and data knowledge. Troubleshooting complex issues and providing advisory services to improve the client’s data landscape
Help to streamline and simplify the clients’ complex data landscape by integrating different applications and data architectures
Implementation from requirements analysis, platform selection, digital architecture design, application design and development, testing, and deployment
Interstate travel may be required

Basic qualifications:
Bachelor’s degree
Experience across systems integration, information management, data management and architecture, and business analytics
Experience with being in a team focusing on large-scale, multi-release information centric projects
Experience with waterfall and agile delivery and run / application support functions
Part of a team working on End to end implementation of at least 1 big data project

Preferred Skills:
Hand on experience in Data warehousing using ETL tools such as DataStage, Autosys and TeraData
Hands on experience in ETL job development with multiple stages like sequential file, Transformer, Lookup, join, sort and Database stages.
Strong hand on skills in design, development and implementation of various data remediation, Data migration, data integration techniques.
Strong hand on data modelling experience.
Strong hands on experience in database performance tuning including complex query optimizations and physical database tuning using Teradata.
Understanding of architectural designs and strategy related to data migration, data cleansing, data quality and data consolidation.
Proven data analysis, requirement gathering and problem-solving skills
Exposure to Unix environment and shell scripting.
Experience in Banking and Financial services industry
Desirable: Knowledge of cloud computing infrastructure (e.g. Amazon Web Services EC2, Google Cloud, Microsoft Azure)
About Accenture

Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. We combine unmatched experience and specialized capabilities across more than 40 industries — powered by the world’s largest network of Advanced Technology and Intelligent Operations centers. With 513,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises. Visit us at www.accenture.com.

Accenture is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, marital, domestic or civil partnership status, sexual orientation, gender identity, or any other basis as protected by applicable law.

Vera Goga is the Recruiter managing this role. As the team experience high volumes of applications, we appreciate your patience to allow for a fair and timely process.",3.9,"Accenture
3.9",Sydney,-1,10000+ Employees,1989,Company - Public,Consulting,Business Services,$10+ billion (USD),-1
Student Engineer,-1,"The candidate will have the ability to:
Undertake onsite inspection to collect asset condition data based on the relevant engineering standards and technical guidelines;
Undertake desktop analysis to evaluate the condition and performance of the assets;
Provide the appropriate information, advice, engineering input and support services for the sustainable management of Council’s stormwater and transport networks.
Qualifications:
The successful candidate will be enrolled in a Bachelor of Engineering with a minimum of two years completed.
Position Number: 100678
Position Hours: Fixed term (3 months), hours will be negotiated with the successful candidate, maximum of 75 hours per fortnight.
Salary: Schedule A, Salary Point 4.0. $28.64 per hour ($55,853.45 per annum, pro-rata) in accordance with Glenorchy City Council’s Enterprise Agreement 2016
Please note that all successful applicants will be required to provide a current National Police Check prior to commencement of employment.
For further information on this position, contact Patrick Marshall, Senior Civil Engineer on (03) 6216 6800.
How to apply: Applications for this position must be lodged on this submission site or on the Glenorchy City Council website www.gcc.tas.gov.au - Careers page.
To be considered for this role, all applicants must address the key selection criteria in the and provide a current resume. A copy of the position description can be found by clicking the below hyperlink or on the Glenorchy City Council website.
Applications close at 8pm on Sunday, 1st November 2020
- Student Engineer",4.0,"Glenorchy City Council
4.0",Glenorchy,-1,501 to 1000 Employees,-1,Government,-1,-1,Less than $1 million (USD),-1
Data Engineer involving DevOps,-1,"Data Engineer involving DevOps
Axiom Technologies is an Australia based entity with the history of providing Managed IT solutions to medium to large scale enterprises globally. Please visit our website for more information about what we do at www.axiomtechnologies.com
Axiom Technologies is an Equal Opportunity Employer and encourage applicants from all backgrounds and gender to apply, including, Aboriginal and Torres Strait Islander candidates
Job Requirements:
8+ years IT experience, with at least 5+ years of “Data Engineer/Deveoper” focused titles/roles,
Data Tools: Hands on experience with Apache Beam.
Testing: Hands on experience with automated testing activities/outcomes
DevOps: Experience with the processes involving Microservices facilities for artifacts developed
Platform/OS: Mid-range/Unix
Languages: Unix (Shell) Scripting/commands, SQL, Python
File formats: Text, CSV, Parquet, JSON, XML
Scheduling: Jenkins, Airflow
Auto Scripting: Designing/creation of scripts for repetitive activity. E.g. Unix scripting/SQL
Big data: Exposure to Data Lake Concepts, Hive (Schema), HDFS
Source Control tools: GIT
Delivery Models: Agile, Scrum
Ingestion Design: Create/assess Source/Target data mapping designs
Frameworks: Development and delivery frameworks
Activity Reporting/Repository: Jira, Confluence.
Quality: Accuracy and attention to detail
Industry: Financial Services/Banking
Solutions: Define solutions from High level to detail design to address automating ingestion activity. Facilitate/confirm requirements from product owners, business team members and technical associates,
Process Automation: Automating processes in file management, testing data in files, analysis and design, configuration management.
Script Automation: Ability to design/create scripts to automate/improve data copy/migration/ETL for any repetitive activity.
Languages: Java, Python
Scheduling: Control-M
Databases: Relational. E.g. POSTGRESS, Oracle – as a ETL developer
File Formats: Mainframe – experience with referencing its data formats/copybooks
Big data: Experience referencing/using Hive (Schema) to access data in HDFS
Metadata management tools: MDM, EDC and Axon
Performance: Assess, recommend, improve mappings, SQL queries, Batch feeds
Automation Tools: Other tools that may add value to an automation program and generally support development. E.g. API, REST, JDBC, Webservices, Message Queues/Load balancer,
Cloud: Experience with processing of data files to be ingested/stored in the Cloud, preferably with AWS.
Prod Support: Experience in a production support role performing root cause / impact analysis – under time constraints
Experience in a similar role
8+ Years
What next?
If you are looking for that next challenge in your career and wish to apply for this role, please forward your resume to careers.au@axiomtechnologies.com",2.0,"Axiom Technologies
2.0",Melbourne,-1,1 to 50 Employees,-1,Company - Private,Industrial Manufacturing,Manufacturing,Less than $1 million (USD),-1
Data Engineer,-1,"About the Role
We are on an exciting digital journey so it’s a great time to join ME! We are seeking a Junior Data Engineer who enjoys rolling up their sleeves, learning and growing. As part of our Enterprise Data Team, you will ensure fit for purpose data warehouse solutions are built for use across the bank and by utilising best practise ETL standards, whilst ensuring the data is trusted by our BI developers and key business consumers. Oh, and you’ll get to work on Microsoft technology stack too!
You will be involved with investigating data issues, keeping data feeds flowing and collaborating with different projects across the bank to deliver quality data solutions. How important does that sound? What’s even more important is this role contributes directly to our overall business strategy through the provision of data to enable analytics & reporting, as well as supporting business and decision system processes.

About You
You’re naturally a highly motivated and energetic person who thrives in a dynamic, ever-changing collaborative team environment. Ideally you have previous experience as an ETL developer, Data Engineer or a BI developer, and if you have a degree in computer science or similar it would really put you ahead of the rest.

With your knowledge of SQL coding, data modelling, understanding of data warehouse concepts, plus experience of working on complex ETL solutions, you’re ready to expand your horizons and launch your career into the world of IT at ME.

About ME
We’re not like other banks.
ME was created by the industry super funds to be different from the pack – with a core purpose to help all Australians get ahead financially – no conditions, asterisks or exceptions. And we know that looking after customers starts with taking care of our people.
We believe everyone deserves the same opportunities in life, regardless of gender or identity, sexuality, ethnicity, religion or disability ‒ with internal affinity groups.
Perk ME up
Once you get your feet in the door at ME, we’ll put them both in your very own ME-branded Converse shoes. You’ll also get the following financial, health and fun perks when you join the team:
4U Extras portal (discounts and cashback on 100s of items including cinemas, shopping and gym memberships
10% Myki discount
Purchased Leave programme
Internal wellness programme (Mindfully ME)
Professional education through LinkedIn Learning
Novated Leasing
Professional membership reimbursements
Health checks
Financial education (To help you manage your money smarter)
LGBTIQ+ and Women at ME affinity groups

I want those Converse shoes (and the role)
Can’t see a closing date on the advert? That’s because we’re pretty efficient here at ME and we may start looking at applications sooner rather than later, so if this role sounds like your jam, be sure to apply by submitting your resume today.

Should an applicant be the preferred candidate, background checks (including police checks, reference checks, ASIC banned and disqualified persons and bankruptcy checks) will be completed prior to the candidate's employment being confirmed. The outcomes of the background checks do not automatically bar candidates; however will be assessed against the inherent requirements of the job.
Back Share
Apply Now",3.0,"ME Bank
3.0",Melbourne,-1,501 to 1000 Employees,-1,Company - Private,Banks & Credit Unions,Finance,$100 to $500 million (USD),-1
Software Engineer - Machine Learning/Data Science,-1,"Zendesk is looking for a Software Engineer - Machine Learning/Data Science for a full time position in our Melbourne office.
As part of our engineering team, you will work at a scale where the challenges start to get seriously interesting. Our global engineering team is widely dispersed over the world, with people across nearly every continent. You will get a chance to do cool things with a diverse bunch of people while working in the Melbourne office that is home to Zendesk’s first machine learning (ML) research team.
The Data Science Team, together with Data Engineering, have built Satisfaction Prediction, Answer Bot and Content Cues — products that use Machine Learning (ML) and Artificial Intelligence (AI) to help our customers work more efficiently.
What you get to do every day:
We’re currently looking for someone to join our team as we research, develop, and productionise Machine Learning and Deep Learning models. In addition to frequenting Melbourne’s finest purveyors of coffee, ramen, and bulgogi, you may find yourself:
Building machine learning models including neural networks in TensorFlow
Writing and deploying production-grade Python
Querying and constructing datasets in AWS Athena, Spark
Evaluating and responding to real-world model performance
Scaling your ML to millions of predictions per day
Presenting your work to a broader audience
Watching your algorithm help Zendesk’s end-users
What you'll bring to the role:
A strong foundation in a quantitative discipline (e.g. machine learning, statistics, bio/eco/etc-informatics, econometrics, etc) is critical for this position. While experience in deep learning and natural language processing would be beneficial, your best qualities are:
dedication to continuous learning
collaborative work attitude
strong communication skills
You should also be comfortable with at least one programming language, such as Python, R or Scala.
Application Deadline: 18/11/2020
Job Types: Full-time, Permanent
Salary: $85,000.00 – $110,000.00 per year
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Temporarily due to COVID-19",4.5,"Zendesk
4.5",Melbourne,-1,1001 to 5000 Employees,2007,Company - Public,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),-1
Software Engineer (Machine Learning),-1,"About the Role
AdelaideMRI is building a medical reporting tool. We require an engineer to work primarily on machine learning projects to improve reporting speed and report comprehensiveness.
You will perform data analysis of medical report datasets and image datasets to infer sentence recommendations, image classifications, or other actionable results for the doctors.
Skills and Experience
Background in machine learning or image processing
Qualifications in Computer Science, Software Development or Engineering or equivalent experience
Bonus points for Python
No prior medical knowledge is required.
This position offers flexible hours and work arrangements.
Job Type: Full-time
Experience:
Software Engineering: 1 year (Preferred)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Yes",-1,Adelaide MRI,Australia,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Hey there, we’re PEXA!

We started as an idea: to deliver a single, national e-Conveyancing solution. We collaborated with the industry to create a national electronic lodgement and settlement platform: PEXA. From our humble beginnings, we’ve now grown to more than 320 employees across 5 different states. We’re still expanding at a rapid rate and constantly challenging ourselves to create great experiences for our members as they transition to fully digital conveyancing.

Why become a PEXArian?

Great question! Being a PEXArian is so much more than just a job. We are passionate, motivated & unashamedly enthusiastic at PEXA - we love what we do and we’re proud to admit it! Creating brilliant member experiences wouldn’t be possible if we didn’t also strive to create an amazing employee experience. Alongside our members, our employees are at the heart of everything we do.
Here’s a snapshot of what your life at PEXA could look like:

Your growth:
We encourage you to hit your personal and professional Learning & Development goals with our tailored programs and tools.

Your wellness:
We care about your holistic well being - a fully stocked kitchen, four wellness days, a $250 wellness subsidy as well as lunch and learn sessions to support your financial well being.

Your work/life blend:
We know that work is just one aspect of your life, we want to help you create your ideal work/life blend, rather than squeezing in life around work.

Your family:
With a range of benefits aimed at supporting your family including access to a subsidised school holiday program, extended parental leave and flexi-time to support your return to work, superannuation payments for unpaid parental leave for primary carers and a childcare allowance for pre-primary aged children, when we say, ‘welcome to the family’, we really mean it!
The impact you'd drive:
The successful candidate will be responsible for developing, and maintaining infrastructure to support the delivery of new and existing products. They will also be contributing to establish the rules and frameworks for obtaining the required approvals for new products.
On day one we’d love you to have:
Experience with Python, Spark
Event streaming/sourcing with Kafka or AWS Kinesis
Experience with data structures, formats and data security best practices
AWS experience (e.g CloudFormation, S3, ECS, Lambda, SQS, IAM, KMS, DynamoDB, Glue, Athena)
Query construction and optimisation (e.g. SQL, Elasticsearch, Splunk, DynamoDB)
Git, version control practices, and continuous integration/delivery servers
PyUnit and unit testing frameworks
Production release cycles and maintenance
Collaborating with technical and non-technical teams
Even better:
Agile methodology/delivery
GraphQL
Modern frontend technology (e.g. ReactJS, TypeScript)
Machine learning frameworks and tools (e.g. TensorFlow, PyTorch)
OAuth 2, SAML 2, JWT
Data visualisation and exploration tools (e.g. Jupyter notebooks, Tableau)
AWS SageMaker
Sounds like you?
If this role sounds like you, apply today to have your application reviewed ASAP!",3.9,"Property Exchange Australia Limited
3.9",Melbourne,-1,201 to 500 Employees,2010,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Ongoing position
Full time
Based in Sydney, NSW
Who we are
Australian Red Cross is part of the world’s largest humanitarian organisation. Our aim is to improve the lives of the most vulnerable people in Australia and across our region.
About the role
The Data Engineer role will sit within the Data and Integration Squad in IT and will own (design, implement and support) the AWS Big Data technologies such as the Data Lake and Data Warehouse and support the organisation in growing the data analytics capabilities at Red Cross. In addition to this, the data engineer role will also administer the Power BI tool and support the implementation of the data mastering capability.
What you will bring
Experience building and optimizing data pipelines, architectures and data sets.
Experience in dimensional modelling and building data vaults
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with structured, semi-structured and unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Why work for us?
Work for purpose and know that your work assists Red Cross support and empower people and communities in times of vulnerability.
Generous salary packaging options available that can increase your take home pay.
Further information
To find out more about this opportunity please see the position description below or contact Sharath Kumar Gurram on 02 8651 8839.
Position Description: Position Description - Data Engineer .pdf
Applications for this position will close at 11:55pm Thursday, 5 November 2020.",4.1,"Australian Red Cross
4.1",New South Wales,-1,1001 to 5000 Employees,-1,Nonprofit Organization,Industrial Manufacturing,Manufacturing,$500 million to $1 billion (USD),-1
Junior Fullstack Data Engineer (Python and React),-1,"Formbay is the leading Renewable Energy Certificate Trading company in Sydney. We provide Digital Workflow and Compliance solutions in the renewable energy industry and document processing.
Thanks to our meteoric growth and our commitment to be the best at all we do, we've identified the need to bring on board a new Junior Fullstack Data Engineer.
Reporting to our Principal Machine Learning Engineer, you will help build Machine Learning pipelines for our existing Digital Workflow and Compliance solutions to automate fraud detection and document processing over terabytes of photographic and documentary data – including documents, photos, GPS data and aerial/satellite photography.
Our stack is based on Python, JavaScript, Dask, Tensorflow, CUDA, Nix/NixOS, AWS, Docker, PostgreSQL and more – familiarity with these applications will give you a leg-up on the competition.
Our ideal candidate will have the following competencies:
SQL
Python
JavaScript/TypeScript
Our candidate must also be comfortable working with Linux.
Located a stone's throw away from the Queen Victoria Building in Sydney's bustling CBD, we are centrally-located with easy access to public transportation, bars, cafes and fine dining.
Formbay will provide flexible working hours, a generous remuneration package and the opportunity to work on a world-first software solution are what we can offer you. Free, twice-weekly gym sessions and really, really good coffee are also available.
No hiring/recruitment agencies need apply.",5.0,"Formbay
5.0",Sydney,-1,1 to 50 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is an experienced and qualified Data Engineer to join our IT team based in Birtinya.
Key Responsibilities:
Create and maintain data pipelines and or ETL scripts
Create and maintain data integration including API and Batch interfaces
Performed detailed data analysis
Create and maintain corporate data models
Create and maintain data visualization using Qlik.Sense , PowerBI or Simliar Toolset
Experience in defining, building and maintaining data virtualization and/or star schema data warehouses
Maintain, tune and optimise database, integration and visualisation toolsets
ABOUT YOU:
To succeed in this role, you’ll need to bring the following experience and skills:
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Excellent communication skills both oral and written, with an ability to bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking
Experience with data analysis and modelling will be beneficial

How to Apply
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kawana Waters,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Graduate Data Science / Engineer,-1,"The NRMA is an organisation looking to the future, and right now, we are on the lookout for people who can help us reach our goal: to continue to shape the way Australians move, for the next 100 years and beyond. www.mynrma.com.au.
Everyone new to the team, along with our current staff, will temporarily work from home until it is safe to return to our offices. All interviewing and on boarding will be done virtually due to COVID-19.


Your opportunity
As Graduate Data Scientist or Engineer you will be part of the Data Engineering team delivering cloud data transition program for business initiatives and supporting the entire data platform build.
Your key responsibilities will be to:
Implementing Concepts of Data Warehousing, Data Mart creations within Cloud
Use of SQL for data analysis and insights
Building AI/Machine Learning prototype for implementing and supporting existing algorithms
Data Analytical reports build, using different tool sets


Requirements for Success:
Relevant Degree - Computer Science, Computer Engineering, Software Engineering, Data Science
Excellent SQL skills and demonstrated working knowledge in Python
Demonstrated understanding in data structure and algorithms.
Knowledge and concept of data warehousing methodologies
Any reporting tools experience Tableau or Oracle Analytics Cloud, Looker is desirable
Exposure to Google/AWS/Azure/Oracle any cloud based platforms is desirable
Good communication and interpersonal skills

If you have the required skills and the passion to join our high performing team, please apply today.

Employee Benefits
To ensure our employees feel valued, empowered and celebrated we provide a range of employee benefits including:
50% discount on all NRMA insurances
Free Roadside Assistance
12 weeks paid primary and 4 weeks paid secondary parental leave
Free NRMA Blue Membership
At the NRMA Group, we are People Moving People and diversity and inclusion are part of our DNA. Together, we continue to build an inclusive culture that encourages, supports and celebrates the diverse voices of our employees. It fuels our innovation, promotes flexible ways of working and connects us closer to our members and the communities we serve.",2.5,"NRMA Motoring & Services
2.5",Sydney,-1,501 to 1000 Employees,-1,Nonprofit Organization,Casual Restaurants,"Restaurants, Bars & Food Services",$500 million to $1 billion (USD),-1
Data Centre Engineer,-1,"We are a leading world group that provides low-carbon energy and services. To tackle the climate emergency facing us all, our aim is to become the world leader in the zero-carbon energy transition ""as a service"" for our clients – particular for companies and regional authorities. We use our expertise in our key business areas (renewables, gas, services) to provide competitive and bespoke solutions.
The Data Centre Engineer will be employed as part of a 24/7 ongoing shift to coordinate and monitor third party service providers, maintain the data centre facilities and infrastructure plans, coordinate the implementation of customer requests within the data centre and monitor systems, all in accordance with the Contract KPIs and SLAs.
Coordinate and monitor third party service providers for regular maintenance & testing, service faults & call outs, ensuring works are performed in accordance with Contract SLAs
Monitor and maintain the data centre facilities and infrastructure plans and documentation, including electrical, mechanical, hydraulics, fire and BMS/EMS systems
Coordinate the implementation of internal and external customer requests within the data centre
Perform scheduled plant checks and minor maintenance works
Ensure all Work Order requests are raised and closed in a timely manner
Conduct inductions for staff, vendors and contractors
Ensure all work permits for vendor works are raised and closed
Perform inventory checks on all equipment and critical spares

Qualifications
The selected candidate must be able to demonstrate:
Electrical or HVAC background, or Graduate Electrical or Mechanical Engineer
Passionate about quality work and career minded looking for a new challenge
Can commit to a day and night shift roster (2 days of day shift, then 2 days of night shift, 4 days off)
Ideally able to commence asap
As part of carrying out the duties of this role, it is mandatory to hold Australian Citizenship.

If you are interested and meet the selection criteria apply with an up-to-date resume via the apply instructions on this website.

ENGIE Services is an EEO employer, where all applicants are treated with fairness and respect and have equal access to the opportunities available.

We will not be engaging in the services of a recruitment agency to fill this vacancy and therefore request all interested candidates apply directly to this advertisement.

Job
: Maintenance
Primary Location
: Oceania-Australia-New South Wales-Erskine Park
Organization
: ENGIE Services Australia and New Zealand
Schedule
: Full-time
Nature of Responsibility
: Senior operational / administrative role
Job Posting
: Sep 11, 2020, 6:29:59 AM",3.7,"ENGIE Services Australia & New Zealand
3.7",Sydney,-1,5001 to 10000 Employees,1995,Company - Public,Energy,"Oil, Gas, Energy & Utilities",$2 to $5 billion (USD),-1
Senior Data Engineer,-1,"Senior Data Engineer, Temporary, SYDNEY - McKell

Job Title: Senior Data Engineer

Salary: SNSW Grade 9/10 - The package includes base salary range of $111,806 to $134,667, plus employer's contribution to superannuation and annual leave loading.

Location: Head Office – Haymarket

Employment Status: Temporary through till 30th June 2021


About Service NSW:

Service NSW is making it easier for people and businesses across NSW to access government services. The role designs, builds and analyses complex data from multiple sources to identify revenue, process and business improvement opportunities; providing new information and insights to the business to inform planning, continuous improvement and performance.

About the Role

We are currently seeking to appoint a Senior Data Engineer to deliver expert advice and services in the design of a Single View of Customer and data-related services to support the achievement of business outcomes and strategic goals. We support flexible working practices with staff working remotely during this time.

In this role you will:

Design, build and support a modern data platform based in AWS and vendor technologies.
Provide expertise on data modelling for Graph data model and Customer Data Platform (CDP).
Create data pipelines, load, transformation and reporting workloads in AWS.
Work with the latest data engineering technologies like Apache Kafka, AWS Kinesis, AWS Neptune, AWS Glue and AWS Athena.
Contribute to the design and decision-making of the right tool or platform for the job according to requirements.
Provide expert advice and guidance on data quality and data engineering best practices.
Support a “bigger than you can imagine” scale of data in production environments.
Design, develop and support a metrics-driven reporting solution and a meaningful business intelligence platform.
Document the solution design and support procedures of solutions.
Produce reports, visualisations and recommendations to answer complex business problems that are presented in the most appropriate format to ensure clarity for target audience.
Analyse and define new process improvement opportunities to support continuous improvement and business outcomes; providing advice to stakeholders, on ways to improve the efficiency and reliability of data products and services.
Be very responsive to the information needs of the business by corresponding to customers in a timely manner and provide support/solutions to issues raised.
Troubleshoot and perform root cause analysis on production issues. Identify and implement long term solutions to problems. Perform scheduled maintenance, release deployment and production support activities after business hours, from time to time.
Liaise with internal and external customers to discuss and gather requirements, solutions etc. and maintain a good working relationship with the stakeholders.


Skills and Experience Required:

Solid experience with workflow technologies designing and building data pipelines, data models and data stores.
Experience working within and an understanding of Amazon AWS ecosystem, including security and performance tuning.
Hands on experience working with different types of databases, with focus on Graph and NoSQL databases.
Experience with data streaming required. Having used Kafka and related technologies is an added advantage.
Sound knowledge and experience working with batch processing, data extraction and API integration.
Hands on experience with at least one programming language: Java, Python or scripting.
Demonstrated experience working in an Agile based, fast paced, complex environment within cross-functional teams.
Experience developing systematised insights, data analytics and reporting solutions is an added advantage.
Experience with interactive visualisation of data insights is an added advantage.


Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Salary Grade 9/10, with the base salary for this role starting at 111,806 base plus superannuation

Closing Date: 6th November at 9:59am - applications will be reviewed on a rolling basis, applications may close early or extend

Please apply online, direct applications submitted via email will not be considered.

The Department of Customer Service is proud to be an EEO Employer who are fully focused on equality and believe deeply in diversity of all identities making us different and a true reflection of our NSW customers. As an inclusive workplace, we support various employee resource groups, practice flexible work and workplace adjustment.

If you do require an adjustment during the recruitment process, please notify us on your application form.",3.2,"Service NSW
3.2",Sydney,-1,501 to 1000 Employees,2012,Government,State & Regional Agencies,Government,Unknown / Non-Applicable,-1
Data Engineer - Entry / Mid Level,-1,"Work with a great team on interesting projects customers
Gain more experience in AWS, Data, DevOps cloud operations
Got a working knowledge of AWS? We will teach you the cool stuff!

Itoc is seeking an up and coming Data Engineer to join our growing Data Team in Sydney.

This is an exciting role working with databases, data lakes, data warehouses, data transformation (Python SQL) and enabling AI/ML.

You will be implementing foundational, robust and production ready data platforms to enable business data-discovery, self-service, AI/ML functions across a range of client types and industries, allowing them to do more with their data.

You'll be responsible for:

Deploying data repositories such as lakes and warehouses.
Contribute to our growing portfolio of data solutions.
Ongoing optimisation and management of data platforms.
Development of transformational logic for data pipelines
Data evangelism. We want to show our clients how to follow the best practices for data.

Desired Skills and Experience

To take up the challenge, you will have a depth of skills and experience including:

1-2+ yrs of focused data experience working with SQL and/or NoSQL solutions
A solid education in Software Engineering or equivalent industry experience.
Anything Data focused preferred.
Ability to analyse business scenarios and associated data landscape to derive potential opportunities.
Strong foundation in Python and SQL
Working knowledge of APIs
Principle knowledge of the different relational database platforms and modern data storage techniques
Knowledge of the different aspects of data environments
Collect, store, process, verify consume
Experience with version management systems (such as GIT)
Working knowledge of AWS or another cloud platform - we will teach you the cool stuff.
Great communication skills, an ability to work closely with customers, developers and engineers and the confidence to present ideas in open forums.
Relevant tertiary qualifications and/or industry certifications.
Great communication skills, an ability to work closely with clients, developers and engineers and the confidence to present ideas in open forums.

While not required, a background in consulting and professional services is highly desirable.

Itoc Description

This is an exciting and challenging career opportunity to join the growing Sydney-based Data Team of a leading cloud solution provider where you will be given support to reach your long term career goals. You will be part of a team of cloud experts and will work in an environment of continuous improvement and learning delivering innovative cloud solutions across SaaS, online business and enterprise business.

On offer is a chance to join a team with a great working environment, in an organisation that values its employees and sees the value in ensuring they are engaged. Our team are clearly passionate about what they do, that's why we won the following awards:

Customer Obsession Partner of the Year 2015: ANZ Region
Customer Obsession Leadership Partner 2015: re:Invent

As an employer of choice Itoc offers competitive remuneration, training and development programs and a great working environment. We value a healthy work life balance.

The Perks

MacBook or Dell
Continuous internal learning that will provide training and career development opportunities
Working with a collaborative, social team and leveling-up your skills faster than you will anywhere else.
Quarterly social events

Itoc

Culture and smarts are important to us. Bring your secret sauce. This is no ordinary environment, you will work along some of the Cloud’s best. All engineers at Itoc must gain at least five AWS certifications. We work hard but we have fun.

Please note you must have full working rights in Australia and be available on-shore for face to face interviews.

No recruiters please.",4.0,"Itoc
4.0",Sydney,-1,1 to 50 Employees,2013,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Date: 01-Oct-2020

Location:
Melbourne, VIC, AU

Department:Description:
Technology discounts - from Apple HP Lenovo to Windows
Flexible work arrangements - work in a way that suits you best
Salary packaging - to suit your personal and financial circumstances

Do you want to work for one of the fastest growing data teams in Australia? Do you want to work on multiple data platforms and provide new solution offerings by leveraging cloud and big data technologies?

About the team

Big data information and analytics. Three words that spark apprehension in most businesses. But our team of experts are constantly curious and excited about combining our wonderful array of technological expertise to transform data into our clients most valuable assets making their work smarter. Our data consultants are supported with resources training and tools they need to excel at their work but also the freedom and power to create their own paths forward to make a difference.

As a Senior Consultant in Big Data you will work closely with the team and stakeholders to build and deliver a Cloud based vision for a next generation Big Data analytics platform with strong focus on data quality data security and deliver the systems that process huge volumes of data.

What will you typical day look like?

You will play a pivotal role in - Designing and producing high performing and stable applications to perform complex processing of massive volumes of data in a new cloud based architecture; Building real-time data processing applications which are integrated with business systems to enable value from analytic models to drive rapid decision making; Contributing to system architecture design for a data platform (including cloud-based structures both on and off premises data warehouse components and data lakes); this could cover a range of technologies various countries/locations and lines of business; Support data strategy or technology strategy definition programs including technology stack definition and target operating model requirements

Enough about us lets talk about you:
You are someone with:
Use of traditional data analytics tools and techniques (e.g. MSSQL Oracle MySQL) and ETL software (e.g. SSIS Informatica CloverETL)
Working in large scale cloud data solutions using platforms such as AWS or Azure or GCP will be a bonus.
Experience in scripting or programming (e.g. Python Java Scala C#)
Excellent verbal and written communication skills to adapt to technical and non-technical audiences.
Educated to degree level (or have equivalent experience)
Why Deloitte?

At Deloitte we create positively differentiated work experiences that enable our people to feel valued and achieve their full potential. We value difference and embrace people with diverse backgrounds and thinking styles. Knowing that people work best in different ways we are happy to discuss alternative arrangements if the working pattern you are looking for is not specifically indicated.",3.8,"Deloitte
3.8",Melbourne,-1,10000+ Employees,1850,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Engineer,-1,"Opportunity to grow the team
Period of growth
Intuitive app
S2M are working with a FinTech who have created a unique financial product to help thousands of people better manage their finance, and is currently scaling the company to the next level!

They are looking for a Data Engineer to join, and looking for someone who wants to be hands on, with opportunity to grow the team in future.

Role:

Looking for people with strong AWS experience. You will need passion for data and a cloud, through which you will help a rapidly scaling Australian FinTech establish their data infrastructure from the ground up.
5+ years’ experience as a data engineer within the data and analytics domain
A python 3.X aficionado who is very comfortable creating and orchestrating AWS data pipelines with nothing but code
Strong project delivery toolset experience in open source data integration tools
Experience with processing large volumes of complex data including visualisation and insights generation
Ability to define and develop data integration patterns and pipelines
Ability to assess complexity of data (volume, structure, relationship etc.)
Hands on experience working with different databases (RDBMS, NoSQL, Blob storage etc)
Hands on technical expertise setting up DevOps automation
Hands on experience working technologies/platform e.g. AWS, Dockers, Containers
Experience building data profiling and data cleansing frameworks
Technical reconciliation and reporting
Knowledge and experience in end-to-end project delivery, either traditional SDLC or agile delivery methodologies (or hybrid approaches)
Exceptional communication, documentation and presentation skills
If this sounds like you, get in touch today - kate.gabb@s2m.com.au
3167410agsdf",3.1,"S2M
3.1",Sydney,-1,Unknown,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Analysts,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is seeking experienced and qualified Data Analysts to join our IT team based in our corporate office in Birtinya (Sunshine Coast) or at our meat processing facility in Kilcoy.
Key Responsibilities:
A mixture of data analysis and commercial skills to source, blend and analyse data to gain insight and answer key commercial questions
Working with strategic leaders to define and model Key Performance Indicators, and assist in building forecasting models
Working closely with data engineers and BI developers to specify data pipelines and report visualisation
Drive the creation and implementation of data quality business rule including data definition, governance and quality assurance
About You:
To succeed in this role, you’ll need to bring the following experience and skills:
Proven ability to derive insight and knowledge from data using commercial expertise is a strong requirement
Strong SQL and Excel skills are essential, along with strong data analysis and commercial insights
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Effective people communicator - engage with stakeholders on reporting needs, interpret requirements into visual solutions and train/deliver the outputs to the stakeholders getting signoff of acceptance
Bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking

How to Apply:
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kilcoy,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Network Data Engineer,-1,"Min 6+ years of experience in the relevant technologies
Australian Driving License for visiting remote locations / Data Centre for day to day technical work.
Managing Network devices (switches, routers, firewalls, load balancer, and wireless technology)
Performing MACD activities for all network devices.
Supporting BAU operation activities.
Proficient in performing in-depth details of technical troubleshooting, cause and provide recommendation to the client for incidents causing extended network outage to client’s critical locations.
Provide exceptional network services in terms of network support, break-fix, design and consulting, new projects, implementation.
Configure, administer, and document firewall infrastructure.
Manage the firewall deployment, rules migrations, and firewall administration.
Supporting Cloud Migration Activities from traditional to AWS/Azure.
Setting up VPN tunnel with Cloud and 3rd Party network devices.
Integrating and upgrading existing ISP bandwidth with support from ISP Vendor.
Setting up VPN profiles for Users.
Installing hot fix and patches to mitigate the security devices from attacks and bugs.
Reviewing and fine tuning the firewall rules and NAT rules.
Documentation and change control.
Mentoring, Motivating and Guiding support teams
Technical skills:
o LAN
o Wireless
o WAN
o MPLS
o Routing protocols (OSPF,BGP)
o DMVPN
o Azure cloud Networking
o Network Security
Fortigate Manager / Analyzer / Firewall
Cisco ASA
Firepower FTD
Cisco Any connect
Site to Site VPN
F5 Load Balancing and Scripting iRule
Job Types: Full-time, Contract
Schedule:
8 hour shift
Experience:
Scripting: 5 years (Required)
Data Network: 5 years (Required)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Required)",3.6,"Total IT Global
3.6",Sydney,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Engineer - Processing & Analysis,-1,"Job Description:
Design,build and maintain the ingestion system to support various types of data(e.g. User behavior, RDS, NoSQL db and others) to be ingested to the data warehouse more timely and accurately
Translate data requirements into scalable technical data service with low latency and high concurrency
Design,build and maintain the batch or real time data pipeline in production using Hadoop big data technology
Analyze and improve efficiency, scalability, and stability of the system
Define and manage SLA,Data quality for all data sets in allocated areas of ownership
Requirements:
Minimum B.S. degree in Computer Science or a related technical field
2+ years of working experience in programming languages,such as Java,Scala,Python
Familiar with Hadoop, Spark and Flink data processing, experience of TB data processing experience is a plus
Familiar designing and operating of a robust distributed system is a plus
Understand data mining or machine learning
Excited to work intimately with data
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"SYNOPSIS:
Lead Data Engineer
Applications close Sunday 8 November 2020
Ongoing
Contact name: Shyni Sasikala
Phone: (02) 6249 9048
Email: Shyni.Sasikala@ga.gov.au

The Data Policy and Informatics section within the Digital Science and Information branch creates, implements, and promotes policies, platforms and tools that improve and support the quality, discoverability, accessibility, and general usability of Geoscience Australia’s science data products. The section consults with internal and external research, government and industry partners to establish collaborative data frameworks, architectures and models within Geoscience Australia (GA) and across broader national and international communities of practice. The section innovates, builds and maintains tools, systems, processes and governance that enable digital data management, cataloguing and open data delivery.
GA makes accessible a wide range of geoscientific and spatial data to a wide variety of stakeholders in multiple formats, and in recent years GA's data volumes have grown exponentially. GA is focussed on making its data and metadata assets accessible so that they can be used in machine to machine interactions for data analytics and other applications in environments that range from High Performance Computing (HPC), through high-end cloud servers, to mobile devices.
We currently have two opportunities for Lead Data Engineers in the Informatics team. The Lead Data Engineer is responsible for innovating and exploring new technologies that will advance GA’s science goals and maximise the uptake and use of GA’s science data. The Lead Data Engineer reports to the team’s Assistant Director but also works closely with other developers, data scientists and engineers within the Digital Science and Innovation (DiSI) branch, as well as diverse stakeholders both within and external to GA.",3.9,"Geoscience Australia
3.9",Canberra,-1,501 to 1000 Employees,2001,Government,Federal Agencies,Government,$100 to $500 million (USD),-1
Data Engineer,-1,"The Seven Network is part of Seven West Media, one of Australia’s most prominent media companies, with a market leading presence in content across broadcast television, online and in print. Comprising some of Australia’s most renowned media brands, SWM includes not just Seven Network and its affiliate channels 7two, 7mate, 7flix and BVOD offering 7plus, but also 7NEWS.com.au, The West Australian, The Sunday Times and more.
At Seven we are here to bring all Australians closer to the moments that move us - we’re first on the scene, with our finger on the pulse, on demand, in the moment. Together, we’re responsible for creating and sustaining authentic Australian engagement.
A new and exciting opportunity has opened for a Data Engineer to join the Audience Intelligence team. Based in Sydney and reporting to the Head of Data Enablement, you’ll be responsible for:
Implementation of end to end data solutions to support Data Strategy for the SWM group.
Work closely with the Data Solution Designers to develop and maintain scalable data pipelines and build out new file and API based integrations to address requirements from the various business stakeholders.
Collaborates with engineering, analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organisation.
Work on Data Preparation for analytics and data scientist team members and assist them from an engineering perspective in building and optimising the models including building the automation of the end to end workflows
Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.
Perform data analysis required to troubleshoot data related issues and assist in the resolution of production data issues.
Work effectively with vendors for successful delivery of projects and acceptance of the solution
Work on Delivery projects using Agile Software Development methodologies
We are looking for someone who has:
Bachelor's degree in computer science, computer engineering or other technical discipline is essential
Proven experience working as a digital analytics specialist
Extensive experience with digital analytics implementation (e.g. Google Analytics, Snowplow, Adobe Analytics) and BI processes and visualisation platforms
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience in ETL and building and optimizing ‘big data’ pipelines and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Experience with big data tools: Hadoop, Spark, etc., AWS cloud services: EC2, S3, Lambda and familiar with version control systems: Git
Strong coding skills with knowledge of Unix/Linux and scripting languages such as Unix Shell scripting, Python desirable
Experience supporting and working with cross-functional teams in a fast-paced environment.
Ability to multi-task and problem solve with changing demands and priorities
Ability to work under pressure to meet deadlines and detail oriented
Your success is our success: we will provide you with opportunities for you to keep learning and growing, enabling you to challenge and develop yourself. In return, we offer a benefits program that has something in it for everyone.
Seven West Media is an equal opportunity employer and we are committed to creating a diverse and inclusive workplace.
Recruitment Agencies: Seven West Media does not accept any unsolicited agency resumes and will not be responsible for any fees related to unsolicited resumes.
Advertised: 19 Oct 2020 12:00 AM AUS Eastern Daylight Time
Applications close:

Back to search results",2.5,"Seven West Media
2.5",Sydney,-1,5001 to 10000 Employees,1956,Company - Public,TV Broadcast & Cable Networks,Media,Unknown / Non-Applicable,-1
BICON Rules Engineer,-1,"APS 5 - $73,299 - $80,410 per annum plus superannuation
Biosecurity Plant Division
Canberra, ACT
Play an active role in managing biosecurity risk to Australia
Work in a motivated and professional team with a wide range of skills and backgrounds
Full training provided

Who we are
The BICON Content Development Team maintains and improves the Biosecurity Import CONditions database (BICON) content to allow external clients to understand and comply with their biosecurity obligations and internal clients to effectively manage biosecurity risk and regulate imports. We work collaboratively with internal clients to comprehend and implement their BICON content requirements and optimise the use of BICON to publish clear import requirements and onshore management support procedures to effectively manage biosecurity risk.

The Jobs
Key duties of these positions include:

working with business content (import and permit conditions) and import programs to understand and construct decision tree structures in the BICON database, in accordance with system design and authoring conventions
executing changes to import and permit conditions in alignment with service standards while complying with system rules and authoring conventions
providing technical advice through various formats on the most appropriate means of authoring BICON content to achieve import program and stakeholder objectives
using workflow management tools to maintain detailed records of changes to import conditions and key decisions
performing administrative tasks including system reporting, data analysis and scoping tasks for the BICON content change work program
contributing to the development and maintenance of instructional material, authoring conventions and courseware
clearly documenting and reporting system issues
developing and maintaining effective working relationships with internal and external stakeholders.

What we are looking for
Knowledge and experience
Experience working with complex IT systems.
Experience working collaboratively and as part of a team.
Knowledge of the role of biosecurity is preferred but not essential.

For additional information, please read the Job Description below.
Candidate Information Package docx Opens in new window",3.9,"Department of Agriculture & Water Resources
3.9",Australia,-1,5001 to 10000 Employees,-1,Government,Federal Agencies,Government,$500 million to $1 billion (USD),-1
Cloud Data Engineer,-1,"Job no: 509605
Work type: Permanent Full Time
Location: Melbourne, Canberra, Sydney
Do you embrace digital disruption?
Do you love solving complex problems, designing sophisticated solutions and building innovative technology?
Do you believe in creating powerful actionable insights from Data and Analytics?
Do you want to work in a diverse and flexible working environment?
KPMG is one of the most trusted and respected global professional services firms. Through depth of expertise, clarity of insight and strength of purpose we help our clients solve complex challenges, steer change, strengthen, transition and grow. We are a team based practice and this extends to our clients whom we work and collaborate with, in solving complex problems. Together, we design, innovate and implement, providing enduring advice that support our clients and the services they deliver. Our clients vary in size and come from a diverse range of sectors – all sharing in a common goal: to embrace change and deliver services that make Australia a better place. We are looking for talented individuals who would like to join us on the journey.
KPMG’s Digital Delta Team
We re-imagine and re-invent organisations to become world class digital enterprises using advanced technologies, data and human insights. We help organisations to embrace Digital Strategy, Artificial Intelligence (AI) & Cognitive, the Internet of Things (IoT), Data, Analytics & Modelling, Mobile App & Web, and User Experience (UX) & User Interface (UI) and more.
We work with clients to:
Formulate strategies that re-imagine organisations
Harness innovation from the 4th industrial revolution
Actioning insights from trusted data to consistently and quickly make clear decisions
Build adaptive organisations
Thrive as a connected enterprise – front, middle and back office
This is how you’ll contribute:
We are looking for ambitious Data Engineers who are passionate about helping clients define bold ambitions and deliver on them. Joining our team will take you on a journey of personal and technical growth and provide the opportunity to inspire confidence and empower change.
As a Data Engineer you are the designer, builder and manager of the information or ""big data"" infrastructure, preparing data for analytical or operational use. You will design, construct, test and maintain a data pipeline to pull together information from different source systems; integrating, consolidating and cleansing data; and structure it for use in individual analytics applications.
The KPMG Difference
Our people are focused on creating a diverse and dynamic environment that embraces and values differences. We value the variety of unique experiences, qualities and characteristics our people possess and we share and learn from each other.
We are proud to be consistently recognised as an employer of choice for women, and for our achievements in LGBT+ workplace inclusion.
Our commitment to ‘Flexibility’ allows our people to manage the changing demands of work, personal or family life. Explore the links below to hear our people share their experience @ KPMG:
Flexibility empowers wellbeing
Flexibility enables contribution to the community
Flexibility inspires technology & innovation
Flexibility supports family

Make KPMG the clear choice for your career and be Extraordinary!

Advertised: 09 Sep 2020 AUS Eastern Standard Time
Applications close:",3.8,"KPMG
3.8",Sydney,-1,10000+ Employees,1987,Subsidiary or Business Segment,Accounting,Accounting & Legal,$2 to $5 billion (USD),-1
Computer Network and Systems Engineer,-1,"Duties Include but are not limited to:
Tasks Include:
analysing, developing, interpreting and evaluating complex system design and architecture specifications, data models and diagrams in the development, configuration and integration of computer systems
researching, analysing, evaluating and monitoring network infrastructure to ensure networks are configured to operate at optimal performance
assessing and recommending improvements to network operations and integrated hardware, software, communications and operating systems
providing specialist skills in supporting and troubleshooting network problems and emergencies
installing, configuring, testing, maintaining and administering new and upgraded networks, software database applications, servers and workstations
providing network programming in support of specific business needs and requirements
preparing and maintaining procedures and documentation for network inventory, and recording diagnosis and resolution of network faults, enhancements and modifications to networks, and maintenance instructions
monitoring network traffic, and activity, capacity and usage to ensure continued integrity and optimal network performance
Skills and Experience Required:
Must have experience working in a Managed Service environment
Demonstrated experience in IT Networks and Data Centres
Understanding of systems and architectures to meet client needs
Experience in Help Desk including break / fix
Effective and timely documentation
Effective Task Management Skills
Be solution and outcome focused and willing to learn new technologies
Excellent communication skills with staff, clients and partners
Time management, ability to prioritise and deliver to schedule
Experience with N-Able and Connectwise desired
Open Cabling license desired
Job Types: Full-time, Permanent
Salary: $30.00 per hour
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,Trans-plant training,Canberra,-1,-1,-1,-1,-1,-1,-1,-1
Software Engineer (Data),-1,"If you are looking for an opportunity to make a real impact with smart people who are genuinely doing things differently then you've come to the right place! We're growing our data engineering capabilities and are looking for awesome data engineers to join our team.
With our diverse range of clients and projects, no day will look the same - but here's a great snapshot of what you'll be doing:
Work with some of the best Data Scientists and Engineers to deliver production-grade AI and Machine Learning systems as we deliver client projects from inception to production.
Consulting with our clients and working with them to build modern data systems using the 'best of' technologies and principles.
Advising clients on data strategy, architecture and technology.
Applying best software engineering practices in coding, monitoring and alerting, using CI/CD, TDD and cloud architectures.
Working over a wide range of big data tools and environments: not limited to; Apache Kafka, Spark, Python, Scala, Hive, Airflow, AWS EMR & Glue, GCP Dataproc & Dataflow, BigQuery, Snowflake, Redshift.
Who are we?
Glad you asked! We are Eliiza. Data science. Engineered for scale.
We are a passionate team of data scientists and engineers who apply data science and machine learning to solve real-world problems. Our mission is to create a bright future for Australian businesses and society in a world increasingly influenced by intelligent technologies.
We've created a culture that values diversity where people can truly be themselves! We care a lot about growing the Australian AI community in a positive direction, and we're doing several things to try and achieve that:
We provide opportunities for underrepresented groups to work in AI through our associate and intern programmes
We organise and participate in a range of community events, reading groups and meetups
We produce the AI Australia podcast
We blog about topics we care about
We stream brown bag sessions to the broader community
We're also part of Mantel Group's 'house of brands' which means it's not just the Eliiza team you'll work with, learn from and see at social events - there's another 230 of us across DigIO, Kasna & CMD Solutions!
So you're ready for something new?
We're keen to know more about you! Our team is made up of a range of people, with different experience across a huge range of data driven skill sets.
We'd love to hear from you if you have experience with:
one (or more) core language(s), ideally Scala, Python or Java
one (or more) cloud platforms, AWS, GCP, Azure
ETL/ELT concepts and technologies e.g. Data partitioning, Hive, Spark
streaming data concepts and technologies, ideally Kafka (Kinesis, Beam or Pubsub will do)
We'd be over the moon if you:
Experience with distributed/columnar databases (e.g. Snowflake, Big query, Redshift).
Experience with any of a variety of databases e.g. RDMS, NoSql, Columar, Distributed, Time series, Graph.
Knowledge of job orchestration and scheduling. Any experience with Airflow, Luigi or Oozie.
Experience with containers and container orchestration (Docker, Docker Compose or Kubernetes).
However, we value a diversity of skill-sets, and don't necessarily require that you're skilled with all of the above. If you feel you don't fit all the experience/skills listed above we still encourage you to apply or get in touch.
What's on offer if you join us?
We make sure you're always one step ahead by investing your learning and development, every year. We build our own training where it doesn't exist yet.
We hire smart people and get out of their way. By focusing on our five principles and not getting caught up in red tape, we trust you to get the job done.
You'll get all the tools you need - a new iPhone or Google phone, a new Macbook Pro or Dell, and a lot of branded swag!
But hold on, you mentioned a house of brands?
We certainly did! Mantel Group is an Australian-owned, 'house of brands' company with four technology businesses (Eliiza being one of them!) across Melbourne and Sydney. We're building a group of companies with open borders so we can support you to take on new skills without leaving an awesome team - we understand you won't have one job for life!
We may only be just two years old but Mantel Group has already been recognised #9 in the 2020 Best Places to Work in Australia and #4 in the AFR's 2020 fastest growing new companies.
Keen to chat?
Click ""Apply"" to share your details with our talent team, and we'll be in touch.
In the meantime, check out 'how we hire' to find out what's in store if you're successful and get to know us better by visiting our website and following Eliiza on LinkedIn.",-1,Eliiza,Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Infrastructure Engineer,-1,"Job Description:
Design and grow the Shopee data platform to support a variety of big data applications using open-source technologies including Kafka, Hadoop, Presto, HBase, Spark, Hive, Druid, and our own creations. Some examples include a real-time data streaming platform, a unified query platform, a cluster management system, and a machine learning platform
Dig into the source code of some open-source big data system to get the whole control and familiar with the details, configurations, designs and source code. Develop and maintain the internal release of big data systems and components as the business requirements.
Keep close and overall monitoring for all the deployments of the systems, maintain the system’s stability, improve the performance, discover the performance bottlenecks, tracking and troubleshooting, cost optimisation.
Requirements:
B. Sci. / Ms / PhD in Computer Science or a related technical field
Familiar with at least one of these languages: Java, Scala, Python, Bash under Linux / Unix. Scala is a plus
Familiar with the use and compute logical of SQL
Knowledge about the Big Data Infrastructure system technology like Distributed File System, Distributed Computing, Distributed Database will be a plus
Hands-on experiences Hadoop, Spark, Kafka, and/or Presto will be a plus
Love to use and develop open-source technologies
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"Work on an award-winning, international technology!
Endless career opportunities
An innovative, friendly team of 300+
This role will be focused on the development of our existing ClaimLogik line of products as well as working on our new cloud-first, modern suite of applications.

Intelligent Thought, our technology business is scaling and shipping our software globally. Already profitable, part of a much larger group business, with investors such as Macquarie Capital and Envest – we are all set to deliver textbook disruption to the Insurance Industry. The growth of the platform, of our customer base, and the increasing industry demand have led to the need for this role to help the team scale.

Our Philosophy
Give each employee a sense of purpose and an environment for them to connect the importance of their role to delivering a service that matters to our customers.
Challenge the ‘why’ of traditional claims processes.
Keep it simple – do only what brings value and what matters to the customer
Enable employee decisions, empower our people
Responsibilities:
Create, extend and maintain ETL pipelines to form our data lake, data warehouse and analytics platform (currently using the Microsoft Azure set of tools and service)
Help define the optimal data pipeline architecture
Influence the tool selection, platform selection, data architecture and strategy which will transform the business to be truly data-driven
Understand, analyse and size user requirements
Work with different parts of the business to provide them with the insights they need to deliver the best results
Skills & experience:
Degree or qualification in computer science or related
Advanced knowledge of relational database, including query authoring and query optimisation (MS SQL Server and PostgreSQL).
Experience building and optimising ETL pipelines
Experience designing complex data models
Experience working with cloud platforms (Azure or AWS)
Efficient time management and organisational skills
High attention to detail and accuracy
Effective communication skills to build strong working relationships; both written and verbal
Proactive and results-driven
Why Claim Central?
Claim Central Consolidated is a global insurance industry leader across, claims management, insurance technology and data and analytics. Currently operating in the United States, Australia, South Africa, Italy and New Zealand, we have pioneered digitally connected claims management services across the globe. Claim Central is a disruptor and thought leader in the industry and we were recognised as the Australian Financial Review’s 8th Most Innovative Company in Australia in 2016. This business is in a period of unprecedented growth, transitioning our technology and services into multiple geographies at a rapid pace. Our unique culture is based on teamwork, collaboration, trust, respect and performance. We also offer many benefits apart from our exceptional team culture; including flexible work arrangements, and continued professional development.

Be a part of this journey in a career-defining role.",-1,Claim Central,Matraville,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer - AI/ML,-1,"Our client provides services to a major industry across the country. The business is still early in it's days of technology development and the environment is greenfields in nature (no pun intended), effectively working like a start-up.

Their data and analytics team have worked and built leading and bleeding-edge technologies in this space and what they have created so far may be game-changing. From a machine learning perspective, the progress they have made to the business has already seen proven success in changing the future of an industry that will have positive consequences for all those involved.

You will have previously worked in a technical capacity in the data and analytics space and have experience working with an organisation where machine learning has been implemented, not just a concept that the business talks about having or the technology team would love to have. The commercial experience you will have had in the ML field will be proven examples of where you have affected the way a business or industry used to perform, to the changes that have come about from this.

Technically, you will have extensive experience in the Microsoft space - Power BI, Azure etc and you will have previously mentored and coached junior members of the teams you have been part of.

This is a rare opportunity in Brisbane where the business has truly embraced and funded projects across the ML space and would be a great chance for those in the Data Development/Data Engineering field, who are looking to move into a Data Scientist role in the future.

Please send your application through if you would like to know more.",4.0,"Emanate Technology
4.0",Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Solution designer/ ETL Engineer & Data Modeller,-1,"We are looking for a Qualified and Experienced Solution Designer to join our client for a period of 6 months with a view to extend.
You will work closely with team members and your contribution will range across gathering and analyzing information, developing and documenting improved processes and work instructions and experienced DWH Lead with skills in requirement analysis, solution designing, developing, testing and supporting ETL solutions.
A hands-on solution designer, data modeler and ETL developer for Data Warehousing and ETL application transformation projects using Informatica PowerCenter.
Knowledge on AWS, S3, Redshift, Informatica BDM, and related technologies.
Experience working with IPython, PySparks, AuCuMo, Airflow, Jenkins, Github, Athena, JIRA, Rally, Spectrum, Glue, Flyway.
Good exposure on Oracle PL/SQL, aware of DBA activities, writing and performance tuning of complex SQL queries.
Contract length: 6 months
Job Types: Full-time, Contract
Salary: $650.00 – $800.00 per day
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,nducive,Melbourne,-1,-1,-1,-1,-1,-1,-1,-1
"Data Engineer, Wollongong NSW or Mount Waverley VIC",-1,"Company Description
BlueScope is a technically advanced supplier of steel and steel products in Australia. We are an inclusive organisation and every day we showcase our technology and expertise throughout the world.

Job Description
We are looking for two Data Engineers to join our IT team, based in Wollongong NSW or Mount Waverley VIC. Use your experience in analytics to unlock business value, enabling use of big data for insights and decision-making.
Reporting to the Data Product Owner for our Australian Steel Products (ASP) business, this position will support strategic goals related to data. This will see you:
Gather business and technical requirements with the view to deliver outcomes;
Develop and implement end-to-end data collection, consolidation, modelling and visualisation solutions;
Document metadata in a dictionary and catalogue;
Ensure consumers of such information understand its accuracy, timeliness, quality and sensitivity, so that it is used appropriately; and
Identify opportunities to enhance analytics.
What are the benefits?
Work in a supportive and collaborative team environment whilst we embark on a journey to transform the way our business uses data!
Our systems landscape is broad and diverse. You will be encouraged to think creatively to develop data solutions which solve real business problems.
Working in this role you will enjoy:
the chance to learn more about data science;
salaried remuneration with attractive superannuation options;
the opportunity to participate in a performance incentive scheme; and
access to further development and career opportunities with BlueScope.
Who are we looking for?
We welcome applications from professionals with experience in data analytics and/or programming. Supported by your knowledge of project delivery methods (e.g. Agile), you will demonstrate:
experience with data mining, wrangling, mapping and visualisation techniques (e.g. Azure Data Factory, Databricks and/or DevOps etc.);
well-developed ability in gathering business and technical requirements;
skills in developing and implementing collection, consolidation, modelling and visualisation solutions; and
a passion for sharing your knowledge and desire for ongoing professional development.

Qualifications

null

Additional Information
We're proud to have been named an Inclusive Employer for 2019–2020 by the Diversity Council of Australia. We believe that our people are our strength. Having a diverse and inclusive workplace enables us to improve our capability and ensure continued, sustainable success.
We know that workplace flexibility can mean something different to everyone. Under our B-Flex initiative all of our roles have some degree of flexibility. We encourage you to discuss your needs with us.
Applications close Sunday 25th October 2020.",3.3,"BlueScope
3.3",Wollongong,-1,201 to 500 Employees,-1,Company - Private,Construction,"Construction, Repair & Maintenance",$100 to $500 million (USD),-1
ETL Data Engineer,-1,"ETL Data Engineer

Join a team that’s changing how Australia lives, works, plays and grows
We want you to be the best version of you

Work with innovative teams and explore new technologies to help solve real-world problems.

A typical day as a Data Engineer

ETL / Big Data Engineering professionals will be responsible for guiding the full lifecycle of a Data solution, including:
Working in highly client-facing roles to contribute throughout the end-to-end delivery lifecycle of complex and large-scale digital solutions
Use case and business case development
Support existing and new applications utilizing in-depth technical and data knowledge. Troubleshooting complex issues and providing advisory services to improve the client’s data landscape
Help to streamline and simplify the clients’ complex data landscape by integrating different applications and data architectures
Implementation from requirements analysis, platform selection, digital architecture design, application design and development, testing, and deployment
Interstate travel may be required

Basic qualifications:
Bachelor’s degree
Experience across systems integration, information management, data management and architecture, and business analytics
Experience with being in a team focusing on large-scale, multi-release information centric projects
Experience with waterfall and agile delivery and run / application support functions
Part of a team working on End to end implementation of at least 1 big data project

Preferred Skills:
Hand on experience in Data warehousing using ETL tools such as DataStage, Autosys and TeraData
Hands on experience in ETL job development with multiple stages like sequential file, Transformer, Lookup, join, sort and Database stages.
Strong hand on skills in design, development and implementation of various data remediation, Data migration, data integration techniques.
Strong hand on data modelling experience.
Strong hands on experience in database performance tuning including complex query optimizations and physical database tuning using Teradata.
Understanding of architectural designs and strategy related to data migration, data cleansing, data quality and data consolidation.
Proven data analysis, requirement gathering and problem-solving skills
Exposure to Unix environment and shell scripting.
Experience in Banking and Financial services industry
Desirable: Knowledge of cloud computing infrastructure (e.g. Amazon Web Services EC2, Google Cloud, Microsoft Azure)
About Accenture

Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. We combine unmatched experience and specialized capabilities across more than 40 industries — powered by the world’s largest network of Advanced Technology and Intelligent Operations centers. With 513,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises. Visit us at www.accenture.com.

Accenture is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, marital, domestic or civil partnership status, sexual orientation, gender identity, or any other basis as protected by applicable law.

Vera Goga is the Recruiter managing this role. As the team experience high volumes of applications, we appreciate your patience to allow for a fair and timely process.",3.9,"Accenture
3.9",Sydney,-1,10000+ Employees,1989,Company - Public,Consulting,Business Services,$10+ billion (USD),-1
Student Engineer,-1,"The candidate will have the ability to:
Undertake onsite inspection to collect asset condition data based on the relevant engineering standards and technical guidelines;
Undertake desktop analysis to evaluate the condition and performance of the assets;
Provide the appropriate information, advice, engineering input and support services for the sustainable management of Council’s stormwater and transport networks.
Qualifications:
The successful candidate will be enrolled in a Bachelor of Engineering with a minimum of two years completed.
Position Number: 100678
Position Hours: Fixed term (3 months), hours will be negotiated with the successful candidate, maximum of 75 hours per fortnight.
Salary: Schedule A, Salary Point 4.0. $28.64 per hour ($55,853.45 per annum, pro-rata) in accordance with Glenorchy City Council’s Enterprise Agreement 2016
Please note that all successful applicants will be required to provide a current National Police Check prior to commencement of employment.
For further information on this position, contact Patrick Marshall, Senior Civil Engineer on (03) 6216 6800.
How to apply: Applications for this position must be lodged on this submission site or on the Glenorchy City Council website www.gcc.tas.gov.au - Careers page.
To be considered for this role, all applicants must address the key selection criteria in the and provide a current resume. A copy of the position description can be found by clicking the below hyperlink or on the Glenorchy City Council website.
Applications close at 8pm on Sunday, 1st November 2020
- Student Engineer",4.0,"Glenorchy City Council
4.0",Glenorchy,-1,501 to 1000 Employees,-1,Government,-1,-1,Less than $1 million (USD),-1
Data Engineer involving DevOps,-1,"Data Engineer involving DevOps
Axiom Technologies is an Australia based entity with the history of providing Managed IT solutions to medium to large scale enterprises globally. Please visit our website for more information about what we do at www.axiomtechnologies.com
Axiom Technologies is an Equal Opportunity Employer and encourage applicants from all backgrounds and gender to apply, including, Aboriginal and Torres Strait Islander candidates
Job Requirements:
8+ years IT experience, with at least 5+ years of “Data Engineer/Deveoper” focused titles/roles,
Data Tools: Hands on experience with Apache Beam.
Testing: Hands on experience with automated testing activities/outcomes
DevOps: Experience with the processes involving Microservices facilities for artifacts developed
Platform/OS: Mid-range/Unix
Languages: Unix (Shell) Scripting/commands, SQL, Python
File formats: Text, CSV, Parquet, JSON, XML
Scheduling: Jenkins, Airflow
Auto Scripting: Designing/creation of scripts for repetitive activity. E.g. Unix scripting/SQL
Big data: Exposure to Data Lake Concepts, Hive (Schema), HDFS
Source Control tools: GIT
Delivery Models: Agile, Scrum
Ingestion Design: Create/assess Source/Target data mapping designs
Frameworks: Development and delivery frameworks
Activity Reporting/Repository: Jira, Confluence.
Quality: Accuracy and attention to detail
Industry: Financial Services/Banking
Solutions: Define solutions from High level to detail design to address automating ingestion activity. Facilitate/confirm requirements from product owners, business team members and technical associates,
Process Automation: Automating processes in file management, testing data in files, analysis and design, configuration management.
Script Automation: Ability to design/create scripts to automate/improve data copy/migration/ETL for any repetitive activity.
Languages: Java, Python
Scheduling: Control-M
Databases: Relational. E.g. POSTGRESS, Oracle – as a ETL developer
File Formats: Mainframe – experience with referencing its data formats/copybooks
Big data: Experience referencing/using Hive (Schema) to access data in HDFS
Metadata management tools: MDM, EDC and Axon
Performance: Assess, recommend, improve mappings, SQL queries, Batch feeds
Automation Tools: Other tools that may add value to an automation program and generally support development. E.g. API, REST, JDBC, Webservices, Message Queues/Load balancer,
Cloud: Experience with processing of data files to be ingested/stored in the Cloud, preferably with AWS.
Prod Support: Experience in a production support role performing root cause / impact analysis – under time constraints
Experience in a similar role
8+ Years
What next?
If you are looking for that next challenge in your career and wish to apply for this role, please forward your resume to careers.au@axiomtechnologies.com",2.0,"Axiom Technologies
2.0",Melbourne,-1,1 to 50 Employees,-1,Company - Private,Industrial Manufacturing,Manufacturing,Less than $1 million (USD),-1
Data Engineer,-1,"About the Role
We are on an exciting digital journey so it’s a great time to join ME! We are seeking a Junior Data Engineer who enjoys rolling up their sleeves, learning and growing. As part of our Enterprise Data Team, you will ensure fit for purpose data warehouse solutions are built for use across the bank and by utilising best practise ETL standards, whilst ensuring the data is trusted by our BI developers and key business consumers. Oh, and you’ll get to work on Microsoft technology stack too!
You will be involved with investigating data issues, keeping data feeds flowing and collaborating with different projects across the bank to deliver quality data solutions. How important does that sound? What’s even more important is this role contributes directly to our overall business strategy through the provision of data to enable analytics & reporting, as well as supporting business and decision system processes.

About You
You’re naturally a highly motivated and energetic person who thrives in a dynamic, ever-changing collaborative team environment. Ideally you have previous experience as an ETL developer, Data Engineer or a BI developer, and if you have a degree in computer science or similar it would really put you ahead of the rest.

With your knowledge of SQL coding, data modelling, understanding of data warehouse concepts, plus experience of working on complex ETL solutions, you’re ready to expand your horizons and launch your career into the world of IT at ME.

About ME
We’re not like other banks.
ME was created by the industry super funds to be different from the pack – with a core purpose to help all Australians get ahead financially – no conditions, asterisks or exceptions. And we know that looking after customers starts with taking care of our people.
We believe everyone deserves the same opportunities in life, regardless of gender or identity, sexuality, ethnicity, religion or disability ‒ with internal affinity groups.
Perk ME up
Once you get your feet in the door at ME, we’ll put them both in your very own ME-branded Converse shoes. You’ll also get the following financial, health and fun perks when you join the team:
4U Extras portal (discounts and cashback on 100s of items including cinemas, shopping and gym memberships
10% Myki discount
Purchased Leave programme
Internal wellness programme (Mindfully ME)
Professional education through LinkedIn Learning
Novated Leasing
Professional membership reimbursements
Health checks
Financial education (To help you manage your money smarter)
LGBTIQ+ and Women at ME affinity groups

I want those Converse shoes (and the role)
Can’t see a closing date on the advert? That’s because we’re pretty efficient here at ME and we may start looking at applications sooner rather than later, so if this role sounds like your jam, be sure to apply by submitting your resume today.

Should an applicant be the preferred candidate, background checks (including police checks, reference checks, ASIC banned and disqualified persons and bankruptcy checks) will be completed prior to the candidate's employment being confirmed. The outcomes of the background checks do not automatically bar candidates; however will be assessed against the inherent requirements of the job.
Back Share
Apply Now",3.0,"ME Bank
3.0",Melbourne,-1,501 to 1000 Employees,-1,Company - Private,Banks & Credit Unions,Finance,$100 to $500 million (USD),-1
Software Engineer - Machine Learning/Data Science,-1,"Zendesk is looking for a Software Engineer - Machine Learning/Data Science for a full time position in our Melbourne office.
As part of our engineering team, you will work at a scale where the challenges start to get seriously interesting. Our global engineering team is widely dispersed over the world, with people across nearly every continent. You will get a chance to do cool things with a diverse bunch of people while working in the Melbourne office that is home to Zendesk’s first machine learning (ML) research team.
The Data Science Team, together with Data Engineering, have built Satisfaction Prediction, Answer Bot and Content Cues — products that use Machine Learning (ML) and Artificial Intelligence (AI) to help our customers work more efficiently.
What you get to do every day:
We’re currently looking for someone to join our team as we research, develop, and productionise Machine Learning and Deep Learning models. In addition to frequenting Melbourne’s finest purveyors of coffee, ramen, and bulgogi, you may find yourself:
Building machine learning models including neural networks in TensorFlow
Writing and deploying production-grade Python
Querying and constructing datasets in AWS Athena, Spark
Evaluating and responding to real-world model performance
Scaling your ML to millions of predictions per day
Presenting your work to a broader audience
Watching your algorithm help Zendesk’s end-users
What you'll bring to the role:
A strong foundation in a quantitative discipline (e.g. machine learning, statistics, bio/eco/etc-informatics, econometrics, etc) is critical for this position. While experience in deep learning and natural language processing would be beneficial, your best qualities are:
dedication to continuous learning
collaborative work attitude
strong communication skills
You should also be comfortable with at least one programming language, such as Python, R or Scala.
Application Deadline: 18/11/2020
Job Types: Full-time, Permanent
Salary: $85,000.00 – $110,000.00 per year
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Temporarily due to COVID-19",4.5,"Zendesk
4.5",Melbourne,-1,1001 to 5000 Employees,2007,Company - Public,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),-1
Software Engineer (Machine Learning),-1,"About the Role
AdelaideMRI is building a medical reporting tool. We require an engineer to work primarily on machine learning projects to improve reporting speed and report comprehensiveness.
You will perform data analysis of medical report datasets and image datasets to infer sentence recommendations, image classifications, or other actionable results for the doctors.
Skills and Experience
Background in machine learning or image processing
Qualifications in Computer Science, Software Development or Engineering or equivalent experience
Bonus points for Python
No prior medical knowledge is required.
This position offers flexible hours and work arrangements.
Job Type: Full-time
Experience:
Software Engineering: 1 year (Preferred)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Yes",-1,Adelaide MRI,Australia,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Hey there, we’re PEXA!

We started as an idea: to deliver a single, national e-Conveyancing solution. We collaborated with the industry to create a national electronic lodgement and settlement platform: PEXA. From our humble beginnings, we’ve now grown to more than 320 employees across 5 different states. We’re still expanding at a rapid rate and constantly challenging ourselves to create great experiences for our members as they transition to fully digital conveyancing.

Why become a PEXArian?

Great question! Being a PEXArian is so much more than just a job. We are passionate, motivated & unashamedly enthusiastic at PEXA - we love what we do and we’re proud to admit it! Creating brilliant member experiences wouldn’t be possible if we didn’t also strive to create an amazing employee experience. Alongside our members, our employees are at the heart of everything we do.
Here’s a snapshot of what your life at PEXA could look like:

Your growth:
We encourage you to hit your personal and professional Learning & Development goals with our tailored programs and tools.

Your wellness:
We care about your holistic well being - a fully stocked kitchen, four wellness days, a $250 wellness subsidy as well as lunch and learn sessions to support your financial well being.

Your work/life blend:
We know that work is just one aspect of your life, we want to help you create your ideal work/life blend, rather than squeezing in life around work.

Your family:
With a range of benefits aimed at supporting your family including access to a subsidised school holiday program, extended parental leave and flexi-time to support your return to work, superannuation payments for unpaid parental leave for primary carers and a childcare allowance for pre-primary aged children, when we say, ‘welcome to the family’, we really mean it!
The impact you'd drive:
The successful candidate will be responsible for developing, and maintaining infrastructure to support the delivery of new and existing products. They will also be contributing to establish the rules and frameworks for obtaining the required approvals for new products.
On day one we’d love you to have:
Experience with Python, Spark
Event streaming/sourcing with Kafka or AWS Kinesis
Experience with data structures, formats and data security best practices
AWS experience (e.g CloudFormation, S3, ECS, Lambda, SQS, IAM, KMS, DynamoDB, Glue, Athena)
Query construction and optimisation (e.g. SQL, Elasticsearch, Splunk, DynamoDB)
Git, version control practices, and continuous integration/delivery servers
PyUnit and unit testing frameworks
Production release cycles and maintenance
Collaborating with technical and non-technical teams
Even better:
Agile methodology/delivery
GraphQL
Modern frontend technology (e.g. ReactJS, TypeScript)
Machine learning frameworks and tools (e.g. TensorFlow, PyTorch)
OAuth 2, SAML 2, JWT
Data visualisation and exploration tools (e.g. Jupyter notebooks, Tableau)
AWS SageMaker
Sounds like you?
If this role sounds like you, apply today to have your application reviewed ASAP!",3.9,"Property Exchange Australia Limited
3.9",Melbourne,-1,201 to 500 Employees,2010,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Ongoing position
Full time
Based in Sydney, NSW
Who we are
Australian Red Cross is part of the world’s largest humanitarian organisation. Our aim is to improve the lives of the most vulnerable people in Australia and across our region.
About the role
The Data Engineer role will sit within the Data and Integration Squad in IT and will own (design, implement and support) the AWS Big Data technologies such as the Data Lake and Data Warehouse and support the organisation in growing the data analytics capabilities at Red Cross. In addition to this, the data engineer role will also administer the Power BI tool and support the implementation of the data mastering capability.
What you will bring
Experience building and optimizing data pipelines, architectures and data sets.
Experience in dimensional modelling and building data vaults
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with structured, semi-structured and unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Why work for us?
Work for purpose and know that your work assists Red Cross support and empower people and communities in times of vulnerability.
Generous salary packaging options available that can increase your take home pay.
Further information
To find out more about this opportunity please see the position description below or contact Sharath Kumar Gurram on 02 8651 8839.
Position Description: Position Description - Data Engineer .pdf
Applications for this position will close at 11:55pm Thursday, 5 November 2020.",4.1,"Australian Red Cross
4.1",New South Wales,-1,1001 to 5000 Employees,-1,Nonprofit Organization,Industrial Manufacturing,Manufacturing,$500 million to $1 billion (USD),-1
Junior Fullstack Data Engineer (Python and React),-1,"Formbay is the leading Renewable Energy Certificate Trading company in Sydney. We provide Digital Workflow and Compliance solutions in the renewable energy industry and document processing.
Thanks to our meteoric growth and our commitment to be the best at all we do, we've identified the need to bring on board a new Junior Fullstack Data Engineer.
Reporting to our Principal Machine Learning Engineer, you will help build Machine Learning pipelines for our existing Digital Workflow and Compliance solutions to automate fraud detection and document processing over terabytes of photographic and documentary data – including documents, photos, GPS data and aerial/satellite photography.
Our stack is based on Python, JavaScript, Dask, Tensorflow, CUDA, Nix/NixOS, AWS, Docker, PostgreSQL and more – familiarity with these applications will give you a leg-up on the competition.
Our ideal candidate will have the following competencies:
SQL
Python
JavaScript/TypeScript
Our candidate must also be comfortable working with Linux.
Located a stone's throw away from the Queen Victoria Building in Sydney's bustling CBD, we are centrally-located with easy access to public transportation, bars, cafes and fine dining.
Formbay will provide flexible working hours, a generous remuneration package and the opportunity to work on a world-first software solution are what we can offer you. Free, twice-weekly gym sessions and really, really good coffee are also available.
No hiring/recruitment agencies need apply.",5.0,"Formbay
5.0",Sydney,-1,1 to 50 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is an experienced and qualified Data Engineer to join our IT team based in Birtinya.
Key Responsibilities:
Create and maintain data pipelines and or ETL scripts
Create and maintain data integration including API and Batch interfaces
Performed detailed data analysis
Create and maintain corporate data models
Create and maintain data visualization using Qlik.Sense , PowerBI or Simliar Toolset
Experience in defining, building and maintaining data virtualization and/or star schema data warehouses
Maintain, tune and optimise database, integration and visualisation toolsets
ABOUT YOU:
To succeed in this role, you’ll need to bring the following experience and skills:
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Excellent communication skills both oral and written, with an ability to bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking
Experience with data analysis and modelling will be beneficial

How to Apply
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kawana Waters,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Graduate Data Science / Engineer,-1,"The NRMA is an organisation looking to the future, and right now, we are on the lookout for people who can help us reach our goal: to continue to shape the way Australians move, for the next 100 years and beyond. www.mynrma.com.au.
Everyone new to the team, along with our current staff, will temporarily work from home until it is safe to return to our offices. All interviewing and on boarding will be done virtually due to COVID-19.


Your opportunity
As Graduate Data Scientist or Engineer you will be part of the Data Engineering team delivering cloud data transition program for business initiatives and supporting the entire data platform build.
Your key responsibilities will be to:
Implementing Concepts of Data Warehousing, Data Mart creations within Cloud
Use of SQL for data analysis and insights
Building AI/Machine Learning prototype for implementing and supporting existing algorithms
Data Analytical reports build, using different tool sets


Requirements for Success:
Relevant Degree - Computer Science, Computer Engineering, Software Engineering, Data Science
Excellent SQL skills and demonstrated working knowledge in Python
Demonstrated understanding in data structure and algorithms.
Knowledge and concept of data warehousing methodologies
Any reporting tools experience Tableau or Oracle Analytics Cloud, Looker is desirable
Exposure to Google/AWS/Azure/Oracle any cloud based platforms is desirable
Good communication and interpersonal skills

If you have the required skills and the passion to join our high performing team, please apply today.

Employee Benefits
To ensure our employees feel valued, empowered and celebrated we provide a range of employee benefits including:
50% discount on all NRMA insurances
Free Roadside Assistance
12 weeks paid primary and 4 weeks paid secondary parental leave
Free NRMA Blue Membership
At the NRMA Group, we are People Moving People and diversity and inclusion are part of our DNA. Together, we continue to build an inclusive culture that encourages, supports and celebrates the diverse voices of our employees. It fuels our innovation, promotes flexible ways of working and connects us closer to our members and the communities we serve.",2.5,"NRMA Motoring & Services
2.5",Sydney,-1,501 to 1000 Employees,-1,Nonprofit Organization,Casual Restaurants,"Restaurants, Bars & Food Services",$500 million to $1 billion (USD),-1
Data Centre Engineer,-1,"We are a leading world group that provides low-carbon energy and services. To tackle the climate emergency facing us all, our aim is to become the world leader in the zero-carbon energy transition ""as a service"" for our clients – particular for companies and regional authorities. We use our expertise in our key business areas (renewables, gas, services) to provide competitive and bespoke solutions.
The Data Centre Engineer will be employed as part of a 24/7 ongoing shift to coordinate and monitor third party service providers, maintain the data centre facilities and infrastructure plans, coordinate the implementation of customer requests within the data centre and monitor systems, all in accordance with the Contract KPIs and SLAs.
Coordinate and monitor third party service providers for regular maintenance & testing, service faults & call outs, ensuring works are performed in accordance with Contract SLAs
Monitor and maintain the data centre facilities and infrastructure plans and documentation, including electrical, mechanical, hydraulics, fire and BMS/EMS systems
Coordinate the implementation of internal and external customer requests within the data centre
Perform scheduled plant checks and minor maintenance works
Ensure all Work Order requests are raised and closed in a timely manner
Conduct inductions for staff, vendors and contractors
Ensure all work permits for vendor works are raised and closed
Perform inventory checks on all equipment and critical spares

Qualifications
The selected candidate must be able to demonstrate:
Electrical or HVAC background, or Graduate Electrical or Mechanical Engineer
Passionate about quality work and career minded looking for a new challenge
Can commit to a day and night shift roster (2 days of day shift, then 2 days of night shift, 4 days off)
Ideally able to commence asap
As part of carrying out the duties of this role, it is mandatory to hold Australian Citizenship.

If you are interested and meet the selection criteria apply with an up-to-date resume via the apply instructions on this website.

ENGIE Services is an EEO employer, where all applicants are treated with fairness and respect and have equal access to the opportunities available.

We will not be engaging in the services of a recruitment agency to fill this vacancy and therefore request all interested candidates apply directly to this advertisement.

Job
: Maintenance
Primary Location
: Oceania-Australia-New South Wales-Erskine Park
Organization
: ENGIE Services Australia and New Zealand
Schedule
: Full-time
Nature of Responsibility
: Senior operational / administrative role
Job Posting
: Sep 11, 2020, 6:29:59 AM",3.7,"ENGIE Services Australia & New Zealand
3.7",Sydney,-1,5001 to 10000 Employees,1995,Company - Public,Energy,"Oil, Gas, Energy & Utilities",$2 to $5 billion (USD),-1
Senior Data Engineer,-1,"Senior Data Engineer, Temporary, SYDNEY - McKell

Job Title: Senior Data Engineer

Salary: SNSW Grade 9/10 - The package includes base salary range of $111,806 to $134,667, plus employer's contribution to superannuation and annual leave loading.

Location: Head Office – Haymarket

Employment Status: Temporary through till 30th June 2021


About Service NSW:

Service NSW is making it easier for people and businesses across NSW to access government services. The role designs, builds and analyses complex data from multiple sources to identify revenue, process and business improvement opportunities; providing new information and insights to the business to inform planning, continuous improvement and performance.

About the Role

We are currently seeking to appoint a Senior Data Engineer to deliver expert advice and services in the design of a Single View of Customer and data-related services to support the achievement of business outcomes and strategic goals. We support flexible working practices with staff working remotely during this time.

In this role you will:

Design, build and support a modern data platform based in AWS and vendor technologies.
Provide expertise on data modelling for Graph data model and Customer Data Platform (CDP).
Create data pipelines, load, transformation and reporting workloads in AWS.
Work with the latest data engineering technologies like Apache Kafka, AWS Kinesis, AWS Neptune, AWS Glue and AWS Athena.
Contribute to the design and decision-making of the right tool or platform for the job according to requirements.
Provide expert advice and guidance on data quality and data engineering best practices.
Support a “bigger than you can imagine” scale of data in production environments.
Design, develop and support a metrics-driven reporting solution and a meaningful business intelligence platform.
Document the solution design and support procedures of solutions.
Produce reports, visualisations and recommendations to answer complex business problems that are presented in the most appropriate format to ensure clarity for target audience.
Analyse and define new process improvement opportunities to support continuous improvement and business outcomes; providing advice to stakeholders, on ways to improve the efficiency and reliability of data products and services.
Be very responsive to the information needs of the business by corresponding to customers in a timely manner and provide support/solutions to issues raised.
Troubleshoot and perform root cause analysis on production issues. Identify and implement long term solutions to problems. Perform scheduled maintenance, release deployment and production support activities after business hours, from time to time.
Liaise with internal and external customers to discuss and gather requirements, solutions etc. and maintain a good working relationship with the stakeholders.


Skills and Experience Required:

Solid experience with workflow technologies designing and building data pipelines, data models and data stores.
Experience working within and an understanding of Amazon AWS ecosystem, including security and performance tuning.
Hands on experience working with different types of databases, with focus on Graph and NoSQL databases.
Experience with data streaming required. Having used Kafka and related technologies is an added advantage.
Sound knowledge and experience working with batch processing, data extraction and API integration.
Hands on experience with at least one programming language: Java, Python or scripting.
Demonstrated experience working in an Agile based, fast paced, complex environment within cross-functional teams.
Experience developing systematised insights, data analytics and reporting solutions is an added advantage.
Experience with interactive visualisation of data insights is an added advantage.


Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Salary Grade 9/10, with the base salary for this role starting at 111,806 base plus superannuation

Closing Date: 6th November at 9:59am - applications will be reviewed on a rolling basis, applications may close early or extend

Please apply online, direct applications submitted via email will not be considered.

The Department of Customer Service is proud to be an EEO Employer who are fully focused on equality and believe deeply in diversity of all identities making us different and a true reflection of our NSW customers. As an inclusive workplace, we support various employee resource groups, practice flexible work and workplace adjustment.

If you do require an adjustment during the recruitment process, please notify us on your application form.",3.2,"Service NSW
3.2",Sydney,-1,501 to 1000 Employees,2012,Government,State & Regional Agencies,Government,Unknown / Non-Applicable,-1
Data Engineer - Entry / Mid Level,-1,"Work with a great team on interesting projects customers
Gain more experience in AWS, Data, DevOps cloud operations
Got a working knowledge of AWS? We will teach you the cool stuff!

Itoc is seeking an up and coming Data Engineer to join our growing Data Team in Sydney.

This is an exciting role working with databases, data lakes, data warehouses, data transformation (Python SQL) and enabling AI/ML.

You will be implementing foundational, robust and production ready data platforms to enable business data-discovery, self-service, AI/ML functions across a range of client types and industries, allowing them to do more with their data.

You'll be responsible for:

Deploying data repositories such as lakes and warehouses.
Contribute to our growing portfolio of data solutions.
Ongoing optimisation and management of data platforms.
Development of transformational logic for data pipelines
Data evangelism. We want to show our clients how to follow the best practices for data.

Desired Skills and Experience

To take up the challenge, you will have a depth of skills and experience including:

1-2+ yrs of focused data experience working with SQL and/or NoSQL solutions
A solid education in Software Engineering or equivalent industry experience.
Anything Data focused preferred.
Ability to analyse business scenarios and associated data landscape to derive potential opportunities.
Strong foundation in Python and SQL
Working knowledge of APIs
Principle knowledge of the different relational database platforms and modern data storage techniques
Knowledge of the different aspects of data environments
Collect, store, process, verify consume
Experience with version management systems (such as GIT)
Working knowledge of AWS or another cloud platform - we will teach you the cool stuff.
Great communication skills, an ability to work closely with customers, developers and engineers and the confidence to present ideas in open forums.
Relevant tertiary qualifications and/or industry certifications.
Great communication skills, an ability to work closely with clients, developers and engineers and the confidence to present ideas in open forums.

While not required, a background in consulting and professional services is highly desirable.

Itoc Description

This is an exciting and challenging career opportunity to join the growing Sydney-based Data Team of a leading cloud solution provider where you will be given support to reach your long term career goals. You will be part of a team of cloud experts and will work in an environment of continuous improvement and learning delivering innovative cloud solutions across SaaS, online business and enterprise business.

On offer is a chance to join a team with a great working environment, in an organisation that values its employees and sees the value in ensuring they are engaged. Our team are clearly passionate about what they do, that's why we won the following awards:

Customer Obsession Partner of the Year 2015: ANZ Region
Customer Obsession Leadership Partner 2015: re:Invent

As an employer of choice Itoc offers competitive remuneration, training and development programs and a great working environment. We value a healthy work life balance.

The Perks

MacBook or Dell
Continuous internal learning that will provide training and career development opportunities
Working with a collaborative, social team and leveling-up your skills faster than you will anywhere else.
Quarterly social events

Itoc

Culture and smarts are important to us. Bring your secret sauce. This is no ordinary environment, you will work along some of the Cloud’s best. All engineers at Itoc must gain at least five AWS certifications. We work hard but we have fun.

Please note you must have full working rights in Australia and be available on-shore for face to face interviews.

No recruiters please.",4.0,"Itoc
4.0",Sydney,-1,1 to 50 Employees,2013,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Date: 01-Oct-2020

Location:
Melbourne, VIC, AU

Department:Description:
Technology discounts - from Apple HP Lenovo to Windows
Flexible work arrangements - work in a way that suits you best
Salary packaging - to suit your personal and financial circumstances

Do you want to work for one of the fastest growing data teams in Australia? Do you want to work on multiple data platforms and provide new solution offerings by leveraging cloud and big data technologies?

About the team

Big data information and analytics. Three words that spark apprehension in most businesses. But our team of experts are constantly curious and excited about combining our wonderful array of technological expertise to transform data into our clients most valuable assets making their work smarter. Our data consultants are supported with resources training and tools they need to excel at their work but also the freedom and power to create their own paths forward to make a difference.

As a Senior Consultant in Big Data you will work closely with the team and stakeholders to build and deliver a Cloud based vision for a next generation Big Data analytics platform with strong focus on data quality data security and deliver the systems that process huge volumes of data.

What will you typical day look like?

You will play a pivotal role in - Designing and producing high performing and stable applications to perform complex processing of massive volumes of data in a new cloud based architecture; Building real-time data processing applications which are integrated with business systems to enable value from analytic models to drive rapid decision making; Contributing to system architecture design for a data platform (including cloud-based structures both on and off premises data warehouse components and data lakes); this could cover a range of technologies various countries/locations and lines of business; Support data strategy or technology strategy definition programs including technology stack definition and target operating model requirements

Enough about us lets talk about you:
You are someone with:
Use of traditional data analytics tools and techniques (e.g. MSSQL Oracle MySQL) and ETL software (e.g. SSIS Informatica CloverETL)
Working in large scale cloud data solutions using platforms such as AWS or Azure or GCP will be a bonus.
Experience in scripting or programming (e.g. Python Java Scala C#)
Excellent verbal and written communication skills to adapt to technical and non-technical audiences.
Educated to degree level (or have equivalent experience)
Why Deloitte?

At Deloitte we create positively differentiated work experiences that enable our people to feel valued and achieve their full potential. We value difference and embrace people with diverse backgrounds and thinking styles. Knowing that people work best in different ways we are happy to discuss alternative arrangements if the working pattern you are looking for is not specifically indicated.",3.8,"Deloitte
3.8",Melbourne,-1,10000+ Employees,1850,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Engineer,-1,"Opportunity to grow the team
Period of growth
Intuitive app
S2M are working with a FinTech who have created a unique financial product to help thousands of people better manage their finance, and is currently scaling the company to the next level!

They are looking for a Data Engineer to join, and looking for someone who wants to be hands on, with opportunity to grow the team in future.

Role:

Looking for people with strong AWS experience. You will need passion for data and a cloud, through which you will help a rapidly scaling Australian FinTech establish their data infrastructure from the ground up.
5+ years’ experience as a data engineer within the data and analytics domain
A python 3.X aficionado who is very comfortable creating and orchestrating AWS data pipelines with nothing but code
Strong project delivery toolset experience in open source data integration tools
Experience with processing large volumes of complex data including visualisation and insights generation
Ability to define and develop data integration patterns and pipelines
Ability to assess complexity of data (volume, structure, relationship etc.)
Hands on experience working with different databases (RDBMS, NoSQL, Blob storage etc)
Hands on technical expertise setting up DevOps automation
Hands on experience working technologies/platform e.g. AWS, Dockers, Containers
Experience building data profiling and data cleansing frameworks
Technical reconciliation and reporting
Knowledge and experience in end-to-end project delivery, either traditional SDLC or agile delivery methodologies (or hybrid approaches)
Exceptional communication, documentation and presentation skills
If this sounds like you, get in touch today - kate.gabb@s2m.com.au
3167410agsdf",3.1,"S2M
3.1",Sydney,-1,Unknown,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Analysts,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is seeking experienced and qualified Data Analysts to join our IT team based in our corporate office in Birtinya (Sunshine Coast) or at our meat processing facility in Kilcoy.
Key Responsibilities:
A mixture of data analysis and commercial skills to source, blend and analyse data to gain insight and answer key commercial questions
Working with strategic leaders to define and model Key Performance Indicators, and assist in building forecasting models
Working closely with data engineers and BI developers to specify data pipelines and report visualisation
Drive the creation and implementation of data quality business rule including data definition, governance and quality assurance
About You:
To succeed in this role, you’ll need to bring the following experience and skills:
Proven ability to derive insight and knowledge from data using commercial expertise is a strong requirement
Strong SQL and Excel skills are essential, along with strong data analysis and commercial insights
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Effective people communicator - engage with stakeholders on reporting needs, interpret requirements into visual solutions and train/deliver the outputs to the stakeholders getting signoff of acceptance
Bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking

How to Apply:
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kilcoy,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Network Data Engineer,-1,"Min 6+ years of experience in the relevant technologies
Australian Driving License for visiting remote locations / Data Centre for day to day technical work.
Managing Network devices (switches, routers, firewalls, load balancer, and wireless technology)
Performing MACD activities for all network devices.
Supporting BAU operation activities.
Proficient in performing in-depth details of technical troubleshooting, cause and provide recommendation to the client for incidents causing extended network outage to client’s critical locations.
Provide exceptional network services in terms of network support, break-fix, design and consulting, new projects, implementation.
Configure, administer, and document firewall infrastructure.
Manage the firewall deployment, rules migrations, and firewall administration.
Supporting Cloud Migration Activities from traditional to AWS/Azure.
Setting up VPN tunnel with Cloud and 3rd Party network devices.
Integrating and upgrading existing ISP bandwidth with support from ISP Vendor.
Setting up VPN profiles for Users.
Installing hot fix and patches to mitigate the security devices from attacks and bugs.
Reviewing and fine tuning the firewall rules and NAT rules.
Documentation and change control.
Mentoring, Motivating and Guiding support teams
Technical skills:
o LAN
o Wireless
o WAN
o MPLS
o Routing protocols (OSPF,BGP)
o DMVPN
o Azure cloud Networking
o Network Security
Fortigate Manager / Analyzer / Firewall
Cisco ASA
Firepower FTD
Cisco Any connect
Site to Site VPN
F5 Load Balancing and Scripting iRule
Job Types: Full-time, Contract
Schedule:
8 hour shift
Experience:
Scripting: 5 years (Required)
Data Network: 5 years (Required)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Required)",3.6,"Total IT Global
3.6",Sydney,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Engineer - Processing & Analysis,-1,"Job Description:
Design,build and maintain the ingestion system to support various types of data(e.g. User behavior, RDS, NoSQL db and others) to be ingested to the data warehouse more timely and accurately
Translate data requirements into scalable technical data service with low latency and high concurrency
Design,build and maintain the batch or real time data pipeline in production using Hadoop big data technology
Analyze and improve efficiency, scalability, and stability of the system
Define and manage SLA,Data quality for all data sets in allocated areas of ownership
Requirements:
Minimum B.S. degree in Computer Science or a related technical field
2+ years of working experience in programming languages,such as Java,Scala,Python
Familiar with Hadoop, Spark and Flink data processing, experience of TB data processing experience is a plus
Familiar designing and operating of a robust distributed system is a plus
Understand data mining or machine learning
Excited to work intimately with data
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"SYNOPSIS:
Lead Data Engineer
Applications close Sunday 8 November 2020
Ongoing
Contact name: Shyni Sasikala
Phone: (02) 6249 9048
Email: Shyni.Sasikala@ga.gov.au

The Data Policy and Informatics section within the Digital Science and Information branch creates, implements, and promotes policies, platforms and tools that improve and support the quality, discoverability, accessibility, and general usability of Geoscience Australia’s science data products. The section consults with internal and external research, government and industry partners to establish collaborative data frameworks, architectures and models within Geoscience Australia (GA) and across broader national and international communities of practice. The section innovates, builds and maintains tools, systems, processes and governance that enable digital data management, cataloguing and open data delivery.
GA makes accessible a wide range of geoscientific and spatial data to a wide variety of stakeholders in multiple formats, and in recent years GA's data volumes have grown exponentially. GA is focussed on making its data and metadata assets accessible so that they can be used in machine to machine interactions for data analytics and other applications in environments that range from High Performance Computing (HPC), through high-end cloud servers, to mobile devices.
We currently have two opportunities for Lead Data Engineers in the Informatics team. The Lead Data Engineer is responsible for innovating and exploring new technologies that will advance GA’s science goals and maximise the uptake and use of GA’s science data. The Lead Data Engineer reports to the team’s Assistant Director but also works closely with other developers, data scientists and engineers within the Digital Science and Innovation (DiSI) branch, as well as diverse stakeholders both within and external to GA.",3.9,"Geoscience Australia
3.9",Canberra,-1,501 to 1000 Employees,2001,Government,Federal Agencies,Government,$100 to $500 million (USD),-1
Data Engineer,-1,"The Seven Network is part of Seven West Media, one of Australia’s most prominent media companies, with a market leading presence in content across broadcast television, online and in print. Comprising some of Australia’s most renowned media brands, SWM includes not just Seven Network and its affiliate channels 7two, 7mate, 7flix and BVOD offering 7plus, but also 7NEWS.com.au, The West Australian, The Sunday Times and more.
At Seven we are here to bring all Australians closer to the moments that move us - we’re first on the scene, with our finger on the pulse, on demand, in the moment. Together, we’re responsible for creating and sustaining authentic Australian engagement.
A new and exciting opportunity has opened for a Data Engineer to join the Audience Intelligence team. Based in Sydney and reporting to the Head of Data Enablement, you’ll be responsible for:
Implementation of end to end data solutions to support Data Strategy for the SWM group.
Work closely with the Data Solution Designers to develop and maintain scalable data pipelines and build out new file and API based integrations to address requirements from the various business stakeholders.
Collaborates with engineering, analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organisation.
Work on Data Preparation for analytics and data scientist team members and assist them from an engineering perspective in building and optimising the models including building the automation of the end to end workflows
Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.
Perform data analysis required to troubleshoot data related issues and assist in the resolution of production data issues.
Work effectively with vendors for successful delivery of projects and acceptance of the solution
Work on Delivery projects using Agile Software Development methodologies
We are looking for someone who has:
Bachelor's degree in computer science, computer engineering or other technical discipline is essential
Proven experience working as a digital analytics specialist
Extensive experience with digital analytics implementation (e.g. Google Analytics, Snowplow, Adobe Analytics) and BI processes and visualisation platforms
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience in ETL and building and optimizing ‘big data’ pipelines and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Experience with big data tools: Hadoop, Spark, etc., AWS cloud services: EC2, S3, Lambda and familiar with version control systems: Git
Strong coding skills with knowledge of Unix/Linux and scripting languages such as Unix Shell scripting, Python desirable
Experience supporting and working with cross-functional teams in a fast-paced environment.
Ability to multi-task and problem solve with changing demands and priorities
Ability to work under pressure to meet deadlines and detail oriented
Your success is our success: we will provide you with opportunities for you to keep learning and growing, enabling you to challenge and develop yourself. In return, we offer a benefits program that has something in it for everyone.
Seven West Media is an equal opportunity employer and we are committed to creating a diverse and inclusive workplace.
Recruitment Agencies: Seven West Media does not accept any unsolicited agency resumes and will not be responsible for any fees related to unsolicited resumes.
Advertised: 19 Oct 2020 12:00 AM AUS Eastern Daylight Time
Applications close:

Back to search results",2.5,"Seven West Media
2.5",Sydney,-1,5001 to 10000 Employees,1956,Company - Public,TV Broadcast & Cable Networks,Media,Unknown / Non-Applicable,-1
BICON Rules Engineer,-1,"APS 5 - $73,299 - $80,410 per annum plus superannuation
Biosecurity Plant Division
Canberra, ACT
Play an active role in managing biosecurity risk to Australia
Work in a motivated and professional team with a wide range of skills and backgrounds
Full training provided

Who we are
The BICON Content Development Team maintains and improves the Biosecurity Import CONditions database (BICON) content to allow external clients to understand and comply with their biosecurity obligations and internal clients to effectively manage biosecurity risk and regulate imports. We work collaboratively with internal clients to comprehend and implement their BICON content requirements and optimise the use of BICON to publish clear import requirements and onshore management support procedures to effectively manage biosecurity risk.

The Jobs
Key duties of these positions include:

working with business content (import and permit conditions) and import programs to understand and construct decision tree structures in the BICON database, in accordance with system design and authoring conventions
executing changes to import and permit conditions in alignment with service standards while complying with system rules and authoring conventions
providing technical advice through various formats on the most appropriate means of authoring BICON content to achieve import program and stakeholder objectives
using workflow management tools to maintain detailed records of changes to import conditions and key decisions
performing administrative tasks including system reporting, data analysis and scoping tasks for the BICON content change work program
contributing to the development and maintenance of instructional material, authoring conventions and courseware
clearly documenting and reporting system issues
developing and maintaining effective working relationships with internal and external stakeholders.

What we are looking for
Knowledge and experience
Experience working with complex IT systems.
Experience working collaboratively and as part of a team.
Knowledge of the role of biosecurity is preferred but not essential.

For additional information, please read the Job Description below.
Candidate Information Package docx Opens in new window",3.9,"Department of Agriculture & Water Resources
3.9",Australia,-1,5001 to 10000 Employees,-1,Government,Federal Agencies,Government,$500 million to $1 billion (USD),-1
Cloud Data Engineer,-1,"Job no: 509605
Work type: Permanent Full Time
Location: Melbourne, Canberra, Sydney
Do you embrace digital disruption?
Do you love solving complex problems, designing sophisticated solutions and building innovative technology?
Do you believe in creating powerful actionable insights from Data and Analytics?
Do you want to work in a diverse and flexible working environment?
KPMG is one of the most trusted and respected global professional services firms. Through depth of expertise, clarity of insight and strength of purpose we help our clients solve complex challenges, steer change, strengthen, transition and grow. We are a team based practice and this extends to our clients whom we work and collaborate with, in solving complex problems. Together, we design, innovate and implement, providing enduring advice that support our clients and the services they deliver. Our clients vary in size and come from a diverse range of sectors – all sharing in a common goal: to embrace change and deliver services that make Australia a better place. We are looking for talented individuals who would like to join us on the journey.
KPMG’s Digital Delta Team
We re-imagine and re-invent organisations to become world class digital enterprises using advanced technologies, data and human insights. We help organisations to embrace Digital Strategy, Artificial Intelligence (AI) & Cognitive, the Internet of Things (IoT), Data, Analytics & Modelling, Mobile App & Web, and User Experience (UX) & User Interface (UI) and more.
We work with clients to:
Formulate strategies that re-imagine organisations
Harness innovation from the 4th industrial revolution
Actioning insights from trusted data to consistently and quickly make clear decisions
Build adaptive organisations
Thrive as a connected enterprise – front, middle and back office
This is how you’ll contribute:
We are looking for ambitious Data Engineers who are passionate about helping clients define bold ambitions and deliver on them. Joining our team will take you on a journey of personal and technical growth and provide the opportunity to inspire confidence and empower change.
As a Data Engineer you are the designer, builder and manager of the information or ""big data"" infrastructure, preparing data for analytical or operational use. You will design, construct, test and maintain a data pipeline to pull together information from different source systems; integrating, consolidating and cleansing data; and structure it for use in individual analytics applications.
The KPMG Difference
Our people are focused on creating a diverse and dynamic environment that embraces and values differences. We value the variety of unique experiences, qualities and characteristics our people possess and we share and learn from each other.
We are proud to be consistently recognised as an employer of choice for women, and for our achievements in LGBT+ workplace inclusion.
Our commitment to ‘Flexibility’ allows our people to manage the changing demands of work, personal or family life. Explore the links below to hear our people share their experience @ KPMG:
Flexibility empowers wellbeing
Flexibility enables contribution to the community
Flexibility inspires technology & innovation
Flexibility supports family

Make KPMG the clear choice for your career and be Extraordinary!

Advertised: 09 Sep 2020 AUS Eastern Standard Time
Applications close:",3.8,"KPMG
3.8",Sydney,-1,10000+ Employees,1987,Subsidiary or Business Segment,Accounting,Accounting & Legal,$2 to $5 billion (USD),-1
Computer Network and Systems Engineer,-1,"Duties Include but are not limited to:
Tasks Include:
analysing, developing, interpreting and evaluating complex system design and architecture specifications, data models and diagrams in the development, configuration and integration of computer systems
researching, analysing, evaluating and monitoring network infrastructure to ensure networks are configured to operate at optimal performance
assessing and recommending improvements to network operations and integrated hardware, software, communications and operating systems
providing specialist skills in supporting and troubleshooting network problems and emergencies
installing, configuring, testing, maintaining and administering new and upgraded networks, software database applications, servers and workstations
providing network programming in support of specific business needs and requirements
preparing and maintaining procedures and documentation for network inventory, and recording diagnosis and resolution of network faults, enhancements and modifications to networks, and maintenance instructions
monitoring network traffic, and activity, capacity and usage to ensure continued integrity and optimal network performance
Skills and Experience Required:
Must have experience working in a Managed Service environment
Demonstrated experience in IT Networks and Data Centres
Understanding of systems and architectures to meet client needs
Experience in Help Desk including break / fix
Effective and timely documentation
Effective Task Management Skills
Be solution and outcome focused and willing to learn new technologies
Excellent communication skills with staff, clients and partners
Time management, ability to prioritise and deliver to schedule
Experience with N-Able and Connectwise desired
Open Cabling license desired
Job Types: Full-time, Permanent
Salary: $30.00 per hour
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,Trans-plant training,Canberra,-1,-1,-1,-1,-1,-1,-1,-1
Software Engineer (Data),-1,"If you are looking for an opportunity to make a real impact with smart people who are genuinely doing things differently then you've come to the right place! We're growing our data engineering capabilities and are looking for awesome data engineers to join our team.
With our diverse range of clients and projects, no day will look the same - but here's a great snapshot of what you'll be doing:
Work with some of the best Data Scientists and Engineers to deliver production-grade AI and Machine Learning systems as we deliver client projects from inception to production.
Consulting with our clients and working with them to build modern data systems using the 'best of' technologies and principles.
Advising clients on data strategy, architecture and technology.
Applying best software engineering practices in coding, monitoring and alerting, using CI/CD, TDD and cloud architectures.
Working over a wide range of big data tools and environments: not limited to; Apache Kafka, Spark, Python, Scala, Hive, Airflow, AWS EMR & Glue, GCP Dataproc & Dataflow, BigQuery, Snowflake, Redshift.
Who are we?
Glad you asked! We are Eliiza. Data science. Engineered for scale.
We are a passionate team of data scientists and engineers who apply data science and machine learning to solve real-world problems. Our mission is to create a bright future for Australian businesses and society in a world increasingly influenced by intelligent technologies.
We've created a culture that values diversity where people can truly be themselves! We care a lot about growing the Australian AI community in a positive direction, and we're doing several things to try and achieve that:
We provide opportunities for underrepresented groups to work in AI through our associate and intern programmes
We organise and participate in a range of community events, reading groups and meetups
We produce the AI Australia podcast
We blog about topics we care about
We stream brown bag sessions to the broader community
We're also part of Mantel Group's 'house of brands' which means it's not just the Eliiza team you'll work with, learn from and see at social events - there's another 230 of us across DigIO, Kasna & CMD Solutions!
So you're ready for something new?
We're keen to know more about you! Our team is made up of a range of people, with different experience across a huge range of data driven skill sets.
We'd love to hear from you if you have experience with:
one (or more) core language(s), ideally Scala, Python or Java
one (or more) cloud platforms, AWS, GCP, Azure
ETL/ELT concepts and technologies e.g. Data partitioning, Hive, Spark
streaming data concepts and technologies, ideally Kafka (Kinesis, Beam or Pubsub will do)
We'd be over the moon if you:
Experience with distributed/columnar databases (e.g. Snowflake, Big query, Redshift).
Experience with any of a variety of databases e.g. RDMS, NoSql, Columar, Distributed, Time series, Graph.
Knowledge of job orchestration and scheduling. Any experience with Airflow, Luigi or Oozie.
Experience with containers and container orchestration (Docker, Docker Compose or Kubernetes).
However, we value a diversity of skill-sets, and don't necessarily require that you're skilled with all of the above. If you feel you don't fit all the experience/skills listed above we still encourage you to apply or get in touch.
What's on offer if you join us?
We make sure you're always one step ahead by investing your learning and development, every year. We build our own training where it doesn't exist yet.
We hire smart people and get out of their way. By focusing on our five principles and not getting caught up in red tape, we trust you to get the job done.
You'll get all the tools you need - a new iPhone or Google phone, a new Macbook Pro or Dell, and a lot of branded swag!
But hold on, you mentioned a house of brands?
We certainly did! Mantel Group is an Australian-owned, 'house of brands' company with four technology businesses (Eliiza being one of them!) across Melbourne and Sydney. We're building a group of companies with open borders so we can support you to take on new skills without leaving an awesome team - we understand you won't have one job for life!
We may only be just two years old but Mantel Group has already been recognised #9 in the 2020 Best Places to Work in Australia and #4 in the AFR's 2020 fastest growing new companies.
Keen to chat?
Click ""Apply"" to share your details with our talent team, and we'll be in touch.
In the meantime, check out 'how we hire' to find out what's in store if you're successful and get to know us better by visiting our website and following Eliiza on LinkedIn.",-1,Eliiza,Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Infrastructure Engineer,-1,"Job Description:
Design and grow the Shopee data platform to support a variety of big data applications using open-source technologies including Kafka, Hadoop, Presto, HBase, Spark, Hive, Druid, and our own creations. Some examples include a real-time data streaming platform, a unified query platform, a cluster management system, and a machine learning platform
Dig into the source code of some open-source big data system to get the whole control and familiar with the details, configurations, designs and source code. Develop and maintain the internal release of big data systems and components as the business requirements.
Keep close and overall monitoring for all the deployments of the systems, maintain the system’s stability, improve the performance, discover the performance bottlenecks, tracking and troubleshooting, cost optimisation.
Requirements:
B. Sci. / Ms / PhD in Computer Science or a related technical field
Familiar with at least one of these languages: Java, Scala, Python, Bash under Linux / Unix. Scala is a plus
Familiar with the use and compute logical of SQL
Knowledge about the Big Data Infrastructure system technology like Distributed File System, Distributed Computing, Distributed Database will be a plus
Hands-on experiences Hadoop, Spark, Kafka, and/or Presto will be a plus
Love to use and develop open-source technologies
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"Work on an award-winning, international technology!
Endless career opportunities
An innovative, friendly team of 300+
This role will be focused on the development of our existing ClaimLogik line of products as well as working on our new cloud-first, modern suite of applications.

Intelligent Thought, our technology business is scaling and shipping our software globally. Already profitable, part of a much larger group business, with investors such as Macquarie Capital and Envest – we are all set to deliver textbook disruption to the Insurance Industry. The growth of the platform, of our customer base, and the increasing industry demand have led to the need for this role to help the team scale.

Our Philosophy
Give each employee a sense of purpose and an environment for them to connect the importance of their role to delivering a service that matters to our customers.
Challenge the ‘why’ of traditional claims processes.
Keep it simple – do only what brings value and what matters to the customer
Enable employee decisions, empower our people
Responsibilities:
Create, extend and maintain ETL pipelines to form our data lake, data warehouse and analytics platform (currently using the Microsoft Azure set of tools and service)
Help define the optimal data pipeline architecture
Influence the tool selection, platform selection, data architecture and strategy which will transform the business to be truly data-driven
Understand, analyse and size user requirements
Work with different parts of the business to provide them with the insights they need to deliver the best results
Skills & experience:
Degree or qualification in computer science or related
Advanced knowledge of relational database, including query authoring and query optimisation (MS SQL Server and PostgreSQL).
Experience building and optimising ETL pipelines
Experience designing complex data models
Experience working with cloud platforms (Azure or AWS)
Efficient time management and organisational skills
High attention to detail and accuracy
Effective communication skills to build strong working relationships; both written and verbal
Proactive and results-driven
Why Claim Central?
Claim Central Consolidated is a global insurance industry leader across, claims management, insurance technology and data and analytics. Currently operating in the United States, Australia, South Africa, Italy and New Zealand, we have pioneered digitally connected claims management services across the globe. Claim Central is a disruptor and thought leader in the industry and we were recognised as the Australian Financial Review’s 8th Most Innovative Company in Australia in 2016. This business is in a period of unprecedented growth, transitioning our technology and services into multiple geographies at a rapid pace. Our unique culture is based on teamwork, collaboration, trust, respect and performance. We also offer many benefits apart from our exceptional team culture; including flexible work arrangements, and continued professional development.

Be a part of this journey in a career-defining role.",-1,Claim Central,Matraville,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer - AI/ML,-1,"Our client provides services to a major industry across the country. The business is still early in it's days of technology development and the environment is greenfields in nature (no pun intended), effectively working like a start-up.

Their data and analytics team have worked and built leading and bleeding-edge technologies in this space and what they have created so far may be game-changing. From a machine learning perspective, the progress they have made to the business has already seen proven success in changing the future of an industry that will have positive consequences for all those involved.

You will have previously worked in a technical capacity in the data and analytics space and have experience working with an organisation where machine learning has been implemented, not just a concept that the business talks about having or the technology team would love to have. The commercial experience you will have had in the ML field will be proven examples of where you have affected the way a business or industry used to perform, to the changes that have come about from this.

Technically, you will have extensive experience in the Microsoft space - Power BI, Azure etc and you will have previously mentored and coached junior members of the teams you have been part of.

This is a rare opportunity in Brisbane where the business has truly embraced and funded projects across the ML space and would be a great chance for those in the Data Development/Data Engineering field, who are looking to move into a Data Scientist role in the future.

Please send your application through if you would like to know more.",4.0,"Emanate Technology
4.0",Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Solution designer/ ETL Engineer & Data Modeller,-1,"We are looking for a Qualified and Experienced Solution Designer to join our client for a period of 6 months with a view to extend.
You will work closely with team members and your contribution will range across gathering and analyzing information, developing and documenting improved processes and work instructions and experienced DWH Lead with skills in requirement analysis, solution designing, developing, testing and supporting ETL solutions.
A hands-on solution designer, data modeler and ETL developer for Data Warehousing and ETL application transformation projects using Informatica PowerCenter.
Knowledge on AWS, S3, Redshift, Informatica BDM, and related technologies.
Experience working with IPython, PySparks, AuCuMo, Airflow, Jenkins, Github, Athena, JIRA, Rally, Spectrum, Glue, Flyway.
Good exposure on Oracle PL/SQL, aware of DBA activities, writing and performance tuning of complex SQL queries.
Contract length: 6 months
Job Types: Full-time, Contract
Salary: $650.00 – $800.00 per day
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,nducive,Melbourne,-1,-1,-1,-1,-1,-1,-1,-1
"Data Engineer, Wollongong NSW or Mount Waverley VIC",-1,"Company Description
BlueScope is a technically advanced supplier of steel and steel products in Australia. We are an inclusive organisation and every day we showcase our technology and expertise throughout the world.

Job Description
We are looking for two Data Engineers to join our IT team, based in Wollongong NSW or Mount Waverley VIC. Use your experience in analytics to unlock business value, enabling use of big data for insights and decision-making.
Reporting to the Data Product Owner for our Australian Steel Products (ASP) business, this position will support strategic goals related to data. This will see you:
Gather business and technical requirements with the view to deliver outcomes;
Develop and implement end-to-end data collection, consolidation, modelling and visualisation solutions;
Document metadata in a dictionary and catalogue;
Ensure consumers of such information understand its accuracy, timeliness, quality and sensitivity, so that it is used appropriately; and
Identify opportunities to enhance analytics.
What are the benefits?
Work in a supportive and collaborative team environment whilst we embark on a journey to transform the way our business uses data!
Our systems landscape is broad and diverse. You will be encouraged to think creatively to develop data solutions which solve real business problems.
Working in this role you will enjoy:
the chance to learn more about data science;
salaried remuneration with attractive superannuation options;
the opportunity to participate in a performance incentive scheme; and
access to further development and career opportunities with BlueScope.
Who are we looking for?
We welcome applications from professionals with experience in data analytics and/or programming. Supported by your knowledge of project delivery methods (e.g. Agile), you will demonstrate:
experience with data mining, wrangling, mapping and visualisation techniques (e.g. Azure Data Factory, Databricks and/or DevOps etc.);
well-developed ability in gathering business and technical requirements;
skills in developing and implementing collection, consolidation, modelling and visualisation solutions; and
a passion for sharing your knowledge and desire for ongoing professional development.

Qualifications

null

Additional Information
We're proud to have been named an Inclusive Employer for 2019–2020 by the Diversity Council of Australia. We believe that our people are our strength. Having a diverse and inclusive workplace enables us to improve our capability and ensure continued, sustainable success.
We know that workplace flexibility can mean something different to everyone. Under our B-Flex initiative all of our roles have some degree of flexibility. We encourage you to discuss your needs with us.
Applications close Sunday 25th October 2020.",3.3,"BlueScope
3.3",Wollongong,-1,201 to 500 Employees,-1,Company - Private,Construction,"Construction, Repair & Maintenance",$100 to $500 million (USD),-1
ETL Data Engineer,-1,"ETL Data Engineer

Join a team that’s changing how Australia lives, works, plays and grows
We want you to be the best version of you

Work with innovative teams and explore new technologies to help solve real-world problems.

A typical day as a Data Engineer

ETL / Big Data Engineering professionals will be responsible for guiding the full lifecycle of a Data solution, including:
Working in highly client-facing roles to contribute throughout the end-to-end delivery lifecycle of complex and large-scale digital solutions
Use case and business case development
Support existing and new applications utilizing in-depth technical and data knowledge. Troubleshooting complex issues and providing advisory services to improve the client’s data landscape
Help to streamline and simplify the clients’ complex data landscape by integrating different applications and data architectures
Implementation from requirements analysis, platform selection, digital architecture design, application design and development, testing, and deployment
Interstate travel may be required

Basic qualifications:
Bachelor’s degree
Experience across systems integration, information management, data management and architecture, and business analytics
Experience with being in a team focusing on large-scale, multi-release information centric projects
Experience with waterfall and agile delivery and run / application support functions
Part of a team working on End to end implementation of at least 1 big data project

Preferred Skills:
Hand on experience in Data warehousing using ETL tools such as DataStage, Autosys and TeraData
Hands on experience in ETL job development with multiple stages like sequential file, Transformer, Lookup, join, sort and Database stages.
Strong hand on skills in design, development and implementation of various data remediation, Data migration, data integration techniques.
Strong hand on data modelling experience.
Strong hands on experience in database performance tuning including complex query optimizations and physical database tuning using Teradata.
Understanding of architectural designs and strategy related to data migration, data cleansing, data quality and data consolidation.
Proven data analysis, requirement gathering and problem-solving skills
Exposure to Unix environment and shell scripting.
Experience in Banking and Financial services industry
Desirable: Knowledge of cloud computing infrastructure (e.g. Amazon Web Services EC2, Google Cloud, Microsoft Azure)
About Accenture

Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. We combine unmatched experience and specialized capabilities across more than 40 industries — powered by the world’s largest network of Advanced Technology and Intelligent Operations centers. With 513,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises. Visit us at www.accenture.com.

Accenture is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, marital, domestic or civil partnership status, sexual orientation, gender identity, or any other basis as protected by applicable law.

Vera Goga is the Recruiter managing this role. As the team experience high volumes of applications, we appreciate your patience to allow for a fair and timely process.",3.9,"Accenture
3.9",Sydney,-1,10000+ Employees,1989,Company - Public,Consulting,Business Services,$10+ billion (USD),-1
Student Engineer,-1,"The candidate will have the ability to:
Undertake onsite inspection to collect asset condition data based on the relevant engineering standards and technical guidelines;
Undertake desktop analysis to evaluate the condition and performance of the assets;
Provide the appropriate information, advice, engineering input and support services for the sustainable management of Council’s stormwater and transport networks.
Qualifications:
The successful candidate will be enrolled in a Bachelor of Engineering with a minimum of two years completed.
Position Number: 100678
Position Hours: Fixed term (3 months), hours will be negotiated with the successful candidate, maximum of 75 hours per fortnight.
Salary: Schedule A, Salary Point 4.0. $28.64 per hour ($55,853.45 per annum, pro-rata) in accordance with Glenorchy City Council’s Enterprise Agreement 2016
Please note that all successful applicants will be required to provide a current National Police Check prior to commencement of employment.
For further information on this position, contact Patrick Marshall, Senior Civil Engineer on (03) 6216 6800.
How to apply: Applications for this position must be lodged on this submission site or on the Glenorchy City Council website www.gcc.tas.gov.au - Careers page.
To be considered for this role, all applicants must address the key selection criteria in the and provide a current resume. A copy of the position description can be found by clicking the below hyperlink or on the Glenorchy City Council website.
Applications close at 8pm on Sunday, 1st November 2020
- Student Engineer",4.0,"Glenorchy City Council
4.0",Glenorchy,-1,501 to 1000 Employees,-1,Government,-1,-1,Less than $1 million (USD),-1
Data Engineer involving DevOps,-1,"Data Engineer involving DevOps
Axiom Technologies is an Australia based entity with the history of providing Managed IT solutions to medium to large scale enterprises globally. Please visit our website for more information about what we do at www.axiomtechnologies.com
Axiom Technologies is an Equal Opportunity Employer and encourage applicants from all backgrounds and gender to apply, including, Aboriginal and Torres Strait Islander candidates
Job Requirements:
8+ years IT experience, with at least 5+ years of “Data Engineer/Deveoper” focused titles/roles,
Data Tools: Hands on experience with Apache Beam.
Testing: Hands on experience with automated testing activities/outcomes
DevOps: Experience with the processes involving Microservices facilities for artifacts developed
Platform/OS: Mid-range/Unix
Languages: Unix (Shell) Scripting/commands, SQL, Python
File formats: Text, CSV, Parquet, JSON, XML
Scheduling: Jenkins, Airflow
Auto Scripting: Designing/creation of scripts for repetitive activity. E.g. Unix scripting/SQL
Big data: Exposure to Data Lake Concepts, Hive (Schema), HDFS
Source Control tools: GIT
Delivery Models: Agile, Scrum
Ingestion Design: Create/assess Source/Target data mapping designs
Frameworks: Development and delivery frameworks
Activity Reporting/Repository: Jira, Confluence.
Quality: Accuracy and attention to detail
Industry: Financial Services/Banking
Solutions: Define solutions from High level to detail design to address automating ingestion activity. Facilitate/confirm requirements from product owners, business team members and technical associates,
Process Automation: Automating processes in file management, testing data in files, analysis and design, configuration management.
Script Automation: Ability to design/create scripts to automate/improve data copy/migration/ETL for any repetitive activity.
Languages: Java, Python
Scheduling: Control-M
Databases: Relational. E.g. POSTGRESS, Oracle – as a ETL developer
File Formats: Mainframe – experience with referencing its data formats/copybooks
Big data: Experience referencing/using Hive (Schema) to access data in HDFS
Metadata management tools: MDM, EDC and Axon
Performance: Assess, recommend, improve mappings, SQL queries, Batch feeds
Automation Tools: Other tools that may add value to an automation program and generally support development. E.g. API, REST, JDBC, Webservices, Message Queues/Load balancer,
Cloud: Experience with processing of data files to be ingested/stored in the Cloud, preferably with AWS.
Prod Support: Experience in a production support role performing root cause / impact analysis – under time constraints
Experience in a similar role
8+ Years
What next?
If you are looking for that next challenge in your career and wish to apply for this role, please forward your resume to careers.au@axiomtechnologies.com",2.0,"Axiom Technologies
2.0",Melbourne,-1,1 to 50 Employees,-1,Company - Private,Industrial Manufacturing,Manufacturing,Less than $1 million (USD),-1
Data Engineer,-1,"About the Role
We are on an exciting digital journey so it’s a great time to join ME! We are seeking a Junior Data Engineer who enjoys rolling up their sleeves, learning and growing. As part of our Enterprise Data Team, you will ensure fit for purpose data warehouse solutions are built for use across the bank and by utilising best practise ETL standards, whilst ensuring the data is trusted by our BI developers and key business consumers. Oh, and you’ll get to work on Microsoft technology stack too!
You will be involved with investigating data issues, keeping data feeds flowing and collaborating with different projects across the bank to deliver quality data solutions. How important does that sound? What’s even more important is this role contributes directly to our overall business strategy through the provision of data to enable analytics & reporting, as well as supporting business and decision system processes.

About You
You’re naturally a highly motivated and energetic person who thrives in a dynamic, ever-changing collaborative team environment. Ideally you have previous experience as an ETL developer, Data Engineer or a BI developer, and if you have a degree in computer science or similar it would really put you ahead of the rest.

With your knowledge of SQL coding, data modelling, understanding of data warehouse concepts, plus experience of working on complex ETL solutions, you’re ready to expand your horizons and launch your career into the world of IT at ME.

About ME
We’re not like other banks.
ME was created by the industry super funds to be different from the pack – with a core purpose to help all Australians get ahead financially – no conditions, asterisks or exceptions. And we know that looking after customers starts with taking care of our people.
We believe everyone deserves the same opportunities in life, regardless of gender or identity, sexuality, ethnicity, religion or disability ‒ with internal affinity groups.
Perk ME up
Once you get your feet in the door at ME, we’ll put them both in your very own ME-branded Converse shoes. You’ll also get the following financial, health and fun perks when you join the team:
4U Extras portal (discounts and cashback on 100s of items including cinemas, shopping and gym memberships
10% Myki discount
Purchased Leave programme
Internal wellness programme (Mindfully ME)
Professional education through LinkedIn Learning
Novated Leasing
Professional membership reimbursements
Health checks
Financial education (To help you manage your money smarter)
LGBTIQ+ and Women at ME affinity groups

I want those Converse shoes (and the role)
Can’t see a closing date on the advert? That’s because we’re pretty efficient here at ME and we may start looking at applications sooner rather than later, so if this role sounds like your jam, be sure to apply by submitting your resume today.

Should an applicant be the preferred candidate, background checks (including police checks, reference checks, ASIC banned and disqualified persons and bankruptcy checks) will be completed prior to the candidate's employment being confirmed. The outcomes of the background checks do not automatically bar candidates; however will be assessed against the inherent requirements of the job.
Back Share
Apply Now",3.0,"ME Bank
3.0",Melbourne,-1,501 to 1000 Employees,-1,Company - Private,Banks & Credit Unions,Finance,$100 to $500 million (USD),-1
Software Engineer - Machine Learning/Data Science,-1,"Zendesk is looking for a Software Engineer - Machine Learning/Data Science for a full time position in our Melbourne office.
As part of our engineering team, you will work at a scale where the challenges start to get seriously interesting. Our global engineering team is widely dispersed over the world, with people across nearly every continent. You will get a chance to do cool things with a diverse bunch of people while working in the Melbourne office that is home to Zendesk’s first machine learning (ML) research team.
The Data Science Team, together with Data Engineering, have built Satisfaction Prediction, Answer Bot and Content Cues — products that use Machine Learning (ML) and Artificial Intelligence (AI) to help our customers work more efficiently.
What you get to do every day:
We’re currently looking for someone to join our team as we research, develop, and productionise Machine Learning and Deep Learning models. In addition to frequenting Melbourne’s finest purveyors of coffee, ramen, and bulgogi, you may find yourself:
Building machine learning models including neural networks in TensorFlow
Writing and deploying production-grade Python
Querying and constructing datasets in AWS Athena, Spark
Evaluating and responding to real-world model performance
Scaling your ML to millions of predictions per day
Presenting your work to a broader audience
Watching your algorithm help Zendesk’s end-users
What you'll bring to the role:
A strong foundation in a quantitative discipline (e.g. machine learning, statistics, bio/eco/etc-informatics, econometrics, etc) is critical for this position. While experience in deep learning and natural language processing would be beneficial, your best qualities are:
dedication to continuous learning
collaborative work attitude
strong communication skills
You should also be comfortable with at least one programming language, such as Python, R or Scala.
Application Deadline: 18/11/2020
Job Types: Full-time, Permanent
Salary: $85,000.00 – $110,000.00 per year
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Temporarily due to COVID-19",4.5,"Zendesk
4.5",Melbourne,-1,1001 to 5000 Employees,2007,Company - Public,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),-1
Software Engineer (Machine Learning),-1,"About the Role
AdelaideMRI is building a medical reporting tool. We require an engineer to work primarily on machine learning projects to improve reporting speed and report comprehensiveness.
You will perform data analysis of medical report datasets and image datasets to infer sentence recommendations, image classifications, or other actionable results for the doctors.
Skills and Experience
Background in machine learning or image processing
Qualifications in Computer Science, Software Development or Engineering or equivalent experience
Bonus points for Python
No prior medical knowledge is required.
This position offers flexible hours and work arrangements.
Job Type: Full-time
Experience:
Software Engineering: 1 year (Preferred)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Yes",-1,Adelaide MRI,Australia,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Hey there, we’re PEXA!

We started as an idea: to deliver a single, national e-Conveyancing solution. We collaborated with the industry to create a national electronic lodgement and settlement platform: PEXA. From our humble beginnings, we’ve now grown to more than 320 employees across 5 different states. We’re still expanding at a rapid rate and constantly challenging ourselves to create great experiences for our members as they transition to fully digital conveyancing.

Why become a PEXArian?

Great question! Being a PEXArian is so much more than just a job. We are passionate, motivated & unashamedly enthusiastic at PEXA - we love what we do and we’re proud to admit it! Creating brilliant member experiences wouldn’t be possible if we didn’t also strive to create an amazing employee experience. Alongside our members, our employees are at the heart of everything we do.
Here’s a snapshot of what your life at PEXA could look like:

Your growth:
We encourage you to hit your personal and professional Learning & Development goals with our tailored programs and tools.

Your wellness:
We care about your holistic well being - a fully stocked kitchen, four wellness days, a $250 wellness subsidy as well as lunch and learn sessions to support your financial well being.

Your work/life blend:
We know that work is just one aspect of your life, we want to help you create your ideal work/life blend, rather than squeezing in life around work.

Your family:
With a range of benefits aimed at supporting your family including access to a subsidised school holiday program, extended parental leave and flexi-time to support your return to work, superannuation payments for unpaid parental leave for primary carers and a childcare allowance for pre-primary aged children, when we say, ‘welcome to the family’, we really mean it!
The impact you'd drive:
The successful candidate will be responsible for developing, and maintaining infrastructure to support the delivery of new and existing products. They will also be contributing to establish the rules and frameworks for obtaining the required approvals for new products.
On day one we’d love you to have:
Experience with Python, Spark
Event streaming/sourcing with Kafka or AWS Kinesis
Experience with data structures, formats and data security best practices
AWS experience (e.g CloudFormation, S3, ECS, Lambda, SQS, IAM, KMS, DynamoDB, Glue, Athena)
Query construction and optimisation (e.g. SQL, Elasticsearch, Splunk, DynamoDB)
Git, version control practices, and continuous integration/delivery servers
PyUnit and unit testing frameworks
Production release cycles and maintenance
Collaborating with technical and non-technical teams
Even better:
Agile methodology/delivery
GraphQL
Modern frontend technology (e.g. ReactJS, TypeScript)
Machine learning frameworks and tools (e.g. TensorFlow, PyTorch)
OAuth 2, SAML 2, JWT
Data visualisation and exploration tools (e.g. Jupyter notebooks, Tableau)
AWS SageMaker
Sounds like you?
If this role sounds like you, apply today to have your application reviewed ASAP!",3.9,"Property Exchange Australia Limited
3.9",Melbourne,-1,201 to 500 Employees,2010,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Ongoing position
Full time
Based in Sydney, NSW
Who we are
Australian Red Cross is part of the world’s largest humanitarian organisation. Our aim is to improve the lives of the most vulnerable people in Australia and across our region.
About the role
The Data Engineer role will sit within the Data and Integration Squad in IT and will own (design, implement and support) the AWS Big Data technologies such as the Data Lake and Data Warehouse and support the organisation in growing the data analytics capabilities at Red Cross. In addition to this, the data engineer role will also administer the Power BI tool and support the implementation of the data mastering capability.
What you will bring
Experience building and optimizing data pipelines, architectures and data sets.
Experience in dimensional modelling and building data vaults
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with structured, semi-structured and unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Why work for us?
Work for purpose and know that your work assists Red Cross support and empower people and communities in times of vulnerability.
Generous salary packaging options available that can increase your take home pay.
Further information
To find out more about this opportunity please see the position description below or contact Sharath Kumar Gurram on 02 8651 8839.
Position Description: Position Description - Data Engineer .pdf
Applications for this position will close at 11:55pm Thursday, 5 November 2020.",4.1,"Australian Red Cross
4.1",New South Wales,-1,1001 to 5000 Employees,-1,Nonprofit Organization,Industrial Manufacturing,Manufacturing,$500 million to $1 billion (USD),-1
Junior Fullstack Data Engineer (Python and React),-1,"Formbay is the leading Renewable Energy Certificate Trading company in Sydney. We provide Digital Workflow and Compliance solutions in the renewable energy industry and document processing.
Thanks to our meteoric growth and our commitment to be the best at all we do, we've identified the need to bring on board a new Junior Fullstack Data Engineer.
Reporting to our Principal Machine Learning Engineer, you will help build Machine Learning pipelines for our existing Digital Workflow and Compliance solutions to automate fraud detection and document processing over terabytes of photographic and documentary data – including documents, photos, GPS data and aerial/satellite photography.
Our stack is based on Python, JavaScript, Dask, Tensorflow, CUDA, Nix/NixOS, AWS, Docker, PostgreSQL and more – familiarity with these applications will give you a leg-up on the competition.
Our ideal candidate will have the following competencies:
SQL
Python
JavaScript/TypeScript
Our candidate must also be comfortable working with Linux.
Located a stone's throw away from the Queen Victoria Building in Sydney's bustling CBD, we are centrally-located with easy access to public transportation, bars, cafes and fine dining.
Formbay will provide flexible working hours, a generous remuneration package and the opportunity to work on a world-first software solution are what we can offer you. Free, twice-weekly gym sessions and really, really good coffee are also available.
No hiring/recruitment agencies need apply.",5.0,"Formbay
5.0",Sydney,-1,1 to 50 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is an experienced and qualified Data Engineer to join our IT team based in Birtinya.
Key Responsibilities:
Create and maintain data pipelines and or ETL scripts
Create and maintain data integration including API and Batch interfaces
Performed detailed data analysis
Create and maintain corporate data models
Create and maintain data visualization using Qlik.Sense , PowerBI or Simliar Toolset
Experience in defining, building and maintaining data virtualization and/or star schema data warehouses
Maintain, tune and optimise database, integration and visualisation toolsets
ABOUT YOU:
To succeed in this role, you’ll need to bring the following experience and skills:
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Excellent communication skills both oral and written, with an ability to bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking
Experience with data analysis and modelling will be beneficial

How to Apply
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kawana Waters,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Graduate Data Science / Engineer,-1,"The NRMA is an organisation looking to the future, and right now, we are on the lookout for people who can help us reach our goal: to continue to shape the way Australians move, for the next 100 years and beyond. www.mynrma.com.au.
Everyone new to the team, along with our current staff, will temporarily work from home until it is safe to return to our offices. All interviewing and on boarding will be done virtually due to COVID-19.


Your opportunity
As Graduate Data Scientist or Engineer you will be part of the Data Engineering team delivering cloud data transition program for business initiatives and supporting the entire data platform build.
Your key responsibilities will be to:
Implementing Concepts of Data Warehousing, Data Mart creations within Cloud
Use of SQL for data analysis and insights
Building AI/Machine Learning prototype for implementing and supporting existing algorithms
Data Analytical reports build, using different tool sets


Requirements for Success:
Relevant Degree - Computer Science, Computer Engineering, Software Engineering, Data Science
Excellent SQL skills and demonstrated working knowledge in Python
Demonstrated understanding in data structure and algorithms.
Knowledge and concept of data warehousing methodologies
Any reporting tools experience Tableau or Oracle Analytics Cloud, Looker is desirable
Exposure to Google/AWS/Azure/Oracle any cloud based platforms is desirable
Good communication and interpersonal skills

If you have the required skills and the passion to join our high performing team, please apply today.

Employee Benefits
To ensure our employees feel valued, empowered and celebrated we provide a range of employee benefits including:
50% discount on all NRMA insurances
Free Roadside Assistance
12 weeks paid primary and 4 weeks paid secondary parental leave
Free NRMA Blue Membership
At the NRMA Group, we are People Moving People and diversity and inclusion are part of our DNA. Together, we continue to build an inclusive culture that encourages, supports and celebrates the diverse voices of our employees. It fuels our innovation, promotes flexible ways of working and connects us closer to our members and the communities we serve.",2.5,"NRMA Motoring & Services
2.5",Sydney,-1,501 to 1000 Employees,-1,Nonprofit Organization,Casual Restaurants,"Restaurants, Bars & Food Services",$500 million to $1 billion (USD),-1
Data Centre Engineer,-1,"We are a leading world group that provides low-carbon energy and services. To tackle the climate emergency facing us all, our aim is to become the world leader in the zero-carbon energy transition ""as a service"" for our clients – particular for companies and regional authorities. We use our expertise in our key business areas (renewables, gas, services) to provide competitive and bespoke solutions.
The Data Centre Engineer will be employed as part of a 24/7 ongoing shift to coordinate and monitor third party service providers, maintain the data centre facilities and infrastructure plans, coordinate the implementation of customer requests within the data centre and monitor systems, all in accordance with the Contract KPIs and SLAs.
Coordinate and monitor third party service providers for regular maintenance & testing, service faults & call outs, ensuring works are performed in accordance with Contract SLAs
Monitor and maintain the data centre facilities and infrastructure plans and documentation, including electrical, mechanical, hydraulics, fire and BMS/EMS systems
Coordinate the implementation of internal and external customer requests within the data centre
Perform scheduled plant checks and minor maintenance works
Ensure all Work Order requests are raised and closed in a timely manner
Conduct inductions for staff, vendors and contractors
Ensure all work permits for vendor works are raised and closed
Perform inventory checks on all equipment and critical spares

Qualifications
The selected candidate must be able to demonstrate:
Electrical or HVAC background, or Graduate Electrical or Mechanical Engineer
Passionate about quality work and career minded looking for a new challenge
Can commit to a day and night shift roster (2 days of day shift, then 2 days of night shift, 4 days off)
Ideally able to commence asap
As part of carrying out the duties of this role, it is mandatory to hold Australian Citizenship.

If you are interested and meet the selection criteria apply with an up-to-date resume via the apply instructions on this website.

ENGIE Services is an EEO employer, where all applicants are treated with fairness and respect and have equal access to the opportunities available.

We will not be engaging in the services of a recruitment agency to fill this vacancy and therefore request all interested candidates apply directly to this advertisement.

Job
: Maintenance
Primary Location
: Oceania-Australia-New South Wales-Erskine Park
Organization
: ENGIE Services Australia and New Zealand
Schedule
: Full-time
Nature of Responsibility
: Senior operational / administrative role
Job Posting
: Sep 11, 2020, 6:29:59 AM",3.7,"ENGIE Services Australia & New Zealand
3.7",Sydney,-1,5001 to 10000 Employees,1995,Company - Public,Energy,"Oil, Gas, Energy & Utilities",$2 to $5 billion (USD),-1
Senior Data Engineer,-1,"Senior Data Engineer, Temporary, SYDNEY - McKell

Job Title: Senior Data Engineer

Salary: SNSW Grade 9/10 - The package includes base salary range of $111,806 to $134,667, plus employer's contribution to superannuation and annual leave loading.

Location: Head Office – Haymarket

Employment Status: Temporary through till 30th June 2021


About Service NSW:

Service NSW is making it easier for people and businesses across NSW to access government services. The role designs, builds and analyses complex data from multiple sources to identify revenue, process and business improvement opportunities; providing new information and insights to the business to inform planning, continuous improvement and performance.

About the Role

We are currently seeking to appoint a Senior Data Engineer to deliver expert advice and services in the design of a Single View of Customer and data-related services to support the achievement of business outcomes and strategic goals. We support flexible working practices with staff working remotely during this time.

In this role you will:

Design, build and support a modern data platform based in AWS and vendor technologies.
Provide expertise on data modelling for Graph data model and Customer Data Platform (CDP).
Create data pipelines, load, transformation and reporting workloads in AWS.
Work with the latest data engineering technologies like Apache Kafka, AWS Kinesis, AWS Neptune, AWS Glue and AWS Athena.
Contribute to the design and decision-making of the right tool or platform for the job according to requirements.
Provide expert advice and guidance on data quality and data engineering best practices.
Support a “bigger than you can imagine” scale of data in production environments.
Design, develop and support a metrics-driven reporting solution and a meaningful business intelligence platform.
Document the solution design and support procedures of solutions.
Produce reports, visualisations and recommendations to answer complex business problems that are presented in the most appropriate format to ensure clarity for target audience.
Analyse and define new process improvement opportunities to support continuous improvement and business outcomes; providing advice to stakeholders, on ways to improve the efficiency and reliability of data products and services.
Be very responsive to the information needs of the business by corresponding to customers in a timely manner and provide support/solutions to issues raised.
Troubleshoot and perform root cause analysis on production issues. Identify and implement long term solutions to problems. Perform scheduled maintenance, release deployment and production support activities after business hours, from time to time.
Liaise with internal and external customers to discuss and gather requirements, solutions etc. and maintain a good working relationship with the stakeholders.


Skills and Experience Required:

Solid experience with workflow technologies designing and building data pipelines, data models and data stores.
Experience working within and an understanding of Amazon AWS ecosystem, including security and performance tuning.
Hands on experience working with different types of databases, with focus on Graph and NoSQL databases.
Experience with data streaming required. Having used Kafka and related technologies is an added advantage.
Sound knowledge and experience working with batch processing, data extraction and API integration.
Hands on experience with at least one programming language: Java, Python or scripting.
Demonstrated experience working in an Agile based, fast paced, complex environment within cross-functional teams.
Experience developing systematised insights, data analytics and reporting solutions is an added advantage.
Experience with interactive visualisation of data insights is an added advantage.


Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Salary Grade 9/10, with the base salary for this role starting at 111,806 base plus superannuation

Closing Date: 6th November at 9:59am - applications will be reviewed on a rolling basis, applications may close early or extend

Please apply online, direct applications submitted via email will not be considered.

The Department of Customer Service is proud to be an EEO Employer who are fully focused on equality and believe deeply in diversity of all identities making us different and a true reflection of our NSW customers. As an inclusive workplace, we support various employee resource groups, practice flexible work and workplace adjustment.

If you do require an adjustment during the recruitment process, please notify us on your application form.",3.2,"Service NSW
3.2",Sydney,-1,501 to 1000 Employees,2012,Government,State & Regional Agencies,Government,Unknown / Non-Applicable,-1
Data Engineer - Entry / Mid Level,-1,"Work with a great team on interesting projects customers
Gain more experience in AWS, Data, DevOps cloud operations
Got a working knowledge of AWS? We will teach you the cool stuff!

Itoc is seeking an up and coming Data Engineer to join our growing Data Team in Sydney.

This is an exciting role working with databases, data lakes, data warehouses, data transformation (Python SQL) and enabling AI/ML.

You will be implementing foundational, robust and production ready data platforms to enable business data-discovery, self-service, AI/ML functions across a range of client types and industries, allowing them to do more with their data.

You'll be responsible for:

Deploying data repositories such as lakes and warehouses.
Contribute to our growing portfolio of data solutions.
Ongoing optimisation and management of data platforms.
Development of transformational logic for data pipelines
Data evangelism. We want to show our clients how to follow the best practices for data.

Desired Skills and Experience

To take up the challenge, you will have a depth of skills and experience including:

1-2+ yrs of focused data experience working with SQL and/or NoSQL solutions
A solid education in Software Engineering or equivalent industry experience.
Anything Data focused preferred.
Ability to analyse business scenarios and associated data landscape to derive potential opportunities.
Strong foundation in Python and SQL
Working knowledge of APIs
Principle knowledge of the different relational database platforms and modern data storage techniques
Knowledge of the different aspects of data environments
Collect, store, process, verify consume
Experience with version management systems (such as GIT)
Working knowledge of AWS or another cloud platform - we will teach you the cool stuff.
Great communication skills, an ability to work closely with customers, developers and engineers and the confidence to present ideas in open forums.
Relevant tertiary qualifications and/or industry certifications.
Great communication skills, an ability to work closely with clients, developers and engineers and the confidence to present ideas in open forums.

While not required, a background in consulting and professional services is highly desirable.

Itoc Description

This is an exciting and challenging career opportunity to join the growing Sydney-based Data Team of a leading cloud solution provider where you will be given support to reach your long term career goals. You will be part of a team of cloud experts and will work in an environment of continuous improvement and learning delivering innovative cloud solutions across SaaS, online business and enterprise business.

On offer is a chance to join a team with a great working environment, in an organisation that values its employees and sees the value in ensuring they are engaged. Our team are clearly passionate about what they do, that's why we won the following awards:

Customer Obsession Partner of the Year 2015: ANZ Region
Customer Obsession Leadership Partner 2015: re:Invent

As an employer of choice Itoc offers competitive remuneration, training and development programs and a great working environment. We value a healthy work life balance.

The Perks

MacBook or Dell
Continuous internal learning that will provide training and career development opportunities
Working with a collaborative, social team and leveling-up your skills faster than you will anywhere else.
Quarterly social events

Itoc

Culture and smarts are important to us. Bring your secret sauce. This is no ordinary environment, you will work along some of the Cloud’s best. All engineers at Itoc must gain at least five AWS certifications. We work hard but we have fun.

Please note you must have full working rights in Australia and be available on-shore for face to face interviews.

No recruiters please.",4.0,"Itoc
4.0",Sydney,-1,1 to 50 Employees,2013,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Date: 01-Oct-2020

Location:
Melbourne, VIC, AU

Department:Description:
Technology discounts - from Apple HP Lenovo to Windows
Flexible work arrangements - work in a way that suits you best
Salary packaging - to suit your personal and financial circumstances

Do you want to work for one of the fastest growing data teams in Australia? Do you want to work on multiple data platforms and provide new solution offerings by leveraging cloud and big data technologies?

About the team

Big data information and analytics. Three words that spark apprehension in most businesses. But our team of experts are constantly curious and excited about combining our wonderful array of technological expertise to transform data into our clients most valuable assets making their work smarter. Our data consultants are supported with resources training and tools they need to excel at their work but also the freedom and power to create their own paths forward to make a difference.

As a Senior Consultant in Big Data you will work closely with the team and stakeholders to build and deliver a Cloud based vision for a next generation Big Data analytics platform with strong focus on data quality data security and deliver the systems that process huge volumes of data.

What will you typical day look like?

You will play a pivotal role in - Designing and producing high performing and stable applications to perform complex processing of massive volumes of data in a new cloud based architecture; Building real-time data processing applications which are integrated with business systems to enable value from analytic models to drive rapid decision making; Contributing to system architecture design for a data platform (including cloud-based structures both on and off premises data warehouse components and data lakes); this could cover a range of technologies various countries/locations and lines of business; Support data strategy or technology strategy definition programs including technology stack definition and target operating model requirements

Enough about us lets talk about you:
You are someone with:
Use of traditional data analytics tools and techniques (e.g. MSSQL Oracle MySQL) and ETL software (e.g. SSIS Informatica CloverETL)
Working in large scale cloud data solutions using platforms such as AWS or Azure or GCP will be a bonus.
Experience in scripting or programming (e.g. Python Java Scala C#)
Excellent verbal and written communication skills to adapt to technical and non-technical audiences.
Educated to degree level (or have equivalent experience)
Why Deloitte?

At Deloitte we create positively differentiated work experiences that enable our people to feel valued and achieve their full potential. We value difference and embrace people with diverse backgrounds and thinking styles. Knowing that people work best in different ways we are happy to discuss alternative arrangements if the working pattern you are looking for is not specifically indicated.",3.8,"Deloitte
3.8",Melbourne,-1,10000+ Employees,1850,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Engineer,-1,"Opportunity to grow the team
Period of growth
Intuitive app
S2M are working with a FinTech who have created a unique financial product to help thousands of people better manage their finance, and is currently scaling the company to the next level!

They are looking for a Data Engineer to join, and looking for someone who wants to be hands on, with opportunity to grow the team in future.

Role:

Looking for people with strong AWS experience. You will need passion for data and a cloud, through which you will help a rapidly scaling Australian FinTech establish their data infrastructure from the ground up.
5+ years’ experience as a data engineer within the data and analytics domain
A python 3.X aficionado who is very comfortable creating and orchestrating AWS data pipelines with nothing but code
Strong project delivery toolset experience in open source data integration tools
Experience with processing large volumes of complex data including visualisation and insights generation
Ability to define and develop data integration patterns and pipelines
Ability to assess complexity of data (volume, structure, relationship etc.)
Hands on experience working with different databases (RDBMS, NoSQL, Blob storage etc)
Hands on technical expertise setting up DevOps automation
Hands on experience working technologies/platform e.g. AWS, Dockers, Containers
Experience building data profiling and data cleansing frameworks
Technical reconciliation and reporting
Knowledge and experience in end-to-end project delivery, either traditional SDLC or agile delivery methodologies (or hybrid approaches)
Exceptional communication, documentation and presentation skills
If this sounds like you, get in touch today - kate.gabb@s2m.com.au
3167410agsdf",3.1,"S2M
3.1",Sydney,-1,Unknown,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Analysts,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is seeking experienced and qualified Data Analysts to join our IT team based in our corporate office in Birtinya (Sunshine Coast) or at our meat processing facility in Kilcoy.
Key Responsibilities:
A mixture of data analysis and commercial skills to source, blend and analyse data to gain insight and answer key commercial questions
Working with strategic leaders to define and model Key Performance Indicators, and assist in building forecasting models
Working closely with data engineers and BI developers to specify data pipelines and report visualisation
Drive the creation and implementation of data quality business rule including data definition, governance and quality assurance
About You:
To succeed in this role, you’ll need to bring the following experience and skills:
Proven ability to derive insight and knowledge from data using commercial expertise is a strong requirement
Strong SQL and Excel skills are essential, along with strong data analysis and commercial insights
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Effective people communicator - engage with stakeholders on reporting needs, interpret requirements into visual solutions and train/deliver the outputs to the stakeholders getting signoff of acceptance
Bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking

How to Apply:
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kilcoy,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Network Data Engineer,-1,"Min 6+ years of experience in the relevant technologies
Australian Driving License for visiting remote locations / Data Centre for day to day technical work.
Managing Network devices (switches, routers, firewalls, load balancer, and wireless technology)
Performing MACD activities for all network devices.
Supporting BAU operation activities.
Proficient in performing in-depth details of technical troubleshooting, cause and provide recommendation to the client for incidents causing extended network outage to client’s critical locations.
Provide exceptional network services in terms of network support, break-fix, design and consulting, new projects, implementation.
Configure, administer, and document firewall infrastructure.
Manage the firewall deployment, rules migrations, and firewall administration.
Supporting Cloud Migration Activities from traditional to AWS/Azure.
Setting up VPN tunnel with Cloud and 3rd Party network devices.
Integrating and upgrading existing ISP bandwidth with support from ISP Vendor.
Setting up VPN profiles for Users.
Installing hot fix and patches to mitigate the security devices from attacks and bugs.
Reviewing and fine tuning the firewall rules and NAT rules.
Documentation and change control.
Mentoring, Motivating and Guiding support teams
Technical skills:
o LAN
o Wireless
o WAN
o MPLS
o Routing protocols (OSPF,BGP)
o DMVPN
o Azure cloud Networking
o Network Security
Fortigate Manager / Analyzer / Firewall
Cisco ASA
Firepower FTD
Cisco Any connect
Site to Site VPN
F5 Load Balancing and Scripting iRule
Job Types: Full-time, Contract
Schedule:
8 hour shift
Experience:
Scripting: 5 years (Required)
Data Network: 5 years (Required)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Required)",3.6,"Total IT Global
3.6",Sydney,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Engineer - Processing & Analysis,-1,"Job Description:
Design,build and maintain the ingestion system to support various types of data(e.g. User behavior, RDS, NoSQL db and others) to be ingested to the data warehouse more timely and accurately
Translate data requirements into scalable technical data service with low latency and high concurrency
Design,build and maintain the batch or real time data pipeline in production using Hadoop big data technology
Analyze and improve efficiency, scalability, and stability of the system
Define and manage SLA,Data quality for all data sets in allocated areas of ownership
Requirements:
Minimum B.S. degree in Computer Science or a related technical field
2+ years of working experience in programming languages,such as Java,Scala,Python
Familiar with Hadoop, Spark and Flink data processing, experience of TB data processing experience is a plus
Familiar designing and operating of a robust distributed system is a plus
Understand data mining or machine learning
Excited to work intimately with data
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"SYNOPSIS:
Lead Data Engineer
Applications close Sunday 8 November 2020
Ongoing
Contact name: Shyni Sasikala
Phone: (02) 6249 9048
Email: Shyni.Sasikala@ga.gov.au

The Data Policy and Informatics section within the Digital Science and Information branch creates, implements, and promotes policies, platforms and tools that improve and support the quality, discoverability, accessibility, and general usability of Geoscience Australia’s science data products. The section consults with internal and external research, government and industry partners to establish collaborative data frameworks, architectures and models within Geoscience Australia (GA) and across broader national and international communities of practice. The section innovates, builds and maintains tools, systems, processes and governance that enable digital data management, cataloguing and open data delivery.
GA makes accessible a wide range of geoscientific and spatial data to a wide variety of stakeholders in multiple formats, and in recent years GA's data volumes have grown exponentially. GA is focussed on making its data and metadata assets accessible so that they can be used in machine to machine interactions for data analytics and other applications in environments that range from High Performance Computing (HPC), through high-end cloud servers, to mobile devices.
We currently have two opportunities for Lead Data Engineers in the Informatics team. The Lead Data Engineer is responsible for innovating and exploring new technologies that will advance GA’s science goals and maximise the uptake and use of GA’s science data. The Lead Data Engineer reports to the team’s Assistant Director but also works closely with other developers, data scientists and engineers within the Digital Science and Innovation (DiSI) branch, as well as diverse stakeholders both within and external to GA.",3.9,"Geoscience Australia
3.9",Canberra,-1,501 to 1000 Employees,2001,Government,Federal Agencies,Government,$100 to $500 million (USD),-1
Data Engineer,-1,"The Seven Network is part of Seven West Media, one of Australia’s most prominent media companies, with a market leading presence in content across broadcast television, online and in print. Comprising some of Australia’s most renowned media brands, SWM includes not just Seven Network and its affiliate channels 7two, 7mate, 7flix and BVOD offering 7plus, but also 7NEWS.com.au, The West Australian, The Sunday Times and more.
At Seven we are here to bring all Australians closer to the moments that move us - we’re first on the scene, with our finger on the pulse, on demand, in the moment. Together, we’re responsible for creating and sustaining authentic Australian engagement.
A new and exciting opportunity has opened for a Data Engineer to join the Audience Intelligence team. Based in Sydney and reporting to the Head of Data Enablement, you’ll be responsible for:
Implementation of end to end data solutions to support Data Strategy for the SWM group.
Work closely with the Data Solution Designers to develop and maintain scalable data pipelines and build out new file and API based integrations to address requirements from the various business stakeholders.
Collaborates with engineering, analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organisation.
Work on Data Preparation for analytics and data scientist team members and assist them from an engineering perspective in building and optimising the models including building the automation of the end to end workflows
Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.
Perform data analysis required to troubleshoot data related issues and assist in the resolution of production data issues.
Work effectively with vendors for successful delivery of projects and acceptance of the solution
Work on Delivery projects using Agile Software Development methodologies
We are looking for someone who has:
Bachelor's degree in computer science, computer engineering or other technical discipline is essential
Proven experience working as a digital analytics specialist
Extensive experience with digital analytics implementation (e.g. Google Analytics, Snowplow, Adobe Analytics) and BI processes and visualisation platforms
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience in ETL and building and optimizing ‘big data’ pipelines and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Experience with big data tools: Hadoop, Spark, etc., AWS cloud services: EC2, S3, Lambda and familiar with version control systems: Git
Strong coding skills with knowledge of Unix/Linux and scripting languages such as Unix Shell scripting, Python desirable
Experience supporting and working with cross-functional teams in a fast-paced environment.
Ability to multi-task and problem solve with changing demands and priorities
Ability to work under pressure to meet deadlines and detail oriented
Your success is our success: we will provide you with opportunities for you to keep learning and growing, enabling you to challenge and develop yourself. In return, we offer a benefits program that has something in it for everyone.
Seven West Media is an equal opportunity employer and we are committed to creating a diverse and inclusive workplace.
Recruitment Agencies: Seven West Media does not accept any unsolicited agency resumes and will not be responsible for any fees related to unsolicited resumes.
Advertised: 19 Oct 2020 12:00 AM AUS Eastern Daylight Time
Applications close:

Back to search results",2.5,"Seven West Media
2.5",Sydney,-1,5001 to 10000 Employees,1956,Company - Public,TV Broadcast & Cable Networks,Media,Unknown / Non-Applicable,-1
BICON Rules Engineer,-1,"APS 5 - $73,299 - $80,410 per annum plus superannuation
Biosecurity Plant Division
Canberra, ACT
Play an active role in managing biosecurity risk to Australia
Work in a motivated and professional team with a wide range of skills and backgrounds
Full training provided

Who we are
The BICON Content Development Team maintains and improves the Biosecurity Import CONditions database (BICON) content to allow external clients to understand and comply with their biosecurity obligations and internal clients to effectively manage biosecurity risk and regulate imports. We work collaboratively with internal clients to comprehend and implement their BICON content requirements and optimise the use of BICON to publish clear import requirements and onshore management support procedures to effectively manage biosecurity risk.

The Jobs
Key duties of these positions include:

working with business content (import and permit conditions) and import programs to understand and construct decision tree structures in the BICON database, in accordance with system design and authoring conventions
executing changes to import and permit conditions in alignment with service standards while complying with system rules and authoring conventions
providing technical advice through various formats on the most appropriate means of authoring BICON content to achieve import program and stakeholder objectives
using workflow management tools to maintain detailed records of changes to import conditions and key decisions
performing administrative tasks including system reporting, data analysis and scoping tasks for the BICON content change work program
contributing to the development and maintenance of instructional material, authoring conventions and courseware
clearly documenting and reporting system issues
developing and maintaining effective working relationships with internal and external stakeholders.

What we are looking for
Knowledge and experience
Experience working with complex IT systems.
Experience working collaboratively and as part of a team.
Knowledge of the role of biosecurity is preferred but not essential.

For additional information, please read the Job Description below.
Candidate Information Package docx Opens in new window",3.9,"Department of Agriculture & Water Resources
3.9",Australia,-1,5001 to 10000 Employees,-1,Government,Federal Agencies,Government,$500 million to $1 billion (USD),-1
Cloud Data Engineer,-1,"Job no: 509605
Work type: Permanent Full Time
Location: Melbourne, Canberra, Sydney
Do you embrace digital disruption?
Do you love solving complex problems, designing sophisticated solutions and building innovative technology?
Do you believe in creating powerful actionable insights from Data and Analytics?
Do you want to work in a diverse and flexible working environment?
KPMG is one of the most trusted and respected global professional services firms. Through depth of expertise, clarity of insight and strength of purpose we help our clients solve complex challenges, steer change, strengthen, transition and grow. We are a team based practice and this extends to our clients whom we work and collaborate with, in solving complex problems. Together, we design, innovate and implement, providing enduring advice that support our clients and the services they deliver. Our clients vary in size and come from a diverse range of sectors – all sharing in a common goal: to embrace change and deliver services that make Australia a better place. We are looking for talented individuals who would like to join us on the journey.
KPMG’s Digital Delta Team
We re-imagine and re-invent organisations to become world class digital enterprises using advanced technologies, data and human insights. We help organisations to embrace Digital Strategy, Artificial Intelligence (AI) & Cognitive, the Internet of Things (IoT), Data, Analytics & Modelling, Mobile App & Web, and User Experience (UX) & User Interface (UI) and more.
We work with clients to:
Formulate strategies that re-imagine organisations
Harness innovation from the 4th industrial revolution
Actioning insights from trusted data to consistently and quickly make clear decisions
Build adaptive organisations
Thrive as a connected enterprise – front, middle and back office
This is how you’ll contribute:
We are looking for ambitious Data Engineers who are passionate about helping clients define bold ambitions and deliver on them. Joining our team will take you on a journey of personal and technical growth and provide the opportunity to inspire confidence and empower change.
As a Data Engineer you are the designer, builder and manager of the information or ""big data"" infrastructure, preparing data for analytical or operational use. You will design, construct, test and maintain a data pipeline to pull together information from different source systems; integrating, consolidating and cleansing data; and structure it for use in individual analytics applications.
The KPMG Difference
Our people are focused on creating a diverse and dynamic environment that embraces and values differences. We value the variety of unique experiences, qualities and characteristics our people possess and we share and learn from each other.
We are proud to be consistently recognised as an employer of choice for women, and for our achievements in LGBT+ workplace inclusion.
Our commitment to ‘Flexibility’ allows our people to manage the changing demands of work, personal or family life. Explore the links below to hear our people share their experience @ KPMG:
Flexibility empowers wellbeing
Flexibility enables contribution to the community
Flexibility inspires technology & innovation
Flexibility supports family

Make KPMG the clear choice for your career and be Extraordinary!

Advertised: 09 Sep 2020 AUS Eastern Standard Time
Applications close:",3.8,"KPMG
3.8",Sydney,-1,10000+ Employees,1987,Subsidiary or Business Segment,Accounting,Accounting & Legal,$2 to $5 billion (USD),-1
Computer Network and Systems Engineer,-1,"Duties Include but are not limited to:
Tasks Include:
analysing, developing, interpreting and evaluating complex system design and architecture specifications, data models and diagrams in the development, configuration and integration of computer systems
researching, analysing, evaluating and monitoring network infrastructure to ensure networks are configured to operate at optimal performance
assessing and recommending improvements to network operations and integrated hardware, software, communications and operating systems
providing specialist skills in supporting and troubleshooting network problems and emergencies
installing, configuring, testing, maintaining and administering new and upgraded networks, software database applications, servers and workstations
providing network programming in support of specific business needs and requirements
preparing and maintaining procedures and documentation for network inventory, and recording diagnosis and resolution of network faults, enhancements and modifications to networks, and maintenance instructions
monitoring network traffic, and activity, capacity and usage to ensure continued integrity and optimal network performance
Skills and Experience Required:
Must have experience working in a Managed Service environment
Demonstrated experience in IT Networks and Data Centres
Understanding of systems and architectures to meet client needs
Experience in Help Desk including break / fix
Effective and timely documentation
Effective Task Management Skills
Be solution and outcome focused and willing to learn new technologies
Excellent communication skills with staff, clients and partners
Time management, ability to prioritise and deliver to schedule
Experience with N-Able and Connectwise desired
Open Cabling license desired
Job Types: Full-time, Permanent
Salary: $30.00 per hour
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,Trans-plant training,Canberra,-1,-1,-1,-1,-1,-1,-1,-1
Software Engineer (Data),-1,"If you are looking for an opportunity to make a real impact with smart people who are genuinely doing things differently then you've come to the right place! We're growing our data engineering capabilities and are looking for awesome data engineers to join our team.
With our diverse range of clients and projects, no day will look the same - but here's a great snapshot of what you'll be doing:
Work with some of the best Data Scientists and Engineers to deliver production-grade AI and Machine Learning systems as we deliver client projects from inception to production.
Consulting with our clients and working with them to build modern data systems using the 'best of' technologies and principles.
Advising clients on data strategy, architecture and technology.
Applying best software engineering practices in coding, monitoring and alerting, using CI/CD, TDD and cloud architectures.
Working over a wide range of big data tools and environments: not limited to; Apache Kafka, Spark, Python, Scala, Hive, Airflow, AWS EMR & Glue, GCP Dataproc & Dataflow, BigQuery, Snowflake, Redshift.
Who are we?
Glad you asked! We are Eliiza. Data science. Engineered for scale.
We are a passionate team of data scientists and engineers who apply data science and machine learning to solve real-world problems. Our mission is to create a bright future for Australian businesses and society in a world increasingly influenced by intelligent technologies.
We've created a culture that values diversity where people can truly be themselves! We care a lot about growing the Australian AI community in a positive direction, and we're doing several things to try and achieve that:
We provide opportunities for underrepresented groups to work in AI through our associate and intern programmes
We organise and participate in a range of community events, reading groups and meetups
We produce the AI Australia podcast
We blog about topics we care about
We stream brown bag sessions to the broader community
We're also part of Mantel Group's 'house of brands' which means it's not just the Eliiza team you'll work with, learn from and see at social events - there's another 230 of us across DigIO, Kasna & CMD Solutions!
So you're ready for something new?
We're keen to know more about you! Our team is made up of a range of people, with different experience across a huge range of data driven skill sets.
We'd love to hear from you if you have experience with:
one (or more) core language(s), ideally Scala, Python or Java
one (or more) cloud platforms, AWS, GCP, Azure
ETL/ELT concepts and technologies e.g. Data partitioning, Hive, Spark
streaming data concepts and technologies, ideally Kafka (Kinesis, Beam or Pubsub will do)
We'd be over the moon if you:
Experience with distributed/columnar databases (e.g. Snowflake, Big query, Redshift).
Experience with any of a variety of databases e.g. RDMS, NoSql, Columar, Distributed, Time series, Graph.
Knowledge of job orchestration and scheduling. Any experience with Airflow, Luigi or Oozie.
Experience with containers and container orchestration (Docker, Docker Compose or Kubernetes).
However, we value a diversity of skill-sets, and don't necessarily require that you're skilled with all of the above. If you feel you don't fit all the experience/skills listed above we still encourage you to apply or get in touch.
What's on offer if you join us?
We make sure you're always one step ahead by investing your learning and development, every year. We build our own training where it doesn't exist yet.
We hire smart people and get out of their way. By focusing on our five principles and not getting caught up in red tape, we trust you to get the job done.
You'll get all the tools you need - a new iPhone or Google phone, a new Macbook Pro or Dell, and a lot of branded swag!
But hold on, you mentioned a house of brands?
We certainly did! Mantel Group is an Australian-owned, 'house of brands' company with four technology businesses (Eliiza being one of them!) across Melbourne and Sydney. We're building a group of companies with open borders so we can support you to take on new skills without leaving an awesome team - we understand you won't have one job for life!
We may only be just two years old but Mantel Group has already been recognised #9 in the 2020 Best Places to Work in Australia and #4 in the AFR's 2020 fastest growing new companies.
Keen to chat?
Click ""Apply"" to share your details with our talent team, and we'll be in touch.
In the meantime, check out 'how we hire' to find out what's in store if you're successful and get to know us better by visiting our website and following Eliiza on LinkedIn.",-1,Eliiza,Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Infrastructure Engineer,-1,"Job Description:
Design and grow the Shopee data platform to support a variety of big data applications using open-source technologies including Kafka, Hadoop, Presto, HBase, Spark, Hive, Druid, and our own creations. Some examples include a real-time data streaming platform, a unified query platform, a cluster management system, and a machine learning platform
Dig into the source code of some open-source big data system to get the whole control and familiar with the details, configurations, designs and source code. Develop and maintain the internal release of big data systems and components as the business requirements.
Keep close and overall monitoring for all the deployments of the systems, maintain the system’s stability, improve the performance, discover the performance bottlenecks, tracking and troubleshooting, cost optimisation.
Requirements:
B. Sci. / Ms / PhD in Computer Science or a related technical field
Familiar with at least one of these languages: Java, Scala, Python, Bash under Linux / Unix. Scala is a plus
Familiar with the use and compute logical of SQL
Knowledge about the Big Data Infrastructure system technology like Distributed File System, Distributed Computing, Distributed Database will be a plus
Hands-on experiences Hadoop, Spark, Kafka, and/or Presto will be a plus
Love to use and develop open-source technologies
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"Work on an award-winning, international technology!
Endless career opportunities
An innovative, friendly team of 300+
This role will be focused on the development of our existing ClaimLogik line of products as well as working on our new cloud-first, modern suite of applications.

Intelligent Thought, our technology business is scaling and shipping our software globally. Already profitable, part of a much larger group business, with investors such as Macquarie Capital and Envest – we are all set to deliver textbook disruption to the Insurance Industry. The growth of the platform, of our customer base, and the increasing industry demand have led to the need for this role to help the team scale.

Our Philosophy
Give each employee a sense of purpose and an environment for them to connect the importance of their role to delivering a service that matters to our customers.
Challenge the ‘why’ of traditional claims processes.
Keep it simple – do only what brings value and what matters to the customer
Enable employee decisions, empower our people
Responsibilities:
Create, extend and maintain ETL pipelines to form our data lake, data warehouse and analytics platform (currently using the Microsoft Azure set of tools and service)
Help define the optimal data pipeline architecture
Influence the tool selection, platform selection, data architecture and strategy which will transform the business to be truly data-driven
Understand, analyse and size user requirements
Work with different parts of the business to provide them with the insights they need to deliver the best results
Skills & experience:
Degree or qualification in computer science or related
Advanced knowledge of relational database, including query authoring and query optimisation (MS SQL Server and PostgreSQL).
Experience building and optimising ETL pipelines
Experience designing complex data models
Experience working with cloud platforms (Azure or AWS)
Efficient time management and organisational skills
High attention to detail and accuracy
Effective communication skills to build strong working relationships; both written and verbal
Proactive and results-driven
Why Claim Central?
Claim Central Consolidated is a global insurance industry leader across, claims management, insurance technology and data and analytics. Currently operating in the United States, Australia, South Africa, Italy and New Zealand, we have pioneered digitally connected claims management services across the globe. Claim Central is a disruptor and thought leader in the industry and we were recognised as the Australian Financial Review’s 8th Most Innovative Company in Australia in 2016. This business is in a period of unprecedented growth, transitioning our technology and services into multiple geographies at a rapid pace. Our unique culture is based on teamwork, collaboration, trust, respect and performance. We also offer many benefits apart from our exceptional team culture; including flexible work arrangements, and continued professional development.

Be a part of this journey in a career-defining role.",-1,Claim Central,Matraville,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer - AI/ML,-1,"Our client provides services to a major industry across the country. The business is still early in it's days of technology development and the environment is greenfields in nature (no pun intended), effectively working like a start-up.

Their data and analytics team have worked and built leading and bleeding-edge technologies in this space and what they have created so far may be game-changing. From a machine learning perspective, the progress they have made to the business has already seen proven success in changing the future of an industry that will have positive consequences for all those involved.

You will have previously worked in a technical capacity in the data and analytics space and have experience working with an organisation where machine learning has been implemented, not just a concept that the business talks about having or the technology team would love to have. The commercial experience you will have had in the ML field will be proven examples of where you have affected the way a business or industry used to perform, to the changes that have come about from this.

Technically, you will have extensive experience in the Microsoft space - Power BI, Azure etc and you will have previously mentored and coached junior members of the teams you have been part of.

This is a rare opportunity in Brisbane where the business has truly embraced and funded projects across the ML space and would be a great chance for those in the Data Development/Data Engineering field, who are looking to move into a Data Scientist role in the future.

Please send your application through if you would like to know more.",4.0,"Emanate Technology
4.0",Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Solution designer/ ETL Engineer & Data Modeller,-1,"We are looking for a Qualified and Experienced Solution Designer to join our client for a period of 6 months with a view to extend.
You will work closely with team members and your contribution will range across gathering and analyzing information, developing and documenting improved processes and work instructions and experienced DWH Lead with skills in requirement analysis, solution designing, developing, testing and supporting ETL solutions.
A hands-on solution designer, data modeler and ETL developer for Data Warehousing and ETL application transformation projects using Informatica PowerCenter.
Knowledge on AWS, S3, Redshift, Informatica BDM, and related technologies.
Experience working with IPython, PySparks, AuCuMo, Airflow, Jenkins, Github, Athena, JIRA, Rally, Spectrum, Glue, Flyway.
Good exposure on Oracle PL/SQL, aware of DBA activities, writing and performance tuning of complex SQL queries.
Contract length: 6 months
Job Types: Full-time, Contract
Salary: $650.00 – $800.00 per day
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,nducive,Melbourne,-1,-1,-1,-1,-1,-1,-1,-1
"Data Engineer, Wollongong NSW or Mount Waverley VIC",-1,"Company Description
BlueScope is a technically advanced supplier of steel and steel products in Australia. We are an inclusive organisation and every day we showcase our technology and expertise throughout the world.

Job Description
We are looking for two Data Engineers to join our IT team, based in Wollongong NSW or Mount Waverley VIC. Use your experience in analytics to unlock business value, enabling use of big data for insights and decision-making.
Reporting to the Data Product Owner for our Australian Steel Products (ASP) business, this position will support strategic goals related to data. This will see you:
Gather business and technical requirements with the view to deliver outcomes;
Develop and implement end-to-end data collection, consolidation, modelling and visualisation solutions;
Document metadata in a dictionary and catalogue;
Ensure consumers of such information understand its accuracy, timeliness, quality and sensitivity, so that it is used appropriately; and
Identify opportunities to enhance analytics.
What are the benefits?
Work in a supportive and collaborative team environment whilst we embark on a journey to transform the way our business uses data!
Our systems landscape is broad and diverse. You will be encouraged to think creatively to develop data solutions which solve real business problems.
Working in this role you will enjoy:
the chance to learn more about data science;
salaried remuneration with attractive superannuation options;
the opportunity to participate in a performance incentive scheme; and
access to further development and career opportunities with BlueScope.
Who are we looking for?
We welcome applications from professionals with experience in data analytics and/or programming. Supported by your knowledge of project delivery methods (e.g. Agile), you will demonstrate:
experience with data mining, wrangling, mapping and visualisation techniques (e.g. Azure Data Factory, Databricks and/or DevOps etc.);
well-developed ability in gathering business and technical requirements;
skills in developing and implementing collection, consolidation, modelling and visualisation solutions; and
a passion for sharing your knowledge and desire for ongoing professional development.

Qualifications

null

Additional Information
We're proud to have been named an Inclusive Employer for 2019–2020 by the Diversity Council of Australia. We believe that our people are our strength. Having a diverse and inclusive workplace enables us to improve our capability and ensure continued, sustainable success.
We know that workplace flexibility can mean something different to everyone. Under our B-Flex initiative all of our roles have some degree of flexibility. We encourage you to discuss your needs with us.
Applications close Sunday 25th October 2020.",3.3,"BlueScope
3.3",Wollongong,-1,201 to 500 Employees,-1,Company - Private,Construction,"Construction, Repair & Maintenance",$100 to $500 million (USD),-1
ETL Data Engineer,-1,"ETL Data Engineer

Join a team that’s changing how Australia lives, works, plays and grows
We want you to be the best version of you

Work with innovative teams and explore new technologies to help solve real-world problems.

A typical day as a Data Engineer

ETL / Big Data Engineering professionals will be responsible for guiding the full lifecycle of a Data solution, including:
Working in highly client-facing roles to contribute throughout the end-to-end delivery lifecycle of complex and large-scale digital solutions
Use case and business case development
Support existing and new applications utilizing in-depth technical and data knowledge. Troubleshooting complex issues and providing advisory services to improve the client’s data landscape
Help to streamline and simplify the clients’ complex data landscape by integrating different applications and data architectures
Implementation from requirements analysis, platform selection, digital architecture design, application design and development, testing, and deployment
Interstate travel may be required

Basic qualifications:
Bachelor’s degree
Experience across systems integration, information management, data management and architecture, and business analytics
Experience with being in a team focusing on large-scale, multi-release information centric projects
Experience with waterfall and agile delivery and run / application support functions
Part of a team working on End to end implementation of at least 1 big data project

Preferred Skills:
Hand on experience in Data warehousing using ETL tools such as DataStage, Autosys and TeraData
Hands on experience in ETL job development with multiple stages like sequential file, Transformer, Lookup, join, sort and Database stages.
Strong hand on skills in design, development and implementation of various data remediation, Data migration, data integration techniques.
Strong hand on data modelling experience.
Strong hands on experience in database performance tuning including complex query optimizations and physical database tuning using Teradata.
Understanding of architectural designs and strategy related to data migration, data cleansing, data quality and data consolidation.
Proven data analysis, requirement gathering and problem-solving skills
Exposure to Unix environment and shell scripting.
Experience in Banking and Financial services industry
Desirable: Knowledge of cloud computing infrastructure (e.g. Amazon Web Services EC2, Google Cloud, Microsoft Azure)
About Accenture

Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. We combine unmatched experience and specialized capabilities across more than 40 industries — powered by the world’s largest network of Advanced Technology and Intelligent Operations centers. With 513,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises. Visit us at www.accenture.com.

Accenture is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, marital, domestic or civil partnership status, sexual orientation, gender identity, or any other basis as protected by applicable law.

Vera Goga is the Recruiter managing this role. As the team experience high volumes of applications, we appreciate your patience to allow for a fair and timely process.",3.9,"Accenture
3.9",Sydney,-1,10000+ Employees,1989,Company - Public,Consulting,Business Services,$10+ billion (USD),-1
Student Engineer,-1,"The candidate will have the ability to:
Undertake onsite inspection to collect asset condition data based on the relevant engineering standards and technical guidelines;
Undertake desktop analysis to evaluate the condition and performance of the assets;
Provide the appropriate information, advice, engineering input and support services for the sustainable management of Council’s stormwater and transport networks.
Qualifications:
The successful candidate will be enrolled in a Bachelor of Engineering with a minimum of two years completed.
Position Number: 100678
Position Hours: Fixed term (3 months), hours will be negotiated with the successful candidate, maximum of 75 hours per fortnight.
Salary: Schedule A, Salary Point 4.0. $28.64 per hour ($55,853.45 per annum, pro-rata) in accordance with Glenorchy City Council’s Enterprise Agreement 2016
Please note that all successful applicants will be required to provide a current National Police Check prior to commencement of employment.
For further information on this position, contact Patrick Marshall, Senior Civil Engineer on (03) 6216 6800.
How to apply: Applications for this position must be lodged on this submission site or on the Glenorchy City Council website www.gcc.tas.gov.au - Careers page.
To be considered for this role, all applicants must address the key selection criteria in the and provide a current resume. A copy of the position description can be found by clicking the below hyperlink or on the Glenorchy City Council website.
Applications close at 8pm on Sunday, 1st November 2020
- Student Engineer",4.0,"Glenorchy City Council
4.0",Glenorchy,-1,501 to 1000 Employees,-1,Government,-1,-1,Less than $1 million (USD),-1
Data Engineer involving DevOps,-1,"Data Engineer involving DevOps
Axiom Technologies is an Australia based entity with the history of providing Managed IT solutions to medium to large scale enterprises globally. Please visit our website for more information about what we do at www.axiomtechnologies.com
Axiom Technologies is an Equal Opportunity Employer and encourage applicants from all backgrounds and gender to apply, including, Aboriginal and Torres Strait Islander candidates
Job Requirements:
8+ years IT experience, with at least 5+ years of “Data Engineer/Deveoper” focused titles/roles,
Data Tools: Hands on experience with Apache Beam.
Testing: Hands on experience with automated testing activities/outcomes
DevOps: Experience with the processes involving Microservices facilities for artifacts developed
Platform/OS: Mid-range/Unix
Languages: Unix (Shell) Scripting/commands, SQL, Python
File formats: Text, CSV, Parquet, JSON, XML
Scheduling: Jenkins, Airflow
Auto Scripting: Designing/creation of scripts for repetitive activity. E.g. Unix scripting/SQL
Big data: Exposure to Data Lake Concepts, Hive (Schema), HDFS
Source Control tools: GIT
Delivery Models: Agile, Scrum
Ingestion Design: Create/assess Source/Target data mapping designs
Frameworks: Development and delivery frameworks
Activity Reporting/Repository: Jira, Confluence.
Quality: Accuracy and attention to detail
Industry: Financial Services/Banking
Solutions: Define solutions from High level to detail design to address automating ingestion activity. Facilitate/confirm requirements from product owners, business team members and technical associates,
Process Automation: Automating processes in file management, testing data in files, analysis and design, configuration management.
Script Automation: Ability to design/create scripts to automate/improve data copy/migration/ETL for any repetitive activity.
Languages: Java, Python
Scheduling: Control-M
Databases: Relational. E.g. POSTGRESS, Oracle – as a ETL developer
File Formats: Mainframe – experience with referencing its data formats/copybooks
Big data: Experience referencing/using Hive (Schema) to access data in HDFS
Metadata management tools: MDM, EDC and Axon
Performance: Assess, recommend, improve mappings, SQL queries, Batch feeds
Automation Tools: Other tools that may add value to an automation program and generally support development. E.g. API, REST, JDBC, Webservices, Message Queues/Load balancer,
Cloud: Experience with processing of data files to be ingested/stored in the Cloud, preferably with AWS.
Prod Support: Experience in a production support role performing root cause / impact analysis – under time constraints
Experience in a similar role
8+ Years
What next?
If you are looking for that next challenge in your career and wish to apply for this role, please forward your resume to careers.au@axiomtechnologies.com",2.0,"Axiom Technologies
2.0",Melbourne,-1,1 to 50 Employees,-1,Company - Private,Industrial Manufacturing,Manufacturing,Less than $1 million (USD),-1
Data Engineer,-1,"About the Role
We are on an exciting digital journey so it’s a great time to join ME! We are seeking a Junior Data Engineer who enjoys rolling up their sleeves, learning and growing. As part of our Enterprise Data Team, you will ensure fit for purpose data warehouse solutions are built for use across the bank and by utilising best practise ETL standards, whilst ensuring the data is trusted by our BI developers and key business consumers. Oh, and you’ll get to work on Microsoft technology stack too!
You will be involved with investigating data issues, keeping data feeds flowing and collaborating with different projects across the bank to deliver quality data solutions. How important does that sound? What’s even more important is this role contributes directly to our overall business strategy through the provision of data to enable analytics & reporting, as well as supporting business and decision system processes.

About You
You’re naturally a highly motivated and energetic person who thrives in a dynamic, ever-changing collaborative team environment. Ideally you have previous experience as an ETL developer, Data Engineer or a BI developer, and if you have a degree in computer science or similar it would really put you ahead of the rest.

With your knowledge of SQL coding, data modelling, understanding of data warehouse concepts, plus experience of working on complex ETL solutions, you’re ready to expand your horizons and launch your career into the world of IT at ME.

About ME
We’re not like other banks.
ME was created by the industry super funds to be different from the pack – with a core purpose to help all Australians get ahead financially – no conditions, asterisks or exceptions. And we know that looking after customers starts with taking care of our people.
We believe everyone deserves the same opportunities in life, regardless of gender or identity, sexuality, ethnicity, religion or disability ‒ with internal affinity groups.
Perk ME up
Once you get your feet in the door at ME, we’ll put them both in your very own ME-branded Converse shoes. You’ll also get the following financial, health and fun perks when you join the team:
4U Extras portal (discounts and cashback on 100s of items including cinemas, shopping and gym memberships
10% Myki discount
Purchased Leave programme
Internal wellness programme (Mindfully ME)
Professional education through LinkedIn Learning
Novated Leasing
Professional membership reimbursements
Health checks
Financial education (To help you manage your money smarter)
LGBTIQ+ and Women at ME affinity groups

I want those Converse shoes (and the role)
Can’t see a closing date on the advert? That’s because we’re pretty efficient here at ME and we may start looking at applications sooner rather than later, so if this role sounds like your jam, be sure to apply by submitting your resume today.

Should an applicant be the preferred candidate, background checks (including police checks, reference checks, ASIC banned and disqualified persons and bankruptcy checks) will be completed prior to the candidate's employment being confirmed. The outcomes of the background checks do not automatically bar candidates; however will be assessed against the inherent requirements of the job.
Back Share
Apply Now",3.0,"ME Bank
3.0",Melbourne,-1,501 to 1000 Employees,-1,Company - Private,Banks & Credit Unions,Finance,$100 to $500 million (USD),-1
Software Engineer - Machine Learning/Data Science,-1,"Zendesk is looking for a Software Engineer - Machine Learning/Data Science for a full time position in our Melbourne office.
As part of our engineering team, you will work at a scale where the challenges start to get seriously interesting. Our global engineering team is widely dispersed over the world, with people across nearly every continent. You will get a chance to do cool things with a diverse bunch of people while working in the Melbourne office that is home to Zendesk’s first machine learning (ML) research team.
The Data Science Team, together with Data Engineering, have built Satisfaction Prediction, Answer Bot and Content Cues — products that use Machine Learning (ML) and Artificial Intelligence (AI) to help our customers work more efficiently.
What you get to do every day:
We’re currently looking for someone to join our team as we research, develop, and productionise Machine Learning and Deep Learning models. In addition to frequenting Melbourne’s finest purveyors of coffee, ramen, and bulgogi, you may find yourself:
Building machine learning models including neural networks in TensorFlow
Writing and deploying production-grade Python
Querying and constructing datasets in AWS Athena, Spark
Evaluating and responding to real-world model performance
Scaling your ML to millions of predictions per day
Presenting your work to a broader audience
Watching your algorithm help Zendesk’s end-users
What you'll bring to the role:
A strong foundation in a quantitative discipline (e.g. machine learning, statistics, bio/eco/etc-informatics, econometrics, etc) is critical for this position. While experience in deep learning and natural language processing would be beneficial, your best qualities are:
dedication to continuous learning
collaborative work attitude
strong communication skills
You should also be comfortable with at least one programming language, such as Python, R or Scala.
Application Deadline: 18/11/2020
Job Types: Full-time, Permanent
Salary: $85,000.00 – $110,000.00 per year
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Temporarily due to COVID-19",4.5,"Zendesk
4.5",Melbourne,-1,1001 to 5000 Employees,2007,Company - Public,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),-1
Software Engineer (Machine Learning),-1,"About the Role
AdelaideMRI is building a medical reporting tool. We require an engineer to work primarily on machine learning projects to improve reporting speed and report comprehensiveness.
You will perform data analysis of medical report datasets and image datasets to infer sentence recommendations, image classifications, or other actionable results for the doctors.
Skills and Experience
Background in machine learning or image processing
Qualifications in Computer Science, Software Development or Engineering or equivalent experience
Bonus points for Python
No prior medical knowledge is required.
This position offers flexible hours and work arrangements.
Job Type: Full-time
Experience:
Software Engineering: 1 year (Preferred)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Yes",-1,Adelaide MRI,Australia,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Hey there, we’re PEXA!

We started as an idea: to deliver a single, national e-Conveyancing solution. We collaborated with the industry to create a national electronic lodgement and settlement platform: PEXA. From our humble beginnings, we’ve now grown to more than 320 employees across 5 different states. We’re still expanding at a rapid rate and constantly challenging ourselves to create great experiences for our members as they transition to fully digital conveyancing.

Why become a PEXArian?

Great question! Being a PEXArian is so much more than just a job. We are passionate, motivated & unashamedly enthusiastic at PEXA - we love what we do and we’re proud to admit it! Creating brilliant member experiences wouldn’t be possible if we didn’t also strive to create an amazing employee experience. Alongside our members, our employees are at the heart of everything we do.
Here’s a snapshot of what your life at PEXA could look like:

Your growth:
We encourage you to hit your personal and professional Learning & Development goals with our tailored programs and tools.

Your wellness:
We care about your holistic well being - a fully stocked kitchen, four wellness days, a $250 wellness subsidy as well as lunch and learn sessions to support your financial well being.

Your work/life blend:
We know that work is just one aspect of your life, we want to help you create your ideal work/life blend, rather than squeezing in life around work.

Your family:
With a range of benefits aimed at supporting your family including access to a subsidised school holiday program, extended parental leave and flexi-time to support your return to work, superannuation payments for unpaid parental leave for primary carers and a childcare allowance for pre-primary aged children, when we say, ‘welcome to the family’, we really mean it!
The impact you'd drive:
The successful candidate will be responsible for developing, and maintaining infrastructure to support the delivery of new and existing products. They will also be contributing to establish the rules and frameworks for obtaining the required approvals for new products.
On day one we’d love you to have:
Experience with Python, Spark
Event streaming/sourcing with Kafka or AWS Kinesis
Experience with data structures, formats and data security best practices
AWS experience (e.g CloudFormation, S3, ECS, Lambda, SQS, IAM, KMS, DynamoDB, Glue, Athena)
Query construction and optimisation (e.g. SQL, Elasticsearch, Splunk, DynamoDB)
Git, version control practices, and continuous integration/delivery servers
PyUnit and unit testing frameworks
Production release cycles and maintenance
Collaborating with technical and non-technical teams
Even better:
Agile methodology/delivery
GraphQL
Modern frontend technology (e.g. ReactJS, TypeScript)
Machine learning frameworks and tools (e.g. TensorFlow, PyTorch)
OAuth 2, SAML 2, JWT
Data visualisation and exploration tools (e.g. Jupyter notebooks, Tableau)
AWS SageMaker
Sounds like you?
If this role sounds like you, apply today to have your application reviewed ASAP!",3.9,"Property Exchange Australia Limited
3.9",Melbourne,-1,201 to 500 Employees,2010,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Ongoing position
Full time
Based in Sydney, NSW
Who we are
Australian Red Cross is part of the world’s largest humanitarian organisation. Our aim is to improve the lives of the most vulnerable people in Australia and across our region.
About the role
The Data Engineer role will sit within the Data and Integration Squad in IT and will own (design, implement and support) the AWS Big Data technologies such as the Data Lake and Data Warehouse and support the organisation in growing the data analytics capabilities at Red Cross. In addition to this, the data engineer role will also administer the Power BI tool and support the implementation of the data mastering capability.
What you will bring
Experience building and optimizing data pipelines, architectures and data sets.
Experience in dimensional modelling and building data vaults
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with structured, semi-structured and unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Why work for us?
Work for purpose and know that your work assists Red Cross support and empower people and communities in times of vulnerability.
Generous salary packaging options available that can increase your take home pay.
Further information
To find out more about this opportunity please see the position description below or contact Sharath Kumar Gurram on 02 8651 8839.
Position Description: Position Description - Data Engineer .pdf
Applications for this position will close at 11:55pm Thursday, 5 November 2020.",4.1,"Australian Red Cross
4.1",New South Wales,-1,1001 to 5000 Employees,-1,Nonprofit Organization,Industrial Manufacturing,Manufacturing,$500 million to $1 billion (USD),-1
Junior Fullstack Data Engineer (Python and React),-1,"Formbay is the leading Renewable Energy Certificate Trading company in Sydney. We provide Digital Workflow and Compliance solutions in the renewable energy industry and document processing.
Thanks to our meteoric growth and our commitment to be the best at all we do, we've identified the need to bring on board a new Junior Fullstack Data Engineer.
Reporting to our Principal Machine Learning Engineer, you will help build Machine Learning pipelines for our existing Digital Workflow and Compliance solutions to automate fraud detection and document processing over terabytes of photographic and documentary data – including documents, photos, GPS data and aerial/satellite photography.
Our stack is based on Python, JavaScript, Dask, Tensorflow, CUDA, Nix/NixOS, AWS, Docker, PostgreSQL and more – familiarity with these applications will give you a leg-up on the competition.
Our ideal candidate will have the following competencies:
SQL
Python
JavaScript/TypeScript
Our candidate must also be comfortable working with Linux.
Located a stone's throw away from the Queen Victoria Building in Sydney's bustling CBD, we are centrally-located with easy access to public transportation, bars, cafes and fine dining.
Formbay will provide flexible working hours, a generous remuneration package and the opportunity to work on a world-first software solution are what we can offer you. Free, twice-weekly gym sessions and really, really good coffee are also available.
No hiring/recruitment agencies need apply.",5.0,"Formbay
5.0",Sydney,-1,1 to 50 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is an experienced and qualified Data Engineer to join our IT team based in Birtinya.
Key Responsibilities:
Create and maintain data pipelines and or ETL scripts
Create and maintain data integration including API and Batch interfaces
Performed detailed data analysis
Create and maintain corporate data models
Create and maintain data visualization using Qlik.Sense , PowerBI or Simliar Toolset
Experience in defining, building and maintaining data virtualization and/or star schema data warehouses
Maintain, tune and optimise database, integration and visualisation toolsets
ABOUT YOU:
To succeed in this role, you’ll need to bring the following experience and skills:
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Excellent communication skills both oral and written, with an ability to bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking
Experience with data analysis and modelling will be beneficial

How to Apply
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kawana Waters,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Graduate Data Science / Engineer,-1,"The NRMA is an organisation looking to the future, and right now, we are on the lookout for people who can help us reach our goal: to continue to shape the way Australians move, for the next 100 years and beyond. www.mynrma.com.au.
Everyone new to the team, along with our current staff, will temporarily work from home until it is safe to return to our offices. All interviewing and on boarding will be done virtually due to COVID-19.


Your opportunity
As Graduate Data Scientist or Engineer you will be part of the Data Engineering team delivering cloud data transition program for business initiatives and supporting the entire data platform build.
Your key responsibilities will be to:
Implementing Concepts of Data Warehousing, Data Mart creations within Cloud
Use of SQL for data analysis and insights
Building AI/Machine Learning prototype for implementing and supporting existing algorithms
Data Analytical reports build, using different tool sets


Requirements for Success:
Relevant Degree - Computer Science, Computer Engineering, Software Engineering, Data Science
Excellent SQL skills and demonstrated working knowledge in Python
Demonstrated understanding in data structure and algorithms.
Knowledge and concept of data warehousing methodologies
Any reporting tools experience Tableau or Oracle Analytics Cloud, Looker is desirable
Exposure to Google/AWS/Azure/Oracle any cloud based platforms is desirable
Good communication and interpersonal skills

If you have the required skills and the passion to join our high performing team, please apply today.

Employee Benefits
To ensure our employees feel valued, empowered and celebrated we provide a range of employee benefits including:
50% discount on all NRMA insurances
Free Roadside Assistance
12 weeks paid primary and 4 weeks paid secondary parental leave
Free NRMA Blue Membership
At the NRMA Group, we are People Moving People and diversity and inclusion are part of our DNA. Together, we continue to build an inclusive culture that encourages, supports and celebrates the diverse voices of our employees. It fuels our innovation, promotes flexible ways of working and connects us closer to our members and the communities we serve.",2.5,"NRMA Motoring & Services
2.5",Sydney,-1,501 to 1000 Employees,-1,Nonprofit Organization,Casual Restaurants,"Restaurants, Bars & Food Services",$500 million to $1 billion (USD),-1
Data Centre Engineer,-1,"We are a leading world group that provides low-carbon energy and services. To tackle the climate emergency facing us all, our aim is to become the world leader in the zero-carbon energy transition ""as a service"" for our clients – particular for companies and regional authorities. We use our expertise in our key business areas (renewables, gas, services) to provide competitive and bespoke solutions.
The Data Centre Engineer will be employed as part of a 24/7 ongoing shift to coordinate and monitor third party service providers, maintain the data centre facilities and infrastructure plans, coordinate the implementation of customer requests within the data centre and monitor systems, all in accordance with the Contract KPIs and SLAs.
Coordinate and monitor third party service providers for regular maintenance & testing, service faults & call outs, ensuring works are performed in accordance with Contract SLAs
Monitor and maintain the data centre facilities and infrastructure plans and documentation, including electrical, mechanical, hydraulics, fire and BMS/EMS systems
Coordinate the implementation of internal and external customer requests within the data centre
Perform scheduled plant checks and minor maintenance works
Ensure all Work Order requests are raised and closed in a timely manner
Conduct inductions for staff, vendors and contractors
Ensure all work permits for vendor works are raised and closed
Perform inventory checks on all equipment and critical spares

Qualifications
The selected candidate must be able to demonstrate:
Electrical or HVAC background, or Graduate Electrical or Mechanical Engineer
Passionate about quality work and career minded looking for a new challenge
Can commit to a day and night shift roster (2 days of day shift, then 2 days of night shift, 4 days off)
Ideally able to commence asap
As part of carrying out the duties of this role, it is mandatory to hold Australian Citizenship.

If you are interested and meet the selection criteria apply with an up-to-date resume via the apply instructions on this website.

ENGIE Services is an EEO employer, where all applicants are treated with fairness and respect and have equal access to the opportunities available.

We will not be engaging in the services of a recruitment agency to fill this vacancy and therefore request all interested candidates apply directly to this advertisement.

Job
: Maintenance
Primary Location
: Oceania-Australia-New South Wales-Erskine Park
Organization
: ENGIE Services Australia and New Zealand
Schedule
: Full-time
Nature of Responsibility
: Senior operational / administrative role
Job Posting
: Sep 11, 2020, 6:29:59 AM",3.7,"ENGIE Services Australia & New Zealand
3.7",Sydney,-1,5001 to 10000 Employees,1995,Company - Public,Energy,"Oil, Gas, Energy & Utilities",$2 to $5 billion (USD),-1
Senior Data Engineer,-1,"Senior Data Engineer, Temporary, SYDNEY - McKell

Job Title: Senior Data Engineer

Salary: SNSW Grade 9/10 - The package includes base salary range of $111,806 to $134,667, plus employer's contribution to superannuation and annual leave loading.

Location: Head Office – Haymarket

Employment Status: Temporary through till 30th June 2021


About Service NSW:

Service NSW is making it easier for people and businesses across NSW to access government services. The role designs, builds and analyses complex data from multiple sources to identify revenue, process and business improvement opportunities; providing new information and insights to the business to inform planning, continuous improvement and performance.

About the Role

We are currently seeking to appoint a Senior Data Engineer to deliver expert advice and services in the design of a Single View of Customer and data-related services to support the achievement of business outcomes and strategic goals. We support flexible working practices with staff working remotely during this time.

In this role you will:

Design, build and support a modern data platform based in AWS and vendor technologies.
Provide expertise on data modelling for Graph data model and Customer Data Platform (CDP).
Create data pipelines, load, transformation and reporting workloads in AWS.
Work with the latest data engineering technologies like Apache Kafka, AWS Kinesis, AWS Neptune, AWS Glue and AWS Athena.
Contribute to the design and decision-making of the right tool or platform for the job according to requirements.
Provide expert advice and guidance on data quality and data engineering best practices.
Support a “bigger than you can imagine” scale of data in production environments.
Design, develop and support a metrics-driven reporting solution and a meaningful business intelligence platform.
Document the solution design and support procedures of solutions.
Produce reports, visualisations and recommendations to answer complex business problems that are presented in the most appropriate format to ensure clarity for target audience.
Analyse and define new process improvement opportunities to support continuous improvement and business outcomes; providing advice to stakeholders, on ways to improve the efficiency and reliability of data products and services.
Be very responsive to the information needs of the business by corresponding to customers in a timely manner and provide support/solutions to issues raised.
Troubleshoot and perform root cause analysis on production issues. Identify and implement long term solutions to problems. Perform scheduled maintenance, release deployment and production support activities after business hours, from time to time.
Liaise with internal and external customers to discuss and gather requirements, solutions etc. and maintain a good working relationship with the stakeholders.


Skills and Experience Required:

Solid experience with workflow technologies designing and building data pipelines, data models and data stores.
Experience working within and an understanding of Amazon AWS ecosystem, including security and performance tuning.
Hands on experience working with different types of databases, with focus on Graph and NoSQL databases.
Experience with data streaming required. Having used Kafka and related technologies is an added advantage.
Sound knowledge and experience working with batch processing, data extraction and API integration.
Hands on experience with at least one programming language: Java, Python or scripting.
Demonstrated experience working in an Agile based, fast paced, complex environment within cross-functional teams.
Experience developing systematised insights, data analytics and reporting solutions is an added advantage.
Experience with interactive visualisation of data insights is an added advantage.


Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Salary Grade 9/10, with the base salary for this role starting at 111,806 base plus superannuation

Closing Date: 6th November at 9:59am - applications will be reviewed on a rolling basis, applications may close early or extend

Please apply online, direct applications submitted via email will not be considered.

The Department of Customer Service is proud to be an EEO Employer who are fully focused on equality and believe deeply in diversity of all identities making us different and a true reflection of our NSW customers. As an inclusive workplace, we support various employee resource groups, practice flexible work and workplace adjustment.

If you do require an adjustment during the recruitment process, please notify us on your application form.",3.2,"Service NSW
3.2",Sydney,-1,501 to 1000 Employees,2012,Government,State & Regional Agencies,Government,Unknown / Non-Applicable,-1
Data Engineer - Entry / Mid Level,-1,"Work with a great team on interesting projects customers
Gain more experience in AWS, Data, DevOps cloud operations
Got a working knowledge of AWS? We will teach you the cool stuff!

Itoc is seeking an up and coming Data Engineer to join our growing Data Team in Sydney.

This is an exciting role working with databases, data lakes, data warehouses, data transformation (Python SQL) and enabling AI/ML.

You will be implementing foundational, robust and production ready data platforms to enable business data-discovery, self-service, AI/ML functions across a range of client types and industries, allowing them to do more with their data.

You'll be responsible for:

Deploying data repositories such as lakes and warehouses.
Contribute to our growing portfolio of data solutions.
Ongoing optimisation and management of data platforms.
Development of transformational logic for data pipelines
Data evangelism. We want to show our clients how to follow the best practices for data.

Desired Skills and Experience

To take up the challenge, you will have a depth of skills and experience including:

1-2+ yrs of focused data experience working with SQL and/or NoSQL solutions
A solid education in Software Engineering or equivalent industry experience.
Anything Data focused preferred.
Ability to analyse business scenarios and associated data landscape to derive potential opportunities.
Strong foundation in Python and SQL
Working knowledge of APIs
Principle knowledge of the different relational database platforms and modern data storage techniques
Knowledge of the different aspects of data environments
Collect, store, process, verify consume
Experience with version management systems (such as GIT)
Working knowledge of AWS or another cloud platform - we will teach you the cool stuff.
Great communication skills, an ability to work closely with customers, developers and engineers and the confidence to present ideas in open forums.
Relevant tertiary qualifications and/or industry certifications.
Great communication skills, an ability to work closely with clients, developers and engineers and the confidence to present ideas in open forums.

While not required, a background in consulting and professional services is highly desirable.

Itoc Description

This is an exciting and challenging career opportunity to join the growing Sydney-based Data Team of a leading cloud solution provider where you will be given support to reach your long term career goals. You will be part of a team of cloud experts and will work in an environment of continuous improvement and learning delivering innovative cloud solutions across SaaS, online business and enterprise business.

On offer is a chance to join a team with a great working environment, in an organisation that values its employees and sees the value in ensuring they are engaged. Our team are clearly passionate about what they do, that's why we won the following awards:

Customer Obsession Partner of the Year 2015: ANZ Region
Customer Obsession Leadership Partner 2015: re:Invent

As an employer of choice Itoc offers competitive remuneration, training and development programs and a great working environment. We value a healthy work life balance.

The Perks

MacBook or Dell
Continuous internal learning that will provide training and career development opportunities
Working with a collaborative, social team and leveling-up your skills faster than you will anywhere else.
Quarterly social events

Itoc

Culture and smarts are important to us. Bring your secret sauce. This is no ordinary environment, you will work along some of the Cloud’s best. All engineers at Itoc must gain at least five AWS certifications. We work hard but we have fun.

Please note you must have full working rights in Australia and be available on-shore for face to face interviews.

No recruiters please.",4.0,"Itoc
4.0",Sydney,-1,1 to 50 Employees,2013,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Date: 01-Oct-2020

Location:
Melbourne, VIC, AU

Department:Description:
Technology discounts - from Apple HP Lenovo to Windows
Flexible work arrangements - work in a way that suits you best
Salary packaging - to suit your personal and financial circumstances

Do you want to work for one of the fastest growing data teams in Australia? Do you want to work on multiple data platforms and provide new solution offerings by leveraging cloud and big data technologies?

About the team

Big data information and analytics. Three words that spark apprehension in most businesses. But our team of experts are constantly curious and excited about combining our wonderful array of technological expertise to transform data into our clients most valuable assets making their work smarter. Our data consultants are supported with resources training and tools they need to excel at their work but also the freedom and power to create their own paths forward to make a difference.

As a Senior Consultant in Big Data you will work closely with the team and stakeholders to build and deliver a Cloud based vision for a next generation Big Data analytics platform with strong focus on data quality data security and deliver the systems that process huge volumes of data.

What will you typical day look like?

You will play a pivotal role in - Designing and producing high performing and stable applications to perform complex processing of massive volumes of data in a new cloud based architecture; Building real-time data processing applications which are integrated with business systems to enable value from analytic models to drive rapid decision making; Contributing to system architecture design for a data platform (including cloud-based structures both on and off premises data warehouse components and data lakes); this could cover a range of technologies various countries/locations and lines of business; Support data strategy or technology strategy definition programs including technology stack definition and target operating model requirements

Enough about us lets talk about you:
You are someone with:
Use of traditional data analytics tools and techniques (e.g. MSSQL Oracle MySQL) and ETL software (e.g. SSIS Informatica CloverETL)
Working in large scale cloud data solutions using platforms such as AWS or Azure or GCP will be a bonus.
Experience in scripting or programming (e.g. Python Java Scala C#)
Excellent verbal and written communication skills to adapt to technical and non-technical audiences.
Educated to degree level (or have equivalent experience)
Why Deloitte?

At Deloitte we create positively differentiated work experiences that enable our people to feel valued and achieve their full potential. We value difference and embrace people with diverse backgrounds and thinking styles. Knowing that people work best in different ways we are happy to discuss alternative arrangements if the working pattern you are looking for is not specifically indicated.",3.8,"Deloitte
3.8",Melbourne,-1,10000+ Employees,1850,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Engineer,-1,"Opportunity to grow the team
Period of growth
Intuitive app
S2M are working with a FinTech who have created a unique financial product to help thousands of people better manage their finance, and is currently scaling the company to the next level!

They are looking for a Data Engineer to join, and looking for someone who wants to be hands on, with opportunity to grow the team in future.

Role:

Looking for people with strong AWS experience. You will need passion for data and a cloud, through which you will help a rapidly scaling Australian FinTech establish their data infrastructure from the ground up.
5+ years’ experience as a data engineer within the data and analytics domain
A python 3.X aficionado who is very comfortable creating and orchestrating AWS data pipelines with nothing but code
Strong project delivery toolset experience in open source data integration tools
Experience with processing large volumes of complex data including visualisation and insights generation
Ability to define and develop data integration patterns and pipelines
Ability to assess complexity of data (volume, structure, relationship etc.)
Hands on experience working with different databases (RDBMS, NoSQL, Blob storage etc)
Hands on technical expertise setting up DevOps automation
Hands on experience working technologies/platform e.g. AWS, Dockers, Containers
Experience building data profiling and data cleansing frameworks
Technical reconciliation and reporting
Knowledge and experience in end-to-end project delivery, either traditional SDLC or agile delivery methodologies (or hybrid approaches)
Exceptional communication, documentation and presentation skills
If this sounds like you, get in touch today - kate.gabb@s2m.com.au
3167410agsdf",3.1,"S2M
3.1",Sydney,-1,Unknown,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Analysts,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is seeking experienced and qualified Data Analysts to join our IT team based in our corporate office in Birtinya (Sunshine Coast) or at our meat processing facility in Kilcoy.
Key Responsibilities:
A mixture of data analysis and commercial skills to source, blend and analyse data to gain insight and answer key commercial questions
Working with strategic leaders to define and model Key Performance Indicators, and assist in building forecasting models
Working closely with data engineers and BI developers to specify data pipelines and report visualisation
Drive the creation and implementation of data quality business rule including data definition, governance and quality assurance
About You:
To succeed in this role, you’ll need to bring the following experience and skills:
Proven ability to derive insight and knowledge from data using commercial expertise is a strong requirement
Strong SQL and Excel skills are essential, along with strong data analysis and commercial insights
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Effective people communicator - engage with stakeholders on reporting needs, interpret requirements into visual solutions and train/deliver the outputs to the stakeholders getting signoff of acceptance
Bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking

How to Apply:
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kilcoy,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Network Data Engineer,-1,"Min 6+ years of experience in the relevant technologies
Australian Driving License for visiting remote locations / Data Centre for day to day technical work.
Managing Network devices (switches, routers, firewalls, load balancer, and wireless technology)
Performing MACD activities for all network devices.
Supporting BAU operation activities.
Proficient in performing in-depth details of technical troubleshooting, cause and provide recommendation to the client for incidents causing extended network outage to client’s critical locations.
Provide exceptional network services in terms of network support, break-fix, design and consulting, new projects, implementation.
Configure, administer, and document firewall infrastructure.
Manage the firewall deployment, rules migrations, and firewall administration.
Supporting Cloud Migration Activities from traditional to AWS/Azure.
Setting up VPN tunnel with Cloud and 3rd Party network devices.
Integrating and upgrading existing ISP bandwidth with support from ISP Vendor.
Setting up VPN profiles for Users.
Installing hot fix and patches to mitigate the security devices from attacks and bugs.
Reviewing and fine tuning the firewall rules and NAT rules.
Documentation and change control.
Mentoring, Motivating and Guiding support teams
Technical skills:
o LAN
o Wireless
o WAN
o MPLS
o Routing protocols (OSPF,BGP)
o DMVPN
o Azure cloud Networking
o Network Security
Fortigate Manager / Analyzer / Firewall
Cisco ASA
Firepower FTD
Cisco Any connect
Site to Site VPN
F5 Load Balancing and Scripting iRule
Job Types: Full-time, Contract
Schedule:
8 hour shift
Experience:
Scripting: 5 years (Required)
Data Network: 5 years (Required)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Required)",3.6,"Total IT Global
3.6",Sydney,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Engineer - Processing & Analysis,-1,"Job Description:
Design,build and maintain the ingestion system to support various types of data(e.g. User behavior, RDS, NoSQL db and others) to be ingested to the data warehouse more timely and accurately
Translate data requirements into scalable technical data service with low latency and high concurrency
Design,build and maintain the batch or real time data pipeline in production using Hadoop big data technology
Analyze and improve efficiency, scalability, and stability of the system
Define and manage SLA,Data quality for all data sets in allocated areas of ownership
Requirements:
Minimum B.S. degree in Computer Science or a related technical field
2+ years of working experience in programming languages,such as Java,Scala,Python
Familiar with Hadoop, Spark and Flink data processing, experience of TB data processing experience is a plus
Familiar designing and operating of a robust distributed system is a plus
Understand data mining or machine learning
Excited to work intimately with data
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"SYNOPSIS:
Lead Data Engineer
Applications close Sunday 8 November 2020
Ongoing
Contact name: Shyni Sasikala
Phone: (02) 6249 9048
Email: Shyni.Sasikala@ga.gov.au

The Data Policy and Informatics section within the Digital Science and Information branch creates, implements, and promotes policies, platforms and tools that improve and support the quality, discoverability, accessibility, and general usability of Geoscience Australia’s science data products. The section consults with internal and external research, government and industry partners to establish collaborative data frameworks, architectures and models within Geoscience Australia (GA) and across broader national and international communities of practice. The section innovates, builds and maintains tools, systems, processes and governance that enable digital data management, cataloguing and open data delivery.
GA makes accessible a wide range of geoscientific and spatial data to a wide variety of stakeholders in multiple formats, and in recent years GA's data volumes have grown exponentially. GA is focussed on making its data and metadata assets accessible so that they can be used in machine to machine interactions for data analytics and other applications in environments that range from High Performance Computing (HPC), through high-end cloud servers, to mobile devices.
We currently have two opportunities for Lead Data Engineers in the Informatics team. The Lead Data Engineer is responsible for innovating and exploring new technologies that will advance GA’s science goals and maximise the uptake and use of GA’s science data. The Lead Data Engineer reports to the team’s Assistant Director but also works closely with other developers, data scientists and engineers within the Digital Science and Innovation (DiSI) branch, as well as diverse stakeholders both within and external to GA.",3.9,"Geoscience Australia
3.9",Canberra,-1,501 to 1000 Employees,2001,Government,Federal Agencies,Government,$100 to $500 million (USD),-1
Data Engineer,-1,"The Seven Network is part of Seven West Media, one of Australia’s most prominent media companies, with a market leading presence in content across broadcast television, online and in print. Comprising some of Australia’s most renowned media brands, SWM includes not just Seven Network and its affiliate channels 7two, 7mate, 7flix and BVOD offering 7plus, but also 7NEWS.com.au, The West Australian, The Sunday Times and more.
At Seven we are here to bring all Australians closer to the moments that move us - we’re first on the scene, with our finger on the pulse, on demand, in the moment. Together, we’re responsible for creating and sustaining authentic Australian engagement.
A new and exciting opportunity has opened for a Data Engineer to join the Audience Intelligence team. Based in Sydney and reporting to the Head of Data Enablement, you’ll be responsible for:
Implementation of end to end data solutions to support Data Strategy for the SWM group.
Work closely with the Data Solution Designers to develop and maintain scalable data pipelines and build out new file and API based integrations to address requirements from the various business stakeholders.
Collaborates with engineering, analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organisation.
Work on Data Preparation for analytics and data scientist team members and assist them from an engineering perspective in building and optimising the models including building the automation of the end to end workflows
Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.
Perform data analysis required to troubleshoot data related issues and assist in the resolution of production data issues.
Work effectively with vendors for successful delivery of projects and acceptance of the solution
Work on Delivery projects using Agile Software Development methodologies
We are looking for someone who has:
Bachelor's degree in computer science, computer engineering or other technical discipline is essential
Proven experience working as a digital analytics specialist
Extensive experience with digital analytics implementation (e.g. Google Analytics, Snowplow, Adobe Analytics) and BI processes and visualisation platforms
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience in ETL and building and optimizing ‘big data’ pipelines and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Experience with big data tools: Hadoop, Spark, etc., AWS cloud services: EC2, S3, Lambda and familiar with version control systems: Git
Strong coding skills with knowledge of Unix/Linux and scripting languages such as Unix Shell scripting, Python desirable
Experience supporting and working with cross-functional teams in a fast-paced environment.
Ability to multi-task and problem solve with changing demands and priorities
Ability to work under pressure to meet deadlines and detail oriented
Your success is our success: we will provide you with opportunities for you to keep learning and growing, enabling you to challenge and develop yourself. In return, we offer a benefits program that has something in it for everyone.
Seven West Media is an equal opportunity employer and we are committed to creating a diverse and inclusive workplace.
Recruitment Agencies: Seven West Media does not accept any unsolicited agency resumes and will not be responsible for any fees related to unsolicited resumes.
Advertised: 19 Oct 2020 12:00 AM AUS Eastern Daylight Time
Applications close:

Back to search results",2.5,"Seven West Media
2.5",Sydney,-1,5001 to 10000 Employees,1956,Company - Public,TV Broadcast & Cable Networks,Media,Unknown / Non-Applicable,-1
BICON Rules Engineer,-1,"APS 5 - $73,299 - $80,410 per annum plus superannuation
Biosecurity Plant Division
Canberra, ACT
Play an active role in managing biosecurity risk to Australia
Work in a motivated and professional team with a wide range of skills and backgrounds
Full training provided

Who we are
The BICON Content Development Team maintains and improves the Biosecurity Import CONditions database (BICON) content to allow external clients to understand and comply with their biosecurity obligations and internal clients to effectively manage biosecurity risk and regulate imports. We work collaboratively with internal clients to comprehend and implement their BICON content requirements and optimise the use of BICON to publish clear import requirements and onshore management support procedures to effectively manage biosecurity risk.

The Jobs
Key duties of these positions include:

working with business content (import and permit conditions) and import programs to understand and construct decision tree structures in the BICON database, in accordance with system design and authoring conventions
executing changes to import and permit conditions in alignment with service standards while complying with system rules and authoring conventions
providing technical advice through various formats on the most appropriate means of authoring BICON content to achieve import program and stakeholder objectives
using workflow management tools to maintain detailed records of changes to import conditions and key decisions
performing administrative tasks including system reporting, data analysis and scoping tasks for the BICON content change work program
contributing to the development and maintenance of instructional material, authoring conventions and courseware
clearly documenting and reporting system issues
developing and maintaining effective working relationships with internal and external stakeholders.

What we are looking for
Knowledge and experience
Experience working with complex IT systems.
Experience working collaboratively and as part of a team.
Knowledge of the role of biosecurity is preferred but not essential.

For additional information, please read the Job Description below.
Candidate Information Package docx Opens in new window",3.9,"Department of Agriculture & Water Resources
3.9",Australia,-1,5001 to 10000 Employees,-1,Government,Federal Agencies,Government,$500 million to $1 billion (USD),-1
Cloud Data Engineer,-1,"Job no: 509605
Work type: Permanent Full Time
Location: Melbourne, Canberra, Sydney
Do you embrace digital disruption?
Do you love solving complex problems, designing sophisticated solutions and building innovative technology?
Do you believe in creating powerful actionable insights from Data and Analytics?
Do you want to work in a diverse and flexible working environment?
KPMG is one of the most trusted and respected global professional services firms. Through depth of expertise, clarity of insight and strength of purpose we help our clients solve complex challenges, steer change, strengthen, transition and grow. We are a team based practice and this extends to our clients whom we work and collaborate with, in solving complex problems. Together, we design, innovate and implement, providing enduring advice that support our clients and the services they deliver. Our clients vary in size and come from a diverse range of sectors – all sharing in a common goal: to embrace change and deliver services that make Australia a better place. We are looking for talented individuals who would like to join us on the journey.
KPMG’s Digital Delta Team
We re-imagine and re-invent organisations to become world class digital enterprises using advanced technologies, data and human insights. We help organisations to embrace Digital Strategy, Artificial Intelligence (AI) & Cognitive, the Internet of Things (IoT), Data, Analytics & Modelling, Mobile App & Web, and User Experience (UX) & User Interface (UI) and more.
We work with clients to:
Formulate strategies that re-imagine organisations
Harness innovation from the 4th industrial revolution
Actioning insights from trusted data to consistently and quickly make clear decisions
Build adaptive organisations
Thrive as a connected enterprise – front, middle and back office
This is how you’ll contribute:
We are looking for ambitious Data Engineers who are passionate about helping clients define bold ambitions and deliver on them. Joining our team will take you on a journey of personal and technical growth and provide the opportunity to inspire confidence and empower change.
As a Data Engineer you are the designer, builder and manager of the information or ""big data"" infrastructure, preparing data for analytical or operational use. You will design, construct, test and maintain a data pipeline to pull together information from different source systems; integrating, consolidating and cleansing data; and structure it for use in individual analytics applications.
The KPMG Difference
Our people are focused on creating a diverse and dynamic environment that embraces and values differences. We value the variety of unique experiences, qualities and characteristics our people possess and we share and learn from each other.
We are proud to be consistently recognised as an employer of choice for women, and for our achievements in LGBT+ workplace inclusion.
Our commitment to ‘Flexibility’ allows our people to manage the changing demands of work, personal or family life. Explore the links below to hear our people share their experience @ KPMG:
Flexibility empowers wellbeing
Flexibility enables contribution to the community
Flexibility inspires technology & innovation
Flexibility supports family

Make KPMG the clear choice for your career and be Extraordinary!

Advertised: 09 Sep 2020 AUS Eastern Standard Time
Applications close:",3.8,"KPMG
3.8",Sydney,-1,10000+ Employees,1987,Subsidiary or Business Segment,Accounting,Accounting & Legal,$2 to $5 billion (USD),-1
Computer Network and Systems Engineer,-1,"Duties Include but are not limited to:
Tasks Include:
analysing, developing, interpreting and evaluating complex system design and architecture specifications, data models and diagrams in the development, configuration and integration of computer systems
researching, analysing, evaluating and monitoring network infrastructure to ensure networks are configured to operate at optimal performance
assessing and recommending improvements to network operations and integrated hardware, software, communications and operating systems
providing specialist skills in supporting and troubleshooting network problems and emergencies
installing, configuring, testing, maintaining and administering new and upgraded networks, software database applications, servers and workstations
providing network programming in support of specific business needs and requirements
preparing and maintaining procedures and documentation for network inventory, and recording diagnosis and resolution of network faults, enhancements and modifications to networks, and maintenance instructions
monitoring network traffic, and activity, capacity and usage to ensure continued integrity and optimal network performance
Skills and Experience Required:
Must have experience working in a Managed Service environment
Demonstrated experience in IT Networks and Data Centres
Understanding of systems and architectures to meet client needs
Experience in Help Desk including break / fix
Effective and timely documentation
Effective Task Management Skills
Be solution and outcome focused and willing to learn new technologies
Excellent communication skills with staff, clients and partners
Time management, ability to prioritise and deliver to schedule
Experience with N-Able and Connectwise desired
Open Cabling license desired
Job Types: Full-time, Permanent
Salary: $30.00 per hour
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,Trans-plant training,Canberra,-1,-1,-1,-1,-1,-1,-1,-1
Software Engineer (Data),-1,"If you are looking for an opportunity to make a real impact with smart people who are genuinely doing things differently then you've come to the right place! We're growing our data engineering capabilities and are looking for awesome data engineers to join our team.
With our diverse range of clients and projects, no day will look the same - but here's a great snapshot of what you'll be doing:
Work with some of the best Data Scientists and Engineers to deliver production-grade AI and Machine Learning systems as we deliver client projects from inception to production.
Consulting with our clients and working with them to build modern data systems using the 'best of' technologies and principles.
Advising clients on data strategy, architecture and technology.
Applying best software engineering practices in coding, monitoring and alerting, using CI/CD, TDD and cloud architectures.
Working over a wide range of big data tools and environments: not limited to; Apache Kafka, Spark, Python, Scala, Hive, Airflow, AWS EMR & Glue, GCP Dataproc & Dataflow, BigQuery, Snowflake, Redshift.
Who are we?
Glad you asked! We are Eliiza. Data science. Engineered for scale.
We are a passionate team of data scientists and engineers who apply data science and machine learning to solve real-world problems. Our mission is to create a bright future for Australian businesses and society in a world increasingly influenced by intelligent technologies.
We've created a culture that values diversity where people can truly be themselves! We care a lot about growing the Australian AI community in a positive direction, and we're doing several things to try and achieve that:
We provide opportunities for underrepresented groups to work in AI through our associate and intern programmes
We organise and participate in a range of community events, reading groups and meetups
We produce the AI Australia podcast
We blog about topics we care about
We stream brown bag sessions to the broader community
We're also part of Mantel Group's 'house of brands' which means it's not just the Eliiza team you'll work with, learn from and see at social events - there's another 230 of us across DigIO, Kasna & CMD Solutions!
So you're ready for something new?
We're keen to know more about you! Our team is made up of a range of people, with different experience across a huge range of data driven skill sets.
We'd love to hear from you if you have experience with:
one (or more) core language(s), ideally Scala, Python or Java
one (or more) cloud platforms, AWS, GCP, Azure
ETL/ELT concepts and technologies e.g. Data partitioning, Hive, Spark
streaming data concepts and technologies, ideally Kafka (Kinesis, Beam or Pubsub will do)
We'd be over the moon if you:
Experience with distributed/columnar databases (e.g. Snowflake, Big query, Redshift).
Experience with any of a variety of databases e.g. RDMS, NoSql, Columar, Distributed, Time series, Graph.
Knowledge of job orchestration and scheduling. Any experience with Airflow, Luigi or Oozie.
Experience with containers and container orchestration (Docker, Docker Compose or Kubernetes).
However, we value a diversity of skill-sets, and don't necessarily require that you're skilled with all of the above. If you feel you don't fit all the experience/skills listed above we still encourage you to apply or get in touch.
What's on offer if you join us?
We make sure you're always one step ahead by investing your learning and development, every year. We build our own training where it doesn't exist yet.
We hire smart people and get out of their way. By focusing on our five principles and not getting caught up in red tape, we trust you to get the job done.
You'll get all the tools you need - a new iPhone or Google phone, a new Macbook Pro or Dell, and a lot of branded swag!
But hold on, you mentioned a house of brands?
We certainly did! Mantel Group is an Australian-owned, 'house of brands' company with four technology businesses (Eliiza being one of them!) across Melbourne and Sydney. We're building a group of companies with open borders so we can support you to take on new skills without leaving an awesome team - we understand you won't have one job for life!
We may only be just two years old but Mantel Group has already been recognised #9 in the 2020 Best Places to Work in Australia and #4 in the AFR's 2020 fastest growing new companies.
Keen to chat?
Click ""Apply"" to share your details with our talent team, and we'll be in touch.
In the meantime, check out 'how we hire' to find out what's in store if you're successful and get to know us better by visiting our website and following Eliiza on LinkedIn.",-1,Eliiza,Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Infrastructure Engineer,-1,"Job Description:
Design and grow the Shopee data platform to support a variety of big data applications using open-source technologies including Kafka, Hadoop, Presto, HBase, Spark, Hive, Druid, and our own creations. Some examples include a real-time data streaming platform, a unified query platform, a cluster management system, and a machine learning platform
Dig into the source code of some open-source big data system to get the whole control and familiar with the details, configurations, designs and source code. Develop and maintain the internal release of big data systems and components as the business requirements.
Keep close and overall monitoring for all the deployments of the systems, maintain the system’s stability, improve the performance, discover the performance bottlenecks, tracking and troubleshooting, cost optimisation.
Requirements:
B. Sci. / Ms / PhD in Computer Science or a related technical field
Familiar with at least one of these languages: Java, Scala, Python, Bash under Linux / Unix. Scala is a plus
Familiar with the use and compute logical of SQL
Knowledge about the Big Data Infrastructure system technology like Distributed File System, Distributed Computing, Distributed Database will be a plus
Hands-on experiences Hadoop, Spark, Kafka, and/or Presto will be a plus
Love to use and develop open-source technologies
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"Work on an award-winning, international technology!
Endless career opportunities
An innovative, friendly team of 300+
This role will be focused on the development of our existing ClaimLogik line of products as well as working on our new cloud-first, modern suite of applications.

Intelligent Thought, our technology business is scaling and shipping our software globally. Already profitable, part of a much larger group business, with investors such as Macquarie Capital and Envest – we are all set to deliver textbook disruption to the Insurance Industry. The growth of the platform, of our customer base, and the increasing industry demand have led to the need for this role to help the team scale.

Our Philosophy
Give each employee a sense of purpose and an environment for them to connect the importance of their role to delivering a service that matters to our customers.
Challenge the ‘why’ of traditional claims processes.
Keep it simple – do only what brings value and what matters to the customer
Enable employee decisions, empower our people
Responsibilities:
Create, extend and maintain ETL pipelines to form our data lake, data warehouse and analytics platform (currently using the Microsoft Azure set of tools and service)
Help define the optimal data pipeline architecture
Influence the tool selection, platform selection, data architecture and strategy which will transform the business to be truly data-driven
Understand, analyse and size user requirements
Work with different parts of the business to provide them with the insights they need to deliver the best results
Skills & experience:
Degree or qualification in computer science or related
Advanced knowledge of relational database, including query authoring and query optimisation (MS SQL Server and PostgreSQL).
Experience building and optimising ETL pipelines
Experience designing complex data models
Experience working with cloud platforms (Azure or AWS)
Efficient time management and organisational skills
High attention to detail and accuracy
Effective communication skills to build strong working relationships; both written and verbal
Proactive and results-driven
Why Claim Central?
Claim Central Consolidated is a global insurance industry leader across, claims management, insurance technology and data and analytics. Currently operating in the United States, Australia, South Africa, Italy and New Zealand, we have pioneered digitally connected claims management services across the globe. Claim Central is a disruptor and thought leader in the industry and we were recognised as the Australian Financial Review’s 8th Most Innovative Company in Australia in 2016. This business is in a period of unprecedented growth, transitioning our technology and services into multiple geographies at a rapid pace. Our unique culture is based on teamwork, collaboration, trust, respect and performance. We also offer many benefits apart from our exceptional team culture; including flexible work arrangements, and continued professional development.

Be a part of this journey in a career-defining role.",-1,Claim Central,Matraville,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer - AI/ML,-1,"Our client provides services to a major industry across the country. The business is still early in it's days of technology development and the environment is greenfields in nature (no pun intended), effectively working like a start-up.

Their data and analytics team have worked and built leading and bleeding-edge technologies in this space and what they have created so far may be game-changing. From a machine learning perspective, the progress they have made to the business has already seen proven success in changing the future of an industry that will have positive consequences for all those involved.

You will have previously worked in a technical capacity in the data and analytics space and have experience working with an organisation where machine learning has been implemented, not just a concept that the business talks about having or the technology team would love to have. The commercial experience you will have had in the ML field will be proven examples of where you have affected the way a business or industry used to perform, to the changes that have come about from this.

Technically, you will have extensive experience in the Microsoft space - Power BI, Azure etc and you will have previously mentored and coached junior members of the teams you have been part of.

This is a rare opportunity in Brisbane where the business has truly embraced and funded projects across the ML space and would be a great chance for those in the Data Development/Data Engineering field, who are looking to move into a Data Scientist role in the future.

Please send your application through if you would like to know more.",4.0,"Emanate Technology
4.0",Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Solution designer/ ETL Engineer & Data Modeller,-1,"We are looking for a Qualified and Experienced Solution Designer to join our client for a period of 6 months with a view to extend.
You will work closely with team members and your contribution will range across gathering and analyzing information, developing and documenting improved processes and work instructions and experienced DWH Lead with skills in requirement analysis, solution designing, developing, testing and supporting ETL solutions.
A hands-on solution designer, data modeler and ETL developer for Data Warehousing and ETL application transformation projects using Informatica PowerCenter.
Knowledge on AWS, S3, Redshift, Informatica BDM, and related technologies.
Experience working with IPython, PySparks, AuCuMo, Airflow, Jenkins, Github, Athena, JIRA, Rally, Spectrum, Glue, Flyway.
Good exposure on Oracle PL/SQL, aware of DBA activities, writing and performance tuning of complex SQL queries.
Contract length: 6 months
Job Types: Full-time, Contract
Salary: $650.00 – $800.00 per day
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,nducive,Melbourne,-1,-1,-1,-1,-1,-1,-1,-1
"Data Engineer, Wollongong NSW or Mount Waverley VIC",-1,"Company Description
BlueScope is a technically advanced supplier of steel and steel products in Australia. We are an inclusive organisation and every day we showcase our technology and expertise throughout the world.

Job Description
We are looking for two Data Engineers to join our IT team, based in Wollongong NSW or Mount Waverley VIC. Use your experience in analytics to unlock business value, enabling use of big data for insights and decision-making.
Reporting to the Data Product Owner for our Australian Steel Products (ASP) business, this position will support strategic goals related to data. This will see you:
Gather business and technical requirements with the view to deliver outcomes;
Develop and implement end-to-end data collection, consolidation, modelling and visualisation solutions;
Document metadata in a dictionary and catalogue;
Ensure consumers of such information understand its accuracy, timeliness, quality and sensitivity, so that it is used appropriately; and
Identify opportunities to enhance analytics.
What are the benefits?
Work in a supportive and collaborative team environment whilst we embark on a journey to transform the way our business uses data!
Our systems landscape is broad and diverse. You will be encouraged to think creatively to develop data solutions which solve real business problems.
Working in this role you will enjoy:
the chance to learn more about data science;
salaried remuneration with attractive superannuation options;
the opportunity to participate in a performance incentive scheme; and
access to further development and career opportunities with BlueScope.
Who are we looking for?
We welcome applications from professionals with experience in data analytics and/or programming. Supported by your knowledge of project delivery methods (e.g. Agile), you will demonstrate:
experience with data mining, wrangling, mapping and visualisation techniques (e.g. Azure Data Factory, Databricks and/or DevOps etc.);
well-developed ability in gathering business and technical requirements;
skills in developing and implementing collection, consolidation, modelling and visualisation solutions; and
a passion for sharing your knowledge and desire for ongoing professional development.

Qualifications

null

Additional Information
We're proud to have been named an Inclusive Employer for 2019–2020 by the Diversity Council of Australia. We believe that our people are our strength. Having a diverse and inclusive workplace enables us to improve our capability and ensure continued, sustainable success.
We know that workplace flexibility can mean something different to everyone. Under our B-Flex initiative all of our roles have some degree of flexibility. We encourage you to discuss your needs with us.
Applications close Sunday 25th October 2020.",3.3,"BlueScope
3.3",Wollongong,-1,201 to 500 Employees,-1,Company - Private,Construction,"Construction, Repair & Maintenance",$100 to $500 million (USD),-1
ETL Data Engineer,-1,"ETL Data Engineer

Join a team that’s changing how Australia lives, works, plays and grows
We want you to be the best version of you

Work with innovative teams and explore new technologies to help solve real-world problems.

A typical day as a Data Engineer

ETL / Big Data Engineering professionals will be responsible for guiding the full lifecycle of a Data solution, including:
Working in highly client-facing roles to contribute throughout the end-to-end delivery lifecycle of complex and large-scale digital solutions
Use case and business case development
Support existing and new applications utilizing in-depth technical and data knowledge. Troubleshooting complex issues and providing advisory services to improve the client’s data landscape
Help to streamline and simplify the clients’ complex data landscape by integrating different applications and data architectures
Implementation from requirements analysis, platform selection, digital architecture design, application design and development, testing, and deployment
Interstate travel may be required

Basic qualifications:
Bachelor’s degree
Experience across systems integration, information management, data management and architecture, and business analytics
Experience with being in a team focusing on large-scale, multi-release information centric projects
Experience with waterfall and agile delivery and run / application support functions
Part of a team working on End to end implementation of at least 1 big data project

Preferred Skills:
Hand on experience in Data warehousing using ETL tools such as DataStage, Autosys and TeraData
Hands on experience in ETL job development with multiple stages like sequential file, Transformer, Lookup, join, sort and Database stages.
Strong hand on skills in design, development and implementation of various data remediation, Data migration, data integration techniques.
Strong hand on data modelling experience.
Strong hands on experience in database performance tuning including complex query optimizations and physical database tuning using Teradata.
Understanding of architectural designs and strategy related to data migration, data cleansing, data quality and data consolidation.
Proven data analysis, requirement gathering and problem-solving skills
Exposure to Unix environment and shell scripting.
Experience in Banking and Financial services industry
Desirable: Knowledge of cloud computing infrastructure (e.g. Amazon Web Services EC2, Google Cloud, Microsoft Azure)
About Accenture

Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. We combine unmatched experience and specialized capabilities across more than 40 industries — powered by the world’s largest network of Advanced Technology and Intelligent Operations centers. With 513,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises. Visit us at www.accenture.com.

Accenture is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, marital, domestic or civil partnership status, sexual orientation, gender identity, or any other basis as protected by applicable law.

Vera Goga is the Recruiter managing this role. As the team experience high volumes of applications, we appreciate your patience to allow for a fair and timely process.",3.9,"Accenture
3.9",Sydney,-1,10000+ Employees,1989,Company - Public,Consulting,Business Services,$10+ billion (USD),-1
Student Engineer,-1,"The candidate will have the ability to:
Undertake onsite inspection to collect asset condition data based on the relevant engineering standards and technical guidelines;
Undertake desktop analysis to evaluate the condition and performance of the assets;
Provide the appropriate information, advice, engineering input and support services for the sustainable management of Council’s stormwater and transport networks.
Qualifications:
The successful candidate will be enrolled in a Bachelor of Engineering with a minimum of two years completed.
Position Number: 100678
Position Hours: Fixed term (3 months), hours will be negotiated with the successful candidate, maximum of 75 hours per fortnight.
Salary: Schedule A, Salary Point 4.0. $28.64 per hour ($55,853.45 per annum, pro-rata) in accordance with Glenorchy City Council’s Enterprise Agreement 2016
Please note that all successful applicants will be required to provide a current National Police Check prior to commencement of employment.
For further information on this position, contact Patrick Marshall, Senior Civil Engineer on (03) 6216 6800.
How to apply: Applications for this position must be lodged on this submission site or on the Glenorchy City Council website www.gcc.tas.gov.au - Careers page.
To be considered for this role, all applicants must address the key selection criteria in the and provide a current resume. A copy of the position description can be found by clicking the below hyperlink or on the Glenorchy City Council website.
Applications close at 8pm on Sunday, 1st November 2020
- Student Engineer",4.0,"Glenorchy City Council
4.0",Glenorchy,-1,501 to 1000 Employees,-1,Government,-1,-1,Less than $1 million (USD),-1
Data Engineer involving DevOps,-1,"Data Engineer involving DevOps
Axiom Technologies is an Australia based entity with the history of providing Managed IT solutions to medium to large scale enterprises globally. Please visit our website for more information about what we do at www.axiomtechnologies.com
Axiom Technologies is an Equal Opportunity Employer and encourage applicants from all backgrounds and gender to apply, including, Aboriginal and Torres Strait Islander candidates
Job Requirements:
8+ years IT experience, with at least 5+ years of “Data Engineer/Deveoper” focused titles/roles,
Data Tools: Hands on experience with Apache Beam.
Testing: Hands on experience with automated testing activities/outcomes
DevOps: Experience with the processes involving Microservices facilities for artifacts developed
Platform/OS: Mid-range/Unix
Languages: Unix (Shell) Scripting/commands, SQL, Python
File formats: Text, CSV, Parquet, JSON, XML
Scheduling: Jenkins, Airflow
Auto Scripting: Designing/creation of scripts for repetitive activity. E.g. Unix scripting/SQL
Big data: Exposure to Data Lake Concepts, Hive (Schema), HDFS
Source Control tools: GIT
Delivery Models: Agile, Scrum
Ingestion Design: Create/assess Source/Target data mapping designs
Frameworks: Development and delivery frameworks
Activity Reporting/Repository: Jira, Confluence.
Quality: Accuracy and attention to detail
Industry: Financial Services/Banking
Solutions: Define solutions from High level to detail design to address automating ingestion activity. Facilitate/confirm requirements from product owners, business team members and technical associates,
Process Automation: Automating processes in file management, testing data in files, analysis and design, configuration management.
Script Automation: Ability to design/create scripts to automate/improve data copy/migration/ETL for any repetitive activity.
Languages: Java, Python
Scheduling: Control-M
Databases: Relational. E.g. POSTGRESS, Oracle – as a ETL developer
File Formats: Mainframe – experience with referencing its data formats/copybooks
Big data: Experience referencing/using Hive (Schema) to access data in HDFS
Metadata management tools: MDM, EDC and Axon
Performance: Assess, recommend, improve mappings, SQL queries, Batch feeds
Automation Tools: Other tools that may add value to an automation program and generally support development. E.g. API, REST, JDBC, Webservices, Message Queues/Load balancer,
Cloud: Experience with processing of data files to be ingested/stored in the Cloud, preferably with AWS.
Prod Support: Experience in a production support role performing root cause / impact analysis – under time constraints
Experience in a similar role
8+ Years
What next?
If you are looking for that next challenge in your career and wish to apply for this role, please forward your resume to careers.au@axiomtechnologies.com",2.0,"Axiom Technologies
2.0",Melbourne,-1,1 to 50 Employees,-1,Company - Private,Industrial Manufacturing,Manufacturing,Less than $1 million (USD),-1
Data Engineer,-1,"About the Role
We are on an exciting digital journey so it’s a great time to join ME! We are seeking a Junior Data Engineer who enjoys rolling up their sleeves, learning and growing. As part of our Enterprise Data Team, you will ensure fit for purpose data warehouse solutions are built for use across the bank and by utilising best practise ETL standards, whilst ensuring the data is trusted by our BI developers and key business consumers. Oh, and you’ll get to work on Microsoft technology stack too!
You will be involved with investigating data issues, keeping data feeds flowing and collaborating with different projects across the bank to deliver quality data solutions. How important does that sound? What’s even more important is this role contributes directly to our overall business strategy through the provision of data to enable analytics & reporting, as well as supporting business and decision system processes.

About You
You’re naturally a highly motivated and energetic person who thrives in a dynamic, ever-changing collaborative team environment. Ideally you have previous experience as an ETL developer, Data Engineer or a BI developer, and if you have a degree in computer science or similar it would really put you ahead of the rest.

With your knowledge of SQL coding, data modelling, understanding of data warehouse concepts, plus experience of working on complex ETL solutions, you’re ready to expand your horizons and launch your career into the world of IT at ME.

About ME
We’re not like other banks.
ME was created by the industry super funds to be different from the pack – with a core purpose to help all Australians get ahead financially – no conditions, asterisks or exceptions. And we know that looking after customers starts with taking care of our people.
We believe everyone deserves the same opportunities in life, regardless of gender or identity, sexuality, ethnicity, religion or disability ‒ with internal affinity groups.
Perk ME up
Once you get your feet in the door at ME, we’ll put them both in your very own ME-branded Converse shoes. You’ll also get the following financial, health and fun perks when you join the team:
4U Extras portal (discounts and cashback on 100s of items including cinemas, shopping and gym memberships
10% Myki discount
Purchased Leave programme
Internal wellness programme (Mindfully ME)
Professional education through LinkedIn Learning
Novated Leasing
Professional membership reimbursements
Health checks
Financial education (To help you manage your money smarter)
LGBTIQ+ and Women at ME affinity groups

I want those Converse shoes (and the role)
Can’t see a closing date on the advert? That’s because we’re pretty efficient here at ME and we may start looking at applications sooner rather than later, so if this role sounds like your jam, be sure to apply by submitting your resume today.

Should an applicant be the preferred candidate, background checks (including police checks, reference checks, ASIC banned and disqualified persons and bankruptcy checks) will be completed prior to the candidate's employment being confirmed. The outcomes of the background checks do not automatically bar candidates; however will be assessed against the inherent requirements of the job.
Back Share
Apply Now",3.0,"ME Bank
3.0",Melbourne,-1,501 to 1000 Employees,-1,Company - Private,Banks & Credit Unions,Finance,$100 to $500 million (USD),-1
Software Engineer - Machine Learning/Data Science,-1,"Zendesk is looking for a Software Engineer - Machine Learning/Data Science for a full time position in our Melbourne office.
As part of our engineering team, you will work at a scale where the challenges start to get seriously interesting. Our global engineering team is widely dispersed over the world, with people across nearly every continent. You will get a chance to do cool things with a diverse bunch of people while working in the Melbourne office that is home to Zendesk’s first machine learning (ML) research team.
The Data Science Team, together with Data Engineering, have built Satisfaction Prediction, Answer Bot and Content Cues — products that use Machine Learning (ML) and Artificial Intelligence (AI) to help our customers work more efficiently.
What you get to do every day:
We’re currently looking for someone to join our team as we research, develop, and productionise Machine Learning and Deep Learning models. In addition to frequenting Melbourne’s finest purveyors of coffee, ramen, and bulgogi, you may find yourself:
Building machine learning models including neural networks in TensorFlow
Writing and deploying production-grade Python
Querying and constructing datasets in AWS Athena, Spark
Evaluating and responding to real-world model performance
Scaling your ML to millions of predictions per day
Presenting your work to a broader audience
Watching your algorithm help Zendesk’s end-users
What you'll bring to the role:
A strong foundation in a quantitative discipline (e.g. machine learning, statistics, bio/eco/etc-informatics, econometrics, etc) is critical for this position. While experience in deep learning and natural language processing would be beneficial, your best qualities are:
dedication to continuous learning
collaborative work attitude
strong communication skills
You should also be comfortable with at least one programming language, such as Python, R or Scala.
Application Deadline: 18/11/2020
Job Types: Full-time, Permanent
Salary: $85,000.00 – $110,000.00 per year
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Temporarily due to COVID-19",4.5,"Zendesk
4.5",Melbourne,-1,1001 to 5000 Employees,2007,Company - Public,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),-1
Software Engineer (Machine Learning),-1,"About the Role
AdelaideMRI is building a medical reporting tool. We require an engineer to work primarily on machine learning projects to improve reporting speed and report comprehensiveness.
You will perform data analysis of medical report datasets and image datasets to infer sentence recommendations, image classifications, or other actionable results for the doctors.
Skills and Experience
Background in machine learning or image processing
Qualifications in Computer Science, Software Development or Engineering or equivalent experience
Bonus points for Python
No prior medical knowledge is required.
This position offers flexible hours and work arrangements.
Job Type: Full-time
Experience:
Software Engineering: 1 year (Preferred)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Yes",-1,Adelaide MRI,Australia,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Hey there, we’re PEXA!

We started as an idea: to deliver a single, national e-Conveyancing solution. We collaborated with the industry to create a national electronic lodgement and settlement platform: PEXA. From our humble beginnings, we’ve now grown to more than 320 employees across 5 different states. We’re still expanding at a rapid rate and constantly challenging ourselves to create great experiences for our members as they transition to fully digital conveyancing.

Why become a PEXArian?

Great question! Being a PEXArian is so much more than just a job. We are passionate, motivated & unashamedly enthusiastic at PEXA - we love what we do and we’re proud to admit it! Creating brilliant member experiences wouldn’t be possible if we didn’t also strive to create an amazing employee experience. Alongside our members, our employees are at the heart of everything we do.
Here’s a snapshot of what your life at PEXA could look like:

Your growth:
We encourage you to hit your personal and professional Learning & Development goals with our tailored programs and tools.

Your wellness:
We care about your holistic well being - a fully stocked kitchen, four wellness days, a $250 wellness subsidy as well as lunch and learn sessions to support your financial well being.

Your work/life blend:
We know that work is just one aspect of your life, we want to help you create your ideal work/life blend, rather than squeezing in life around work.

Your family:
With a range of benefits aimed at supporting your family including access to a subsidised school holiday program, extended parental leave and flexi-time to support your return to work, superannuation payments for unpaid parental leave for primary carers and a childcare allowance for pre-primary aged children, when we say, ‘welcome to the family’, we really mean it!
The impact you'd drive:
The successful candidate will be responsible for developing, and maintaining infrastructure to support the delivery of new and existing products. They will also be contributing to establish the rules and frameworks for obtaining the required approvals for new products.
On day one we’d love you to have:
Experience with Python, Spark
Event streaming/sourcing with Kafka or AWS Kinesis
Experience with data structures, formats and data security best practices
AWS experience (e.g CloudFormation, S3, ECS, Lambda, SQS, IAM, KMS, DynamoDB, Glue, Athena)
Query construction and optimisation (e.g. SQL, Elasticsearch, Splunk, DynamoDB)
Git, version control practices, and continuous integration/delivery servers
PyUnit and unit testing frameworks
Production release cycles and maintenance
Collaborating with technical and non-technical teams
Even better:
Agile methodology/delivery
GraphQL
Modern frontend technology (e.g. ReactJS, TypeScript)
Machine learning frameworks and tools (e.g. TensorFlow, PyTorch)
OAuth 2, SAML 2, JWT
Data visualisation and exploration tools (e.g. Jupyter notebooks, Tableau)
AWS SageMaker
Sounds like you?
If this role sounds like you, apply today to have your application reviewed ASAP!",3.9,"Property Exchange Australia Limited
3.9",Melbourne,-1,201 to 500 Employees,2010,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Ongoing position
Full time
Based in Sydney, NSW
Who we are
Australian Red Cross is part of the world’s largest humanitarian organisation. Our aim is to improve the lives of the most vulnerable people in Australia and across our region.
About the role
The Data Engineer role will sit within the Data and Integration Squad in IT and will own (design, implement and support) the AWS Big Data technologies such as the Data Lake and Data Warehouse and support the organisation in growing the data analytics capabilities at Red Cross. In addition to this, the data engineer role will also administer the Power BI tool and support the implementation of the data mastering capability.
What you will bring
Experience building and optimizing data pipelines, architectures and data sets.
Experience in dimensional modelling and building data vaults
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with structured, semi-structured and unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Why work for us?
Work for purpose and know that your work assists Red Cross support and empower people and communities in times of vulnerability.
Generous salary packaging options available that can increase your take home pay.
Further information
To find out more about this opportunity please see the position description below or contact Sharath Kumar Gurram on 02 8651 8839.
Position Description: Position Description - Data Engineer .pdf
Applications for this position will close at 11:55pm Thursday, 5 November 2020.",4.1,"Australian Red Cross
4.1",New South Wales,-1,1001 to 5000 Employees,-1,Nonprofit Organization,Industrial Manufacturing,Manufacturing,$500 million to $1 billion (USD),-1
Junior Fullstack Data Engineer (Python and React),-1,"Formbay is the leading Renewable Energy Certificate Trading company in Sydney. We provide Digital Workflow and Compliance solutions in the renewable energy industry and document processing.
Thanks to our meteoric growth and our commitment to be the best at all we do, we've identified the need to bring on board a new Junior Fullstack Data Engineer.
Reporting to our Principal Machine Learning Engineer, you will help build Machine Learning pipelines for our existing Digital Workflow and Compliance solutions to automate fraud detection and document processing over terabytes of photographic and documentary data – including documents, photos, GPS data and aerial/satellite photography.
Our stack is based on Python, JavaScript, Dask, Tensorflow, CUDA, Nix/NixOS, AWS, Docker, PostgreSQL and more – familiarity with these applications will give you a leg-up on the competition.
Our ideal candidate will have the following competencies:
SQL
Python
JavaScript/TypeScript
Our candidate must also be comfortable working with Linux.
Located a stone's throw away from the Queen Victoria Building in Sydney's bustling CBD, we are centrally-located with easy access to public transportation, bars, cafes and fine dining.
Formbay will provide flexible working hours, a generous remuneration package and the opportunity to work on a world-first software solution are what we can offer you. Free, twice-weekly gym sessions and really, really good coffee are also available.
No hiring/recruitment agencies need apply.",5.0,"Formbay
5.0",Sydney,-1,1 to 50 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is an experienced and qualified Data Engineer to join our IT team based in Birtinya.
Key Responsibilities:
Create and maintain data pipelines and or ETL scripts
Create and maintain data integration including API and Batch interfaces
Performed detailed data analysis
Create and maintain corporate data models
Create and maintain data visualization using Qlik.Sense , PowerBI or Simliar Toolset
Experience in defining, building and maintaining data virtualization and/or star schema data warehouses
Maintain, tune and optimise database, integration and visualisation toolsets
ABOUT YOU:
To succeed in this role, you’ll need to bring the following experience and skills:
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Excellent communication skills both oral and written, with an ability to bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking
Experience with data analysis and modelling will be beneficial

How to Apply
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kawana Waters,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Graduate Data Science / Engineer,-1,"The NRMA is an organisation looking to the future, and right now, we are on the lookout for people who can help us reach our goal: to continue to shape the way Australians move, for the next 100 years and beyond. www.mynrma.com.au.
Everyone new to the team, along with our current staff, will temporarily work from home until it is safe to return to our offices. All interviewing and on boarding will be done virtually due to COVID-19.


Your opportunity
As Graduate Data Scientist or Engineer you will be part of the Data Engineering team delivering cloud data transition program for business initiatives and supporting the entire data platform build.
Your key responsibilities will be to:
Implementing Concepts of Data Warehousing, Data Mart creations within Cloud
Use of SQL for data analysis and insights
Building AI/Machine Learning prototype for implementing and supporting existing algorithms
Data Analytical reports build, using different tool sets


Requirements for Success:
Relevant Degree - Computer Science, Computer Engineering, Software Engineering, Data Science
Excellent SQL skills and demonstrated working knowledge in Python
Demonstrated understanding in data structure and algorithms.
Knowledge and concept of data warehousing methodologies
Any reporting tools experience Tableau or Oracle Analytics Cloud, Looker is desirable
Exposure to Google/AWS/Azure/Oracle any cloud based platforms is desirable
Good communication and interpersonal skills

If you have the required skills and the passion to join our high performing team, please apply today.

Employee Benefits
To ensure our employees feel valued, empowered and celebrated we provide a range of employee benefits including:
50% discount on all NRMA insurances
Free Roadside Assistance
12 weeks paid primary and 4 weeks paid secondary parental leave
Free NRMA Blue Membership
At the NRMA Group, we are People Moving People and diversity and inclusion are part of our DNA. Together, we continue to build an inclusive culture that encourages, supports and celebrates the diverse voices of our employees. It fuels our innovation, promotes flexible ways of working and connects us closer to our members and the communities we serve.",2.5,"NRMA Motoring & Services
2.5",Sydney,-1,501 to 1000 Employees,-1,Nonprofit Organization,Casual Restaurants,"Restaurants, Bars & Food Services",$500 million to $1 billion (USD),-1
Data Centre Engineer,-1,"We are a leading world group that provides low-carbon energy and services. To tackle the climate emergency facing us all, our aim is to become the world leader in the zero-carbon energy transition ""as a service"" for our clients – particular for companies and regional authorities. We use our expertise in our key business areas (renewables, gas, services) to provide competitive and bespoke solutions.
The Data Centre Engineer will be employed as part of a 24/7 ongoing shift to coordinate and monitor third party service providers, maintain the data centre facilities and infrastructure plans, coordinate the implementation of customer requests within the data centre and monitor systems, all in accordance with the Contract KPIs and SLAs.
Coordinate and monitor third party service providers for regular maintenance & testing, service faults & call outs, ensuring works are performed in accordance with Contract SLAs
Monitor and maintain the data centre facilities and infrastructure plans and documentation, including electrical, mechanical, hydraulics, fire and BMS/EMS systems
Coordinate the implementation of internal and external customer requests within the data centre
Perform scheduled plant checks and minor maintenance works
Ensure all Work Order requests are raised and closed in a timely manner
Conduct inductions for staff, vendors and contractors
Ensure all work permits for vendor works are raised and closed
Perform inventory checks on all equipment and critical spares

Qualifications
The selected candidate must be able to demonstrate:
Electrical or HVAC background, or Graduate Electrical or Mechanical Engineer
Passionate about quality work and career minded looking for a new challenge
Can commit to a day and night shift roster (2 days of day shift, then 2 days of night shift, 4 days off)
Ideally able to commence asap
As part of carrying out the duties of this role, it is mandatory to hold Australian Citizenship.

If you are interested and meet the selection criteria apply with an up-to-date resume via the apply instructions on this website.

ENGIE Services is an EEO employer, where all applicants are treated with fairness and respect and have equal access to the opportunities available.

We will not be engaging in the services of a recruitment agency to fill this vacancy and therefore request all interested candidates apply directly to this advertisement.

Job
: Maintenance
Primary Location
: Oceania-Australia-New South Wales-Erskine Park
Organization
: ENGIE Services Australia and New Zealand
Schedule
: Full-time
Nature of Responsibility
: Senior operational / administrative role
Job Posting
: Sep 11, 2020, 6:29:59 AM",3.7,"ENGIE Services Australia & New Zealand
3.7",Sydney,-1,5001 to 10000 Employees,1995,Company - Public,Energy,"Oil, Gas, Energy & Utilities",$2 to $5 billion (USD),-1
Senior Data Engineer,-1,"Senior Data Engineer, Temporary, SYDNEY - McKell

Job Title: Senior Data Engineer

Salary: SNSW Grade 9/10 - The package includes base salary range of $111,806 to $134,667, plus employer's contribution to superannuation and annual leave loading.

Location: Head Office – Haymarket

Employment Status: Temporary through till 30th June 2021


About Service NSW:

Service NSW is making it easier for people and businesses across NSW to access government services. The role designs, builds and analyses complex data from multiple sources to identify revenue, process and business improvement opportunities; providing new information and insights to the business to inform planning, continuous improvement and performance.

About the Role

We are currently seeking to appoint a Senior Data Engineer to deliver expert advice and services in the design of a Single View of Customer and data-related services to support the achievement of business outcomes and strategic goals. We support flexible working practices with staff working remotely during this time.

In this role you will:

Design, build and support a modern data platform based in AWS and vendor technologies.
Provide expertise on data modelling for Graph data model and Customer Data Platform (CDP).
Create data pipelines, load, transformation and reporting workloads in AWS.
Work with the latest data engineering technologies like Apache Kafka, AWS Kinesis, AWS Neptune, AWS Glue and AWS Athena.
Contribute to the design and decision-making of the right tool or platform for the job according to requirements.
Provide expert advice and guidance on data quality and data engineering best practices.
Support a “bigger than you can imagine” scale of data in production environments.
Design, develop and support a metrics-driven reporting solution and a meaningful business intelligence platform.
Document the solution design and support procedures of solutions.
Produce reports, visualisations and recommendations to answer complex business problems that are presented in the most appropriate format to ensure clarity for target audience.
Analyse and define new process improvement opportunities to support continuous improvement and business outcomes; providing advice to stakeholders, on ways to improve the efficiency and reliability of data products and services.
Be very responsive to the information needs of the business by corresponding to customers in a timely manner and provide support/solutions to issues raised.
Troubleshoot and perform root cause analysis on production issues. Identify and implement long term solutions to problems. Perform scheduled maintenance, release deployment and production support activities after business hours, from time to time.
Liaise with internal and external customers to discuss and gather requirements, solutions etc. and maintain a good working relationship with the stakeholders.


Skills and Experience Required:

Solid experience with workflow technologies designing and building data pipelines, data models and data stores.
Experience working within and an understanding of Amazon AWS ecosystem, including security and performance tuning.
Hands on experience working with different types of databases, with focus on Graph and NoSQL databases.
Experience with data streaming required. Having used Kafka and related technologies is an added advantage.
Sound knowledge and experience working with batch processing, data extraction and API integration.
Hands on experience with at least one programming language: Java, Python or scripting.
Demonstrated experience working in an Agile based, fast paced, complex environment within cross-functional teams.
Experience developing systematised insights, data analytics and reporting solutions is an added advantage.
Experience with interactive visualisation of data insights is an added advantage.


Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Salary Grade 9/10, with the base salary for this role starting at 111,806 base plus superannuation

Closing Date: 6th November at 9:59am - applications will be reviewed on a rolling basis, applications may close early or extend

Please apply online, direct applications submitted via email will not be considered.

The Department of Customer Service is proud to be an EEO Employer who are fully focused on equality and believe deeply in diversity of all identities making us different and a true reflection of our NSW customers. As an inclusive workplace, we support various employee resource groups, practice flexible work and workplace adjustment.

If you do require an adjustment during the recruitment process, please notify us on your application form.",3.2,"Service NSW
3.2",Sydney,-1,501 to 1000 Employees,2012,Government,State & Regional Agencies,Government,Unknown / Non-Applicable,-1
Data Engineer - Entry / Mid Level,-1,"Work with a great team on interesting projects customers
Gain more experience in AWS, Data, DevOps cloud operations
Got a working knowledge of AWS? We will teach you the cool stuff!

Itoc is seeking an up and coming Data Engineer to join our growing Data Team in Sydney.

This is an exciting role working with databases, data lakes, data warehouses, data transformation (Python SQL) and enabling AI/ML.

You will be implementing foundational, robust and production ready data platforms to enable business data-discovery, self-service, AI/ML functions across a range of client types and industries, allowing them to do more with their data.

You'll be responsible for:

Deploying data repositories such as lakes and warehouses.
Contribute to our growing portfolio of data solutions.
Ongoing optimisation and management of data platforms.
Development of transformational logic for data pipelines
Data evangelism. We want to show our clients how to follow the best practices for data.

Desired Skills and Experience

To take up the challenge, you will have a depth of skills and experience including:

1-2+ yrs of focused data experience working with SQL and/or NoSQL solutions
A solid education in Software Engineering or equivalent industry experience.
Anything Data focused preferred.
Ability to analyse business scenarios and associated data landscape to derive potential opportunities.
Strong foundation in Python and SQL
Working knowledge of APIs
Principle knowledge of the different relational database platforms and modern data storage techniques
Knowledge of the different aspects of data environments
Collect, store, process, verify consume
Experience with version management systems (such as GIT)
Working knowledge of AWS or another cloud platform - we will teach you the cool stuff.
Great communication skills, an ability to work closely with customers, developers and engineers and the confidence to present ideas in open forums.
Relevant tertiary qualifications and/or industry certifications.
Great communication skills, an ability to work closely with clients, developers and engineers and the confidence to present ideas in open forums.

While not required, a background in consulting and professional services is highly desirable.

Itoc Description

This is an exciting and challenging career opportunity to join the growing Sydney-based Data Team of a leading cloud solution provider where you will be given support to reach your long term career goals. You will be part of a team of cloud experts and will work in an environment of continuous improvement and learning delivering innovative cloud solutions across SaaS, online business and enterprise business.

On offer is a chance to join a team with a great working environment, in an organisation that values its employees and sees the value in ensuring they are engaged. Our team are clearly passionate about what they do, that's why we won the following awards:

Customer Obsession Partner of the Year 2015: ANZ Region
Customer Obsession Leadership Partner 2015: re:Invent

As an employer of choice Itoc offers competitive remuneration, training and development programs and a great working environment. We value a healthy work life balance.

The Perks

MacBook or Dell
Continuous internal learning that will provide training and career development opportunities
Working with a collaborative, social team and leveling-up your skills faster than you will anywhere else.
Quarterly social events

Itoc

Culture and smarts are important to us. Bring your secret sauce. This is no ordinary environment, you will work along some of the Cloud’s best. All engineers at Itoc must gain at least five AWS certifications. We work hard but we have fun.

Please note you must have full working rights in Australia and be available on-shore for face to face interviews.

No recruiters please.",4.0,"Itoc
4.0",Sydney,-1,1 to 50 Employees,2013,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Date: 01-Oct-2020

Location:
Melbourne, VIC, AU

Department:Description:
Technology discounts - from Apple HP Lenovo to Windows
Flexible work arrangements - work in a way that suits you best
Salary packaging - to suit your personal and financial circumstances

Do you want to work for one of the fastest growing data teams in Australia? Do you want to work on multiple data platforms and provide new solution offerings by leveraging cloud and big data technologies?

About the team

Big data information and analytics. Three words that spark apprehension in most businesses. But our team of experts are constantly curious and excited about combining our wonderful array of technological expertise to transform data into our clients most valuable assets making their work smarter. Our data consultants are supported with resources training and tools they need to excel at their work but also the freedom and power to create their own paths forward to make a difference.

As a Senior Consultant in Big Data you will work closely with the team and stakeholders to build and deliver a Cloud based vision for a next generation Big Data analytics platform with strong focus on data quality data security and deliver the systems that process huge volumes of data.

What will you typical day look like?

You will play a pivotal role in - Designing and producing high performing and stable applications to perform complex processing of massive volumes of data in a new cloud based architecture; Building real-time data processing applications which are integrated with business systems to enable value from analytic models to drive rapid decision making; Contributing to system architecture design for a data platform (including cloud-based structures both on and off premises data warehouse components and data lakes); this could cover a range of technologies various countries/locations and lines of business; Support data strategy or technology strategy definition programs including technology stack definition and target operating model requirements

Enough about us lets talk about you:
You are someone with:
Use of traditional data analytics tools and techniques (e.g. MSSQL Oracle MySQL) and ETL software (e.g. SSIS Informatica CloverETL)
Working in large scale cloud data solutions using platforms such as AWS or Azure or GCP will be a bonus.
Experience in scripting or programming (e.g. Python Java Scala C#)
Excellent verbal and written communication skills to adapt to technical and non-technical audiences.
Educated to degree level (or have equivalent experience)
Why Deloitte?

At Deloitte we create positively differentiated work experiences that enable our people to feel valued and achieve their full potential. We value difference and embrace people with diverse backgrounds and thinking styles. Knowing that people work best in different ways we are happy to discuss alternative arrangements if the working pattern you are looking for is not specifically indicated.",3.8,"Deloitte
3.8",Melbourne,-1,10000+ Employees,1850,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Engineer,-1,"Opportunity to grow the team
Period of growth
Intuitive app
S2M are working with a FinTech who have created a unique financial product to help thousands of people better manage their finance, and is currently scaling the company to the next level!

They are looking for a Data Engineer to join, and looking for someone who wants to be hands on, with opportunity to grow the team in future.

Role:

Looking for people with strong AWS experience. You will need passion for data and a cloud, through which you will help a rapidly scaling Australian FinTech establish their data infrastructure from the ground up.
5+ years’ experience as a data engineer within the data and analytics domain
A python 3.X aficionado who is very comfortable creating and orchestrating AWS data pipelines with nothing but code
Strong project delivery toolset experience in open source data integration tools
Experience with processing large volumes of complex data including visualisation and insights generation
Ability to define and develop data integration patterns and pipelines
Ability to assess complexity of data (volume, structure, relationship etc.)
Hands on experience working with different databases (RDBMS, NoSQL, Blob storage etc)
Hands on technical expertise setting up DevOps automation
Hands on experience working technologies/platform e.g. AWS, Dockers, Containers
Experience building data profiling and data cleansing frameworks
Technical reconciliation and reporting
Knowledge and experience in end-to-end project delivery, either traditional SDLC or agile delivery methodologies (or hybrid approaches)
Exceptional communication, documentation and presentation skills
If this sounds like you, get in touch today - kate.gabb@s2m.com.au
3167410agsdf",3.1,"S2M
3.1",Sydney,-1,Unknown,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Analysts,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is seeking experienced and qualified Data Analysts to join our IT team based in our corporate office in Birtinya (Sunshine Coast) or at our meat processing facility in Kilcoy.
Key Responsibilities:
A mixture of data analysis and commercial skills to source, blend and analyse data to gain insight and answer key commercial questions
Working with strategic leaders to define and model Key Performance Indicators, and assist in building forecasting models
Working closely with data engineers and BI developers to specify data pipelines and report visualisation
Drive the creation and implementation of data quality business rule including data definition, governance and quality assurance
About You:
To succeed in this role, you’ll need to bring the following experience and skills:
Proven ability to derive insight and knowledge from data using commercial expertise is a strong requirement
Strong SQL and Excel skills are essential, along with strong data analysis and commercial insights
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Effective people communicator - engage with stakeholders on reporting needs, interpret requirements into visual solutions and train/deliver the outputs to the stakeholders getting signoff of acceptance
Bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking

How to Apply:
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kilcoy,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Network Data Engineer,-1,"Min 6+ years of experience in the relevant technologies
Australian Driving License for visiting remote locations / Data Centre for day to day technical work.
Managing Network devices (switches, routers, firewalls, load balancer, and wireless technology)
Performing MACD activities for all network devices.
Supporting BAU operation activities.
Proficient in performing in-depth details of technical troubleshooting, cause and provide recommendation to the client for incidents causing extended network outage to client’s critical locations.
Provide exceptional network services in terms of network support, break-fix, design and consulting, new projects, implementation.
Configure, administer, and document firewall infrastructure.
Manage the firewall deployment, rules migrations, and firewall administration.
Supporting Cloud Migration Activities from traditional to AWS/Azure.
Setting up VPN tunnel with Cloud and 3rd Party network devices.
Integrating and upgrading existing ISP bandwidth with support from ISP Vendor.
Setting up VPN profiles for Users.
Installing hot fix and patches to mitigate the security devices from attacks and bugs.
Reviewing and fine tuning the firewall rules and NAT rules.
Documentation and change control.
Mentoring, Motivating and Guiding support teams
Technical skills:
o LAN
o Wireless
o WAN
o MPLS
o Routing protocols (OSPF,BGP)
o DMVPN
o Azure cloud Networking
o Network Security
Fortigate Manager / Analyzer / Firewall
Cisco ASA
Firepower FTD
Cisco Any connect
Site to Site VPN
F5 Load Balancing and Scripting iRule
Job Types: Full-time, Contract
Schedule:
8 hour shift
Experience:
Scripting: 5 years (Required)
Data Network: 5 years (Required)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Required)",3.6,"Total IT Global
3.6",Sydney,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Engineer - Processing & Analysis,-1,"Job Description:
Design,build and maintain the ingestion system to support various types of data(e.g. User behavior, RDS, NoSQL db and others) to be ingested to the data warehouse more timely and accurately
Translate data requirements into scalable technical data service with low latency and high concurrency
Design,build and maintain the batch or real time data pipeline in production using Hadoop big data technology
Analyze and improve efficiency, scalability, and stability of the system
Define and manage SLA,Data quality for all data sets in allocated areas of ownership
Requirements:
Minimum B.S. degree in Computer Science or a related technical field
2+ years of working experience in programming languages,such as Java,Scala,Python
Familiar with Hadoop, Spark and Flink data processing, experience of TB data processing experience is a plus
Familiar designing and operating of a robust distributed system is a plus
Understand data mining or machine learning
Excited to work intimately with data
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"SYNOPSIS:
Lead Data Engineer
Applications close Sunday 8 November 2020
Ongoing
Contact name: Shyni Sasikala
Phone: (02) 6249 9048
Email: Shyni.Sasikala@ga.gov.au

The Data Policy and Informatics section within the Digital Science and Information branch creates, implements, and promotes policies, platforms and tools that improve and support the quality, discoverability, accessibility, and general usability of Geoscience Australia’s science data products. The section consults with internal and external research, government and industry partners to establish collaborative data frameworks, architectures and models within Geoscience Australia (GA) and across broader national and international communities of practice. The section innovates, builds and maintains tools, systems, processes and governance that enable digital data management, cataloguing and open data delivery.
GA makes accessible a wide range of geoscientific and spatial data to a wide variety of stakeholders in multiple formats, and in recent years GA's data volumes have grown exponentially. GA is focussed on making its data and metadata assets accessible so that they can be used in machine to machine interactions for data analytics and other applications in environments that range from High Performance Computing (HPC), through high-end cloud servers, to mobile devices.
We currently have two opportunities for Lead Data Engineers in the Informatics team. The Lead Data Engineer is responsible for innovating and exploring new technologies that will advance GA’s science goals and maximise the uptake and use of GA’s science data. The Lead Data Engineer reports to the team’s Assistant Director but also works closely with other developers, data scientists and engineers within the Digital Science and Innovation (DiSI) branch, as well as diverse stakeholders both within and external to GA.",3.9,"Geoscience Australia
3.9",Canberra,-1,501 to 1000 Employees,2001,Government,Federal Agencies,Government,$100 to $500 million (USD),-1
Data Engineer,-1,"The Seven Network is part of Seven West Media, one of Australia’s most prominent media companies, with a market leading presence in content across broadcast television, online and in print. Comprising some of Australia’s most renowned media brands, SWM includes not just Seven Network and its affiliate channels 7two, 7mate, 7flix and BVOD offering 7plus, but also 7NEWS.com.au, The West Australian, The Sunday Times and more.
At Seven we are here to bring all Australians closer to the moments that move us - we’re first on the scene, with our finger on the pulse, on demand, in the moment. Together, we’re responsible for creating and sustaining authentic Australian engagement.
A new and exciting opportunity has opened for a Data Engineer to join the Audience Intelligence team. Based in Sydney and reporting to the Head of Data Enablement, you’ll be responsible for:
Implementation of end to end data solutions to support Data Strategy for the SWM group.
Work closely with the Data Solution Designers to develop and maintain scalable data pipelines and build out new file and API based integrations to address requirements from the various business stakeholders.
Collaborates with engineering, analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organisation.
Work on Data Preparation for analytics and data scientist team members and assist them from an engineering perspective in building and optimising the models including building the automation of the end to end workflows
Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.
Perform data analysis required to troubleshoot data related issues and assist in the resolution of production data issues.
Work effectively with vendors for successful delivery of projects and acceptance of the solution
Work on Delivery projects using Agile Software Development methodologies
We are looking for someone who has:
Bachelor's degree in computer science, computer engineering or other technical discipline is essential
Proven experience working as a digital analytics specialist
Extensive experience with digital analytics implementation (e.g. Google Analytics, Snowplow, Adobe Analytics) and BI processes and visualisation platforms
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience in ETL and building and optimizing ‘big data’ pipelines and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Experience with big data tools: Hadoop, Spark, etc., AWS cloud services: EC2, S3, Lambda and familiar with version control systems: Git
Strong coding skills with knowledge of Unix/Linux and scripting languages such as Unix Shell scripting, Python desirable
Experience supporting and working with cross-functional teams in a fast-paced environment.
Ability to multi-task and problem solve with changing demands and priorities
Ability to work under pressure to meet deadlines and detail oriented
Your success is our success: we will provide you with opportunities for you to keep learning and growing, enabling you to challenge and develop yourself. In return, we offer a benefits program that has something in it for everyone.
Seven West Media is an equal opportunity employer and we are committed to creating a diverse and inclusive workplace.
Recruitment Agencies: Seven West Media does not accept any unsolicited agency resumes and will not be responsible for any fees related to unsolicited resumes.
Advertised: 19 Oct 2020 12:00 AM AUS Eastern Daylight Time
Applications close:

Back to search results",2.5,"Seven West Media
2.5",Sydney,-1,5001 to 10000 Employees,1956,Company - Public,TV Broadcast & Cable Networks,Media,Unknown / Non-Applicable,-1
BICON Rules Engineer,-1,"APS 5 - $73,299 - $80,410 per annum plus superannuation
Biosecurity Plant Division
Canberra, ACT
Play an active role in managing biosecurity risk to Australia
Work in a motivated and professional team with a wide range of skills and backgrounds
Full training provided

Who we are
The BICON Content Development Team maintains and improves the Biosecurity Import CONditions database (BICON) content to allow external clients to understand and comply with their biosecurity obligations and internal clients to effectively manage biosecurity risk and regulate imports. We work collaboratively with internal clients to comprehend and implement their BICON content requirements and optimise the use of BICON to publish clear import requirements and onshore management support procedures to effectively manage biosecurity risk.

The Jobs
Key duties of these positions include:

working with business content (import and permit conditions) and import programs to understand and construct decision tree structures in the BICON database, in accordance with system design and authoring conventions
executing changes to import and permit conditions in alignment with service standards while complying with system rules and authoring conventions
providing technical advice through various formats on the most appropriate means of authoring BICON content to achieve import program and stakeholder objectives
using workflow management tools to maintain detailed records of changes to import conditions and key decisions
performing administrative tasks including system reporting, data analysis and scoping tasks for the BICON content change work program
contributing to the development and maintenance of instructional material, authoring conventions and courseware
clearly documenting and reporting system issues
developing and maintaining effective working relationships with internal and external stakeholders.

What we are looking for
Knowledge and experience
Experience working with complex IT systems.
Experience working collaboratively and as part of a team.
Knowledge of the role of biosecurity is preferred but not essential.

For additional information, please read the Job Description below.
Candidate Information Package docx Opens in new window",3.9,"Department of Agriculture & Water Resources
3.9",Australia,-1,5001 to 10000 Employees,-1,Government,Federal Agencies,Government,$500 million to $1 billion (USD),-1
Cloud Data Engineer,-1,"Job no: 509605
Work type: Permanent Full Time
Location: Melbourne, Canberra, Sydney
Do you embrace digital disruption?
Do you love solving complex problems, designing sophisticated solutions and building innovative technology?
Do you believe in creating powerful actionable insights from Data and Analytics?
Do you want to work in a diverse and flexible working environment?
KPMG is one of the most trusted and respected global professional services firms. Through depth of expertise, clarity of insight and strength of purpose we help our clients solve complex challenges, steer change, strengthen, transition and grow. We are a team based practice and this extends to our clients whom we work and collaborate with, in solving complex problems. Together, we design, innovate and implement, providing enduring advice that support our clients and the services they deliver. Our clients vary in size and come from a diverse range of sectors – all sharing in a common goal: to embrace change and deliver services that make Australia a better place. We are looking for talented individuals who would like to join us on the journey.
KPMG’s Digital Delta Team
We re-imagine and re-invent organisations to become world class digital enterprises using advanced technologies, data and human insights. We help organisations to embrace Digital Strategy, Artificial Intelligence (AI) & Cognitive, the Internet of Things (IoT), Data, Analytics & Modelling, Mobile App & Web, and User Experience (UX) & User Interface (UI) and more.
We work with clients to:
Formulate strategies that re-imagine organisations
Harness innovation from the 4th industrial revolution
Actioning insights from trusted data to consistently and quickly make clear decisions
Build adaptive organisations
Thrive as a connected enterprise – front, middle and back office
This is how you’ll contribute:
We are looking for ambitious Data Engineers who are passionate about helping clients define bold ambitions and deliver on them. Joining our team will take you on a journey of personal and technical growth and provide the opportunity to inspire confidence and empower change.
As a Data Engineer you are the designer, builder and manager of the information or ""big data"" infrastructure, preparing data for analytical or operational use. You will design, construct, test and maintain a data pipeline to pull together information from different source systems; integrating, consolidating and cleansing data; and structure it for use in individual analytics applications.
The KPMG Difference
Our people are focused on creating a diverse and dynamic environment that embraces and values differences. We value the variety of unique experiences, qualities and characteristics our people possess and we share and learn from each other.
We are proud to be consistently recognised as an employer of choice for women, and for our achievements in LGBT+ workplace inclusion.
Our commitment to ‘Flexibility’ allows our people to manage the changing demands of work, personal or family life. Explore the links below to hear our people share their experience @ KPMG:
Flexibility empowers wellbeing
Flexibility enables contribution to the community
Flexibility inspires technology & innovation
Flexibility supports family

Make KPMG the clear choice for your career and be Extraordinary!

Advertised: 09 Sep 2020 AUS Eastern Standard Time
Applications close:",3.8,"KPMG
3.8",Sydney,-1,10000+ Employees,1987,Subsidiary or Business Segment,Accounting,Accounting & Legal,$2 to $5 billion (USD),-1
Computer Network and Systems Engineer,-1,"Duties Include but are not limited to:
Tasks Include:
analysing, developing, interpreting and evaluating complex system design and architecture specifications, data models and diagrams in the development, configuration and integration of computer systems
researching, analysing, evaluating and monitoring network infrastructure to ensure networks are configured to operate at optimal performance
assessing and recommending improvements to network operations and integrated hardware, software, communications and operating systems
providing specialist skills in supporting and troubleshooting network problems and emergencies
installing, configuring, testing, maintaining and administering new and upgraded networks, software database applications, servers and workstations
providing network programming in support of specific business needs and requirements
preparing and maintaining procedures and documentation for network inventory, and recording diagnosis and resolution of network faults, enhancements and modifications to networks, and maintenance instructions
monitoring network traffic, and activity, capacity and usage to ensure continued integrity and optimal network performance
Skills and Experience Required:
Must have experience working in a Managed Service environment
Demonstrated experience in IT Networks and Data Centres
Understanding of systems and architectures to meet client needs
Experience in Help Desk including break / fix
Effective and timely documentation
Effective Task Management Skills
Be solution and outcome focused and willing to learn new technologies
Excellent communication skills with staff, clients and partners
Time management, ability to prioritise and deliver to schedule
Experience with N-Able and Connectwise desired
Open Cabling license desired
Job Types: Full-time, Permanent
Salary: $30.00 per hour
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,Trans-plant training,Canberra,-1,-1,-1,-1,-1,-1,-1,-1
Software Engineer (Data),-1,"If you are looking for an opportunity to make a real impact with smart people who are genuinely doing things differently then you've come to the right place! We're growing our data engineering capabilities and are looking for awesome data engineers to join our team.
With our diverse range of clients and projects, no day will look the same - but here's a great snapshot of what you'll be doing:
Work with some of the best Data Scientists and Engineers to deliver production-grade AI and Machine Learning systems as we deliver client projects from inception to production.
Consulting with our clients and working with them to build modern data systems using the 'best of' technologies and principles.
Advising clients on data strategy, architecture and technology.
Applying best software engineering practices in coding, monitoring and alerting, using CI/CD, TDD and cloud architectures.
Working over a wide range of big data tools and environments: not limited to; Apache Kafka, Spark, Python, Scala, Hive, Airflow, AWS EMR & Glue, GCP Dataproc & Dataflow, BigQuery, Snowflake, Redshift.
Who are we?
Glad you asked! We are Eliiza. Data science. Engineered for scale.
We are a passionate team of data scientists and engineers who apply data science and machine learning to solve real-world problems. Our mission is to create a bright future for Australian businesses and society in a world increasingly influenced by intelligent technologies.
We've created a culture that values diversity where people can truly be themselves! We care a lot about growing the Australian AI community in a positive direction, and we're doing several things to try and achieve that:
We provide opportunities for underrepresented groups to work in AI through our associate and intern programmes
We organise and participate in a range of community events, reading groups and meetups
We produce the AI Australia podcast
We blog about topics we care about
We stream brown bag sessions to the broader community
We're also part of Mantel Group's 'house of brands' which means it's not just the Eliiza team you'll work with, learn from and see at social events - there's another 230 of us across DigIO, Kasna & CMD Solutions!
So you're ready for something new?
We're keen to know more about you! Our team is made up of a range of people, with different experience across a huge range of data driven skill sets.
We'd love to hear from you if you have experience with:
one (or more) core language(s), ideally Scala, Python or Java
one (or more) cloud platforms, AWS, GCP, Azure
ETL/ELT concepts and technologies e.g. Data partitioning, Hive, Spark
streaming data concepts and technologies, ideally Kafka (Kinesis, Beam or Pubsub will do)
We'd be over the moon if you:
Experience with distributed/columnar databases (e.g. Snowflake, Big query, Redshift).
Experience with any of a variety of databases e.g. RDMS, NoSql, Columar, Distributed, Time series, Graph.
Knowledge of job orchestration and scheduling. Any experience with Airflow, Luigi or Oozie.
Experience with containers and container orchestration (Docker, Docker Compose or Kubernetes).
However, we value a diversity of skill-sets, and don't necessarily require that you're skilled with all of the above. If you feel you don't fit all the experience/skills listed above we still encourage you to apply or get in touch.
What's on offer if you join us?
We make sure you're always one step ahead by investing your learning and development, every year. We build our own training where it doesn't exist yet.
We hire smart people and get out of their way. By focusing on our five principles and not getting caught up in red tape, we trust you to get the job done.
You'll get all the tools you need - a new iPhone or Google phone, a new Macbook Pro or Dell, and a lot of branded swag!
But hold on, you mentioned a house of brands?
We certainly did! Mantel Group is an Australian-owned, 'house of brands' company with four technology businesses (Eliiza being one of them!) across Melbourne and Sydney. We're building a group of companies with open borders so we can support you to take on new skills without leaving an awesome team - we understand you won't have one job for life!
We may only be just two years old but Mantel Group has already been recognised #9 in the 2020 Best Places to Work in Australia and #4 in the AFR's 2020 fastest growing new companies.
Keen to chat?
Click ""Apply"" to share your details with our talent team, and we'll be in touch.
In the meantime, check out 'how we hire' to find out what's in store if you're successful and get to know us better by visiting our website and following Eliiza on LinkedIn.",-1,Eliiza,Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Infrastructure Engineer,-1,"Job Description:
Design and grow the Shopee data platform to support a variety of big data applications using open-source technologies including Kafka, Hadoop, Presto, HBase, Spark, Hive, Druid, and our own creations. Some examples include a real-time data streaming platform, a unified query platform, a cluster management system, and a machine learning platform
Dig into the source code of some open-source big data system to get the whole control and familiar with the details, configurations, designs and source code. Develop and maintain the internal release of big data systems and components as the business requirements.
Keep close and overall monitoring for all the deployments of the systems, maintain the system’s stability, improve the performance, discover the performance bottlenecks, tracking and troubleshooting, cost optimisation.
Requirements:
B. Sci. / Ms / PhD in Computer Science or a related technical field
Familiar with at least one of these languages: Java, Scala, Python, Bash under Linux / Unix. Scala is a plus
Familiar with the use and compute logical of SQL
Knowledge about the Big Data Infrastructure system technology like Distributed File System, Distributed Computing, Distributed Database will be a plus
Hands-on experiences Hadoop, Spark, Kafka, and/or Presto will be a plus
Love to use and develop open-source technologies
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"Work on an award-winning, international technology!
Endless career opportunities
An innovative, friendly team of 300+
This role will be focused on the development of our existing ClaimLogik line of products as well as working on our new cloud-first, modern suite of applications.

Intelligent Thought, our technology business is scaling and shipping our software globally. Already profitable, part of a much larger group business, with investors such as Macquarie Capital and Envest – we are all set to deliver textbook disruption to the Insurance Industry. The growth of the platform, of our customer base, and the increasing industry demand have led to the need for this role to help the team scale.

Our Philosophy
Give each employee a sense of purpose and an environment for them to connect the importance of their role to delivering a service that matters to our customers.
Challenge the ‘why’ of traditional claims processes.
Keep it simple – do only what brings value and what matters to the customer
Enable employee decisions, empower our people
Responsibilities:
Create, extend and maintain ETL pipelines to form our data lake, data warehouse and analytics platform (currently using the Microsoft Azure set of tools and service)
Help define the optimal data pipeline architecture
Influence the tool selection, platform selection, data architecture and strategy which will transform the business to be truly data-driven
Understand, analyse and size user requirements
Work with different parts of the business to provide them with the insights they need to deliver the best results
Skills & experience:
Degree or qualification in computer science or related
Advanced knowledge of relational database, including query authoring and query optimisation (MS SQL Server and PostgreSQL).
Experience building and optimising ETL pipelines
Experience designing complex data models
Experience working with cloud platforms (Azure or AWS)
Efficient time management and organisational skills
High attention to detail and accuracy
Effective communication skills to build strong working relationships; both written and verbal
Proactive and results-driven
Why Claim Central?
Claim Central Consolidated is a global insurance industry leader across, claims management, insurance technology and data and analytics. Currently operating in the United States, Australia, South Africa, Italy and New Zealand, we have pioneered digitally connected claims management services across the globe. Claim Central is a disruptor and thought leader in the industry and we were recognised as the Australian Financial Review’s 8th Most Innovative Company in Australia in 2016. This business is in a period of unprecedented growth, transitioning our technology and services into multiple geographies at a rapid pace. Our unique culture is based on teamwork, collaboration, trust, respect and performance. We also offer many benefits apart from our exceptional team culture; including flexible work arrangements, and continued professional development.

Be a part of this journey in a career-defining role.",-1,Claim Central,Matraville,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer - AI/ML,-1,"Our client provides services to a major industry across the country. The business is still early in it's days of technology development and the environment is greenfields in nature (no pun intended), effectively working like a start-up.

Their data and analytics team have worked and built leading and bleeding-edge technologies in this space and what they have created so far may be game-changing. From a machine learning perspective, the progress they have made to the business has already seen proven success in changing the future of an industry that will have positive consequences for all those involved.

You will have previously worked in a technical capacity in the data and analytics space and have experience working with an organisation where machine learning has been implemented, not just a concept that the business talks about having or the technology team would love to have. The commercial experience you will have had in the ML field will be proven examples of where you have affected the way a business or industry used to perform, to the changes that have come about from this.

Technically, you will have extensive experience in the Microsoft space - Power BI, Azure etc and you will have previously mentored and coached junior members of the teams you have been part of.

This is a rare opportunity in Brisbane where the business has truly embraced and funded projects across the ML space and would be a great chance for those in the Data Development/Data Engineering field, who are looking to move into a Data Scientist role in the future.

Please send your application through if you would like to know more.",4.0,"Emanate Technology
4.0",Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Solution designer/ ETL Engineer & Data Modeller,-1,"We are looking for a Qualified and Experienced Solution Designer to join our client for a period of 6 months with a view to extend.
You will work closely with team members and your contribution will range across gathering and analyzing information, developing and documenting improved processes and work instructions and experienced DWH Lead with skills in requirement analysis, solution designing, developing, testing and supporting ETL solutions.
A hands-on solution designer, data modeler and ETL developer for Data Warehousing and ETL application transformation projects using Informatica PowerCenter.
Knowledge on AWS, S3, Redshift, Informatica BDM, and related technologies.
Experience working with IPython, PySparks, AuCuMo, Airflow, Jenkins, Github, Athena, JIRA, Rally, Spectrum, Glue, Flyway.
Good exposure on Oracle PL/SQL, aware of DBA activities, writing and performance tuning of complex SQL queries.
Contract length: 6 months
Job Types: Full-time, Contract
Salary: $650.00 – $800.00 per day
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,nducive,Melbourne,-1,-1,-1,-1,-1,-1,-1,-1
"Data Engineer, Wollongong NSW or Mount Waverley VIC",-1,"Company Description
BlueScope is a technically advanced supplier of steel and steel products in Australia. We are an inclusive organisation and every day we showcase our technology and expertise throughout the world.

Job Description
We are looking for two Data Engineers to join our IT team, based in Wollongong NSW or Mount Waverley VIC. Use your experience in analytics to unlock business value, enabling use of big data for insights and decision-making.
Reporting to the Data Product Owner for our Australian Steel Products (ASP) business, this position will support strategic goals related to data. This will see you:
Gather business and technical requirements with the view to deliver outcomes;
Develop and implement end-to-end data collection, consolidation, modelling and visualisation solutions;
Document metadata in a dictionary and catalogue;
Ensure consumers of such information understand its accuracy, timeliness, quality and sensitivity, so that it is used appropriately; and
Identify opportunities to enhance analytics.
What are the benefits?
Work in a supportive and collaborative team environment whilst we embark on a journey to transform the way our business uses data!
Our systems landscape is broad and diverse. You will be encouraged to think creatively to develop data solutions which solve real business problems.
Working in this role you will enjoy:
the chance to learn more about data science;
salaried remuneration with attractive superannuation options;
the opportunity to participate in a performance incentive scheme; and
access to further development and career opportunities with BlueScope.
Who are we looking for?
We welcome applications from professionals with experience in data analytics and/or programming. Supported by your knowledge of project delivery methods (e.g. Agile), you will demonstrate:
experience with data mining, wrangling, mapping and visualisation techniques (e.g. Azure Data Factory, Databricks and/or DevOps etc.);
well-developed ability in gathering business and technical requirements;
skills in developing and implementing collection, consolidation, modelling and visualisation solutions; and
a passion for sharing your knowledge and desire for ongoing professional development.

Qualifications

null

Additional Information
We're proud to have been named an Inclusive Employer for 2019–2020 by the Diversity Council of Australia. We believe that our people are our strength. Having a diverse and inclusive workplace enables us to improve our capability and ensure continued, sustainable success.
We know that workplace flexibility can mean something different to everyone. Under our B-Flex initiative all of our roles have some degree of flexibility. We encourage you to discuss your needs with us.
Applications close Sunday 25th October 2020.",3.3,"BlueScope
3.3",Wollongong,-1,201 to 500 Employees,-1,Company - Private,Construction,"Construction, Repair & Maintenance",$100 to $500 million (USD),-1
ETL Data Engineer,-1,"ETL Data Engineer

Join a team that’s changing how Australia lives, works, plays and grows
We want you to be the best version of you

Work with innovative teams and explore new technologies to help solve real-world problems.

A typical day as a Data Engineer

ETL / Big Data Engineering professionals will be responsible for guiding the full lifecycle of a Data solution, including:
Working in highly client-facing roles to contribute throughout the end-to-end delivery lifecycle of complex and large-scale digital solutions
Use case and business case development
Support existing and new applications utilizing in-depth technical and data knowledge. Troubleshooting complex issues and providing advisory services to improve the client’s data landscape
Help to streamline and simplify the clients’ complex data landscape by integrating different applications and data architectures
Implementation from requirements analysis, platform selection, digital architecture design, application design and development, testing, and deployment
Interstate travel may be required

Basic qualifications:
Bachelor’s degree
Experience across systems integration, information management, data management and architecture, and business analytics
Experience with being in a team focusing on large-scale, multi-release information centric projects
Experience with waterfall and agile delivery and run / application support functions
Part of a team working on End to end implementation of at least 1 big data project

Preferred Skills:
Hand on experience in Data warehousing using ETL tools such as DataStage, Autosys and TeraData
Hands on experience in ETL job development with multiple stages like sequential file, Transformer, Lookup, join, sort and Database stages.
Strong hand on skills in design, development and implementation of various data remediation, Data migration, data integration techniques.
Strong hand on data modelling experience.
Strong hands on experience in database performance tuning including complex query optimizations and physical database tuning using Teradata.
Understanding of architectural designs and strategy related to data migration, data cleansing, data quality and data consolidation.
Proven data analysis, requirement gathering and problem-solving skills
Exposure to Unix environment and shell scripting.
Experience in Banking and Financial services industry
Desirable: Knowledge of cloud computing infrastructure (e.g. Amazon Web Services EC2, Google Cloud, Microsoft Azure)
About Accenture

Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. We combine unmatched experience and specialized capabilities across more than 40 industries — powered by the world’s largest network of Advanced Technology and Intelligent Operations centers. With 513,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises. Visit us at www.accenture.com.

Accenture is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, marital, domestic or civil partnership status, sexual orientation, gender identity, or any other basis as protected by applicable law.

Vera Goga is the Recruiter managing this role. As the team experience high volumes of applications, we appreciate your patience to allow for a fair and timely process.",3.9,"Accenture
3.9",Sydney,-1,10000+ Employees,1989,Company - Public,Consulting,Business Services,$10+ billion (USD),-1
Student Engineer,-1,"The candidate will have the ability to:
Undertake onsite inspection to collect asset condition data based on the relevant engineering standards and technical guidelines;
Undertake desktop analysis to evaluate the condition and performance of the assets;
Provide the appropriate information, advice, engineering input and support services for the sustainable management of Council’s stormwater and transport networks.
Qualifications:
The successful candidate will be enrolled in a Bachelor of Engineering with a minimum of two years completed.
Position Number: 100678
Position Hours: Fixed term (3 months), hours will be negotiated with the successful candidate, maximum of 75 hours per fortnight.
Salary: Schedule A, Salary Point 4.0. $28.64 per hour ($55,853.45 per annum, pro-rata) in accordance with Glenorchy City Council’s Enterprise Agreement 2016
Please note that all successful applicants will be required to provide a current National Police Check prior to commencement of employment.
For further information on this position, contact Patrick Marshall, Senior Civil Engineer on (03) 6216 6800.
How to apply: Applications for this position must be lodged on this submission site or on the Glenorchy City Council website www.gcc.tas.gov.au - Careers page.
To be considered for this role, all applicants must address the key selection criteria in the and provide a current resume. A copy of the position description can be found by clicking the below hyperlink or on the Glenorchy City Council website.
Applications close at 8pm on Sunday, 1st November 2020
- Student Engineer",4.0,"Glenorchy City Council
4.0",Glenorchy,-1,501 to 1000 Employees,-1,Government,-1,-1,Less than $1 million (USD),-1
Data Engineer involving DevOps,-1,"Data Engineer involving DevOps
Axiom Technologies is an Australia based entity with the history of providing Managed IT solutions to medium to large scale enterprises globally. Please visit our website for more information about what we do at www.axiomtechnologies.com
Axiom Technologies is an Equal Opportunity Employer and encourage applicants from all backgrounds and gender to apply, including, Aboriginal and Torres Strait Islander candidates
Job Requirements:
8+ years IT experience, with at least 5+ years of “Data Engineer/Deveoper” focused titles/roles,
Data Tools: Hands on experience with Apache Beam.
Testing: Hands on experience with automated testing activities/outcomes
DevOps: Experience with the processes involving Microservices facilities for artifacts developed
Platform/OS: Mid-range/Unix
Languages: Unix (Shell) Scripting/commands, SQL, Python
File formats: Text, CSV, Parquet, JSON, XML
Scheduling: Jenkins, Airflow
Auto Scripting: Designing/creation of scripts for repetitive activity. E.g. Unix scripting/SQL
Big data: Exposure to Data Lake Concepts, Hive (Schema), HDFS
Source Control tools: GIT
Delivery Models: Agile, Scrum
Ingestion Design: Create/assess Source/Target data mapping designs
Frameworks: Development and delivery frameworks
Activity Reporting/Repository: Jira, Confluence.
Quality: Accuracy and attention to detail
Industry: Financial Services/Banking
Solutions: Define solutions from High level to detail design to address automating ingestion activity. Facilitate/confirm requirements from product owners, business team members and technical associates,
Process Automation: Automating processes in file management, testing data in files, analysis and design, configuration management.
Script Automation: Ability to design/create scripts to automate/improve data copy/migration/ETL for any repetitive activity.
Languages: Java, Python
Scheduling: Control-M
Databases: Relational. E.g. POSTGRESS, Oracle – as a ETL developer
File Formats: Mainframe – experience with referencing its data formats/copybooks
Big data: Experience referencing/using Hive (Schema) to access data in HDFS
Metadata management tools: MDM, EDC and Axon
Performance: Assess, recommend, improve mappings, SQL queries, Batch feeds
Automation Tools: Other tools that may add value to an automation program and generally support development. E.g. API, REST, JDBC, Webservices, Message Queues/Load balancer,
Cloud: Experience with processing of data files to be ingested/stored in the Cloud, preferably with AWS.
Prod Support: Experience in a production support role performing root cause / impact analysis – under time constraints
Experience in a similar role
8+ Years
What next?
If you are looking for that next challenge in your career and wish to apply for this role, please forward your resume to careers.au@axiomtechnologies.com",2.0,"Axiom Technologies
2.0",Melbourne,-1,1 to 50 Employees,-1,Company - Private,Industrial Manufacturing,Manufacturing,Less than $1 million (USD),-1
Data Engineer,-1,"About the Role
We are on an exciting digital journey so it’s a great time to join ME! We are seeking a Junior Data Engineer who enjoys rolling up their sleeves, learning and growing. As part of our Enterprise Data Team, you will ensure fit for purpose data warehouse solutions are built for use across the bank and by utilising best practise ETL standards, whilst ensuring the data is trusted by our BI developers and key business consumers. Oh, and you’ll get to work on Microsoft technology stack too!
You will be involved with investigating data issues, keeping data feeds flowing and collaborating with different projects across the bank to deliver quality data solutions. How important does that sound? What’s even more important is this role contributes directly to our overall business strategy through the provision of data to enable analytics & reporting, as well as supporting business and decision system processes.

About You
You’re naturally a highly motivated and energetic person who thrives in a dynamic, ever-changing collaborative team environment. Ideally you have previous experience as an ETL developer, Data Engineer or a BI developer, and if you have a degree in computer science or similar it would really put you ahead of the rest.

With your knowledge of SQL coding, data modelling, understanding of data warehouse concepts, plus experience of working on complex ETL solutions, you’re ready to expand your horizons and launch your career into the world of IT at ME.

About ME
We’re not like other banks.
ME was created by the industry super funds to be different from the pack – with a core purpose to help all Australians get ahead financially – no conditions, asterisks or exceptions. And we know that looking after customers starts with taking care of our people.
We believe everyone deserves the same opportunities in life, regardless of gender or identity, sexuality, ethnicity, religion or disability ‒ with internal affinity groups.
Perk ME up
Once you get your feet in the door at ME, we’ll put them both in your very own ME-branded Converse shoes. You’ll also get the following financial, health and fun perks when you join the team:
4U Extras portal (discounts and cashback on 100s of items including cinemas, shopping and gym memberships
10% Myki discount
Purchased Leave programme
Internal wellness programme (Mindfully ME)
Professional education through LinkedIn Learning
Novated Leasing
Professional membership reimbursements
Health checks
Financial education (To help you manage your money smarter)
LGBTIQ+ and Women at ME affinity groups

I want those Converse shoes (and the role)
Can’t see a closing date on the advert? That’s because we’re pretty efficient here at ME and we may start looking at applications sooner rather than later, so if this role sounds like your jam, be sure to apply by submitting your resume today.

Should an applicant be the preferred candidate, background checks (including police checks, reference checks, ASIC banned and disqualified persons and bankruptcy checks) will be completed prior to the candidate's employment being confirmed. The outcomes of the background checks do not automatically bar candidates; however will be assessed against the inherent requirements of the job.
Back Share
Apply Now",3.0,"ME Bank
3.0",Melbourne,-1,501 to 1000 Employees,-1,Company - Private,Banks & Credit Unions,Finance,$100 to $500 million (USD),-1
Software Engineer - Machine Learning/Data Science,-1,"Zendesk is looking for a Software Engineer - Machine Learning/Data Science for a full time position in our Melbourne office.
As part of our engineering team, you will work at a scale where the challenges start to get seriously interesting. Our global engineering team is widely dispersed over the world, with people across nearly every continent. You will get a chance to do cool things with a diverse bunch of people while working in the Melbourne office that is home to Zendesk’s first machine learning (ML) research team.
The Data Science Team, together with Data Engineering, have built Satisfaction Prediction, Answer Bot and Content Cues — products that use Machine Learning (ML) and Artificial Intelligence (AI) to help our customers work more efficiently.
What you get to do every day:
We’re currently looking for someone to join our team as we research, develop, and productionise Machine Learning and Deep Learning models. In addition to frequenting Melbourne’s finest purveyors of coffee, ramen, and bulgogi, you may find yourself:
Building machine learning models including neural networks in TensorFlow
Writing and deploying production-grade Python
Querying and constructing datasets in AWS Athena, Spark
Evaluating and responding to real-world model performance
Scaling your ML to millions of predictions per day
Presenting your work to a broader audience
Watching your algorithm help Zendesk’s end-users
What you'll bring to the role:
A strong foundation in a quantitative discipline (e.g. machine learning, statistics, bio/eco/etc-informatics, econometrics, etc) is critical for this position. While experience in deep learning and natural language processing would be beneficial, your best qualities are:
dedication to continuous learning
collaborative work attitude
strong communication skills
You should also be comfortable with at least one programming language, such as Python, R or Scala.
Application Deadline: 18/11/2020
Job Types: Full-time, Permanent
Salary: $85,000.00 – $110,000.00 per year
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Temporarily due to COVID-19",4.5,"Zendesk
4.5",Melbourne,-1,1001 to 5000 Employees,2007,Company - Public,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),-1
Software Engineer (Machine Learning),-1,"About the Role
AdelaideMRI is building a medical reporting tool. We require an engineer to work primarily on machine learning projects to improve reporting speed and report comprehensiveness.
You will perform data analysis of medical report datasets and image datasets to infer sentence recommendations, image classifications, or other actionable results for the doctors.
Skills and Experience
Background in machine learning or image processing
Qualifications in Computer Science, Software Development or Engineering or equivalent experience
Bonus points for Python
No prior medical knowledge is required.
This position offers flexible hours and work arrangements.
Job Type: Full-time
Experience:
Software Engineering: 1 year (Preferred)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Yes",-1,Adelaide MRI,Australia,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Hey there, we’re PEXA!

We started as an idea: to deliver a single, national e-Conveyancing solution. We collaborated with the industry to create a national electronic lodgement and settlement platform: PEXA. From our humble beginnings, we’ve now grown to more than 320 employees across 5 different states. We’re still expanding at a rapid rate and constantly challenging ourselves to create great experiences for our members as they transition to fully digital conveyancing.

Why become a PEXArian?

Great question! Being a PEXArian is so much more than just a job. We are passionate, motivated & unashamedly enthusiastic at PEXA - we love what we do and we’re proud to admit it! Creating brilliant member experiences wouldn’t be possible if we didn’t also strive to create an amazing employee experience. Alongside our members, our employees are at the heart of everything we do.
Here’s a snapshot of what your life at PEXA could look like:

Your growth:
We encourage you to hit your personal and professional Learning & Development goals with our tailored programs and tools.

Your wellness:
We care about your holistic well being - a fully stocked kitchen, four wellness days, a $250 wellness subsidy as well as lunch and learn sessions to support your financial well being.

Your work/life blend:
We know that work is just one aspect of your life, we want to help you create your ideal work/life blend, rather than squeezing in life around work.

Your family:
With a range of benefits aimed at supporting your family including access to a subsidised school holiday program, extended parental leave and flexi-time to support your return to work, superannuation payments for unpaid parental leave for primary carers and a childcare allowance for pre-primary aged children, when we say, ‘welcome to the family’, we really mean it!
The impact you'd drive:
The successful candidate will be responsible for developing, and maintaining infrastructure to support the delivery of new and existing products. They will also be contributing to establish the rules and frameworks for obtaining the required approvals for new products.
On day one we’d love you to have:
Experience with Python, Spark
Event streaming/sourcing with Kafka or AWS Kinesis
Experience with data structures, formats and data security best practices
AWS experience (e.g CloudFormation, S3, ECS, Lambda, SQS, IAM, KMS, DynamoDB, Glue, Athena)
Query construction and optimisation (e.g. SQL, Elasticsearch, Splunk, DynamoDB)
Git, version control practices, and continuous integration/delivery servers
PyUnit and unit testing frameworks
Production release cycles and maintenance
Collaborating with technical and non-technical teams
Even better:
Agile methodology/delivery
GraphQL
Modern frontend technology (e.g. ReactJS, TypeScript)
Machine learning frameworks and tools (e.g. TensorFlow, PyTorch)
OAuth 2, SAML 2, JWT
Data visualisation and exploration tools (e.g. Jupyter notebooks, Tableau)
AWS SageMaker
Sounds like you?
If this role sounds like you, apply today to have your application reviewed ASAP!",3.9,"Property Exchange Australia Limited
3.9",Melbourne,-1,201 to 500 Employees,2010,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Ongoing position
Full time
Based in Sydney, NSW
Who we are
Australian Red Cross is part of the world’s largest humanitarian organisation. Our aim is to improve the lives of the most vulnerable people in Australia and across our region.
About the role
The Data Engineer role will sit within the Data and Integration Squad in IT and will own (design, implement and support) the AWS Big Data technologies such as the Data Lake and Data Warehouse and support the organisation in growing the data analytics capabilities at Red Cross. In addition to this, the data engineer role will also administer the Power BI tool and support the implementation of the data mastering capability.
What you will bring
Experience building and optimizing data pipelines, architectures and data sets.
Experience in dimensional modelling and building data vaults
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with structured, semi-structured and unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Why work for us?
Work for purpose and know that your work assists Red Cross support and empower people and communities in times of vulnerability.
Generous salary packaging options available that can increase your take home pay.
Further information
To find out more about this opportunity please see the position description below or contact Sharath Kumar Gurram on 02 8651 8839.
Position Description: Position Description - Data Engineer .pdf
Applications for this position will close at 11:55pm Thursday, 5 November 2020.",4.1,"Australian Red Cross
4.1",New South Wales,-1,1001 to 5000 Employees,-1,Nonprofit Organization,Industrial Manufacturing,Manufacturing,$500 million to $1 billion (USD),-1
Junior Fullstack Data Engineer (Python and React),-1,"Formbay is the leading Renewable Energy Certificate Trading company in Sydney. We provide Digital Workflow and Compliance solutions in the renewable energy industry and document processing.
Thanks to our meteoric growth and our commitment to be the best at all we do, we've identified the need to bring on board a new Junior Fullstack Data Engineer.
Reporting to our Principal Machine Learning Engineer, you will help build Machine Learning pipelines for our existing Digital Workflow and Compliance solutions to automate fraud detection and document processing over terabytes of photographic and documentary data – including documents, photos, GPS data and aerial/satellite photography.
Our stack is based on Python, JavaScript, Dask, Tensorflow, CUDA, Nix/NixOS, AWS, Docker, PostgreSQL and more – familiarity with these applications will give you a leg-up on the competition.
Our ideal candidate will have the following competencies:
SQL
Python
JavaScript/TypeScript
Our candidate must also be comfortable working with Linux.
Located a stone's throw away from the Queen Victoria Building in Sydney's bustling CBD, we are centrally-located with easy access to public transportation, bars, cafes and fine dining.
Formbay will provide flexible working hours, a generous remuneration package and the opportunity to work on a world-first software solution are what we can offer you. Free, twice-weekly gym sessions and really, really good coffee are also available.
No hiring/recruitment agencies need apply.",5.0,"Formbay
5.0",Sydney,-1,1 to 50 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is an experienced and qualified Data Engineer to join our IT team based in Birtinya.
Key Responsibilities:
Create and maintain data pipelines and or ETL scripts
Create and maintain data integration including API and Batch interfaces
Performed detailed data analysis
Create and maintain corporate data models
Create and maintain data visualization using Qlik.Sense , PowerBI or Simliar Toolset
Experience in defining, building and maintaining data virtualization and/or star schema data warehouses
Maintain, tune and optimise database, integration and visualisation toolsets
ABOUT YOU:
To succeed in this role, you’ll need to bring the following experience and skills:
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Excellent communication skills both oral and written, with an ability to bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking
Experience with data analysis and modelling will be beneficial

How to Apply
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kawana Waters,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Graduate Data Science / Engineer,-1,"The NRMA is an organisation looking to the future, and right now, we are on the lookout for people who can help us reach our goal: to continue to shape the way Australians move, for the next 100 years and beyond. www.mynrma.com.au.
Everyone new to the team, along with our current staff, will temporarily work from home until it is safe to return to our offices. All interviewing and on boarding will be done virtually due to COVID-19.


Your opportunity
As Graduate Data Scientist or Engineer you will be part of the Data Engineering team delivering cloud data transition program for business initiatives and supporting the entire data platform build.
Your key responsibilities will be to:
Implementing Concepts of Data Warehousing, Data Mart creations within Cloud
Use of SQL for data analysis and insights
Building AI/Machine Learning prototype for implementing and supporting existing algorithms
Data Analytical reports build, using different tool sets


Requirements for Success:
Relevant Degree - Computer Science, Computer Engineering, Software Engineering, Data Science
Excellent SQL skills and demonstrated working knowledge in Python
Demonstrated understanding in data structure and algorithms.
Knowledge and concept of data warehousing methodologies
Any reporting tools experience Tableau or Oracle Analytics Cloud, Looker is desirable
Exposure to Google/AWS/Azure/Oracle any cloud based platforms is desirable
Good communication and interpersonal skills

If you have the required skills and the passion to join our high performing team, please apply today.

Employee Benefits
To ensure our employees feel valued, empowered and celebrated we provide a range of employee benefits including:
50% discount on all NRMA insurances
Free Roadside Assistance
12 weeks paid primary and 4 weeks paid secondary parental leave
Free NRMA Blue Membership
At the NRMA Group, we are People Moving People and diversity and inclusion are part of our DNA. Together, we continue to build an inclusive culture that encourages, supports and celebrates the diverse voices of our employees. It fuels our innovation, promotes flexible ways of working and connects us closer to our members and the communities we serve.",2.5,"NRMA Motoring & Services
2.5",Sydney,-1,501 to 1000 Employees,-1,Nonprofit Organization,Casual Restaurants,"Restaurants, Bars & Food Services",$500 million to $1 billion (USD),-1
Data Centre Engineer,-1,"We are a leading world group that provides low-carbon energy and services. To tackle the climate emergency facing us all, our aim is to become the world leader in the zero-carbon energy transition ""as a service"" for our clients – particular for companies and regional authorities. We use our expertise in our key business areas (renewables, gas, services) to provide competitive and bespoke solutions.
The Data Centre Engineer will be employed as part of a 24/7 ongoing shift to coordinate and monitor third party service providers, maintain the data centre facilities and infrastructure plans, coordinate the implementation of customer requests within the data centre and monitor systems, all in accordance with the Contract KPIs and SLAs.
Coordinate and monitor third party service providers for regular maintenance & testing, service faults & call outs, ensuring works are performed in accordance with Contract SLAs
Monitor and maintain the data centre facilities and infrastructure plans and documentation, including electrical, mechanical, hydraulics, fire and BMS/EMS systems
Coordinate the implementation of internal and external customer requests within the data centre
Perform scheduled plant checks and minor maintenance works
Ensure all Work Order requests are raised and closed in a timely manner
Conduct inductions for staff, vendors and contractors
Ensure all work permits for vendor works are raised and closed
Perform inventory checks on all equipment and critical spares

Qualifications
The selected candidate must be able to demonstrate:
Electrical or HVAC background, or Graduate Electrical or Mechanical Engineer
Passionate about quality work and career minded looking for a new challenge
Can commit to a day and night shift roster (2 days of day shift, then 2 days of night shift, 4 days off)
Ideally able to commence asap
As part of carrying out the duties of this role, it is mandatory to hold Australian Citizenship.

If you are interested and meet the selection criteria apply with an up-to-date resume via the apply instructions on this website.

ENGIE Services is an EEO employer, where all applicants are treated with fairness and respect and have equal access to the opportunities available.

We will not be engaging in the services of a recruitment agency to fill this vacancy and therefore request all interested candidates apply directly to this advertisement.

Job
: Maintenance
Primary Location
: Oceania-Australia-New South Wales-Erskine Park
Organization
: ENGIE Services Australia and New Zealand
Schedule
: Full-time
Nature of Responsibility
: Senior operational / administrative role
Job Posting
: Sep 11, 2020, 6:29:59 AM",3.7,"ENGIE Services Australia & New Zealand
3.7",Sydney,-1,5001 to 10000 Employees,1995,Company - Public,Energy,"Oil, Gas, Energy & Utilities",$2 to $5 billion (USD),-1
Senior Data Engineer,-1,"Senior Data Engineer, Temporary, SYDNEY - McKell

Job Title: Senior Data Engineer

Salary: SNSW Grade 9/10 - The package includes base salary range of $111,806 to $134,667, plus employer's contribution to superannuation and annual leave loading.

Location: Head Office – Haymarket

Employment Status: Temporary through till 30th June 2021


About Service NSW:

Service NSW is making it easier for people and businesses across NSW to access government services. The role designs, builds and analyses complex data from multiple sources to identify revenue, process and business improvement opportunities; providing new information and insights to the business to inform planning, continuous improvement and performance.

About the Role

We are currently seeking to appoint a Senior Data Engineer to deliver expert advice and services in the design of a Single View of Customer and data-related services to support the achievement of business outcomes and strategic goals. We support flexible working practices with staff working remotely during this time.

In this role you will:

Design, build and support a modern data platform based in AWS and vendor technologies.
Provide expertise on data modelling for Graph data model and Customer Data Platform (CDP).
Create data pipelines, load, transformation and reporting workloads in AWS.
Work with the latest data engineering technologies like Apache Kafka, AWS Kinesis, AWS Neptune, AWS Glue and AWS Athena.
Contribute to the design and decision-making of the right tool or platform for the job according to requirements.
Provide expert advice and guidance on data quality and data engineering best practices.
Support a “bigger than you can imagine” scale of data in production environments.
Design, develop and support a metrics-driven reporting solution and a meaningful business intelligence platform.
Document the solution design and support procedures of solutions.
Produce reports, visualisations and recommendations to answer complex business problems that are presented in the most appropriate format to ensure clarity for target audience.
Analyse and define new process improvement opportunities to support continuous improvement and business outcomes; providing advice to stakeholders, on ways to improve the efficiency and reliability of data products and services.
Be very responsive to the information needs of the business by corresponding to customers in a timely manner and provide support/solutions to issues raised.
Troubleshoot and perform root cause analysis on production issues. Identify and implement long term solutions to problems. Perform scheduled maintenance, release deployment and production support activities after business hours, from time to time.
Liaise with internal and external customers to discuss and gather requirements, solutions etc. and maintain a good working relationship with the stakeholders.


Skills and Experience Required:

Solid experience with workflow technologies designing and building data pipelines, data models and data stores.
Experience working within and an understanding of Amazon AWS ecosystem, including security and performance tuning.
Hands on experience working with different types of databases, with focus on Graph and NoSQL databases.
Experience with data streaming required. Having used Kafka and related technologies is an added advantage.
Sound knowledge and experience working with batch processing, data extraction and API integration.
Hands on experience with at least one programming language: Java, Python or scripting.
Demonstrated experience working in an Agile based, fast paced, complex environment within cross-functional teams.
Experience developing systematised insights, data analytics and reporting solutions is an added advantage.
Experience with interactive visualisation of data insights is an added advantage.


Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Salary Grade 9/10, with the base salary for this role starting at 111,806 base plus superannuation

Closing Date: 6th November at 9:59am - applications will be reviewed on a rolling basis, applications may close early or extend

Please apply online, direct applications submitted via email will not be considered.

The Department of Customer Service is proud to be an EEO Employer who are fully focused on equality and believe deeply in diversity of all identities making us different and a true reflection of our NSW customers. As an inclusive workplace, we support various employee resource groups, practice flexible work and workplace adjustment.

If you do require an adjustment during the recruitment process, please notify us on your application form.",3.2,"Service NSW
3.2",Sydney,-1,501 to 1000 Employees,2012,Government,State & Regional Agencies,Government,Unknown / Non-Applicable,-1
Data Engineer - Entry / Mid Level,-1,"Work with a great team on interesting projects customers
Gain more experience in AWS, Data, DevOps cloud operations
Got a working knowledge of AWS? We will teach you the cool stuff!

Itoc is seeking an up and coming Data Engineer to join our growing Data Team in Sydney.

This is an exciting role working with databases, data lakes, data warehouses, data transformation (Python SQL) and enabling AI/ML.

You will be implementing foundational, robust and production ready data platforms to enable business data-discovery, self-service, AI/ML functions across a range of client types and industries, allowing them to do more with their data.

You'll be responsible for:

Deploying data repositories such as lakes and warehouses.
Contribute to our growing portfolio of data solutions.
Ongoing optimisation and management of data platforms.
Development of transformational logic for data pipelines
Data evangelism. We want to show our clients how to follow the best practices for data.

Desired Skills and Experience

To take up the challenge, you will have a depth of skills and experience including:

1-2+ yrs of focused data experience working with SQL and/or NoSQL solutions
A solid education in Software Engineering or equivalent industry experience.
Anything Data focused preferred.
Ability to analyse business scenarios and associated data landscape to derive potential opportunities.
Strong foundation in Python and SQL
Working knowledge of APIs
Principle knowledge of the different relational database platforms and modern data storage techniques
Knowledge of the different aspects of data environments
Collect, store, process, verify consume
Experience with version management systems (such as GIT)
Working knowledge of AWS or another cloud platform - we will teach you the cool stuff.
Great communication skills, an ability to work closely with customers, developers and engineers and the confidence to present ideas in open forums.
Relevant tertiary qualifications and/or industry certifications.
Great communication skills, an ability to work closely with clients, developers and engineers and the confidence to present ideas in open forums.

While not required, a background in consulting and professional services is highly desirable.

Itoc Description

This is an exciting and challenging career opportunity to join the growing Sydney-based Data Team of a leading cloud solution provider where you will be given support to reach your long term career goals. You will be part of a team of cloud experts and will work in an environment of continuous improvement and learning delivering innovative cloud solutions across SaaS, online business and enterprise business.

On offer is a chance to join a team with a great working environment, in an organisation that values its employees and sees the value in ensuring they are engaged. Our team are clearly passionate about what they do, that's why we won the following awards:

Customer Obsession Partner of the Year 2015: ANZ Region
Customer Obsession Leadership Partner 2015: re:Invent

As an employer of choice Itoc offers competitive remuneration, training and development programs and a great working environment. We value a healthy work life balance.

The Perks

MacBook or Dell
Continuous internal learning that will provide training and career development opportunities
Working with a collaborative, social team and leveling-up your skills faster than you will anywhere else.
Quarterly social events

Itoc

Culture and smarts are important to us. Bring your secret sauce. This is no ordinary environment, you will work along some of the Cloud’s best. All engineers at Itoc must gain at least five AWS certifications. We work hard but we have fun.

Please note you must have full working rights in Australia and be available on-shore for face to face interviews.

No recruiters please.",4.0,"Itoc
4.0",Sydney,-1,1 to 50 Employees,2013,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Date: 01-Oct-2020

Location:
Melbourne, VIC, AU

Department:Description:
Technology discounts - from Apple HP Lenovo to Windows
Flexible work arrangements - work in a way that suits you best
Salary packaging - to suit your personal and financial circumstances

Do you want to work for one of the fastest growing data teams in Australia? Do you want to work on multiple data platforms and provide new solution offerings by leveraging cloud and big data technologies?

About the team

Big data information and analytics. Three words that spark apprehension in most businesses. But our team of experts are constantly curious and excited about combining our wonderful array of technological expertise to transform data into our clients most valuable assets making their work smarter. Our data consultants are supported with resources training and tools they need to excel at their work but also the freedom and power to create their own paths forward to make a difference.

As a Senior Consultant in Big Data you will work closely with the team and stakeholders to build and deliver a Cloud based vision for a next generation Big Data analytics platform with strong focus on data quality data security and deliver the systems that process huge volumes of data.

What will you typical day look like?

You will play a pivotal role in - Designing and producing high performing and stable applications to perform complex processing of massive volumes of data in a new cloud based architecture; Building real-time data processing applications which are integrated with business systems to enable value from analytic models to drive rapid decision making; Contributing to system architecture design for a data platform (including cloud-based structures both on and off premises data warehouse components and data lakes); this could cover a range of technologies various countries/locations and lines of business; Support data strategy or technology strategy definition programs including technology stack definition and target operating model requirements

Enough about us lets talk about you:
You are someone with:
Use of traditional data analytics tools and techniques (e.g. MSSQL Oracle MySQL) and ETL software (e.g. SSIS Informatica CloverETL)
Working in large scale cloud data solutions using platforms such as AWS or Azure or GCP will be a bonus.
Experience in scripting or programming (e.g. Python Java Scala C#)
Excellent verbal and written communication skills to adapt to technical and non-technical audiences.
Educated to degree level (or have equivalent experience)
Why Deloitte?

At Deloitte we create positively differentiated work experiences that enable our people to feel valued and achieve their full potential. We value difference and embrace people with diverse backgrounds and thinking styles. Knowing that people work best in different ways we are happy to discuss alternative arrangements if the working pattern you are looking for is not specifically indicated.",3.8,"Deloitte
3.8",Melbourne,-1,10000+ Employees,1850,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Engineer,-1,"Opportunity to grow the team
Period of growth
Intuitive app
S2M are working with a FinTech who have created a unique financial product to help thousands of people better manage their finance, and is currently scaling the company to the next level!

They are looking for a Data Engineer to join, and looking for someone who wants to be hands on, with opportunity to grow the team in future.

Role:

Looking for people with strong AWS experience. You will need passion for data and a cloud, through which you will help a rapidly scaling Australian FinTech establish their data infrastructure from the ground up.
5+ years’ experience as a data engineer within the data and analytics domain
A python 3.X aficionado who is very comfortable creating and orchestrating AWS data pipelines with nothing but code
Strong project delivery toolset experience in open source data integration tools
Experience with processing large volumes of complex data including visualisation and insights generation
Ability to define and develop data integration patterns and pipelines
Ability to assess complexity of data (volume, structure, relationship etc.)
Hands on experience working with different databases (RDBMS, NoSQL, Blob storage etc)
Hands on technical expertise setting up DevOps automation
Hands on experience working technologies/platform e.g. AWS, Dockers, Containers
Experience building data profiling and data cleansing frameworks
Technical reconciliation and reporting
Knowledge and experience in end-to-end project delivery, either traditional SDLC or agile delivery methodologies (or hybrid approaches)
Exceptional communication, documentation and presentation skills
If this sounds like you, get in touch today - kate.gabb@s2m.com.au
3167410agsdf",3.1,"S2M
3.1",Sydney,-1,Unknown,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Analysts,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is seeking experienced and qualified Data Analysts to join our IT team based in our corporate office in Birtinya (Sunshine Coast) or at our meat processing facility in Kilcoy.
Key Responsibilities:
A mixture of data analysis and commercial skills to source, blend and analyse data to gain insight and answer key commercial questions
Working with strategic leaders to define and model Key Performance Indicators, and assist in building forecasting models
Working closely with data engineers and BI developers to specify data pipelines and report visualisation
Drive the creation and implementation of data quality business rule including data definition, governance and quality assurance
About You:
To succeed in this role, you’ll need to bring the following experience and skills:
Proven ability to derive insight and knowledge from data using commercial expertise is a strong requirement
Strong SQL and Excel skills are essential, along with strong data analysis and commercial insights
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Effective people communicator - engage with stakeholders on reporting needs, interpret requirements into visual solutions and train/deliver the outputs to the stakeholders getting signoff of acceptance
Bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking

How to Apply:
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kilcoy,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Network Data Engineer,-1,"Min 6+ years of experience in the relevant technologies
Australian Driving License for visiting remote locations / Data Centre for day to day technical work.
Managing Network devices (switches, routers, firewalls, load balancer, and wireless technology)
Performing MACD activities for all network devices.
Supporting BAU operation activities.
Proficient in performing in-depth details of technical troubleshooting, cause and provide recommendation to the client for incidents causing extended network outage to client’s critical locations.
Provide exceptional network services in terms of network support, break-fix, design and consulting, new projects, implementation.
Configure, administer, and document firewall infrastructure.
Manage the firewall deployment, rules migrations, and firewall administration.
Supporting Cloud Migration Activities from traditional to AWS/Azure.
Setting up VPN tunnel with Cloud and 3rd Party network devices.
Integrating and upgrading existing ISP bandwidth with support from ISP Vendor.
Setting up VPN profiles for Users.
Installing hot fix and patches to mitigate the security devices from attacks and bugs.
Reviewing and fine tuning the firewall rules and NAT rules.
Documentation and change control.
Mentoring, Motivating and Guiding support teams
Technical skills:
o LAN
o Wireless
o WAN
o MPLS
o Routing protocols (OSPF,BGP)
o DMVPN
o Azure cloud Networking
o Network Security
Fortigate Manager / Analyzer / Firewall
Cisco ASA
Firepower FTD
Cisco Any connect
Site to Site VPN
F5 Load Balancing and Scripting iRule
Job Types: Full-time, Contract
Schedule:
8 hour shift
Experience:
Scripting: 5 years (Required)
Data Network: 5 years (Required)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Required)",3.6,"Total IT Global
3.6",Sydney,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Engineer - Processing & Analysis,-1,"Job Description:
Design,build and maintain the ingestion system to support various types of data(e.g. User behavior, RDS, NoSQL db and others) to be ingested to the data warehouse more timely and accurately
Translate data requirements into scalable technical data service with low latency and high concurrency
Design,build and maintain the batch or real time data pipeline in production using Hadoop big data technology
Analyze and improve efficiency, scalability, and stability of the system
Define and manage SLA,Data quality for all data sets in allocated areas of ownership
Requirements:
Minimum B.S. degree in Computer Science or a related technical field
2+ years of working experience in programming languages,such as Java,Scala,Python
Familiar with Hadoop, Spark and Flink data processing, experience of TB data processing experience is a plus
Familiar designing and operating of a robust distributed system is a plus
Understand data mining or machine learning
Excited to work intimately with data
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"SYNOPSIS:
Lead Data Engineer
Applications close Sunday 8 November 2020
Ongoing
Contact name: Shyni Sasikala
Phone: (02) 6249 9048
Email: Shyni.Sasikala@ga.gov.au

The Data Policy and Informatics section within the Digital Science and Information branch creates, implements, and promotes policies, platforms and tools that improve and support the quality, discoverability, accessibility, and general usability of Geoscience Australia’s science data products. The section consults with internal and external research, government and industry partners to establish collaborative data frameworks, architectures and models within Geoscience Australia (GA) and across broader national and international communities of practice. The section innovates, builds and maintains tools, systems, processes and governance that enable digital data management, cataloguing and open data delivery.
GA makes accessible a wide range of geoscientific and spatial data to a wide variety of stakeholders in multiple formats, and in recent years GA's data volumes have grown exponentially. GA is focussed on making its data and metadata assets accessible so that they can be used in machine to machine interactions for data analytics and other applications in environments that range from High Performance Computing (HPC), through high-end cloud servers, to mobile devices.
We currently have two opportunities for Lead Data Engineers in the Informatics team. The Lead Data Engineer is responsible for innovating and exploring new technologies that will advance GA’s science goals and maximise the uptake and use of GA’s science data. The Lead Data Engineer reports to the team’s Assistant Director but also works closely with other developers, data scientists and engineers within the Digital Science and Innovation (DiSI) branch, as well as diverse stakeholders both within and external to GA.",3.9,"Geoscience Australia
3.9",Canberra,-1,501 to 1000 Employees,2001,Government,Federal Agencies,Government,$100 to $500 million (USD),-1
Data Engineer,-1,"The Seven Network is part of Seven West Media, one of Australia’s most prominent media companies, with a market leading presence in content across broadcast television, online and in print. Comprising some of Australia’s most renowned media brands, SWM includes not just Seven Network and its affiliate channels 7two, 7mate, 7flix and BVOD offering 7plus, but also 7NEWS.com.au, The West Australian, The Sunday Times and more.
At Seven we are here to bring all Australians closer to the moments that move us - we’re first on the scene, with our finger on the pulse, on demand, in the moment. Together, we’re responsible for creating and sustaining authentic Australian engagement.
A new and exciting opportunity has opened for a Data Engineer to join the Audience Intelligence team. Based in Sydney and reporting to the Head of Data Enablement, you’ll be responsible for:
Implementation of end to end data solutions to support Data Strategy for the SWM group.
Work closely with the Data Solution Designers to develop and maintain scalable data pipelines and build out new file and API based integrations to address requirements from the various business stakeholders.
Collaborates with engineering, analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organisation.
Work on Data Preparation for analytics and data scientist team members and assist them from an engineering perspective in building and optimising the models including building the automation of the end to end workflows
Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.
Perform data analysis required to troubleshoot data related issues and assist in the resolution of production data issues.
Work effectively with vendors for successful delivery of projects and acceptance of the solution
Work on Delivery projects using Agile Software Development methodologies
We are looking for someone who has:
Bachelor's degree in computer science, computer engineering or other technical discipline is essential
Proven experience working as a digital analytics specialist
Extensive experience with digital analytics implementation (e.g. Google Analytics, Snowplow, Adobe Analytics) and BI processes and visualisation platforms
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience in ETL and building and optimizing ‘big data’ pipelines and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Experience with big data tools: Hadoop, Spark, etc., AWS cloud services: EC2, S3, Lambda and familiar with version control systems: Git
Strong coding skills with knowledge of Unix/Linux and scripting languages such as Unix Shell scripting, Python desirable
Experience supporting and working with cross-functional teams in a fast-paced environment.
Ability to multi-task and problem solve with changing demands and priorities
Ability to work under pressure to meet deadlines and detail oriented
Your success is our success: we will provide you with opportunities for you to keep learning and growing, enabling you to challenge and develop yourself. In return, we offer a benefits program that has something in it for everyone.
Seven West Media is an equal opportunity employer and we are committed to creating a diverse and inclusive workplace.
Recruitment Agencies: Seven West Media does not accept any unsolicited agency resumes and will not be responsible for any fees related to unsolicited resumes.
Advertised: 19 Oct 2020 12:00 AM AUS Eastern Daylight Time
Applications close:

Back to search results",2.5,"Seven West Media
2.5",Sydney,-1,5001 to 10000 Employees,1956,Company - Public,TV Broadcast & Cable Networks,Media,Unknown / Non-Applicable,-1
BICON Rules Engineer,-1,"APS 5 - $73,299 - $80,410 per annum plus superannuation
Biosecurity Plant Division
Canberra, ACT
Play an active role in managing biosecurity risk to Australia
Work in a motivated and professional team with a wide range of skills and backgrounds
Full training provided

Who we are
The BICON Content Development Team maintains and improves the Biosecurity Import CONditions database (BICON) content to allow external clients to understand and comply with their biosecurity obligations and internal clients to effectively manage biosecurity risk and regulate imports. We work collaboratively with internal clients to comprehend and implement their BICON content requirements and optimise the use of BICON to publish clear import requirements and onshore management support procedures to effectively manage biosecurity risk.

The Jobs
Key duties of these positions include:

working with business content (import and permit conditions) and import programs to understand and construct decision tree structures in the BICON database, in accordance with system design and authoring conventions
executing changes to import and permit conditions in alignment with service standards while complying with system rules and authoring conventions
providing technical advice through various formats on the most appropriate means of authoring BICON content to achieve import program and stakeholder objectives
using workflow management tools to maintain detailed records of changes to import conditions and key decisions
performing administrative tasks including system reporting, data analysis and scoping tasks for the BICON content change work program
contributing to the development and maintenance of instructional material, authoring conventions and courseware
clearly documenting and reporting system issues
developing and maintaining effective working relationships with internal and external stakeholders.

What we are looking for
Knowledge and experience
Experience working with complex IT systems.
Experience working collaboratively and as part of a team.
Knowledge of the role of biosecurity is preferred but not essential.

For additional information, please read the Job Description below.
Candidate Information Package docx Opens in new window",3.9,"Department of Agriculture & Water Resources
3.9",Australia,-1,5001 to 10000 Employees,-1,Government,Federal Agencies,Government,$500 million to $1 billion (USD),-1
Cloud Data Engineer,-1,"Job no: 509605
Work type: Permanent Full Time
Location: Melbourne, Canberra, Sydney
Do you embrace digital disruption?
Do you love solving complex problems, designing sophisticated solutions and building innovative technology?
Do you believe in creating powerful actionable insights from Data and Analytics?
Do you want to work in a diverse and flexible working environment?
KPMG is one of the most trusted and respected global professional services firms. Through depth of expertise, clarity of insight and strength of purpose we help our clients solve complex challenges, steer change, strengthen, transition and grow. We are a team based practice and this extends to our clients whom we work and collaborate with, in solving complex problems. Together, we design, innovate and implement, providing enduring advice that support our clients and the services they deliver. Our clients vary in size and come from a diverse range of sectors – all sharing in a common goal: to embrace change and deliver services that make Australia a better place. We are looking for talented individuals who would like to join us on the journey.
KPMG’s Digital Delta Team
We re-imagine and re-invent organisations to become world class digital enterprises using advanced technologies, data and human insights. We help organisations to embrace Digital Strategy, Artificial Intelligence (AI) & Cognitive, the Internet of Things (IoT), Data, Analytics & Modelling, Mobile App & Web, and User Experience (UX) & User Interface (UI) and more.
We work with clients to:
Formulate strategies that re-imagine organisations
Harness innovation from the 4th industrial revolution
Actioning insights from trusted data to consistently and quickly make clear decisions
Build adaptive organisations
Thrive as a connected enterprise – front, middle and back office
This is how you’ll contribute:
We are looking for ambitious Data Engineers who are passionate about helping clients define bold ambitions and deliver on them. Joining our team will take you on a journey of personal and technical growth and provide the opportunity to inspire confidence and empower change.
As a Data Engineer you are the designer, builder and manager of the information or ""big data"" infrastructure, preparing data for analytical or operational use. You will design, construct, test and maintain a data pipeline to pull together information from different source systems; integrating, consolidating and cleansing data; and structure it for use in individual analytics applications.
The KPMG Difference
Our people are focused on creating a diverse and dynamic environment that embraces and values differences. We value the variety of unique experiences, qualities and characteristics our people possess and we share and learn from each other.
We are proud to be consistently recognised as an employer of choice for women, and for our achievements in LGBT+ workplace inclusion.
Our commitment to ‘Flexibility’ allows our people to manage the changing demands of work, personal or family life. Explore the links below to hear our people share their experience @ KPMG:
Flexibility empowers wellbeing
Flexibility enables contribution to the community
Flexibility inspires technology & innovation
Flexibility supports family

Make KPMG the clear choice for your career and be Extraordinary!

Advertised: 09 Sep 2020 AUS Eastern Standard Time
Applications close:",3.8,"KPMG
3.8",Sydney,-1,10000+ Employees,1987,Subsidiary or Business Segment,Accounting,Accounting & Legal,$2 to $5 billion (USD),-1
Computer Network and Systems Engineer,-1,"Duties Include but are not limited to:
Tasks Include:
analysing, developing, interpreting and evaluating complex system design and architecture specifications, data models and diagrams in the development, configuration and integration of computer systems
researching, analysing, evaluating and monitoring network infrastructure to ensure networks are configured to operate at optimal performance
assessing and recommending improvements to network operations and integrated hardware, software, communications and operating systems
providing specialist skills in supporting and troubleshooting network problems and emergencies
installing, configuring, testing, maintaining and administering new and upgraded networks, software database applications, servers and workstations
providing network programming in support of specific business needs and requirements
preparing and maintaining procedures and documentation for network inventory, and recording diagnosis and resolution of network faults, enhancements and modifications to networks, and maintenance instructions
monitoring network traffic, and activity, capacity and usage to ensure continued integrity and optimal network performance
Skills and Experience Required:
Must have experience working in a Managed Service environment
Demonstrated experience in IT Networks and Data Centres
Understanding of systems and architectures to meet client needs
Experience in Help Desk including break / fix
Effective and timely documentation
Effective Task Management Skills
Be solution and outcome focused and willing to learn new technologies
Excellent communication skills with staff, clients and partners
Time management, ability to prioritise and deliver to schedule
Experience with N-Able and Connectwise desired
Open Cabling license desired
Job Types: Full-time, Permanent
Salary: $30.00 per hour
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,Trans-plant training,Canberra,-1,-1,-1,-1,-1,-1,-1,-1
Software Engineer (Data),-1,"If you are looking for an opportunity to make a real impact with smart people who are genuinely doing things differently then you've come to the right place! We're growing our data engineering capabilities and are looking for awesome data engineers to join our team.
With our diverse range of clients and projects, no day will look the same - but here's a great snapshot of what you'll be doing:
Work with some of the best Data Scientists and Engineers to deliver production-grade AI and Machine Learning systems as we deliver client projects from inception to production.
Consulting with our clients and working with them to build modern data systems using the 'best of' technologies and principles.
Advising clients on data strategy, architecture and technology.
Applying best software engineering practices in coding, monitoring and alerting, using CI/CD, TDD and cloud architectures.
Working over a wide range of big data tools and environments: not limited to; Apache Kafka, Spark, Python, Scala, Hive, Airflow, AWS EMR & Glue, GCP Dataproc & Dataflow, BigQuery, Snowflake, Redshift.
Who are we?
Glad you asked! We are Eliiza. Data science. Engineered for scale.
We are a passionate team of data scientists and engineers who apply data science and machine learning to solve real-world problems. Our mission is to create a bright future for Australian businesses and society in a world increasingly influenced by intelligent technologies.
We've created a culture that values diversity where people can truly be themselves! We care a lot about growing the Australian AI community in a positive direction, and we're doing several things to try and achieve that:
We provide opportunities for underrepresented groups to work in AI through our associate and intern programmes
We organise and participate in a range of community events, reading groups and meetups
We produce the AI Australia podcast
We blog about topics we care about
We stream brown bag sessions to the broader community
We're also part of Mantel Group's 'house of brands' which means it's not just the Eliiza team you'll work with, learn from and see at social events - there's another 230 of us across DigIO, Kasna & CMD Solutions!
So you're ready for something new?
We're keen to know more about you! Our team is made up of a range of people, with different experience across a huge range of data driven skill sets.
We'd love to hear from you if you have experience with:
one (or more) core language(s), ideally Scala, Python or Java
one (or more) cloud platforms, AWS, GCP, Azure
ETL/ELT concepts and technologies e.g. Data partitioning, Hive, Spark
streaming data concepts and technologies, ideally Kafka (Kinesis, Beam or Pubsub will do)
We'd be over the moon if you:
Experience with distributed/columnar databases (e.g. Snowflake, Big query, Redshift).
Experience with any of a variety of databases e.g. RDMS, NoSql, Columar, Distributed, Time series, Graph.
Knowledge of job orchestration and scheduling. Any experience with Airflow, Luigi or Oozie.
Experience with containers and container orchestration (Docker, Docker Compose or Kubernetes).
However, we value a diversity of skill-sets, and don't necessarily require that you're skilled with all of the above. If you feel you don't fit all the experience/skills listed above we still encourage you to apply or get in touch.
What's on offer if you join us?
We make sure you're always one step ahead by investing your learning and development, every year. We build our own training where it doesn't exist yet.
We hire smart people and get out of their way. By focusing on our five principles and not getting caught up in red tape, we trust you to get the job done.
You'll get all the tools you need - a new iPhone or Google phone, a new Macbook Pro or Dell, and a lot of branded swag!
But hold on, you mentioned a house of brands?
We certainly did! Mantel Group is an Australian-owned, 'house of brands' company with four technology businesses (Eliiza being one of them!) across Melbourne and Sydney. We're building a group of companies with open borders so we can support you to take on new skills without leaving an awesome team - we understand you won't have one job for life!
We may only be just two years old but Mantel Group has already been recognised #9 in the 2020 Best Places to Work in Australia and #4 in the AFR's 2020 fastest growing new companies.
Keen to chat?
Click ""Apply"" to share your details with our talent team, and we'll be in touch.
In the meantime, check out 'how we hire' to find out what's in store if you're successful and get to know us better by visiting our website and following Eliiza on LinkedIn.",-1,Eliiza,Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Infrastructure Engineer,-1,"Job Description:
Design and grow the Shopee data platform to support a variety of big data applications using open-source technologies including Kafka, Hadoop, Presto, HBase, Spark, Hive, Druid, and our own creations. Some examples include a real-time data streaming platform, a unified query platform, a cluster management system, and a machine learning platform
Dig into the source code of some open-source big data system to get the whole control and familiar with the details, configurations, designs and source code. Develop and maintain the internal release of big data systems and components as the business requirements.
Keep close and overall monitoring for all the deployments of the systems, maintain the system’s stability, improve the performance, discover the performance bottlenecks, tracking and troubleshooting, cost optimisation.
Requirements:
B. Sci. / Ms / PhD in Computer Science or a related technical field
Familiar with at least one of these languages: Java, Scala, Python, Bash under Linux / Unix. Scala is a plus
Familiar with the use and compute logical of SQL
Knowledge about the Big Data Infrastructure system technology like Distributed File System, Distributed Computing, Distributed Database will be a plus
Hands-on experiences Hadoop, Spark, Kafka, and/or Presto will be a plus
Love to use and develop open-source technologies
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"Work on an award-winning, international technology!
Endless career opportunities
An innovative, friendly team of 300+
This role will be focused on the development of our existing ClaimLogik line of products as well as working on our new cloud-first, modern suite of applications.

Intelligent Thought, our technology business is scaling and shipping our software globally. Already profitable, part of a much larger group business, with investors such as Macquarie Capital and Envest – we are all set to deliver textbook disruption to the Insurance Industry. The growth of the platform, of our customer base, and the increasing industry demand have led to the need for this role to help the team scale.

Our Philosophy
Give each employee a sense of purpose and an environment for them to connect the importance of their role to delivering a service that matters to our customers.
Challenge the ‘why’ of traditional claims processes.
Keep it simple – do only what brings value and what matters to the customer
Enable employee decisions, empower our people
Responsibilities:
Create, extend and maintain ETL pipelines to form our data lake, data warehouse and analytics platform (currently using the Microsoft Azure set of tools and service)
Help define the optimal data pipeline architecture
Influence the tool selection, platform selection, data architecture and strategy which will transform the business to be truly data-driven
Understand, analyse and size user requirements
Work with different parts of the business to provide them with the insights they need to deliver the best results
Skills & experience:
Degree or qualification in computer science or related
Advanced knowledge of relational database, including query authoring and query optimisation (MS SQL Server and PostgreSQL).
Experience building and optimising ETL pipelines
Experience designing complex data models
Experience working with cloud platforms (Azure or AWS)
Efficient time management and organisational skills
High attention to detail and accuracy
Effective communication skills to build strong working relationships; both written and verbal
Proactive and results-driven
Why Claim Central?
Claim Central Consolidated is a global insurance industry leader across, claims management, insurance technology and data and analytics. Currently operating in the United States, Australia, South Africa, Italy and New Zealand, we have pioneered digitally connected claims management services across the globe. Claim Central is a disruptor and thought leader in the industry and we were recognised as the Australian Financial Review’s 8th Most Innovative Company in Australia in 2016. This business is in a period of unprecedented growth, transitioning our technology and services into multiple geographies at a rapid pace. Our unique culture is based on teamwork, collaboration, trust, respect and performance. We also offer many benefits apart from our exceptional team culture; including flexible work arrangements, and continued professional development.

Be a part of this journey in a career-defining role.",-1,Claim Central,Matraville,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer - AI/ML,-1,"Our client provides services to a major industry across the country. The business is still early in it's days of technology development and the environment is greenfields in nature (no pun intended), effectively working like a start-up.

Their data and analytics team have worked and built leading and bleeding-edge technologies in this space and what they have created so far may be game-changing. From a machine learning perspective, the progress they have made to the business has already seen proven success in changing the future of an industry that will have positive consequences for all those involved.

You will have previously worked in a technical capacity in the data and analytics space and have experience working with an organisation where machine learning has been implemented, not just a concept that the business talks about having or the technology team would love to have. The commercial experience you will have had in the ML field will be proven examples of where you have affected the way a business or industry used to perform, to the changes that have come about from this.

Technically, you will have extensive experience in the Microsoft space - Power BI, Azure etc and you will have previously mentored and coached junior members of the teams you have been part of.

This is a rare opportunity in Brisbane where the business has truly embraced and funded projects across the ML space and would be a great chance for those in the Data Development/Data Engineering field, who are looking to move into a Data Scientist role in the future.

Please send your application through if you would like to know more.",4.0,"Emanate Technology
4.0",Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Solution designer/ ETL Engineer & Data Modeller,-1,"We are looking for a Qualified and Experienced Solution Designer to join our client for a period of 6 months with a view to extend.
You will work closely with team members and your contribution will range across gathering and analyzing information, developing and documenting improved processes and work instructions and experienced DWH Lead with skills in requirement analysis, solution designing, developing, testing and supporting ETL solutions.
A hands-on solution designer, data modeler and ETL developer for Data Warehousing and ETL application transformation projects using Informatica PowerCenter.
Knowledge on AWS, S3, Redshift, Informatica BDM, and related technologies.
Experience working with IPython, PySparks, AuCuMo, Airflow, Jenkins, Github, Athena, JIRA, Rally, Spectrum, Glue, Flyway.
Good exposure on Oracle PL/SQL, aware of DBA activities, writing and performance tuning of complex SQL queries.
Contract length: 6 months
Job Types: Full-time, Contract
Salary: $650.00 – $800.00 per day
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,nducive,Melbourne,-1,-1,-1,-1,-1,-1,-1,-1
"Data Engineer, Wollongong NSW or Mount Waverley VIC",-1,"Company Description
BlueScope is a technically advanced supplier of steel and steel products in Australia. We are an inclusive organisation and every day we showcase our technology and expertise throughout the world.

Job Description
We are looking for two Data Engineers to join our IT team, based in Wollongong NSW or Mount Waverley VIC. Use your experience in analytics to unlock business value, enabling use of big data for insights and decision-making.
Reporting to the Data Product Owner for our Australian Steel Products (ASP) business, this position will support strategic goals related to data. This will see you:
Gather business and technical requirements with the view to deliver outcomes;
Develop and implement end-to-end data collection, consolidation, modelling and visualisation solutions;
Document metadata in a dictionary and catalogue;
Ensure consumers of such information understand its accuracy, timeliness, quality and sensitivity, so that it is used appropriately; and
Identify opportunities to enhance analytics.
What are the benefits?
Work in a supportive and collaborative team environment whilst we embark on a journey to transform the way our business uses data!
Our systems landscape is broad and diverse. You will be encouraged to think creatively to develop data solutions which solve real business problems.
Working in this role you will enjoy:
the chance to learn more about data science;
salaried remuneration with attractive superannuation options;
the opportunity to participate in a performance incentive scheme; and
access to further development and career opportunities with BlueScope.
Who are we looking for?
We welcome applications from professionals with experience in data analytics and/or programming. Supported by your knowledge of project delivery methods (e.g. Agile), you will demonstrate:
experience with data mining, wrangling, mapping and visualisation techniques (e.g. Azure Data Factory, Databricks and/or DevOps etc.);
well-developed ability in gathering business and technical requirements;
skills in developing and implementing collection, consolidation, modelling and visualisation solutions; and
a passion for sharing your knowledge and desire for ongoing professional development.

Qualifications

null

Additional Information
We're proud to have been named an Inclusive Employer for 2019–2020 by the Diversity Council of Australia. We believe that our people are our strength. Having a diverse and inclusive workplace enables us to improve our capability and ensure continued, sustainable success.
We know that workplace flexibility can mean something different to everyone. Under our B-Flex initiative all of our roles have some degree of flexibility. We encourage you to discuss your needs with us.
Applications close Sunday 25th October 2020.",3.3,"BlueScope
3.3",Wollongong,-1,201 to 500 Employees,-1,Company - Private,Construction,"Construction, Repair & Maintenance",$100 to $500 million (USD),-1
ETL Data Engineer,-1,"ETL Data Engineer

Join a team that’s changing how Australia lives, works, plays and grows
We want you to be the best version of you

Work with innovative teams and explore new technologies to help solve real-world problems.

A typical day as a Data Engineer

ETL / Big Data Engineering professionals will be responsible for guiding the full lifecycle of a Data solution, including:
Working in highly client-facing roles to contribute throughout the end-to-end delivery lifecycle of complex and large-scale digital solutions
Use case and business case development
Support existing and new applications utilizing in-depth technical and data knowledge. Troubleshooting complex issues and providing advisory services to improve the client’s data landscape
Help to streamline and simplify the clients’ complex data landscape by integrating different applications and data architectures
Implementation from requirements analysis, platform selection, digital architecture design, application design and development, testing, and deployment
Interstate travel may be required

Basic qualifications:
Bachelor’s degree
Experience across systems integration, information management, data management and architecture, and business analytics
Experience with being in a team focusing on large-scale, multi-release information centric projects
Experience with waterfall and agile delivery and run / application support functions
Part of a team working on End to end implementation of at least 1 big data project

Preferred Skills:
Hand on experience in Data warehousing using ETL tools such as DataStage, Autosys and TeraData
Hands on experience in ETL job development with multiple stages like sequential file, Transformer, Lookup, join, sort and Database stages.
Strong hand on skills in design, development and implementation of various data remediation, Data migration, data integration techniques.
Strong hand on data modelling experience.
Strong hands on experience in database performance tuning including complex query optimizations and physical database tuning using Teradata.
Understanding of architectural designs and strategy related to data migration, data cleansing, data quality and data consolidation.
Proven data analysis, requirement gathering and problem-solving skills
Exposure to Unix environment and shell scripting.
Experience in Banking and Financial services industry
Desirable: Knowledge of cloud computing infrastructure (e.g. Amazon Web Services EC2, Google Cloud, Microsoft Azure)
About Accenture

Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. We combine unmatched experience and specialized capabilities across more than 40 industries — powered by the world’s largest network of Advanced Technology and Intelligent Operations centers. With 513,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises. Visit us at www.accenture.com.

Accenture is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, marital, domestic or civil partnership status, sexual orientation, gender identity, or any other basis as protected by applicable law.

Vera Goga is the Recruiter managing this role. As the team experience high volumes of applications, we appreciate your patience to allow for a fair and timely process.",3.9,"Accenture
3.9",Sydney,-1,10000+ Employees,1989,Company - Public,Consulting,Business Services,$10+ billion (USD),-1
Student Engineer,-1,"The candidate will have the ability to:
Undertake onsite inspection to collect asset condition data based on the relevant engineering standards and technical guidelines;
Undertake desktop analysis to evaluate the condition and performance of the assets;
Provide the appropriate information, advice, engineering input and support services for the sustainable management of Council’s stormwater and transport networks.
Qualifications:
The successful candidate will be enrolled in a Bachelor of Engineering with a minimum of two years completed.
Position Number: 100678
Position Hours: Fixed term (3 months), hours will be negotiated with the successful candidate, maximum of 75 hours per fortnight.
Salary: Schedule A, Salary Point 4.0. $28.64 per hour ($55,853.45 per annum, pro-rata) in accordance with Glenorchy City Council’s Enterprise Agreement 2016
Please note that all successful applicants will be required to provide a current National Police Check prior to commencement of employment.
For further information on this position, contact Patrick Marshall, Senior Civil Engineer on (03) 6216 6800.
How to apply: Applications for this position must be lodged on this submission site or on the Glenorchy City Council website www.gcc.tas.gov.au - Careers page.
To be considered for this role, all applicants must address the key selection criteria in the and provide a current resume. A copy of the position description can be found by clicking the below hyperlink or on the Glenorchy City Council website.
Applications close at 8pm on Sunday, 1st November 2020
- Student Engineer",4.0,"Glenorchy City Council
4.0",Glenorchy,-1,501 to 1000 Employees,-1,Government,-1,-1,Less than $1 million (USD),-1
Data Engineer involving DevOps,-1,"Data Engineer involving DevOps
Axiom Technologies is an Australia based entity with the history of providing Managed IT solutions to medium to large scale enterprises globally. Please visit our website for more information about what we do at www.axiomtechnologies.com
Axiom Technologies is an Equal Opportunity Employer and encourage applicants from all backgrounds and gender to apply, including, Aboriginal and Torres Strait Islander candidates
Job Requirements:
8+ years IT experience, with at least 5+ years of “Data Engineer/Deveoper” focused titles/roles,
Data Tools: Hands on experience with Apache Beam.
Testing: Hands on experience with automated testing activities/outcomes
DevOps: Experience with the processes involving Microservices facilities for artifacts developed
Platform/OS: Mid-range/Unix
Languages: Unix (Shell) Scripting/commands, SQL, Python
File formats: Text, CSV, Parquet, JSON, XML
Scheduling: Jenkins, Airflow
Auto Scripting: Designing/creation of scripts for repetitive activity. E.g. Unix scripting/SQL
Big data: Exposure to Data Lake Concepts, Hive (Schema), HDFS
Source Control tools: GIT
Delivery Models: Agile, Scrum
Ingestion Design: Create/assess Source/Target data mapping designs
Frameworks: Development and delivery frameworks
Activity Reporting/Repository: Jira, Confluence.
Quality: Accuracy and attention to detail
Industry: Financial Services/Banking
Solutions: Define solutions from High level to detail design to address automating ingestion activity. Facilitate/confirm requirements from product owners, business team members and technical associates,
Process Automation: Automating processes in file management, testing data in files, analysis and design, configuration management.
Script Automation: Ability to design/create scripts to automate/improve data copy/migration/ETL for any repetitive activity.
Languages: Java, Python
Scheduling: Control-M
Databases: Relational. E.g. POSTGRESS, Oracle – as a ETL developer
File Formats: Mainframe – experience with referencing its data formats/copybooks
Big data: Experience referencing/using Hive (Schema) to access data in HDFS
Metadata management tools: MDM, EDC and Axon
Performance: Assess, recommend, improve mappings, SQL queries, Batch feeds
Automation Tools: Other tools that may add value to an automation program and generally support development. E.g. API, REST, JDBC, Webservices, Message Queues/Load balancer,
Cloud: Experience with processing of data files to be ingested/stored in the Cloud, preferably with AWS.
Prod Support: Experience in a production support role performing root cause / impact analysis – under time constraints
Experience in a similar role
8+ Years
What next?
If you are looking for that next challenge in your career and wish to apply for this role, please forward your resume to careers.au@axiomtechnologies.com",2.0,"Axiom Technologies
2.0",Melbourne,-1,1 to 50 Employees,-1,Company - Private,Industrial Manufacturing,Manufacturing,Less than $1 million (USD),-1
Data Engineer,-1,"About the Role
We are on an exciting digital journey so it’s a great time to join ME! We are seeking a Junior Data Engineer who enjoys rolling up their sleeves, learning and growing. As part of our Enterprise Data Team, you will ensure fit for purpose data warehouse solutions are built for use across the bank and by utilising best practise ETL standards, whilst ensuring the data is trusted by our BI developers and key business consumers. Oh, and you’ll get to work on Microsoft technology stack too!
You will be involved with investigating data issues, keeping data feeds flowing and collaborating with different projects across the bank to deliver quality data solutions. How important does that sound? What’s even more important is this role contributes directly to our overall business strategy through the provision of data to enable analytics & reporting, as well as supporting business and decision system processes.

About You
You’re naturally a highly motivated and energetic person who thrives in a dynamic, ever-changing collaborative team environment. Ideally you have previous experience as an ETL developer, Data Engineer or a BI developer, and if you have a degree in computer science or similar it would really put you ahead of the rest.

With your knowledge of SQL coding, data modelling, understanding of data warehouse concepts, plus experience of working on complex ETL solutions, you’re ready to expand your horizons and launch your career into the world of IT at ME.

About ME
We’re not like other banks.
ME was created by the industry super funds to be different from the pack – with a core purpose to help all Australians get ahead financially – no conditions, asterisks or exceptions. And we know that looking after customers starts with taking care of our people.
We believe everyone deserves the same opportunities in life, regardless of gender or identity, sexuality, ethnicity, religion or disability ‒ with internal affinity groups.
Perk ME up
Once you get your feet in the door at ME, we’ll put them both in your very own ME-branded Converse shoes. You’ll also get the following financial, health and fun perks when you join the team:
4U Extras portal (discounts and cashback on 100s of items including cinemas, shopping and gym memberships
10% Myki discount
Purchased Leave programme
Internal wellness programme (Mindfully ME)
Professional education through LinkedIn Learning
Novated Leasing
Professional membership reimbursements
Health checks
Financial education (To help you manage your money smarter)
LGBTIQ+ and Women at ME affinity groups

I want those Converse shoes (and the role)
Can’t see a closing date on the advert? That’s because we’re pretty efficient here at ME and we may start looking at applications sooner rather than later, so if this role sounds like your jam, be sure to apply by submitting your resume today.

Should an applicant be the preferred candidate, background checks (including police checks, reference checks, ASIC banned and disqualified persons and bankruptcy checks) will be completed prior to the candidate's employment being confirmed. The outcomes of the background checks do not automatically bar candidates; however will be assessed against the inherent requirements of the job.
Back Share
Apply Now",3.0,"ME Bank
3.0",Melbourne,-1,501 to 1000 Employees,-1,Company - Private,Banks & Credit Unions,Finance,$100 to $500 million (USD),-1
Software Engineer - Machine Learning/Data Science,-1,"Zendesk is looking for a Software Engineer - Machine Learning/Data Science for a full time position in our Melbourne office.
As part of our engineering team, you will work at a scale where the challenges start to get seriously interesting. Our global engineering team is widely dispersed over the world, with people across nearly every continent. You will get a chance to do cool things with a diverse bunch of people while working in the Melbourne office that is home to Zendesk’s first machine learning (ML) research team.
The Data Science Team, together with Data Engineering, have built Satisfaction Prediction, Answer Bot and Content Cues — products that use Machine Learning (ML) and Artificial Intelligence (AI) to help our customers work more efficiently.
What you get to do every day:
We’re currently looking for someone to join our team as we research, develop, and productionise Machine Learning and Deep Learning models. In addition to frequenting Melbourne’s finest purveyors of coffee, ramen, and bulgogi, you may find yourself:
Building machine learning models including neural networks in TensorFlow
Writing and deploying production-grade Python
Querying and constructing datasets in AWS Athena, Spark
Evaluating and responding to real-world model performance
Scaling your ML to millions of predictions per day
Presenting your work to a broader audience
Watching your algorithm help Zendesk’s end-users
What you'll bring to the role:
A strong foundation in a quantitative discipline (e.g. machine learning, statistics, bio/eco/etc-informatics, econometrics, etc) is critical for this position. While experience in deep learning and natural language processing would be beneficial, your best qualities are:
dedication to continuous learning
collaborative work attitude
strong communication skills
You should also be comfortable with at least one programming language, such as Python, R or Scala.
Application Deadline: 18/11/2020
Job Types: Full-time, Permanent
Salary: $85,000.00 – $110,000.00 per year
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Temporarily due to COVID-19",4.5,"Zendesk
4.5",Melbourne,-1,1001 to 5000 Employees,2007,Company - Public,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),-1
Software Engineer (Machine Learning),-1,"About the Role
AdelaideMRI is building a medical reporting tool. We require an engineer to work primarily on machine learning projects to improve reporting speed and report comprehensiveness.
You will perform data analysis of medical report datasets and image datasets to infer sentence recommendations, image classifications, or other actionable results for the doctors.
Skills and Experience
Background in machine learning or image processing
Qualifications in Computer Science, Software Development or Engineering or equivalent experience
Bonus points for Python
No prior medical knowledge is required.
This position offers flexible hours and work arrangements.
Job Type: Full-time
Experience:
Software Engineering: 1 year (Preferred)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Yes",-1,Adelaide MRI,Australia,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Hey there, we’re PEXA!

We started as an idea: to deliver a single, national e-Conveyancing solution. We collaborated with the industry to create a national electronic lodgement and settlement platform: PEXA. From our humble beginnings, we’ve now grown to more than 320 employees across 5 different states. We’re still expanding at a rapid rate and constantly challenging ourselves to create great experiences for our members as they transition to fully digital conveyancing.

Why become a PEXArian?

Great question! Being a PEXArian is so much more than just a job. We are passionate, motivated & unashamedly enthusiastic at PEXA - we love what we do and we’re proud to admit it! Creating brilliant member experiences wouldn’t be possible if we didn’t also strive to create an amazing employee experience. Alongside our members, our employees are at the heart of everything we do.
Here’s a snapshot of what your life at PEXA could look like:

Your growth:
We encourage you to hit your personal and professional Learning & Development goals with our tailored programs and tools.

Your wellness:
We care about your holistic well being - a fully stocked kitchen, four wellness days, a $250 wellness subsidy as well as lunch and learn sessions to support your financial well being.

Your work/life blend:
We know that work is just one aspect of your life, we want to help you create your ideal work/life blend, rather than squeezing in life around work.

Your family:
With a range of benefits aimed at supporting your family including access to a subsidised school holiday program, extended parental leave and flexi-time to support your return to work, superannuation payments for unpaid parental leave for primary carers and a childcare allowance for pre-primary aged children, when we say, ‘welcome to the family’, we really mean it!
The impact you'd drive:
The successful candidate will be responsible for developing, and maintaining infrastructure to support the delivery of new and existing products. They will also be contributing to establish the rules and frameworks for obtaining the required approvals for new products.
On day one we’d love you to have:
Experience with Python, Spark
Event streaming/sourcing with Kafka or AWS Kinesis
Experience with data structures, formats and data security best practices
AWS experience (e.g CloudFormation, S3, ECS, Lambda, SQS, IAM, KMS, DynamoDB, Glue, Athena)
Query construction and optimisation (e.g. SQL, Elasticsearch, Splunk, DynamoDB)
Git, version control practices, and continuous integration/delivery servers
PyUnit and unit testing frameworks
Production release cycles and maintenance
Collaborating with technical and non-technical teams
Even better:
Agile methodology/delivery
GraphQL
Modern frontend technology (e.g. ReactJS, TypeScript)
Machine learning frameworks and tools (e.g. TensorFlow, PyTorch)
OAuth 2, SAML 2, JWT
Data visualisation and exploration tools (e.g. Jupyter notebooks, Tableau)
AWS SageMaker
Sounds like you?
If this role sounds like you, apply today to have your application reviewed ASAP!",3.9,"Property Exchange Australia Limited
3.9",Melbourne,-1,201 to 500 Employees,2010,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Ongoing position
Full time
Based in Sydney, NSW
Who we are
Australian Red Cross is part of the world’s largest humanitarian organisation. Our aim is to improve the lives of the most vulnerable people in Australia and across our region.
About the role
The Data Engineer role will sit within the Data and Integration Squad in IT and will own (design, implement and support) the AWS Big Data technologies such as the Data Lake and Data Warehouse and support the organisation in growing the data analytics capabilities at Red Cross. In addition to this, the data engineer role will also administer the Power BI tool and support the implementation of the data mastering capability.
What you will bring
Experience building and optimizing data pipelines, architectures and data sets.
Experience in dimensional modelling and building data vaults
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with structured, semi-structured and unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Why work for us?
Work for purpose and know that your work assists Red Cross support and empower people and communities in times of vulnerability.
Generous salary packaging options available that can increase your take home pay.
Further information
To find out more about this opportunity please see the position description below or contact Sharath Kumar Gurram on 02 8651 8839.
Position Description: Position Description - Data Engineer .pdf
Applications for this position will close at 11:55pm Thursday, 5 November 2020.",4.1,"Australian Red Cross
4.1",New South Wales,-1,1001 to 5000 Employees,-1,Nonprofit Organization,Industrial Manufacturing,Manufacturing,$500 million to $1 billion (USD),-1
Junior Fullstack Data Engineer (Python and React),-1,"Formbay is the leading Renewable Energy Certificate Trading company in Sydney. We provide Digital Workflow and Compliance solutions in the renewable energy industry and document processing.
Thanks to our meteoric growth and our commitment to be the best at all we do, we've identified the need to bring on board a new Junior Fullstack Data Engineer.
Reporting to our Principal Machine Learning Engineer, you will help build Machine Learning pipelines for our existing Digital Workflow and Compliance solutions to automate fraud detection and document processing over terabytes of photographic and documentary data – including documents, photos, GPS data and aerial/satellite photography.
Our stack is based on Python, JavaScript, Dask, Tensorflow, CUDA, Nix/NixOS, AWS, Docker, PostgreSQL and more – familiarity with these applications will give you a leg-up on the competition.
Our ideal candidate will have the following competencies:
SQL
Python
JavaScript/TypeScript
Our candidate must also be comfortable working with Linux.
Located a stone's throw away from the Queen Victoria Building in Sydney's bustling CBD, we are centrally-located with easy access to public transportation, bars, cafes and fine dining.
Formbay will provide flexible working hours, a generous remuneration package and the opportunity to work on a world-first software solution are what we can offer you. Free, twice-weekly gym sessions and really, really good coffee are also available.
No hiring/recruitment agencies need apply.",5.0,"Formbay
5.0",Sydney,-1,1 to 50 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is an experienced and qualified Data Engineer to join our IT team based in Birtinya.
Key Responsibilities:
Create and maintain data pipelines and or ETL scripts
Create and maintain data integration including API and Batch interfaces
Performed detailed data analysis
Create and maintain corporate data models
Create and maintain data visualization using Qlik.Sense , PowerBI or Simliar Toolset
Experience in defining, building and maintaining data virtualization and/or star schema data warehouses
Maintain, tune and optimise database, integration and visualisation toolsets
ABOUT YOU:
To succeed in this role, you’ll need to bring the following experience and skills:
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Excellent communication skills both oral and written, with an ability to bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking
Experience with data analysis and modelling will be beneficial

How to Apply
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kawana Waters,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Graduate Data Science / Engineer,-1,"The NRMA is an organisation looking to the future, and right now, we are on the lookout for people who can help us reach our goal: to continue to shape the way Australians move, for the next 100 years and beyond. www.mynrma.com.au.
Everyone new to the team, along with our current staff, will temporarily work from home until it is safe to return to our offices. All interviewing and on boarding will be done virtually due to COVID-19.


Your opportunity
As Graduate Data Scientist or Engineer you will be part of the Data Engineering team delivering cloud data transition program for business initiatives and supporting the entire data platform build.
Your key responsibilities will be to:
Implementing Concepts of Data Warehousing, Data Mart creations within Cloud
Use of SQL for data analysis and insights
Building AI/Machine Learning prototype for implementing and supporting existing algorithms
Data Analytical reports build, using different tool sets


Requirements for Success:
Relevant Degree - Computer Science, Computer Engineering, Software Engineering, Data Science
Excellent SQL skills and demonstrated working knowledge in Python
Demonstrated understanding in data structure and algorithms.
Knowledge and concept of data warehousing methodologies
Any reporting tools experience Tableau or Oracle Analytics Cloud, Looker is desirable
Exposure to Google/AWS/Azure/Oracle any cloud based platforms is desirable
Good communication and interpersonal skills

If you have the required skills and the passion to join our high performing team, please apply today.

Employee Benefits
To ensure our employees feel valued, empowered and celebrated we provide a range of employee benefits including:
50% discount on all NRMA insurances
Free Roadside Assistance
12 weeks paid primary and 4 weeks paid secondary parental leave
Free NRMA Blue Membership
At the NRMA Group, we are People Moving People and diversity and inclusion are part of our DNA. Together, we continue to build an inclusive culture that encourages, supports and celebrates the diverse voices of our employees. It fuels our innovation, promotes flexible ways of working and connects us closer to our members and the communities we serve.",2.5,"NRMA Motoring & Services
2.5",Sydney,-1,501 to 1000 Employees,-1,Nonprofit Organization,Casual Restaurants,"Restaurants, Bars & Food Services",$500 million to $1 billion (USD),-1
Data Centre Engineer,-1,"We are a leading world group that provides low-carbon energy and services. To tackle the climate emergency facing us all, our aim is to become the world leader in the zero-carbon energy transition ""as a service"" for our clients – particular for companies and regional authorities. We use our expertise in our key business areas (renewables, gas, services) to provide competitive and bespoke solutions.
The Data Centre Engineer will be employed as part of a 24/7 ongoing shift to coordinate and monitor third party service providers, maintain the data centre facilities and infrastructure plans, coordinate the implementation of customer requests within the data centre and monitor systems, all in accordance with the Contract KPIs and SLAs.
Coordinate and monitor third party service providers for regular maintenance & testing, service faults & call outs, ensuring works are performed in accordance with Contract SLAs
Monitor and maintain the data centre facilities and infrastructure plans and documentation, including electrical, mechanical, hydraulics, fire and BMS/EMS systems
Coordinate the implementation of internal and external customer requests within the data centre
Perform scheduled plant checks and minor maintenance works
Ensure all Work Order requests are raised and closed in a timely manner
Conduct inductions for staff, vendors and contractors
Ensure all work permits for vendor works are raised and closed
Perform inventory checks on all equipment and critical spares

Qualifications
The selected candidate must be able to demonstrate:
Electrical or HVAC background, or Graduate Electrical or Mechanical Engineer
Passionate about quality work and career minded looking for a new challenge
Can commit to a day and night shift roster (2 days of day shift, then 2 days of night shift, 4 days off)
Ideally able to commence asap
As part of carrying out the duties of this role, it is mandatory to hold Australian Citizenship.

If you are interested and meet the selection criteria apply with an up-to-date resume via the apply instructions on this website.

ENGIE Services is an EEO employer, where all applicants are treated with fairness and respect and have equal access to the opportunities available.

We will not be engaging in the services of a recruitment agency to fill this vacancy and therefore request all interested candidates apply directly to this advertisement.

Job
: Maintenance
Primary Location
: Oceania-Australia-New South Wales-Erskine Park
Organization
: ENGIE Services Australia and New Zealand
Schedule
: Full-time
Nature of Responsibility
: Senior operational / administrative role
Job Posting
: Sep 11, 2020, 6:29:59 AM",3.7,"ENGIE Services Australia & New Zealand
3.7",Sydney,-1,5001 to 10000 Employees,1995,Company - Public,Energy,"Oil, Gas, Energy & Utilities",$2 to $5 billion (USD),-1
Senior Data Engineer,-1,"Senior Data Engineer, Temporary, SYDNEY - McKell

Job Title: Senior Data Engineer

Salary: SNSW Grade 9/10 - The package includes base salary range of $111,806 to $134,667, plus employer's contribution to superannuation and annual leave loading.

Location: Head Office – Haymarket

Employment Status: Temporary through till 30th June 2021


About Service NSW:

Service NSW is making it easier for people and businesses across NSW to access government services. The role designs, builds and analyses complex data from multiple sources to identify revenue, process and business improvement opportunities; providing new information and insights to the business to inform planning, continuous improvement and performance.

About the Role

We are currently seeking to appoint a Senior Data Engineer to deliver expert advice and services in the design of a Single View of Customer and data-related services to support the achievement of business outcomes and strategic goals. We support flexible working practices with staff working remotely during this time.

In this role you will:

Design, build and support a modern data platform based in AWS and vendor technologies.
Provide expertise on data modelling for Graph data model and Customer Data Platform (CDP).
Create data pipelines, load, transformation and reporting workloads in AWS.
Work with the latest data engineering technologies like Apache Kafka, AWS Kinesis, AWS Neptune, AWS Glue and AWS Athena.
Contribute to the design and decision-making of the right tool or platform for the job according to requirements.
Provide expert advice and guidance on data quality and data engineering best practices.
Support a “bigger than you can imagine” scale of data in production environments.
Design, develop and support a metrics-driven reporting solution and a meaningful business intelligence platform.
Document the solution design and support procedures of solutions.
Produce reports, visualisations and recommendations to answer complex business problems that are presented in the most appropriate format to ensure clarity for target audience.
Analyse and define new process improvement opportunities to support continuous improvement and business outcomes; providing advice to stakeholders, on ways to improve the efficiency and reliability of data products and services.
Be very responsive to the information needs of the business by corresponding to customers in a timely manner and provide support/solutions to issues raised.
Troubleshoot and perform root cause analysis on production issues. Identify and implement long term solutions to problems. Perform scheduled maintenance, release deployment and production support activities after business hours, from time to time.
Liaise with internal and external customers to discuss and gather requirements, solutions etc. and maintain a good working relationship with the stakeholders.


Skills and Experience Required:

Solid experience with workflow technologies designing and building data pipelines, data models and data stores.
Experience working within and an understanding of Amazon AWS ecosystem, including security and performance tuning.
Hands on experience working with different types of databases, with focus on Graph and NoSQL databases.
Experience with data streaming required. Having used Kafka and related technologies is an added advantage.
Sound knowledge and experience working with batch processing, data extraction and API integration.
Hands on experience with at least one programming language: Java, Python or scripting.
Demonstrated experience working in an Agile based, fast paced, complex environment within cross-functional teams.
Experience developing systematised insights, data analytics and reporting solutions is an added advantage.
Experience with interactive visualisation of data insights is an added advantage.


Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Salary Grade 9/10, with the base salary for this role starting at 111,806 base plus superannuation

Closing Date: 6th November at 9:59am - applications will be reviewed on a rolling basis, applications may close early or extend

Please apply online, direct applications submitted via email will not be considered.

The Department of Customer Service is proud to be an EEO Employer who are fully focused on equality and believe deeply in diversity of all identities making us different and a true reflection of our NSW customers. As an inclusive workplace, we support various employee resource groups, practice flexible work and workplace adjustment.

If you do require an adjustment during the recruitment process, please notify us on your application form.",3.2,"Service NSW
3.2",Sydney,-1,501 to 1000 Employees,2012,Government,State & Regional Agencies,Government,Unknown / Non-Applicable,-1
Data Engineer - Entry / Mid Level,-1,"Work with a great team on interesting projects customers
Gain more experience in AWS, Data, DevOps cloud operations
Got a working knowledge of AWS? We will teach you the cool stuff!

Itoc is seeking an up and coming Data Engineer to join our growing Data Team in Sydney.

This is an exciting role working with databases, data lakes, data warehouses, data transformation (Python SQL) and enabling AI/ML.

You will be implementing foundational, robust and production ready data platforms to enable business data-discovery, self-service, AI/ML functions across a range of client types and industries, allowing them to do more with their data.

You'll be responsible for:

Deploying data repositories such as lakes and warehouses.
Contribute to our growing portfolio of data solutions.
Ongoing optimisation and management of data platforms.
Development of transformational logic for data pipelines
Data evangelism. We want to show our clients how to follow the best practices for data.

Desired Skills and Experience

To take up the challenge, you will have a depth of skills and experience including:

1-2+ yrs of focused data experience working with SQL and/or NoSQL solutions
A solid education in Software Engineering or equivalent industry experience.
Anything Data focused preferred.
Ability to analyse business scenarios and associated data landscape to derive potential opportunities.
Strong foundation in Python and SQL
Working knowledge of APIs
Principle knowledge of the different relational database platforms and modern data storage techniques
Knowledge of the different aspects of data environments
Collect, store, process, verify consume
Experience with version management systems (such as GIT)
Working knowledge of AWS or another cloud platform - we will teach you the cool stuff.
Great communication skills, an ability to work closely with customers, developers and engineers and the confidence to present ideas in open forums.
Relevant tertiary qualifications and/or industry certifications.
Great communication skills, an ability to work closely with clients, developers and engineers and the confidence to present ideas in open forums.

While not required, a background in consulting and professional services is highly desirable.

Itoc Description

This is an exciting and challenging career opportunity to join the growing Sydney-based Data Team of a leading cloud solution provider where you will be given support to reach your long term career goals. You will be part of a team of cloud experts and will work in an environment of continuous improvement and learning delivering innovative cloud solutions across SaaS, online business and enterprise business.

On offer is a chance to join a team with a great working environment, in an organisation that values its employees and sees the value in ensuring they are engaged. Our team are clearly passionate about what they do, that's why we won the following awards:

Customer Obsession Partner of the Year 2015: ANZ Region
Customer Obsession Leadership Partner 2015: re:Invent

As an employer of choice Itoc offers competitive remuneration, training and development programs and a great working environment. We value a healthy work life balance.

The Perks

MacBook or Dell
Continuous internal learning that will provide training and career development opportunities
Working with a collaborative, social team and leveling-up your skills faster than you will anywhere else.
Quarterly social events

Itoc

Culture and smarts are important to us. Bring your secret sauce. This is no ordinary environment, you will work along some of the Cloud’s best. All engineers at Itoc must gain at least five AWS certifications. We work hard but we have fun.

Please note you must have full working rights in Australia and be available on-shore for face to face interviews.

No recruiters please.",4.0,"Itoc
4.0",Sydney,-1,1 to 50 Employees,2013,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Date: 01-Oct-2020

Location:
Melbourne, VIC, AU

Department:Description:
Technology discounts - from Apple HP Lenovo to Windows
Flexible work arrangements - work in a way that suits you best
Salary packaging - to suit your personal and financial circumstances

Do you want to work for one of the fastest growing data teams in Australia? Do you want to work on multiple data platforms and provide new solution offerings by leveraging cloud and big data technologies?

About the team

Big data information and analytics. Three words that spark apprehension in most businesses. But our team of experts are constantly curious and excited about combining our wonderful array of technological expertise to transform data into our clients most valuable assets making their work smarter. Our data consultants are supported with resources training and tools they need to excel at their work but also the freedom and power to create their own paths forward to make a difference.

As a Senior Consultant in Big Data you will work closely with the team and stakeholders to build and deliver a Cloud based vision for a next generation Big Data analytics platform with strong focus on data quality data security and deliver the systems that process huge volumes of data.

What will you typical day look like?

You will play a pivotal role in - Designing and producing high performing and stable applications to perform complex processing of massive volumes of data in a new cloud based architecture; Building real-time data processing applications which are integrated with business systems to enable value from analytic models to drive rapid decision making; Contributing to system architecture design for a data platform (including cloud-based structures both on and off premises data warehouse components and data lakes); this could cover a range of technologies various countries/locations and lines of business; Support data strategy or technology strategy definition programs including technology stack definition and target operating model requirements

Enough about us lets talk about you:
You are someone with:
Use of traditional data analytics tools and techniques (e.g. MSSQL Oracle MySQL) and ETL software (e.g. SSIS Informatica CloverETL)
Working in large scale cloud data solutions using platforms such as AWS or Azure or GCP will be a bonus.
Experience in scripting or programming (e.g. Python Java Scala C#)
Excellent verbal and written communication skills to adapt to technical and non-technical audiences.
Educated to degree level (or have equivalent experience)
Why Deloitte?

At Deloitte we create positively differentiated work experiences that enable our people to feel valued and achieve their full potential. We value difference and embrace people with diverse backgrounds and thinking styles. Knowing that people work best in different ways we are happy to discuss alternative arrangements if the working pattern you are looking for is not specifically indicated.",3.8,"Deloitte
3.8",Melbourne,-1,10000+ Employees,1850,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Engineer,-1,"Opportunity to grow the team
Period of growth
Intuitive app
S2M are working with a FinTech who have created a unique financial product to help thousands of people better manage their finance, and is currently scaling the company to the next level!

They are looking for a Data Engineer to join, and looking for someone who wants to be hands on, with opportunity to grow the team in future.

Role:

Looking for people with strong AWS experience. You will need passion for data and a cloud, through which you will help a rapidly scaling Australian FinTech establish their data infrastructure from the ground up.
5+ years’ experience as a data engineer within the data and analytics domain
A python 3.X aficionado who is very comfortable creating and orchestrating AWS data pipelines with nothing but code
Strong project delivery toolset experience in open source data integration tools
Experience with processing large volumes of complex data including visualisation and insights generation
Ability to define and develop data integration patterns and pipelines
Ability to assess complexity of data (volume, structure, relationship etc.)
Hands on experience working with different databases (RDBMS, NoSQL, Blob storage etc)
Hands on technical expertise setting up DevOps automation
Hands on experience working technologies/platform e.g. AWS, Dockers, Containers
Experience building data profiling and data cleansing frameworks
Technical reconciliation and reporting
Knowledge and experience in end-to-end project delivery, either traditional SDLC or agile delivery methodologies (or hybrid approaches)
Exceptional communication, documentation and presentation skills
If this sounds like you, get in touch today - kate.gabb@s2m.com.au
3167410agsdf",3.1,"S2M
3.1",Sydney,-1,Unknown,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Analysts,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is seeking experienced and qualified Data Analysts to join our IT team based in our corporate office in Birtinya (Sunshine Coast) or at our meat processing facility in Kilcoy.
Key Responsibilities:
A mixture of data analysis and commercial skills to source, blend and analyse data to gain insight and answer key commercial questions
Working with strategic leaders to define and model Key Performance Indicators, and assist in building forecasting models
Working closely with data engineers and BI developers to specify data pipelines and report visualisation
Drive the creation and implementation of data quality business rule including data definition, governance and quality assurance
About You:
To succeed in this role, you’ll need to bring the following experience and skills:
Proven ability to derive insight and knowledge from data using commercial expertise is a strong requirement
Strong SQL and Excel skills are essential, along with strong data analysis and commercial insights
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Effective people communicator - engage with stakeholders on reporting needs, interpret requirements into visual solutions and train/deliver the outputs to the stakeholders getting signoff of acceptance
Bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking

How to Apply:
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kilcoy,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Network Data Engineer,-1,"Min 6+ years of experience in the relevant technologies
Australian Driving License for visiting remote locations / Data Centre for day to day technical work.
Managing Network devices (switches, routers, firewalls, load balancer, and wireless technology)
Performing MACD activities for all network devices.
Supporting BAU operation activities.
Proficient in performing in-depth details of technical troubleshooting, cause and provide recommendation to the client for incidents causing extended network outage to client’s critical locations.
Provide exceptional network services in terms of network support, break-fix, design and consulting, new projects, implementation.
Configure, administer, and document firewall infrastructure.
Manage the firewall deployment, rules migrations, and firewall administration.
Supporting Cloud Migration Activities from traditional to AWS/Azure.
Setting up VPN tunnel with Cloud and 3rd Party network devices.
Integrating and upgrading existing ISP bandwidth with support from ISP Vendor.
Setting up VPN profiles for Users.
Installing hot fix and patches to mitigate the security devices from attacks and bugs.
Reviewing and fine tuning the firewall rules and NAT rules.
Documentation and change control.
Mentoring, Motivating and Guiding support teams
Technical skills:
o LAN
o Wireless
o WAN
o MPLS
o Routing protocols (OSPF,BGP)
o DMVPN
o Azure cloud Networking
o Network Security
Fortigate Manager / Analyzer / Firewall
Cisco ASA
Firepower FTD
Cisco Any connect
Site to Site VPN
F5 Load Balancing and Scripting iRule
Job Types: Full-time, Contract
Schedule:
8 hour shift
Experience:
Scripting: 5 years (Required)
Data Network: 5 years (Required)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Required)",3.6,"Total IT Global
3.6",Sydney,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Engineer - Processing & Analysis,-1,"Job Description:
Design,build and maintain the ingestion system to support various types of data(e.g. User behavior, RDS, NoSQL db and others) to be ingested to the data warehouse more timely and accurately
Translate data requirements into scalable technical data service with low latency and high concurrency
Design,build and maintain the batch or real time data pipeline in production using Hadoop big data technology
Analyze and improve efficiency, scalability, and stability of the system
Define and manage SLA,Data quality for all data sets in allocated areas of ownership
Requirements:
Minimum B.S. degree in Computer Science or a related technical field
2+ years of working experience in programming languages,such as Java,Scala,Python
Familiar with Hadoop, Spark and Flink data processing, experience of TB data processing experience is a plus
Familiar designing and operating of a robust distributed system is a plus
Understand data mining or machine learning
Excited to work intimately with data
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"SYNOPSIS:
Lead Data Engineer
Applications close Sunday 8 November 2020
Ongoing
Contact name: Shyni Sasikala
Phone: (02) 6249 9048
Email: Shyni.Sasikala@ga.gov.au

The Data Policy and Informatics section within the Digital Science and Information branch creates, implements, and promotes policies, platforms and tools that improve and support the quality, discoverability, accessibility, and general usability of Geoscience Australia’s science data products. The section consults with internal and external research, government and industry partners to establish collaborative data frameworks, architectures and models within Geoscience Australia (GA) and across broader national and international communities of practice. The section innovates, builds and maintains tools, systems, processes and governance that enable digital data management, cataloguing and open data delivery.
GA makes accessible a wide range of geoscientific and spatial data to a wide variety of stakeholders in multiple formats, and in recent years GA's data volumes have grown exponentially. GA is focussed on making its data and metadata assets accessible so that they can be used in machine to machine interactions for data analytics and other applications in environments that range from High Performance Computing (HPC), through high-end cloud servers, to mobile devices.
We currently have two opportunities for Lead Data Engineers in the Informatics team. The Lead Data Engineer is responsible for innovating and exploring new technologies that will advance GA’s science goals and maximise the uptake and use of GA’s science data. The Lead Data Engineer reports to the team’s Assistant Director but also works closely with other developers, data scientists and engineers within the Digital Science and Innovation (DiSI) branch, as well as diverse stakeholders both within and external to GA.",3.9,"Geoscience Australia
3.9",Canberra,-1,501 to 1000 Employees,2001,Government,Federal Agencies,Government,$100 to $500 million (USD),-1
Data Engineer,-1,"The Seven Network is part of Seven West Media, one of Australia’s most prominent media companies, with a market leading presence in content across broadcast television, online and in print. Comprising some of Australia’s most renowned media brands, SWM includes not just Seven Network and its affiliate channels 7two, 7mate, 7flix and BVOD offering 7plus, but also 7NEWS.com.au, The West Australian, The Sunday Times and more.
At Seven we are here to bring all Australians closer to the moments that move us - we’re first on the scene, with our finger on the pulse, on demand, in the moment. Together, we’re responsible for creating and sustaining authentic Australian engagement.
A new and exciting opportunity has opened for a Data Engineer to join the Audience Intelligence team. Based in Sydney and reporting to the Head of Data Enablement, you’ll be responsible for:
Implementation of end to end data solutions to support Data Strategy for the SWM group.
Work closely with the Data Solution Designers to develop and maintain scalable data pipelines and build out new file and API based integrations to address requirements from the various business stakeholders.
Collaborates with engineering, analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organisation.
Work on Data Preparation for analytics and data scientist team members and assist them from an engineering perspective in building and optimising the models including building the automation of the end to end workflows
Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.
Perform data analysis required to troubleshoot data related issues and assist in the resolution of production data issues.
Work effectively with vendors for successful delivery of projects and acceptance of the solution
Work on Delivery projects using Agile Software Development methodologies
We are looking for someone who has:
Bachelor's degree in computer science, computer engineering or other technical discipline is essential
Proven experience working as a digital analytics specialist
Extensive experience with digital analytics implementation (e.g. Google Analytics, Snowplow, Adobe Analytics) and BI processes and visualisation platforms
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience in ETL and building and optimizing ‘big data’ pipelines and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Experience with big data tools: Hadoop, Spark, etc., AWS cloud services: EC2, S3, Lambda and familiar with version control systems: Git
Strong coding skills with knowledge of Unix/Linux and scripting languages such as Unix Shell scripting, Python desirable
Experience supporting and working with cross-functional teams in a fast-paced environment.
Ability to multi-task and problem solve with changing demands and priorities
Ability to work under pressure to meet deadlines and detail oriented
Your success is our success: we will provide you with opportunities for you to keep learning and growing, enabling you to challenge and develop yourself. In return, we offer a benefits program that has something in it for everyone.
Seven West Media is an equal opportunity employer and we are committed to creating a diverse and inclusive workplace.
Recruitment Agencies: Seven West Media does not accept any unsolicited agency resumes and will not be responsible for any fees related to unsolicited resumes.
Advertised: 19 Oct 2020 12:00 AM AUS Eastern Daylight Time
Applications close:

Back to search results",2.5,"Seven West Media
2.5",Sydney,-1,5001 to 10000 Employees,1956,Company - Public,TV Broadcast & Cable Networks,Media,Unknown / Non-Applicable,-1
BICON Rules Engineer,-1,"APS 5 - $73,299 - $80,410 per annum plus superannuation
Biosecurity Plant Division
Canberra, ACT
Play an active role in managing biosecurity risk to Australia
Work in a motivated and professional team with a wide range of skills and backgrounds
Full training provided

Who we are
The BICON Content Development Team maintains and improves the Biosecurity Import CONditions database (BICON) content to allow external clients to understand and comply with their biosecurity obligations and internal clients to effectively manage biosecurity risk and regulate imports. We work collaboratively with internal clients to comprehend and implement their BICON content requirements and optimise the use of BICON to publish clear import requirements and onshore management support procedures to effectively manage biosecurity risk.

The Jobs
Key duties of these positions include:

working with business content (import and permit conditions) and import programs to understand and construct decision tree structures in the BICON database, in accordance with system design and authoring conventions
executing changes to import and permit conditions in alignment with service standards while complying with system rules and authoring conventions
providing technical advice through various formats on the most appropriate means of authoring BICON content to achieve import program and stakeholder objectives
using workflow management tools to maintain detailed records of changes to import conditions and key decisions
performing administrative tasks including system reporting, data analysis and scoping tasks for the BICON content change work program
contributing to the development and maintenance of instructional material, authoring conventions and courseware
clearly documenting and reporting system issues
developing and maintaining effective working relationships with internal and external stakeholders.

What we are looking for
Knowledge and experience
Experience working with complex IT systems.
Experience working collaboratively and as part of a team.
Knowledge of the role of biosecurity is preferred but not essential.

For additional information, please read the Job Description below.
Candidate Information Package docx Opens in new window",3.9,"Department of Agriculture & Water Resources
3.9",Australia,-1,5001 to 10000 Employees,-1,Government,Federal Agencies,Government,$500 million to $1 billion (USD),-1
Cloud Data Engineer,-1,"Job no: 509605
Work type: Permanent Full Time
Location: Melbourne, Canberra, Sydney
Do you embrace digital disruption?
Do you love solving complex problems, designing sophisticated solutions and building innovative technology?
Do you believe in creating powerful actionable insights from Data and Analytics?
Do you want to work in a diverse and flexible working environment?
KPMG is one of the most trusted and respected global professional services firms. Through depth of expertise, clarity of insight and strength of purpose we help our clients solve complex challenges, steer change, strengthen, transition and grow. We are a team based practice and this extends to our clients whom we work and collaborate with, in solving complex problems. Together, we design, innovate and implement, providing enduring advice that support our clients and the services they deliver. Our clients vary in size and come from a diverse range of sectors – all sharing in a common goal: to embrace change and deliver services that make Australia a better place. We are looking for talented individuals who would like to join us on the journey.
KPMG’s Digital Delta Team
We re-imagine and re-invent organisations to become world class digital enterprises using advanced technologies, data and human insights. We help organisations to embrace Digital Strategy, Artificial Intelligence (AI) & Cognitive, the Internet of Things (IoT), Data, Analytics & Modelling, Mobile App & Web, and User Experience (UX) & User Interface (UI) and more.
We work with clients to:
Formulate strategies that re-imagine organisations
Harness innovation from the 4th industrial revolution
Actioning insights from trusted data to consistently and quickly make clear decisions
Build adaptive organisations
Thrive as a connected enterprise – front, middle and back office
This is how you’ll contribute:
We are looking for ambitious Data Engineers who are passionate about helping clients define bold ambitions and deliver on them. Joining our team will take you on a journey of personal and technical growth and provide the opportunity to inspire confidence and empower change.
As a Data Engineer you are the designer, builder and manager of the information or ""big data"" infrastructure, preparing data for analytical or operational use. You will design, construct, test and maintain a data pipeline to pull together information from different source systems; integrating, consolidating and cleansing data; and structure it for use in individual analytics applications.
The KPMG Difference
Our people are focused on creating a diverse and dynamic environment that embraces and values differences. We value the variety of unique experiences, qualities and characteristics our people possess and we share and learn from each other.
We are proud to be consistently recognised as an employer of choice for women, and for our achievements in LGBT+ workplace inclusion.
Our commitment to ‘Flexibility’ allows our people to manage the changing demands of work, personal or family life. Explore the links below to hear our people share their experience @ KPMG:
Flexibility empowers wellbeing
Flexibility enables contribution to the community
Flexibility inspires technology & innovation
Flexibility supports family

Make KPMG the clear choice for your career and be Extraordinary!

Advertised: 09 Sep 2020 AUS Eastern Standard Time
Applications close:",3.8,"KPMG
3.8",Sydney,-1,10000+ Employees,1987,Subsidiary or Business Segment,Accounting,Accounting & Legal,$2 to $5 billion (USD),-1
Computer Network and Systems Engineer,-1,"Duties Include but are not limited to:
Tasks Include:
analysing, developing, interpreting and evaluating complex system design and architecture specifications, data models and diagrams in the development, configuration and integration of computer systems
researching, analysing, evaluating and monitoring network infrastructure to ensure networks are configured to operate at optimal performance
assessing and recommending improvements to network operations and integrated hardware, software, communications and operating systems
providing specialist skills in supporting and troubleshooting network problems and emergencies
installing, configuring, testing, maintaining and administering new and upgraded networks, software database applications, servers and workstations
providing network programming in support of specific business needs and requirements
preparing and maintaining procedures and documentation for network inventory, and recording diagnosis and resolution of network faults, enhancements and modifications to networks, and maintenance instructions
monitoring network traffic, and activity, capacity and usage to ensure continued integrity and optimal network performance
Skills and Experience Required:
Must have experience working in a Managed Service environment
Demonstrated experience in IT Networks and Data Centres
Understanding of systems and architectures to meet client needs
Experience in Help Desk including break / fix
Effective and timely documentation
Effective Task Management Skills
Be solution and outcome focused and willing to learn new technologies
Excellent communication skills with staff, clients and partners
Time management, ability to prioritise and deliver to schedule
Experience with N-Able and Connectwise desired
Open Cabling license desired
Job Types: Full-time, Permanent
Salary: $30.00 per hour
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,Trans-plant training,Canberra,-1,-1,-1,-1,-1,-1,-1,-1
Software Engineer (Data),-1,"If you are looking for an opportunity to make a real impact with smart people who are genuinely doing things differently then you've come to the right place! We're growing our data engineering capabilities and are looking for awesome data engineers to join our team.
With our diverse range of clients and projects, no day will look the same - but here's a great snapshot of what you'll be doing:
Work with some of the best Data Scientists and Engineers to deliver production-grade AI and Machine Learning systems as we deliver client projects from inception to production.
Consulting with our clients and working with them to build modern data systems using the 'best of' technologies and principles.
Advising clients on data strategy, architecture and technology.
Applying best software engineering practices in coding, monitoring and alerting, using CI/CD, TDD and cloud architectures.
Working over a wide range of big data tools and environments: not limited to; Apache Kafka, Spark, Python, Scala, Hive, Airflow, AWS EMR & Glue, GCP Dataproc & Dataflow, BigQuery, Snowflake, Redshift.
Who are we?
Glad you asked! We are Eliiza. Data science. Engineered for scale.
We are a passionate team of data scientists and engineers who apply data science and machine learning to solve real-world problems. Our mission is to create a bright future for Australian businesses and society in a world increasingly influenced by intelligent technologies.
We've created a culture that values diversity where people can truly be themselves! We care a lot about growing the Australian AI community in a positive direction, and we're doing several things to try and achieve that:
We provide opportunities for underrepresented groups to work in AI through our associate and intern programmes
We organise and participate in a range of community events, reading groups and meetups
We produce the AI Australia podcast
We blog about topics we care about
We stream brown bag sessions to the broader community
We're also part of Mantel Group's 'house of brands' which means it's not just the Eliiza team you'll work with, learn from and see at social events - there's another 230 of us across DigIO, Kasna & CMD Solutions!
So you're ready for something new?
We're keen to know more about you! Our team is made up of a range of people, with different experience across a huge range of data driven skill sets.
We'd love to hear from you if you have experience with:
one (or more) core language(s), ideally Scala, Python or Java
one (or more) cloud platforms, AWS, GCP, Azure
ETL/ELT concepts and technologies e.g. Data partitioning, Hive, Spark
streaming data concepts and technologies, ideally Kafka (Kinesis, Beam or Pubsub will do)
We'd be over the moon if you:
Experience with distributed/columnar databases (e.g. Snowflake, Big query, Redshift).
Experience with any of a variety of databases e.g. RDMS, NoSql, Columar, Distributed, Time series, Graph.
Knowledge of job orchestration and scheduling. Any experience with Airflow, Luigi or Oozie.
Experience with containers and container orchestration (Docker, Docker Compose or Kubernetes).
However, we value a diversity of skill-sets, and don't necessarily require that you're skilled with all of the above. If you feel you don't fit all the experience/skills listed above we still encourage you to apply or get in touch.
What's on offer if you join us?
We make sure you're always one step ahead by investing your learning and development, every year. We build our own training where it doesn't exist yet.
We hire smart people and get out of their way. By focusing on our five principles and not getting caught up in red tape, we trust you to get the job done.
You'll get all the tools you need - a new iPhone or Google phone, a new Macbook Pro or Dell, and a lot of branded swag!
But hold on, you mentioned a house of brands?
We certainly did! Mantel Group is an Australian-owned, 'house of brands' company with four technology businesses (Eliiza being one of them!) across Melbourne and Sydney. We're building a group of companies with open borders so we can support you to take on new skills without leaving an awesome team - we understand you won't have one job for life!
We may only be just two years old but Mantel Group has already been recognised #9 in the 2020 Best Places to Work in Australia and #4 in the AFR's 2020 fastest growing new companies.
Keen to chat?
Click ""Apply"" to share your details with our talent team, and we'll be in touch.
In the meantime, check out 'how we hire' to find out what's in store if you're successful and get to know us better by visiting our website and following Eliiza on LinkedIn.",-1,Eliiza,Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Infrastructure Engineer,-1,"Job Description:
Design and grow the Shopee data platform to support a variety of big data applications using open-source technologies including Kafka, Hadoop, Presto, HBase, Spark, Hive, Druid, and our own creations. Some examples include a real-time data streaming platform, a unified query platform, a cluster management system, and a machine learning platform
Dig into the source code of some open-source big data system to get the whole control and familiar with the details, configurations, designs and source code. Develop and maintain the internal release of big data systems and components as the business requirements.
Keep close and overall monitoring for all the deployments of the systems, maintain the system’s stability, improve the performance, discover the performance bottlenecks, tracking and troubleshooting, cost optimisation.
Requirements:
B. Sci. / Ms / PhD in Computer Science or a related technical field
Familiar with at least one of these languages: Java, Scala, Python, Bash under Linux / Unix. Scala is a plus
Familiar with the use and compute logical of SQL
Knowledge about the Big Data Infrastructure system technology like Distributed File System, Distributed Computing, Distributed Database will be a plus
Hands-on experiences Hadoop, Spark, Kafka, and/or Presto will be a plus
Love to use and develop open-source technologies
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"Work on an award-winning, international technology!
Endless career opportunities
An innovative, friendly team of 300+
This role will be focused on the development of our existing ClaimLogik line of products as well as working on our new cloud-first, modern suite of applications.

Intelligent Thought, our technology business is scaling and shipping our software globally. Already profitable, part of a much larger group business, with investors such as Macquarie Capital and Envest – we are all set to deliver textbook disruption to the Insurance Industry. The growth of the platform, of our customer base, and the increasing industry demand have led to the need for this role to help the team scale.

Our Philosophy
Give each employee a sense of purpose and an environment for them to connect the importance of their role to delivering a service that matters to our customers.
Challenge the ‘why’ of traditional claims processes.
Keep it simple – do only what brings value and what matters to the customer
Enable employee decisions, empower our people
Responsibilities:
Create, extend and maintain ETL pipelines to form our data lake, data warehouse and analytics platform (currently using the Microsoft Azure set of tools and service)
Help define the optimal data pipeline architecture
Influence the tool selection, platform selection, data architecture and strategy which will transform the business to be truly data-driven
Understand, analyse and size user requirements
Work with different parts of the business to provide them with the insights they need to deliver the best results
Skills & experience:
Degree or qualification in computer science or related
Advanced knowledge of relational database, including query authoring and query optimisation (MS SQL Server and PostgreSQL).
Experience building and optimising ETL pipelines
Experience designing complex data models
Experience working with cloud platforms (Azure or AWS)
Efficient time management and organisational skills
High attention to detail and accuracy
Effective communication skills to build strong working relationships; both written and verbal
Proactive and results-driven
Why Claim Central?
Claim Central Consolidated is a global insurance industry leader across, claims management, insurance technology and data and analytics. Currently operating in the United States, Australia, South Africa, Italy and New Zealand, we have pioneered digitally connected claims management services across the globe. Claim Central is a disruptor and thought leader in the industry and we were recognised as the Australian Financial Review’s 8th Most Innovative Company in Australia in 2016. This business is in a period of unprecedented growth, transitioning our technology and services into multiple geographies at a rapid pace. Our unique culture is based on teamwork, collaboration, trust, respect and performance. We also offer many benefits apart from our exceptional team culture; including flexible work arrangements, and continued professional development.

Be a part of this journey in a career-defining role.",-1,Claim Central,Matraville,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer - AI/ML,-1,"Our client provides services to a major industry across the country. The business is still early in it's days of technology development and the environment is greenfields in nature (no pun intended), effectively working like a start-up.

Their data and analytics team have worked and built leading and bleeding-edge technologies in this space and what they have created so far may be game-changing. From a machine learning perspective, the progress they have made to the business has already seen proven success in changing the future of an industry that will have positive consequences for all those involved.

You will have previously worked in a technical capacity in the data and analytics space and have experience working with an organisation where machine learning has been implemented, not just a concept that the business talks about having or the technology team would love to have. The commercial experience you will have had in the ML field will be proven examples of where you have affected the way a business or industry used to perform, to the changes that have come about from this.

Technically, you will have extensive experience in the Microsoft space - Power BI, Azure etc and you will have previously mentored and coached junior members of the teams you have been part of.

This is a rare opportunity in Brisbane where the business has truly embraced and funded projects across the ML space and would be a great chance for those in the Data Development/Data Engineering field, who are looking to move into a Data Scientist role in the future.

Please send your application through if you would like to know more.",4.0,"Emanate Technology
4.0",Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Solution designer/ ETL Engineer & Data Modeller,-1,"We are looking for a Qualified and Experienced Solution Designer to join our client for a period of 6 months with a view to extend.
You will work closely with team members and your contribution will range across gathering and analyzing information, developing and documenting improved processes and work instructions and experienced DWH Lead with skills in requirement analysis, solution designing, developing, testing and supporting ETL solutions.
A hands-on solution designer, data modeler and ETL developer for Data Warehousing and ETL application transformation projects using Informatica PowerCenter.
Knowledge on AWS, S3, Redshift, Informatica BDM, and related technologies.
Experience working with IPython, PySparks, AuCuMo, Airflow, Jenkins, Github, Athena, JIRA, Rally, Spectrum, Glue, Flyway.
Good exposure on Oracle PL/SQL, aware of DBA activities, writing and performance tuning of complex SQL queries.
Contract length: 6 months
Job Types: Full-time, Contract
Salary: $650.00 – $800.00 per day
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,nducive,Melbourne,-1,-1,-1,-1,-1,-1,-1,-1
"Data Engineer, Wollongong NSW or Mount Waverley VIC",-1,"Company Description
BlueScope is a technically advanced supplier of steel and steel products in Australia. We are an inclusive organisation and every day we showcase our technology and expertise throughout the world.

Job Description
We are looking for two Data Engineers to join our IT team, based in Wollongong NSW or Mount Waverley VIC. Use your experience in analytics to unlock business value, enabling use of big data for insights and decision-making.
Reporting to the Data Product Owner for our Australian Steel Products (ASP) business, this position will support strategic goals related to data. This will see you:
Gather business and technical requirements with the view to deliver outcomes;
Develop and implement end-to-end data collection, consolidation, modelling and visualisation solutions;
Document metadata in a dictionary and catalogue;
Ensure consumers of such information understand its accuracy, timeliness, quality and sensitivity, so that it is used appropriately; and
Identify opportunities to enhance analytics.
What are the benefits?
Work in a supportive and collaborative team environment whilst we embark on a journey to transform the way our business uses data!
Our systems landscape is broad and diverse. You will be encouraged to think creatively to develop data solutions which solve real business problems.
Working in this role you will enjoy:
the chance to learn more about data science;
salaried remuneration with attractive superannuation options;
the opportunity to participate in a performance incentive scheme; and
access to further development and career opportunities with BlueScope.
Who are we looking for?
We welcome applications from professionals with experience in data analytics and/or programming. Supported by your knowledge of project delivery methods (e.g. Agile), you will demonstrate:
experience with data mining, wrangling, mapping and visualisation techniques (e.g. Azure Data Factory, Databricks and/or DevOps etc.);
well-developed ability in gathering business and technical requirements;
skills in developing and implementing collection, consolidation, modelling and visualisation solutions; and
a passion for sharing your knowledge and desire for ongoing professional development.

Qualifications

null

Additional Information
We're proud to have been named an Inclusive Employer for 2019–2020 by the Diversity Council of Australia. We believe that our people are our strength. Having a diverse and inclusive workplace enables us to improve our capability and ensure continued, sustainable success.
We know that workplace flexibility can mean something different to everyone. Under our B-Flex initiative all of our roles have some degree of flexibility. We encourage you to discuss your needs with us.
Applications close Sunday 25th October 2020.",3.3,"BlueScope
3.3",Wollongong,-1,201 to 500 Employees,-1,Company - Private,Construction,"Construction, Repair & Maintenance",$100 to $500 million (USD),-1
ETL Data Engineer,-1,"ETL Data Engineer

Join a team that’s changing how Australia lives, works, plays and grows
We want you to be the best version of you

Work with innovative teams and explore new technologies to help solve real-world problems.

A typical day as a Data Engineer

ETL / Big Data Engineering professionals will be responsible for guiding the full lifecycle of a Data solution, including:
Working in highly client-facing roles to contribute throughout the end-to-end delivery lifecycle of complex and large-scale digital solutions
Use case and business case development
Support existing and new applications utilizing in-depth technical and data knowledge. Troubleshooting complex issues and providing advisory services to improve the client’s data landscape
Help to streamline and simplify the clients’ complex data landscape by integrating different applications and data architectures
Implementation from requirements analysis, platform selection, digital architecture design, application design and development, testing, and deployment
Interstate travel may be required

Basic qualifications:
Bachelor’s degree
Experience across systems integration, information management, data management and architecture, and business analytics
Experience with being in a team focusing on large-scale, multi-release information centric projects
Experience with waterfall and agile delivery and run / application support functions
Part of a team working on End to end implementation of at least 1 big data project

Preferred Skills:
Hand on experience in Data warehousing using ETL tools such as DataStage, Autosys and TeraData
Hands on experience in ETL job development with multiple stages like sequential file, Transformer, Lookup, join, sort and Database stages.
Strong hand on skills in design, development and implementation of various data remediation, Data migration, data integration techniques.
Strong hand on data modelling experience.
Strong hands on experience in database performance tuning including complex query optimizations and physical database tuning using Teradata.
Understanding of architectural designs and strategy related to data migration, data cleansing, data quality and data consolidation.
Proven data analysis, requirement gathering and problem-solving skills
Exposure to Unix environment and shell scripting.
Experience in Banking and Financial services industry
Desirable: Knowledge of cloud computing infrastructure (e.g. Amazon Web Services EC2, Google Cloud, Microsoft Azure)
About Accenture

Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. We combine unmatched experience and specialized capabilities across more than 40 industries — powered by the world’s largest network of Advanced Technology and Intelligent Operations centers. With 513,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises. Visit us at www.accenture.com.

Accenture is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, marital, domestic or civil partnership status, sexual orientation, gender identity, or any other basis as protected by applicable law.

Vera Goga is the Recruiter managing this role. As the team experience high volumes of applications, we appreciate your patience to allow for a fair and timely process.",3.9,"Accenture
3.9",Sydney,-1,10000+ Employees,1989,Company - Public,Consulting,Business Services,$10+ billion (USD),-1
Student Engineer,-1,"The candidate will have the ability to:
Undertake onsite inspection to collect asset condition data based on the relevant engineering standards and technical guidelines;
Undertake desktop analysis to evaluate the condition and performance of the assets;
Provide the appropriate information, advice, engineering input and support services for the sustainable management of Council’s stormwater and transport networks.
Qualifications:
The successful candidate will be enrolled in a Bachelor of Engineering with a minimum of two years completed.
Position Number: 100678
Position Hours: Fixed term (3 months), hours will be negotiated with the successful candidate, maximum of 75 hours per fortnight.
Salary: Schedule A, Salary Point 4.0. $28.64 per hour ($55,853.45 per annum, pro-rata) in accordance with Glenorchy City Council’s Enterprise Agreement 2016
Please note that all successful applicants will be required to provide a current National Police Check prior to commencement of employment.
For further information on this position, contact Patrick Marshall, Senior Civil Engineer on (03) 6216 6800.
How to apply: Applications for this position must be lodged on this submission site or on the Glenorchy City Council website www.gcc.tas.gov.au - Careers page.
To be considered for this role, all applicants must address the key selection criteria in the and provide a current resume. A copy of the position description can be found by clicking the below hyperlink or on the Glenorchy City Council website.
Applications close at 8pm on Sunday, 1st November 2020
- Student Engineer",4.0,"Glenorchy City Council
4.0",Glenorchy,-1,501 to 1000 Employees,-1,Government,-1,-1,Less than $1 million (USD),-1
Data Engineer involving DevOps,-1,"Data Engineer involving DevOps
Axiom Technologies is an Australia based entity with the history of providing Managed IT solutions to medium to large scale enterprises globally. Please visit our website for more information about what we do at www.axiomtechnologies.com
Axiom Technologies is an Equal Opportunity Employer and encourage applicants from all backgrounds and gender to apply, including, Aboriginal and Torres Strait Islander candidates
Job Requirements:
8+ years IT experience, with at least 5+ years of “Data Engineer/Deveoper” focused titles/roles,
Data Tools: Hands on experience with Apache Beam.
Testing: Hands on experience with automated testing activities/outcomes
DevOps: Experience with the processes involving Microservices facilities for artifacts developed
Platform/OS: Mid-range/Unix
Languages: Unix (Shell) Scripting/commands, SQL, Python
File formats: Text, CSV, Parquet, JSON, XML
Scheduling: Jenkins, Airflow
Auto Scripting: Designing/creation of scripts for repetitive activity. E.g. Unix scripting/SQL
Big data: Exposure to Data Lake Concepts, Hive (Schema), HDFS
Source Control tools: GIT
Delivery Models: Agile, Scrum
Ingestion Design: Create/assess Source/Target data mapping designs
Frameworks: Development and delivery frameworks
Activity Reporting/Repository: Jira, Confluence.
Quality: Accuracy and attention to detail
Industry: Financial Services/Banking
Solutions: Define solutions from High level to detail design to address automating ingestion activity. Facilitate/confirm requirements from product owners, business team members and technical associates,
Process Automation: Automating processes in file management, testing data in files, analysis and design, configuration management.
Script Automation: Ability to design/create scripts to automate/improve data copy/migration/ETL for any repetitive activity.
Languages: Java, Python
Scheduling: Control-M
Databases: Relational. E.g. POSTGRESS, Oracle – as a ETL developer
File Formats: Mainframe – experience with referencing its data formats/copybooks
Big data: Experience referencing/using Hive (Schema) to access data in HDFS
Metadata management tools: MDM, EDC and Axon
Performance: Assess, recommend, improve mappings, SQL queries, Batch feeds
Automation Tools: Other tools that may add value to an automation program and generally support development. E.g. API, REST, JDBC, Webservices, Message Queues/Load balancer,
Cloud: Experience with processing of data files to be ingested/stored in the Cloud, preferably with AWS.
Prod Support: Experience in a production support role performing root cause / impact analysis – under time constraints
Experience in a similar role
8+ Years
What next?
If you are looking for that next challenge in your career and wish to apply for this role, please forward your resume to careers.au@axiomtechnologies.com",2.0,"Axiom Technologies
2.0",Melbourne,-1,1 to 50 Employees,-1,Company - Private,Industrial Manufacturing,Manufacturing,Less than $1 million (USD),-1
Data Engineer,-1,"About the Role
We are on an exciting digital journey so it’s a great time to join ME! We are seeking a Junior Data Engineer who enjoys rolling up their sleeves, learning and growing. As part of our Enterprise Data Team, you will ensure fit for purpose data warehouse solutions are built for use across the bank and by utilising best practise ETL standards, whilst ensuring the data is trusted by our BI developers and key business consumers. Oh, and you’ll get to work on Microsoft technology stack too!
You will be involved with investigating data issues, keeping data feeds flowing and collaborating with different projects across the bank to deliver quality data solutions. How important does that sound? What’s even more important is this role contributes directly to our overall business strategy through the provision of data to enable analytics & reporting, as well as supporting business and decision system processes.

About You
You’re naturally a highly motivated and energetic person who thrives in a dynamic, ever-changing collaborative team environment. Ideally you have previous experience as an ETL developer, Data Engineer or a BI developer, and if you have a degree in computer science or similar it would really put you ahead of the rest.

With your knowledge of SQL coding, data modelling, understanding of data warehouse concepts, plus experience of working on complex ETL solutions, you’re ready to expand your horizons and launch your career into the world of IT at ME.

About ME
We’re not like other banks.
ME was created by the industry super funds to be different from the pack – with a core purpose to help all Australians get ahead financially – no conditions, asterisks or exceptions. And we know that looking after customers starts with taking care of our people.
We believe everyone deserves the same opportunities in life, regardless of gender or identity, sexuality, ethnicity, religion or disability ‒ with internal affinity groups.
Perk ME up
Once you get your feet in the door at ME, we’ll put them both in your very own ME-branded Converse shoes. You’ll also get the following financial, health and fun perks when you join the team:
4U Extras portal (discounts and cashback on 100s of items including cinemas, shopping and gym memberships
10% Myki discount
Purchased Leave programme
Internal wellness programme (Mindfully ME)
Professional education through LinkedIn Learning
Novated Leasing
Professional membership reimbursements
Health checks
Financial education (To help you manage your money smarter)
LGBTIQ+ and Women at ME affinity groups

I want those Converse shoes (and the role)
Can’t see a closing date on the advert? That’s because we’re pretty efficient here at ME and we may start looking at applications sooner rather than later, so if this role sounds like your jam, be sure to apply by submitting your resume today.

Should an applicant be the preferred candidate, background checks (including police checks, reference checks, ASIC banned and disqualified persons and bankruptcy checks) will be completed prior to the candidate's employment being confirmed. The outcomes of the background checks do not automatically bar candidates; however will be assessed against the inherent requirements of the job.
Back Share
Apply Now",3.0,"ME Bank
3.0",Melbourne,-1,501 to 1000 Employees,-1,Company - Private,Banks & Credit Unions,Finance,$100 to $500 million (USD),-1
Software Engineer - Machine Learning/Data Science,-1,"Zendesk is looking for a Software Engineer - Machine Learning/Data Science for a full time position in our Melbourne office.
As part of our engineering team, you will work at a scale where the challenges start to get seriously interesting. Our global engineering team is widely dispersed over the world, with people across nearly every continent. You will get a chance to do cool things with a diverse bunch of people while working in the Melbourne office that is home to Zendesk’s first machine learning (ML) research team.
The Data Science Team, together with Data Engineering, have built Satisfaction Prediction, Answer Bot and Content Cues — products that use Machine Learning (ML) and Artificial Intelligence (AI) to help our customers work more efficiently.
What you get to do every day:
We’re currently looking for someone to join our team as we research, develop, and productionise Machine Learning and Deep Learning models. In addition to frequenting Melbourne’s finest purveyors of coffee, ramen, and bulgogi, you may find yourself:
Building machine learning models including neural networks in TensorFlow
Writing and deploying production-grade Python
Querying and constructing datasets in AWS Athena, Spark
Evaluating and responding to real-world model performance
Scaling your ML to millions of predictions per day
Presenting your work to a broader audience
Watching your algorithm help Zendesk’s end-users
What you'll bring to the role:
A strong foundation in a quantitative discipline (e.g. machine learning, statistics, bio/eco/etc-informatics, econometrics, etc) is critical for this position. While experience in deep learning and natural language processing would be beneficial, your best qualities are:
dedication to continuous learning
collaborative work attitude
strong communication skills
You should also be comfortable with at least one programming language, such as Python, R or Scala.
Application Deadline: 18/11/2020
Job Types: Full-time, Permanent
Salary: $85,000.00 – $110,000.00 per year
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Temporarily due to COVID-19",4.5,"Zendesk
4.5",Melbourne,-1,1001 to 5000 Employees,2007,Company - Public,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),-1
Software Engineer (Machine Learning),-1,"About the Role
AdelaideMRI is building a medical reporting tool. We require an engineer to work primarily on machine learning projects to improve reporting speed and report comprehensiveness.
You will perform data analysis of medical report datasets and image datasets to infer sentence recommendations, image classifications, or other actionable results for the doctors.
Skills and Experience
Background in machine learning or image processing
Qualifications in Computer Science, Software Development or Engineering or equivalent experience
Bonus points for Python
No prior medical knowledge is required.
This position offers flexible hours and work arrangements.
Job Type: Full-time
Experience:
Software Engineering: 1 year (Preferred)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Yes",-1,Adelaide MRI,Australia,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Hey there, we’re PEXA!

We started as an idea: to deliver a single, national e-Conveyancing solution. We collaborated with the industry to create a national electronic lodgement and settlement platform: PEXA. From our humble beginnings, we’ve now grown to more than 320 employees across 5 different states. We’re still expanding at a rapid rate and constantly challenging ourselves to create great experiences for our members as they transition to fully digital conveyancing.

Why become a PEXArian?

Great question! Being a PEXArian is so much more than just a job. We are passionate, motivated & unashamedly enthusiastic at PEXA - we love what we do and we’re proud to admit it! Creating brilliant member experiences wouldn’t be possible if we didn’t also strive to create an amazing employee experience. Alongside our members, our employees are at the heart of everything we do.
Here’s a snapshot of what your life at PEXA could look like:

Your growth:
We encourage you to hit your personal and professional Learning & Development goals with our tailored programs and tools.

Your wellness:
We care about your holistic well being - a fully stocked kitchen, four wellness days, a $250 wellness subsidy as well as lunch and learn sessions to support your financial well being.

Your work/life blend:
We know that work is just one aspect of your life, we want to help you create your ideal work/life blend, rather than squeezing in life around work.

Your family:
With a range of benefits aimed at supporting your family including access to a subsidised school holiday program, extended parental leave and flexi-time to support your return to work, superannuation payments for unpaid parental leave for primary carers and a childcare allowance for pre-primary aged children, when we say, ‘welcome to the family’, we really mean it!
The impact you'd drive:
The successful candidate will be responsible for developing, and maintaining infrastructure to support the delivery of new and existing products. They will also be contributing to establish the rules and frameworks for obtaining the required approvals for new products.
On day one we’d love you to have:
Experience with Python, Spark
Event streaming/sourcing with Kafka or AWS Kinesis
Experience with data structures, formats and data security best practices
AWS experience (e.g CloudFormation, S3, ECS, Lambda, SQS, IAM, KMS, DynamoDB, Glue, Athena)
Query construction and optimisation (e.g. SQL, Elasticsearch, Splunk, DynamoDB)
Git, version control practices, and continuous integration/delivery servers
PyUnit and unit testing frameworks
Production release cycles and maintenance
Collaborating with technical and non-technical teams
Even better:
Agile methodology/delivery
GraphQL
Modern frontend technology (e.g. ReactJS, TypeScript)
Machine learning frameworks and tools (e.g. TensorFlow, PyTorch)
OAuth 2, SAML 2, JWT
Data visualisation and exploration tools (e.g. Jupyter notebooks, Tableau)
AWS SageMaker
Sounds like you?
If this role sounds like you, apply today to have your application reviewed ASAP!",3.9,"Property Exchange Australia Limited
3.9",Melbourne,-1,201 to 500 Employees,2010,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Ongoing position
Full time
Based in Sydney, NSW
Who we are
Australian Red Cross is part of the world’s largest humanitarian organisation. Our aim is to improve the lives of the most vulnerable people in Australia and across our region.
About the role
The Data Engineer role will sit within the Data and Integration Squad in IT and will own (design, implement and support) the AWS Big Data technologies such as the Data Lake and Data Warehouse and support the organisation in growing the data analytics capabilities at Red Cross. In addition to this, the data engineer role will also administer the Power BI tool and support the implementation of the data mastering capability.
What you will bring
Experience building and optimizing data pipelines, architectures and data sets.
Experience in dimensional modelling and building data vaults
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with structured, semi-structured and unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Why work for us?
Work for purpose and know that your work assists Red Cross support and empower people and communities in times of vulnerability.
Generous salary packaging options available that can increase your take home pay.
Further information
To find out more about this opportunity please see the position description below or contact Sharath Kumar Gurram on 02 8651 8839.
Position Description: Position Description - Data Engineer .pdf
Applications for this position will close at 11:55pm Thursday, 5 November 2020.",4.1,"Australian Red Cross
4.1",New South Wales,-1,1001 to 5000 Employees,-1,Nonprofit Organization,Industrial Manufacturing,Manufacturing,$500 million to $1 billion (USD),-1
Junior Fullstack Data Engineer (Python and React),-1,"Formbay is the leading Renewable Energy Certificate Trading company in Sydney. We provide Digital Workflow and Compliance solutions in the renewable energy industry and document processing.
Thanks to our meteoric growth and our commitment to be the best at all we do, we've identified the need to bring on board a new Junior Fullstack Data Engineer.
Reporting to our Principal Machine Learning Engineer, you will help build Machine Learning pipelines for our existing Digital Workflow and Compliance solutions to automate fraud detection and document processing over terabytes of photographic and documentary data – including documents, photos, GPS data and aerial/satellite photography.
Our stack is based on Python, JavaScript, Dask, Tensorflow, CUDA, Nix/NixOS, AWS, Docker, PostgreSQL and more – familiarity with these applications will give you a leg-up on the competition.
Our ideal candidate will have the following competencies:
SQL
Python
JavaScript/TypeScript
Our candidate must also be comfortable working with Linux.
Located a stone's throw away from the Queen Victoria Building in Sydney's bustling CBD, we are centrally-located with easy access to public transportation, bars, cafes and fine dining.
Formbay will provide flexible working hours, a generous remuneration package and the opportunity to work on a world-first software solution are what we can offer you. Free, twice-weekly gym sessions and really, really good coffee are also available.
No hiring/recruitment agencies need apply.",5.0,"Formbay
5.0",Sydney,-1,1 to 50 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is an experienced and qualified Data Engineer to join our IT team based in Birtinya.
Key Responsibilities:
Create and maintain data pipelines and or ETL scripts
Create and maintain data integration including API and Batch interfaces
Performed detailed data analysis
Create and maintain corporate data models
Create and maintain data visualization using Qlik.Sense , PowerBI or Simliar Toolset
Experience in defining, building and maintaining data virtualization and/or star schema data warehouses
Maintain, tune and optimise database, integration and visualisation toolsets
ABOUT YOU:
To succeed in this role, you’ll need to bring the following experience and skills:
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Excellent communication skills both oral and written, with an ability to bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking
Experience with data analysis and modelling will be beneficial

How to Apply
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kawana Waters,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Graduate Data Science / Engineer,-1,"The NRMA is an organisation looking to the future, and right now, we are on the lookout for people who can help us reach our goal: to continue to shape the way Australians move, for the next 100 years and beyond. www.mynrma.com.au.
Everyone new to the team, along with our current staff, will temporarily work from home until it is safe to return to our offices. All interviewing and on boarding will be done virtually due to COVID-19.


Your opportunity
As Graduate Data Scientist or Engineer you will be part of the Data Engineering team delivering cloud data transition program for business initiatives and supporting the entire data platform build.
Your key responsibilities will be to:
Implementing Concepts of Data Warehousing, Data Mart creations within Cloud
Use of SQL for data analysis and insights
Building AI/Machine Learning prototype for implementing and supporting existing algorithms
Data Analytical reports build, using different tool sets


Requirements for Success:
Relevant Degree - Computer Science, Computer Engineering, Software Engineering, Data Science
Excellent SQL skills and demonstrated working knowledge in Python
Demonstrated understanding in data structure and algorithms.
Knowledge and concept of data warehousing methodologies
Any reporting tools experience Tableau or Oracle Analytics Cloud, Looker is desirable
Exposure to Google/AWS/Azure/Oracle any cloud based platforms is desirable
Good communication and interpersonal skills

If you have the required skills and the passion to join our high performing team, please apply today.

Employee Benefits
To ensure our employees feel valued, empowered and celebrated we provide a range of employee benefits including:
50% discount on all NRMA insurances
Free Roadside Assistance
12 weeks paid primary and 4 weeks paid secondary parental leave
Free NRMA Blue Membership
At the NRMA Group, we are People Moving People and diversity and inclusion are part of our DNA. Together, we continue to build an inclusive culture that encourages, supports and celebrates the diverse voices of our employees. It fuels our innovation, promotes flexible ways of working and connects us closer to our members and the communities we serve.",2.5,"NRMA Motoring & Services
2.5",Sydney,-1,501 to 1000 Employees,-1,Nonprofit Organization,Casual Restaurants,"Restaurants, Bars & Food Services",$500 million to $1 billion (USD),-1
Data Centre Engineer,-1,"We are a leading world group that provides low-carbon energy and services. To tackle the climate emergency facing us all, our aim is to become the world leader in the zero-carbon energy transition ""as a service"" for our clients – particular for companies and regional authorities. We use our expertise in our key business areas (renewables, gas, services) to provide competitive and bespoke solutions.
The Data Centre Engineer will be employed as part of a 24/7 ongoing shift to coordinate and monitor third party service providers, maintain the data centre facilities and infrastructure plans, coordinate the implementation of customer requests within the data centre and monitor systems, all in accordance with the Contract KPIs and SLAs.
Coordinate and monitor third party service providers for regular maintenance & testing, service faults & call outs, ensuring works are performed in accordance with Contract SLAs
Monitor and maintain the data centre facilities and infrastructure plans and documentation, including electrical, mechanical, hydraulics, fire and BMS/EMS systems
Coordinate the implementation of internal and external customer requests within the data centre
Perform scheduled plant checks and minor maintenance works
Ensure all Work Order requests are raised and closed in a timely manner
Conduct inductions for staff, vendors and contractors
Ensure all work permits for vendor works are raised and closed
Perform inventory checks on all equipment and critical spares

Qualifications
The selected candidate must be able to demonstrate:
Electrical or HVAC background, or Graduate Electrical or Mechanical Engineer
Passionate about quality work and career minded looking for a new challenge
Can commit to a day and night shift roster (2 days of day shift, then 2 days of night shift, 4 days off)
Ideally able to commence asap
As part of carrying out the duties of this role, it is mandatory to hold Australian Citizenship.

If you are interested and meet the selection criteria apply with an up-to-date resume via the apply instructions on this website.

ENGIE Services is an EEO employer, where all applicants are treated with fairness and respect and have equal access to the opportunities available.

We will not be engaging in the services of a recruitment agency to fill this vacancy and therefore request all interested candidates apply directly to this advertisement.

Job
: Maintenance
Primary Location
: Oceania-Australia-New South Wales-Erskine Park
Organization
: ENGIE Services Australia and New Zealand
Schedule
: Full-time
Nature of Responsibility
: Senior operational / administrative role
Job Posting
: Sep 11, 2020, 6:29:59 AM",3.7,"ENGIE Services Australia & New Zealand
3.7",Sydney,-1,5001 to 10000 Employees,1995,Company - Public,Energy,"Oil, Gas, Energy & Utilities",$2 to $5 billion (USD),-1
Senior Data Engineer,-1,"Senior Data Engineer, Temporary, SYDNEY - McKell

Job Title: Senior Data Engineer

Salary: SNSW Grade 9/10 - The package includes base salary range of $111,806 to $134,667, plus employer's contribution to superannuation and annual leave loading.

Location: Head Office – Haymarket

Employment Status: Temporary through till 30th June 2021


About Service NSW:

Service NSW is making it easier for people and businesses across NSW to access government services. The role designs, builds and analyses complex data from multiple sources to identify revenue, process and business improvement opportunities; providing new information and insights to the business to inform planning, continuous improvement and performance.

About the Role

We are currently seeking to appoint a Senior Data Engineer to deliver expert advice and services in the design of a Single View of Customer and data-related services to support the achievement of business outcomes and strategic goals. We support flexible working practices with staff working remotely during this time.

In this role you will:

Design, build and support a modern data platform based in AWS and vendor technologies.
Provide expertise on data modelling for Graph data model and Customer Data Platform (CDP).
Create data pipelines, load, transformation and reporting workloads in AWS.
Work with the latest data engineering technologies like Apache Kafka, AWS Kinesis, AWS Neptune, AWS Glue and AWS Athena.
Contribute to the design and decision-making of the right tool or platform for the job according to requirements.
Provide expert advice and guidance on data quality and data engineering best practices.
Support a “bigger than you can imagine” scale of data in production environments.
Design, develop and support a metrics-driven reporting solution and a meaningful business intelligence platform.
Document the solution design and support procedures of solutions.
Produce reports, visualisations and recommendations to answer complex business problems that are presented in the most appropriate format to ensure clarity for target audience.
Analyse and define new process improvement opportunities to support continuous improvement and business outcomes; providing advice to stakeholders, on ways to improve the efficiency and reliability of data products and services.
Be very responsive to the information needs of the business by corresponding to customers in a timely manner and provide support/solutions to issues raised.
Troubleshoot and perform root cause analysis on production issues. Identify and implement long term solutions to problems. Perform scheduled maintenance, release deployment and production support activities after business hours, from time to time.
Liaise with internal and external customers to discuss and gather requirements, solutions etc. and maintain a good working relationship with the stakeholders.


Skills and Experience Required:

Solid experience with workflow technologies designing and building data pipelines, data models and data stores.
Experience working within and an understanding of Amazon AWS ecosystem, including security and performance tuning.
Hands on experience working with different types of databases, with focus on Graph and NoSQL databases.
Experience with data streaming required. Having used Kafka and related technologies is an added advantage.
Sound knowledge and experience working with batch processing, data extraction and API integration.
Hands on experience with at least one programming language: Java, Python or scripting.
Demonstrated experience working in an Agile based, fast paced, complex environment within cross-functional teams.
Experience developing systematised insights, data analytics and reporting solutions is an added advantage.
Experience with interactive visualisation of data insights is an added advantage.


Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Salary Grade 9/10, with the base salary for this role starting at 111,806 base plus superannuation

Closing Date: 6th November at 9:59am - applications will be reviewed on a rolling basis, applications may close early or extend

Please apply online, direct applications submitted via email will not be considered.

The Department of Customer Service is proud to be an EEO Employer who are fully focused on equality and believe deeply in diversity of all identities making us different and a true reflection of our NSW customers. As an inclusive workplace, we support various employee resource groups, practice flexible work and workplace adjustment.

If you do require an adjustment during the recruitment process, please notify us on your application form.",3.2,"Service NSW
3.2",Sydney,-1,501 to 1000 Employees,2012,Government,State & Regional Agencies,Government,Unknown / Non-Applicable,-1
Data Engineer - Entry / Mid Level,-1,"Work with a great team on interesting projects customers
Gain more experience in AWS, Data, DevOps cloud operations
Got a working knowledge of AWS? We will teach you the cool stuff!

Itoc is seeking an up and coming Data Engineer to join our growing Data Team in Sydney.

This is an exciting role working with databases, data lakes, data warehouses, data transformation (Python SQL) and enabling AI/ML.

You will be implementing foundational, robust and production ready data platforms to enable business data-discovery, self-service, AI/ML functions across a range of client types and industries, allowing them to do more with their data.

You'll be responsible for:

Deploying data repositories such as lakes and warehouses.
Contribute to our growing portfolio of data solutions.
Ongoing optimisation and management of data platforms.
Development of transformational logic for data pipelines
Data evangelism. We want to show our clients how to follow the best practices for data.

Desired Skills and Experience

To take up the challenge, you will have a depth of skills and experience including:

1-2+ yrs of focused data experience working with SQL and/or NoSQL solutions
A solid education in Software Engineering or equivalent industry experience.
Anything Data focused preferred.
Ability to analyse business scenarios and associated data landscape to derive potential opportunities.
Strong foundation in Python and SQL
Working knowledge of APIs
Principle knowledge of the different relational database platforms and modern data storage techniques
Knowledge of the different aspects of data environments
Collect, store, process, verify consume
Experience with version management systems (such as GIT)
Working knowledge of AWS or another cloud platform - we will teach you the cool stuff.
Great communication skills, an ability to work closely with customers, developers and engineers and the confidence to present ideas in open forums.
Relevant tertiary qualifications and/or industry certifications.
Great communication skills, an ability to work closely with clients, developers and engineers and the confidence to present ideas in open forums.

While not required, a background in consulting and professional services is highly desirable.

Itoc Description

This is an exciting and challenging career opportunity to join the growing Sydney-based Data Team of a leading cloud solution provider where you will be given support to reach your long term career goals. You will be part of a team of cloud experts and will work in an environment of continuous improvement and learning delivering innovative cloud solutions across SaaS, online business and enterprise business.

On offer is a chance to join a team with a great working environment, in an organisation that values its employees and sees the value in ensuring they are engaged. Our team are clearly passionate about what they do, that's why we won the following awards:

Customer Obsession Partner of the Year 2015: ANZ Region
Customer Obsession Leadership Partner 2015: re:Invent

As an employer of choice Itoc offers competitive remuneration, training and development programs and a great working environment. We value a healthy work life balance.

The Perks

MacBook or Dell
Continuous internal learning that will provide training and career development opportunities
Working with a collaborative, social team and leveling-up your skills faster than you will anywhere else.
Quarterly social events

Itoc

Culture and smarts are important to us. Bring your secret sauce. This is no ordinary environment, you will work along some of the Cloud’s best. All engineers at Itoc must gain at least five AWS certifications. We work hard but we have fun.

Please note you must have full working rights in Australia and be available on-shore for face to face interviews.

No recruiters please.",4.0,"Itoc
4.0",Sydney,-1,1 to 50 Employees,2013,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Date: 01-Oct-2020

Location:
Melbourne, VIC, AU

Department:Description:
Technology discounts - from Apple HP Lenovo to Windows
Flexible work arrangements - work in a way that suits you best
Salary packaging - to suit your personal and financial circumstances

Do you want to work for one of the fastest growing data teams in Australia? Do you want to work on multiple data platforms and provide new solution offerings by leveraging cloud and big data technologies?

About the team

Big data information and analytics. Three words that spark apprehension in most businesses. But our team of experts are constantly curious and excited about combining our wonderful array of technological expertise to transform data into our clients most valuable assets making their work smarter. Our data consultants are supported with resources training and tools they need to excel at their work but also the freedom and power to create their own paths forward to make a difference.

As a Senior Consultant in Big Data you will work closely with the team and stakeholders to build and deliver a Cloud based vision for a next generation Big Data analytics platform with strong focus on data quality data security and deliver the systems that process huge volumes of data.

What will you typical day look like?

You will play a pivotal role in - Designing and producing high performing and stable applications to perform complex processing of massive volumes of data in a new cloud based architecture; Building real-time data processing applications which are integrated with business systems to enable value from analytic models to drive rapid decision making; Contributing to system architecture design for a data platform (including cloud-based structures both on and off premises data warehouse components and data lakes); this could cover a range of technologies various countries/locations and lines of business; Support data strategy or technology strategy definition programs including technology stack definition and target operating model requirements

Enough about us lets talk about you:
You are someone with:
Use of traditional data analytics tools and techniques (e.g. MSSQL Oracle MySQL) and ETL software (e.g. SSIS Informatica CloverETL)
Working in large scale cloud data solutions using platforms such as AWS or Azure or GCP will be a bonus.
Experience in scripting or programming (e.g. Python Java Scala C#)
Excellent verbal and written communication skills to adapt to technical and non-technical audiences.
Educated to degree level (or have equivalent experience)
Why Deloitte?

At Deloitte we create positively differentiated work experiences that enable our people to feel valued and achieve their full potential. We value difference and embrace people with diverse backgrounds and thinking styles. Knowing that people work best in different ways we are happy to discuss alternative arrangements if the working pattern you are looking for is not specifically indicated.",3.8,"Deloitte
3.8",Melbourne,-1,10000+ Employees,1850,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Engineer,-1,"Opportunity to grow the team
Period of growth
Intuitive app
S2M are working with a FinTech who have created a unique financial product to help thousands of people better manage their finance, and is currently scaling the company to the next level!

They are looking for a Data Engineer to join, and looking for someone who wants to be hands on, with opportunity to grow the team in future.

Role:

Looking for people with strong AWS experience. You will need passion for data and a cloud, through which you will help a rapidly scaling Australian FinTech establish their data infrastructure from the ground up.
5+ years’ experience as a data engineer within the data and analytics domain
A python 3.X aficionado who is very comfortable creating and orchestrating AWS data pipelines with nothing but code
Strong project delivery toolset experience in open source data integration tools
Experience with processing large volumes of complex data including visualisation and insights generation
Ability to define and develop data integration patterns and pipelines
Ability to assess complexity of data (volume, structure, relationship etc.)
Hands on experience working with different databases (RDBMS, NoSQL, Blob storage etc)
Hands on technical expertise setting up DevOps automation
Hands on experience working technologies/platform e.g. AWS, Dockers, Containers
Experience building data profiling and data cleansing frameworks
Technical reconciliation and reporting
Knowledge and experience in end-to-end project delivery, either traditional SDLC or agile delivery methodologies (or hybrid approaches)
Exceptional communication, documentation and presentation skills
If this sounds like you, get in touch today - kate.gabb@s2m.com.au
3167410agsdf",3.1,"S2M
3.1",Sydney,-1,Unknown,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Analysts,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is seeking experienced and qualified Data Analysts to join our IT team based in our corporate office in Birtinya (Sunshine Coast) or at our meat processing facility in Kilcoy.
Key Responsibilities:
A mixture of data analysis and commercial skills to source, blend and analyse data to gain insight and answer key commercial questions
Working with strategic leaders to define and model Key Performance Indicators, and assist in building forecasting models
Working closely with data engineers and BI developers to specify data pipelines and report visualisation
Drive the creation and implementation of data quality business rule including data definition, governance and quality assurance
About You:
To succeed in this role, you’ll need to bring the following experience and skills:
Proven ability to derive insight and knowledge from data using commercial expertise is a strong requirement
Strong SQL and Excel skills are essential, along with strong data analysis and commercial insights
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Effective people communicator - engage with stakeholders on reporting needs, interpret requirements into visual solutions and train/deliver the outputs to the stakeholders getting signoff of acceptance
Bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking

How to Apply:
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kilcoy,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Network Data Engineer,-1,"Min 6+ years of experience in the relevant technologies
Australian Driving License for visiting remote locations / Data Centre for day to day technical work.
Managing Network devices (switches, routers, firewalls, load balancer, and wireless technology)
Performing MACD activities for all network devices.
Supporting BAU operation activities.
Proficient in performing in-depth details of technical troubleshooting, cause and provide recommendation to the client for incidents causing extended network outage to client’s critical locations.
Provide exceptional network services in terms of network support, break-fix, design and consulting, new projects, implementation.
Configure, administer, and document firewall infrastructure.
Manage the firewall deployment, rules migrations, and firewall administration.
Supporting Cloud Migration Activities from traditional to AWS/Azure.
Setting up VPN tunnel with Cloud and 3rd Party network devices.
Integrating and upgrading existing ISP bandwidth with support from ISP Vendor.
Setting up VPN profiles for Users.
Installing hot fix and patches to mitigate the security devices from attacks and bugs.
Reviewing and fine tuning the firewall rules and NAT rules.
Documentation and change control.
Mentoring, Motivating and Guiding support teams
Technical skills:
o LAN
o Wireless
o WAN
o MPLS
o Routing protocols (OSPF,BGP)
o DMVPN
o Azure cloud Networking
o Network Security
Fortigate Manager / Analyzer / Firewall
Cisco ASA
Firepower FTD
Cisco Any connect
Site to Site VPN
F5 Load Balancing and Scripting iRule
Job Types: Full-time, Contract
Schedule:
8 hour shift
Experience:
Scripting: 5 years (Required)
Data Network: 5 years (Required)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Required)",3.6,"Total IT Global
3.6",Sydney,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Engineer - Processing & Analysis,-1,"Job Description:
Design,build and maintain the ingestion system to support various types of data(e.g. User behavior, RDS, NoSQL db and others) to be ingested to the data warehouse more timely and accurately
Translate data requirements into scalable technical data service with low latency and high concurrency
Design,build and maintain the batch or real time data pipeline in production using Hadoop big data technology
Analyze and improve efficiency, scalability, and stability of the system
Define and manage SLA,Data quality for all data sets in allocated areas of ownership
Requirements:
Minimum B.S. degree in Computer Science or a related technical field
2+ years of working experience in programming languages,such as Java,Scala,Python
Familiar with Hadoop, Spark and Flink data processing, experience of TB data processing experience is a plus
Familiar designing and operating of a robust distributed system is a plus
Understand data mining or machine learning
Excited to work intimately with data
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"SYNOPSIS:
Lead Data Engineer
Applications close Sunday 8 November 2020
Ongoing
Contact name: Shyni Sasikala
Phone: (02) 6249 9048
Email: Shyni.Sasikala@ga.gov.au

The Data Policy and Informatics section within the Digital Science and Information branch creates, implements, and promotes policies, platforms and tools that improve and support the quality, discoverability, accessibility, and general usability of Geoscience Australia’s science data products. The section consults with internal and external research, government and industry partners to establish collaborative data frameworks, architectures and models within Geoscience Australia (GA) and across broader national and international communities of practice. The section innovates, builds and maintains tools, systems, processes and governance that enable digital data management, cataloguing and open data delivery.
GA makes accessible a wide range of geoscientific and spatial data to a wide variety of stakeholders in multiple formats, and in recent years GA's data volumes have grown exponentially. GA is focussed on making its data and metadata assets accessible so that they can be used in machine to machine interactions for data analytics and other applications in environments that range from High Performance Computing (HPC), through high-end cloud servers, to mobile devices.
We currently have two opportunities for Lead Data Engineers in the Informatics team. The Lead Data Engineer is responsible for innovating and exploring new technologies that will advance GA’s science goals and maximise the uptake and use of GA’s science data. The Lead Data Engineer reports to the team’s Assistant Director but also works closely with other developers, data scientists and engineers within the Digital Science and Innovation (DiSI) branch, as well as diverse stakeholders both within and external to GA.",3.9,"Geoscience Australia
3.9",Canberra,-1,501 to 1000 Employees,2001,Government,Federal Agencies,Government,$100 to $500 million (USD),-1
Data Engineer,-1,"The Seven Network is part of Seven West Media, one of Australia’s most prominent media companies, with a market leading presence in content across broadcast television, online and in print. Comprising some of Australia’s most renowned media brands, SWM includes not just Seven Network and its affiliate channels 7two, 7mate, 7flix and BVOD offering 7plus, but also 7NEWS.com.au, The West Australian, The Sunday Times and more.
At Seven we are here to bring all Australians closer to the moments that move us - we’re first on the scene, with our finger on the pulse, on demand, in the moment. Together, we’re responsible for creating and sustaining authentic Australian engagement.
A new and exciting opportunity has opened for a Data Engineer to join the Audience Intelligence team. Based in Sydney and reporting to the Head of Data Enablement, you’ll be responsible for:
Implementation of end to end data solutions to support Data Strategy for the SWM group.
Work closely with the Data Solution Designers to develop and maintain scalable data pipelines and build out new file and API based integrations to address requirements from the various business stakeholders.
Collaborates with engineering, analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organisation.
Work on Data Preparation for analytics and data scientist team members and assist them from an engineering perspective in building and optimising the models including building the automation of the end to end workflows
Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.
Perform data analysis required to troubleshoot data related issues and assist in the resolution of production data issues.
Work effectively with vendors for successful delivery of projects and acceptance of the solution
Work on Delivery projects using Agile Software Development methodologies
We are looking for someone who has:
Bachelor's degree in computer science, computer engineering or other technical discipline is essential
Proven experience working as a digital analytics specialist
Extensive experience with digital analytics implementation (e.g. Google Analytics, Snowplow, Adobe Analytics) and BI processes and visualisation platforms
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience in ETL and building and optimizing ‘big data’ pipelines and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Experience with big data tools: Hadoop, Spark, etc., AWS cloud services: EC2, S3, Lambda and familiar with version control systems: Git
Strong coding skills with knowledge of Unix/Linux and scripting languages such as Unix Shell scripting, Python desirable
Experience supporting and working with cross-functional teams in a fast-paced environment.
Ability to multi-task and problem solve with changing demands and priorities
Ability to work under pressure to meet deadlines and detail oriented
Your success is our success: we will provide you with opportunities for you to keep learning and growing, enabling you to challenge and develop yourself. In return, we offer a benefits program that has something in it for everyone.
Seven West Media is an equal opportunity employer and we are committed to creating a diverse and inclusive workplace.
Recruitment Agencies: Seven West Media does not accept any unsolicited agency resumes and will not be responsible for any fees related to unsolicited resumes.
Advertised: 19 Oct 2020 12:00 AM AUS Eastern Daylight Time
Applications close:

Back to search results",2.5,"Seven West Media
2.5",Sydney,-1,5001 to 10000 Employees,1956,Company - Public,TV Broadcast & Cable Networks,Media,Unknown / Non-Applicable,-1
BICON Rules Engineer,-1,"APS 5 - $73,299 - $80,410 per annum plus superannuation
Biosecurity Plant Division
Canberra, ACT
Play an active role in managing biosecurity risk to Australia
Work in a motivated and professional team with a wide range of skills and backgrounds
Full training provided

Who we are
The BICON Content Development Team maintains and improves the Biosecurity Import CONditions database (BICON) content to allow external clients to understand and comply with their biosecurity obligations and internal clients to effectively manage biosecurity risk and regulate imports. We work collaboratively with internal clients to comprehend and implement their BICON content requirements and optimise the use of BICON to publish clear import requirements and onshore management support procedures to effectively manage biosecurity risk.

The Jobs
Key duties of these positions include:

working with business content (import and permit conditions) and import programs to understand and construct decision tree structures in the BICON database, in accordance with system design and authoring conventions
executing changes to import and permit conditions in alignment with service standards while complying with system rules and authoring conventions
providing technical advice through various formats on the most appropriate means of authoring BICON content to achieve import program and stakeholder objectives
using workflow management tools to maintain detailed records of changes to import conditions and key decisions
performing administrative tasks including system reporting, data analysis and scoping tasks for the BICON content change work program
contributing to the development and maintenance of instructional material, authoring conventions and courseware
clearly documenting and reporting system issues
developing and maintaining effective working relationships with internal and external stakeholders.

What we are looking for
Knowledge and experience
Experience working with complex IT systems.
Experience working collaboratively and as part of a team.
Knowledge of the role of biosecurity is preferred but not essential.

For additional information, please read the Job Description below.
Candidate Information Package docx Opens in new window",3.9,"Department of Agriculture & Water Resources
3.9",Australia,-1,5001 to 10000 Employees,-1,Government,Federal Agencies,Government,$500 million to $1 billion (USD),-1
Cloud Data Engineer,-1,"Job no: 509605
Work type: Permanent Full Time
Location: Melbourne, Canberra, Sydney
Do you embrace digital disruption?
Do you love solving complex problems, designing sophisticated solutions and building innovative technology?
Do you believe in creating powerful actionable insights from Data and Analytics?
Do you want to work in a diverse and flexible working environment?
KPMG is one of the most trusted and respected global professional services firms. Through depth of expertise, clarity of insight and strength of purpose we help our clients solve complex challenges, steer change, strengthen, transition and grow. We are a team based practice and this extends to our clients whom we work and collaborate with, in solving complex problems. Together, we design, innovate and implement, providing enduring advice that support our clients and the services they deliver. Our clients vary in size and come from a diverse range of sectors – all sharing in a common goal: to embrace change and deliver services that make Australia a better place. We are looking for talented individuals who would like to join us on the journey.
KPMG’s Digital Delta Team
We re-imagine and re-invent organisations to become world class digital enterprises using advanced technologies, data and human insights. We help organisations to embrace Digital Strategy, Artificial Intelligence (AI) & Cognitive, the Internet of Things (IoT), Data, Analytics & Modelling, Mobile App & Web, and User Experience (UX) & User Interface (UI) and more.
We work with clients to:
Formulate strategies that re-imagine organisations
Harness innovation from the 4th industrial revolution
Actioning insights from trusted data to consistently and quickly make clear decisions
Build adaptive organisations
Thrive as a connected enterprise – front, middle and back office
This is how you’ll contribute:
We are looking for ambitious Data Engineers who are passionate about helping clients define bold ambitions and deliver on them. Joining our team will take you on a journey of personal and technical growth and provide the opportunity to inspire confidence and empower change.
As a Data Engineer you are the designer, builder and manager of the information or ""big data"" infrastructure, preparing data for analytical or operational use. You will design, construct, test and maintain a data pipeline to pull together information from different source systems; integrating, consolidating and cleansing data; and structure it for use in individual analytics applications.
The KPMG Difference
Our people are focused on creating a diverse and dynamic environment that embraces and values differences. We value the variety of unique experiences, qualities and characteristics our people possess and we share and learn from each other.
We are proud to be consistently recognised as an employer of choice for women, and for our achievements in LGBT+ workplace inclusion.
Our commitment to ‘Flexibility’ allows our people to manage the changing demands of work, personal or family life. Explore the links below to hear our people share their experience @ KPMG:
Flexibility empowers wellbeing
Flexibility enables contribution to the community
Flexibility inspires technology & innovation
Flexibility supports family

Make KPMG the clear choice for your career and be Extraordinary!

Advertised: 09 Sep 2020 AUS Eastern Standard Time
Applications close:",3.8,"KPMG
3.8",Sydney,-1,10000+ Employees,1987,Subsidiary or Business Segment,Accounting,Accounting & Legal,$2 to $5 billion (USD),-1
Computer Network and Systems Engineer,-1,"Duties Include but are not limited to:
Tasks Include:
analysing, developing, interpreting and evaluating complex system design and architecture specifications, data models and diagrams in the development, configuration and integration of computer systems
researching, analysing, evaluating and monitoring network infrastructure to ensure networks are configured to operate at optimal performance
assessing and recommending improvements to network operations and integrated hardware, software, communications and operating systems
providing specialist skills in supporting and troubleshooting network problems and emergencies
installing, configuring, testing, maintaining and administering new and upgraded networks, software database applications, servers and workstations
providing network programming in support of specific business needs and requirements
preparing and maintaining procedures and documentation for network inventory, and recording diagnosis and resolution of network faults, enhancements and modifications to networks, and maintenance instructions
monitoring network traffic, and activity, capacity and usage to ensure continued integrity and optimal network performance
Skills and Experience Required:
Must have experience working in a Managed Service environment
Demonstrated experience in IT Networks and Data Centres
Understanding of systems and architectures to meet client needs
Experience in Help Desk including break / fix
Effective and timely documentation
Effective Task Management Skills
Be solution and outcome focused and willing to learn new technologies
Excellent communication skills with staff, clients and partners
Time management, ability to prioritise and deliver to schedule
Experience with N-Able and Connectwise desired
Open Cabling license desired
Job Types: Full-time, Permanent
Salary: $30.00 per hour
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,Trans-plant training,Canberra,-1,-1,-1,-1,-1,-1,-1,-1
Software Engineer (Data),-1,"If you are looking for an opportunity to make a real impact with smart people who are genuinely doing things differently then you've come to the right place! We're growing our data engineering capabilities and are looking for awesome data engineers to join our team.
With our diverse range of clients and projects, no day will look the same - but here's a great snapshot of what you'll be doing:
Work with some of the best Data Scientists and Engineers to deliver production-grade AI and Machine Learning systems as we deliver client projects from inception to production.
Consulting with our clients and working with them to build modern data systems using the 'best of' technologies and principles.
Advising clients on data strategy, architecture and technology.
Applying best software engineering practices in coding, monitoring and alerting, using CI/CD, TDD and cloud architectures.
Working over a wide range of big data tools and environments: not limited to; Apache Kafka, Spark, Python, Scala, Hive, Airflow, AWS EMR & Glue, GCP Dataproc & Dataflow, BigQuery, Snowflake, Redshift.
Who are we?
Glad you asked! We are Eliiza. Data science. Engineered for scale.
We are a passionate team of data scientists and engineers who apply data science and machine learning to solve real-world problems. Our mission is to create a bright future for Australian businesses and society in a world increasingly influenced by intelligent technologies.
We've created a culture that values diversity where people can truly be themselves! We care a lot about growing the Australian AI community in a positive direction, and we're doing several things to try and achieve that:
We provide opportunities for underrepresented groups to work in AI through our associate and intern programmes
We organise and participate in a range of community events, reading groups and meetups
We produce the AI Australia podcast
We blog about topics we care about
We stream brown bag sessions to the broader community
We're also part of Mantel Group's 'house of brands' which means it's not just the Eliiza team you'll work with, learn from and see at social events - there's another 230 of us across DigIO, Kasna & CMD Solutions!
So you're ready for something new?
We're keen to know more about you! Our team is made up of a range of people, with different experience across a huge range of data driven skill sets.
We'd love to hear from you if you have experience with:
one (or more) core language(s), ideally Scala, Python or Java
one (or more) cloud platforms, AWS, GCP, Azure
ETL/ELT concepts and technologies e.g. Data partitioning, Hive, Spark
streaming data concepts and technologies, ideally Kafka (Kinesis, Beam or Pubsub will do)
We'd be over the moon if you:
Experience with distributed/columnar databases (e.g. Snowflake, Big query, Redshift).
Experience with any of a variety of databases e.g. RDMS, NoSql, Columar, Distributed, Time series, Graph.
Knowledge of job orchestration and scheduling. Any experience with Airflow, Luigi or Oozie.
Experience with containers and container orchestration (Docker, Docker Compose or Kubernetes).
However, we value a diversity of skill-sets, and don't necessarily require that you're skilled with all of the above. If you feel you don't fit all the experience/skills listed above we still encourage you to apply or get in touch.
What's on offer if you join us?
We make sure you're always one step ahead by investing your learning and development, every year. We build our own training where it doesn't exist yet.
We hire smart people and get out of their way. By focusing on our five principles and not getting caught up in red tape, we trust you to get the job done.
You'll get all the tools you need - a new iPhone or Google phone, a new Macbook Pro or Dell, and a lot of branded swag!
But hold on, you mentioned a house of brands?
We certainly did! Mantel Group is an Australian-owned, 'house of brands' company with four technology businesses (Eliiza being one of them!) across Melbourne and Sydney. We're building a group of companies with open borders so we can support you to take on new skills without leaving an awesome team - we understand you won't have one job for life!
We may only be just two years old but Mantel Group has already been recognised #9 in the 2020 Best Places to Work in Australia and #4 in the AFR's 2020 fastest growing new companies.
Keen to chat?
Click ""Apply"" to share your details with our talent team, and we'll be in touch.
In the meantime, check out 'how we hire' to find out what's in store if you're successful and get to know us better by visiting our website and following Eliiza on LinkedIn.",-1,Eliiza,Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Infrastructure Engineer,-1,"Job Description:
Design and grow the Shopee data platform to support a variety of big data applications using open-source technologies including Kafka, Hadoop, Presto, HBase, Spark, Hive, Druid, and our own creations. Some examples include a real-time data streaming platform, a unified query platform, a cluster management system, and a machine learning platform
Dig into the source code of some open-source big data system to get the whole control and familiar with the details, configurations, designs and source code. Develop and maintain the internal release of big data systems and components as the business requirements.
Keep close and overall monitoring for all the deployments of the systems, maintain the system’s stability, improve the performance, discover the performance bottlenecks, tracking and troubleshooting, cost optimisation.
Requirements:
B. Sci. / Ms / PhD in Computer Science or a related technical field
Familiar with at least one of these languages: Java, Scala, Python, Bash under Linux / Unix. Scala is a plus
Familiar with the use and compute logical of SQL
Knowledge about the Big Data Infrastructure system technology like Distributed File System, Distributed Computing, Distributed Database will be a plus
Hands-on experiences Hadoop, Spark, Kafka, and/or Presto will be a plus
Love to use and develop open-source technologies
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"Work on an award-winning, international technology!
Endless career opportunities
An innovative, friendly team of 300+
This role will be focused on the development of our existing ClaimLogik line of products as well as working on our new cloud-first, modern suite of applications.

Intelligent Thought, our technology business is scaling and shipping our software globally. Already profitable, part of a much larger group business, with investors such as Macquarie Capital and Envest – we are all set to deliver textbook disruption to the Insurance Industry. The growth of the platform, of our customer base, and the increasing industry demand have led to the need for this role to help the team scale.

Our Philosophy
Give each employee a sense of purpose and an environment for them to connect the importance of their role to delivering a service that matters to our customers.
Challenge the ‘why’ of traditional claims processes.
Keep it simple – do only what brings value and what matters to the customer
Enable employee decisions, empower our people
Responsibilities:
Create, extend and maintain ETL pipelines to form our data lake, data warehouse and analytics platform (currently using the Microsoft Azure set of tools and service)
Help define the optimal data pipeline architecture
Influence the tool selection, platform selection, data architecture and strategy which will transform the business to be truly data-driven
Understand, analyse and size user requirements
Work with different parts of the business to provide them with the insights they need to deliver the best results
Skills & experience:
Degree or qualification in computer science or related
Advanced knowledge of relational database, including query authoring and query optimisation (MS SQL Server and PostgreSQL).
Experience building and optimising ETL pipelines
Experience designing complex data models
Experience working with cloud platforms (Azure or AWS)
Efficient time management and organisational skills
High attention to detail and accuracy
Effective communication skills to build strong working relationships; both written and verbal
Proactive and results-driven
Why Claim Central?
Claim Central Consolidated is a global insurance industry leader across, claims management, insurance technology and data and analytics. Currently operating in the United States, Australia, South Africa, Italy and New Zealand, we have pioneered digitally connected claims management services across the globe. Claim Central is a disruptor and thought leader in the industry and we were recognised as the Australian Financial Review’s 8th Most Innovative Company in Australia in 2016. This business is in a period of unprecedented growth, transitioning our technology and services into multiple geographies at a rapid pace. Our unique culture is based on teamwork, collaboration, trust, respect and performance. We also offer many benefits apart from our exceptional team culture; including flexible work arrangements, and continued professional development.

Be a part of this journey in a career-defining role.",-1,Claim Central,Matraville,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer - AI/ML,-1,"Our client provides services to a major industry across the country. The business is still early in it's days of technology development and the environment is greenfields in nature (no pun intended), effectively working like a start-up.

Their data and analytics team have worked and built leading and bleeding-edge technologies in this space and what they have created so far may be game-changing. From a machine learning perspective, the progress they have made to the business has already seen proven success in changing the future of an industry that will have positive consequences for all those involved.

You will have previously worked in a technical capacity in the data and analytics space and have experience working with an organisation where machine learning has been implemented, not just a concept that the business talks about having or the technology team would love to have. The commercial experience you will have had in the ML field will be proven examples of where you have affected the way a business or industry used to perform, to the changes that have come about from this.

Technically, you will have extensive experience in the Microsoft space - Power BI, Azure etc and you will have previously mentored and coached junior members of the teams you have been part of.

This is a rare opportunity in Brisbane where the business has truly embraced and funded projects across the ML space and would be a great chance for those in the Data Development/Data Engineering field, who are looking to move into a Data Scientist role in the future.

Please send your application through if you would like to know more.",4.0,"Emanate Technology
4.0",Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Solution designer/ ETL Engineer & Data Modeller,-1,"We are looking for a Qualified and Experienced Solution Designer to join our client for a period of 6 months with a view to extend.
You will work closely with team members and your contribution will range across gathering and analyzing information, developing and documenting improved processes and work instructions and experienced DWH Lead with skills in requirement analysis, solution designing, developing, testing and supporting ETL solutions.
A hands-on solution designer, data modeler and ETL developer for Data Warehousing and ETL application transformation projects using Informatica PowerCenter.
Knowledge on AWS, S3, Redshift, Informatica BDM, and related technologies.
Experience working with IPython, PySparks, AuCuMo, Airflow, Jenkins, Github, Athena, JIRA, Rally, Spectrum, Glue, Flyway.
Good exposure on Oracle PL/SQL, aware of DBA activities, writing and performance tuning of complex SQL queries.
Contract length: 6 months
Job Types: Full-time, Contract
Salary: $650.00 – $800.00 per day
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,nducive,Melbourne,-1,-1,-1,-1,-1,-1,-1,-1
"Data Engineer, Wollongong NSW or Mount Waverley VIC",-1,"Company Description
BlueScope is a technically advanced supplier of steel and steel products in Australia. We are an inclusive organisation and every day we showcase our technology and expertise throughout the world.

Job Description
We are looking for two Data Engineers to join our IT team, based in Wollongong NSW or Mount Waverley VIC. Use your experience in analytics to unlock business value, enabling use of big data for insights and decision-making.
Reporting to the Data Product Owner for our Australian Steel Products (ASP) business, this position will support strategic goals related to data. This will see you:
Gather business and technical requirements with the view to deliver outcomes;
Develop and implement end-to-end data collection, consolidation, modelling and visualisation solutions;
Document metadata in a dictionary and catalogue;
Ensure consumers of such information understand its accuracy, timeliness, quality and sensitivity, so that it is used appropriately; and
Identify opportunities to enhance analytics.
What are the benefits?
Work in a supportive and collaborative team environment whilst we embark on a journey to transform the way our business uses data!
Our systems landscape is broad and diverse. You will be encouraged to think creatively to develop data solutions which solve real business problems.
Working in this role you will enjoy:
the chance to learn more about data science;
salaried remuneration with attractive superannuation options;
the opportunity to participate in a performance incentive scheme; and
access to further development and career opportunities with BlueScope.
Who are we looking for?
We welcome applications from professionals with experience in data analytics and/or programming. Supported by your knowledge of project delivery methods (e.g. Agile), you will demonstrate:
experience with data mining, wrangling, mapping and visualisation techniques (e.g. Azure Data Factory, Databricks and/or DevOps etc.);
well-developed ability in gathering business and technical requirements;
skills in developing and implementing collection, consolidation, modelling and visualisation solutions; and
a passion for sharing your knowledge and desire for ongoing professional development.

Qualifications

null

Additional Information
We're proud to have been named an Inclusive Employer for 2019–2020 by the Diversity Council of Australia. We believe that our people are our strength. Having a diverse and inclusive workplace enables us to improve our capability and ensure continued, sustainable success.
We know that workplace flexibility can mean something different to everyone. Under our B-Flex initiative all of our roles have some degree of flexibility. We encourage you to discuss your needs with us.
Applications close Sunday 25th October 2020.",3.3,"BlueScope
3.3",Wollongong,-1,201 to 500 Employees,-1,Company - Private,Construction,"Construction, Repair & Maintenance",$100 to $500 million (USD),-1
ETL Data Engineer,-1,"ETL Data Engineer

Join a team that’s changing how Australia lives, works, plays and grows
We want you to be the best version of you

Work with innovative teams and explore new technologies to help solve real-world problems.

A typical day as a Data Engineer

ETL / Big Data Engineering professionals will be responsible for guiding the full lifecycle of a Data solution, including:
Working in highly client-facing roles to contribute throughout the end-to-end delivery lifecycle of complex and large-scale digital solutions
Use case and business case development
Support existing and new applications utilizing in-depth technical and data knowledge. Troubleshooting complex issues and providing advisory services to improve the client’s data landscape
Help to streamline and simplify the clients’ complex data landscape by integrating different applications and data architectures
Implementation from requirements analysis, platform selection, digital architecture design, application design and development, testing, and deployment
Interstate travel may be required

Basic qualifications:
Bachelor’s degree
Experience across systems integration, information management, data management and architecture, and business analytics
Experience with being in a team focusing on large-scale, multi-release information centric projects
Experience with waterfall and agile delivery and run / application support functions
Part of a team working on End to end implementation of at least 1 big data project

Preferred Skills:
Hand on experience in Data warehousing using ETL tools such as DataStage, Autosys and TeraData
Hands on experience in ETL job development with multiple stages like sequential file, Transformer, Lookup, join, sort and Database stages.
Strong hand on skills in design, development and implementation of various data remediation, Data migration, data integration techniques.
Strong hand on data modelling experience.
Strong hands on experience in database performance tuning including complex query optimizations and physical database tuning using Teradata.
Understanding of architectural designs and strategy related to data migration, data cleansing, data quality and data consolidation.
Proven data analysis, requirement gathering and problem-solving skills
Exposure to Unix environment and shell scripting.
Experience in Banking and Financial services industry
Desirable: Knowledge of cloud computing infrastructure (e.g. Amazon Web Services EC2, Google Cloud, Microsoft Azure)
About Accenture

Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. We combine unmatched experience and specialized capabilities across more than 40 industries — powered by the world’s largest network of Advanced Technology and Intelligent Operations centers. With 513,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises. Visit us at www.accenture.com.

Accenture is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, marital, domestic or civil partnership status, sexual orientation, gender identity, or any other basis as protected by applicable law.

Vera Goga is the Recruiter managing this role. As the team experience high volumes of applications, we appreciate your patience to allow for a fair and timely process.",3.9,"Accenture
3.9",Sydney,-1,10000+ Employees,1989,Company - Public,Consulting,Business Services,$10+ billion (USD),-1
Student Engineer,-1,"The candidate will have the ability to:
Undertake onsite inspection to collect asset condition data based on the relevant engineering standards and technical guidelines;
Undertake desktop analysis to evaluate the condition and performance of the assets;
Provide the appropriate information, advice, engineering input and support services for the sustainable management of Council’s stormwater and transport networks.
Qualifications:
The successful candidate will be enrolled in a Bachelor of Engineering with a minimum of two years completed.
Position Number: 100678
Position Hours: Fixed term (3 months), hours will be negotiated with the successful candidate, maximum of 75 hours per fortnight.
Salary: Schedule A, Salary Point 4.0. $28.64 per hour ($55,853.45 per annum, pro-rata) in accordance with Glenorchy City Council’s Enterprise Agreement 2016
Please note that all successful applicants will be required to provide a current National Police Check prior to commencement of employment.
For further information on this position, contact Patrick Marshall, Senior Civil Engineer on (03) 6216 6800.
How to apply: Applications for this position must be lodged on this submission site or on the Glenorchy City Council website www.gcc.tas.gov.au - Careers page.
To be considered for this role, all applicants must address the key selection criteria in the and provide a current resume. A copy of the position description can be found by clicking the below hyperlink or on the Glenorchy City Council website.
Applications close at 8pm on Sunday, 1st November 2020
- Student Engineer",4.0,"Glenorchy City Council
4.0",Glenorchy,-1,501 to 1000 Employees,-1,Government,-1,-1,Less than $1 million (USD),-1
Data Engineer involving DevOps,-1,"Data Engineer involving DevOps
Axiom Technologies is an Australia based entity with the history of providing Managed IT solutions to medium to large scale enterprises globally. Please visit our website for more information about what we do at www.axiomtechnologies.com
Axiom Technologies is an Equal Opportunity Employer and encourage applicants from all backgrounds and gender to apply, including, Aboriginal and Torres Strait Islander candidates
Job Requirements:
8+ years IT experience, with at least 5+ years of “Data Engineer/Deveoper” focused titles/roles,
Data Tools: Hands on experience with Apache Beam.
Testing: Hands on experience with automated testing activities/outcomes
DevOps: Experience with the processes involving Microservices facilities for artifacts developed
Platform/OS: Mid-range/Unix
Languages: Unix (Shell) Scripting/commands, SQL, Python
File formats: Text, CSV, Parquet, JSON, XML
Scheduling: Jenkins, Airflow
Auto Scripting: Designing/creation of scripts for repetitive activity. E.g. Unix scripting/SQL
Big data: Exposure to Data Lake Concepts, Hive (Schema), HDFS
Source Control tools: GIT
Delivery Models: Agile, Scrum
Ingestion Design: Create/assess Source/Target data mapping designs
Frameworks: Development and delivery frameworks
Activity Reporting/Repository: Jira, Confluence.
Quality: Accuracy and attention to detail
Industry: Financial Services/Banking
Solutions: Define solutions from High level to detail design to address automating ingestion activity. Facilitate/confirm requirements from product owners, business team members and technical associates,
Process Automation: Automating processes in file management, testing data in files, analysis and design, configuration management.
Script Automation: Ability to design/create scripts to automate/improve data copy/migration/ETL for any repetitive activity.
Languages: Java, Python
Scheduling: Control-M
Databases: Relational. E.g. POSTGRESS, Oracle – as a ETL developer
File Formats: Mainframe – experience with referencing its data formats/copybooks
Big data: Experience referencing/using Hive (Schema) to access data in HDFS
Metadata management tools: MDM, EDC and Axon
Performance: Assess, recommend, improve mappings, SQL queries, Batch feeds
Automation Tools: Other tools that may add value to an automation program and generally support development. E.g. API, REST, JDBC, Webservices, Message Queues/Load balancer,
Cloud: Experience with processing of data files to be ingested/stored in the Cloud, preferably with AWS.
Prod Support: Experience in a production support role performing root cause / impact analysis – under time constraints
Experience in a similar role
8+ Years
What next?
If you are looking for that next challenge in your career and wish to apply for this role, please forward your resume to careers.au@axiomtechnologies.com",2.0,"Axiom Technologies
2.0",Melbourne,-1,1 to 50 Employees,-1,Company - Private,Industrial Manufacturing,Manufacturing,Less than $1 million (USD),-1
Data Engineer,-1,"About the Role
We are on an exciting digital journey so it’s a great time to join ME! We are seeking a Junior Data Engineer who enjoys rolling up their sleeves, learning and growing. As part of our Enterprise Data Team, you will ensure fit for purpose data warehouse solutions are built for use across the bank and by utilising best practise ETL standards, whilst ensuring the data is trusted by our BI developers and key business consumers. Oh, and you’ll get to work on Microsoft technology stack too!
You will be involved with investigating data issues, keeping data feeds flowing and collaborating with different projects across the bank to deliver quality data solutions. How important does that sound? What’s even more important is this role contributes directly to our overall business strategy through the provision of data to enable analytics & reporting, as well as supporting business and decision system processes.

About You
You’re naturally a highly motivated and energetic person who thrives in a dynamic, ever-changing collaborative team environment. Ideally you have previous experience as an ETL developer, Data Engineer or a BI developer, and if you have a degree in computer science or similar it would really put you ahead of the rest.

With your knowledge of SQL coding, data modelling, understanding of data warehouse concepts, plus experience of working on complex ETL solutions, you’re ready to expand your horizons and launch your career into the world of IT at ME.

About ME
We’re not like other banks.
ME was created by the industry super funds to be different from the pack – with a core purpose to help all Australians get ahead financially – no conditions, asterisks or exceptions. And we know that looking after customers starts with taking care of our people.
We believe everyone deserves the same opportunities in life, regardless of gender or identity, sexuality, ethnicity, religion or disability ‒ with internal affinity groups.
Perk ME up
Once you get your feet in the door at ME, we’ll put them both in your very own ME-branded Converse shoes. You’ll also get the following financial, health and fun perks when you join the team:
4U Extras portal (discounts and cashback on 100s of items including cinemas, shopping and gym memberships
10% Myki discount
Purchased Leave programme
Internal wellness programme (Mindfully ME)
Professional education through LinkedIn Learning
Novated Leasing
Professional membership reimbursements
Health checks
Financial education (To help you manage your money smarter)
LGBTIQ+ and Women at ME affinity groups

I want those Converse shoes (and the role)
Can’t see a closing date on the advert? That’s because we’re pretty efficient here at ME and we may start looking at applications sooner rather than later, so if this role sounds like your jam, be sure to apply by submitting your resume today.

Should an applicant be the preferred candidate, background checks (including police checks, reference checks, ASIC banned and disqualified persons and bankruptcy checks) will be completed prior to the candidate's employment being confirmed. The outcomes of the background checks do not automatically bar candidates; however will be assessed against the inherent requirements of the job.
Back Share
Apply Now",3.0,"ME Bank
3.0",Melbourne,-1,501 to 1000 Employees,-1,Company - Private,Banks & Credit Unions,Finance,$100 to $500 million (USD),-1
Software Engineer - Machine Learning/Data Science,-1,"Zendesk is looking for a Software Engineer - Machine Learning/Data Science for a full time position in our Melbourne office.
As part of our engineering team, you will work at a scale where the challenges start to get seriously interesting. Our global engineering team is widely dispersed over the world, with people across nearly every continent. You will get a chance to do cool things with a diverse bunch of people while working in the Melbourne office that is home to Zendesk’s first machine learning (ML) research team.
The Data Science Team, together with Data Engineering, have built Satisfaction Prediction, Answer Bot and Content Cues — products that use Machine Learning (ML) and Artificial Intelligence (AI) to help our customers work more efficiently.
What you get to do every day:
We’re currently looking for someone to join our team as we research, develop, and productionise Machine Learning and Deep Learning models. In addition to frequenting Melbourne’s finest purveyors of coffee, ramen, and bulgogi, you may find yourself:
Building machine learning models including neural networks in TensorFlow
Writing and deploying production-grade Python
Querying and constructing datasets in AWS Athena, Spark
Evaluating and responding to real-world model performance
Scaling your ML to millions of predictions per day
Presenting your work to a broader audience
Watching your algorithm help Zendesk’s end-users
What you'll bring to the role:
A strong foundation in a quantitative discipline (e.g. machine learning, statistics, bio/eco/etc-informatics, econometrics, etc) is critical for this position. While experience in deep learning and natural language processing would be beneficial, your best qualities are:
dedication to continuous learning
collaborative work attitude
strong communication skills
You should also be comfortable with at least one programming language, such as Python, R or Scala.
Application Deadline: 18/11/2020
Job Types: Full-time, Permanent
Salary: $85,000.00 – $110,000.00 per year
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Temporarily due to COVID-19",4.5,"Zendesk
4.5",Melbourne,-1,1001 to 5000 Employees,2007,Company - Public,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),-1
Software Engineer (Machine Learning),-1,"About the Role
AdelaideMRI is building a medical reporting tool. We require an engineer to work primarily on machine learning projects to improve reporting speed and report comprehensiveness.
You will perform data analysis of medical report datasets and image datasets to infer sentence recommendations, image classifications, or other actionable results for the doctors.
Skills and Experience
Background in machine learning or image processing
Qualifications in Computer Science, Software Development or Engineering or equivalent experience
Bonus points for Python
No prior medical knowledge is required.
This position offers flexible hours and work arrangements.
Job Type: Full-time
Experience:
Software Engineering: 1 year (Preferred)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Yes",-1,Adelaide MRI,Australia,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Hey there, we’re PEXA!

We started as an idea: to deliver a single, national e-Conveyancing solution. We collaborated with the industry to create a national electronic lodgement and settlement platform: PEXA. From our humble beginnings, we’ve now grown to more than 320 employees across 5 different states. We’re still expanding at a rapid rate and constantly challenging ourselves to create great experiences for our members as they transition to fully digital conveyancing.

Why become a PEXArian?

Great question! Being a PEXArian is so much more than just a job. We are passionate, motivated & unashamedly enthusiastic at PEXA - we love what we do and we’re proud to admit it! Creating brilliant member experiences wouldn’t be possible if we didn’t also strive to create an amazing employee experience. Alongside our members, our employees are at the heart of everything we do.
Here’s a snapshot of what your life at PEXA could look like:

Your growth:
We encourage you to hit your personal and professional Learning & Development goals with our tailored programs and tools.

Your wellness:
We care about your holistic well being - a fully stocked kitchen, four wellness days, a $250 wellness subsidy as well as lunch and learn sessions to support your financial well being.

Your work/life blend:
We know that work is just one aspect of your life, we want to help you create your ideal work/life blend, rather than squeezing in life around work.

Your family:
With a range of benefits aimed at supporting your family including access to a subsidised school holiday program, extended parental leave and flexi-time to support your return to work, superannuation payments for unpaid parental leave for primary carers and a childcare allowance for pre-primary aged children, when we say, ‘welcome to the family’, we really mean it!
The impact you'd drive:
The successful candidate will be responsible for developing, and maintaining infrastructure to support the delivery of new and existing products. They will also be contributing to establish the rules and frameworks for obtaining the required approvals for new products.
On day one we’d love you to have:
Experience with Python, Spark
Event streaming/sourcing with Kafka or AWS Kinesis
Experience with data structures, formats and data security best practices
AWS experience (e.g CloudFormation, S3, ECS, Lambda, SQS, IAM, KMS, DynamoDB, Glue, Athena)
Query construction and optimisation (e.g. SQL, Elasticsearch, Splunk, DynamoDB)
Git, version control practices, and continuous integration/delivery servers
PyUnit and unit testing frameworks
Production release cycles and maintenance
Collaborating with technical and non-technical teams
Even better:
Agile methodology/delivery
GraphQL
Modern frontend technology (e.g. ReactJS, TypeScript)
Machine learning frameworks and tools (e.g. TensorFlow, PyTorch)
OAuth 2, SAML 2, JWT
Data visualisation and exploration tools (e.g. Jupyter notebooks, Tableau)
AWS SageMaker
Sounds like you?
If this role sounds like you, apply today to have your application reviewed ASAP!",3.9,"Property Exchange Australia Limited
3.9",Melbourne,-1,201 to 500 Employees,2010,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Ongoing position
Full time
Based in Sydney, NSW
Who we are
Australian Red Cross is part of the world’s largest humanitarian organisation. Our aim is to improve the lives of the most vulnerable people in Australia and across our region.
About the role
The Data Engineer role will sit within the Data and Integration Squad in IT and will own (design, implement and support) the AWS Big Data technologies such as the Data Lake and Data Warehouse and support the organisation in growing the data analytics capabilities at Red Cross. In addition to this, the data engineer role will also administer the Power BI tool and support the implementation of the data mastering capability.
What you will bring
Experience building and optimizing data pipelines, architectures and data sets.
Experience in dimensional modelling and building data vaults
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with structured, semi-structured and unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Why work for us?
Work for purpose and know that your work assists Red Cross support and empower people and communities in times of vulnerability.
Generous salary packaging options available that can increase your take home pay.
Further information
To find out more about this opportunity please see the position description below or contact Sharath Kumar Gurram on 02 8651 8839.
Position Description: Position Description - Data Engineer .pdf
Applications for this position will close at 11:55pm Thursday, 5 November 2020.",4.1,"Australian Red Cross
4.1",New South Wales,-1,1001 to 5000 Employees,-1,Nonprofit Organization,Industrial Manufacturing,Manufacturing,$500 million to $1 billion (USD),-1
Junior Fullstack Data Engineer (Python and React),-1,"Formbay is the leading Renewable Energy Certificate Trading company in Sydney. We provide Digital Workflow and Compliance solutions in the renewable energy industry and document processing.
Thanks to our meteoric growth and our commitment to be the best at all we do, we've identified the need to bring on board a new Junior Fullstack Data Engineer.
Reporting to our Principal Machine Learning Engineer, you will help build Machine Learning pipelines for our existing Digital Workflow and Compliance solutions to automate fraud detection and document processing over terabytes of photographic and documentary data – including documents, photos, GPS data and aerial/satellite photography.
Our stack is based on Python, JavaScript, Dask, Tensorflow, CUDA, Nix/NixOS, AWS, Docker, PostgreSQL and more – familiarity with these applications will give you a leg-up on the competition.
Our ideal candidate will have the following competencies:
SQL
Python
JavaScript/TypeScript
Our candidate must also be comfortable working with Linux.
Located a stone's throw away from the Queen Victoria Building in Sydney's bustling CBD, we are centrally-located with easy access to public transportation, bars, cafes and fine dining.
Formbay will provide flexible working hours, a generous remuneration package and the opportunity to work on a world-first software solution are what we can offer you. Free, twice-weekly gym sessions and really, really good coffee are also available.
No hiring/recruitment agencies need apply.",5.0,"Formbay
5.0",Sydney,-1,1 to 50 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is an experienced and qualified Data Engineer to join our IT team based in Birtinya.
Key Responsibilities:
Create and maintain data pipelines and or ETL scripts
Create and maintain data integration including API and Batch interfaces
Performed detailed data analysis
Create and maintain corporate data models
Create and maintain data visualization using Qlik.Sense , PowerBI or Simliar Toolset
Experience in defining, building and maintaining data virtualization and/or star schema data warehouses
Maintain, tune and optimise database, integration and visualisation toolsets
ABOUT YOU:
To succeed in this role, you’ll need to bring the following experience and skills:
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Excellent communication skills both oral and written, with an ability to bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking
Experience with data analysis and modelling will be beneficial

How to Apply
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kawana Waters,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Graduate Data Science / Engineer,-1,"The NRMA is an organisation looking to the future, and right now, we are on the lookout for people who can help us reach our goal: to continue to shape the way Australians move, for the next 100 years and beyond. www.mynrma.com.au.
Everyone new to the team, along with our current staff, will temporarily work from home until it is safe to return to our offices. All interviewing and on boarding will be done virtually due to COVID-19.


Your opportunity
As Graduate Data Scientist or Engineer you will be part of the Data Engineering team delivering cloud data transition program for business initiatives and supporting the entire data platform build.
Your key responsibilities will be to:
Implementing Concepts of Data Warehousing, Data Mart creations within Cloud
Use of SQL for data analysis and insights
Building AI/Machine Learning prototype for implementing and supporting existing algorithms
Data Analytical reports build, using different tool sets


Requirements for Success:
Relevant Degree - Computer Science, Computer Engineering, Software Engineering, Data Science
Excellent SQL skills and demonstrated working knowledge in Python
Demonstrated understanding in data structure and algorithms.
Knowledge and concept of data warehousing methodologies
Any reporting tools experience Tableau or Oracle Analytics Cloud, Looker is desirable
Exposure to Google/AWS/Azure/Oracle any cloud based platforms is desirable
Good communication and interpersonal skills

If you have the required skills and the passion to join our high performing team, please apply today.

Employee Benefits
To ensure our employees feel valued, empowered and celebrated we provide a range of employee benefits including:
50% discount on all NRMA insurances
Free Roadside Assistance
12 weeks paid primary and 4 weeks paid secondary parental leave
Free NRMA Blue Membership
At the NRMA Group, we are People Moving People and diversity and inclusion are part of our DNA. Together, we continue to build an inclusive culture that encourages, supports and celebrates the diverse voices of our employees. It fuels our innovation, promotes flexible ways of working and connects us closer to our members and the communities we serve.",2.5,"NRMA Motoring & Services
2.5",Sydney,-1,501 to 1000 Employees,-1,Nonprofit Organization,Casual Restaurants,"Restaurants, Bars & Food Services",$500 million to $1 billion (USD),-1
Data Centre Engineer,-1,"We are a leading world group that provides low-carbon energy and services. To tackle the climate emergency facing us all, our aim is to become the world leader in the zero-carbon energy transition ""as a service"" for our clients – particular for companies and regional authorities. We use our expertise in our key business areas (renewables, gas, services) to provide competitive and bespoke solutions.
The Data Centre Engineer will be employed as part of a 24/7 ongoing shift to coordinate and monitor third party service providers, maintain the data centre facilities and infrastructure plans, coordinate the implementation of customer requests within the data centre and monitor systems, all in accordance with the Contract KPIs and SLAs.
Coordinate and monitor third party service providers for regular maintenance & testing, service faults & call outs, ensuring works are performed in accordance with Contract SLAs
Monitor and maintain the data centre facilities and infrastructure plans and documentation, including electrical, mechanical, hydraulics, fire and BMS/EMS systems
Coordinate the implementation of internal and external customer requests within the data centre
Perform scheduled plant checks and minor maintenance works
Ensure all Work Order requests are raised and closed in a timely manner
Conduct inductions for staff, vendors and contractors
Ensure all work permits for vendor works are raised and closed
Perform inventory checks on all equipment and critical spares

Qualifications
The selected candidate must be able to demonstrate:
Electrical or HVAC background, or Graduate Electrical or Mechanical Engineer
Passionate about quality work and career minded looking for a new challenge
Can commit to a day and night shift roster (2 days of day shift, then 2 days of night shift, 4 days off)
Ideally able to commence asap
As part of carrying out the duties of this role, it is mandatory to hold Australian Citizenship.

If you are interested and meet the selection criteria apply with an up-to-date resume via the apply instructions on this website.

ENGIE Services is an EEO employer, where all applicants are treated with fairness and respect and have equal access to the opportunities available.

We will not be engaging in the services of a recruitment agency to fill this vacancy and therefore request all interested candidates apply directly to this advertisement.

Job
: Maintenance
Primary Location
: Oceania-Australia-New South Wales-Erskine Park
Organization
: ENGIE Services Australia and New Zealand
Schedule
: Full-time
Nature of Responsibility
: Senior operational / administrative role
Job Posting
: Sep 11, 2020, 6:29:59 AM",3.7,"ENGIE Services Australia & New Zealand
3.7",Sydney,-1,5001 to 10000 Employees,1995,Company - Public,Energy,"Oil, Gas, Energy & Utilities",$2 to $5 billion (USD),-1
Senior Data Engineer,-1,"Senior Data Engineer, Temporary, SYDNEY - McKell

Job Title: Senior Data Engineer

Salary: SNSW Grade 9/10 - The package includes base salary range of $111,806 to $134,667, plus employer's contribution to superannuation and annual leave loading.

Location: Head Office – Haymarket

Employment Status: Temporary through till 30th June 2021


About Service NSW:

Service NSW is making it easier for people and businesses across NSW to access government services. The role designs, builds and analyses complex data from multiple sources to identify revenue, process and business improvement opportunities; providing new information and insights to the business to inform planning, continuous improvement and performance.

About the Role

We are currently seeking to appoint a Senior Data Engineer to deliver expert advice and services in the design of a Single View of Customer and data-related services to support the achievement of business outcomes and strategic goals. We support flexible working practices with staff working remotely during this time.

In this role you will:

Design, build and support a modern data platform based in AWS and vendor technologies.
Provide expertise on data modelling for Graph data model and Customer Data Platform (CDP).
Create data pipelines, load, transformation and reporting workloads in AWS.
Work with the latest data engineering technologies like Apache Kafka, AWS Kinesis, AWS Neptune, AWS Glue and AWS Athena.
Contribute to the design and decision-making of the right tool or platform for the job according to requirements.
Provide expert advice and guidance on data quality and data engineering best practices.
Support a “bigger than you can imagine” scale of data in production environments.
Design, develop and support a metrics-driven reporting solution and a meaningful business intelligence platform.
Document the solution design and support procedures of solutions.
Produce reports, visualisations and recommendations to answer complex business problems that are presented in the most appropriate format to ensure clarity for target audience.
Analyse and define new process improvement opportunities to support continuous improvement and business outcomes; providing advice to stakeholders, on ways to improve the efficiency and reliability of data products and services.
Be very responsive to the information needs of the business by corresponding to customers in a timely manner and provide support/solutions to issues raised.
Troubleshoot and perform root cause analysis on production issues. Identify and implement long term solutions to problems. Perform scheduled maintenance, release deployment and production support activities after business hours, from time to time.
Liaise with internal and external customers to discuss and gather requirements, solutions etc. and maintain a good working relationship with the stakeholders.


Skills and Experience Required:

Solid experience with workflow technologies designing and building data pipelines, data models and data stores.
Experience working within and an understanding of Amazon AWS ecosystem, including security and performance tuning.
Hands on experience working with different types of databases, with focus on Graph and NoSQL databases.
Experience with data streaming required. Having used Kafka and related technologies is an added advantage.
Sound knowledge and experience working with batch processing, data extraction and API integration.
Hands on experience with at least one programming language: Java, Python or scripting.
Demonstrated experience working in an Agile based, fast paced, complex environment within cross-functional teams.
Experience developing systematised insights, data analytics and reporting solutions is an added advantage.
Experience with interactive visualisation of data insights is an added advantage.


Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Salary Grade 9/10, with the base salary for this role starting at 111,806 base plus superannuation

Closing Date: 6th November at 9:59am - applications will be reviewed on a rolling basis, applications may close early or extend

Please apply online, direct applications submitted via email will not be considered.

The Department of Customer Service is proud to be an EEO Employer who are fully focused on equality and believe deeply in diversity of all identities making us different and a true reflection of our NSW customers. As an inclusive workplace, we support various employee resource groups, practice flexible work and workplace adjustment.

If you do require an adjustment during the recruitment process, please notify us on your application form.",3.2,"Service NSW
3.2",Sydney,-1,501 to 1000 Employees,2012,Government,State & Regional Agencies,Government,Unknown / Non-Applicable,-1
Data Engineer - Entry / Mid Level,-1,"Work with a great team on interesting projects customers
Gain more experience in AWS, Data, DevOps cloud operations
Got a working knowledge of AWS? We will teach you the cool stuff!

Itoc is seeking an up and coming Data Engineer to join our growing Data Team in Sydney.

This is an exciting role working with databases, data lakes, data warehouses, data transformation (Python SQL) and enabling AI/ML.

You will be implementing foundational, robust and production ready data platforms to enable business data-discovery, self-service, AI/ML functions across a range of client types and industries, allowing them to do more with their data.

You'll be responsible for:

Deploying data repositories such as lakes and warehouses.
Contribute to our growing portfolio of data solutions.
Ongoing optimisation and management of data platforms.
Development of transformational logic for data pipelines
Data evangelism. We want to show our clients how to follow the best practices for data.

Desired Skills and Experience

To take up the challenge, you will have a depth of skills and experience including:

1-2+ yrs of focused data experience working with SQL and/or NoSQL solutions
A solid education in Software Engineering or equivalent industry experience.
Anything Data focused preferred.
Ability to analyse business scenarios and associated data landscape to derive potential opportunities.
Strong foundation in Python and SQL
Working knowledge of APIs
Principle knowledge of the different relational database platforms and modern data storage techniques
Knowledge of the different aspects of data environments
Collect, store, process, verify consume
Experience with version management systems (such as GIT)
Working knowledge of AWS or another cloud platform - we will teach you the cool stuff.
Great communication skills, an ability to work closely with customers, developers and engineers and the confidence to present ideas in open forums.
Relevant tertiary qualifications and/or industry certifications.
Great communication skills, an ability to work closely with clients, developers and engineers and the confidence to present ideas in open forums.

While not required, a background in consulting and professional services is highly desirable.

Itoc Description

This is an exciting and challenging career opportunity to join the growing Sydney-based Data Team of a leading cloud solution provider where you will be given support to reach your long term career goals. You will be part of a team of cloud experts and will work in an environment of continuous improvement and learning delivering innovative cloud solutions across SaaS, online business and enterprise business.

On offer is a chance to join a team with a great working environment, in an organisation that values its employees and sees the value in ensuring they are engaged. Our team are clearly passionate about what they do, that's why we won the following awards:

Customer Obsession Partner of the Year 2015: ANZ Region
Customer Obsession Leadership Partner 2015: re:Invent

As an employer of choice Itoc offers competitive remuneration, training and development programs and a great working environment. We value a healthy work life balance.

The Perks

MacBook or Dell
Continuous internal learning that will provide training and career development opportunities
Working with a collaborative, social team and leveling-up your skills faster than you will anywhere else.
Quarterly social events

Itoc

Culture and smarts are important to us. Bring your secret sauce. This is no ordinary environment, you will work along some of the Cloud’s best. All engineers at Itoc must gain at least five AWS certifications. We work hard but we have fun.

Please note you must have full working rights in Australia and be available on-shore for face to face interviews.

No recruiters please.",4.0,"Itoc
4.0",Sydney,-1,1 to 50 Employees,2013,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Date: 01-Oct-2020

Location:
Melbourne, VIC, AU

Department:Description:
Technology discounts - from Apple HP Lenovo to Windows
Flexible work arrangements - work in a way that suits you best
Salary packaging - to suit your personal and financial circumstances

Do you want to work for one of the fastest growing data teams in Australia? Do you want to work on multiple data platforms and provide new solution offerings by leveraging cloud and big data technologies?

About the team

Big data information and analytics. Three words that spark apprehension in most businesses. But our team of experts are constantly curious and excited about combining our wonderful array of technological expertise to transform data into our clients most valuable assets making their work smarter. Our data consultants are supported with resources training and tools they need to excel at their work but also the freedom and power to create their own paths forward to make a difference.

As a Senior Consultant in Big Data you will work closely with the team and stakeholders to build and deliver a Cloud based vision for a next generation Big Data analytics platform with strong focus on data quality data security and deliver the systems that process huge volumes of data.

What will you typical day look like?

You will play a pivotal role in - Designing and producing high performing and stable applications to perform complex processing of massive volumes of data in a new cloud based architecture; Building real-time data processing applications which are integrated with business systems to enable value from analytic models to drive rapid decision making; Contributing to system architecture design for a data platform (including cloud-based structures both on and off premises data warehouse components and data lakes); this could cover a range of technologies various countries/locations and lines of business; Support data strategy or technology strategy definition programs including technology stack definition and target operating model requirements

Enough about us lets talk about you:
You are someone with:
Use of traditional data analytics tools and techniques (e.g. MSSQL Oracle MySQL) and ETL software (e.g. SSIS Informatica CloverETL)
Working in large scale cloud data solutions using platforms such as AWS or Azure or GCP will be a bonus.
Experience in scripting or programming (e.g. Python Java Scala C#)
Excellent verbal and written communication skills to adapt to technical and non-technical audiences.
Educated to degree level (or have equivalent experience)
Why Deloitte?

At Deloitte we create positively differentiated work experiences that enable our people to feel valued and achieve their full potential. We value difference and embrace people with diverse backgrounds and thinking styles. Knowing that people work best in different ways we are happy to discuss alternative arrangements if the working pattern you are looking for is not specifically indicated.",3.8,"Deloitte
3.8",Melbourne,-1,10000+ Employees,1850,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Engineer,-1,"Opportunity to grow the team
Period of growth
Intuitive app
S2M are working with a FinTech who have created a unique financial product to help thousands of people better manage their finance, and is currently scaling the company to the next level!

They are looking for a Data Engineer to join, and looking for someone who wants to be hands on, with opportunity to grow the team in future.

Role:

Looking for people with strong AWS experience. You will need passion for data and a cloud, through which you will help a rapidly scaling Australian FinTech establish their data infrastructure from the ground up.
5+ years’ experience as a data engineer within the data and analytics domain
A python 3.X aficionado who is very comfortable creating and orchestrating AWS data pipelines with nothing but code
Strong project delivery toolset experience in open source data integration tools
Experience with processing large volumes of complex data including visualisation and insights generation
Ability to define and develop data integration patterns and pipelines
Ability to assess complexity of data (volume, structure, relationship etc.)
Hands on experience working with different databases (RDBMS, NoSQL, Blob storage etc)
Hands on technical expertise setting up DevOps automation
Hands on experience working technologies/platform e.g. AWS, Dockers, Containers
Experience building data profiling and data cleansing frameworks
Technical reconciliation and reporting
Knowledge and experience in end-to-end project delivery, either traditional SDLC or agile delivery methodologies (or hybrid approaches)
Exceptional communication, documentation and presentation skills
If this sounds like you, get in touch today - kate.gabb@s2m.com.au
3167410agsdf",3.1,"S2M
3.1",Sydney,-1,Unknown,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Analysts,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is seeking experienced and qualified Data Analysts to join our IT team based in our corporate office in Birtinya (Sunshine Coast) or at our meat processing facility in Kilcoy.
Key Responsibilities:
A mixture of data analysis and commercial skills to source, blend and analyse data to gain insight and answer key commercial questions
Working with strategic leaders to define and model Key Performance Indicators, and assist in building forecasting models
Working closely with data engineers and BI developers to specify data pipelines and report visualisation
Drive the creation and implementation of data quality business rule including data definition, governance and quality assurance
About You:
To succeed in this role, you’ll need to bring the following experience and skills:
Proven ability to derive insight and knowledge from data using commercial expertise is a strong requirement
Strong SQL and Excel skills are essential, along with strong data analysis and commercial insights
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Effective people communicator - engage with stakeholders on reporting needs, interpret requirements into visual solutions and train/deliver the outputs to the stakeholders getting signoff of acceptance
Bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking

How to Apply:
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kilcoy,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Network Data Engineer,-1,"Min 6+ years of experience in the relevant technologies
Australian Driving License for visiting remote locations / Data Centre for day to day technical work.
Managing Network devices (switches, routers, firewalls, load balancer, and wireless technology)
Performing MACD activities for all network devices.
Supporting BAU operation activities.
Proficient in performing in-depth details of technical troubleshooting, cause and provide recommendation to the client for incidents causing extended network outage to client’s critical locations.
Provide exceptional network services in terms of network support, break-fix, design and consulting, new projects, implementation.
Configure, administer, and document firewall infrastructure.
Manage the firewall deployment, rules migrations, and firewall administration.
Supporting Cloud Migration Activities from traditional to AWS/Azure.
Setting up VPN tunnel with Cloud and 3rd Party network devices.
Integrating and upgrading existing ISP bandwidth with support from ISP Vendor.
Setting up VPN profiles for Users.
Installing hot fix and patches to mitigate the security devices from attacks and bugs.
Reviewing and fine tuning the firewall rules and NAT rules.
Documentation and change control.
Mentoring, Motivating and Guiding support teams
Technical skills:
o LAN
o Wireless
o WAN
o MPLS
o Routing protocols (OSPF,BGP)
o DMVPN
o Azure cloud Networking
o Network Security
Fortigate Manager / Analyzer / Firewall
Cisco ASA
Firepower FTD
Cisco Any connect
Site to Site VPN
F5 Load Balancing and Scripting iRule
Job Types: Full-time, Contract
Schedule:
8 hour shift
Experience:
Scripting: 5 years (Required)
Data Network: 5 years (Required)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Required)",3.6,"Total IT Global
3.6",Sydney,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Engineer - Processing & Analysis,-1,"Job Description:
Design,build and maintain the ingestion system to support various types of data(e.g. User behavior, RDS, NoSQL db and others) to be ingested to the data warehouse more timely and accurately
Translate data requirements into scalable technical data service with low latency and high concurrency
Design,build and maintain the batch or real time data pipeline in production using Hadoop big data technology
Analyze and improve efficiency, scalability, and stability of the system
Define and manage SLA,Data quality for all data sets in allocated areas of ownership
Requirements:
Minimum B.S. degree in Computer Science or a related technical field
2+ years of working experience in programming languages,such as Java,Scala,Python
Familiar with Hadoop, Spark and Flink data processing, experience of TB data processing experience is a plus
Familiar designing and operating of a robust distributed system is a plus
Understand data mining or machine learning
Excited to work intimately with data
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"SYNOPSIS:
Lead Data Engineer
Applications close Sunday 8 November 2020
Ongoing
Contact name: Shyni Sasikala
Phone: (02) 6249 9048
Email: Shyni.Sasikala@ga.gov.au

The Data Policy and Informatics section within the Digital Science and Information branch creates, implements, and promotes policies, platforms and tools that improve and support the quality, discoverability, accessibility, and general usability of Geoscience Australia’s science data products. The section consults with internal and external research, government and industry partners to establish collaborative data frameworks, architectures and models within Geoscience Australia (GA) and across broader national and international communities of practice. The section innovates, builds and maintains tools, systems, processes and governance that enable digital data management, cataloguing and open data delivery.
GA makes accessible a wide range of geoscientific and spatial data to a wide variety of stakeholders in multiple formats, and in recent years GA's data volumes have grown exponentially. GA is focussed on making its data and metadata assets accessible so that they can be used in machine to machine interactions for data analytics and other applications in environments that range from High Performance Computing (HPC), through high-end cloud servers, to mobile devices.
We currently have two opportunities for Lead Data Engineers in the Informatics team. The Lead Data Engineer is responsible for innovating and exploring new technologies that will advance GA’s science goals and maximise the uptake and use of GA’s science data. The Lead Data Engineer reports to the team’s Assistant Director but also works closely with other developers, data scientists and engineers within the Digital Science and Innovation (DiSI) branch, as well as diverse stakeholders both within and external to GA.",3.9,"Geoscience Australia
3.9",Canberra,-1,501 to 1000 Employees,2001,Government,Federal Agencies,Government,$100 to $500 million (USD),-1
Data Engineer,-1,"The Seven Network is part of Seven West Media, one of Australia’s most prominent media companies, with a market leading presence in content across broadcast television, online and in print. Comprising some of Australia’s most renowned media brands, SWM includes not just Seven Network and its affiliate channels 7two, 7mate, 7flix and BVOD offering 7plus, but also 7NEWS.com.au, The West Australian, The Sunday Times and more.
At Seven we are here to bring all Australians closer to the moments that move us - we’re first on the scene, with our finger on the pulse, on demand, in the moment. Together, we’re responsible for creating and sustaining authentic Australian engagement.
A new and exciting opportunity has opened for a Data Engineer to join the Audience Intelligence team. Based in Sydney and reporting to the Head of Data Enablement, you’ll be responsible for:
Implementation of end to end data solutions to support Data Strategy for the SWM group.
Work closely with the Data Solution Designers to develop and maintain scalable data pipelines and build out new file and API based integrations to address requirements from the various business stakeholders.
Collaborates with engineering, analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organisation.
Work on Data Preparation for analytics and data scientist team members and assist them from an engineering perspective in building and optimising the models including building the automation of the end to end workflows
Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.
Perform data analysis required to troubleshoot data related issues and assist in the resolution of production data issues.
Work effectively with vendors for successful delivery of projects and acceptance of the solution
Work on Delivery projects using Agile Software Development methodologies
We are looking for someone who has:
Bachelor's degree in computer science, computer engineering or other technical discipline is essential
Proven experience working as a digital analytics specialist
Extensive experience with digital analytics implementation (e.g. Google Analytics, Snowplow, Adobe Analytics) and BI processes and visualisation platforms
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience in ETL and building and optimizing ‘big data’ pipelines and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Experience with big data tools: Hadoop, Spark, etc., AWS cloud services: EC2, S3, Lambda and familiar with version control systems: Git
Strong coding skills with knowledge of Unix/Linux and scripting languages such as Unix Shell scripting, Python desirable
Experience supporting and working with cross-functional teams in a fast-paced environment.
Ability to multi-task and problem solve with changing demands and priorities
Ability to work under pressure to meet deadlines and detail oriented
Your success is our success: we will provide you with opportunities for you to keep learning and growing, enabling you to challenge and develop yourself. In return, we offer a benefits program that has something in it for everyone.
Seven West Media is an equal opportunity employer and we are committed to creating a diverse and inclusive workplace.
Recruitment Agencies: Seven West Media does not accept any unsolicited agency resumes and will not be responsible for any fees related to unsolicited resumes.
Advertised: 19 Oct 2020 12:00 AM AUS Eastern Daylight Time
Applications close:

Back to search results",2.5,"Seven West Media
2.5",Sydney,-1,5001 to 10000 Employees,1956,Company - Public,TV Broadcast & Cable Networks,Media,Unknown / Non-Applicable,-1
BICON Rules Engineer,-1,"APS 5 - $73,299 - $80,410 per annum plus superannuation
Biosecurity Plant Division
Canberra, ACT
Play an active role in managing biosecurity risk to Australia
Work in a motivated and professional team with a wide range of skills and backgrounds
Full training provided

Who we are
The BICON Content Development Team maintains and improves the Biosecurity Import CONditions database (BICON) content to allow external clients to understand and comply with their biosecurity obligations and internal clients to effectively manage biosecurity risk and regulate imports. We work collaboratively with internal clients to comprehend and implement their BICON content requirements and optimise the use of BICON to publish clear import requirements and onshore management support procedures to effectively manage biosecurity risk.

The Jobs
Key duties of these positions include:

working with business content (import and permit conditions) and import programs to understand and construct decision tree structures in the BICON database, in accordance with system design and authoring conventions
executing changes to import and permit conditions in alignment with service standards while complying with system rules and authoring conventions
providing technical advice through various formats on the most appropriate means of authoring BICON content to achieve import program and stakeholder objectives
using workflow management tools to maintain detailed records of changes to import conditions and key decisions
performing administrative tasks including system reporting, data analysis and scoping tasks for the BICON content change work program
contributing to the development and maintenance of instructional material, authoring conventions and courseware
clearly documenting and reporting system issues
developing and maintaining effective working relationships with internal and external stakeholders.

What we are looking for
Knowledge and experience
Experience working with complex IT systems.
Experience working collaboratively and as part of a team.
Knowledge of the role of biosecurity is preferred but not essential.

For additional information, please read the Job Description below.
Candidate Information Package docx Opens in new window",3.9,"Department of Agriculture & Water Resources
3.9",Australia,-1,5001 to 10000 Employees,-1,Government,Federal Agencies,Government,$500 million to $1 billion (USD),-1
Cloud Data Engineer,-1,"Job no: 509605
Work type: Permanent Full Time
Location: Melbourne, Canberra, Sydney
Do you embrace digital disruption?
Do you love solving complex problems, designing sophisticated solutions and building innovative technology?
Do you believe in creating powerful actionable insights from Data and Analytics?
Do you want to work in a diverse and flexible working environment?
KPMG is one of the most trusted and respected global professional services firms. Through depth of expertise, clarity of insight and strength of purpose we help our clients solve complex challenges, steer change, strengthen, transition and grow. We are a team based practice and this extends to our clients whom we work and collaborate with, in solving complex problems. Together, we design, innovate and implement, providing enduring advice that support our clients and the services they deliver. Our clients vary in size and come from a diverse range of sectors – all sharing in a common goal: to embrace change and deliver services that make Australia a better place. We are looking for talented individuals who would like to join us on the journey.
KPMG’s Digital Delta Team
We re-imagine and re-invent organisations to become world class digital enterprises using advanced technologies, data and human insights. We help organisations to embrace Digital Strategy, Artificial Intelligence (AI) & Cognitive, the Internet of Things (IoT), Data, Analytics & Modelling, Mobile App & Web, and User Experience (UX) & User Interface (UI) and more.
We work with clients to:
Formulate strategies that re-imagine organisations
Harness innovation from the 4th industrial revolution
Actioning insights from trusted data to consistently and quickly make clear decisions
Build adaptive organisations
Thrive as a connected enterprise – front, middle and back office
This is how you’ll contribute:
We are looking for ambitious Data Engineers who are passionate about helping clients define bold ambitions and deliver on them. Joining our team will take you on a journey of personal and technical growth and provide the opportunity to inspire confidence and empower change.
As a Data Engineer you are the designer, builder and manager of the information or ""big data"" infrastructure, preparing data for analytical or operational use. You will design, construct, test and maintain a data pipeline to pull together information from different source systems; integrating, consolidating and cleansing data; and structure it for use in individual analytics applications.
The KPMG Difference
Our people are focused on creating a diverse and dynamic environment that embraces and values differences. We value the variety of unique experiences, qualities and characteristics our people possess and we share and learn from each other.
We are proud to be consistently recognised as an employer of choice for women, and for our achievements in LGBT+ workplace inclusion.
Our commitment to ‘Flexibility’ allows our people to manage the changing demands of work, personal or family life. Explore the links below to hear our people share their experience @ KPMG:
Flexibility empowers wellbeing
Flexibility enables contribution to the community
Flexibility inspires technology & innovation
Flexibility supports family

Make KPMG the clear choice for your career and be Extraordinary!

Advertised: 09 Sep 2020 AUS Eastern Standard Time
Applications close:",3.8,"KPMG
3.8",Sydney,-1,10000+ Employees,1987,Subsidiary or Business Segment,Accounting,Accounting & Legal,$2 to $5 billion (USD),-1
Computer Network and Systems Engineer,-1,"Duties Include but are not limited to:
Tasks Include:
analysing, developing, interpreting and evaluating complex system design and architecture specifications, data models and diagrams in the development, configuration and integration of computer systems
researching, analysing, evaluating and monitoring network infrastructure to ensure networks are configured to operate at optimal performance
assessing and recommending improvements to network operations and integrated hardware, software, communications and operating systems
providing specialist skills in supporting and troubleshooting network problems and emergencies
installing, configuring, testing, maintaining and administering new and upgraded networks, software database applications, servers and workstations
providing network programming in support of specific business needs and requirements
preparing and maintaining procedures and documentation for network inventory, and recording diagnosis and resolution of network faults, enhancements and modifications to networks, and maintenance instructions
monitoring network traffic, and activity, capacity and usage to ensure continued integrity and optimal network performance
Skills and Experience Required:
Must have experience working in a Managed Service environment
Demonstrated experience in IT Networks and Data Centres
Understanding of systems and architectures to meet client needs
Experience in Help Desk including break / fix
Effective and timely documentation
Effective Task Management Skills
Be solution and outcome focused and willing to learn new technologies
Excellent communication skills with staff, clients and partners
Time management, ability to prioritise and deliver to schedule
Experience with N-Able and Connectwise desired
Open Cabling license desired
Job Types: Full-time, Permanent
Salary: $30.00 per hour
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,Trans-plant training,Canberra,-1,-1,-1,-1,-1,-1,-1,-1
Software Engineer (Data),-1,"If you are looking for an opportunity to make a real impact with smart people who are genuinely doing things differently then you've come to the right place! We're growing our data engineering capabilities and are looking for awesome data engineers to join our team.
With our diverse range of clients and projects, no day will look the same - but here's a great snapshot of what you'll be doing:
Work with some of the best Data Scientists and Engineers to deliver production-grade AI and Machine Learning systems as we deliver client projects from inception to production.
Consulting with our clients and working with them to build modern data systems using the 'best of' technologies and principles.
Advising clients on data strategy, architecture and technology.
Applying best software engineering practices in coding, monitoring and alerting, using CI/CD, TDD and cloud architectures.
Working over a wide range of big data tools and environments: not limited to; Apache Kafka, Spark, Python, Scala, Hive, Airflow, AWS EMR & Glue, GCP Dataproc & Dataflow, BigQuery, Snowflake, Redshift.
Who are we?
Glad you asked! We are Eliiza. Data science. Engineered for scale.
We are a passionate team of data scientists and engineers who apply data science and machine learning to solve real-world problems. Our mission is to create a bright future for Australian businesses and society in a world increasingly influenced by intelligent technologies.
We've created a culture that values diversity where people can truly be themselves! We care a lot about growing the Australian AI community in a positive direction, and we're doing several things to try and achieve that:
We provide opportunities for underrepresented groups to work in AI through our associate and intern programmes
We organise and participate in a range of community events, reading groups and meetups
We produce the AI Australia podcast
We blog about topics we care about
We stream brown bag sessions to the broader community
We're also part of Mantel Group's 'house of brands' which means it's not just the Eliiza team you'll work with, learn from and see at social events - there's another 230 of us across DigIO, Kasna & CMD Solutions!
So you're ready for something new?
We're keen to know more about you! Our team is made up of a range of people, with different experience across a huge range of data driven skill sets.
We'd love to hear from you if you have experience with:
one (or more) core language(s), ideally Scala, Python or Java
one (or more) cloud platforms, AWS, GCP, Azure
ETL/ELT concepts and technologies e.g. Data partitioning, Hive, Spark
streaming data concepts and technologies, ideally Kafka (Kinesis, Beam or Pubsub will do)
We'd be over the moon if you:
Experience with distributed/columnar databases (e.g. Snowflake, Big query, Redshift).
Experience with any of a variety of databases e.g. RDMS, NoSql, Columar, Distributed, Time series, Graph.
Knowledge of job orchestration and scheduling. Any experience with Airflow, Luigi or Oozie.
Experience with containers and container orchestration (Docker, Docker Compose or Kubernetes).
However, we value a diversity of skill-sets, and don't necessarily require that you're skilled with all of the above. If you feel you don't fit all the experience/skills listed above we still encourage you to apply or get in touch.
What's on offer if you join us?
We make sure you're always one step ahead by investing your learning and development, every year. We build our own training where it doesn't exist yet.
We hire smart people and get out of their way. By focusing on our five principles and not getting caught up in red tape, we trust you to get the job done.
You'll get all the tools you need - a new iPhone or Google phone, a new Macbook Pro or Dell, and a lot of branded swag!
But hold on, you mentioned a house of brands?
We certainly did! Mantel Group is an Australian-owned, 'house of brands' company with four technology businesses (Eliiza being one of them!) across Melbourne and Sydney. We're building a group of companies with open borders so we can support you to take on new skills without leaving an awesome team - we understand you won't have one job for life!
We may only be just two years old but Mantel Group has already been recognised #9 in the 2020 Best Places to Work in Australia and #4 in the AFR's 2020 fastest growing new companies.
Keen to chat?
Click ""Apply"" to share your details with our talent team, and we'll be in touch.
In the meantime, check out 'how we hire' to find out what's in store if you're successful and get to know us better by visiting our website and following Eliiza on LinkedIn.",-1,Eliiza,Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Infrastructure Engineer,-1,"Job Description:
Design and grow the Shopee data platform to support a variety of big data applications using open-source technologies including Kafka, Hadoop, Presto, HBase, Spark, Hive, Druid, and our own creations. Some examples include a real-time data streaming platform, a unified query platform, a cluster management system, and a machine learning platform
Dig into the source code of some open-source big data system to get the whole control and familiar with the details, configurations, designs and source code. Develop and maintain the internal release of big data systems and components as the business requirements.
Keep close and overall monitoring for all the deployments of the systems, maintain the system’s stability, improve the performance, discover the performance bottlenecks, tracking and troubleshooting, cost optimisation.
Requirements:
B. Sci. / Ms / PhD in Computer Science or a related technical field
Familiar with at least one of these languages: Java, Scala, Python, Bash under Linux / Unix. Scala is a plus
Familiar with the use and compute logical of SQL
Knowledge about the Big Data Infrastructure system technology like Distributed File System, Distributed Computing, Distributed Database will be a plus
Hands-on experiences Hadoop, Spark, Kafka, and/or Presto will be a plus
Love to use and develop open-source technologies
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"Work on an award-winning, international technology!
Endless career opportunities
An innovative, friendly team of 300+
This role will be focused on the development of our existing ClaimLogik line of products as well as working on our new cloud-first, modern suite of applications.

Intelligent Thought, our technology business is scaling and shipping our software globally. Already profitable, part of a much larger group business, with investors such as Macquarie Capital and Envest – we are all set to deliver textbook disruption to the Insurance Industry. The growth of the platform, of our customer base, and the increasing industry demand have led to the need for this role to help the team scale.

Our Philosophy
Give each employee a sense of purpose and an environment for them to connect the importance of their role to delivering a service that matters to our customers.
Challenge the ‘why’ of traditional claims processes.
Keep it simple – do only what brings value and what matters to the customer
Enable employee decisions, empower our people
Responsibilities:
Create, extend and maintain ETL pipelines to form our data lake, data warehouse and analytics platform (currently using the Microsoft Azure set of tools and service)
Help define the optimal data pipeline architecture
Influence the tool selection, platform selection, data architecture and strategy which will transform the business to be truly data-driven
Understand, analyse and size user requirements
Work with different parts of the business to provide them with the insights they need to deliver the best results
Skills & experience:
Degree or qualification in computer science or related
Advanced knowledge of relational database, including query authoring and query optimisation (MS SQL Server and PostgreSQL).
Experience building and optimising ETL pipelines
Experience designing complex data models
Experience working with cloud platforms (Azure or AWS)
Efficient time management and organisational skills
High attention to detail and accuracy
Effective communication skills to build strong working relationships; both written and verbal
Proactive and results-driven
Why Claim Central?
Claim Central Consolidated is a global insurance industry leader across, claims management, insurance technology and data and analytics. Currently operating in the United States, Australia, South Africa, Italy and New Zealand, we have pioneered digitally connected claims management services across the globe. Claim Central is a disruptor and thought leader in the industry and we were recognised as the Australian Financial Review’s 8th Most Innovative Company in Australia in 2016. This business is in a period of unprecedented growth, transitioning our technology and services into multiple geographies at a rapid pace. Our unique culture is based on teamwork, collaboration, trust, respect and performance. We also offer many benefits apart from our exceptional team culture; including flexible work arrangements, and continued professional development.

Be a part of this journey in a career-defining role.",-1,Claim Central,Matraville,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer - AI/ML,-1,"Our client provides services to a major industry across the country. The business is still early in it's days of technology development and the environment is greenfields in nature (no pun intended), effectively working like a start-up.

Their data and analytics team have worked and built leading and bleeding-edge technologies in this space and what they have created so far may be game-changing. From a machine learning perspective, the progress they have made to the business has already seen proven success in changing the future of an industry that will have positive consequences for all those involved.

You will have previously worked in a technical capacity in the data and analytics space and have experience working with an organisation where machine learning has been implemented, not just a concept that the business talks about having or the technology team would love to have. The commercial experience you will have had in the ML field will be proven examples of where you have affected the way a business or industry used to perform, to the changes that have come about from this.

Technically, you will have extensive experience in the Microsoft space - Power BI, Azure etc and you will have previously mentored and coached junior members of the teams you have been part of.

This is a rare opportunity in Brisbane where the business has truly embraced and funded projects across the ML space and would be a great chance for those in the Data Development/Data Engineering field, who are looking to move into a Data Scientist role in the future.

Please send your application through if you would like to know more.",4.0,"Emanate Technology
4.0",Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Solution designer/ ETL Engineer & Data Modeller,-1,"We are looking for a Qualified and Experienced Solution Designer to join our client for a period of 6 months with a view to extend.
You will work closely with team members and your contribution will range across gathering and analyzing information, developing and documenting improved processes and work instructions and experienced DWH Lead with skills in requirement analysis, solution designing, developing, testing and supporting ETL solutions.
A hands-on solution designer, data modeler and ETL developer for Data Warehousing and ETL application transformation projects using Informatica PowerCenter.
Knowledge on AWS, S3, Redshift, Informatica BDM, and related technologies.
Experience working with IPython, PySparks, AuCuMo, Airflow, Jenkins, Github, Athena, JIRA, Rally, Spectrum, Glue, Flyway.
Good exposure on Oracle PL/SQL, aware of DBA activities, writing and performance tuning of complex SQL queries.
Contract length: 6 months
Job Types: Full-time, Contract
Salary: $650.00 – $800.00 per day
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,nducive,Melbourne,-1,-1,-1,-1,-1,-1,-1,-1
"Data Engineer, Wollongong NSW or Mount Waverley VIC",-1,"Company Description
BlueScope is a technically advanced supplier of steel and steel products in Australia. We are an inclusive organisation and every day we showcase our technology and expertise throughout the world.

Job Description
We are looking for two Data Engineers to join our IT team, based in Wollongong NSW or Mount Waverley VIC. Use your experience in analytics to unlock business value, enabling use of big data for insights and decision-making.
Reporting to the Data Product Owner for our Australian Steel Products (ASP) business, this position will support strategic goals related to data. This will see you:
Gather business and technical requirements with the view to deliver outcomes;
Develop and implement end-to-end data collection, consolidation, modelling and visualisation solutions;
Document metadata in a dictionary and catalogue;
Ensure consumers of such information understand its accuracy, timeliness, quality and sensitivity, so that it is used appropriately; and
Identify opportunities to enhance analytics.
What are the benefits?
Work in a supportive and collaborative team environment whilst we embark on a journey to transform the way our business uses data!
Our systems landscape is broad and diverse. You will be encouraged to think creatively to develop data solutions which solve real business problems.
Working in this role you will enjoy:
the chance to learn more about data science;
salaried remuneration with attractive superannuation options;
the opportunity to participate in a performance incentive scheme; and
access to further development and career opportunities with BlueScope.
Who are we looking for?
We welcome applications from professionals with experience in data analytics and/or programming. Supported by your knowledge of project delivery methods (e.g. Agile), you will demonstrate:
experience with data mining, wrangling, mapping and visualisation techniques (e.g. Azure Data Factory, Databricks and/or DevOps etc.);
well-developed ability in gathering business and technical requirements;
skills in developing and implementing collection, consolidation, modelling and visualisation solutions; and
a passion for sharing your knowledge and desire for ongoing professional development.

Qualifications

null

Additional Information
We're proud to have been named an Inclusive Employer for 2019–2020 by the Diversity Council of Australia. We believe that our people are our strength. Having a diverse and inclusive workplace enables us to improve our capability and ensure continued, sustainable success.
We know that workplace flexibility can mean something different to everyone. Under our B-Flex initiative all of our roles have some degree of flexibility. We encourage you to discuss your needs with us.
Applications close Sunday 25th October 2020.",3.3,"BlueScope
3.3",Wollongong,-1,201 to 500 Employees,-1,Company - Private,Construction,"Construction, Repair & Maintenance",$100 to $500 million (USD),-1
ETL Data Engineer,-1,"ETL Data Engineer

Join a team that’s changing how Australia lives, works, plays and grows
We want you to be the best version of you

Work with innovative teams and explore new technologies to help solve real-world problems.

A typical day as a Data Engineer

ETL / Big Data Engineering professionals will be responsible for guiding the full lifecycle of a Data solution, including:
Working in highly client-facing roles to contribute throughout the end-to-end delivery lifecycle of complex and large-scale digital solutions
Use case and business case development
Support existing and new applications utilizing in-depth technical and data knowledge. Troubleshooting complex issues and providing advisory services to improve the client’s data landscape
Help to streamline and simplify the clients’ complex data landscape by integrating different applications and data architectures
Implementation from requirements analysis, platform selection, digital architecture design, application design and development, testing, and deployment
Interstate travel may be required

Basic qualifications:
Bachelor’s degree
Experience across systems integration, information management, data management and architecture, and business analytics
Experience with being in a team focusing on large-scale, multi-release information centric projects
Experience with waterfall and agile delivery and run / application support functions
Part of a team working on End to end implementation of at least 1 big data project

Preferred Skills:
Hand on experience in Data warehousing using ETL tools such as DataStage, Autosys and TeraData
Hands on experience in ETL job development with multiple stages like sequential file, Transformer, Lookup, join, sort and Database stages.
Strong hand on skills in design, development and implementation of various data remediation, Data migration, data integration techniques.
Strong hand on data modelling experience.
Strong hands on experience in database performance tuning including complex query optimizations and physical database tuning using Teradata.
Understanding of architectural designs and strategy related to data migration, data cleansing, data quality and data consolidation.
Proven data analysis, requirement gathering and problem-solving skills
Exposure to Unix environment and shell scripting.
Experience in Banking and Financial services industry
Desirable: Knowledge of cloud computing infrastructure (e.g. Amazon Web Services EC2, Google Cloud, Microsoft Azure)
About Accenture

Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. We combine unmatched experience and specialized capabilities across more than 40 industries — powered by the world’s largest network of Advanced Technology and Intelligent Operations centers. With 513,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises. Visit us at www.accenture.com.

Accenture is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, marital, domestic or civil partnership status, sexual orientation, gender identity, or any other basis as protected by applicable law.

Vera Goga is the Recruiter managing this role. As the team experience high volumes of applications, we appreciate your patience to allow for a fair and timely process.",3.9,"Accenture
3.9",Sydney,-1,10000+ Employees,1989,Company - Public,Consulting,Business Services,$10+ billion (USD),-1
Student Engineer,-1,"The candidate will have the ability to:
Undertake onsite inspection to collect asset condition data based on the relevant engineering standards and technical guidelines;
Undertake desktop analysis to evaluate the condition and performance of the assets;
Provide the appropriate information, advice, engineering input and support services for the sustainable management of Council’s stormwater and transport networks.
Qualifications:
The successful candidate will be enrolled in a Bachelor of Engineering with a minimum of two years completed.
Position Number: 100678
Position Hours: Fixed term (3 months), hours will be negotiated with the successful candidate, maximum of 75 hours per fortnight.
Salary: Schedule A, Salary Point 4.0. $28.64 per hour ($55,853.45 per annum, pro-rata) in accordance with Glenorchy City Council’s Enterprise Agreement 2016
Please note that all successful applicants will be required to provide a current National Police Check prior to commencement of employment.
For further information on this position, contact Patrick Marshall, Senior Civil Engineer on (03) 6216 6800.
How to apply: Applications for this position must be lodged on this submission site or on the Glenorchy City Council website www.gcc.tas.gov.au - Careers page.
To be considered for this role, all applicants must address the key selection criteria in the and provide a current resume. A copy of the position description can be found by clicking the below hyperlink or on the Glenorchy City Council website.
Applications close at 8pm on Sunday, 1st November 2020
- Student Engineer",4.0,"Glenorchy City Council
4.0",Glenorchy,-1,501 to 1000 Employees,-1,Government,-1,-1,Less than $1 million (USD),-1
Data Engineer involving DevOps,-1,"Data Engineer involving DevOps
Axiom Technologies is an Australia based entity with the history of providing Managed IT solutions to medium to large scale enterprises globally. Please visit our website for more information about what we do at www.axiomtechnologies.com
Axiom Technologies is an Equal Opportunity Employer and encourage applicants from all backgrounds and gender to apply, including, Aboriginal and Torres Strait Islander candidates
Job Requirements:
8+ years IT experience, with at least 5+ years of “Data Engineer/Deveoper” focused titles/roles,
Data Tools: Hands on experience with Apache Beam.
Testing: Hands on experience with automated testing activities/outcomes
DevOps: Experience with the processes involving Microservices facilities for artifacts developed
Platform/OS: Mid-range/Unix
Languages: Unix (Shell) Scripting/commands, SQL, Python
File formats: Text, CSV, Parquet, JSON, XML
Scheduling: Jenkins, Airflow
Auto Scripting: Designing/creation of scripts for repetitive activity. E.g. Unix scripting/SQL
Big data: Exposure to Data Lake Concepts, Hive (Schema), HDFS
Source Control tools: GIT
Delivery Models: Agile, Scrum
Ingestion Design: Create/assess Source/Target data mapping designs
Frameworks: Development and delivery frameworks
Activity Reporting/Repository: Jira, Confluence.
Quality: Accuracy and attention to detail
Industry: Financial Services/Banking
Solutions: Define solutions from High level to detail design to address automating ingestion activity. Facilitate/confirm requirements from product owners, business team members and technical associates,
Process Automation: Automating processes in file management, testing data in files, analysis and design, configuration management.
Script Automation: Ability to design/create scripts to automate/improve data copy/migration/ETL for any repetitive activity.
Languages: Java, Python
Scheduling: Control-M
Databases: Relational. E.g. POSTGRESS, Oracle – as a ETL developer
File Formats: Mainframe – experience with referencing its data formats/copybooks
Big data: Experience referencing/using Hive (Schema) to access data in HDFS
Metadata management tools: MDM, EDC and Axon
Performance: Assess, recommend, improve mappings, SQL queries, Batch feeds
Automation Tools: Other tools that may add value to an automation program and generally support development. E.g. API, REST, JDBC, Webservices, Message Queues/Load balancer,
Cloud: Experience with processing of data files to be ingested/stored in the Cloud, preferably with AWS.
Prod Support: Experience in a production support role performing root cause / impact analysis – under time constraints
Experience in a similar role
8+ Years
What next?
If you are looking for that next challenge in your career and wish to apply for this role, please forward your resume to careers.au@axiomtechnologies.com",2.0,"Axiom Technologies
2.0",Melbourne,-1,1 to 50 Employees,-1,Company - Private,Industrial Manufacturing,Manufacturing,Less than $1 million (USD),-1
Data Engineer,-1,"About the Role
We are on an exciting digital journey so it’s a great time to join ME! We are seeking a Junior Data Engineer who enjoys rolling up their sleeves, learning and growing. As part of our Enterprise Data Team, you will ensure fit for purpose data warehouse solutions are built for use across the bank and by utilising best practise ETL standards, whilst ensuring the data is trusted by our BI developers and key business consumers. Oh, and you’ll get to work on Microsoft technology stack too!
You will be involved with investigating data issues, keeping data feeds flowing and collaborating with different projects across the bank to deliver quality data solutions. How important does that sound? What’s even more important is this role contributes directly to our overall business strategy through the provision of data to enable analytics & reporting, as well as supporting business and decision system processes.

About You
You’re naturally a highly motivated and energetic person who thrives in a dynamic, ever-changing collaborative team environment. Ideally you have previous experience as an ETL developer, Data Engineer or a BI developer, and if you have a degree in computer science or similar it would really put you ahead of the rest.

With your knowledge of SQL coding, data modelling, understanding of data warehouse concepts, plus experience of working on complex ETL solutions, you’re ready to expand your horizons and launch your career into the world of IT at ME.

About ME
We’re not like other banks.
ME was created by the industry super funds to be different from the pack – with a core purpose to help all Australians get ahead financially – no conditions, asterisks or exceptions. And we know that looking after customers starts with taking care of our people.
We believe everyone deserves the same opportunities in life, regardless of gender or identity, sexuality, ethnicity, religion or disability ‒ with internal affinity groups.
Perk ME up
Once you get your feet in the door at ME, we’ll put them both in your very own ME-branded Converse shoes. You’ll also get the following financial, health and fun perks when you join the team:
4U Extras portal (discounts and cashback on 100s of items including cinemas, shopping and gym memberships
10% Myki discount
Purchased Leave programme
Internal wellness programme (Mindfully ME)
Professional education through LinkedIn Learning
Novated Leasing
Professional membership reimbursements
Health checks
Financial education (To help you manage your money smarter)
LGBTIQ+ and Women at ME affinity groups

I want those Converse shoes (and the role)
Can’t see a closing date on the advert? That’s because we’re pretty efficient here at ME and we may start looking at applications sooner rather than later, so if this role sounds like your jam, be sure to apply by submitting your resume today.

Should an applicant be the preferred candidate, background checks (including police checks, reference checks, ASIC banned and disqualified persons and bankruptcy checks) will be completed prior to the candidate's employment being confirmed. The outcomes of the background checks do not automatically bar candidates; however will be assessed against the inherent requirements of the job.
Back Share
Apply Now",3.0,"ME Bank
3.0",Melbourne,-1,501 to 1000 Employees,-1,Company - Private,Banks & Credit Unions,Finance,$100 to $500 million (USD),-1
Software Engineer - Machine Learning/Data Science,-1,"Zendesk is looking for a Software Engineer - Machine Learning/Data Science for a full time position in our Melbourne office.
As part of our engineering team, you will work at a scale where the challenges start to get seriously interesting. Our global engineering team is widely dispersed over the world, with people across nearly every continent. You will get a chance to do cool things with a diverse bunch of people while working in the Melbourne office that is home to Zendesk’s first machine learning (ML) research team.
The Data Science Team, together with Data Engineering, have built Satisfaction Prediction, Answer Bot and Content Cues — products that use Machine Learning (ML) and Artificial Intelligence (AI) to help our customers work more efficiently.
What you get to do every day:
We’re currently looking for someone to join our team as we research, develop, and productionise Machine Learning and Deep Learning models. In addition to frequenting Melbourne’s finest purveyors of coffee, ramen, and bulgogi, you may find yourself:
Building machine learning models including neural networks in TensorFlow
Writing and deploying production-grade Python
Querying and constructing datasets in AWS Athena, Spark
Evaluating and responding to real-world model performance
Scaling your ML to millions of predictions per day
Presenting your work to a broader audience
Watching your algorithm help Zendesk’s end-users
What you'll bring to the role:
A strong foundation in a quantitative discipline (e.g. machine learning, statistics, bio/eco/etc-informatics, econometrics, etc) is critical for this position. While experience in deep learning and natural language processing would be beneficial, your best qualities are:
dedication to continuous learning
collaborative work attitude
strong communication skills
You should also be comfortable with at least one programming language, such as Python, R or Scala.
Application Deadline: 18/11/2020
Job Types: Full-time, Permanent
Salary: $85,000.00 – $110,000.00 per year
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Temporarily due to COVID-19",4.5,"Zendesk
4.5",Melbourne,-1,1001 to 5000 Employees,2007,Company - Public,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),-1
Software Engineer (Machine Learning),-1,"About the Role
AdelaideMRI is building a medical reporting tool. We require an engineer to work primarily on machine learning projects to improve reporting speed and report comprehensiveness.
You will perform data analysis of medical report datasets and image datasets to infer sentence recommendations, image classifications, or other actionable results for the doctors.
Skills and Experience
Background in machine learning or image processing
Qualifications in Computer Science, Software Development or Engineering or equivalent experience
Bonus points for Python
No prior medical knowledge is required.
This position offers flexible hours and work arrangements.
Job Type: Full-time
Experience:
Software Engineering: 1 year (Preferred)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Yes",-1,Adelaide MRI,Australia,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Hey there, we’re PEXA!

We started as an idea: to deliver a single, national e-Conveyancing solution. We collaborated with the industry to create a national electronic lodgement and settlement platform: PEXA. From our humble beginnings, we’ve now grown to more than 320 employees across 5 different states. We’re still expanding at a rapid rate and constantly challenging ourselves to create great experiences for our members as they transition to fully digital conveyancing.

Why become a PEXArian?

Great question! Being a PEXArian is so much more than just a job. We are passionate, motivated & unashamedly enthusiastic at PEXA - we love what we do and we’re proud to admit it! Creating brilliant member experiences wouldn’t be possible if we didn’t also strive to create an amazing employee experience. Alongside our members, our employees are at the heart of everything we do.
Here’s a snapshot of what your life at PEXA could look like:

Your growth:
We encourage you to hit your personal and professional Learning & Development goals with our tailored programs and tools.

Your wellness:
We care about your holistic well being - a fully stocked kitchen, four wellness days, a $250 wellness subsidy as well as lunch and learn sessions to support your financial well being.

Your work/life blend:
We know that work is just one aspect of your life, we want to help you create your ideal work/life blend, rather than squeezing in life around work.

Your family:
With a range of benefits aimed at supporting your family including access to a subsidised school holiday program, extended parental leave and flexi-time to support your return to work, superannuation payments for unpaid parental leave for primary carers and a childcare allowance for pre-primary aged children, when we say, ‘welcome to the family’, we really mean it!
The impact you'd drive:
The successful candidate will be responsible for developing, and maintaining infrastructure to support the delivery of new and existing products. They will also be contributing to establish the rules and frameworks for obtaining the required approvals for new products.
On day one we’d love you to have:
Experience with Python, Spark
Event streaming/sourcing with Kafka or AWS Kinesis
Experience with data structures, formats and data security best practices
AWS experience (e.g CloudFormation, S3, ECS, Lambda, SQS, IAM, KMS, DynamoDB, Glue, Athena)
Query construction and optimisation (e.g. SQL, Elasticsearch, Splunk, DynamoDB)
Git, version control practices, and continuous integration/delivery servers
PyUnit and unit testing frameworks
Production release cycles and maintenance
Collaborating with technical and non-technical teams
Even better:
Agile methodology/delivery
GraphQL
Modern frontend technology (e.g. ReactJS, TypeScript)
Machine learning frameworks and tools (e.g. TensorFlow, PyTorch)
OAuth 2, SAML 2, JWT
Data visualisation and exploration tools (e.g. Jupyter notebooks, Tableau)
AWS SageMaker
Sounds like you?
If this role sounds like you, apply today to have your application reviewed ASAP!",3.9,"Property Exchange Australia Limited
3.9",Melbourne,-1,201 to 500 Employees,2010,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Ongoing position
Full time
Based in Sydney, NSW
Who we are
Australian Red Cross is part of the world’s largest humanitarian organisation. Our aim is to improve the lives of the most vulnerable people in Australia and across our region.
About the role
The Data Engineer role will sit within the Data and Integration Squad in IT and will own (design, implement and support) the AWS Big Data technologies such as the Data Lake and Data Warehouse and support the organisation in growing the data analytics capabilities at Red Cross. In addition to this, the data engineer role will also administer the Power BI tool and support the implementation of the data mastering capability.
What you will bring
Experience building and optimizing data pipelines, architectures and data sets.
Experience in dimensional modelling and building data vaults
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with structured, semi-structured and unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Why work for us?
Work for purpose and know that your work assists Red Cross support and empower people and communities in times of vulnerability.
Generous salary packaging options available that can increase your take home pay.
Further information
To find out more about this opportunity please see the position description below or contact Sharath Kumar Gurram on 02 8651 8839.
Position Description: Position Description - Data Engineer .pdf
Applications for this position will close at 11:55pm Thursday, 5 November 2020.",4.1,"Australian Red Cross
4.1",New South Wales,-1,1001 to 5000 Employees,-1,Nonprofit Organization,Industrial Manufacturing,Manufacturing,$500 million to $1 billion (USD),-1
Junior Fullstack Data Engineer (Python and React),-1,"Formbay is the leading Renewable Energy Certificate Trading company in Sydney. We provide Digital Workflow and Compliance solutions in the renewable energy industry and document processing.
Thanks to our meteoric growth and our commitment to be the best at all we do, we've identified the need to bring on board a new Junior Fullstack Data Engineer.
Reporting to our Principal Machine Learning Engineer, you will help build Machine Learning pipelines for our existing Digital Workflow and Compliance solutions to automate fraud detection and document processing over terabytes of photographic and documentary data – including documents, photos, GPS data and aerial/satellite photography.
Our stack is based on Python, JavaScript, Dask, Tensorflow, CUDA, Nix/NixOS, AWS, Docker, PostgreSQL and more – familiarity with these applications will give you a leg-up on the competition.
Our ideal candidate will have the following competencies:
SQL
Python
JavaScript/TypeScript
Our candidate must also be comfortable working with Linux.
Located a stone's throw away from the Queen Victoria Building in Sydney's bustling CBD, we are centrally-located with easy access to public transportation, bars, cafes and fine dining.
Formbay will provide flexible working hours, a generous remuneration package and the opportunity to work on a world-first software solution are what we can offer you. Free, twice-weekly gym sessions and really, really good coffee are also available.
No hiring/recruitment agencies need apply.",5.0,"Formbay
5.0",Sydney,-1,1 to 50 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is an experienced and qualified Data Engineer to join our IT team based in Birtinya.
Key Responsibilities:
Create and maintain data pipelines and or ETL scripts
Create and maintain data integration including API and Batch interfaces
Performed detailed data analysis
Create and maintain corporate data models
Create and maintain data visualization using Qlik.Sense , PowerBI or Simliar Toolset
Experience in defining, building and maintaining data virtualization and/or star schema data warehouses
Maintain, tune and optimise database, integration and visualisation toolsets
ABOUT YOU:
To succeed in this role, you’ll need to bring the following experience and skills:
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Excellent communication skills both oral and written, with an ability to bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking
Experience with data analysis and modelling will be beneficial

How to Apply
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kawana Waters,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Graduate Data Science / Engineer,-1,"The NRMA is an organisation looking to the future, and right now, we are on the lookout for people who can help us reach our goal: to continue to shape the way Australians move, for the next 100 years and beyond. www.mynrma.com.au.
Everyone new to the team, along with our current staff, will temporarily work from home until it is safe to return to our offices. All interviewing and on boarding will be done virtually due to COVID-19.


Your opportunity
As Graduate Data Scientist or Engineer you will be part of the Data Engineering team delivering cloud data transition program for business initiatives and supporting the entire data platform build.
Your key responsibilities will be to:
Implementing Concepts of Data Warehousing, Data Mart creations within Cloud
Use of SQL for data analysis and insights
Building AI/Machine Learning prototype for implementing and supporting existing algorithms
Data Analytical reports build, using different tool sets


Requirements for Success:
Relevant Degree - Computer Science, Computer Engineering, Software Engineering, Data Science
Excellent SQL skills and demonstrated working knowledge in Python
Demonstrated understanding in data structure and algorithms.
Knowledge and concept of data warehousing methodologies
Any reporting tools experience Tableau or Oracle Analytics Cloud, Looker is desirable
Exposure to Google/AWS/Azure/Oracle any cloud based platforms is desirable
Good communication and interpersonal skills

If you have the required skills and the passion to join our high performing team, please apply today.

Employee Benefits
To ensure our employees feel valued, empowered and celebrated we provide a range of employee benefits including:
50% discount on all NRMA insurances
Free Roadside Assistance
12 weeks paid primary and 4 weeks paid secondary parental leave
Free NRMA Blue Membership
At the NRMA Group, we are People Moving People and diversity and inclusion are part of our DNA. Together, we continue to build an inclusive culture that encourages, supports and celebrates the diverse voices of our employees. It fuels our innovation, promotes flexible ways of working and connects us closer to our members and the communities we serve.",2.5,"NRMA Motoring & Services
2.5",Sydney,-1,501 to 1000 Employees,-1,Nonprofit Organization,Casual Restaurants,"Restaurants, Bars & Food Services",$500 million to $1 billion (USD),-1
Data Centre Engineer,-1,"We are a leading world group that provides low-carbon energy and services. To tackle the climate emergency facing us all, our aim is to become the world leader in the zero-carbon energy transition ""as a service"" for our clients – particular for companies and regional authorities. We use our expertise in our key business areas (renewables, gas, services) to provide competitive and bespoke solutions.
The Data Centre Engineer will be employed as part of a 24/7 ongoing shift to coordinate and monitor third party service providers, maintain the data centre facilities and infrastructure plans, coordinate the implementation of customer requests within the data centre and monitor systems, all in accordance with the Contract KPIs and SLAs.
Coordinate and monitor third party service providers for regular maintenance & testing, service faults & call outs, ensuring works are performed in accordance with Contract SLAs
Monitor and maintain the data centre facilities and infrastructure plans and documentation, including electrical, mechanical, hydraulics, fire and BMS/EMS systems
Coordinate the implementation of internal and external customer requests within the data centre
Perform scheduled plant checks and minor maintenance works
Ensure all Work Order requests are raised and closed in a timely manner
Conduct inductions for staff, vendors and contractors
Ensure all work permits for vendor works are raised and closed
Perform inventory checks on all equipment and critical spares

Qualifications
The selected candidate must be able to demonstrate:
Electrical or HVAC background, or Graduate Electrical or Mechanical Engineer
Passionate about quality work and career minded looking for a new challenge
Can commit to a day and night shift roster (2 days of day shift, then 2 days of night shift, 4 days off)
Ideally able to commence asap
As part of carrying out the duties of this role, it is mandatory to hold Australian Citizenship.

If you are interested and meet the selection criteria apply with an up-to-date resume via the apply instructions on this website.

ENGIE Services is an EEO employer, where all applicants are treated with fairness and respect and have equal access to the opportunities available.

We will not be engaging in the services of a recruitment agency to fill this vacancy and therefore request all interested candidates apply directly to this advertisement.

Job
: Maintenance
Primary Location
: Oceania-Australia-New South Wales-Erskine Park
Organization
: ENGIE Services Australia and New Zealand
Schedule
: Full-time
Nature of Responsibility
: Senior operational / administrative role
Job Posting
: Sep 11, 2020, 6:29:59 AM",3.7,"ENGIE Services Australia & New Zealand
3.7",Sydney,-1,5001 to 10000 Employees,1995,Company - Public,Energy,"Oil, Gas, Energy & Utilities",$2 to $5 billion (USD),-1
Senior Data Engineer,-1,"Senior Data Engineer, Temporary, SYDNEY - McKell

Job Title: Senior Data Engineer

Salary: SNSW Grade 9/10 - The package includes base salary range of $111,806 to $134,667, plus employer's contribution to superannuation and annual leave loading.

Location: Head Office – Haymarket

Employment Status: Temporary through till 30th June 2021


About Service NSW:

Service NSW is making it easier for people and businesses across NSW to access government services. The role designs, builds and analyses complex data from multiple sources to identify revenue, process and business improvement opportunities; providing new information and insights to the business to inform planning, continuous improvement and performance.

About the Role

We are currently seeking to appoint a Senior Data Engineer to deliver expert advice and services in the design of a Single View of Customer and data-related services to support the achievement of business outcomes and strategic goals. We support flexible working practices with staff working remotely during this time.

In this role you will:

Design, build and support a modern data platform based in AWS and vendor technologies.
Provide expertise on data modelling for Graph data model and Customer Data Platform (CDP).
Create data pipelines, load, transformation and reporting workloads in AWS.
Work with the latest data engineering technologies like Apache Kafka, AWS Kinesis, AWS Neptune, AWS Glue and AWS Athena.
Contribute to the design and decision-making of the right tool or platform for the job according to requirements.
Provide expert advice and guidance on data quality and data engineering best practices.
Support a “bigger than you can imagine” scale of data in production environments.
Design, develop and support a metrics-driven reporting solution and a meaningful business intelligence platform.
Document the solution design and support procedures of solutions.
Produce reports, visualisations and recommendations to answer complex business problems that are presented in the most appropriate format to ensure clarity for target audience.
Analyse and define new process improvement opportunities to support continuous improvement and business outcomes; providing advice to stakeholders, on ways to improve the efficiency and reliability of data products and services.
Be very responsive to the information needs of the business by corresponding to customers in a timely manner and provide support/solutions to issues raised.
Troubleshoot and perform root cause analysis on production issues. Identify and implement long term solutions to problems. Perform scheduled maintenance, release deployment and production support activities after business hours, from time to time.
Liaise with internal and external customers to discuss and gather requirements, solutions etc. and maintain a good working relationship with the stakeholders.


Skills and Experience Required:

Solid experience with workflow technologies designing and building data pipelines, data models and data stores.
Experience working within and an understanding of Amazon AWS ecosystem, including security and performance tuning.
Hands on experience working with different types of databases, with focus on Graph and NoSQL databases.
Experience with data streaming required. Having used Kafka and related technologies is an added advantage.
Sound knowledge and experience working with batch processing, data extraction and API integration.
Hands on experience with at least one programming language: Java, Python or scripting.
Demonstrated experience working in an Agile based, fast paced, complex environment within cross-functional teams.
Experience developing systematised insights, data analytics and reporting solutions is an added advantage.
Experience with interactive visualisation of data insights is an added advantage.


Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Salary Grade 9/10, with the base salary for this role starting at 111,806 base plus superannuation

Closing Date: 6th November at 9:59am - applications will be reviewed on a rolling basis, applications may close early or extend

Please apply online, direct applications submitted via email will not be considered.

The Department of Customer Service is proud to be an EEO Employer who are fully focused on equality and believe deeply in diversity of all identities making us different and a true reflection of our NSW customers. As an inclusive workplace, we support various employee resource groups, practice flexible work and workplace adjustment.

If you do require an adjustment during the recruitment process, please notify us on your application form.",3.2,"Service NSW
3.2",Sydney,-1,501 to 1000 Employees,2012,Government,State & Regional Agencies,Government,Unknown / Non-Applicable,-1
Data Engineer - Entry / Mid Level,-1,"Work with a great team on interesting projects customers
Gain more experience in AWS, Data, DevOps cloud operations
Got a working knowledge of AWS? We will teach you the cool stuff!

Itoc is seeking an up and coming Data Engineer to join our growing Data Team in Sydney.

This is an exciting role working with databases, data lakes, data warehouses, data transformation (Python SQL) and enabling AI/ML.

You will be implementing foundational, robust and production ready data platforms to enable business data-discovery, self-service, AI/ML functions across a range of client types and industries, allowing them to do more with their data.

You'll be responsible for:

Deploying data repositories such as lakes and warehouses.
Contribute to our growing portfolio of data solutions.
Ongoing optimisation and management of data platforms.
Development of transformational logic for data pipelines
Data evangelism. We want to show our clients how to follow the best practices for data.

Desired Skills and Experience

To take up the challenge, you will have a depth of skills and experience including:

1-2+ yrs of focused data experience working with SQL and/or NoSQL solutions
A solid education in Software Engineering or equivalent industry experience.
Anything Data focused preferred.
Ability to analyse business scenarios and associated data landscape to derive potential opportunities.
Strong foundation in Python and SQL
Working knowledge of APIs
Principle knowledge of the different relational database platforms and modern data storage techniques
Knowledge of the different aspects of data environments
Collect, store, process, verify consume
Experience with version management systems (such as GIT)
Working knowledge of AWS or another cloud platform - we will teach you the cool stuff.
Great communication skills, an ability to work closely with customers, developers and engineers and the confidence to present ideas in open forums.
Relevant tertiary qualifications and/or industry certifications.
Great communication skills, an ability to work closely with clients, developers and engineers and the confidence to present ideas in open forums.

While not required, a background in consulting and professional services is highly desirable.

Itoc Description

This is an exciting and challenging career opportunity to join the growing Sydney-based Data Team of a leading cloud solution provider where you will be given support to reach your long term career goals. You will be part of a team of cloud experts and will work in an environment of continuous improvement and learning delivering innovative cloud solutions across SaaS, online business and enterprise business.

On offer is a chance to join a team with a great working environment, in an organisation that values its employees and sees the value in ensuring they are engaged. Our team are clearly passionate about what they do, that's why we won the following awards:

Customer Obsession Partner of the Year 2015: ANZ Region
Customer Obsession Leadership Partner 2015: re:Invent

As an employer of choice Itoc offers competitive remuneration, training and development programs and a great working environment. We value a healthy work life balance.

The Perks

MacBook or Dell
Continuous internal learning that will provide training and career development opportunities
Working with a collaborative, social team and leveling-up your skills faster than you will anywhere else.
Quarterly social events

Itoc

Culture and smarts are important to us. Bring your secret sauce. This is no ordinary environment, you will work along some of the Cloud’s best. All engineers at Itoc must gain at least five AWS certifications. We work hard but we have fun.

Please note you must have full working rights in Australia and be available on-shore for face to face interviews.

No recruiters please.",4.0,"Itoc
4.0",Sydney,-1,1 to 50 Employees,2013,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Date: 01-Oct-2020

Location:
Melbourne, VIC, AU

Department:Description:
Technology discounts - from Apple HP Lenovo to Windows
Flexible work arrangements - work in a way that suits you best
Salary packaging - to suit your personal and financial circumstances

Do you want to work for one of the fastest growing data teams in Australia? Do you want to work on multiple data platforms and provide new solution offerings by leveraging cloud and big data technologies?

About the team

Big data information and analytics. Three words that spark apprehension in most businesses. But our team of experts are constantly curious and excited about combining our wonderful array of technological expertise to transform data into our clients most valuable assets making their work smarter. Our data consultants are supported with resources training and tools they need to excel at their work but also the freedom and power to create their own paths forward to make a difference.

As a Senior Consultant in Big Data you will work closely with the team and stakeholders to build and deliver a Cloud based vision for a next generation Big Data analytics platform with strong focus on data quality data security and deliver the systems that process huge volumes of data.

What will you typical day look like?

You will play a pivotal role in - Designing and producing high performing and stable applications to perform complex processing of massive volumes of data in a new cloud based architecture; Building real-time data processing applications which are integrated with business systems to enable value from analytic models to drive rapid decision making; Contributing to system architecture design for a data platform (including cloud-based structures both on and off premises data warehouse components and data lakes); this could cover a range of technologies various countries/locations and lines of business; Support data strategy or technology strategy definition programs including technology stack definition and target operating model requirements

Enough about us lets talk about you:
You are someone with:
Use of traditional data analytics tools and techniques (e.g. MSSQL Oracle MySQL) and ETL software (e.g. SSIS Informatica CloverETL)
Working in large scale cloud data solutions using platforms such as AWS or Azure or GCP will be a bonus.
Experience in scripting or programming (e.g. Python Java Scala C#)
Excellent verbal and written communication skills to adapt to technical and non-technical audiences.
Educated to degree level (or have equivalent experience)
Why Deloitte?

At Deloitte we create positively differentiated work experiences that enable our people to feel valued and achieve their full potential. We value difference and embrace people with diverse backgrounds and thinking styles. Knowing that people work best in different ways we are happy to discuss alternative arrangements if the working pattern you are looking for is not specifically indicated.",3.8,"Deloitte
3.8",Melbourne,-1,10000+ Employees,1850,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Engineer,-1,"Opportunity to grow the team
Period of growth
Intuitive app
S2M are working with a FinTech who have created a unique financial product to help thousands of people better manage their finance, and is currently scaling the company to the next level!

They are looking for a Data Engineer to join, and looking for someone who wants to be hands on, with opportunity to grow the team in future.

Role:

Looking for people with strong AWS experience. You will need passion for data and a cloud, through which you will help a rapidly scaling Australian FinTech establish their data infrastructure from the ground up.
5+ years’ experience as a data engineer within the data and analytics domain
A python 3.X aficionado who is very comfortable creating and orchestrating AWS data pipelines with nothing but code
Strong project delivery toolset experience in open source data integration tools
Experience with processing large volumes of complex data including visualisation and insights generation
Ability to define and develop data integration patterns and pipelines
Ability to assess complexity of data (volume, structure, relationship etc.)
Hands on experience working with different databases (RDBMS, NoSQL, Blob storage etc)
Hands on technical expertise setting up DevOps automation
Hands on experience working technologies/platform e.g. AWS, Dockers, Containers
Experience building data profiling and data cleansing frameworks
Technical reconciliation and reporting
Knowledge and experience in end-to-end project delivery, either traditional SDLC or agile delivery methodologies (or hybrid approaches)
Exceptional communication, documentation and presentation skills
If this sounds like you, get in touch today - kate.gabb@s2m.com.au
3167410agsdf",3.1,"S2M
3.1",Sydney,-1,Unknown,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Analysts,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is seeking experienced and qualified Data Analysts to join our IT team based in our corporate office in Birtinya (Sunshine Coast) or at our meat processing facility in Kilcoy.
Key Responsibilities:
A mixture of data analysis and commercial skills to source, blend and analyse data to gain insight and answer key commercial questions
Working with strategic leaders to define and model Key Performance Indicators, and assist in building forecasting models
Working closely with data engineers and BI developers to specify data pipelines and report visualisation
Drive the creation and implementation of data quality business rule including data definition, governance and quality assurance
About You:
To succeed in this role, you’ll need to bring the following experience and skills:
Proven ability to derive insight and knowledge from data using commercial expertise is a strong requirement
Strong SQL and Excel skills are essential, along with strong data analysis and commercial insights
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Effective people communicator - engage with stakeholders on reporting needs, interpret requirements into visual solutions and train/deliver the outputs to the stakeholders getting signoff of acceptance
Bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking

How to Apply:
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kilcoy,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Network Data Engineer,-1,"Min 6+ years of experience in the relevant technologies
Australian Driving License for visiting remote locations / Data Centre for day to day technical work.
Managing Network devices (switches, routers, firewalls, load balancer, and wireless technology)
Performing MACD activities for all network devices.
Supporting BAU operation activities.
Proficient in performing in-depth details of technical troubleshooting, cause and provide recommendation to the client for incidents causing extended network outage to client’s critical locations.
Provide exceptional network services in terms of network support, break-fix, design and consulting, new projects, implementation.
Configure, administer, and document firewall infrastructure.
Manage the firewall deployment, rules migrations, and firewall administration.
Supporting Cloud Migration Activities from traditional to AWS/Azure.
Setting up VPN tunnel with Cloud and 3rd Party network devices.
Integrating and upgrading existing ISP bandwidth with support from ISP Vendor.
Setting up VPN profiles for Users.
Installing hot fix and patches to mitigate the security devices from attacks and bugs.
Reviewing and fine tuning the firewall rules and NAT rules.
Documentation and change control.
Mentoring, Motivating and Guiding support teams
Technical skills:
o LAN
o Wireless
o WAN
o MPLS
o Routing protocols (OSPF,BGP)
o DMVPN
o Azure cloud Networking
o Network Security
Fortigate Manager / Analyzer / Firewall
Cisco ASA
Firepower FTD
Cisco Any connect
Site to Site VPN
F5 Load Balancing and Scripting iRule
Job Types: Full-time, Contract
Schedule:
8 hour shift
Experience:
Scripting: 5 years (Required)
Data Network: 5 years (Required)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Required)",3.6,"Total IT Global
3.6",Sydney,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Engineer - Processing & Analysis,-1,"Job Description:
Design,build and maintain the ingestion system to support various types of data(e.g. User behavior, RDS, NoSQL db and others) to be ingested to the data warehouse more timely and accurately
Translate data requirements into scalable technical data service with low latency and high concurrency
Design,build and maintain the batch or real time data pipeline in production using Hadoop big data technology
Analyze and improve efficiency, scalability, and stability of the system
Define and manage SLA,Data quality for all data sets in allocated areas of ownership
Requirements:
Minimum B.S. degree in Computer Science or a related technical field
2+ years of working experience in programming languages,such as Java,Scala,Python
Familiar with Hadoop, Spark and Flink data processing, experience of TB data processing experience is a plus
Familiar designing and operating of a robust distributed system is a plus
Understand data mining or machine learning
Excited to work intimately with data
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"SYNOPSIS:
Lead Data Engineer
Applications close Sunday 8 November 2020
Ongoing
Contact name: Shyni Sasikala
Phone: (02) 6249 9048
Email: Shyni.Sasikala@ga.gov.au

The Data Policy and Informatics section within the Digital Science and Information branch creates, implements, and promotes policies, platforms and tools that improve and support the quality, discoverability, accessibility, and general usability of Geoscience Australia’s science data products. The section consults with internal and external research, government and industry partners to establish collaborative data frameworks, architectures and models within Geoscience Australia (GA) and across broader national and international communities of practice. The section innovates, builds and maintains tools, systems, processes and governance that enable digital data management, cataloguing and open data delivery.
GA makes accessible a wide range of geoscientific and spatial data to a wide variety of stakeholders in multiple formats, and in recent years GA's data volumes have grown exponentially. GA is focussed on making its data and metadata assets accessible so that they can be used in machine to machine interactions for data analytics and other applications in environments that range from High Performance Computing (HPC), through high-end cloud servers, to mobile devices.
We currently have two opportunities for Lead Data Engineers in the Informatics team. The Lead Data Engineer is responsible for innovating and exploring new technologies that will advance GA’s science goals and maximise the uptake and use of GA’s science data. The Lead Data Engineer reports to the team’s Assistant Director but also works closely with other developers, data scientists and engineers within the Digital Science and Innovation (DiSI) branch, as well as diverse stakeholders both within and external to GA.",3.9,"Geoscience Australia
3.9",Canberra,-1,501 to 1000 Employees,2001,Government,Federal Agencies,Government,$100 to $500 million (USD),-1
Data Engineer,-1,"The Seven Network is part of Seven West Media, one of Australia’s most prominent media companies, with a market leading presence in content across broadcast television, online and in print. Comprising some of Australia’s most renowned media brands, SWM includes not just Seven Network and its affiliate channels 7two, 7mate, 7flix and BVOD offering 7plus, but also 7NEWS.com.au, The West Australian, The Sunday Times and more.
At Seven we are here to bring all Australians closer to the moments that move us - we’re first on the scene, with our finger on the pulse, on demand, in the moment. Together, we’re responsible for creating and sustaining authentic Australian engagement.
A new and exciting opportunity has opened for a Data Engineer to join the Audience Intelligence team. Based in Sydney and reporting to the Head of Data Enablement, you’ll be responsible for:
Implementation of end to end data solutions to support Data Strategy for the SWM group.
Work closely with the Data Solution Designers to develop and maintain scalable data pipelines and build out new file and API based integrations to address requirements from the various business stakeholders.
Collaborates with engineering, analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organisation.
Work on Data Preparation for analytics and data scientist team members and assist them from an engineering perspective in building and optimising the models including building the automation of the end to end workflows
Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.
Perform data analysis required to troubleshoot data related issues and assist in the resolution of production data issues.
Work effectively with vendors for successful delivery of projects and acceptance of the solution
Work on Delivery projects using Agile Software Development methodologies
We are looking for someone who has:
Bachelor's degree in computer science, computer engineering or other technical discipline is essential
Proven experience working as a digital analytics specialist
Extensive experience with digital analytics implementation (e.g. Google Analytics, Snowplow, Adobe Analytics) and BI processes and visualisation platforms
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience in ETL and building and optimizing ‘big data’ pipelines and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Experience with big data tools: Hadoop, Spark, etc., AWS cloud services: EC2, S3, Lambda and familiar with version control systems: Git
Strong coding skills with knowledge of Unix/Linux and scripting languages such as Unix Shell scripting, Python desirable
Experience supporting and working with cross-functional teams in a fast-paced environment.
Ability to multi-task and problem solve with changing demands and priorities
Ability to work under pressure to meet deadlines and detail oriented
Your success is our success: we will provide you with opportunities for you to keep learning and growing, enabling you to challenge and develop yourself. In return, we offer a benefits program that has something in it for everyone.
Seven West Media is an equal opportunity employer and we are committed to creating a diverse and inclusive workplace.
Recruitment Agencies: Seven West Media does not accept any unsolicited agency resumes and will not be responsible for any fees related to unsolicited resumes.
Advertised: 19 Oct 2020 12:00 AM AUS Eastern Daylight Time
Applications close:

Back to search results",2.5,"Seven West Media
2.5",Sydney,-1,5001 to 10000 Employees,1956,Company - Public,TV Broadcast & Cable Networks,Media,Unknown / Non-Applicable,-1
BICON Rules Engineer,-1,"APS 5 - $73,299 - $80,410 per annum plus superannuation
Biosecurity Plant Division
Canberra, ACT
Play an active role in managing biosecurity risk to Australia
Work in a motivated and professional team with a wide range of skills and backgrounds
Full training provided

Who we are
The BICON Content Development Team maintains and improves the Biosecurity Import CONditions database (BICON) content to allow external clients to understand and comply with their biosecurity obligations and internal clients to effectively manage biosecurity risk and regulate imports. We work collaboratively with internal clients to comprehend and implement their BICON content requirements and optimise the use of BICON to publish clear import requirements and onshore management support procedures to effectively manage biosecurity risk.

The Jobs
Key duties of these positions include:

working with business content (import and permit conditions) and import programs to understand and construct decision tree structures in the BICON database, in accordance with system design and authoring conventions
executing changes to import and permit conditions in alignment with service standards while complying with system rules and authoring conventions
providing technical advice through various formats on the most appropriate means of authoring BICON content to achieve import program and stakeholder objectives
using workflow management tools to maintain detailed records of changes to import conditions and key decisions
performing administrative tasks including system reporting, data analysis and scoping tasks for the BICON content change work program
contributing to the development and maintenance of instructional material, authoring conventions and courseware
clearly documenting and reporting system issues
developing and maintaining effective working relationships with internal and external stakeholders.

What we are looking for
Knowledge and experience
Experience working with complex IT systems.
Experience working collaboratively and as part of a team.
Knowledge of the role of biosecurity is preferred but not essential.

For additional information, please read the Job Description below.
Candidate Information Package docx Opens in new window",3.9,"Department of Agriculture & Water Resources
3.9",Australia,-1,5001 to 10000 Employees,-1,Government,Federal Agencies,Government,$500 million to $1 billion (USD),-1
Cloud Data Engineer,-1,"Job no: 509605
Work type: Permanent Full Time
Location: Melbourne, Canberra, Sydney
Do you embrace digital disruption?
Do you love solving complex problems, designing sophisticated solutions and building innovative technology?
Do you believe in creating powerful actionable insights from Data and Analytics?
Do you want to work in a diverse and flexible working environment?
KPMG is one of the most trusted and respected global professional services firms. Through depth of expertise, clarity of insight and strength of purpose we help our clients solve complex challenges, steer change, strengthen, transition and grow. We are a team based practice and this extends to our clients whom we work and collaborate with, in solving complex problems. Together, we design, innovate and implement, providing enduring advice that support our clients and the services they deliver. Our clients vary in size and come from a diverse range of sectors – all sharing in a common goal: to embrace change and deliver services that make Australia a better place. We are looking for talented individuals who would like to join us on the journey.
KPMG’s Digital Delta Team
We re-imagine and re-invent organisations to become world class digital enterprises using advanced technologies, data and human insights. We help organisations to embrace Digital Strategy, Artificial Intelligence (AI) & Cognitive, the Internet of Things (IoT), Data, Analytics & Modelling, Mobile App & Web, and User Experience (UX) & User Interface (UI) and more.
We work with clients to:
Formulate strategies that re-imagine organisations
Harness innovation from the 4th industrial revolution
Actioning insights from trusted data to consistently and quickly make clear decisions
Build adaptive organisations
Thrive as a connected enterprise – front, middle and back office
This is how you’ll contribute:
We are looking for ambitious Data Engineers who are passionate about helping clients define bold ambitions and deliver on them. Joining our team will take you on a journey of personal and technical growth and provide the opportunity to inspire confidence and empower change.
As a Data Engineer you are the designer, builder and manager of the information or ""big data"" infrastructure, preparing data for analytical or operational use. You will design, construct, test and maintain a data pipeline to pull together information from different source systems; integrating, consolidating and cleansing data; and structure it for use in individual analytics applications.
The KPMG Difference
Our people are focused on creating a diverse and dynamic environment that embraces and values differences. We value the variety of unique experiences, qualities and characteristics our people possess and we share and learn from each other.
We are proud to be consistently recognised as an employer of choice for women, and for our achievements in LGBT+ workplace inclusion.
Our commitment to ‘Flexibility’ allows our people to manage the changing demands of work, personal or family life. Explore the links below to hear our people share their experience @ KPMG:
Flexibility empowers wellbeing
Flexibility enables contribution to the community
Flexibility inspires technology & innovation
Flexibility supports family

Make KPMG the clear choice for your career and be Extraordinary!

Advertised: 09 Sep 2020 AUS Eastern Standard Time
Applications close:",3.8,"KPMG
3.8",Sydney,-1,10000+ Employees,1987,Subsidiary or Business Segment,Accounting,Accounting & Legal,$2 to $5 billion (USD),-1
Computer Network and Systems Engineer,-1,"Duties Include but are not limited to:
Tasks Include:
analysing, developing, interpreting and evaluating complex system design and architecture specifications, data models and diagrams in the development, configuration and integration of computer systems
researching, analysing, evaluating and monitoring network infrastructure to ensure networks are configured to operate at optimal performance
assessing and recommending improvements to network operations and integrated hardware, software, communications and operating systems
providing specialist skills in supporting and troubleshooting network problems and emergencies
installing, configuring, testing, maintaining and administering new and upgraded networks, software database applications, servers and workstations
providing network programming in support of specific business needs and requirements
preparing and maintaining procedures and documentation for network inventory, and recording diagnosis and resolution of network faults, enhancements and modifications to networks, and maintenance instructions
monitoring network traffic, and activity, capacity and usage to ensure continued integrity and optimal network performance
Skills and Experience Required:
Must have experience working in a Managed Service environment
Demonstrated experience in IT Networks and Data Centres
Understanding of systems and architectures to meet client needs
Experience in Help Desk including break / fix
Effective and timely documentation
Effective Task Management Skills
Be solution and outcome focused and willing to learn new technologies
Excellent communication skills with staff, clients and partners
Time management, ability to prioritise and deliver to schedule
Experience with N-Able and Connectwise desired
Open Cabling license desired
Job Types: Full-time, Permanent
Salary: $30.00 per hour
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,Trans-plant training,Canberra,-1,-1,-1,-1,-1,-1,-1,-1
Software Engineer (Data),-1,"If you are looking for an opportunity to make a real impact with smart people who are genuinely doing things differently then you've come to the right place! We're growing our data engineering capabilities and are looking for awesome data engineers to join our team.
With our diverse range of clients and projects, no day will look the same - but here's a great snapshot of what you'll be doing:
Work with some of the best Data Scientists and Engineers to deliver production-grade AI and Machine Learning systems as we deliver client projects from inception to production.
Consulting with our clients and working with them to build modern data systems using the 'best of' technologies and principles.
Advising clients on data strategy, architecture and technology.
Applying best software engineering practices in coding, monitoring and alerting, using CI/CD, TDD and cloud architectures.
Working over a wide range of big data tools and environments: not limited to; Apache Kafka, Spark, Python, Scala, Hive, Airflow, AWS EMR & Glue, GCP Dataproc & Dataflow, BigQuery, Snowflake, Redshift.
Who are we?
Glad you asked! We are Eliiza. Data science. Engineered for scale.
We are a passionate team of data scientists and engineers who apply data science and machine learning to solve real-world problems. Our mission is to create a bright future for Australian businesses and society in a world increasingly influenced by intelligent technologies.
We've created a culture that values diversity where people can truly be themselves! We care a lot about growing the Australian AI community in a positive direction, and we're doing several things to try and achieve that:
We provide opportunities for underrepresented groups to work in AI through our associate and intern programmes
We organise and participate in a range of community events, reading groups and meetups
We produce the AI Australia podcast
We blog about topics we care about
We stream brown bag sessions to the broader community
We're also part of Mantel Group's 'house of brands' which means it's not just the Eliiza team you'll work with, learn from and see at social events - there's another 230 of us across DigIO, Kasna & CMD Solutions!
So you're ready for something new?
We're keen to know more about you! Our team is made up of a range of people, with different experience across a huge range of data driven skill sets.
We'd love to hear from you if you have experience with:
one (or more) core language(s), ideally Scala, Python or Java
one (or more) cloud platforms, AWS, GCP, Azure
ETL/ELT concepts and technologies e.g. Data partitioning, Hive, Spark
streaming data concepts and technologies, ideally Kafka (Kinesis, Beam or Pubsub will do)
We'd be over the moon if you:
Experience with distributed/columnar databases (e.g. Snowflake, Big query, Redshift).
Experience with any of a variety of databases e.g. RDMS, NoSql, Columar, Distributed, Time series, Graph.
Knowledge of job orchestration and scheduling. Any experience with Airflow, Luigi or Oozie.
Experience with containers and container orchestration (Docker, Docker Compose or Kubernetes).
However, we value a diversity of skill-sets, and don't necessarily require that you're skilled with all of the above. If you feel you don't fit all the experience/skills listed above we still encourage you to apply or get in touch.
What's on offer if you join us?
We make sure you're always one step ahead by investing your learning and development, every year. We build our own training where it doesn't exist yet.
We hire smart people and get out of their way. By focusing on our five principles and not getting caught up in red tape, we trust you to get the job done.
You'll get all the tools you need - a new iPhone or Google phone, a new Macbook Pro or Dell, and a lot of branded swag!
But hold on, you mentioned a house of brands?
We certainly did! Mantel Group is an Australian-owned, 'house of brands' company with four technology businesses (Eliiza being one of them!) across Melbourne and Sydney. We're building a group of companies with open borders so we can support you to take on new skills without leaving an awesome team - we understand you won't have one job for life!
We may only be just two years old but Mantel Group has already been recognised #9 in the 2020 Best Places to Work in Australia and #4 in the AFR's 2020 fastest growing new companies.
Keen to chat?
Click ""Apply"" to share your details with our talent team, and we'll be in touch.
In the meantime, check out 'how we hire' to find out what's in store if you're successful and get to know us better by visiting our website and following Eliiza on LinkedIn.",-1,Eliiza,Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Infrastructure Engineer,-1,"Job Description:
Design and grow the Shopee data platform to support a variety of big data applications using open-source technologies including Kafka, Hadoop, Presto, HBase, Spark, Hive, Druid, and our own creations. Some examples include a real-time data streaming platform, a unified query platform, a cluster management system, and a machine learning platform
Dig into the source code of some open-source big data system to get the whole control and familiar with the details, configurations, designs and source code. Develop and maintain the internal release of big data systems and components as the business requirements.
Keep close and overall monitoring for all the deployments of the systems, maintain the system’s stability, improve the performance, discover the performance bottlenecks, tracking and troubleshooting, cost optimisation.
Requirements:
B. Sci. / Ms / PhD in Computer Science or a related technical field
Familiar with at least one of these languages: Java, Scala, Python, Bash under Linux / Unix. Scala is a plus
Familiar with the use and compute logical of SQL
Knowledge about the Big Data Infrastructure system technology like Distributed File System, Distributed Computing, Distributed Database will be a plus
Hands-on experiences Hadoop, Spark, Kafka, and/or Presto will be a plus
Love to use and develop open-source technologies
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"Work on an award-winning, international technology!
Endless career opportunities
An innovative, friendly team of 300+
This role will be focused on the development of our existing ClaimLogik line of products as well as working on our new cloud-first, modern suite of applications.

Intelligent Thought, our technology business is scaling and shipping our software globally. Already profitable, part of a much larger group business, with investors such as Macquarie Capital and Envest – we are all set to deliver textbook disruption to the Insurance Industry. The growth of the platform, of our customer base, and the increasing industry demand have led to the need for this role to help the team scale.

Our Philosophy
Give each employee a sense of purpose and an environment for them to connect the importance of their role to delivering a service that matters to our customers.
Challenge the ‘why’ of traditional claims processes.
Keep it simple – do only what brings value and what matters to the customer
Enable employee decisions, empower our people
Responsibilities:
Create, extend and maintain ETL pipelines to form our data lake, data warehouse and analytics platform (currently using the Microsoft Azure set of tools and service)
Help define the optimal data pipeline architecture
Influence the tool selection, platform selection, data architecture and strategy which will transform the business to be truly data-driven
Understand, analyse and size user requirements
Work with different parts of the business to provide them with the insights they need to deliver the best results
Skills & experience:
Degree or qualification in computer science or related
Advanced knowledge of relational database, including query authoring and query optimisation (MS SQL Server and PostgreSQL).
Experience building and optimising ETL pipelines
Experience designing complex data models
Experience working with cloud platforms (Azure or AWS)
Efficient time management and organisational skills
High attention to detail and accuracy
Effective communication skills to build strong working relationships; both written and verbal
Proactive and results-driven
Why Claim Central?
Claim Central Consolidated is a global insurance industry leader across, claims management, insurance technology and data and analytics. Currently operating in the United States, Australia, South Africa, Italy and New Zealand, we have pioneered digitally connected claims management services across the globe. Claim Central is a disruptor and thought leader in the industry and we were recognised as the Australian Financial Review’s 8th Most Innovative Company in Australia in 2016. This business is in a period of unprecedented growth, transitioning our technology and services into multiple geographies at a rapid pace. Our unique culture is based on teamwork, collaboration, trust, respect and performance. We also offer many benefits apart from our exceptional team culture; including flexible work arrangements, and continued professional development.

Be a part of this journey in a career-defining role.",-1,Claim Central,Matraville,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer - AI/ML,-1,"Our client provides services to a major industry across the country. The business is still early in it's days of technology development and the environment is greenfields in nature (no pun intended), effectively working like a start-up.

Their data and analytics team have worked and built leading and bleeding-edge technologies in this space and what they have created so far may be game-changing. From a machine learning perspective, the progress they have made to the business has already seen proven success in changing the future of an industry that will have positive consequences for all those involved.

You will have previously worked in a technical capacity in the data and analytics space and have experience working with an organisation where machine learning has been implemented, not just a concept that the business talks about having or the technology team would love to have. The commercial experience you will have had in the ML field will be proven examples of where you have affected the way a business or industry used to perform, to the changes that have come about from this.

Technically, you will have extensive experience in the Microsoft space - Power BI, Azure etc and you will have previously mentored and coached junior members of the teams you have been part of.

This is a rare opportunity in Brisbane where the business has truly embraced and funded projects across the ML space and would be a great chance for those in the Data Development/Data Engineering field, who are looking to move into a Data Scientist role in the future.

Please send your application through if you would like to know more.",4.0,"Emanate Technology
4.0",Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Solution designer/ ETL Engineer & Data Modeller,-1,"We are looking for a Qualified and Experienced Solution Designer to join our client for a period of 6 months with a view to extend.
You will work closely with team members and your contribution will range across gathering and analyzing information, developing and documenting improved processes and work instructions and experienced DWH Lead with skills in requirement analysis, solution designing, developing, testing and supporting ETL solutions.
A hands-on solution designer, data modeler and ETL developer for Data Warehousing and ETL application transformation projects using Informatica PowerCenter.
Knowledge on AWS, S3, Redshift, Informatica BDM, and related technologies.
Experience working with IPython, PySparks, AuCuMo, Airflow, Jenkins, Github, Athena, JIRA, Rally, Spectrum, Glue, Flyway.
Good exposure on Oracle PL/SQL, aware of DBA activities, writing and performance tuning of complex SQL queries.
Contract length: 6 months
Job Types: Full-time, Contract
Salary: $650.00 – $800.00 per day
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,nducive,Melbourne,-1,-1,-1,-1,-1,-1,-1,-1
"Data Engineer, Wollongong NSW or Mount Waverley VIC",-1,"Company Description
BlueScope is a technically advanced supplier of steel and steel products in Australia. We are an inclusive organisation and every day we showcase our technology and expertise throughout the world.

Job Description
We are looking for two Data Engineers to join our IT team, based in Wollongong NSW or Mount Waverley VIC. Use your experience in analytics to unlock business value, enabling use of big data for insights and decision-making.
Reporting to the Data Product Owner for our Australian Steel Products (ASP) business, this position will support strategic goals related to data. This will see you:
Gather business and technical requirements with the view to deliver outcomes;
Develop and implement end-to-end data collection, consolidation, modelling and visualisation solutions;
Document metadata in a dictionary and catalogue;
Ensure consumers of such information understand its accuracy, timeliness, quality and sensitivity, so that it is used appropriately; and
Identify opportunities to enhance analytics.
What are the benefits?
Work in a supportive and collaborative team environment whilst we embark on a journey to transform the way our business uses data!
Our systems landscape is broad and diverse. You will be encouraged to think creatively to develop data solutions which solve real business problems.
Working in this role you will enjoy:
the chance to learn more about data science;
salaried remuneration with attractive superannuation options;
the opportunity to participate in a performance incentive scheme; and
access to further development and career opportunities with BlueScope.
Who are we looking for?
We welcome applications from professionals with experience in data analytics and/or programming. Supported by your knowledge of project delivery methods (e.g. Agile), you will demonstrate:
experience with data mining, wrangling, mapping and visualisation techniques (e.g. Azure Data Factory, Databricks and/or DevOps etc.);
well-developed ability in gathering business and technical requirements;
skills in developing and implementing collection, consolidation, modelling and visualisation solutions; and
a passion for sharing your knowledge and desire for ongoing professional development.

Qualifications

null

Additional Information
We're proud to have been named an Inclusive Employer for 2019–2020 by the Diversity Council of Australia. We believe that our people are our strength. Having a diverse and inclusive workplace enables us to improve our capability and ensure continued, sustainable success.
We know that workplace flexibility can mean something different to everyone. Under our B-Flex initiative all of our roles have some degree of flexibility. We encourage you to discuss your needs with us.
Applications close Sunday 25th October 2020.",3.3,"BlueScope
3.3",Wollongong,-1,201 to 500 Employees,-1,Company - Private,Construction,"Construction, Repair & Maintenance",$100 to $500 million (USD),-1
ETL Data Engineer,-1,"ETL Data Engineer

Join a team that’s changing how Australia lives, works, plays and grows
We want you to be the best version of you

Work with innovative teams and explore new technologies to help solve real-world problems.

A typical day as a Data Engineer

ETL / Big Data Engineering professionals will be responsible for guiding the full lifecycle of a Data solution, including:
Working in highly client-facing roles to contribute throughout the end-to-end delivery lifecycle of complex and large-scale digital solutions
Use case and business case development
Support existing and new applications utilizing in-depth technical and data knowledge. Troubleshooting complex issues and providing advisory services to improve the client’s data landscape
Help to streamline and simplify the clients’ complex data landscape by integrating different applications and data architectures
Implementation from requirements analysis, platform selection, digital architecture design, application design and development, testing, and deployment
Interstate travel may be required

Basic qualifications:
Bachelor’s degree
Experience across systems integration, information management, data management and architecture, and business analytics
Experience with being in a team focusing on large-scale, multi-release information centric projects
Experience with waterfall and agile delivery and run / application support functions
Part of a team working on End to end implementation of at least 1 big data project

Preferred Skills:
Hand on experience in Data warehousing using ETL tools such as DataStage, Autosys and TeraData
Hands on experience in ETL job development with multiple stages like sequential file, Transformer, Lookup, join, sort and Database stages.
Strong hand on skills in design, development and implementation of various data remediation, Data migration, data integration techniques.
Strong hand on data modelling experience.
Strong hands on experience in database performance tuning including complex query optimizations and physical database tuning using Teradata.
Understanding of architectural designs and strategy related to data migration, data cleansing, data quality and data consolidation.
Proven data analysis, requirement gathering and problem-solving skills
Exposure to Unix environment and shell scripting.
Experience in Banking and Financial services industry
Desirable: Knowledge of cloud computing infrastructure (e.g. Amazon Web Services EC2, Google Cloud, Microsoft Azure)
About Accenture

Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. We combine unmatched experience and specialized capabilities across more than 40 industries — powered by the world’s largest network of Advanced Technology and Intelligent Operations centers. With 513,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises. Visit us at www.accenture.com.

Accenture is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, marital, domestic or civil partnership status, sexual orientation, gender identity, or any other basis as protected by applicable law.

Vera Goga is the Recruiter managing this role. As the team experience high volumes of applications, we appreciate your patience to allow for a fair and timely process.",3.9,"Accenture
3.9",Sydney,-1,10000+ Employees,1989,Company - Public,Consulting,Business Services,$10+ billion (USD),-1
Student Engineer,-1,"The candidate will have the ability to:
Undertake onsite inspection to collect asset condition data based on the relevant engineering standards and technical guidelines;
Undertake desktop analysis to evaluate the condition and performance of the assets;
Provide the appropriate information, advice, engineering input and support services for the sustainable management of Council’s stormwater and transport networks.
Qualifications:
The successful candidate will be enrolled in a Bachelor of Engineering with a minimum of two years completed.
Position Number: 100678
Position Hours: Fixed term (3 months), hours will be negotiated with the successful candidate, maximum of 75 hours per fortnight.
Salary: Schedule A, Salary Point 4.0. $28.64 per hour ($55,853.45 per annum, pro-rata) in accordance with Glenorchy City Council’s Enterprise Agreement 2016
Please note that all successful applicants will be required to provide a current National Police Check prior to commencement of employment.
For further information on this position, contact Patrick Marshall, Senior Civil Engineer on (03) 6216 6800.
How to apply: Applications for this position must be lodged on this submission site or on the Glenorchy City Council website www.gcc.tas.gov.au - Careers page.
To be considered for this role, all applicants must address the key selection criteria in the and provide a current resume. A copy of the position description can be found by clicking the below hyperlink or on the Glenorchy City Council website.
Applications close at 8pm on Sunday, 1st November 2020
- Student Engineer",4.0,"Glenorchy City Council
4.0",Glenorchy,-1,501 to 1000 Employees,-1,Government,-1,-1,Less than $1 million (USD),-1
Data Engineer involving DevOps,-1,"Data Engineer involving DevOps
Axiom Technologies is an Australia based entity with the history of providing Managed IT solutions to medium to large scale enterprises globally. Please visit our website for more information about what we do at www.axiomtechnologies.com
Axiom Technologies is an Equal Opportunity Employer and encourage applicants from all backgrounds and gender to apply, including, Aboriginal and Torres Strait Islander candidates
Job Requirements:
8+ years IT experience, with at least 5+ years of “Data Engineer/Deveoper” focused titles/roles,
Data Tools: Hands on experience with Apache Beam.
Testing: Hands on experience with automated testing activities/outcomes
DevOps: Experience with the processes involving Microservices facilities for artifacts developed
Platform/OS: Mid-range/Unix
Languages: Unix (Shell) Scripting/commands, SQL, Python
File formats: Text, CSV, Parquet, JSON, XML
Scheduling: Jenkins, Airflow
Auto Scripting: Designing/creation of scripts for repetitive activity. E.g. Unix scripting/SQL
Big data: Exposure to Data Lake Concepts, Hive (Schema), HDFS
Source Control tools: GIT
Delivery Models: Agile, Scrum
Ingestion Design: Create/assess Source/Target data mapping designs
Frameworks: Development and delivery frameworks
Activity Reporting/Repository: Jira, Confluence.
Quality: Accuracy and attention to detail
Industry: Financial Services/Banking
Solutions: Define solutions from High level to detail design to address automating ingestion activity. Facilitate/confirm requirements from product owners, business team members and technical associates,
Process Automation: Automating processes in file management, testing data in files, analysis and design, configuration management.
Script Automation: Ability to design/create scripts to automate/improve data copy/migration/ETL for any repetitive activity.
Languages: Java, Python
Scheduling: Control-M
Databases: Relational. E.g. POSTGRESS, Oracle – as a ETL developer
File Formats: Mainframe – experience with referencing its data formats/copybooks
Big data: Experience referencing/using Hive (Schema) to access data in HDFS
Metadata management tools: MDM, EDC and Axon
Performance: Assess, recommend, improve mappings, SQL queries, Batch feeds
Automation Tools: Other tools that may add value to an automation program and generally support development. E.g. API, REST, JDBC, Webservices, Message Queues/Load balancer,
Cloud: Experience with processing of data files to be ingested/stored in the Cloud, preferably with AWS.
Prod Support: Experience in a production support role performing root cause / impact analysis – under time constraints
Experience in a similar role
8+ Years
What next?
If you are looking for that next challenge in your career and wish to apply for this role, please forward your resume to careers.au@axiomtechnologies.com",2.0,"Axiom Technologies
2.0",Melbourne,-1,1 to 50 Employees,-1,Company - Private,Industrial Manufacturing,Manufacturing,Less than $1 million (USD),-1
Data Engineer,-1,"About the Role
We are on an exciting digital journey so it’s a great time to join ME! We are seeking a Junior Data Engineer who enjoys rolling up their sleeves, learning and growing. As part of our Enterprise Data Team, you will ensure fit for purpose data warehouse solutions are built for use across the bank and by utilising best practise ETL standards, whilst ensuring the data is trusted by our BI developers and key business consumers. Oh, and you’ll get to work on Microsoft technology stack too!
You will be involved with investigating data issues, keeping data feeds flowing and collaborating with different projects across the bank to deliver quality data solutions. How important does that sound? What’s even more important is this role contributes directly to our overall business strategy through the provision of data to enable analytics & reporting, as well as supporting business and decision system processes.

About You
You’re naturally a highly motivated and energetic person who thrives in a dynamic, ever-changing collaborative team environment. Ideally you have previous experience as an ETL developer, Data Engineer or a BI developer, and if you have a degree in computer science or similar it would really put you ahead of the rest.

With your knowledge of SQL coding, data modelling, understanding of data warehouse concepts, plus experience of working on complex ETL solutions, you’re ready to expand your horizons and launch your career into the world of IT at ME.

About ME
We’re not like other banks.
ME was created by the industry super funds to be different from the pack – with a core purpose to help all Australians get ahead financially – no conditions, asterisks or exceptions. And we know that looking after customers starts with taking care of our people.
We believe everyone deserves the same opportunities in life, regardless of gender or identity, sexuality, ethnicity, religion or disability ‒ with internal affinity groups.
Perk ME up
Once you get your feet in the door at ME, we’ll put them both in your very own ME-branded Converse shoes. You’ll also get the following financial, health and fun perks when you join the team:
4U Extras portal (discounts and cashback on 100s of items including cinemas, shopping and gym memberships
10% Myki discount
Purchased Leave programme
Internal wellness programme (Mindfully ME)
Professional education through LinkedIn Learning
Novated Leasing
Professional membership reimbursements
Health checks
Financial education (To help you manage your money smarter)
LGBTIQ+ and Women at ME affinity groups

I want those Converse shoes (and the role)
Can’t see a closing date on the advert? That’s because we’re pretty efficient here at ME and we may start looking at applications sooner rather than later, so if this role sounds like your jam, be sure to apply by submitting your resume today.

Should an applicant be the preferred candidate, background checks (including police checks, reference checks, ASIC banned and disqualified persons and bankruptcy checks) will be completed prior to the candidate's employment being confirmed. The outcomes of the background checks do not automatically bar candidates; however will be assessed against the inherent requirements of the job.
Back Share
Apply Now",3.0,"ME Bank
3.0",Melbourne,-1,501 to 1000 Employees,-1,Company - Private,Banks & Credit Unions,Finance,$100 to $500 million (USD),-1
Software Engineer - Machine Learning/Data Science,-1,"Zendesk is looking for a Software Engineer - Machine Learning/Data Science for a full time position in our Melbourne office.
As part of our engineering team, you will work at a scale where the challenges start to get seriously interesting. Our global engineering team is widely dispersed over the world, with people across nearly every continent. You will get a chance to do cool things with a diverse bunch of people while working in the Melbourne office that is home to Zendesk’s first machine learning (ML) research team.
The Data Science Team, together with Data Engineering, have built Satisfaction Prediction, Answer Bot and Content Cues — products that use Machine Learning (ML) and Artificial Intelligence (AI) to help our customers work more efficiently.
What you get to do every day:
We’re currently looking for someone to join our team as we research, develop, and productionise Machine Learning and Deep Learning models. In addition to frequenting Melbourne’s finest purveyors of coffee, ramen, and bulgogi, you may find yourself:
Building machine learning models including neural networks in TensorFlow
Writing and deploying production-grade Python
Querying and constructing datasets in AWS Athena, Spark
Evaluating and responding to real-world model performance
Scaling your ML to millions of predictions per day
Presenting your work to a broader audience
Watching your algorithm help Zendesk’s end-users
What you'll bring to the role:
A strong foundation in a quantitative discipline (e.g. machine learning, statistics, bio/eco/etc-informatics, econometrics, etc) is critical for this position. While experience in deep learning and natural language processing would be beneficial, your best qualities are:
dedication to continuous learning
collaborative work attitude
strong communication skills
You should also be comfortable with at least one programming language, such as Python, R or Scala.
Application Deadline: 18/11/2020
Job Types: Full-time, Permanent
Salary: $85,000.00 – $110,000.00 per year
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Temporarily due to COVID-19",4.5,"Zendesk
4.5",Melbourne,-1,1001 to 5000 Employees,2007,Company - Public,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),-1
Software Engineer (Machine Learning),-1,"About the Role
AdelaideMRI is building a medical reporting tool. We require an engineer to work primarily on machine learning projects to improve reporting speed and report comprehensiveness.
You will perform data analysis of medical report datasets and image datasets to infer sentence recommendations, image classifications, or other actionable results for the doctors.
Skills and Experience
Background in machine learning or image processing
Qualifications in Computer Science, Software Development or Engineering or equivalent experience
Bonus points for Python
No prior medical knowledge is required.
This position offers flexible hours and work arrangements.
Job Type: Full-time
Experience:
Software Engineering: 1 year (Preferred)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Yes",-1,Adelaide MRI,Australia,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Hey there, we’re PEXA!

We started as an idea: to deliver a single, national e-Conveyancing solution. We collaborated with the industry to create a national electronic lodgement and settlement platform: PEXA. From our humble beginnings, we’ve now grown to more than 320 employees across 5 different states. We’re still expanding at a rapid rate and constantly challenging ourselves to create great experiences for our members as they transition to fully digital conveyancing.

Why become a PEXArian?

Great question! Being a PEXArian is so much more than just a job. We are passionate, motivated & unashamedly enthusiastic at PEXA - we love what we do and we’re proud to admit it! Creating brilliant member experiences wouldn’t be possible if we didn’t also strive to create an amazing employee experience. Alongside our members, our employees are at the heart of everything we do.
Here’s a snapshot of what your life at PEXA could look like:

Your growth:
We encourage you to hit your personal and professional Learning & Development goals with our tailored programs and tools.

Your wellness:
We care about your holistic well being - a fully stocked kitchen, four wellness days, a $250 wellness subsidy as well as lunch and learn sessions to support your financial well being.

Your work/life blend:
We know that work is just one aspect of your life, we want to help you create your ideal work/life blend, rather than squeezing in life around work.

Your family:
With a range of benefits aimed at supporting your family including access to a subsidised school holiday program, extended parental leave and flexi-time to support your return to work, superannuation payments for unpaid parental leave for primary carers and a childcare allowance for pre-primary aged children, when we say, ‘welcome to the family’, we really mean it!
The impact you'd drive:
The successful candidate will be responsible for developing, and maintaining infrastructure to support the delivery of new and existing products. They will also be contributing to establish the rules and frameworks for obtaining the required approvals for new products.
On day one we’d love you to have:
Experience with Python, Spark
Event streaming/sourcing with Kafka or AWS Kinesis
Experience with data structures, formats and data security best practices
AWS experience (e.g CloudFormation, S3, ECS, Lambda, SQS, IAM, KMS, DynamoDB, Glue, Athena)
Query construction and optimisation (e.g. SQL, Elasticsearch, Splunk, DynamoDB)
Git, version control practices, and continuous integration/delivery servers
PyUnit and unit testing frameworks
Production release cycles and maintenance
Collaborating with technical and non-technical teams
Even better:
Agile methodology/delivery
GraphQL
Modern frontend technology (e.g. ReactJS, TypeScript)
Machine learning frameworks and tools (e.g. TensorFlow, PyTorch)
OAuth 2, SAML 2, JWT
Data visualisation and exploration tools (e.g. Jupyter notebooks, Tableau)
AWS SageMaker
Sounds like you?
If this role sounds like you, apply today to have your application reviewed ASAP!",3.9,"Property Exchange Australia Limited
3.9",Melbourne,-1,201 to 500 Employees,2010,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Ongoing position
Full time
Based in Sydney, NSW
Who we are
Australian Red Cross is part of the world’s largest humanitarian organisation. Our aim is to improve the lives of the most vulnerable people in Australia and across our region.
About the role
The Data Engineer role will sit within the Data and Integration Squad in IT and will own (design, implement and support) the AWS Big Data technologies such as the Data Lake and Data Warehouse and support the organisation in growing the data analytics capabilities at Red Cross. In addition to this, the data engineer role will also administer the Power BI tool and support the implementation of the data mastering capability.
What you will bring
Experience building and optimizing data pipelines, architectures and data sets.
Experience in dimensional modelling and building data vaults
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with structured, semi-structured and unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Why work for us?
Work for purpose and know that your work assists Red Cross support and empower people and communities in times of vulnerability.
Generous salary packaging options available that can increase your take home pay.
Further information
To find out more about this opportunity please see the position description below or contact Sharath Kumar Gurram on 02 8651 8839.
Position Description: Position Description - Data Engineer .pdf
Applications for this position will close at 11:55pm Thursday, 5 November 2020.",4.1,"Australian Red Cross
4.1",New South Wales,-1,1001 to 5000 Employees,-1,Nonprofit Organization,Industrial Manufacturing,Manufacturing,$500 million to $1 billion (USD),-1
Junior Fullstack Data Engineer (Python and React),-1,"Formbay is the leading Renewable Energy Certificate Trading company in Sydney. We provide Digital Workflow and Compliance solutions in the renewable energy industry and document processing.
Thanks to our meteoric growth and our commitment to be the best at all we do, we've identified the need to bring on board a new Junior Fullstack Data Engineer.
Reporting to our Principal Machine Learning Engineer, you will help build Machine Learning pipelines for our existing Digital Workflow and Compliance solutions to automate fraud detection and document processing over terabytes of photographic and documentary data – including documents, photos, GPS data and aerial/satellite photography.
Our stack is based on Python, JavaScript, Dask, Tensorflow, CUDA, Nix/NixOS, AWS, Docker, PostgreSQL and more – familiarity with these applications will give you a leg-up on the competition.
Our ideal candidate will have the following competencies:
SQL
Python
JavaScript/TypeScript
Our candidate must also be comfortable working with Linux.
Located a stone's throw away from the Queen Victoria Building in Sydney's bustling CBD, we are centrally-located with easy access to public transportation, bars, cafes and fine dining.
Formbay will provide flexible working hours, a generous remuneration package and the opportunity to work on a world-first software solution are what we can offer you. Free, twice-weekly gym sessions and really, really good coffee are also available.
No hiring/recruitment agencies need apply.",5.0,"Formbay
5.0",Sydney,-1,1 to 50 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is an experienced and qualified Data Engineer to join our IT team based in Birtinya.
Key Responsibilities:
Create and maintain data pipelines and or ETL scripts
Create and maintain data integration including API and Batch interfaces
Performed detailed data analysis
Create and maintain corporate data models
Create and maintain data visualization using Qlik.Sense , PowerBI or Simliar Toolset
Experience in defining, building and maintaining data virtualization and/or star schema data warehouses
Maintain, tune and optimise database, integration and visualisation toolsets
ABOUT YOU:
To succeed in this role, you’ll need to bring the following experience and skills:
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Excellent communication skills both oral and written, with an ability to bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking
Experience with data analysis and modelling will be beneficial

How to Apply
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kawana Waters,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Graduate Data Science / Engineer,-1,"The NRMA is an organisation looking to the future, and right now, we are on the lookout for people who can help us reach our goal: to continue to shape the way Australians move, for the next 100 years and beyond. www.mynrma.com.au.
Everyone new to the team, along with our current staff, will temporarily work from home until it is safe to return to our offices. All interviewing and on boarding will be done virtually due to COVID-19.


Your opportunity
As Graduate Data Scientist or Engineer you will be part of the Data Engineering team delivering cloud data transition program for business initiatives and supporting the entire data platform build.
Your key responsibilities will be to:
Implementing Concepts of Data Warehousing, Data Mart creations within Cloud
Use of SQL for data analysis and insights
Building AI/Machine Learning prototype for implementing and supporting existing algorithms
Data Analytical reports build, using different tool sets


Requirements for Success:
Relevant Degree - Computer Science, Computer Engineering, Software Engineering, Data Science
Excellent SQL skills and demonstrated working knowledge in Python
Demonstrated understanding in data structure and algorithms.
Knowledge and concept of data warehousing methodologies
Any reporting tools experience Tableau or Oracle Analytics Cloud, Looker is desirable
Exposure to Google/AWS/Azure/Oracle any cloud based platforms is desirable
Good communication and interpersonal skills

If you have the required skills and the passion to join our high performing team, please apply today.

Employee Benefits
To ensure our employees feel valued, empowered and celebrated we provide a range of employee benefits including:
50% discount on all NRMA insurances
Free Roadside Assistance
12 weeks paid primary and 4 weeks paid secondary parental leave
Free NRMA Blue Membership
At the NRMA Group, we are People Moving People and diversity and inclusion are part of our DNA. Together, we continue to build an inclusive culture that encourages, supports and celebrates the diverse voices of our employees. It fuels our innovation, promotes flexible ways of working and connects us closer to our members and the communities we serve.",2.5,"NRMA Motoring & Services
2.5",Sydney,-1,501 to 1000 Employees,-1,Nonprofit Organization,Casual Restaurants,"Restaurants, Bars & Food Services",$500 million to $1 billion (USD),-1
Data Centre Engineer,-1,"We are a leading world group that provides low-carbon energy and services. To tackle the climate emergency facing us all, our aim is to become the world leader in the zero-carbon energy transition ""as a service"" for our clients – particular for companies and regional authorities. We use our expertise in our key business areas (renewables, gas, services) to provide competitive and bespoke solutions.
The Data Centre Engineer will be employed as part of a 24/7 ongoing shift to coordinate and monitor third party service providers, maintain the data centre facilities and infrastructure plans, coordinate the implementation of customer requests within the data centre and monitor systems, all in accordance with the Contract KPIs and SLAs.
Coordinate and monitor third party service providers for regular maintenance & testing, service faults & call outs, ensuring works are performed in accordance with Contract SLAs
Monitor and maintain the data centre facilities and infrastructure plans and documentation, including electrical, mechanical, hydraulics, fire and BMS/EMS systems
Coordinate the implementation of internal and external customer requests within the data centre
Perform scheduled plant checks and minor maintenance works
Ensure all Work Order requests are raised and closed in a timely manner
Conduct inductions for staff, vendors and contractors
Ensure all work permits for vendor works are raised and closed
Perform inventory checks on all equipment and critical spares

Qualifications
The selected candidate must be able to demonstrate:
Electrical or HVAC background, or Graduate Electrical or Mechanical Engineer
Passionate about quality work and career minded looking for a new challenge
Can commit to a day and night shift roster (2 days of day shift, then 2 days of night shift, 4 days off)
Ideally able to commence asap
As part of carrying out the duties of this role, it is mandatory to hold Australian Citizenship.

If you are interested and meet the selection criteria apply with an up-to-date resume via the apply instructions on this website.

ENGIE Services is an EEO employer, where all applicants are treated with fairness and respect and have equal access to the opportunities available.

We will not be engaging in the services of a recruitment agency to fill this vacancy and therefore request all interested candidates apply directly to this advertisement.

Job
: Maintenance
Primary Location
: Oceania-Australia-New South Wales-Erskine Park
Organization
: ENGIE Services Australia and New Zealand
Schedule
: Full-time
Nature of Responsibility
: Senior operational / administrative role
Job Posting
: Sep 11, 2020, 6:29:59 AM",3.7,"ENGIE Services Australia & New Zealand
3.7",Sydney,-1,5001 to 10000 Employees,1995,Company - Public,Energy,"Oil, Gas, Energy & Utilities",$2 to $5 billion (USD),-1
Senior Data Engineer,-1,"Senior Data Engineer, Temporary, SYDNEY - McKell

Job Title: Senior Data Engineer

Salary: SNSW Grade 9/10 - The package includes base salary range of $111,806 to $134,667, plus employer's contribution to superannuation and annual leave loading.

Location: Head Office – Haymarket

Employment Status: Temporary through till 30th June 2021


About Service NSW:

Service NSW is making it easier for people and businesses across NSW to access government services. The role designs, builds and analyses complex data from multiple sources to identify revenue, process and business improvement opportunities; providing new information and insights to the business to inform planning, continuous improvement and performance.

About the Role

We are currently seeking to appoint a Senior Data Engineer to deliver expert advice and services in the design of a Single View of Customer and data-related services to support the achievement of business outcomes and strategic goals. We support flexible working practices with staff working remotely during this time.

In this role you will:

Design, build and support a modern data platform based in AWS and vendor technologies.
Provide expertise on data modelling for Graph data model and Customer Data Platform (CDP).
Create data pipelines, load, transformation and reporting workloads in AWS.
Work with the latest data engineering technologies like Apache Kafka, AWS Kinesis, AWS Neptune, AWS Glue and AWS Athena.
Contribute to the design and decision-making of the right tool or platform for the job according to requirements.
Provide expert advice and guidance on data quality and data engineering best practices.
Support a “bigger than you can imagine” scale of data in production environments.
Design, develop and support a metrics-driven reporting solution and a meaningful business intelligence platform.
Document the solution design and support procedures of solutions.
Produce reports, visualisations and recommendations to answer complex business problems that are presented in the most appropriate format to ensure clarity for target audience.
Analyse and define new process improvement opportunities to support continuous improvement and business outcomes; providing advice to stakeholders, on ways to improve the efficiency and reliability of data products and services.
Be very responsive to the information needs of the business by corresponding to customers in a timely manner and provide support/solutions to issues raised.
Troubleshoot and perform root cause analysis on production issues. Identify and implement long term solutions to problems. Perform scheduled maintenance, release deployment and production support activities after business hours, from time to time.
Liaise with internal and external customers to discuss and gather requirements, solutions etc. and maintain a good working relationship with the stakeholders.


Skills and Experience Required:

Solid experience with workflow technologies designing and building data pipelines, data models and data stores.
Experience working within and an understanding of Amazon AWS ecosystem, including security and performance tuning.
Hands on experience working with different types of databases, with focus on Graph and NoSQL databases.
Experience with data streaming required. Having used Kafka and related technologies is an added advantage.
Sound knowledge and experience working with batch processing, data extraction and API integration.
Hands on experience with at least one programming language: Java, Python or scripting.
Demonstrated experience working in an Agile based, fast paced, complex environment within cross-functional teams.
Experience developing systematised insights, data analytics and reporting solutions is an added advantage.
Experience with interactive visualisation of data insights is an added advantage.


Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Salary Grade 9/10, with the base salary for this role starting at 111,806 base plus superannuation

Closing Date: 6th November at 9:59am - applications will be reviewed on a rolling basis, applications may close early or extend

Please apply online, direct applications submitted via email will not be considered.

The Department of Customer Service is proud to be an EEO Employer who are fully focused on equality and believe deeply in diversity of all identities making us different and a true reflection of our NSW customers. As an inclusive workplace, we support various employee resource groups, practice flexible work and workplace adjustment.

If you do require an adjustment during the recruitment process, please notify us on your application form.",3.2,"Service NSW
3.2",Sydney,-1,501 to 1000 Employees,2012,Government,State & Regional Agencies,Government,Unknown / Non-Applicable,-1
Data Engineer - Entry / Mid Level,-1,"Work with a great team on interesting projects customers
Gain more experience in AWS, Data, DevOps cloud operations
Got a working knowledge of AWS? We will teach you the cool stuff!

Itoc is seeking an up and coming Data Engineer to join our growing Data Team in Sydney.

This is an exciting role working with databases, data lakes, data warehouses, data transformation (Python SQL) and enabling AI/ML.

You will be implementing foundational, robust and production ready data platforms to enable business data-discovery, self-service, AI/ML functions across a range of client types and industries, allowing them to do more with their data.

You'll be responsible for:

Deploying data repositories such as lakes and warehouses.
Contribute to our growing portfolio of data solutions.
Ongoing optimisation and management of data platforms.
Development of transformational logic for data pipelines
Data evangelism. We want to show our clients how to follow the best practices for data.

Desired Skills and Experience

To take up the challenge, you will have a depth of skills and experience including:

1-2+ yrs of focused data experience working with SQL and/or NoSQL solutions
A solid education in Software Engineering or equivalent industry experience.
Anything Data focused preferred.
Ability to analyse business scenarios and associated data landscape to derive potential opportunities.
Strong foundation in Python and SQL
Working knowledge of APIs
Principle knowledge of the different relational database platforms and modern data storage techniques
Knowledge of the different aspects of data environments
Collect, store, process, verify consume
Experience with version management systems (such as GIT)
Working knowledge of AWS or another cloud platform - we will teach you the cool stuff.
Great communication skills, an ability to work closely with customers, developers and engineers and the confidence to present ideas in open forums.
Relevant tertiary qualifications and/or industry certifications.
Great communication skills, an ability to work closely with clients, developers and engineers and the confidence to present ideas in open forums.

While not required, a background in consulting and professional services is highly desirable.

Itoc Description

This is an exciting and challenging career opportunity to join the growing Sydney-based Data Team of a leading cloud solution provider where you will be given support to reach your long term career goals. You will be part of a team of cloud experts and will work in an environment of continuous improvement and learning delivering innovative cloud solutions across SaaS, online business and enterprise business.

On offer is a chance to join a team with a great working environment, in an organisation that values its employees and sees the value in ensuring they are engaged. Our team are clearly passionate about what they do, that's why we won the following awards:

Customer Obsession Partner of the Year 2015: ANZ Region
Customer Obsession Leadership Partner 2015: re:Invent

As an employer of choice Itoc offers competitive remuneration, training and development programs and a great working environment. We value a healthy work life balance.

The Perks

MacBook or Dell
Continuous internal learning that will provide training and career development opportunities
Working with a collaborative, social team and leveling-up your skills faster than you will anywhere else.
Quarterly social events

Itoc

Culture and smarts are important to us. Bring your secret sauce. This is no ordinary environment, you will work along some of the Cloud’s best. All engineers at Itoc must gain at least five AWS certifications. We work hard but we have fun.

Please note you must have full working rights in Australia and be available on-shore for face to face interviews.

No recruiters please.",4.0,"Itoc
4.0",Sydney,-1,1 to 50 Employees,2013,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Date: 01-Oct-2020

Location:
Melbourne, VIC, AU

Department:Description:
Technology discounts - from Apple HP Lenovo to Windows
Flexible work arrangements - work in a way that suits you best
Salary packaging - to suit your personal and financial circumstances

Do you want to work for one of the fastest growing data teams in Australia? Do you want to work on multiple data platforms and provide new solution offerings by leveraging cloud and big data technologies?

About the team

Big data information and analytics. Three words that spark apprehension in most businesses. But our team of experts are constantly curious and excited about combining our wonderful array of technological expertise to transform data into our clients most valuable assets making their work smarter. Our data consultants are supported with resources training and tools they need to excel at their work but also the freedom and power to create their own paths forward to make a difference.

As a Senior Consultant in Big Data you will work closely with the team and stakeholders to build and deliver a Cloud based vision for a next generation Big Data analytics platform with strong focus on data quality data security and deliver the systems that process huge volumes of data.

What will you typical day look like?

You will play a pivotal role in - Designing and producing high performing and stable applications to perform complex processing of massive volumes of data in a new cloud based architecture; Building real-time data processing applications which are integrated with business systems to enable value from analytic models to drive rapid decision making; Contributing to system architecture design for a data platform (including cloud-based structures both on and off premises data warehouse components and data lakes); this could cover a range of technologies various countries/locations and lines of business; Support data strategy or technology strategy definition programs including technology stack definition and target operating model requirements

Enough about us lets talk about you:
You are someone with:
Use of traditional data analytics tools and techniques (e.g. MSSQL Oracle MySQL) and ETL software (e.g. SSIS Informatica CloverETL)
Working in large scale cloud data solutions using platforms such as AWS or Azure or GCP will be a bonus.
Experience in scripting or programming (e.g. Python Java Scala C#)
Excellent verbal and written communication skills to adapt to technical and non-technical audiences.
Educated to degree level (or have equivalent experience)
Why Deloitte?

At Deloitte we create positively differentiated work experiences that enable our people to feel valued and achieve their full potential. We value difference and embrace people with diverse backgrounds and thinking styles. Knowing that people work best in different ways we are happy to discuss alternative arrangements if the working pattern you are looking for is not specifically indicated.",3.8,"Deloitte
3.8",Melbourne,-1,10000+ Employees,1850,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Engineer,-1,"Opportunity to grow the team
Period of growth
Intuitive app
S2M are working with a FinTech who have created a unique financial product to help thousands of people better manage their finance, and is currently scaling the company to the next level!

They are looking for a Data Engineer to join, and looking for someone who wants to be hands on, with opportunity to grow the team in future.

Role:

Looking for people with strong AWS experience. You will need passion for data and a cloud, through which you will help a rapidly scaling Australian FinTech establish their data infrastructure from the ground up.
5+ years’ experience as a data engineer within the data and analytics domain
A python 3.X aficionado who is very comfortable creating and orchestrating AWS data pipelines with nothing but code
Strong project delivery toolset experience in open source data integration tools
Experience with processing large volumes of complex data including visualisation and insights generation
Ability to define and develop data integration patterns and pipelines
Ability to assess complexity of data (volume, structure, relationship etc.)
Hands on experience working with different databases (RDBMS, NoSQL, Blob storage etc)
Hands on technical expertise setting up DevOps automation
Hands on experience working technologies/platform e.g. AWS, Dockers, Containers
Experience building data profiling and data cleansing frameworks
Technical reconciliation and reporting
Knowledge and experience in end-to-end project delivery, either traditional SDLC or agile delivery methodologies (or hybrid approaches)
Exceptional communication, documentation and presentation skills
If this sounds like you, get in touch today - kate.gabb@s2m.com.au
3167410agsdf",3.1,"S2M
3.1",Sydney,-1,Unknown,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Analysts,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is seeking experienced and qualified Data Analysts to join our IT team based in our corporate office in Birtinya (Sunshine Coast) or at our meat processing facility in Kilcoy.
Key Responsibilities:
A mixture of data analysis and commercial skills to source, blend and analyse data to gain insight and answer key commercial questions
Working with strategic leaders to define and model Key Performance Indicators, and assist in building forecasting models
Working closely with data engineers and BI developers to specify data pipelines and report visualisation
Drive the creation and implementation of data quality business rule including data definition, governance and quality assurance
About You:
To succeed in this role, you’ll need to bring the following experience and skills:
Proven ability to derive insight and knowledge from data using commercial expertise is a strong requirement
Strong SQL and Excel skills are essential, along with strong data analysis and commercial insights
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Effective people communicator - engage with stakeholders on reporting needs, interpret requirements into visual solutions and train/deliver the outputs to the stakeholders getting signoff of acceptance
Bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking

How to Apply:
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kilcoy,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Network Data Engineer,-1,"Min 6+ years of experience in the relevant technologies
Australian Driving License for visiting remote locations / Data Centre for day to day technical work.
Managing Network devices (switches, routers, firewalls, load balancer, and wireless technology)
Performing MACD activities for all network devices.
Supporting BAU operation activities.
Proficient in performing in-depth details of technical troubleshooting, cause and provide recommendation to the client for incidents causing extended network outage to client’s critical locations.
Provide exceptional network services in terms of network support, break-fix, design and consulting, new projects, implementation.
Configure, administer, and document firewall infrastructure.
Manage the firewall deployment, rules migrations, and firewall administration.
Supporting Cloud Migration Activities from traditional to AWS/Azure.
Setting up VPN tunnel with Cloud and 3rd Party network devices.
Integrating and upgrading existing ISP bandwidth with support from ISP Vendor.
Setting up VPN profiles for Users.
Installing hot fix and patches to mitigate the security devices from attacks and bugs.
Reviewing and fine tuning the firewall rules and NAT rules.
Documentation and change control.
Mentoring, Motivating and Guiding support teams
Technical skills:
o LAN
o Wireless
o WAN
o MPLS
o Routing protocols (OSPF,BGP)
o DMVPN
o Azure cloud Networking
o Network Security
Fortigate Manager / Analyzer / Firewall
Cisco ASA
Firepower FTD
Cisco Any connect
Site to Site VPN
F5 Load Balancing and Scripting iRule
Job Types: Full-time, Contract
Schedule:
8 hour shift
Experience:
Scripting: 5 years (Required)
Data Network: 5 years (Required)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Required)",3.6,"Total IT Global
3.6",Sydney,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Engineer - Processing & Analysis,-1,"Job Description:
Design,build and maintain the ingestion system to support various types of data(e.g. User behavior, RDS, NoSQL db and others) to be ingested to the data warehouse more timely and accurately
Translate data requirements into scalable technical data service with low latency and high concurrency
Design,build and maintain the batch or real time data pipeline in production using Hadoop big data technology
Analyze and improve efficiency, scalability, and stability of the system
Define and manage SLA,Data quality for all data sets in allocated areas of ownership
Requirements:
Minimum B.S. degree in Computer Science or a related technical field
2+ years of working experience in programming languages,such as Java,Scala,Python
Familiar with Hadoop, Spark and Flink data processing, experience of TB data processing experience is a plus
Familiar designing and operating of a robust distributed system is a plus
Understand data mining or machine learning
Excited to work intimately with data
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"SYNOPSIS:
Lead Data Engineer
Applications close Sunday 8 November 2020
Ongoing
Contact name: Shyni Sasikala
Phone: (02) 6249 9048
Email: Shyni.Sasikala@ga.gov.au

The Data Policy and Informatics section within the Digital Science and Information branch creates, implements, and promotes policies, platforms and tools that improve and support the quality, discoverability, accessibility, and general usability of Geoscience Australia’s science data products. The section consults with internal and external research, government and industry partners to establish collaborative data frameworks, architectures and models within Geoscience Australia (GA) and across broader national and international communities of practice. The section innovates, builds and maintains tools, systems, processes and governance that enable digital data management, cataloguing and open data delivery.
GA makes accessible a wide range of geoscientific and spatial data to a wide variety of stakeholders in multiple formats, and in recent years GA's data volumes have grown exponentially. GA is focussed on making its data and metadata assets accessible so that they can be used in machine to machine interactions for data analytics and other applications in environments that range from High Performance Computing (HPC), through high-end cloud servers, to mobile devices.
We currently have two opportunities for Lead Data Engineers in the Informatics team. The Lead Data Engineer is responsible for innovating and exploring new technologies that will advance GA’s science goals and maximise the uptake and use of GA’s science data. The Lead Data Engineer reports to the team’s Assistant Director but also works closely with other developers, data scientists and engineers within the Digital Science and Innovation (DiSI) branch, as well as diverse stakeholders both within and external to GA.",3.9,"Geoscience Australia
3.9",Canberra,-1,501 to 1000 Employees,2001,Government,Federal Agencies,Government,$100 to $500 million (USD),-1
Data Engineer,-1,"The Seven Network is part of Seven West Media, one of Australia’s most prominent media companies, with a market leading presence in content across broadcast television, online and in print. Comprising some of Australia’s most renowned media brands, SWM includes not just Seven Network and its affiliate channels 7two, 7mate, 7flix and BVOD offering 7plus, but also 7NEWS.com.au, The West Australian, The Sunday Times and more.
At Seven we are here to bring all Australians closer to the moments that move us - we’re first on the scene, with our finger on the pulse, on demand, in the moment. Together, we’re responsible for creating and sustaining authentic Australian engagement.
A new and exciting opportunity has opened for a Data Engineer to join the Audience Intelligence team. Based in Sydney and reporting to the Head of Data Enablement, you’ll be responsible for:
Implementation of end to end data solutions to support Data Strategy for the SWM group.
Work closely with the Data Solution Designers to develop and maintain scalable data pipelines and build out new file and API based integrations to address requirements from the various business stakeholders.
Collaborates with engineering, analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organisation.
Work on Data Preparation for analytics and data scientist team members and assist them from an engineering perspective in building and optimising the models including building the automation of the end to end workflows
Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.
Perform data analysis required to troubleshoot data related issues and assist in the resolution of production data issues.
Work effectively with vendors for successful delivery of projects and acceptance of the solution
Work on Delivery projects using Agile Software Development methodologies
We are looking for someone who has:
Bachelor's degree in computer science, computer engineering or other technical discipline is essential
Proven experience working as a digital analytics specialist
Extensive experience with digital analytics implementation (e.g. Google Analytics, Snowplow, Adobe Analytics) and BI processes and visualisation platforms
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience in ETL and building and optimizing ‘big data’ pipelines and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Experience with big data tools: Hadoop, Spark, etc., AWS cloud services: EC2, S3, Lambda and familiar with version control systems: Git
Strong coding skills with knowledge of Unix/Linux and scripting languages such as Unix Shell scripting, Python desirable
Experience supporting and working with cross-functional teams in a fast-paced environment.
Ability to multi-task and problem solve with changing demands and priorities
Ability to work under pressure to meet deadlines and detail oriented
Your success is our success: we will provide you with opportunities for you to keep learning and growing, enabling you to challenge and develop yourself. In return, we offer a benefits program that has something in it for everyone.
Seven West Media is an equal opportunity employer and we are committed to creating a diverse and inclusive workplace.
Recruitment Agencies: Seven West Media does not accept any unsolicited agency resumes and will not be responsible for any fees related to unsolicited resumes.
Advertised: 19 Oct 2020 12:00 AM AUS Eastern Daylight Time
Applications close:

Back to search results",2.5,"Seven West Media
2.5",Sydney,-1,5001 to 10000 Employees,1956,Company - Public,TV Broadcast & Cable Networks,Media,Unknown / Non-Applicable,-1
BICON Rules Engineer,-1,"APS 5 - $73,299 - $80,410 per annum plus superannuation
Biosecurity Plant Division
Canberra, ACT
Play an active role in managing biosecurity risk to Australia
Work in a motivated and professional team with a wide range of skills and backgrounds
Full training provided

Who we are
The BICON Content Development Team maintains and improves the Biosecurity Import CONditions database (BICON) content to allow external clients to understand and comply with their biosecurity obligations and internal clients to effectively manage biosecurity risk and regulate imports. We work collaboratively with internal clients to comprehend and implement their BICON content requirements and optimise the use of BICON to publish clear import requirements and onshore management support procedures to effectively manage biosecurity risk.

The Jobs
Key duties of these positions include:

working with business content (import and permit conditions) and import programs to understand and construct decision tree structures in the BICON database, in accordance with system design and authoring conventions
executing changes to import and permit conditions in alignment with service standards while complying with system rules and authoring conventions
providing technical advice through various formats on the most appropriate means of authoring BICON content to achieve import program and stakeholder objectives
using workflow management tools to maintain detailed records of changes to import conditions and key decisions
performing administrative tasks including system reporting, data analysis and scoping tasks for the BICON content change work program
contributing to the development and maintenance of instructional material, authoring conventions and courseware
clearly documenting and reporting system issues
developing and maintaining effective working relationships with internal and external stakeholders.

What we are looking for
Knowledge and experience
Experience working with complex IT systems.
Experience working collaboratively and as part of a team.
Knowledge of the role of biosecurity is preferred but not essential.

For additional information, please read the Job Description below.
Candidate Information Package docx Opens in new window",3.9,"Department of Agriculture & Water Resources
3.9",Australia,-1,5001 to 10000 Employees,-1,Government,Federal Agencies,Government,$500 million to $1 billion (USD),-1
Cloud Data Engineer,-1,"Job no: 509605
Work type: Permanent Full Time
Location: Melbourne, Canberra, Sydney
Do you embrace digital disruption?
Do you love solving complex problems, designing sophisticated solutions and building innovative technology?
Do you believe in creating powerful actionable insights from Data and Analytics?
Do you want to work in a diverse and flexible working environment?
KPMG is one of the most trusted and respected global professional services firms. Through depth of expertise, clarity of insight and strength of purpose we help our clients solve complex challenges, steer change, strengthen, transition and grow. We are a team based practice and this extends to our clients whom we work and collaborate with, in solving complex problems. Together, we design, innovate and implement, providing enduring advice that support our clients and the services they deliver. Our clients vary in size and come from a diverse range of sectors – all sharing in a common goal: to embrace change and deliver services that make Australia a better place. We are looking for talented individuals who would like to join us on the journey.
KPMG’s Digital Delta Team
We re-imagine and re-invent organisations to become world class digital enterprises using advanced technologies, data and human insights. We help organisations to embrace Digital Strategy, Artificial Intelligence (AI) & Cognitive, the Internet of Things (IoT), Data, Analytics & Modelling, Mobile App & Web, and User Experience (UX) & User Interface (UI) and more.
We work with clients to:
Formulate strategies that re-imagine organisations
Harness innovation from the 4th industrial revolution
Actioning insights from trusted data to consistently and quickly make clear decisions
Build adaptive organisations
Thrive as a connected enterprise – front, middle and back office
This is how you’ll contribute:
We are looking for ambitious Data Engineers who are passionate about helping clients define bold ambitions and deliver on them. Joining our team will take you on a journey of personal and technical growth and provide the opportunity to inspire confidence and empower change.
As a Data Engineer you are the designer, builder and manager of the information or ""big data"" infrastructure, preparing data for analytical or operational use. You will design, construct, test and maintain a data pipeline to pull together information from different source systems; integrating, consolidating and cleansing data; and structure it for use in individual analytics applications.
The KPMG Difference
Our people are focused on creating a diverse and dynamic environment that embraces and values differences. We value the variety of unique experiences, qualities and characteristics our people possess and we share and learn from each other.
We are proud to be consistently recognised as an employer of choice for women, and for our achievements in LGBT+ workplace inclusion.
Our commitment to ‘Flexibility’ allows our people to manage the changing demands of work, personal or family life. Explore the links below to hear our people share their experience @ KPMG:
Flexibility empowers wellbeing
Flexibility enables contribution to the community
Flexibility inspires technology & innovation
Flexibility supports family

Make KPMG the clear choice for your career and be Extraordinary!

Advertised: 09 Sep 2020 AUS Eastern Standard Time
Applications close:",3.8,"KPMG
3.8",Sydney,-1,10000+ Employees,1987,Subsidiary or Business Segment,Accounting,Accounting & Legal,$2 to $5 billion (USD),-1
Computer Network and Systems Engineer,-1,"Duties Include but are not limited to:
Tasks Include:
analysing, developing, interpreting and evaluating complex system design and architecture specifications, data models and diagrams in the development, configuration and integration of computer systems
researching, analysing, evaluating and monitoring network infrastructure to ensure networks are configured to operate at optimal performance
assessing and recommending improvements to network operations and integrated hardware, software, communications and operating systems
providing specialist skills in supporting and troubleshooting network problems and emergencies
installing, configuring, testing, maintaining and administering new and upgraded networks, software database applications, servers and workstations
providing network programming in support of specific business needs and requirements
preparing and maintaining procedures and documentation for network inventory, and recording diagnosis and resolution of network faults, enhancements and modifications to networks, and maintenance instructions
monitoring network traffic, and activity, capacity and usage to ensure continued integrity and optimal network performance
Skills and Experience Required:
Must have experience working in a Managed Service environment
Demonstrated experience in IT Networks and Data Centres
Understanding of systems and architectures to meet client needs
Experience in Help Desk including break / fix
Effective and timely documentation
Effective Task Management Skills
Be solution and outcome focused and willing to learn new technologies
Excellent communication skills with staff, clients and partners
Time management, ability to prioritise and deliver to schedule
Experience with N-Able and Connectwise desired
Open Cabling license desired
Job Types: Full-time, Permanent
Salary: $30.00 per hour
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,Trans-plant training,Canberra,-1,-1,-1,-1,-1,-1,-1,-1
Software Engineer (Data),-1,"If you are looking for an opportunity to make a real impact with smart people who are genuinely doing things differently then you've come to the right place! We're growing our data engineering capabilities and are looking for awesome data engineers to join our team.
With our diverse range of clients and projects, no day will look the same - but here's a great snapshot of what you'll be doing:
Work with some of the best Data Scientists and Engineers to deliver production-grade AI and Machine Learning systems as we deliver client projects from inception to production.
Consulting with our clients and working with them to build modern data systems using the 'best of' technologies and principles.
Advising clients on data strategy, architecture and technology.
Applying best software engineering practices in coding, monitoring and alerting, using CI/CD, TDD and cloud architectures.
Working over a wide range of big data tools and environments: not limited to; Apache Kafka, Spark, Python, Scala, Hive, Airflow, AWS EMR & Glue, GCP Dataproc & Dataflow, BigQuery, Snowflake, Redshift.
Who are we?
Glad you asked! We are Eliiza. Data science. Engineered for scale.
We are a passionate team of data scientists and engineers who apply data science and machine learning to solve real-world problems. Our mission is to create a bright future for Australian businesses and society in a world increasingly influenced by intelligent technologies.
We've created a culture that values diversity where people can truly be themselves! We care a lot about growing the Australian AI community in a positive direction, and we're doing several things to try and achieve that:
We provide opportunities for underrepresented groups to work in AI through our associate and intern programmes
We organise and participate in a range of community events, reading groups and meetups
We produce the AI Australia podcast
We blog about topics we care about
We stream brown bag sessions to the broader community
We're also part of Mantel Group's 'house of brands' which means it's not just the Eliiza team you'll work with, learn from and see at social events - there's another 230 of us across DigIO, Kasna & CMD Solutions!
So you're ready for something new?
We're keen to know more about you! Our team is made up of a range of people, with different experience across a huge range of data driven skill sets.
We'd love to hear from you if you have experience with:
one (or more) core language(s), ideally Scala, Python or Java
one (or more) cloud platforms, AWS, GCP, Azure
ETL/ELT concepts and technologies e.g. Data partitioning, Hive, Spark
streaming data concepts and technologies, ideally Kafka (Kinesis, Beam or Pubsub will do)
We'd be over the moon if you:
Experience with distributed/columnar databases (e.g. Snowflake, Big query, Redshift).
Experience with any of a variety of databases e.g. RDMS, NoSql, Columar, Distributed, Time series, Graph.
Knowledge of job orchestration and scheduling. Any experience with Airflow, Luigi or Oozie.
Experience with containers and container orchestration (Docker, Docker Compose or Kubernetes).
However, we value a diversity of skill-sets, and don't necessarily require that you're skilled with all of the above. If you feel you don't fit all the experience/skills listed above we still encourage you to apply or get in touch.
What's on offer if you join us?
We make sure you're always one step ahead by investing your learning and development, every year. We build our own training where it doesn't exist yet.
We hire smart people and get out of their way. By focusing on our five principles and not getting caught up in red tape, we trust you to get the job done.
You'll get all the tools you need - a new iPhone or Google phone, a new Macbook Pro or Dell, and a lot of branded swag!
But hold on, you mentioned a house of brands?
We certainly did! Mantel Group is an Australian-owned, 'house of brands' company with four technology businesses (Eliiza being one of them!) across Melbourne and Sydney. We're building a group of companies with open borders so we can support you to take on new skills without leaving an awesome team - we understand you won't have one job for life!
We may only be just two years old but Mantel Group has already been recognised #9 in the 2020 Best Places to Work in Australia and #4 in the AFR's 2020 fastest growing new companies.
Keen to chat?
Click ""Apply"" to share your details with our talent team, and we'll be in touch.
In the meantime, check out 'how we hire' to find out what's in store if you're successful and get to know us better by visiting our website and following Eliiza on LinkedIn.",-1,Eliiza,Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Infrastructure Engineer,-1,"Job Description:
Design and grow the Shopee data platform to support a variety of big data applications using open-source technologies including Kafka, Hadoop, Presto, HBase, Spark, Hive, Druid, and our own creations. Some examples include a real-time data streaming platform, a unified query platform, a cluster management system, and a machine learning platform
Dig into the source code of some open-source big data system to get the whole control and familiar with the details, configurations, designs and source code. Develop and maintain the internal release of big data systems and components as the business requirements.
Keep close and overall monitoring for all the deployments of the systems, maintain the system’s stability, improve the performance, discover the performance bottlenecks, tracking and troubleshooting, cost optimisation.
Requirements:
B. Sci. / Ms / PhD in Computer Science or a related technical field
Familiar with at least one of these languages: Java, Scala, Python, Bash under Linux / Unix. Scala is a plus
Familiar with the use and compute logical of SQL
Knowledge about the Big Data Infrastructure system technology like Distributed File System, Distributed Computing, Distributed Database will be a plus
Hands-on experiences Hadoop, Spark, Kafka, and/or Presto will be a plus
Love to use and develop open-source technologies
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"Work on an award-winning, international technology!
Endless career opportunities
An innovative, friendly team of 300+
This role will be focused on the development of our existing ClaimLogik line of products as well as working on our new cloud-first, modern suite of applications.

Intelligent Thought, our technology business is scaling and shipping our software globally. Already profitable, part of a much larger group business, with investors such as Macquarie Capital and Envest – we are all set to deliver textbook disruption to the Insurance Industry. The growth of the platform, of our customer base, and the increasing industry demand have led to the need for this role to help the team scale.

Our Philosophy
Give each employee a sense of purpose and an environment for them to connect the importance of their role to delivering a service that matters to our customers.
Challenge the ‘why’ of traditional claims processes.
Keep it simple – do only what brings value and what matters to the customer
Enable employee decisions, empower our people
Responsibilities:
Create, extend and maintain ETL pipelines to form our data lake, data warehouse and analytics platform (currently using the Microsoft Azure set of tools and service)
Help define the optimal data pipeline architecture
Influence the tool selection, platform selection, data architecture and strategy which will transform the business to be truly data-driven
Understand, analyse and size user requirements
Work with different parts of the business to provide them with the insights they need to deliver the best results
Skills & experience:
Degree or qualification in computer science or related
Advanced knowledge of relational database, including query authoring and query optimisation (MS SQL Server and PostgreSQL).
Experience building and optimising ETL pipelines
Experience designing complex data models
Experience working with cloud platforms (Azure or AWS)
Efficient time management and organisational skills
High attention to detail and accuracy
Effective communication skills to build strong working relationships; both written and verbal
Proactive and results-driven
Why Claim Central?
Claim Central Consolidated is a global insurance industry leader across, claims management, insurance technology and data and analytics. Currently operating in the United States, Australia, South Africa, Italy and New Zealand, we have pioneered digitally connected claims management services across the globe. Claim Central is a disruptor and thought leader in the industry and we were recognised as the Australian Financial Review’s 8th Most Innovative Company in Australia in 2016. This business is in a period of unprecedented growth, transitioning our technology and services into multiple geographies at a rapid pace. Our unique culture is based on teamwork, collaboration, trust, respect and performance. We also offer many benefits apart from our exceptional team culture; including flexible work arrangements, and continued professional development.

Be a part of this journey in a career-defining role.",-1,Claim Central,Matraville,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer - AI/ML,-1,"Our client provides services to a major industry across the country. The business is still early in it's days of technology development and the environment is greenfields in nature (no pun intended), effectively working like a start-up.

Their data and analytics team have worked and built leading and bleeding-edge technologies in this space and what they have created so far may be game-changing. From a machine learning perspective, the progress they have made to the business has already seen proven success in changing the future of an industry that will have positive consequences for all those involved.

You will have previously worked in a technical capacity in the data and analytics space and have experience working with an organisation where machine learning has been implemented, not just a concept that the business talks about having or the technology team would love to have. The commercial experience you will have had in the ML field will be proven examples of where you have affected the way a business or industry used to perform, to the changes that have come about from this.

Technically, you will have extensive experience in the Microsoft space - Power BI, Azure etc and you will have previously mentored and coached junior members of the teams you have been part of.

This is a rare opportunity in Brisbane where the business has truly embraced and funded projects across the ML space and would be a great chance for those in the Data Development/Data Engineering field, who are looking to move into a Data Scientist role in the future.

Please send your application through if you would like to know more.",4.0,"Emanate Technology
4.0",Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Solution designer/ ETL Engineer & Data Modeller,-1,"We are looking for a Qualified and Experienced Solution Designer to join our client for a period of 6 months with a view to extend.
You will work closely with team members and your contribution will range across gathering and analyzing information, developing and documenting improved processes and work instructions and experienced DWH Lead with skills in requirement analysis, solution designing, developing, testing and supporting ETL solutions.
A hands-on solution designer, data modeler and ETL developer for Data Warehousing and ETL application transformation projects using Informatica PowerCenter.
Knowledge on AWS, S3, Redshift, Informatica BDM, and related technologies.
Experience working with IPython, PySparks, AuCuMo, Airflow, Jenkins, Github, Athena, JIRA, Rally, Spectrum, Glue, Flyway.
Good exposure on Oracle PL/SQL, aware of DBA activities, writing and performance tuning of complex SQL queries.
Contract length: 6 months
Job Types: Full-time, Contract
Salary: $650.00 – $800.00 per day
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,nducive,Melbourne,-1,-1,-1,-1,-1,-1,-1,-1
"Data Engineer, Wollongong NSW or Mount Waverley VIC",-1,"Company Description
BlueScope is a technically advanced supplier of steel and steel products in Australia. We are an inclusive organisation and every day we showcase our technology and expertise throughout the world.

Job Description
We are looking for two Data Engineers to join our IT team, based in Wollongong NSW or Mount Waverley VIC. Use your experience in analytics to unlock business value, enabling use of big data for insights and decision-making.
Reporting to the Data Product Owner for our Australian Steel Products (ASP) business, this position will support strategic goals related to data. This will see you:
Gather business and technical requirements with the view to deliver outcomes;
Develop and implement end-to-end data collection, consolidation, modelling and visualisation solutions;
Document metadata in a dictionary and catalogue;
Ensure consumers of such information understand its accuracy, timeliness, quality and sensitivity, so that it is used appropriately; and
Identify opportunities to enhance analytics.
What are the benefits?
Work in a supportive and collaborative team environment whilst we embark on a journey to transform the way our business uses data!
Our systems landscape is broad and diverse. You will be encouraged to think creatively to develop data solutions which solve real business problems.
Working in this role you will enjoy:
the chance to learn more about data science;
salaried remuneration with attractive superannuation options;
the opportunity to participate in a performance incentive scheme; and
access to further development and career opportunities with BlueScope.
Who are we looking for?
We welcome applications from professionals with experience in data analytics and/or programming. Supported by your knowledge of project delivery methods (e.g. Agile), you will demonstrate:
experience with data mining, wrangling, mapping and visualisation techniques (e.g. Azure Data Factory, Databricks and/or DevOps etc.);
well-developed ability in gathering business and technical requirements;
skills in developing and implementing collection, consolidation, modelling and visualisation solutions; and
a passion for sharing your knowledge and desire for ongoing professional development.

Qualifications

null

Additional Information
We're proud to have been named an Inclusive Employer for 2019–2020 by the Diversity Council of Australia. We believe that our people are our strength. Having a diverse and inclusive workplace enables us to improve our capability and ensure continued, sustainable success.
We know that workplace flexibility can mean something different to everyone. Under our B-Flex initiative all of our roles have some degree of flexibility. We encourage you to discuss your needs with us.
Applications close Sunday 25th October 2020.",3.3,"BlueScope
3.3",Wollongong,-1,201 to 500 Employees,-1,Company - Private,Construction,"Construction, Repair & Maintenance",$100 to $500 million (USD),-1
ETL Data Engineer,-1,"ETL Data Engineer

Join a team that’s changing how Australia lives, works, plays and grows
We want you to be the best version of you

Work with innovative teams and explore new technologies to help solve real-world problems.

A typical day as a Data Engineer

ETL / Big Data Engineering professionals will be responsible for guiding the full lifecycle of a Data solution, including:
Working in highly client-facing roles to contribute throughout the end-to-end delivery lifecycle of complex and large-scale digital solutions
Use case and business case development
Support existing and new applications utilizing in-depth technical and data knowledge. Troubleshooting complex issues and providing advisory services to improve the client’s data landscape
Help to streamline and simplify the clients’ complex data landscape by integrating different applications and data architectures
Implementation from requirements analysis, platform selection, digital architecture design, application design and development, testing, and deployment
Interstate travel may be required

Basic qualifications:
Bachelor’s degree
Experience across systems integration, information management, data management and architecture, and business analytics
Experience with being in a team focusing on large-scale, multi-release information centric projects
Experience with waterfall and agile delivery and run / application support functions
Part of a team working on End to end implementation of at least 1 big data project

Preferred Skills:
Hand on experience in Data warehousing using ETL tools such as DataStage, Autosys and TeraData
Hands on experience in ETL job development with multiple stages like sequential file, Transformer, Lookup, join, sort and Database stages.
Strong hand on skills in design, development and implementation of various data remediation, Data migration, data integration techniques.
Strong hand on data modelling experience.
Strong hands on experience in database performance tuning including complex query optimizations and physical database tuning using Teradata.
Understanding of architectural designs and strategy related to data migration, data cleansing, data quality and data consolidation.
Proven data analysis, requirement gathering and problem-solving skills
Exposure to Unix environment and shell scripting.
Experience in Banking and Financial services industry
Desirable: Knowledge of cloud computing infrastructure (e.g. Amazon Web Services EC2, Google Cloud, Microsoft Azure)
About Accenture

Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. We combine unmatched experience and specialized capabilities across more than 40 industries — powered by the world’s largest network of Advanced Technology and Intelligent Operations centers. With 513,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises. Visit us at www.accenture.com.

Accenture is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, marital, domestic or civil partnership status, sexual orientation, gender identity, or any other basis as protected by applicable law.

Vera Goga is the Recruiter managing this role. As the team experience high volumes of applications, we appreciate your patience to allow for a fair and timely process.",3.9,"Accenture
3.9",Sydney,-1,10000+ Employees,1989,Company - Public,Consulting,Business Services,$10+ billion (USD),-1
Student Engineer,-1,"The candidate will have the ability to:
Undertake onsite inspection to collect asset condition data based on the relevant engineering standards and technical guidelines;
Undertake desktop analysis to evaluate the condition and performance of the assets;
Provide the appropriate information, advice, engineering input and support services for the sustainable management of Council’s stormwater and transport networks.
Qualifications:
The successful candidate will be enrolled in a Bachelor of Engineering with a minimum of two years completed.
Position Number: 100678
Position Hours: Fixed term (3 months), hours will be negotiated with the successful candidate, maximum of 75 hours per fortnight.
Salary: Schedule A, Salary Point 4.0. $28.64 per hour ($55,853.45 per annum, pro-rata) in accordance with Glenorchy City Council’s Enterprise Agreement 2016
Please note that all successful applicants will be required to provide a current National Police Check prior to commencement of employment.
For further information on this position, contact Patrick Marshall, Senior Civil Engineer on (03) 6216 6800.
How to apply: Applications for this position must be lodged on this submission site or on the Glenorchy City Council website www.gcc.tas.gov.au - Careers page.
To be considered for this role, all applicants must address the key selection criteria in the and provide a current resume. A copy of the position description can be found by clicking the below hyperlink or on the Glenorchy City Council website.
Applications close at 8pm on Sunday, 1st November 2020
- Student Engineer",4.0,"Glenorchy City Council
4.0",Glenorchy,-1,501 to 1000 Employees,-1,Government,-1,-1,Less than $1 million (USD),-1
Data Engineer involving DevOps,-1,"Data Engineer involving DevOps
Axiom Technologies is an Australia based entity with the history of providing Managed IT solutions to medium to large scale enterprises globally. Please visit our website for more information about what we do at www.axiomtechnologies.com
Axiom Technologies is an Equal Opportunity Employer and encourage applicants from all backgrounds and gender to apply, including, Aboriginal and Torres Strait Islander candidates
Job Requirements:
8+ years IT experience, with at least 5+ years of “Data Engineer/Deveoper” focused titles/roles,
Data Tools: Hands on experience with Apache Beam.
Testing: Hands on experience with automated testing activities/outcomes
DevOps: Experience with the processes involving Microservices facilities for artifacts developed
Platform/OS: Mid-range/Unix
Languages: Unix (Shell) Scripting/commands, SQL, Python
File formats: Text, CSV, Parquet, JSON, XML
Scheduling: Jenkins, Airflow
Auto Scripting: Designing/creation of scripts for repetitive activity. E.g. Unix scripting/SQL
Big data: Exposure to Data Lake Concepts, Hive (Schema), HDFS
Source Control tools: GIT
Delivery Models: Agile, Scrum
Ingestion Design: Create/assess Source/Target data mapping designs
Frameworks: Development and delivery frameworks
Activity Reporting/Repository: Jira, Confluence.
Quality: Accuracy and attention to detail
Industry: Financial Services/Banking
Solutions: Define solutions from High level to detail design to address automating ingestion activity. Facilitate/confirm requirements from product owners, business team members and technical associates,
Process Automation: Automating processes in file management, testing data in files, analysis and design, configuration management.
Script Automation: Ability to design/create scripts to automate/improve data copy/migration/ETL for any repetitive activity.
Languages: Java, Python
Scheduling: Control-M
Databases: Relational. E.g. POSTGRESS, Oracle – as a ETL developer
File Formats: Mainframe – experience with referencing its data formats/copybooks
Big data: Experience referencing/using Hive (Schema) to access data in HDFS
Metadata management tools: MDM, EDC and Axon
Performance: Assess, recommend, improve mappings, SQL queries, Batch feeds
Automation Tools: Other tools that may add value to an automation program and generally support development. E.g. API, REST, JDBC, Webservices, Message Queues/Load balancer,
Cloud: Experience with processing of data files to be ingested/stored in the Cloud, preferably with AWS.
Prod Support: Experience in a production support role performing root cause / impact analysis – under time constraints
Experience in a similar role
8+ Years
What next?
If you are looking for that next challenge in your career and wish to apply for this role, please forward your resume to careers.au@axiomtechnologies.com",2.0,"Axiom Technologies
2.0",Melbourne,-1,1 to 50 Employees,-1,Company - Private,Industrial Manufacturing,Manufacturing,Less than $1 million (USD),-1
Data Engineer,-1,"About the Role
We are on an exciting digital journey so it’s a great time to join ME! We are seeking a Junior Data Engineer who enjoys rolling up their sleeves, learning and growing. As part of our Enterprise Data Team, you will ensure fit for purpose data warehouse solutions are built for use across the bank and by utilising best practise ETL standards, whilst ensuring the data is trusted by our BI developers and key business consumers. Oh, and you’ll get to work on Microsoft technology stack too!
You will be involved with investigating data issues, keeping data feeds flowing and collaborating with different projects across the bank to deliver quality data solutions. How important does that sound? What’s even more important is this role contributes directly to our overall business strategy through the provision of data to enable analytics & reporting, as well as supporting business and decision system processes.

About You
You’re naturally a highly motivated and energetic person who thrives in a dynamic, ever-changing collaborative team environment. Ideally you have previous experience as an ETL developer, Data Engineer or a BI developer, and if you have a degree in computer science or similar it would really put you ahead of the rest.

With your knowledge of SQL coding, data modelling, understanding of data warehouse concepts, plus experience of working on complex ETL solutions, you’re ready to expand your horizons and launch your career into the world of IT at ME.

About ME
We’re not like other banks.
ME was created by the industry super funds to be different from the pack – with a core purpose to help all Australians get ahead financially – no conditions, asterisks or exceptions. And we know that looking after customers starts with taking care of our people.
We believe everyone deserves the same opportunities in life, regardless of gender or identity, sexuality, ethnicity, religion or disability ‒ with internal affinity groups.
Perk ME up
Once you get your feet in the door at ME, we’ll put them both in your very own ME-branded Converse shoes. You’ll also get the following financial, health and fun perks when you join the team:
4U Extras portal (discounts and cashback on 100s of items including cinemas, shopping and gym memberships
10% Myki discount
Purchased Leave programme
Internal wellness programme (Mindfully ME)
Professional education through LinkedIn Learning
Novated Leasing
Professional membership reimbursements
Health checks
Financial education (To help you manage your money smarter)
LGBTIQ+ and Women at ME affinity groups

I want those Converse shoes (and the role)
Can’t see a closing date on the advert? That’s because we’re pretty efficient here at ME and we may start looking at applications sooner rather than later, so if this role sounds like your jam, be sure to apply by submitting your resume today.

Should an applicant be the preferred candidate, background checks (including police checks, reference checks, ASIC banned and disqualified persons and bankruptcy checks) will be completed prior to the candidate's employment being confirmed. The outcomes of the background checks do not automatically bar candidates; however will be assessed against the inherent requirements of the job.
Back Share
Apply Now",3.0,"ME Bank
3.0",Melbourne,-1,501 to 1000 Employees,-1,Company - Private,Banks & Credit Unions,Finance,$100 to $500 million (USD),-1
Software Engineer - Machine Learning/Data Science,-1,"Zendesk is looking for a Software Engineer - Machine Learning/Data Science for a full time position in our Melbourne office.
As part of our engineering team, you will work at a scale where the challenges start to get seriously interesting. Our global engineering team is widely dispersed over the world, with people across nearly every continent. You will get a chance to do cool things with a diverse bunch of people while working in the Melbourne office that is home to Zendesk’s first machine learning (ML) research team.
The Data Science Team, together with Data Engineering, have built Satisfaction Prediction, Answer Bot and Content Cues — products that use Machine Learning (ML) and Artificial Intelligence (AI) to help our customers work more efficiently.
What you get to do every day:
We’re currently looking for someone to join our team as we research, develop, and productionise Machine Learning and Deep Learning models. In addition to frequenting Melbourne’s finest purveyors of coffee, ramen, and bulgogi, you may find yourself:
Building machine learning models including neural networks in TensorFlow
Writing and deploying production-grade Python
Querying and constructing datasets in AWS Athena, Spark
Evaluating and responding to real-world model performance
Scaling your ML to millions of predictions per day
Presenting your work to a broader audience
Watching your algorithm help Zendesk’s end-users
What you'll bring to the role:
A strong foundation in a quantitative discipline (e.g. machine learning, statistics, bio/eco/etc-informatics, econometrics, etc) is critical for this position. While experience in deep learning and natural language processing would be beneficial, your best qualities are:
dedication to continuous learning
collaborative work attitude
strong communication skills
You should also be comfortable with at least one programming language, such as Python, R or Scala.
Application Deadline: 18/11/2020
Job Types: Full-time, Permanent
Salary: $85,000.00 – $110,000.00 per year
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Temporarily due to COVID-19",4.5,"Zendesk
4.5",Melbourne,-1,1001 to 5000 Employees,2007,Company - Public,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),-1
Software Engineer (Machine Learning),-1,"About the Role
AdelaideMRI is building a medical reporting tool. We require an engineer to work primarily on machine learning projects to improve reporting speed and report comprehensiveness.
You will perform data analysis of medical report datasets and image datasets to infer sentence recommendations, image classifications, or other actionable results for the doctors.
Skills and Experience
Background in machine learning or image processing
Qualifications in Computer Science, Software Development or Engineering or equivalent experience
Bonus points for Python
No prior medical knowledge is required.
This position offers flexible hours and work arrangements.
Job Type: Full-time
Experience:
Software Engineering: 1 year (Preferred)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Yes",-1,Adelaide MRI,Australia,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Hey there, we’re PEXA!

We started as an idea: to deliver a single, national e-Conveyancing solution. We collaborated with the industry to create a national electronic lodgement and settlement platform: PEXA. From our humble beginnings, we’ve now grown to more than 320 employees across 5 different states. We’re still expanding at a rapid rate and constantly challenging ourselves to create great experiences for our members as they transition to fully digital conveyancing.

Why become a PEXArian?

Great question! Being a PEXArian is so much more than just a job. We are passionate, motivated & unashamedly enthusiastic at PEXA - we love what we do and we’re proud to admit it! Creating brilliant member experiences wouldn’t be possible if we didn’t also strive to create an amazing employee experience. Alongside our members, our employees are at the heart of everything we do.
Here’s a snapshot of what your life at PEXA could look like:

Your growth:
We encourage you to hit your personal and professional Learning & Development goals with our tailored programs and tools.

Your wellness:
We care about your holistic well being - a fully stocked kitchen, four wellness days, a $250 wellness subsidy as well as lunch and learn sessions to support your financial well being.

Your work/life blend:
We know that work is just one aspect of your life, we want to help you create your ideal work/life blend, rather than squeezing in life around work.

Your family:
With a range of benefits aimed at supporting your family including access to a subsidised school holiday program, extended parental leave and flexi-time to support your return to work, superannuation payments for unpaid parental leave for primary carers and a childcare allowance for pre-primary aged children, when we say, ‘welcome to the family’, we really mean it!
The impact you'd drive:
The successful candidate will be responsible for developing, and maintaining infrastructure to support the delivery of new and existing products. They will also be contributing to establish the rules and frameworks for obtaining the required approvals for new products.
On day one we’d love you to have:
Experience with Python, Spark
Event streaming/sourcing with Kafka or AWS Kinesis
Experience with data structures, formats and data security best practices
AWS experience (e.g CloudFormation, S3, ECS, Lambda, SQS, IAM, KMS, DynamoDB, Glue, Athena)
Query construction and optimisation (e.g. SQL, Elasticsearch, Splunk, DynamoDB)
Git, version control practices, and continuous integration/delivery servers
PyUnit and unit testing frameworks
Production release cycles and maintenance
Collaborating with technical and non-technical teams
Even better:
Agile methodology/delivery
GraphQL
Modern frontend technology (e.g. ReactJS, TypeScript)
Machine learning frameworks and tools (e.g. TensorFlow, PyTorch)
OAuth 2, SAML 2, JWT
Data visualisation and exploration tools (e.g. Jupyter notebooks, Tableau)
AWS SageMaker
Sounds like you?
If this role sounds like you, apply today to have your application reviewed ASAP!",3.9,"Property Exchange Australia Limited
3.9",Melbourne,-1,201 to 500 Employees,2010,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Ongoing position
Full time
Based in Sydney, NSW
Who we are
Australian Red Cross is part of the world’s largest humanitarian organisation. Our aim is to improve the lives of the most vulnerable people in Australia and across our region.
About the role
The Data Engineer role will sit within the Data and Integration Squad in IT and will own (design, implement and support) the AWS Big Data technologies such as the Data Lake and Data Warehouse and support the organisation in growing the data analytics capabilities at Red Cross. In addition to this, the data engineer role will also administer the Power BI tool and support the implementation of the data mastering capability.
What you will bring
Experience building and optimizing data pipelines, architectures and data sets.
Experience in dimensional modelling and building data vaults
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with structured, semi-structured and unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Why work for us?
Work for purpose and know that your work assists Red Cross support and empower people and communities in times of vulnerability.
Generous salary packaging options available that can increase your take home pay.
Further information
To find out more about this opportunity please see the position description below or contact Sharath Kumar Gurram on 02 8651 8839.
Position Description: Position Description - Data Engineer .pdf
Applications for this position will close at 11:55pm Thursday, 5 November 2020.",4.1,"Australian Red Cross
4.1",New South Wales,-1,1001 to 5000 Employees,-1,Nonprofit Organization,Industrial Manufacturing,Manufacturing,$500 million to $1 billion (USD),-1
Junior Fullstack Data Engineer (Python and React),-1,"Formbay is the leading Renewable Energy Certificate Trading company in Sydney. We provide Digital Workflow and Compliance solutions in the renewable energy industry and document processing.
Thanks to our meteoric growth and our commitment to be the best at all we do, we've identified the need to bring on board a new Junior Fullstack Data Engineer.
Reporting to our Principal Machine Learning Engineer, you will help build Machine Learning pipelines for our existing Digital Workflow and Compliance solutions to automate fraud detection and document processing over terabytes of photographic and documentary data – including documents, photos, GPS data and aerial/satellite photography.
Our stack is based on Python, JavaScript, Dask, Tensorflow, CUDA, Nix/NixOS, AWS, Docker, PostgreSQL and more – familiarity with these applications will give you a leg-up on the competition.
Our ideal candidate will have the following competencies:
SQL
Python
JavaScript/TypeScript
Our candidate must also be comfortable working with Linux.
Located a stone's throw away from the Queen Victoria Building in Sydney's bustling CBD, we are centrally-located with easy access to public transportation, bars, cafes and fine dining.
Formbay will provide flexible working hours, a generous remuneration package and the opportunity to work on a world-first software solution are what we can offer you. Free, twice-weekly gym sessions and really, really good coffee are also available.
No hiring/recruitment agencies need apply.",5.0,"Formbay
5.0",Sydney,-1,1 to 50 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is an experienced and qualified Data Engineer to join our IT team based in Birtinya.
Key Responsibilities:
Create and maintain data pipelines and or ETL scripts
Create and maintain data integration including API and Batch interfaces
Performed detailed data analysis
Create and maintain corporate data models
Create and maintain data visualization using Qlik.Sense , PowerBI or Simliar Toolset
Experience in defining, building and maintaining data virtualization and/or star schema data warehouses
Maintain, tune and optimise database, integration and visualisation toolsets
ABOUT YOU:
To succeed in this role, you’ll need to bring the following experience and skills:
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Excellent communication skills both oral and written, with an ability to bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking
Experience with data analysis and modelling will be beneficial

How to Apply
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kawana Waters,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Graduate Data Science / Engineer,-1,"The NRMA is an organisation looking to the future, and right now, we are on the lookout for people who can help us reach our goal: to continue to shape the way Australians move, for the next 100 years and beyond. www.mynrma.com.au.
Everyone new to the team, along with our current staff, will temporarily work from home until it is safe to return to our offices. All interviewing and on boarding will be done virtually due to COVID-19.


Your opportunity
As Graduate Data Scientist or Engineer you will be part of the Data Engineering team delivering cloud data transition program for business initiatives and supporting the entire data platform build.
Your key responsibilities will be to:
Implementing Concepts of Data Warehousing, Data Mart creations within Cloud
Use of SQL for data analysis and insights
Building AI/Machine Learning prototype for implementing and supporting existing algorithms
Data Analytical reports build, using different tool sets


Requirements for Success:
Relevant Degree - Computer Science, Computer Engineering, Software Engineering, Data Science
Excellent SQL skills and demonstrated working knowledge in Python
Demonstrated understanding in data structure and algorithms.
Knowledge and concept of data warehousing methodologies
Any reporting tools experience Tableau or Oracle Analytics Cloud, Looker is desirable
Exposure to Google/AWS/Azure/Oracle any cloud based platforms is desirable
Good communication and interpersonal skills

If you have the required skills and the passion to join our high performing team, please apply today.

Employee Benefits
To ensure our employees feel valued, empowered and celebrated we provide a range of employee benefits including:
50% discount on all NRMA insurances
Free Roadside Assistance
12 weeks paid primary and 4 weeks paid secondary parental leave
Free NRMA Blue Membership
At the NRMA Group, we are People Moving People and diversity and inclusion are part of our DNA. Together, we continue to build an inclusive culture that encourages, supports and celebrates the diverse voices of our employees. It fuels our innovation, promotes flexible ways of working and connects us closer to our members and the communities we serve.",2.5,"NRMA Motoring & Services
2.5",Sydney,-1,501 to 1000 Employees,-1,Nonprofit Organization,Casual Restaurants,"Restaurants, Bars & Food Services",$500 million to $1 billion (USD),-1
Data Centre Engineer,-1,"We are a leading world group that provides low-carbon energy and services. To tackle the climate emergency facing us all, our aim is to become the world leader in the zero-carbon energy transition ""as a service"" for our clients – particular for companies and regional authorities. We use our expertise in our key business areas (renewables, gas, services) to provide competitive and bespoke solutions.
The Data Centre Engineer will be employed as part of a 24/7 ongoing shift to coordinate and monitor third party service providers, maintain the data centre facilities and infrastructure plans, coordinate the implementation of customer requests within the data centre and monitor systems, all in accordance with the Contract KPIs and SLAs.
Coordinate and monitor third party service providers for regular maintenance & testing, service faults & call outs, ensuring works are performed in accordance with Contract SLAs
Monitor and maintain the data centre facilities and infrastructure plans and documentation, including electrical, mechanical, hydraulics, fire and BMS/EMS systems
Coordinate the implementation of internal and external customer requests within the data centre
Perform scheduled plant checks and minor maintenance works
Ensure all Work Order requests are raised and closed in a timely manner
Conduct inductions for staff, vendors and contractors
Ensure all work permits for vendor works are raised and closed
Perform inventory checks on all equipment and critical spares

Qualifications
The selected candidate must be able to demonstrate:
Electrical or HVAC background, or Graduate Electrical or Mechanical Engineer
Passionate about quality work and career minded looking for a new challenge
Can commit to a day and night shift roster (2 days of day shift, then 2 days of night shift, 4 days off)
Ideally able to commence asap
As part of carrying out the duties of this role, it is mandatory to hold Australian Citizenship.

If you are interested and meet the selection criteria apply with an up-to-date resume via the apply instructions on this website.

ENGIE Services is an EEO employer, where all applicants are treated with fairness and respect and have equal access to the opportunities available.

We will not be engaging in the services of a recruitment agency to fill this vacancy and therefore request all interested candidates apply directly to this advertisement.

Job
: Maintenance
Primary Location
: Oceania-Australia-New South Wales-Erskine Park
Organization
: ENGIE Services Australia and New Zealand
Schedule
: Full-time
Nature of Responsibility
: Senior operational / administrative role
Job Posting
: Sep 11, 2020, 6:29:59 AM",3.7,"ENGIE Services Australia & New Zealand
3.7",Sydney,-1,5001 to 10000 Employees,1995,Company - Public,Energy,"Oil, Gas, Energy & Utilities",$2 to $5 billion (USD),-1
Senior Data Engineer,-1,"Senior Data Engineer, Temporary, SYDNEY - McKell

Job Title: Senior Data Engineer

Salary: SNSW Grade 9/10 - The package includes base salary range of $111,806 to $134,667, plus employer's contribution to superannuation and annual leave loading.

Location: Head Office – Haymarket

Employment Status: Temporary through till 30th June 2021


About Service NSW:

Service NSW is making it easier for people and businesses across NSW to access government services. The role designs, builds and analyses complex data from multiple sources to identify revenue, process and business improvement opportunities; providing new information and insights to the business to inform planning, continuous improvement and performance.

About the Role

We are currently seeking to appoint a Senior Data Engineer to deliver expert advice and services in the design of a Single View of Customer and data-related services to support the achievement of business outcomes and strategic goals. We support flexible working practices with staff working remotely during this time.

In this role you will:

Design, build and support a modern data platform based in AWS and vendor technologies.
Provide expertise on data modelling for Graph data model and Customer Data Platform (CDP).
Create data pipelines, load, transformation and reporting workloads in AWS.
Work with the latest data engineering technologies like Apache Kafka, AWS Kinesis, AWS Neptune, AWS Glue and AWS Athena.
Contribute to the design and decision-making of the right tool or platform for the job according to requirements.
Provide expert advice and guidance on data quality and data engineering best practices.
Support a “bigger than you can imagine” scale of data in production environments.
Design, develop and support a metrics-driven reporting solution and a meaningful business intelligence platform.
Document the solution design and support procedures of solutions.
Produce reports, visualisations and recommendations to answer complex business problems that are presented in the most appropriate format to ensure clarity for target audience.
Analyse and define new process improvement opportunities to support continuous improvement and business outcomes; providing advice to stakeholders, on ways to improve the efficiency and reliability of data products and services.
Be very responsive to the information needs of the business by corresponding to customers in a timely manner and provide support/solutions to issues raised.
Troubleshoot and perform root cause analysis on production issues. Identify and implement long term solutions to problems. Perform scheduled maintenance, release deployment and production support activities after business hours, from time to time.
Liaise with internal and external customers to discuss and gather requirements, solutions etc. and maintain a good working relationship with the stakeholders.


Skills and Experience Required:

Solid experience with workflow technologies designing and building data pipelines, data models and data stores.
Experience working within and an understanding of Amazon AWS ecosystem, including security and performance tuning.
Hands on experience working with different types of databases, with focus on Graph and NoSQL databases.
Experience with data streaming required. Having used Kafka and related technologies is an added advantage.
Sound knowledge and experience working with batch processing, data extraction and API integration.
Hands on experience with at least one programming language: Java, Python or scripting.
Demonstrated experience working in an Agile based, fast paced, complex environment within cross-functional teams.
Experience developing systematised insights, data analytics and reporting solutions is an added advantage.
Experience with interactive visualisation of data insights is an added advantage.


Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Salary Grade 9/10, with the base salary for this role starting at 111,806 base plus superannuation

Closing Date: 6th November at 9:59am - applications will be reviewed on a rolling basis, applications may close early or extend

Please apply online, direct applications submitted via email will not be considered.

The Department of Customer Service is proud to be an EEO Employer who are fully focused on equality and believe deeply in diversity of all identities making us different and a true reflection of our NSW customers. As an inclusive workplace, we support various employee resource groups, practice flexible work and workplace adjustment.

If you do require an adjustment during the recruitment process, please notify us on your application form.",3.2,"Service NSW
3.2",Sydney,-1,501 to 1000 Employees,2012,Government,State & Regional Agencies,Government,Unknown / Non-Applicable,-1
Data Engineer - Entry / Mid Level,-1,"Work with a great team on interesting projects customers
Gain more experience in AWS, Data, DevOps cloud operations
Got a working knowledge of AWS? We will teach you the cool stuff!

Itoc is seeking an up and coming Data Engineer to join our growing Data Team in Sydney.

This is an exciting role working with databases, data lakes, data warehouses, data transformation (Python SQL) and enabling AI/ML.

You will be implementing foundational, robust and production ready data platforms to enable business data-discovery, self-service, AI/ML functions across a range of client types and industries, allowing them to do more with their data.

You'll be responsible for:

Deploying data repositories such as lakes and warehouses.
Contribute to our growing portfolio of data solutions.
Ongoing optimisation and management of data platforms.
Development of transformational logic for data pipelines
Data evangelism. We want to show our clients how to follow the best practices for data.

Desired Skills and Experience

To take up the challenge, you will have a depth of skills and experience including:

1-2+ yrs of focused data experience working with SQL and/or NoSQL solutions
A solid education in Software Engineering or equivalent industry experience.
Anything Data focused preferred.
Ability to analyse business scenarios and associated data landscape to derive potential opportunities.
Strong foundation in Python and SQL
Working knowledge of APIs
Principle knowledge of the different relational database platforms and modern data storage techniques
Knowledge of the different aspects of data environments
Collect, store, process, verify consume
Experience with version management systems (such as GIT)
Working knowledge of AWS or another cloud platform - we will teach you the cool stuff.
Great communication skills, an ability to work closely with customers, developers and engineers and the confidence to present ideas in open forums.
Relevant tertiary qualifications and/or industry certifications.
Great communication skills, an ability to work closely with clients, developers and engineers and the confidence to present ideas in open forums.

While not required, a background in consulting and professional services is highly desirable.

Itoc Description

This is an exciting and challenging career opportunity to join the growing Sydney-based Data Team of a leading cloud solution provider where you will be given support to reach your long term career goals. You will be part of a team of cloud experts and will work in an environment of continuous improvement and learning delivering innovative cloud solutions across SaaS, online business and enterprise business.

On offer is a chance to join a team with a great working environment, in an organisation that values its employees and sees the value in ensuring they are engaged. Our team are clearly passionate about what they do, that's why we won the following awards:

Customer Obsession Partner of the Year 2015: ANZ Region
Customer Obsession Leadership Partner 2015: re:Invent

As an employer of choice Itoc offers competitive remuneration, training and development programs and a great working environment. We value a healthy work life balance.

The Perks

MacBook or Dell
Continuous internal learning that will provide training and career development opportunities
Working with a collaborative, social team and leveling-up your skills faster than you will anywhere else.
Quarterly social events

Itoc

Culture and smarts are important to us. Bring your secret sauce. This is no ordinary environment, you will work along some of the Cloud’s best. All engineers at Itoc must gain at least five AWS certifications. We work hard but we have fun.

Please note you must have full working rights in Australia and be available on-shore for face to face interviews.

No recruiters please.",4.0,"Itoc
4.0",Sydney,-1,1 to 50 Employees,2013,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Date: 01-Oct-2020

Location:
Melbourne, VIC, AU

Department:Description:
Technology discounts - from Apple HP Lenovo to Windows
Flexible work arrangements - work in a way that suits you best
Salary packaging - to suit your personal and financial circumstances

Do you want to work for one of the fastest growing data teams in Australia? Do you want to work on multiple data platforms and provide new solution offerings by leveraging cloud and big data technologies?

About the team

Big data information and analytics. Three words that spark apprehension in most businesses. But our team of experts are constantly curious and excited about combining our wonderful array of technological expertise to transform data into our clients most valuable assets making their work smarter. Our data consultants are supported with resources training and tools they need to excel at their work but also the freedom and power to create their own paths forward to make a difference.

As a Senior Consultant in Big Data you will work closely with the team and stakeholders to build and deliver a Cloud based vision for a next generation Big Data analytics platform with strong focus on data quality data security and deliver the systems that process huge volumes of data.

What will you typical day look like?

You will play a pivotal role in - Designing and producing high performing and stable applications to perform complex processing of massive volumes of data in a new cloud based architecture; Building real-time data processing applications which are integrated with business systems to enable value from analytic models to drive rapid decision making; Contributing to system architecture design for a data platform (including cloud-based structures both on and off premises data warehouse components and data lakes); this could cover a range of technologies various countries/locations and lines of business; Support data strategy or technology strategy definition programs including technology stack definition and target operating model requirements

Enough about us lets talk about you:
You are someone with:
Use of traditional data analytics tools and techniques (e.g. MSSQL Oracle MySQL) and ETL software (e.g. SSIS Informatica CloverETL)
Working in large scale cloud data solutions using platforms such as AWS or Azure or GCP will be a bonus.
Experience in scripting or programming (e.g. Python Java Scala C#)
Excellent verbal and written communication skills to adapt to technical and non-technical audiences.
Educated to degree level (or have equivalent experience)
Why Deloitte?

At Deloitte we create positively differentiated work experiences that enable our people to feel valued and achieve their full potential. We value difference and embrace people with diverse backgrounds and thinking styles. Knowing that people work best in different ways we are happy to discuss alternative arrangements if the working pattern you are looking for is not specifically indicated.",3.8,"Deloitte
3.8",Melbourne,-1,10000+ Employees,1850,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Engineer,-1,"Opportunity to grow the team
Period of growth
Intuitive app
S2M are working with a FinTech who have created a unique financial product to help thousands of people better manage their finance, and is currently scaling the company to the next level!

They are looking for a Data Engineer to join, and looking for someone who wants to be hands on, with opportunity to grow the team in future.

Role:

Looking for people with strong AWS experience. You will need passion for data and a cloud, through which you will help a rapidly scaling Australian FinTech establish their data infrastructure from the ground up.
5+ years’ experience as a data engineer within the data and analytics domain
A python 3.X aficionado who is very comfortable creating and orchestrating AWS data pipelines with nothing but code
Strong project delivery toolset experience in open source data integration tools
Experience with processing large volumes of complex data including visualisation and insights generation
Ability to define and develop data integration patterns and pipelines
Ability to assess complexity of data (volume, structure, relationship etc.)
Hands on experience working with different databases (RDBMS, NoSQL, Blob storage etc)
Hands on technical expertise setting up DevOps automation
Hands on experience working technologies/platform e.g. AWS, Dockers, Containers
Experience building data profiling and data cleansing frameworks
Technical reconciliation and reporting
Knowledge and experience in end-to-end project delivery, either traditional SDLC or agile delivery methodologies (or hybrid approaches)
Exceptional communication, documentation and presentation skills
If this sounds like you, get in touch today - kate.gabb@s2m.com.au
3167410agsdf",3.1,"S2M
3.1",Sydney,-1,Unknown,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Analysts,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is seeking experienced and qualified Data Analysts to join our IT team based in our corporate office in Birtinya (Sunshine Coast) or at our meat processing facility in Kilcoy.
Key Responsibilities:
A mixture of data analysis and commercial skills to source, blend and analyse data to gain insight and answer key commercial questions
Working with strategic leaders to define and model Key Performance Indicators, and assist in building forecasting models
Working closely with data engineers and BI developers to specify data pipelines and report visualisation
Drive the creation and implementation of data quality business rule including data definition, governance and quality assurance
About You:
To succeed in this role, you’ll need to bring the following experience and skills:
Proven ability to derive insight and knowledge from data using commercial expertise is a strong requirement
Strong SQL and Excel skills are essential, along with strong data analysis and commercial insights
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Effective people communicator - engage with stakeholders on reporting needs, interpret requirements into visual solutions and train/deliver the outputs to the stakeholders getting signoff of acceptance
Bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking

How to Apply:
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kilcoy,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Network Data Engineer,-1,"Min 6+ years of experience in the relevant technologies
Australian Driving License for visiting remote locations / Data Centre for day to day technical work.
Managing Network devices (switches, routers, firewalls, load balancer, and wireless technology)
Performing MACD activities for all network devices.
Supporting BAU operation activities.
Proficient in performing in-depth details of technical troubleshooting, cause and provide recommendation to the client for incidents causing extended network outage to client’s critical locations.
Provide exceptional network services in terms of network support, break-fix, design and consulting, new projects, implementation.
Configure, administer, and document firewall infrastructure.
Manage the firewall deployment, rules migrations, and firewall administration.
Supporting Cloud Migration Activities from traditional to AWS/Azure.
Setting up VPN tunnel with Cloud and 3rd Party network devices.
Integrating and upgrading existing ISP bandwidth with support from ISP Vendor.
Setting up VPN profiles for Users.
Installing hot fix and patches to mitigate the security devices from attacks and bugs.
Reviewing and fine tuning the firewall rules and NAT rules.
Documentation and change control.
Mentoring, Motivating and Guiding support teams
Technical skills:
o LAN
o Wireless
o WAN
o MPLS
o Routing protocols (OSPF,BGP)
o DMVPN
o Azure cloud Networking
o Network Security
Fortigate Manager / Analyzer / Firewall
Cisco ASA
Firepower FTD
Cisco Any connect
Site to Site VPN
F5 Load Balancing and Scripting iRule
Job Types: Full-time, Contract
Schedule:
8 hour shift
Experience:
Scripting: 5 years (Required)
Data Network: 5 years (Required)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Required)",3.6,"Total IT Global
3.6",Sydney,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Engineer - Processing & Analysis,-1,"Job Description:
Design,build and maintain the ingestion system to support various types of data(e.g. User behavior, RDS, NoSQL db and others) to be ingested to the data warehouse more timely and accurately
Translate data requirements into scalable technical data service with low latency and high concurrency
Design,build and maintain the batch or real time data pipeline in production using Hadoop big data technology
Analyze and improve efficiency, scalability, and stability of the system
Define and manage SLA,Data quality for all data sets in allocated areas of ownership
Requirements:
Minimum B.S. degree in Computer Science or a related technical field
2+ years of working experience in programming languages,such as Java,Scala,Python
Familiar with Hadoop, Spark and Flink data processing, experience of TB data processing experience is a plus
Familiar designing and operating of a robust distributed system is a plus
Understand data mining or machine learning
Excited to work intimately with data
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"SYNOPSIS:
Lead Data Engineer
Applications close Sunday 8 November 2020
Ongoing
Contact name: Shyni Sasikala
Phone: (02) 6249 9048
Email: Shyni.Sasikala@ga.gov.au

The Data Policy and Informatics section within the Digital Science and Information branch creates, implements, and promotes policies, platforms and tools that improve and support the quality, discoverability, accessibility, and general usability of Geoscience Australia’s science data products. The section consults with internal and external research, government and industry partners to establish collaborative data frameworks, architectures and models within Geoscience Australia (GA) and across broader national and international communities of practice. The section innovates, builds and maintains tools, systems, processes and governance that enable digital data management, cataloguing and open data delivery.
GA makes accessible a wide range of geoscientific and spatial data to a wide variety of stakeholders in multiple formats, and in recent years GA's data volumes have grown exponentially. GA is focussed on making its data and metadata assets accessible so that they can be used in machine to machine interactions for data analytics and other applications in environments that range from High Performance Computing (HPC), through high-end cloud servers, to mobile devices.
We currently have two opportunities for Lead Data Engineers in the Informatics team. The Lead Data Engineer is responsible for innovating and exploring new technologies that will advance GA’s science goals and maximise the uptake and use of GA’s science data. The Lead Data Engineer reports to the team’s Assistant Director but also works closely with other developers, data scientists and engineers within the Digital Science and Innovation (DiSI) branch, as well as diverse stakeholders both within and external to GA.",3.9,"Geoscience Australia
3.9",Canberra,-1,501 to 1000 Employees,2001,Government,Federal Agencies,Government,$100 to $500 million (USD),-1
Data Engineer,-1,"The Seven Network is part of Seven West Media, one of Australia’s most prominent media companies, with a market leading presence in content across broadcast television, online and in print. Comprising some of Australia’s most renowned media brands, SWM includes not just Seven Network and its affiliate channels 7two, 7mate, 7flix and BVOD offering 7plus, but also 7NEWS.com.au, The West Australian, The Sunday Times and more.
At Seven we are here to bring all Australians closer to the moments that move us - we’re first on the scene, with our finger on the pulse, on demand, in the moment. Together, we’re responsible for creating and sustaining authentic Australian engagement.
A new and exciting opportunity has opened for a Data Engineer to join the Audience Intelligence team. Based in Sydney and reporting to the Head of Data Enablement, you’ll be responsible for:
Implementation of end to end data solutions to support Data Strategy for the SWM group.
Work closely with the Data Solution Designers to develop and maintain scalable data pipelines and build out new file and API based integrations to address requirements from the various business stakeholders.
Collaborates with engineering, analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organisation.
Work on Data Preparation for analytics and data scientist team members and assist them from an engineering perspective in building and optimising the models including building the automation of the end to end workflows
Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.
Perform data analysis required to troubleshoot data related issues and assist in the resolution of production data issues.
Work effectively with vendors for successful delivery of projects and acceptance of the solution
Work on Delivery projects using Agile Software Development methodologies
We are looking for someone who has:
Bachelor's degree in computer science, computer engineering or other technical discipline is essential
Proven experience working as a digital analytics specialist
Extensive experience with digital analytics implementation (e.g. Google Analytics, Snowplow, Adobe Analytics) and BI processes and visualisation platforms
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience in ETL and building and optimizing ‘big data’ pipelines and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Experience with big data tools: Hadoop, Spark, etc., AWS cloud services: EC2, S3, Lambda and familiar with version control systems: Git
Strong coding skills with knowledge of Unix/Linux and scripting languages such as Unix Shell scripting, Python desirable
Experience supporting and working with cross-functional teams in a fast-paced environment.
Ability to multi-task and problem solve with changing demands and priorities
Ability to work under pressure to meet deadlines and detail oriented
Your success is our success: we will provide you with opportunities for you to keep learning and growing, enabling you to challenge and develop yourself. In return, we offer a benefits program that has something in it for everyone.
Seven West Media is an equal opportunity employer and we are committed to creating a diverse and inclusive workplace.
Recruitment Agencies: Seven West Media does not accept any unsolicited agency resumes and will not be responsible for any fees related to unsolicited resumes.
Advertised: 19 Oct 2020 12:00 AM AUS Eastern Daylight Time
Applications close:

Back to search results",2.5,"Seven West Media
2.5",Sydney,-1,5001 to 10000 Employees,1956,Company - Public,TV Broadcast & Cable Networks,Media,Unknown / Non-Applicable,-1
BICON Rules Engineer,-1,"APS 5 - $73,299 - $80,410 per annum plus superannuation
Biosecurity Plant Division
Canberra, ACT
Play an active role in managing biosecurity risk to Australia
Work in a motivated and professional team with a wide range of skills and backgrounds
Full training provided

Who we are
The BICON Content Development Team maintains and improves the Biosecurity Import CONditions database (BICON) content to allow external clients to understand and comply with their biosecurity obligations and internal clients to effectively manage biosecurity risk and regulate imports. We work collaboratively with internal clients to comprehend and implement their BICON content requirements and optimise the use of BICON to publish clear import requirements and onshore management support procedures to effectively manage biosecurity risk.

The Jobs
Key duties of these positions include:

working with business content (import and permit conditions) and import programs to understand and construct decision tree structures in the BICON database, in accordance with system design and authoring conventions
executing changes to import and permit conditions in alignment with service standards while complying with system rules and authoring conventions
providing technical advice through various formats on the most appropriate means of authoring BICON content to achieve import program and stakeholder objectives
using workflow management tools to maintain detailed records of changes to import conditions and key decisions
performing administrative tasks including system reporting, data analysis and scoping tasks for the BICON content change work program
contributing to the development and maintenance of instructional material, authoring conventions and courseware
clearly documenting and reporting system issues
developing and maintaining effective working relationships with internal and external stakeholders.

What we are looking for
Knowledge and experience
Experience working with complex IT systems.
Experience working collaboratively and as part of a team.
Knowledge of the role of biosecurity is preferred but not essential.

For additional information, please read the Job Description below.
Candidate Information Package docx Opens in new window",3.9,"Department of Agriculture & Water Resources
3.9",Australia,-1,5001 to 10000 Employees,-1,Government,Federal Agencies,Government,$500 million to $1 billion (USD),-1
Cloud Data Engineer,-1,"Job no: 509605
Work type: Permanent Full Time
Location: Melbourne, Canberra, Sydney
Do you embrace digital disruption?
Do you love solving complex problems, designing sophisticated solutions and building innovative technology?
Do you believe in creating powerful actionable insights from Data and Analytics?
Do you want to work in a diverse and flexible working environment?
KPMG is one of the most trusted and respected global professional services firms. Through depth of expertise, clarity of insight and strength of purpose we help our clients solve complex challenges, steer change, strengthen, transition and grow. We are a team based practice and this extends to our clients whom we work and collaborate with, in solving complex problems. Together, we design, innovate and implement, providing enduring advice that support our clients and the services they deliver. Our clients vary in size and come from a diverse range of sectors – all sharing in a common goal: to embrace change and deliver services that make Australia a better place. We are looking for talented individuals who would like to join us on the journey.
KPMG’s Digital Delta Team
We re-imagine and re-invent organisations to become world class digital enterprises using advanced technologies, data and human insights. We help organisations to embrace Digital Strategy, Artificial Intelligence (AI) & Cognitive, the Internet of Things (IoT), Data, Analytics & Modelling, Mobile App & Web, and User Experience (UX) & User Interface (UI) and more.
We work with clients to:
Formulate strategies that re-imagine organisations
Harness innovation from the 4th industrial revolution
Actioning insights from trusted data to consistently and quickly make clear decisions
Build adaptive organisations
Thrive as a connected enterprise – front, middle and back office
This is how you’ll contribute:
We are looking for ambitious Data Engineers who are passionate about helping clients define bold ambitions and deliver on them. Joining our team will take you on a journey of personal and technical growth and provide the opportunity to inspire confidence and empower change.
As a Data Engineer you are the designer, builder and manager of the information or ""big data"" infrastructure, preparing data for analytical or operational use. You will design, construct, test and maintain a data pipeline to pull together information from different source systems; integrating, consolidating and cleansing data; and structure it for use in individual analytics applications.
The KPMG Difference
Our people are focused on creating a diverse and dynamic environment that embraces and values differences. We value the variety of unique experiences, qualities and characteristics our people possess and we share and learn from each other.
We are proud to be consistently recognised as an employer of choice for women, and for our achievements in LGBT+ workplace inclusion.
Our commitment to ‘Flexibility’ allows our people to manage the changing demands of work, personal or family life. Explore the links below to hear our people share their experience @ KPMG:
Flexibility empowers wellbeing
Flexibility enables contribution to the community
Flexibility inspires technology & innovation
Flexibility supports family

Make KPMG the clear choice for your career and be Extraordinary!

Advertised: 09 Sep 2020 AUS Eastern Standard Time
Applications close:",3.8,"KPMG
3.8",Sydney,-1,10000+ Employees,1987,Subsidiary or Business Segment,Accounting,Accounting & Legal,$2 to $5 billion (USD),-1
Computer Network and Systems Engineer,-1,"Duties Include but are not limited to:
Tasks Include:
analysing, developing, interpreting and evaluating complex system design and architecture specifications, data models and diagrams in the development, configuration and integration of computer systems
researching, analysing, evaluating and monitoring network infrastructure to ensure networks are configured to operate at optimal performance
assessing and recommending improvements to network operations and integrated hardware, software, communications and operating systems
providing specialist skills in supporting and troubleshooting network problems and emergencies
installing, configuring, testing, maintaining and administering new and upgraded networks, software database applications, servers and workstations
providing network programming in support of specific business needs and requirements
preparing and maintaining procedures and documentation for network inventory, and recording diagnosis and resolution of network faults, enhancements and modifications to networks, and maintenance instructions
monitoring network traffic, and activity, capacity and usage to ensure continued integrity and optimal network performance
Skills and Experience Required:
Must have experience working in a Managed Service environment
Demonstrated experience in IT Networks and Data Centres
Understanding of systems and architectures to meet client needs
Experience in Help Desk including break / fix
Effective and timely documentation
Effective Task Management Skills
Be solution and outcome focused and willing to learn new technologies
Excellent communication skills with staff, clients and partners
Time management, ability to prioritise and deliver to schedule
Experience with N-Able and Connectwise desired
Open Cabling license desired
Job Types: Full-time, Permanent
Salary: $30.00 per hour
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,Trans-plant training,Canberra,-1,-1,-1,-1,-1,-1,-1,-1
Software Engineer (Data),-1,"If you are looking for an opportunity to make a real impact with smart people who are genuinely doing things differently then you've come to the right place! We're growing our data engineering capabilities and are looking for awesome data engineers to join our team.
With our diverse range of clients and projects, no day will look the same - but here's a great snapshot of what you'll be doing:
Work with some of the best Data Scientists and Engineers to deliver production-grade AI and Machine Learning systems as we deliver client projects from inception to production.
Consulting with our clients and working with them to build modern data systems using the 'best of' technologies and principles.
Advising clients on data strategy, architecture and technology.
Applying best software engineering practices in coding, monitoring and alerting, using CI/CD, TDD and cloud architectures.
Working over a wide range of big data tools and environments: not limited to; Apache Kafka, Spark, Python, Scala, Hive, Airflow, AWS EMR & Glue, GCP Dataproc & Dataflow, BigQuery, Snowflake, Redshift.
Who are we?
Glad you asked! We are Eliiza. Data science. Engineered for scale.
We are a passionate team of data scientists and engineers who apply data science and machine learning to solve real-world problems. Our mission is to create a bright future for Australian businesses and society in a world increasingly influenced by intelligent technologies.
We've created a culture that values diversity where people can truly be themselves! We care a lot about growing the Australian AI community in a positive direction, and we're doing several things to try and achieve that:
We provide opportunities for underrepresented groups to work in AI through our associate and intern programmes
We organise and participate in a range of community events, reading groups and meetups
We produce the AI Australia podcast
We blog about topics we care about
We stream brown bag sessions to the broader community
We're also part of Mantel Group's 'house of brands' which means it's not just the Eliiza team you'll work with, learn from and see at social events - there's another 230 of us across DigIO, Kasna & CMD Solutions!
So you're ready for something new?
We're keen to know more about you! Our team is made up of a range of people, with different experience across a huge range of data driven skill sets.
We'd love to hear from you if you have experience with:
one (or more) core language(s), ideally Scala, Python or Java
one (or more) cloud platforms, AWS, GCP, Azure
ETL/ELT concepts and technologies e.g. Data partitioning, Hive, Spark
streaming data concepts and technologies, ideally Kafka (Kinesis, Beam or Pubsub will do)
We'd be over the moon if you:
Experience with distributed/columnar databases (e.g. Snowflake, Big query, Redshift).
Experience with any of a variety of databases e.g. RDMS, NoSql, Columar, Distributed, Time series, Graph.
Knowledge of job orchestration and scheduling. Any experience with Airflow, Luigi or Oozie.
Experience with containers and container orchestration (Docker, Docker Compose or Kubernetes).
However, we value a diversity of skill-sets, and don't necessarily require that you're skilled with all of the above. If you feel you don't fit all the experience/skills listed above we still encourage you to apply or get in touch.
What's on offer if you join us?
We make sure you're always one step ahead by investing your learning and development, every year. We build our own training where it doesn't exist yet.
We hire smart people and get out of their way. By focusing on our five principles and not getting caught up in red tape, we trust you to get the job done.
You'll get all the tools you need - a new iPhone or Google phone, a new Macbook Pro or Dell, and a lot of branded swag!
But hold on, you mentioned a house of brands?
We certainly did! Mantel Group is an Australian-owned, 'house of brands' company with four technology businesses (Eliiza being one of them!) across Melbourne and Sydney. We're building a group of companies with open borders so we can support you to take on new skills without leaving an awesome team - we understand you won't have one job for life!
We may only be just two years old but Mantel Group has already been recognised #9 in the 2020 Best Places to Work in Australia and #4 in the AFR's 2020 fastest growing new companies.
Keen to chat?
Click ""Apply"" to share your details with our talent team, and we'll be in touch.
In the meantime, check out 'how we hire' to find out what's in store if you're successful and get to know us better by visiting our website and following Eliiza on LinkedIn.",-1,Eliiza,Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Infrastructure Engineer,-1,"Job Description:
Design and grow the Shopee data platform to support a variety of big data applications using open-source technologies including Kafka, Hadoop, Presto, HBase, Spark, Hive, Druid, and our own creations. Some examples include a real-time data streaming platform, a unified query platform, a cluster management system, and a machine learning platform
Dig into the source code of some open-source big data system to get the whole control and familiar with the details, configurations, designs and source code. Develop and maintain the internal release of big data systems and components as the business requirements.
Keep close and overall monitoring for all the deployments of the systems, maintain the system’s stability, improve the performance, discover the performance bottlenecks, tracking and troubleshooting, cost optimisation.
Requirements:
B. Sci. / Ms / PhD in Computer Science or a related technical field
Familiar with at least one of these languages: Java, Scala, Python, Bash under Linux / Unix. Scala is a plus
Familiar with the use and compute logical of SQL
Knowledge about the Big Data Infrastructure system technology like Distributed File System, Distributed Computing, Distributed Database will be a plus
Hands-on experiences Hadoop, Spark, Kafka, and/or Presto will be a plus
Love to use and develop open-source technologies
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"Work on an award-winning, international technology!
Endless career opportunities
An innovative, friendly team of 300+
This role will be focused on the development of our existing ClaimLogik line of products as well as working on our new cloud-first, modern suite of applications.

Intelligent Thought, our technology business is scaling and shipping our software globally. Already profitable, part of a much larger group business, with investors such as Macquarie Capital and Envest – we are all set to deliver textbook disruption to the Insurance Industry. The growth of the platform, of our customer base, and the increasing industry demand have led to the need for this role to help the team scale.

Our Philosophy
Give each employee a sense of purpose and an environment for them to connect the importance of their role to delivering a service that matters to our customers.
Challenge the ‘why’ of traditional claims processes.
Keep it simple – do only what brings value and what matters to the customer
Enable employee decisions, empower our people
Responsibilities:
Create, extend and maintain ETL pipelines to form our data lake, data warehouse and analytics platform (currently using the Microsoft Azure set of tools and service)
Help define the optimal data pipeline architecture
Influence the tool selection, platform selection, data architecture and strategy which will transform the business to be truly data-driven
Understand, analyse and size user requirements
Work with different parts of the business to provide them with the insights they need to deliver the best results
Skills & experience:
Degree or qualification in computer science or related
Advanced knowledge of relational database, including query authoring and query optimisation (MS SQL Server and PostgreSQL).
Experience building and optimising ETL pipelines
Experience designing complex data models
Experience working with cloud platforms (Azure or AWS)
Efficient time management and organisational skills
High attention to detail and accuracy
Effective communication skills to build strong working relationships; both written and verbal
Proactive and results-driven
Why Claim Central?
Claim Central Consolidated is a global insurance industry leader across, claims management, insurance technology and data and analytics. Currently operating in the United States, Australia, South Africa, Italy and New Zealand, we have pioneered digitally connected claims management services across the globe. Claim Central is a disruptor and thought leader in the industry and we were recognised as the Australian Financial Review’s 8th Most Innovative Company in Australia in 2016. This business is in a period of unprecedented growth, transitioning our technology and services into multiple geographies at a rapid pace. Our unique culture is based on teamwork, collaboration, trust, respect and performance. We also offer many benefits apart from our exceptional team culture; including flexible work arrangements, and continued professional development.

Be a part of this journey in a career-defining role.",-1,Claim Central,Matraville,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer - AI/ML,-1,"Our client provides services to a major industry across the country. The business is still early in it's days of technology development and the environment is greenfields in nature (no pun intended), effectively working like a start-up.

Their data and analytics team have worked and built leading and bleeding-edge technologies in this space and what they have created so far may be game-changing. From a machine learning perspective, the progress they have made to the business has already seen proven success in changing the future of an industry that will have positive consequences for all those involved.

You will have previously worked in a technical capacity in the data and analytics space and have experience working with an organisation where machine learning has been implemented, not just a concept that the business talks about having or the technology team would love to have. The commercial experience you will have had in the ML field will be proven examples of where you have affected the way a business or industry used to perform, to the changes that have come about from this.

Technically, you will have extensive experience in the Microsoft space - Power BI, Azure etc and you will have previously mentored and coached junior members of the teams you have been part of.

This is a rare opportunity in Brisbane where the business has truly embraced and funded projects across the ML space and would be a great chance for those in the Data Development/Data Engineering field, who are looking to move into a Data Scientist role in the future.

Please send your application through if you would like to know more.",4.0,"Emanate Technology
4.0",Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Solution designer/ ETL Engineer & Data Modeller,-1,"We are looking for a Qualified and Experienced Solution Designer to join our client for a period of 6 months with a view to extend.
You will work closely with team members and your contribution will range across gathering and analyzing information, developing and documenting improved processes and work instructions and experienced DWH Lead with skills in requirement analysis, solution designing, developing, testing and supporting ETL solutions.
A hands-on solution designer, data modeler and ETL developer for Data Warehousing and ETL application transformation projects using Informatica PowerCenter.
Knowledge on AWS, S3, Redshift, Informatica BDM, and related technologies.
Experience working with IPython, PySparks, AuCuMo, Airflow, Jenkins, Github, Athena, JIRA, Rally, Spectrum, Glue, Flyway.
Good exposure on Oracle PL/SQL, aware of DBA activities, writing and performance tuning of complex SQL queries.
Contract length: 6 months
Job Types: Full-time, Contract
Salary: $650.00 – $800.00 per day
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,nducive,Melbourne,-1,-1,-1,-1,-1,-1,-1,-1
"Data Engineer, Wollongong NSW or Mount Waverley VIC",-1,"Company Description
BlueScope is a technically advanced supplier of steel and steel products in Australia. We are an inclusive organisation and every day we showcase our technology and expertise throughout the world.

Job Description
We are looking for two Data Engineers to join our IT team, based in Wollongong NSW or Mount Waverley VIC. Use your experience in analytics to unlock business value, enabling use of big data for insights and decision-making.
Reporting to the Data Product Owner for our Australian Steel Products (ASP) business, this position will support strategic goals related to data. This will see you:
Gather business and technical requirements with the view to deliver outcomes;
Develop and implement end-to-end data collection, consolidation, modelling and visualisation solutions;
Document metadata in a dictionary and catalogue;
Ensure consumers of such information understand its accuracy, timeliness, quality and sensitivity, so that it is used appropriately; and
Identify opportunities to enhance analytics.
What are the benefits?
Work in a supportive and collaborative team environment whilst we embark on a journey to transform the way our business uses data!
Our systems landscape is broad and diverse. You will be encouraged to think creatively to develop data solutions which solve real business problems.
Working in this role you will enjoy:
the chance to learn more about data science;
salaried remuneration with attractive superannuation options;
the opportunity to participate in a performance incentive scheme; and
access to further development and career opportunities with BlueScope.
Who are we looking for?
We welcome applications from professionals with experience in data analytics and/or programming. Supported by your knowledge of project delivery methods (e.g. Agile), you will demonstrate:
experience with data mining, wrangling, mapping and visualisation techniques (e.g. Azure Data Factory, Databricks and/or DevOps etc.);
well-developed ability in gathering business and technical requirements;
skills in developing and implementing collection, consolidation, modelling and visualisation solutions; and
a passion for sharing your knowledge and desire for ongoing professional development.

Qualifications

null

Additional Information
We're proud to have been named an Inclusive Employer for 2019–2020 by the Diversity Council of Australia. We believe that our people are our strength. Having a diverse and inclusive workplace enables us to improve our capability and ensure continued, sustainable success.
We know that workplace flexibility can mean something different to everyone. Under our B-Flex initiative all of our roles have some degree of flexibility. We encourage you to discuss your needs with us.
Applications close Sunday 25th October 2020.",3.3,"BlueScope
3.3",Wollongong,-1,201 to 500 Employees,-1,Company - Private,Construction,"Construction, Repair & Maintenance",$100 to $500 million (USD),-1
ETL Data Engineer,-1,"ETL Data Engineer

Join a team that’s changing how Australia lives, works, plays and grows
We want you to be the best version of you

Work with innovative teams and explore new technologies to help solve real-world problems.

A typical day as a Data Engineer

ETL / Big Data Engineering professionals will be responsible for guiding the full lifecycle of a Data solution, including:
Working in highly client-facing roles to contribute throughout the end-to-end delivery lifecycle of complex and large-scale digital solutions
Use case and business case development
Support existing and new applications utilizing in-depth technical and data knowledge. Troubleshooting complex issues and providing advisory services to improve the client’s data landscape
Help to streamline and simplify the clients’ complex data landscape by integrating different applications and data architectures
Implementation from requirements analysis, platform selection, digital architecture design, application design and development, testing, and deployment
Interstate travel may be required

Basic qualifications:
Bachelor’s degree
Experience across systems integration, information management, data management and architecture, and business analytics
Experience with being in a team focusing on large-scale, multi-release information centric projects
Experience with waterfall and agile delivery and run / application support functions
Part of a team working on End to end implementation of at least 1 big data project

Preferred Skills:
Hand on experience in Data warehousing using ETL tools such as DataStage, Autosys and TeraData
Hands on experience in ETL job development with multiple stages like sequential file, Transformer, Lookup, join, sort and Database stages.
Strong hand on skills in design, development and implementation of various data remediation, Data migration, data integration techniques.
Strong hand on data modelling experience.
Strong hands on experience in database performance tuning including complex query optimizations and physical database tuning using Teradata.
Understanding of architectural designs and strategy related to data migration, data cleansing, data quality and data consolidation.
Proven data analysis, requirement gathering and problem-solving skills
Exposure to Unix environment and shell scripting.
Experience in Banking and Financial services industry
Desirable: Knowledge of cloud computing infrastructure (e.g. Amazon Web Services EC2, Google Cloud, Microsoft Azure)
About Accenture

Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. We combine unmatched experience and specialized capabilities across more than 40 industries — powered by the world’s largest network of Advanced Technology and Intelligent Operations centers. With 513,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises. Visit us at www.accenture.com.

Accenture is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, marital, domestic or civil partnership status, sexual orientation, gender identity, or any other basis as protected by applicable law.

Vera Goga is the Recruiter managing this role. As the team experience high volumes of applications, we appreciate your patience to allow for a fair and timely process.",3.9,"Accenture
3.9",Sydney,-1,10000+ Employees,1989,Company - Public,Consulting,Business Services,$10+ billion (USD),-1
Student Engineer,-1,"The candidate will have the ability to:
Undertake onsite inspection to collect asset condition data based on the relevant engineering standards and technical guidelines;
Undertake desktop analysis to evaluate the condition and performance of the assets;
Provide the appropriate information, advice, engineering input and support services for the sustainable management of Council’s stormwater and transport networks.
Qualifications:
The successful candidate will be enrolled in a Bachelor of Engineering with a minimum of two years completed.
Position Number: 100678
Position Hours: Fixed term (3 months), hours will be negotiated with the successful candidate, maximum of 75 hours per fortnight.
Salary: Schedule A, Salary Point 4.0. $28.64 per hour ($55,853.45 per annum, pro-rata) in accordance with Glenorchy City Council’s Enterprise Agreement 2016
Please note that all successful applicants will be required to provide a current National Police Check prior to commencement of employment.
For further information on this position, contact Patrick Marshall, Senior Civil Engineer on (03) 6216 6800.
How to apply: Applications for this position must be lodged on this submission site or on the Glenorchy City Council website www.gcc.tas.gov.au - Careers page.
To be considered for this role, all applicants must address the key selection criteria in the and provide a current resume. A copy of the position description can be found by clicking the below hyperlink or on the Glenorchy City Council website.
Applications close at 8pm on Sunday, 1st November 2020
- Student Engineer",4.0,"Glenorchy City Council
4.0",Glenorchy,-1,501 to 1000 Employees,-1,Government,-1,-1,Less than $1 million (USD),-1
Data Engineer involving DevOps,-1,"Data Engineer involving DevOps
Axiom Technologies is an Australia based entity with the history of providing Managed IT solutions to medium to large scale enterprises globally. Please visit our website for more information about what we do at www.axiomtechnologies.com
Axiom Technologies is an Equal Opportunity Employer and encourage applicants from all backgrounds and gender to apply, including, Aboriginal and Torres Strait Islander candidates
Job Requirements:
8+ years IT experience, with at least 5+ years of “Data Engineer/Deveoper” focused titles/roles,
Data Tools: Hands on experience with Apache Beam.
Testing: Hands on experience with automated testing activities/outcomes
DevOps: Experience with the processes involving Microservices facilities for artifacts developed
Platform/OS: Mid-range/Unix
Languages: Unix (Shell) Scripting/commands, SQL, Python
File formats: Text, CSV, Parquet, JSON, XML
Scheduling: Jenkins, Airflow
Auto Scripting: Designing/creation of scripts for repetitive activity. E.g. Unix scripting/SQL
Big data: Exposure to Data Lake Concepts, Hive (Schema), HDFS
Source Control tools: GIT
Delivery Models: Agile, Scrum
Ingestion Design: Create/assess Source/Target data mapping designs
Frameworks: Development and delivery frameworks
Activity Reporting/Repository: Jira, Confluence.
Quality: Accuracy and attention to detail
Industry: Financial Services/Banking
Solutions: Define solutions from High level to detail design to address automating ingestion activity. Facilitate/confirm requirements from product owners, business team members and technical associates,
Process Automation: Automating processes in file management, testing data in files, analysis and design, configuration management.
Script Automation: Ability to design/create scripts to automate/improve data copy/migration/ETL for any repetitive activity.
Languages: Java, Python
Scheduling: Control-M
Databases: Relational. E.g. POSTGRESS, Oracle – as a ETL developer
File Formats: Mainframe – experience with referencing its data formats/copybooks
Big data: Experience referencing/using Hive (Schema) to access data in HDFS
Metadata management tools: MDM, EDC and Axon
Performance: Assess, recommend, improve mappings, SQL queries, Batch feeds
Automation Tools: Other tools that may add value to an automation program and generally support development. E.g. API, REST, JDBC, Webservices, Message Queues/Load balancer,
Cloud: Experience with processing of data files to be ingested/stored in the Cloud, preferably with AWS.
Prod Support: Experience in a production support role performing root cause / impact analysis – under time constraints
Experience in a similar role
8+ Years
What next?
If you are looking for that next challenge in your career and wish to apply for this role, please forward your resume to careers.au@axiomtechnologies.com",2.0,"Axiom Technologies
2.0",Melbourne,-1,1 to 50 Employees,-1,Company - Private,Industrial Manufacturing,Manufacturing,Less than $1 million (USD),-1
Data Engineer,-1,"About the Role
We are on an exciting digital journey so it’s a great time to join ME! We are seeking a Junior Data Engineer who enjoys rolling up their sleeves, learning and growing. As part of our Enterprise Data Team, you will ensure fit for purpose data warehouse solutions are built for use across the bank and by utilising best practise ETL standards, whilst ensuring the data is trusted by our BI developers and key business consumers. Oh, and you’ll get to work on Microsoft technology stack too!
You will be involved with investigating data issues, keeping data feeds flowing and collaborating with different projects across the bank to deliver quality data solutions. How important does that sound? What’s even more important is this role contributes directly to our overall business strategy through the provision of data to enable analytics & reporting, as well as supporting business and decision system processes.

About You
You’re naturally a highly motivated and energetic person who thrives in a dynamic, ever-changing collaborative team environment. Ideally you have previous experience as an ETL developer, Data Engineer or a BI developer, and if you have a degree in computer science or similar it would really put you ahead of the rest.

With your knowledge of SQL coding, data modelling, understanding of data warehouse concepts, plus experience of working on complex ETL solutions, you’re ready to expand your horizons and launch your career into the world of IT at ME.

About ME
We’re not like other banks.
ME was created by the industry super funds to be different from the pack – with a core purpose to help all Australians get ahead financially – no conditions, asterisks or exceptions. And we know that looking after customers starts with taking care of our people.
We believe everyone deserves the same opportunities in life, regardless of gender or identity, sexuality, ethnicity, religion or disability ‒ with internal affinity groups.
Perk ME up
Once you get your feet in the door at ME, we’ll put them both in your very own ME-branded Converse shoes. You’ll also get the following financial, health and fun perks when you join the team:
4U Extras portal (discounts and cashback on 100s of items including cinemas, shopping and gym memberships
10% Myki discount
Purchased Leave programme
Internal wellness programme (Mindfully ME)
Professional education through LinkedIn Learning
Novated Leasing
Professional membership reimbursements
Health checks
Financial education (To help you manage your money smarter)
LGBTIQ+ and Women at ME affinity groups

I want those Converse shoes (and the role)
Can’t see a closing date on the advert? That’s because we’re pretty efficient here at ME and we may start looking at applications sooner rather than later, so if this role sounds like your jam, be sure to apply by submitting your resume today.

Should an applicant be the preferred candidate, background checks (including police checks, reference checks, ASIC banned and disqualified persons and bankruptcy checks) will be completed prior to the candidate's employment being confirmed. The outcomes of the background checks do not automatically bar candidates; however will be assessed against the inherent requirements of the job.
Back Share
Apply Now",3.0,"ME Bank
3.0",Melbourne,-1,501 to 1000 Employees,-1,Company - Private,Banks & Credit Unions,Finance,$100 to $500 million (USD),-1
Software Engineer - Machine Learning/Data Science,-1,"Zendesk is looking for a Software Engineer - Machine Learning/Data Science for a full time position in our Melbourne office.
As part of our engineering team, you will work at a scale where the challenges start to get seriously interesting. Our global engineering team is widely dispersed over the world, with people across nearly every continent. You will get a chance to do cool things with a diverse bunch of people while working in the Melbourne office that is home to Zendesk’s first machine learning (ML) research team.
The Data Science Team, together with Data Engineering, have built Satisfaction Prediction, Answer Bot and Content Cues — products that use Machine Learning (ML) and Artificial Intelligence (AI) to help our customers work more efficiently.
What you get to do every day:
We’re currently looking for someone to join our team as we research, develop, and productionise Machine Learning and Deep Learning models. In addition to frequenting Melbourne’s finest purveyors of coffee, ramen, and bulgogi, you may find yourself:
Building machine learning models including neural networks in TensorFlow
Writing and deploying production-grade Python
Querying and constructing datasets in AWS Athena, Spark
Evaluating and responding to real-world model performance
Scaling your ML to millions of predictions per day
Presenting your work to a broader audience
Watching your algorithm help Zendesk’s end-users
What you'll bring to the role:
A strong foundation in a quantitative discipline (e.g. machine learning, statistics, bio/eco/etc-informatics, econometrics, etc) is critical for this position. While experience in deep learning and natural language processing would be beneficial, your best qualities are:
dedication to continuous learning
collaborative work attitude
strong communication skills
You should also be comfortable with at least one programming language, such as Python, R or Scala.
Application Deadline: 18/11/2020
Job Types: Full-time, Permanent
Salary: $85,000.00 – $110,000.00 per year
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Temporarily due to COVID-19",4.5,"Zendesk
4.5",Melbourne,-1,1001 to 5000 Employees,2007,Company - Public,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),-1
Software Engineer (Machine Learning),-1,"About the Role
AdelaideMRI is building a medical reporting tool. We require an engineer to work primarily on machine learning projects to improve reporting speed and report comprehensiveness.
You will perform data analysis of medical report datasets and image datasets to infer sentence recommendations, image classifications, or other actionable results for the doctors.
Skills and Experience
Background in machine learning or image processing
Qualifications in Computer Science, Software Development or Engineering or equivalent experience
Bonus points for Python
No prior medical knowledge is required.
This position offers flexible hours and work arrangements.
Job Type: Full-time
Experience:
Software Engineering: 1 year (Preferred)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Yes",-1,Adelaide MRI,Australia,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Hey there, we’re PEXA!

We started as an idea: to deliver a single, national e-Conveyancing solution. We collaborated with the industry to create a national electronic lodgement and settlement platform: PEXA. From our humble beginnings, we’ve now grown to more than 320 employees across 5 different states. We’re still expanding at a rapid rate and constantly challenging ourselves to create great experiences for our members as they transition to fully digital conveyancing.

Why become a PEXArian?

Great question! Being a PEXArian is so much more than just a job. We are passionate, motivated & unashamedly enthusiastic at PEXA - we love what we do and we’re proud to admit it! Creating brilliant member experiences wouldn’t be possible if we didn’t also strive to create an amazing employee experience. Alongside our members, our employees are at the heart of everything we do.
Here’s a snapshot of what your life at PEXA could look like:

Your growth:
We encourage you to hit your personal and professional Learning & Development goals with our tailored programs and tools.

Your wellness:
We care about your holistic well being - a fully stocked kitchen, four wellness days, a $250 wellness subsidy as well as lunch and learn sessions to support your financial well being.

Your work/life blend:
We know that work is just one aspect of your life, we want to help you create your ideal work/life blend, rather than squeezing in life around work.

Your family:
With a range of benefits aimed at supporting your family including access to a subsidised school holiday program, extended parental leave and flexi-time to support your return to work, superannuation payments for unpaid parental leave for primary carers and a childcare allowance for pre-primary aged children, when we say, ‘welcome to the family’, we really mean it!
The impact you'd drive:
The successful candidate will be responsible for developing, and maintaining infrastructure to support the delivery of new and existing products. They will also be contributing to establish the rules and frameworks for obtaining the required approvals for new products.
On day one we’d love you to have:
Experience with Python, Spark
Event streaming/sourcing with Kafka or AWS Kinesis
Experience with data structures, formats and data security best practices
AWS experience (e.g CloudFormation, S3, ECS, Lambda, SQS, IAM, KMS, DynamoDB, Glue, Athena)
Query construction and optimisation (e.g. SQL, Elasticsearch, Splunk, DynamoDB)
Git, version control practices, and continuous integration/delivery servers
PyUnit and unit testing frameworks
Production release cycles and maintenance
Collaborating with technical and non-technical teams
Even better:
Agile methodology/delivery
GraphQL
Modern frontend technology (e.g. ReactJS, TypeScript)
Machine learning frameworks and tools (e.g. TensorFlow, PyTorch)
OAuth 2, SAML 2, JWT
Data visualisation and exploration tools (e.g. Jupyter notebooks, Tableau)
AWS SageMaker
Sounds like you?
If this role sounds like you, apply today to have your application reviewed ASAP!",3.9,"Property Exchange Australia Limited
3.9",Melbourne,-1,201 to 500 Employees,2010,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Ongoing position
Full time
Based in Sydney, NSW
Who we are
Australian Red Cross is part of the world’s largest humanitarian organisation. Our aim is to improve the lives of the most vulnerable people in Australia and across our region.
About the role
The Data Engineer role will sit within the Data and Integration Squad in IT and will own (design, implement and support) the AWS Big Data technologies such as the Data Lake and Data Warehouse and support the organisation in growing the data analytics capabilities at Red Cross. In addition to this, the data engineer role will also administer the Power BI tool and support the implementation of the data mastering capability.
What you will bring
Experience building and optimizing data pipelines, architectures and data sets.
Experience in dimensional modelling and building data vaults
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with structured, semi-structured and unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Why work for us?
Work for purpose and know that your work assists Red Cross support and empower people and communities in times of vulnerability.
Generous salary packaging options available that can increase your take home pay.
Further information
To find out more about this opportunity please see the position description below or contact Sharath Kumar Gurram on 02 8651 8839.
Position Description: Position Description - Data Engineer .pdf
Applications for this position will close at 11:55pm Thursday, 5 November 2020.",4.1,"Australian Red Cross
4.1",New South Wales,-1,1001 to 5000 Employees,-1,Nonprofit Organization,Industrial Manufacturing,Manufacturing,$500 million to $1 billion (USD),-1
Junior Fullstack Data Engineer (Python and React),-1,"Formbay is the leading Renewable Energy Certificate Trading company in Sydney. We provide Digital Workflow and Compliance solutions in the renewable energy industry and document processing.
Thanks to our meteoric growth and our commitment to be the best at all we do, we've identified the need to bring on board a new Junior Fullstack Data Engineer.
Reporting to our Principal Machine Learning Engineer, you will help build Machine Learning pipelines for our existing Digital Workflow and Compliance solutions to automate fraud detection and document processing over terabytes of photographic and documentary data – including documents, photos, GPS data and aerial/satellite photography.
Our stack is based on Python, JavaScript, Dask, Tensorflow, CUDA, Nix/NixOS, AWS, Docker, PostgreSQL and more – familiarity with these applications will give you a leg-up on the competition.
Our ideal candidate will have the following competencies:
SQL
Python
JavaScript/TypeScript
Our candidate must also be comfortable working with Linux.
Located a stone's throw away from the Queen Victoria Building in Sydney's bustling CBD, we are centrally-located with easy access to public transportation, bars, cafes and fine dining.
Formbay will provide flexible working hours, a generous remuneration package and the opportunity to work on a world-first software solution are what we can offer you. Free, twice-weekly gym sessions and really, really good coffee are also available.
No hiring/recruitment agencies need apply.",5.0,"Formbay
5.0",Sydney,-1,1 to 50 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is an experienced and qualified Data Engineer to join our IT team based in Birtinya.
Key Responsibilities:
Create and maintain data pipelines and or ETL scripts
Create and maintain data integration including API and Batch interfaces
Performed detailed data analysis
Create and maintain corporate data models
Create and maintain data visualization using Qlik.Sense , PowerBI or Simliar Toolset
Experience in defining, building and maintaining data virtualization and/or star schema data warehouses
Maintain, tune and optimise database, integration and visualisation toolsets
ABOUT YOU:
To succeed in this role, you’ll need to bring the following experience and skills:
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Excellent communication skills both oral and written, with an ability to bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking
Experience with data analysis and modelling will be beneficial

How to Apply
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kawana Waters,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Graduate Data Science / Engineer,-1,"The NRMA is an organisation looking to the future, and right now, we are on the lookout for people who can help us reach our goal: to continue to shape the way Australians move, for the next 100 years and beyond. www.mynrma.com.au.
Everyone new to the team, along with our current staff, will temporarily work from home until it is safe to return to our offices. All interviewing and on boarding will be done virtually due to COVID-19.


Your opportunity
As Graduate Data Scientist or Engineer you will be part of the Data Engineering team delivering cloud data transition program for business initiatives and supporting the entire data platform build.
Your key responsibilities will be to:
Implementing Concepts of Data Warehousing, Data Mart creations within Cloud
Use of SQL for data analysis and insights
Building AI/Machine Learning prototype for implementing and supporting existing algorithms
Data Analytical reports build, using different tool sets


Requirements for Success:
Relevant Degree - Computer Science, Computer Engineering, Software Engineering, Data Science
Excellent SQL skills and demonstrated working knowledge in Python
Demonstrated understanding in data structure and algorithms.
Knowledge and concept of data warehousing methodologies
Any reporting tools experience Tableau or Oracle Analytics Cloud, Looker is desirable
Exposure to Google/AWS/Azure/Oracle any cloud based platforms is desirable
Good communication and interpersonal skills

If you have the required skills and the passion to join our high performing team, please apply today.

Employee Benefits
To ensure our employees feel valued, empowered and celebrated we provide a range of employee benefits including:
50% discount on all NRMA insurances
Free Roadside Assistance
12 weeks paid primary and 4 weeks paid secondary parental leave
Free NRMA Blue Membership
At the NRMA Group, we are People Moving People and diversity and inclusion are part of our DNA. Together, we continue to build an inclusive culture that encourages, supports and celebrates the diverse voices of our employees. It fuels our innovation, promotes flexible ways of working and connects us closer to our members and the communities we serve.",2.5,"NRMA Motoring & Services
2.5",Sydney,-1,501 to 1000 Employees,-1,Nonprofit Organization,Casual Restaurants,"Restaurants, Bars & Food Services",$500 million to $1 billion (USD),-1
Data Centre Engineer,-1,"We are a leading world group that provides low-carbon energy and services. To tackle the climate emergency facing us all, our aim is to become the world leader in the zero-carbon energy transition ""as a service"" for our clients – particular for companies and regional authorities. We use our expertise in our key business areas (renewables, gas, services) to provide competitive and bespoke solutions.
The Data Centre Engineer will be employed as part of a 24/7 ongoing shift to coordinate and monitor third party service providers, maintain the data centre facilities and infrastructure plans, coordinate the implementation of customer requests within the data centre and monitor systems, all in accordance with the Contract KPIs and SLAs.
Coordinate and monitor third party service providers for regular maintenance & testing, service faults & call outs, ensuring works are performed in accordance with Contract SLAs
Monitor and maintain the data centre facilities and infrastructure plans and documentation, including electrical, mechanical, hydraulics, fire and BMS/EMS systems
Coordinate the implementation of internal and external customer requests within the data centre
Perform scheduled plant checks and minor maintenance works
Ensure all Work Order requests are raised and closed in a timely manner
Conduct inductions for staff, vendors and contractors
Ensure all work permits for vendor works are raised and closed
Perform inventory checks on all equipment and critical spares

Qualifications
The selected candidate must be able to demonstrate:
Electrical or HVAC background, or Graduate Electrical or Mechanical Engineer
Passionate about quality work and career minded looking for a new challenge
Can commit to a day and night shift roster (2 days of day shift, then 2 days of night shift, 4 days off)
Ideally able to commence asap
As part of carrying out the duties of this role, it is mandatory to hold Australian Citizenship.

If you are interested and meet the selection criteria apply with an up-to-date resume via the apply instructions on this website.

ENGIE Services is an EEO employer, where all applicants are treated with fairness and respect and have equal access to the opportunities available.

We will not be engaging in the services of a recruitment agency to fill this vacancy and therefore request all interested candidates apply directly to this advertisement.

Job
: Maintenance
Primary Location
: Oceania-Australia-New South Wales-Erskine Park
Organization
: ENGIE Services Australia and New Zealand
Schedule
: Full-time
Nature of Responsibility
: Senior operational / administrative role
Job Posting
: Sep 11, 2020, 6:29:59 AM",3.7,"ENGIE Services Australia & New Zealand
3.7",Sydney,-1,5001 to 10000 Employees,1995,Company - Public,Energy,"Oil, Gas, Energy & Utilities",$2 to $5 billion (USD),-1
Senior Data Engineer,-1,"Senior Data Engineer, Temporary, SYDNEY - McKell

Job Title: Senior Data Engineer

Salary: SNSW Grade 9/10 - The package includes base salary range of $111,806 to $134,667, plus employer's contribution to superannuation and annual leave loading.

Location: Head Office – Haymarket

Employment Status: Temporary through till 30th June 2021


About Service NSW:

Service NSW is making it easier for people and businesses across NSW to access government services. The role designs, builds and analyses complex data from multiple sources to identify revenue, process and business improvement opportunities; providing new information and insights to the business to inform planning, continuous improvement and performance.

About the Role

We are currently seeking to appoint a Senior Data Engineer to deliver expert advice and services in the design of a Single View of Customer and data-related services to support the achievement of business outcomes and strategic goals. We support flexible working practices with staff working remotely during this time.

In this role you will:

Design, build and support a modern data platform based in AWS and vendor technologies.
Provide expertise on data modelling for Graph data model and Customer Data Platform (CDP).
Create data pipelines, load, transformation and reporting workloads in AWS.
Work with the latest data engineering technologies like Apache Kafka, AWS Kinesis, AWS Neptune, AWS Glue and AWS Athena.
Contribute to the design and decision-making of the right tool or platform for the job according to requirements.
Provide expert advice and guidance on data quality and data engineering best practices.
Support a “bigger than you can imagine” scale of data in production environments.
Design, develop and support a metrics-driven reporting solution and a meaningful business intelligence platform.
Document the solution design and support procedures of solutions.
Produce reports, visualisations and recommendations to answer complex business problems that are presented in the most appropriate format to ensure clarity for target audience.
Analyse and define new process improvement opportunities to support continuous improvement and business outcomes; providing advice to stakeholders, on ways to improve the efficiency and reliability of data products and services.
Be very responsive to the information needs of the business by corresponding to customers in a timely manner and provide support/solutions to issues raised.
Troubleshoot and perform root cause analysis on production issues. Identify and implement long term solutions to problems. Perform scheduled maintenance, release deployment and production support activities after business hours, from time to time.
Liaise with internal and external customers to discuss and gather requirements, solutions etc. and maintain a good working relationship with the stakeholders.


Skills and Experience Required:

Solid experience with workflow technologies designing and building data pipelines, data models and data stores.
Experience working within and an understanding of Amazon AWS ecosystem, including security and performance tuning.
Hands on experience working with different types of databases, with focus on Graph and NoSQL databases.
Experience with data streaming required. Having used Kafka and related technologies is an added advantage.
Sound knowledge and experience working with batch processing, data extraction and API integration.
Hands on experience with at least one programming language: Java, Python or scripting.
Demonstrated experience working in an Agile based, fast paced, complex environment within cross-functional teams.
Experience developing systematised insights, data analytics and reporting solutions is an added advantage.
Experience with interactive visualisation of data insights is an added advantage.


Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Salary Grade 9/10, with the base salary for this role starting at 111,806 base plus superannuation

Closing Date: 6th November at 9:59am - applications will be reviewed on a rolling basis, applications may close early or extend

Please apply online, direct applications submitted via email will not be considered.

The Department of Customer Service is proud to be an EEO Employer who are fully focused on equality and believe deeply in diversity of all identities making us different and a true reflection of our NSW customers. As an inclusive workplace, we support various employee resource groups, practice flexible work and workplace adjustment.

If you do require an adjustment during the recruitment process, please notify us on your application form.",3.2,"Service NSW
3.2",Sydney,-1,501 to 1000 Employees,2012,Government,State & Regional Agencies,Government,Unknown / Non-Applicable,-1
Data Engineer - Entry / Mid Level,-1,"Work with a great team on interesting projects customers
Gain more experience in AWS, Data, DevOps cloud operations
Got a working knowledge of AWS? We will teach you the cool stuff!

Itoc is seeking an up and coming Data Engineer to join our growing Data Team in Sydney.

This is an exciting role working with databases, data lakes, data warehouses, data transformation (Python SQL) and enabling AI/ML.

You will be implementing foundational, robust and production ready data platforms to enable business data-discovery, self-service, AI/ML functions across a range of client types and industries, allowing them to do more with their data.

You'll be responsible for:

Deploying data repositories such as lakes and warehouses.
Contribute to our growing portfolio of data solutions.
Ongoing optimisation and management of data platforms.
Development of transformational logic for data pipelines
Data evangelism. We want to show our clients how to follow the best practices for data.

Desired Skills and Experience

To take up the challenge, you will have a depth of skills and experience including:

1-2+ yrs of focused data experience working with SQL and/or NoSQL solutions
A solid education in Software Engineering or equivalent industry experience.
Anything Data focused preferred.
Ability to analyse business scenarios and associated data landscape to derive potential opportunities.
Strong foundation in Python and SQL
Working knowledge of APIs
Principle knowledge of the different relational database platforms and modern data storage techniques
Knowledge of the different aspects of data environments
Collect, store, process, verify consume
Experience with version management systems (such as GIT)
Working knowledge of AWS or another cloud platform - we will teach you the cool stuff.
Great communication skills, an ability to work closely with customers, developers and engineers and the confidence to present ideas in open forums.
Relevant tertiary qualifications and/or industry certifications.
Great communication skills, an ability to work closely with clients, developers and engineers and the confidence to present ideas in open forums.

While not required, a background in consulting and professional services is highly desirable.

Itoc Description

This is an exciting and challenging career opportunity to join the growing Sydney-based Data Team of a leading cloud solution provider where you will be given support to reach your long term career goals. You will be part of a team of cloud experts and will work in an environment of continuous improvement and learning delivering innovative cloud solutions across SaaS, online business and enterprise business.

On offer is a chance to join a team with a great working environment, in an organisation that values its employees and sees the value in ensuring they are engaged. Our team are clearly passionate about what they do, that's why we won the following awards:

Customer Obsession Partner of the Year 2015: ANZ Region
Customer Obsession Leadership Partner 2015: re:Invent

As an employer of choice Itoc offers competitive remuneration, training and development programs and a great working environment. We value a healthy work life balance.

The Perks

MacBook or Dell
Continuous internal learning that will provide training and career development opportunities
Working with a collaborative, social team and leveling-up your skills faster than you will anywhere else.
Quarterly social events

Itoc

Culture and smarts are important to us. Bring your secret sauce. This is no ordinary environment, you will work along some of the Cloud’s best. All engineers at Itoc must gain at least five AWS certifications. We work hard but we have fun.

Please note you must have full working rights in Australia and be available on-shore for face to face interviews.

No recruiters please.",4.0,"Itoc
4.0",Sydney,-1,1 to 50 Employees,2013,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Date: 01-Oct-2020

Location:
Melbourne, VIC, AU

Department:Description:
Technology discounts - from Apple HP Lenovo to Windows
Flexible work arrangements - work in a way that suits you best
Salary packaging - to suit your personal and financial circumstances

Do you want to work for one of the fastest growing data teams in Australia? Do you want to work on multiple data platforms and provide new solution offerings by leveraging cloud and big data technologies?

About the team

Big data information and analytics. Three words that spark apprehension in most businesses. But our team of experts are constantly curious and excited about combining our wonderful array of technological expertise to transform data into our clients most valuable assets making their work smarter. Our data consultants are supported with resources training and tools they need to excel at their work but also the freedom and power to create their own paths forward to make a difference.

As a Senior Consultant in Big Data you will work closely with the team and stakeholders to build and deliver a Cloud based vision for a next generation Big Data analytics platform with strong focus on data quality data security and deliver the systems that process huge volumes of data.

What will you typical day look like?

You will play a pivotal role in - Designing and producing high performing and stable applications to perform complex processing of massive volumes of data in a new cloud based architecture; Building real-time data processing applications which are integrated with business systems to enable value from analytic models to drive rapid decision making; Contributing to system architecture design for a data platform (including cloud-based structures both on and off premises data warehouse components and data lakes); this could cover a range of technologies various countries/locations and lines of business; Support data strategy or technology strategy definition programs including technology stack definition and target operating model requirements

Enough about us lets talk about you:
You are someone with:
Use of traditional data analytics tools and techniques (e.g. MSSQL Oracle MySQL) and ETL software (e.g. SSIS Informatica CloverETL)
Working in large scale cloud data solutions using platforms such as AWS or Azure or GCP will be a bonus.
Experience in scripting or programming (e.g. Python Java Scala C#)
Excellent verbal and written communication skills to adapt to technical and non-technical audiences.
Educated to degree level (or have equivalent experience)
Why Deloitte?

At Deloitte we create positively differentiated work experiences that enable our people to feel valued and achieve their full potential. We value difference and embrace people with diverse backgrounds and thinking styles. Knowing that people work best in different ways we are happy to discuss alternative arrangements if the working pattern you are looking for is not specifically indicated.",3.8,"Deloitte
3.8",Melbourne,-1,10000+ Employees,1850,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Engineer,-1,"Opportunity to grow the team
Period of growth
Intuitive app
S2M are working with a FinTech who have created a unique financial product to help thousands of people better manage their finance, and is currently scaling the company to the next level!

They are looking for a Data Engineer to join, and looking for someone who wants to be hands on, with opportunity to grow the team in future.

Role:

Looking for people with strong AWS experience. You will need passion for data and a cloud, through which you will help a rapidly scaling Australian FinTech establish their data infrastructure from the ground up.
5+ years’ experience as a data engineer within the data and analytics domain
A python 3.X aficionado who is very comfortable creating and orchestrating AWS data pipelines with nothing but code
Strong project delivery toolset experience in open source data integration tools
Experience with processing large volumes of complex data including visualisation and insights generation
Ability to define and develop data integration patterns and pipelines
Ability to assess complexity of data (volume, structure, relationship etc.)
Hands on experience working with different databases (RDBMS, NoSQL, Blob storage etc)
Hands on technical expertise setting up DevOps automation
Hands on experience working technologies/platform e.g. AWS, Dockers, Containers
Experience building data profiling and data cleansing frameworks
Technical reconciliation and reporting
Knowledge and experience in end-to-end project delivery, either traditional SDLC or agile delivery methodologies (or hybrid approaches)
Exceptional communication, documentation and presentation skills
If this sounds like you, get in touch today - kate.gabb@s2m.com.au
3167410agsdf",3.1,"S2M
3.1",Sydney,-1,Unknown,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Analysts,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is seeking experienced and qualified Data Analysts to join our IT team based in our corporate office in Birtinya (Sunshine Coast) or at our meat processing facility in Kilcoy.
Key Responsibilities:
A mixture of data analysis and commercial skills to source, blend and analyse data to gain insight and answer key commercial questions
Working with strategic leaders to define and model Key Performance Indicators, and assist in building forecasting models
Working closely with data engineers and BI developers to specify data pipelines and report visualisation
Drive the creation and implementation of data quality business rule including data definition, governance and quality assurance
About You:
To succeed in this role, you’ll need to bring the following experience and skills:
Proven ability to derive insight and knowledge from data using commercial expertise is a strong requirement
Strong SQL and Excel skills are essential, along with strong data analysis and commercial insights
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Effective people communicator - engage with stakeholders on reporting needs, interpret requirements into visual solutions and train/deliver the outputs to the stakeholders getting signoff of acceptance
Bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking

How to Apply:
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kilcoy,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Network Data Engineer,-1,"Min 6+ years of experience in the relevant technologies
Australian Driving License for visiting remote locations / Data Centre for day to day technical work.
Managing Network devices (switches, routers, firewalls, load balancer, and wireless technology)
Performing MACD activities for all network devices.
Supporting BAU operation activities.
Proficient in performing in-depth details of technical troubleshooting, cause and provide recommendation to the client for incidents causing extended network outage to client’s critical locations.
Provide exceptional network services in terms of network support, break-fix, design and consulting, new projects, implementation.
Configure, administer, and document firewall infrastructure.
Manage the firewall deployment, rules migrations, and firewall administration.
Supporting Cloud Migration Activities from traditional to AWS/Azure.
Setting up VPN tunnel with Cloud and 3rd Party network devices.
Integrating and upgrading existing ISP bandwidth with support from ISP Vendor.
Setting up VPN profiles for Users.
Installing hot fix and patches to mitigate the security devices from attacks and bugs.
Reviewing and fine tuning the firewall rules and NAT rules.
Documentation and change control.
Mentoring, Motivating and Guiding support teams
Technical skills:
o LAN
o Wireless
o WAN
o MPLS
o Routing protocols (OSPF,BGP)
o DMVPN
o Azure cloud Networking
o Network Security
Fortigate Manager / Analyzer / Firewall
Cisco ASA
Firepower FTD
Cisco Any connect
Site to Site VPN
F5 Load Balancing and Scripting iRule
Job Types: Full-time, Contract
Schedule:
8 hour shift
Experience:
Scripting: 5 years (Required)
Data Network: 5 years (Required)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Required)",3.6,"Total IT Global
3.6",Sydney,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Engineer - Processing & Analysis,-1,"Job Description:
Design,build and maintain the ingestion system to support various types of data(e.g. User behavior, RDS, NoSQL db and others) to be ingested to the data warehouse more timely and accurately
Translate data requirements into scalable technical data service with low latency and high concurrency
Design,build and maintain the batch or real time data pipeline in production using Hadoop big data technology
Analyze and improve efficiency, scalability, and stability of the system
Define and manage SLA,Data quality for all data sets in allocated areas of ownership
Requirements:
Minimum B.S. degree in Computer Science or a related technical field
2+ years of working experience in programming languages,such as Java,Scala,Python
Familiar with Hadoop, Spark and Flink data processing, experience of TB data processing experience is a plus
Familiar designing and operating of a robust distributed system is a plus
Understand data mining or machine learning
Excited to work intimately with data
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"SYNOPSIS:
Lead Data Engineer
Applications close Sunday 8 November 2020
Ongoing
Contact name: Shyni Sasikala
Phone: (02) 6249 9048
Email: Shyni.Sasikala@ga.gov.au

The Data Policy and Informatics section within the Digital Science and Information branch creates, implements, and promotes policies, platforms and tools that improve and support the quality, discoverability, accessibility, and general usability of Geoscience Australia’s science data products. The section consults with internal and external research, government and industry partners to establish collaborative data frameworks, architectures and models within Geoscience Australia (GA) and across broader national and international communities of practice. The section innovates, builds and maintains tools, systems, processes and governance that enable digital data management, cataloguing and open data delivery.
GA makes accessible a wide range of geoscientific and spatial data to a wide variety of stakeholders in multiple formats, and in recent years GA's data volumes have grown exponentially. GA is focussed on making its data and metadata assets accessible so that they can be used in machine to machine interactions for data analytics and other applications in environments that range from High Performance Computing (HPC), through high-end cloud servers, to mobile devices.
We currently have two opportunities for Lead Data Engineers in the Informatics team. The Lead Data Engineer is responsible for innovating and exploring new technologies that will advance GA’s science goals and maximise the uptake and use of GA’s science data. The Lead Data Engineer reports to the team’s Assistant Director but also works closely with other developers, data scientists and engineers within the Digital Science and Innovation (DiSI) branch, as well as diverse stakeholders both within and external to GA.",3.9,"Geoscience Australia
3.9",Canberra,-1,501 to 1000 Employees,2001,Government,Federal Agencies,Government,$100 to $500 million (USD),-1
Data Engineer,-1,"The Seven Network is part of Seven West Media, one of Australia’s most prominent media companies, with a market leading presence in content across broadcast television, online and in print. Comprising some of Australia’s most renowned media brands, SWM includes not just Seven Network and its affiliate channels 7two, 7mate, 7flix and BVOD offering 7plus, but also 7NEWS.com.au, The West Australian, The Sunday Times and more.
At Seven we are here to bring all Australians closer to the moments that move us - we’re first on the scene, with our finger on the pulse, on demand, in the moment. Together, we’re responsible for creating and sustaining authentic Australian engagement.
A new and exciting opportunity has opened for a Data Engineer to join the Audience Intelligence team. Based in Sydney and reporting to the Head of Data Enablement, you’ll be responsible for:
Implementation of end to end data solutions to support Data Strategy for the SWM group.
Work closely with the Data Solution Designers to develop and maintain scalable data pipelines and build out new file and API based integrations to address requirements from the various business stakeholders.
Collaborates with engineering, analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organisation.
Work on Data Preparation for analytics and data scientist team members and assist them from an engineering perspective in building and optimising the models including building the automation of the end to end workflows
Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.
Perform data analysis required to troubleshoot data related issues and assist in the resolution of production data issues.
Work effectively with vendors for successful delivery of projects and acceptance of the solution
Work on Delivery projects using Agile Software Development methodologies
We are looking for someone who has:
Bachelor's degree in computer science, computer engineering or other technical discipline is essential
Proven experience working as a digital analytics specialist
Extensive experience with digital analytics implementation (e.g. Google Analytics, Snowplow, Adobe Analytics) and BI processes and visualisation platforms
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience in ETL and building and optimizing ‘big data’ pipelines and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Experience with big data tools: Hadoop, Spark, etc., AWS cloud services: EC2, S3, Lambda and familiar with version control systems: Git
Strong coding skills with knowledge of Unix/Linux and scripting languages such as Unix Shell scripting, Python desirable
Experience supporting and working with cross-functional teams in a fast-paced environment.
Ability to multi-task and problem solve with changing demands and priorities
Ability to work under pressure to meet deadlines and detail oriented
Your success is our success: we will provide you with opportunities for you to keep learning and growing, enabling you to challenge and develop yourself. In return, we offer a benefits program that has something in it for everyone.
Seven West Media is an equal opportunity employer and we are committed to creating a diverse and inclusive workplace.
Recruitment Agencies: Seven West Media does not accept any unsolicited agency resumes and will not be responsible for any fees related to unsolicited resumes.
Advertised: 19 Oct 2020 12:00 AM AUS Eastern Daylight Time
Applications close:

Back to search results",2.5,"Seven West Media
2.5",Sydney,-1,5001 to 10000 Employees,1956,Company - Public,TV Broadcast & Cable Networks,Media,Unknown / Non-Applicable,-1
BICON Rules Engineer,-1,"APS 5 - $73,299 - $80,410 per annum plus superannuation
Biosecurity Plant Division
Canberra, ACT
Play an active role in managing biosecurity risk to Australia
Work in a motivated and professional team with a wide range of skills and backgrounds
Full training provided

Who we are
The BICON Content Development Team maintains and improves the Biosecurity Import CONditions database (BICON) content to allow external clients to understand and comply with their biosecurity obligations and internal clients to effectively manage biosecurity risk and regulate imports. We work collaboratively with internal clients to comprehend and implement their BICON content requirements and optimise the use of BICON to publish clear import requirements and onshore management support procedures to effectively manage biosecurity risk.

The Jobs
Key duties of these positions include:

working with business content (import and permit conditions) and import programs to understand and construct decision tree structures in the BICON database, in accordance with system design and authoring conventions
executing changes to import and permit conditions in alignment with service standards while complying with system rules and authoring conventions
providing technical advice through various formats on the most appropriate means of authoring BICON content to achieve import program and stakeholder objectives
using workflow management tools to maintain detailed records of changes to import conditions and key decisions
performing administrative tasks including system reporting, data analysis and scoping tasks for the BICON content change work program
contributing to the development and maintenance of instructional material, authoring conventions and courseware
clearly documenting and reporting system issues
developing and maintaining effective working relationships with internal and external stakeholders.

What we are looking for
Knowledge and experience
Experience working with complex IT systems.
Experience working collaboratively and as part of a team.
Knowledge of the role of biosecurity is preferred but not essential.

For additional information, please read the Job Description below.
Candidate Information Package docx Opens in new window",3.9,"Department of Agriculture & Water Resources
3.9",Australia,-1,5001 to 10000 Employees,-1,Government,Federal Agencies,Government,$500 million to $1 billion (USD),-1
Cloud Data Engineer,-1,"Job no: 509605
Work type: Permanent Full Time
Location: Melbourne, Canberra, Sydney
Do you embrace digital disruption?
Do you love solving complex problems, designing sophisticated solutions and building innovative technology?
Do you believe in creating powerful actionable insights from Data and Analytics?
Do you want to work in a diverse and flexible working environment?
KPMG is one of the most trusted and respected global professional services firms. Through depth of expertise, clarity of insight and strength of purpose we help our clients solve complex challenges, steer change, strengthen, transition and grow. We are a team based practice and this extends to our clients whom we work and collaborate with, in solving complex problems. Together, we design, innovate and implement, providing enduring advice that support our clients and the services they deliver. Our clients vary in size and come from a diverse range of sectors – all sharing in a common goal: to embrace change and deliver services that make Australia a better place. We are looking for talented individuals who would like to join us on the journey.
KPMG’s Digital Delta Team
We re-imagine and re-invent organisations to become world class digital enterprises using advanced technologies, data and human insights. We help organisations to embrace Digital Strategy, Artificial Intelligence (AI) & Cognitive, the Internet of Things (IoT), Data, Analytics & Modelling, Mobile App & Web, and User Experience (UX) & User Interface (UI) and more.
We work with clients to:
Formulate strategies that re-imagine organisations
Harness innovation from the 4th industrial revolution
Actioning insights from trusted data to consistently and quickly make clear decisions
Build adaptive organisations
Thrive as a connected enterprise – front, middle and back office
This is how you’ll contribute:
We are looking for ambitious Data Engineers who are passionate about helping clients define bold ambitions and deliver on them. Joining our team will take you on a journey of personal and technical growth and provide the opportunity to inspire confidence and empower change.
As a Data Engineer you are the designer, builder and manager of the information or ""big data"" infrastructure, preparing data for analytical or operational use. You will design, construct, test and maintain a data pipeline to pull together information from different source systems; integrating, consolidating and cleansing data; and structure it for use in individual analytics applications.
The KPMG Difference
Our people are focused on creating a diverse and dynamic environment that embraces and values differences. We value the variety of unique experiences, qualities and characteristics our people possess and we share and learn from each other.
We are proud to be consistently recognised as an employer of choice for women, and for our achievements in LGBT+ workplace inclusion.
Our commitment to ‘Flexibility’ allows our people to manage the changing demands of work, personal or family life. Explore the links below to hear our people share their experience @ KPMG:
Flexibility empowers wellbeing
Flexibility enables contribution to the community
Flexibility inspires technology & innovation
Flexibility supports family

Make KPMG the clear choice for your career and be Extraordinary!

Advertised: 09 Sep 2020 AUS Eastern Standard Time
Applications close:",3.8,"KPMG
3.8",Sydney,-1,10000+ Employees,1987,Subsidiary or Business Segment,Accounting,Accounting & Legal,$2 to $5 billion (USD),-1
Computer Network and Systems Engineer,-1,"Duties Include but are not limited to:
Tasks Include:
analysing, developing, interpreting and evaluating complex system design and architecture specifications, data models and diagrams in the development, configuration and integration of computer systems
researching, analysing, evaluating and monitoring network infrastructure to ensure networks are configured to operate at optimal performance
assessing and recommending improvements to network operations and integrated hardware, software, communications and operating systems
providing specialist skills in supporting and troubleshooting network problems and emergencies
installing, configuring, testing, maintaining and administering new and upgraded networks, software database applications, servers and workstations
providing network programming in support of specific business needs and requirements
preparing and maintaining procedures and documentation for network inventory, and recording diagnosis and resolution of network faults, enhancements and modifications to networks, and maintenance instructions
monitoring network traffic, and activity, capacity and usage to ensure continued integrity and optimal network performance
Skills and Experience Required:
Must have experience working in a Managed Service environment
Demonstrated experience in IT Networks and Data Centres
Understanding of systems and architectures to meet client needs
Experience in Help Desk including break / fix
Effective and timely documentation
Effective Task Management Skills
Be solution and outcome focused and willing to learn new technologies
Excellent communication skills with staff, clients and partners
Time management, ability to prioritise and deliver to schedule
Experience with N-Able and Connectwise desired
Open Cabling license desired
Job Types: Full-time, Permanent
Salary: $30.00 per hour
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,Trans-plant training,Canberra,-1,-1,-1,-1,-1,-1,-1,-1
Software Engineer (Data),-1,"If you are looking for an opportunity to make a real impact with smart people who are genuinely doing things differently then you've come to the right place! We're growing our data engineering capabilities and are looking for awesome data engineers to join our team.
With our diverse range of clients and projects, no day will look the same - but here's a great snapshot of what you'll be doing:
Work with some of the best Data Scientists and Engineers to deliver production-grade AI and Machine Learning systems as we deliver client projects from inception to production.
Consulting with our clients and working with them to build modern data systems using the 'best of' technologies and principles.
Advising clients on data strategy, architecture and technology.
Applying best software engineering practices in coding, monitoring and alerting, using CI/CD, TDD and cloud architectures.
Working over a wide range of big data tools and environments: not limited to; Apache Kafka, Spark, Python, Scala, Hive, Airflow, AWS EMR & Glue, GCP Dataproc & Dataflow, BigQuery, Snowflake, Redshift.
Who are we?
Glad you asked! We are Eliiza. Data science. Engineered for scale.
We are a passionate team of data scientists and engineers who apply data science and machine learning to solve real-world problems. Our mission is to create a bright future for Australian businesses and society in a world increasingly influenced by intelligent technologies.
We've created a culture that values diversity where people can truly be themselves! We care a lot about growing the Australian AI community in a positive direction, and we're doing several things to try and achieve that:
We provide opportunities for underrepresented groups to work in AI through our associate and intern programmes
We organise and participate in a range of community events, reading groups and meetups
We produce the AI Australia podcast
We blog about topics we care about
We stream brown bag sessions to the broader community
We're also part of Mantel Group's 'house of brands' which means it's not just the Eliiza team you'll work with, learn from and see at social events - there's another 230 of us across DigIO, Kasna & CMD Solutions!
So you're ready for something new?
We're keen to know more about you! Our team is made up of a range of people, with different experience across a huge range of data driven skill sets.
We'd love to hear from you if you have experience with:
one (or more) core language(s), ideally Scala, Python or Java
one (or more) cloud platforms, AWS, GCP, Azure
ETL/ELT concepts and technologies e.g. Data partitioning, Hive, Spark
streaming data concepts and technologies, ideally Kafka (Kinesis, Beam or Pubsub will do)
We'd be over the moon if you:
Experience with distributed/columnar databases (e.g. Snowflake, Big query, Redshift).
Experience with any of a variety of databases e.g. RDMS, NoSql, Columar, Distributed, Time series, Graph.
Knowledge of job orchestration and scheduling. Any experience with Airflow, Luigi or Oozie.
Experience with containers and container orchestration (Docker, Docker Compose or Kubernetes).
However, we value a diversity of skill-sets, and don't necessarily require that you're skilled with all of the above. If you feel you don't fit all the experience/skills listed above we still encourage you to apply or get in touch.
What's on offer if you join us?
We make sure you're always one step ahead by investing your learning and development, every year. We build our own training where it doesn't exist yet.
We hire smart people and get out of their way. By focusing on our five principles and not getting caught up in red tape, we trust you to get the job done.
You'll get all the tools you need - a new iPhone or Google phone, a new Macbook Pro or Dell, and a lot of branded swag!
But hold on, you mentioned a house of brands?
We certainly did! Mantel Group is an Australian-owned, 'house of brands' company with four technology businesses (Eliiza being one of them!) across Melbourne and Sydney. We're building a group of companies with open borders so we can support you to take on new skills without leaving an awesome team - we understand you won't have one job for life!
We may only be just two years old but Mantel Group has already been recognised #9 in the 2020 Best Places to Work in Australia and #4 in the AFR's 2020 fastest growing new companies.
Keen to chat?
Click ""Apply"" to share your details with our talent team, and we'll be in touch.
In the meantime, check out 'how we hire' to find out what's in store if you're successful and get to know us better by visiting our website and following Eliiza on LinkedIn.",-1,Eliiza,Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Infrastructure Engineer,-1,"Job Description:
Design and grow the Shopee data platform to support a variety of big data applications using open-source technologies including Kafka, Hadoop, Presto, HBase, Spark, Hive, Druid, and our own creations. Some examples include a real-time data streaming platform, a unified query platform, a cluster management system, and a machine learning platform
Dig into the source code of some open-source big data system to get the whole control and familiar with the details, configurations, designs and source code. Develop and maintain the internal release of big data systems and components as the business requirements.
Keep close and overall monitoring for all the deployments of the systems, maintain the system’s stability, improve the performance, discover the performance bottlenecks, tracking and troubleshooting, cost optimisation.
Requirements:
B. Sci. / Ms / PhD in Computer Science or a related technical field
Familiar with at least one of these languages: Java, Scala, Python, Bash under Linux / Unix. Scala is a plus
Familiar with the use and compute logical of SQL
Knowledge about the Big Data Infrastructure system technology like Distributed File System, Distributed Computing, Distributed Database will be a plus
Hands-on experiences Hadoop, Spark, Kafka, and/or Presto will be a plus
Love to use and develop open-source technologies
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"Work on an award-winning, international technology!
Endless career opportunities
An innovative, friendly team of 300+
This role will be focused on the development of our existing ClaimLogik line of products as well as working on our new cloud-first, modern suite of applications.

Intelligent Thought, our technology business is scaling and shipping our software globally. Already profitable, part of a much larger group business, with investors such as Macquarie Capital and Envest – we are all set to deliver textbook disruption to the Insurance Industry. The growth of the platform, of our customer base, and the increasing industry demand have led to the need for this role to help the team scale.

Our Philosophy
Give each employee a sense of purpose and an environment for them to connect the importance of their role to delivering a service that matters to our customers.
Challenge the ‘why’ of traditional claims processes.
Keep it simple – do only what brings value and what matters to the customer
Enable employee decisions, empower our people
Responsibilities:
Create, extend and maintain ETL pipelines to form our data lake, data warehouse and analytics platform (currently using the Microsoft Azure set of tools and service)
Help define the optimal data pipeline architecture
Influence the tool selection, platform selection, data architecture and strategy which will transform the business to be truly data-driven
Understand, analyse and size user requirements
Work with different parts of the business to provide them with the insights they need to deliver the best results
Skills & experience:
Degree or qualification in computer science or related
Advanced knowledge of relational database, including query authoring and query optimisation (MS SQL Server and PostgreSQL).
Experience building and optimising ETL pipelines
Experience designing complex data models
Experience working with cloud platforms (Azure or AWS)
Efficient time management and organisational skills
High attention to detail and accuracy
Effective communication skills to build strong working relationships; both written and verbal
Proactive and results-driven
Why Claim Central?
Claim Central Consolidated is a global insurance industry leader across, claims management, insurance technology and data and analytics. Currently operating in the United States, Australia, South Africa, Italy and New Zealand, we have pioneered digitally connected claims management services across the globe. Claim Central is a disruptor and thought leader in the industry and we were recognised as the Australian Financial Review’s 8th Most Innovative Company in Australia in 2016. This business is in a period of unprecedented growth, transitioning our technology and services into multiple geographies at a rapid pace. Our unique culture is based on teamwork, collaboration, trust, respect and performance. We also offer many benefits apart from our exceptional team culture; including flexible work arrangements, and continued professional development.

Be a part of this journey in a career-defining role.",-1,Claim Central,Matraville,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer - AI/ML,-1,"Our client provides services to a major industry across the country. The business is still early in it's days of technology development and the environment is greenfields in nature (no pun intended), effectively working like a start-up.

Their data and analytics team have worked and built leading and bleeding-edge technologies in this space and what they have created so far may be game-changing. From a machine learning perspective, the progress they have made to the business has already seen proven success in changing the future of an industry that will have positive consequences for all those involved.

You will have previously worked in a technical capacity in the data and analytics space and have experience working with an organisation where machine learning has been implemented, not just a concept that the business talks about having or the technology team would love to have. The commercial experience you will have had in the ML field will be proven examples of where you have affected the way a business or industry used to perform, to the changes that have come about from this.

Technically, you will have extensive experience in the Microsoft space - Power BI, Azure etc and you will have previously mentored and coached junior members of the teams you have been part of.

This is a rare opportunity in Brisbane where the business has truly embraced and funded projects across the ML space and would be a great chance for those in the Data Development/Data Engineering field, who are looking to move into a Data Scientist role in the future.

Please send your application through if you would like to know more.",4.0,"Emanate Technology
4.0",Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Solution designer/ ETL Engineer & Data Modeller,-1,"We are looking for a Qualified and Experienced Solution Designer to join our client for a period of 6 months with a view to extend.
You will work closely with team members and your contribution will range across gathering and analyzing information, developing and documenting improved processes and work instructions and experienced DWH Lead with skills in requirement analysis, solution designing, developing, testing and supporting ETL solutions.
A hands-on solution designer, data modeler and ETL developer for Data Warehousing and ETL application transformation projects using Informatica PowerCenter.
Knowledge on AWS, S3, Redshift, Informatica BDM, and related technologies.
Experience working with IPython, PySparks, AuCuMo, Airflow, Jenkins, Github, Athena, JIRA, Rally, Spectrum, Glue, Flyway.
Good exposure on Oracle PL/SQL, aware of DBA activities, writing and performance tuning of complex SQL queries.
Contract length: 6 months
Job Types: Full-time, Contract
Salary: $650.00 – $800.00 per day
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,nducive,Melbourne,-1,-1,-1,-1,-1,-1,-1,-1
"Data Engineer, Wollongong NSW or Mount Waverley VIC",-1,"Company Description
BlueScope is a technically advanced supplier of steel and steel products in Australia. We are an inclusive organisation and every day we showcase our technology and expertise throughout the world.

Job Description
We are looking for two Data Engineers to join our IT team, based in Wollongong NSW or Mount Waverley VIC. Use your experience in analytics to unlock business value, enabling use of big data for insights and decision-making.
Reporting to the Data Product Owner for our Australian Steel Products (ASP) business, this position will support strategic goals related to data. This will see you:
Gather business and technical requirements with the view to deliver outcomes;
Develop and implement end-to-end data collection, consolidation, modelling and visualisation solutions;
Document metadata in a dictionary and catalogue;
Ensure consumers of such information understand its accuracy, timeliness, quality and sensitivity, so that it is used appropriately; and
Identify opportunities to enhance analytics.
What are the benefits?
Work in a supportive and collaborative team environment whilst we embark on a journey to transform the way our business uses data!
Our systems landscape is broad and diverse. You will be encouraged to think creatively to develop data solutions which solve real business problems.
Working in this role you will enjoy:
the chance to learn more about data science;
salaried remuneration with attractive superannuation options;
the opportunity to participate in a performance incentive scheme; and
access to further development and career opportunities with BlueScope.
Who are we looking for?
We welcome applications from professionals with experience in data analytics and/or programming. Supported by your knowledge of project delivery methods (e.g. Agile), you will demonstrate:
experience with data mining, wrangling, mapping and visualisation techniques (e.g. Azure Data Factory, Databricks and/or DevOps etc.);
well-developed ability in gathering business and technical requirements;
skills in developing and implementing collection, consolidation, modelling and visualisation solutions; and
a passion for sharing your knowledge and desire for ongoing professional development.

Qualifications

null

Additional Information
We're proud to have been named an Inclusive Employer for 2019–2020 by the Diversity Council of Australia. We believe that our people are our strength. Having a diverse and inclusive workplace enables us to improve our capability and ensure continued, sustainable success.
We know that workplace flexibility can mean something different to everyone. Under our B-Flex initiative all of our roles have some degree of flexibility. We encourage you to discuss your needs with us.
Applications close Sunday 25th October 2020.",3.3,"BlueScope
3.3",Wollongong,-1,201 to 500 Employees,-1,Company - Private,Construction,"Construction, Repair & Maintenance",$100 to $500 million (USD),-1
ETL Data Engineer,-1,"ETL Data Engineer

Join a team that’s changing how Australia lives, works, plays and grows
We want you to be the best version of you

Work with innovative teams and explore new technologies to help solve real-world problems.

A typical day as a Data Engineer

ETL / Big Data Engineering professionals will be responsible for guiding the full lifecycle of a Data solution, including:
Working in highly client-facing roles to contribute throughout the end-to-end delivery lifecycle of complex and large-scale digital solutions
Use case and business case development
Support existing and new applications utilizing in-depth technical and data knowledge. Troubleshooting complex issues and providing advisory services to improve the client’s data landscape
Help to streamline and simplify the clients’ complex data landscape by integrating different applications and data architectures
Implementation from requirements analysis, platform selection, digital architecture design, application design and development, testing, and deployment
Interstate travel may be required

Basic qualifications:
Bachelor’s degree
Experience across systems integration, information management, data management and architecture, and business analytics
Experience with being in a team focusing on large-scale, multi-release information centric projects
Experience with waterfall and agile delivery and run / application support functions
Part of a team working on End to end implementation of at least 1 big data project

Preferred Skills:
Hand on experience in Data warehousing using ETL tools such as DataStage, Autosys and TeraData
Hands on experience in ETL job development with multiple stages like sequential file, Transformer, Lookup, join, sort and Database stages.
Strong hand on skills in design, development and implementation of various data remediation, Data migration, data integration techniques.
Strong hand on data modelling experience.
Strong hands on experience in database performance tuning including complex query optimizations and physical database tuning using Teradata.
Understanding of architectural designs and strategy related to data migration, data cleansing, data quality and data consolidation.
Proven data analysis, requirement gathering and problem-solving skills
Exposure to Unix environment and shell scripting.
Experience in Banking and Financial services industry
Desirable: Knowledge of cloud computing infrastructure (e.g. Amazon Web Services EC2, Google Cloud, Microsoft Azure)
About Accenture

Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. We combine unmatched experience and specialized capabilities across more than 40 industries — powered by the world’s largest network of Advanced Technology and Intelligent Operations centers. With 513,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises. Visit us at www.accenture.com.

Accenture is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, marital, domestic or civil partnership status, sexual orientation, gender identity, or any other basis as protected by applicable law.

Vera Goga is the Recruiter managing this role. As the team experience high volumes of applications, we appreciate your patience to allow for a fair and timely process.",3.9,"Accenture
3.9",Sydney,-1,10000+ Employees,1989,Company - Public,Consulting,Business Services,$10+ billion (USD),-1
Student Engineer,-1,"The candidate will have the ability to:
Undertake onsite inspection to collect asset condition data based on the relevant engineering standards and technical guidelines;
Undertake desktop analysis to evaluate the condition and performance of the assets;
Provide the appropriate information, advice, engineering input and support services for the sustainable management of Council’s stormwater and transport networks.
Qualifications:
The successful candidate will be enrolled in a Bachelor of Engineering with a minimum of two years completed.
Position Number: 100678
Position Hours: Fixed term (3 months), hours will be negotiated with the successful candidate, maximum of 75 hours per fortnight.
Salary: Schedule A, Salary Point 4.0. $28.64 per hour ($55,853.45 per annum, pro-rata) in accordance with Glenorchy City Council’s Enterprise Agreement 2016
Please note that all successful applicants will be required to provide a current National Police Check prior to commencement of employment.
For further information on this position, contact Patrick Marshall, Senior Civil Engineer on (03) 6216 6800.
How to apply: Applications for this position must be lodged on this submission site or on the Glenorchy City Council website www.gcc.tas.gov.au - Careers page.
To be considered for this role, all applicants must address the key selection criteria in the and provide a current resume. A copy of the position description can be found by clicking the below hyperlink or on the Glenorchy City Council website.
Applications close at 8pm on Sunday, 1st November 2020
- Student Engineer",4.0,"Glenorchy City Council
4.0",Glenorchy,-1,501 to 1000 Employees,-1,Government,-1,-1,Less than $1 million (USD),-1
Data Engineer involving DevOps,-1,"Data Engineer involving DevOps
Axiom Technologies is an Australia based entity with the history of providing Managed IT solutions to medium to large scale enterprises globally. Please visit our website for more information about what we do at www.axiomtechnologies.com
Axiom Technologies is an Equal Opportunity Employer and encourage applicants from all backgrounds and gender to apply, including, Aboriginal and Torres Strait Islander candidates
Job Requirements:
8+ years IT experience, with at least 5+ years of “Data Engineer/Deveoper” focused titles/roles,
Data Tools: Hands on experience with Apache Beam.
Testing: Hands on experience with automated testing activities/outcomes
DevOps: Experience with the processes involving Microservices facilities for artifacts developed
Platform/OS: Mid-range/Unix
Languages: Unix (Shell) Scripting/commands, SQL, Python
File formats: Text, CSV, Parquet, JSON, XML
Scheduling: Jenkins, Airflow
Auto Scripting: Designing/creation of scripts for repetitive activity. E.g. Unix scripting/SQL
Big data: Exposure to Data Lake Concepts, Hive (Schema), HDFS
Source Control tools: GIT
Delivery Models: Agile, Scrum
Ingestion Design: Create/assess Source/Target data mapping designs
Frameworks: Development and delivery frameworks
Activity Reporting/Repository: Jira, Confluence.
Quality: Accuracy and attention to detail
Industry: Financial Services/Banking
Solutions: Define solutions from High level to detail design to address automating ingestion activity. Facilitate/confirm requirements from product owners, business team members and technical associates,
Process Automation: Automating processes in file management, testing data in files, analysis and design, configuration management.
Script Automation: Ability to design/create scripts to automate/improve data copy/migration/ETL for any repetitive activity.
Languages: Java, Python
Scheduling: Control-M
Databases: Relational. E.g. POSTGRESS, Oracle – as a ETL developer
File Formats: Mainframe – experience with referencing its data formats/copybooks
Big data: Experience referencing/using Hive (Schema) to access data in HDFS
Metadata management tools: MDM, EDC and Axon
Performance: Assess, recommend, improve mappings, SQL queries, Batch feeds
Automation Tools: Other tools that may add value to an automation program and generally support development. E.g. API, REST, JDBC, Webservices, Message Queues/Load balancer,
Cloud: Experience with processing of data files to be ingested/stored in the Cloud, preferably with AWS.
Prod Support: Experience in a production support role performing root cause / impact analysis – under time constraints
Experience in a similar role
8+ Years
What next?
If you are looking for that next challenge in your career and wish to apply for this role, please forward your resume to careers.au@axiomtechnologies.com",2.0,"Axiom Technologies
2.0",Melbourne,-1,1 to 50 Employees,-1,Company - Private,Industrial Manufacturing,Manufacturing,Less than $1 million (USD),-1
Data Engineer,-1,"About the Role
We are on an exciting digital journey so it’s a great time to join ME! We are seeking a Junior Data Engineer who enjoys rolling up their sleeves, learning and growing. As part of our Enterprise Data Team, you will ensure fit for purpose data warehouse solutions are built for use across the bank and by utilising best practise ETL standards, whilst ensuring the data is trusted by our BI developers and key business consumers. Oh, and you’ll get to work on Microsoft technology stack too!
You will be involved with investigating data issues, keeping data feeds flowing and collaborating with different projects across the bank to deliver quality data solutions. How important does that sound? What’s even more important is this role contributes directly to our overall business strategy through the provision of data to enable analytics & reporting, as well as supporting business and decision system processes.

About You
You’re naturally a highly motivated and energetic person who thrives in a dynamic, ever-changing collaborative team environment. Ideally you have previous experience as an ETL developer, Data Engineer or a BI developer, and if you have a degree in computer science or similar it would really put you ahead of the rest.

With your knowledge of SQL coding, data modelling, understanding of data warehouse concepts, plus experience of working on complex ETL solutions, you’re ready to expand your horizons and launch your career into the world of IT at ME.

About ME
We’re not like other banks.
ME was created by the industry super funds to be different from the pack – with a core purpose to help all Australians get ahead financially – no conditions, asterisks or exceptions. And we know that looking after customers starts with taking care of our people.
We believe everyone deserves the same opportunities in life, regardless of gender or identity, sexuality, ethnicity, religion or disability ‒ with internal affinity groups.
Perk ME up
Once you get your feet in the door at ME, we’ll put them both in your very own ME-branded Converse shoes. You’ll also get the following financial, health and fun perks when you join the team:
4U Extras portal (discounts and cashback on 100s of items including cinemas, shopping and gym memberships
10% Myki discount
Purchased Leave programme
Internal wellness programme (Mindfully ME)
Professional education through LinkedIn Learning
Novated Leasing
Professional membership reimbursements
Health checks
Financial education (To help you manage your money smarter)
LGBTIQ+ and Women at ME affinity groups

I want those Converse shoes (and the role)
Can’t see a closing date on the advert? That’s because we’re pretty efficient here at ME and we may start looking at applications sooner rather than later, so if this role sounds like your jam, be sure to apply by submitting your resume today.

Should an applicant be the preferred candidate, background checks (including police checks, reference checks, ASIC banned and disqualified persons and bankruptcy checks) will be completed prior to the candidate's employment being confirmed. The outcomes of the background checks do not automatically bar candidates; however will be assessed against the inherent requirements of the job.
Back Share
Apply Now",3.0,"ME Bank
3.0",Melbourne,-1,501 to 1000 Employees,-1,Company - Private,Banks & Credit Unions,Finance,$100 to $500 million (USD),-1
Software Engineer - Machine Learning/Data Science,-1,"Zendesk is looking for a Software Engineer - Machine Learning/Data Science for a full time position in our Melbourne office.
As part of our engineering team, you will work at a scale where the challenges start to get seriously interesting. Our global engineering team is widely dispersed over the world, with people across nearly every continent. You will get a chance to do cool things with a diverse bunch of people while working in the Melbourne office that is home to Zendesk’s first machine learning (ML) research team.
The Data Science Team, together with Data Engineering, have built Satisfaction Prediction, Answer Bot and Content Cues — products that use Machine Learning (ML) and Artificial Intelligence (AI) to help our customers work more efficiently.
What you get to do every day:
We’re currently looking for someone to join our team as we research, develop, and productionise Machine Learning and Deep Learning models. In addition to frequenting Melbourne’s finest purveyors of coffee, ramen, and bulgogi, you may find yourself:
Building machine learning models including neural networks in TensorFlow
Writing and deploying production-grade Python
Querying and constructing datasets in AWS Athena, Spark
Evaluating and responding to real-world model performance
Scaling your ML to millions of predictions per day
Presenting your work to a broader audience
Watching your algorithm help Zendesk’s end-users
What you'll bring to the role:
A strong foundation in a quantitative discipline (e.g. machine learning, statistics, bio/eco/etc-informatics, econometrics, etc) is critical for this position. While experience in deep learning and natural language processing would be beneficial, your best qualities are:
dedication to continuous learning
collaborative work attitude
strong communication skills
You should also be comfortable with at least one programming language, such as Python, R or Scala.
Application Deadline: 18/11/2020
Job Types: Full-time, Permanent
Salary: $85,000.00 – $110,000.00 per year
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Temporarily due to COVID-19",4.5,"Zendesk
4.5",Melbourne,-1,1001 to 5000 Employees,2007,Company - Public,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),-1
Software Engineer (Machine Learning),-1,"About the Role
AdelaideMRI is building a medical reporting tool. We require an engineer to work primarily on machine learning projects to improve reporting speed and report comprehensiveness.
You will perform data analysis of medical report datasets and image datasets to infer sentence recommendations, image classifications, or other actionable results for the doctors.
Skills and Experience
Background in machine learning or image processing
Qualifications in Computer Science, Software Development or Engineering or equivalent experience
Bonus points for Python
No prior medical knowledge is required.
This position offers flexible hours and work arrangements.
Job Type: Full-time
Experience:
Software Engineering: 1 year (Preferred)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Yes",-1,Adelaide MRI,Australia,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Hey there, we’re PEXA!

We started as an idea: to deliver a single, national e-Conveyancing solution. We collaborated with the industry to create a national electronic lodgement and settlement platform: PEXA. From our humble beginnings, we’ve now grown to more than 320 employees across 5 different states. We’re still expanding at a rapid rate and constantly challenging ourselves to create great experiences for our members as they transition to fully digital conveyancing.

Why become a PEXArian?

Great question! Being a PEXArian is so much more than just a job. We are passionate, motivated & unashamedly enthusiastic at PEXA - we love what we do and we’re proud to admit it! Creating brilliant member experiences wouldn’t be possible if we didn’t also strive to create an amazing employee experience. Alongside our members, our employees are at the heart of everything we do.
Here’s a snapshot of what your life at PEXA could look like:

Your growth:
We encourage you to hit your personal and professional Learning & Development goals with our tailored programs and tools.

Your wellness:
We care about your holistic well being - a fully stocked kitchen, four wellness days, a $250 wellness subsidy as well as lunch and learn sessions to support your financial well being.

Your work/life blend:
We know that work is just one aspect of your life, we want to help you create your ideal work/life blend, rather than squeezing in life around work.

Your family:
With a range of benefits aimed at supporting your family including access to a subsidised school holiday program, extended parental leave and flexi-time to support your return to work, superannuation payments for unpaid parental leave for primary carers and a childcare allowance for pre-primary aged children, when we say, ‘welcome to the family’, we really mean it!
The impact you'd drive:
The successful candidate will be responsible for developing, and maintaining infrastructure to support the delivery of new and existing products. They will also be contributing to establish the rules and frameworks for obtaining the required approvals for new products.
On day one we’d love you to have:
Experience with Python, Spark
Event streaming/sourcing with Kafka or AWS Kinesis
Experience with data structures, formats and data security best practices
AWS experience (e.g CloudFormation, S3, ECS, Lambda, SQS, IAM, KMS, DynamoDB, Glue, Athena)
Query construction and optimisation (e.g. SQL, Elasticsearch, Splunk, DynamoDB)
Git, version control practices, and continuous integration/delivery servers
PyUnit and unit testing frameworks
Production release cycles and maintenance
Collaborating with technical and non-technical teams
Even better:
Agile methodology/delivery
GraphQL
Modern frontend technology (e.g. ReactJS, TypeScript)
Machine learning frameworks and tools (e.g. TensorFlow, PyTorch)
OAuth 2, SAML 2, JWT
Data visualisation and exploration tools (e.g. Jupyter notebooks, Tableau)
AWS SageMaker
Sounds like you?
If this role sounds like you, apply today to have your application reviewed ASAP!",3.9,"Property Exchange Australia Limited
3.9",Melbourne,-1,201 to 500 Employees,2010,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Ongoing position
Full time
Based in Sydney, NSW
Who we are
Australian Red Cross is part of the world’s largest humanitarian organisation. Our aim is to improve the lives of the most vulnerable people in Australia and across our region.
About the role
The Data Engineer role will sit within the Data and Integration Squad in IT and will own (design, implement and support) the AWS Big Data technologies such as the Data Lake and Data Warehouse and support the organisation in growing the data analytics capabilities at Red Cross. In addition to this, the data engineer role will also administer the Power BI tool and support the implementation of the data mastering capability.
What you will bring
Experience building and optimizing data pipelines, architectures and data sets.
Experience in dimensional modelling and building data vaults
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with structured, semi-structured and unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Why work for us?
Work for purpose and know that your work assists Red Cross support and empower people and communities in times of vulnerability.
Generous salary packaging options available that can increase your take home pay.
Further information
To find out more about this opportunity please see the position description below or contact Sharath Kumar Gurram on 02 8651 8839.
Position Description: Position Description - Data Engineer .pdf
Applications for this position will close at 11:55pm Thursday, 5 November 2020.",4.1,"Australian Red Cross
4.1",New South Wales,-1,1001 to 5000 Employees,-1,Nonprofit Organization,Industrial Manufacturing,Manufacturing,$500 million to $1 billion (USD),-1
Junior Fullstack Data Engineer (Python and React),-1,"Formbay is the leading Renewable Energy Certificate Trading company in Sydney. We provide Digital Workflow and Compliance solutions in the renewable energy industry and document processing.
Thanks to our meteoric growth and our commitment to be the best at all we do, we've identified the need to bring on board a new Junior Fullstack Data Engineer.
Reporting to our Principal Machine Learning Engineer, you will help build Machine Learning pipelines for our existing Digital Workflow and Compliance solutions to automate fraud detection and document processing over terabytes of photographic and documentary data – including documents, photos, GPS data and aerial/satellite photography.
Our stack is based on Python, JavaScript, Dask, Tensorflow, CUDA, Nix/NixOS, AWS, Docker, PostgreSQL and more – familiarity with these applications will give you a leg-up on the competition.
Our ideal candidate will have the following competencies:
SQL
Python
JavaScript/TypeScript
Our candidate must also be comfortable working with Linux.
Located a stone's throw away from the Queen Victoria Building in Sydney's bustling CBD, we are centrally-located with easy access to public transportation, bars, cafes and fine dining.
Formbay will provide flexible working hours, a generous remuneration package and the opportunity to work on a world-first software solution are what we can offer you. Free, twice-weekly gym sessions and really, really good coffee are also available.
No hiring/recruitment agencies need apply.",5.0,"Formbay
5.0",Sydney,-1,1 to 50 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is an experienced and qualified Data Engineer to join our IT team based in Birtinya.
Key Responsibilities:
Create and maintain data pipelines and or ETL scripts
Create and maintain data integration including API and Batch interfaces
Performed detailed data analysis
Create and maintain corporate data models
Create and maintain data visualization using Qlik.Sense , PowerBI or Simliar Toolset
Experience in defining, building and maintaining data virtualization and/or star schema data warehouses
Maintain, tune and optimise database, integration and visualisation toolsets
ABOUT YOU:
To succeed in this role, you’ll need to bring the following experience and skills:
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Excellent communication skills both oral and written, with an ability to bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking
Experience with data analysis and modelling will be beneficial

How to Apply
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kawana Waters,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Graduate Data Science / Engineer,-1,"The NRMA is an organisation looking to the future, and right now, we are on the lookout for people who can help us reach our goal: to continue to shape the way Australians move, for the next 100 years and beyond. www.mynrma.com.au.
Everyone new to the team, along with our current staff, will temporarily work from home until it is safe to return to our offices. All interviewing and on boarding will be done virtually due to COVID-19.


Your opportunity
As Graduate Data Scientist or Engineer you will be part of the Data Engineering team delivering cloud data transition program for business initiatives and supporting the entire data platform build.
Your key responsibilities will be to:
Implementing Concepts of Data Warehousing, Data Mart creations within Cloud
Use of SQL for data analysis and insights
Building AI/Machine Learning prototype for implementing and supporting existing algorithms
Data Analytical reports build, using different tool sets


Requirements for Success:
Relevant Degree - Computer Science, Computer Engineering, Software Engineering, Data Science
Excellent SQL skills and demonstrated working knowledge in Python
Demonstrated understanding in data structure and algorithms.
Knowledge and concept of data warehousing methodologies
Any reporting tools experience Tableau or Oracle Analytics Cloud, Looker is desirable
Exposure to Google/AWS/Azure/Oracle any cloud based platforms is desirable
Good communication and interpersonal skills

If you have the required skills and the passion to join our high performing team, please apply today.

Employee Benefits
To ensure our employees feel valued, empowered and celebrated we provide a range of employee benefits including:
50% discount on all NRMA insurances
Free Roadside Assistance
12 weeks paid primary and 4 weeks paid secondary parental leave
Free NRMA Blue Membership
At the NRMA Group, we are People Moving People and diversity and inclusion are part of our DNA. Together, we continue to build an inclusive culture that encourages, supports and celebrates the diverse voices of our employees. It fuels our innovation, promotes flexible ways of working and connects us closer to our members and the communities we serve.",2.5,"NRMA Motoring & Services
2.5",Sydney,-1,501 to 1000 Employees,-1,Nonprofit Organization,Casual Restaurants,"Restaurants, Bars & Food Services",$500 million to $1 billion (USD),-1
Data Centre Engineer,-1,"We are a leading world group that provides low-carbon energy and services. To tackle the climate emergency facing us all, our aim is to become the world leader in the zero-carbon energy transition ""as a service"" for our clients – particular for companies and regional authorities. We use our expertise in our key business areas (renewables, gas, services) to provide competitive and bespoke solutions.
The Data Centre Engineer will be employed as part of a 24/7 ongoing shift to coordinate and monitor third party service providers, maintain the data centre facilities and infrastructure plans, coordinate the implementation of customer requests within the data centre and monitor systems, all in accordance with the Contract KPIs and SLAs.
Coordinate and monitor third party service providers for regular maintenance & testing, service faults & call outs, ensuring works are performed in accordance with Contract SLAs
Monitor and maintain the data centre facilities and infrastructure plans and documentation, including electrical, mechanical, hydraulics, fire and BMS/EMS systems
Coordinate the implementation of internal and external customer requests within the data centre
Perform scheduled plant checks and minor maintenance works
Ensure all Work Order requests are raised and closed in a timely manner
Conduct inductions for staff, vendors and contractors
Ensure all work permits for vendor works are raised and closed
Perform inventory checks on all equipment and critical spares

Qualifications
The selected candidate must be able to demonstrate:
Electrical or HVAC background, or Graduate Electrical or Mechanical Engineer
Passionate about quality work and career minded looking for a new challenge
Can commit to a day and night shift roster (2 days of day shift, then 2 days of night shift, 4 days off)
Ideally able to commence asap
As part of carrying out the duties of this role, it is mandatory to hold Australian Citizenship.

If you are interested and meet the selection criteria apply with an up-to-date resume via the apply instructions on this website.

ENGIE Services is an EEO employer, where all applicants are treated with fairness and respect and have equal access to the opportunities available.

We will not be engaging in the services of a recruitment agency to fill this vacancy and therefore request all interested candidates apply directly to this advertisement.

Job
: Maintenance
Primary Location
: Oceania-Australia-New South Wales-Erskine Park
Organization
: ENGIE Services Australia and New Zealand
Schedule
: Full-time
Nature of Responsibility
: Senior operational / administrative role
Job Posting
: Sep 11, 2020, 6:29:59 AM",3.7,"ENGIE Services Australia & New Zealand
3.7",Sydney,-1,5001 to 10000 Employees,1995,Company - Public,Energy,"Oil, Gas, Energy & Utilities",$2 to $5 billion (USD),-1
Senior Data Engineer,-1,"Senior Data Engineer, Temporary, SYDNEY - McKell

Job Title: Senior Data Engineer

Salary: SNSW Grade 9/10 - The package includes base salary range of $111,806 to $134,667, plus employer's contribution to superannuation and annual leave loading.

Location: Head Office – Haymarket

Employment Status: Temporary through till 30th June 2021


About Service NSW:

Service NSW is making it easier for people and businesses across NSW to access government services. The role designs, builds and analyses complex data from multiple sources to identify revenue, process and business improvement opportunities; providing new information and insights to the business to inform planning, continuous improvement and performance.

About the Role

We are currently seeking to appoint a Senior Data Engineer to deliver expert advice and services in the design of a Single View of Customer and data-related services to support the achievement of business outcomes and strategic goals. We support flexible working practices with staff working remotely during this time.

In this role you will:

Design, build and support a modern data platform based in AWS and vendor technologies.
Provide expertise on data modelling for Graph data model and Customer Data Platform (CDP).
Create data pipelines, load, transformation and reporting workloads in AWS.
Work with the latest data engineering technologies like Apache Kafka, AWS Kinesis, AWS Neptune, AWS Glue and AWS Athena.
Contribute to the design and decision-making of the right tool or platform for the job according to requirements.
Provide expert advice and guidance on data quality and data engineering best practices.
Support a “bigger than you can imagine” scale of data in production environments.
Design, develop and support a metrics-driven reporting solution and a meaningful business intelligence platform.
Document the solution design and support procedures of solutions.
Produce reports, visualisations and recommendations to answer complex business problems that are presented in the most appropriate format to ensure clarity for target audience.
Analyse and define new process improvement opportunities to support continuous improvement and business outcomes; providing advice to stakeholders, on ways to improve the efficiency and reliability of data products and services.
Be very responsive to the information needs of the business by corresponding to customers in a timely manner and provide support/solutions to issues raised.
Troubleshoot and perform root cause analysis on production issues. Identify and implement long term solutions to problems. Perform scheduled maintenance, release deployment and production support activities after business hours, from time to time.
Liaise with internal and external customers to discuss and gather requirements, solutions etc. and maintain a good working relationship with the stakeholders.


Skills and Experience Required:

Solid experience with workflow technologies designing and building data pipelines, data models and data stores.
Experience working within and an understanding of Amazon AWS ecosystem, including security and performance tuning.
Hands on experience working with different types of databases, with focus on Graph and NoSQL databases.
Experience with data streaming required. Having used Kafka and related technologies is an added advantage.
Sound knowledge and experience working with batch processing, data extraction and API integration.
Hands on experience with at least one programming language: Java, Python or scripting.
Demonstrated experience working in an Agile based, fast paced, complex environment within cross-functional teams.
Experience developing systematised insights, data analytics and reporting solutions is an added advantage.
Experience with interactive visualisation of data insights is an added advantage.


Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Salary Grade 9/10, with the base salary for this role starting at 111,806 base plus superannuation

Closing Date: 6th November at 9:59am - applications will be reviewed on a rolling basis, applications may close early or extend

Please apply online, direct applications submitted via email will not be considered.

The Department of Customer Service is proud to be an EEO Employer who are fully focused on equality and believe deeply in diversity of all identities making us different and a true reflection of our NSW customers. As an inclusive workplace, we support various employee resource groups, practice flexible work and workplace adjustment.

If you do require an adjustment during the recruitment process, please notify us on your application form.",3.2,"Service NSW
3.2",Sydney,-1,501 to 1000 Employees,2012,Government,State & Regional Agencies,Government,Unknown / Non-Applicable,-1
Data Engineer - Entry / Mid Level,-1,"Work with a great team on interesting projects customers
Gain more experience in AWS, Data, DevOps cloud operations
Got a working knowledge of AWS? We will teach you the cool stuff!

Itoc is seeking an up and coming Data Engineer to join our growing Data Team in Sydney.

This is an exciting role working with databases, data lakes, data warehouses, data transformation (Python SQL) and enabling AI/ML.

You will be implementing foundational, robust and production ready data platforms to enable business data-discovery, self-service, AI/ML functions across a range of client types and industries, allowing them to do more with their data.

You'll be responsible for:

Deploying data repositories such as lakes and warehouses.
Contribute to our growing portfolio of data solutions.
Ongoing optimisation and management of data platforms.
Development of transformational logic for data pipelines
Data evangelism. We want to show our clients how to follow the best practices for data.

Desired Skills and Experience

To take up the challenge, you will have a depth of skills and experience including:

1-2+ yrs of focused data experience working with SQL and/or NoSQL solutions
A solid education in Software Engineering or equivalent industry experience.
Anything Data focused preferred.
Ability to analyse business scenarios and associated data landscape to derive potential opportunities.
Strong foundation in Python and SQL
Working knowledge of APIs
Principle knowledge of the different relational database platforms and modern data storage techniques
Knowledge of the different aspects of data environments
Collect, store, process, verify consume
Experience with version management systems (such as GIT)
Working knowledge of AWS or another cloud platform - we will teach you the cool stuff.
Great communication skills, an ability to work closely with customers, developers and engineers and the confidence to present ideas in open forums.
Relevant tertiary qualifications and/or industry certifications.
Great communication skills, an ability to work closely with clients, developers and engineers and the confidence to present ideas in open forums.

While not required, a background in consulting and professional services is highly desirable.

Itoc Description

This is an exciting and challenging career opportunity to join the growing Sydney-based Data Team of a leading cloud solution provider where you will be given support to reach your long term career goals. You will be part of a team of cloud experts and will work in an environment of continuous improvement and learning delivering innovative cloud solutions across SaaS, online business and enterprise business.

On offer is a chance to join a team with a great working environment, in an organisation that values its employees and sees the value in ensuring they are engaged. Our team are clearly passionate about what they do, that's why we won the following awards:

Customer Obsession Partner of the Year 2015: ANZ Region
Customer Obsession Leadership Partner 2015: re:Invent

As an employer of choice Itoc offers competitive remuneration, training and development programs and a great working environment. We value a healthy work life balance.

The Perks

MacBook or Dell
Continuous internal learning that will provide training and career development opportunities
Working with a collaborative, social team and leveling-up your skills faster than you will anywhere else.
Quarterly social events

Itoc

Culture and smarts are important to us. Bring your secret sauce. This is no ordinary environment, you will work along some of the Cloud’s best. All engineers at Itoc must gain at least five AWS certifications. We work hard but we have fun.

Please note you must have full working rights in Australia and be available on-shore for face to face interviews.

No recruiters please.",4.0,"Itoc
4.0",Sydney,-1,1 to 50 Employees,2013,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Date: 01-Oct-2020

Location:
Melbourne, VIC, AU

Department:Description:
Technology discounts - from Apple HP Lenovo to Windows
Flexible work arrangements - work in a way that suits you best
Salary packaging - to suit your personal and financial circumstances

Do you want to work for one of the fastest growing data teams in Australia? Do you want to work on multiple data platforms and provide new solution offerings by leveraging cloud and big data technologies?

About the team

Big data information and analytics. Three words that spark apprehension in most businesses. But our team of experts are constantly curious and excited about combining our wonderful array of technological expertise to transform data into our clients most valuable assets making their work smarter. Our data consultants are supported with resources training and tools they need to excel at their work but also the freedom and power to create their own paths forward to make a difference.

As a Senior Consultant in Big Data you will work closely with the team and stakeholders to build and deliver a Cloud based vision for a next generation Big Data analytics platform with strong focus on data quality data security and deliver the systems that process huge volumes of data.

What will you typical day look like?

You will play a pivotal role in - Designing and producing high performing and stable applications to perform complex processing of massive volumes of data in a new cloud based architecture; Building real-time data processing applications which are integrated with business systems to enable value from analytic models to drive rapid decision making; Contributing to system architecture design for a data platform (including cloud-based structures both on and off premises data warehouse components and data lakes); this could cover a range of technologies various countries/locations and lines of business; Support data strategy or technology strategy definition programs including technology stack definition and target operating model requirements

Enough about us lets talk about you:
You are someone with:
Use of traditional data analytics tools and techniques (e.g. MSSQL Oracle MySQL) and ETL software (e.g. SSIS Informatica CloverETL)
Working in large scale cloud data solutions using platforms such as AWS or Azure or GCP will be a bonus.
Experience in scripting or programming (e.g. Python Java Scala C#)
Excellent verbal and written communication skills to adapt to technical and non-technical audiences.
Educated to degree level (or have equivalent experience)
Why Deloitte?

At Deloitte we create positively differentiated work experiences that enable our people to feel valued and achieve their full potential. We value difference and embrace people with diverse backgrounds and thinking styles. Knowing that people work best in different ways we are happy to discuss alternative arrangements if the working pattern you are looking for is not specifically indicated.",3.8,"Deloitte
3.8",Melbourne,-1,10000+ Employees,1850,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Engineer,-1,"Opportunity to grow the team
Period of growth
Intuitive app
S2M are working with a FinTech who have created a unique financial product to help thousands of people better manage their finance, and is currently scaling the company to the next level!

They are looking for a Data Engineer to join, and looking for someone who wants to be hands on, with opportunity to grow the team in future.

Role:

Looking for people with strong AWS experience. You will need passion for data and a cloud, through which you will help a rapidly scaling Australian FinTech establish their data infrastructure from the ground up.
5+ years’ experience as a data engineer within the data and analytics domain
A python 3.X aficionado who is very comfortable creating and orchestrating AWS data pipelines with nothing but code
Strong project delivery toolset experience in open source data integration tools
Experience with processing large volumes of complex data including visualisation and insights generation
Ability to define and develop data integration patterns and pipelines
Ability to assess complexity of data (volume, structure, relationship etc.)
Hands on experience working with different databases (RDBMS, NoSQL, Blob storage etc)
Hands on technical expertise setting up DevOps automation
Hands on experience working technologies/platform e.g. AWS, Dockers, Containers
Experience building data profiling and data cleansing frameworks
Technical reconciliation and reporting
Knowledge and experience in end-to-end project delivery, either traditional SDLC or agile delivery methodologies (or hybrid approaches)
Exceptional communication, documentation and presentation skills
If this sounds like you, get in touch today - kate.gabb@s2m.com.au
3167410agsdf",3.1,"S2M
3.1",Sydney,-1,Unknown,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Analysts,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is seeking experienced and qualified Data Analysts to join our IT team based in our corporate office in Birtinya (Sunshine Coast) or at our meat processing facility in Kilcoy.
Key Responsibilities:
A mixture of data analysis and commercial skills to source, blend and analyse data to gain insight and answer key commercial questions
Working with strategic leaders to define and model Key Performance Indicators, and assist in building forecasting models
Working closely with data engineers and BI developers to specify data pipelines and report visualisation
Drive the creation and implementation of data quality business rule including data definition, governance and quality assurance
About You:
To succeed in this role, you’ll need to bring the following experience and skills:
Proven ability to derive insight and knowledge from data using commercial expertise is a strong requirement
Strong SQL and Excel skills are essential, along with strong data analysis and commercial insights
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Effective people communicator - engage with stakeholders on reporting needs, interpret requirements into visual solutions and train/deliver the outputs to the stakeholders getting signoff of acceptance
Bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking

How to Apply:
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kilcoy,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Network Data Engineer,-1,"Min 6+ years of experience in the relevant technologies
Australian Driving License for visiting remote locations / Data Centre for day to day technical work.
Managing Network devices (switches, routers, firewalls, load balancer, and wireless technology)
Performing MACD activities for all network devices.
Supporting BAU operation activities.
Proficient in performing in-depth details of technical troubleshooting, cause and provide recommendation to the client for incidents causing extended network outage to client’s critical locations.
Provide exceptional network services in terms of network support, break-fix, design and consulting, new projects, implementation.
Configure, administer, and document firewall infrastructure.
Manage the firewall deployment, rules migrations, and firewall administration.
Supporting Cloud Migration Activities from traditional to AWS/Azure.
Setting up VPN tunnel with Cloud and 3rd Party network devices.
Integrating and upgrading existing ISP bandwidth with support from ISP Vendor.
Setting up VPN profiles for Users.
Installing hot fix and patches to mitigate the security devices from attacks and bugs.
Reviewing and fine tuning the firewall rules and NAT rules.
Documentation and change control.
Mentoring, Motivating and Guiding support teams
Technical skills:
o LAN
o Wireless
o WAN
o MPLS
o Routing protocols (OSPF,BGP)
o DMVPN
o Azure cloud Networking
o Network Security
Fortigate Manager / Analyzer / Firewall
Cisco ASA
Firepower FTD
Cisco Any connect
Site to Site VPN
F5 Load Balancing and Scripting iRule
Job Types: Full-time, Contract
Schedule:
8 hour shift
Experience:
Scripting: 5 years (Required)
Data Network: 5 years (Required)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Required)",3.6,"Total IT Global
3.6",Sydney,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Engineer - Processing & Analysis,-1,"Job Description:
Design,build and maintain the ingestion system to support various types of data(e.g. User behavior, RDS, NoSQL db and others) to be ingested to the data warehouse more timely and accurately
Translate data requirements into scalable technical data service with low latency and high concurrency
Design,build and maintain the batch or real time data pipeline in production using Hadoop big data technology
Analyze and improve efficiency, scalability, and stability of the system
Define and manage SLA,Data quality for all data sets in allocated areas of ownership
Requirements:
Minimum B.S. degree in Computer Science or a related technical field
2+ years of working experience in programming languages,such as Java,Scala,Python
Familiar with Hadoop, Spark and Flink data processing, experience of TB data processing experience is a plus
Familiar designing and operating of a robust distributed system is a plus
Understand data mining or machine learning
Excited to work intimately with data
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"SYNOPSIS:
Lead Data Engineer
Applications close Sunday 8 November 2020
Ongoing
Contact name: Shyni Sasikala
Phone: (02) 6249 9048
Email: Shyni.Sasikala@ga.gov.au

The Data Policy and Informatics section within the Digital Science and Information branch creates, implements, and promotes policies, platforms and tools that improve and support the quality, discoverability, accessibility, and general usability of Geoscience Australia’s science data products. The section consults with internal and external research, government and industry partners to establish collaborative data frameworks, architectures and models within Geoscience Australia (GA) and across broader national and international communities of practice. The section innovates, builds and maintains tools, systems, processes and governance that enable digital data management, cataloguing and open data delivery.
GA makes accessible a wide range of geoscientific and spatial data to a wide variety of stakeholders in multiple formats, and in recent years GA's data volumes have grown exponentially. GA is focussed on making its data and metadata assets accessible so that they can be used in machine to machine interactions for data analytics and other applications in environments that range from High Performance Computing (HPC), through high-end cloud servers, to mobile devices.
We currently have two opportunities for Lead Data Engineers in the Informatics team. The Lead Data Engineer is responsible for innovating and exploring new technologies that will advance GA’s science goals and maximise the uptake and use of GA’s science data. The Lead Data Engineer reports to the team’s Assistant Director but also works closely with other developers, data scientists and engineers within the Digital Science and Innovation (DiSI) branch, as well as diverse stakeholders both within and external to GA.",3.9,"Geoscience Australia
3.9",Canberra,-1,501 to 1000 Employees,2001,Government,Federal Agencies,Government,$100 to $500 million (USD),-1
Data Engineer,-1,"The Seven Network is part of Seven West Media, one of Australia’s most prominent media companies, with a market leading presence in content across broadcast television, online and in print. Comprising some of Australia’s most renowned media brands, SWM includes not just Seven Network and its affiliate channels 7two, 7mate, 7flix and BVOD offering 7plus, but also 7NEWS.com.au, The West Australian, The Sunday Times and more.
At Seven we are here to bring all Australians closer to the moments that move us - we’re first on the scene, with our finger on the pulse, on demand, in the moment. Together, we’re responsible for creating and sustaining authentic Australian engagement.
A new and exciting opportunity has opened for a Data Engineer to join the Audience Intelligence team. Based in Sydney and reporting to the Head of Data Enablement, you’ll be responsible for:
Implementation of end to end data solutions to support Data Strategy for the SWM group.
Work closely with the Data Solution Designers to develop and maintain scalable data pipelines and build out new file and API based integrations to address requirements from the various business stakeholders.
Collaborates with engineering, analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organisation.
Work on Data Preparation for analytics and data scientist team members and assist them from an engineering perspective in building and optimising the models including building the automation of the end to end workflows
Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.
Perform data analysis required to troubleshoot data related issues and assist in the resolution of production data issues.
Work effectively with vendors for successful delivery of projects and acceptance of the solution
Work on Delivery projects using Agile Software Development methodologies
We are looking for someone who has:
Bachelor's degree in computer science, computer engineering or other technical discipline is essential
Proven experience working as a digital analytics specialist
Extensive experience with digital analytics implementation (e.g. Google Analytics, Snowplow, Adobe Analytics) and BI processes and visualisation platforms
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience in ETL and building and optimizing ‘big data’ pipelines and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Experience with big data tools: Hadoop, Spark, etc., AWS cloud services: EC2, S3, Lambda and familiar with version control systems: Git
Strong coding skills with knowledge of Unix/Linux and scripting languages such as Unix Shell scripting, Python desirable
Experience supporting and working with cross-functional teams in a fast-paced environment.
Ability to multi-task and problem solve with changing demands and priorities
Ability to work under pressure to meet deadlines and detail oriented
Your success is our success: we will provide you with opportunities for you to keep learning and growing, enabling you to challenge and develop yourself. In return, we offer a benefits program that has something in it for everyone.
Seven West Media is an equal opportunity employer and we are committed to creating a diverse and inclusive workplace.
Recruitment Agencies: Seven West Media does not accept any unsolicited agency resumes and will not be responsible for any fees related to unsolicited resumes.
Advertised: 19 Oct 2020 12:00 AM AUS Eastern Daylight Time
Applications close:

Back to search results",2.5,"Seven West Media
2.5",Sydney,-1,5001 to 10000 Employees,1956,Company - Public,TV Broadcast & Cable Networks,Media,Unknown / Non-Applicable,-1
BICON Rules Engineer,-1,"APS 5 - $73,299 - $80,410 per annum plus superannuation
Biosecurity Plant Division
Canberra, ACT
Play an active role in managing biosecurity risk to Australia
Work in a motivated and professional team with a wide range of skills and backgrounds
Full training provided

Who we are
The BICON Content Development Team maintains and improves the Biosecurity Import CONditions database (BICON) content to allow external clients to understand and comply with their biosecurity obligations and internal clients to effectively manage biosecurity risk and regulate imports. We work collaboratively with internal clients to comprehend and implement their BICON content requirements and optimise the use of BICON to publish clear import requirements and onshore management support procedures to effectively manage biosecurity risk.

The Jobs
Key duties of these positions include:

working with business content (import and permit conditions) and import programs to understand and construct decision tree structures in the BICON database, in accordance with system design and authoring conventions
executing changes to import and permit conditions in alignment with service standards while complying with system rules and authoring conventions
providing technical advice through various formats on the most appropriate means of authoring BICON content to achieve import program and stakeholder objectives
using workflow management tools to maintain detailed records of changes to import conditions and key decisions
performing administrative tasks including system reporting, data analysis and scoping tasks for the BICON content change work program
contributing to the development and maintenance of instructional material, authoring conventions and courseware
clearly documenting and reporting system issues
developing and maintaining effective working relationships with internal and external stakeholders.

What we are looking for
Knowledge and experience
Experience working with complex IT systems.
Experience working collaboratively and as part of a team.
Knowledge of the role of biosecurity is preferred but not essential.

For additional information, please read the Job Description below.
Candidate Information Package docx Opens in new window",3.9,"Department of Agriculture & Water Resources
3.9",Australia,-1,5001 to 10000 Employees,-1,Government,Federal Agencies,Government,$500 million to $1 billion (USD),-1
Cloud Data Engineer,-1,"Job no: 509605
Work type: Permanent Full Time
Location: Melbourne, Canberra, Sydney
Do you embrace digital disruption?
Do you love solving complex problems, designing sophisticated solutions and building innovative technology?
Do you believe in creating powerful actionable insights from Data and Analytics?
Do you want to work in a diverse and flexible working environment?
KPMG is one of the most trusted and respected global professional services firms. Through depth of expertise, clarity of insight and strength of purpose we help our clients solve complex challenges, steer change, strengthen, transition and grow. We are a team based practice and this extends to our clients whom we work and collaborate with, in solving complex problems. Together, we design, innovate and implement, providing enduring advice that support our clients and the services they deliver. Our clients vary in size and come from a diverse range of sectors – all sharing in a common goal: to embrace change and deliver services that make Australia a better place. We are looking for talented individuals who would like to join us on the journey.
KPMG’s Digital Delta Team
We re-imagine and re-invent organisations to become world class digital enterprises using advanced technologies, data and human insights. We help organisations to embrace Digital Strategy, Artificial Intelligence (AI) & Cognitive, the Internet of Things (IoT), Data, Analytics & Modelling, Mobile App & Web, and User Experience (UX) & User Interface (UI) and more.
We work with clients to:
Formulate strategies that re-imagine organisations
Harness innovation from the 4th industrial revolution
Actioning insights from trusted data to consistently and quickly make clear decisions
Build adaptive organisations
Thrive as a connected enterprise – front, middle and back office
This is how you’ll contribute:
We are looking for ambitious Data Engineers who are passionate about helping clients define bold ambitions and deliver on them. Joining our team will take you on a journey of personal and technical growth and provide the opportunity to inspire confidence and empower change.
As a Data Engineer you are the designer, builder and manager of the information or ""big data"" infrastructure, preparing data for analytical or operational use. You will design, construct, test and maintain a data pipeline to pull together information from different source systems; integrating, consolidating and cleansing data; and structure it for use in individual analytics applications.
The KPMG Difference
Our people are focused on creating a diverse and dynamic environment that embraces and values differences. We value the variety of unique experiences, qualities and characteristics our people possess and we share and learn from each other.
We are proud to be consistently recognised as an employer of choice for women, and for our achievements in LGBT+ workplace inclusion.
Our commitment to ‘Flexibility’ allows our people to manage the changing demands of work, personal or family life. Explore the links below to hear our people share their experience @ KPMG:
Flexibility empowers wellbeing
Flexibility enables contribution to the community
Flexibility inspires technology & innovation
Flexibility supports family

Make KPMG the clear choice for your career and be Extraordinary!

Advertised: 09 Sep 2020 AUS Eastern Standard Time
Applications close:",3.8,"KPMG
3.8",Sydney,-1,10000+ Employees,1987,Subsidiary or Business Segment,Accounting,Accounting & Legal,$2 to $5 billion (USD),-1
Computer Network and Systems Engineer,-1,"Duties Include but are not limited to:
Tasks Include:
analysing, developing, interpreting and evaluating complex system design and architecture specifications, data models and diagrams in the development, configuration and integration of computer systems
researching, analysing, evaluating and monitoring network infrastructure to ensure networks are configured to operate at optimal performance
assessing and recommending improvements to network operations and integrated hardware, software, communications and operating systems
providing specialist skills in supporting and troubleshooting network problems and emergencies
installing, configuring, testing, maintaining and administering new and upgraded networks, software database applications, servers and workstations
providing network programming in support of specific business needs and requirements
preparing and maintaining procedures and documentation for network inventory, and recording diagnosis and resolution of network faults, enhancements and modifications to networks, and maintenance instructions
monitoring network traffic, and activity, capacity and usage to ensure continued integrity and optimal network performance
Skills and Experience Required:
Must have experience working in a Managed Service environment
Demonstrated experience in IT Networks and Data Centres
Understanding of systems and architectures to meet client needs
Experience in Help Desk including break / fix
Effective and timely documentation
Effective Task Management Skills
Be solution and outcome focused and willing to learn new technologies
Excellent communication skills with staff, clients and partners
Time management, ability to prioritise and deliver to schedule
Experience with N-Able and Connectwise desired
Open Cabling license desired
Job Types: Full-time, Permanent
Salary: $30.00 per hour
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,Trans-plant training,Canberra,-1,-1,-1,-1,-1,-1,-1,-1
Software Engineer (Data),-1,"If you are looking for an opportunity to make a real impact with smart people who are genuinely doing things differently then you've come to the right place! We're growing our data engineering capabilities and are looking for awesome data engineers to join our team.
With our diverse range of clients and projects, no day will look the same - but here's a great snapshot of what you'll be doing:
Work with some of the best Data Scientists and Engineers to deliver production-grade AI and Machine Learning systems as we deliver client projects from inception to production.
Consulting with our clients and working with them to build modern data systems using the 'best of' technologies and principles.
Advising clients on data strategy, architecture and technology.
Applying best software engineering practices in coding, monitoring and alerting, using CI/CD, TDD and cloud architectures.
Working over a wide range of big data tools and environments: not limited to; Apache Kafka, Spark, Python, Scala, Hive, Airflow, AWS EMR & Glue, GCP Dataproc & Dataflow, BigQuery, Snowflake, Redshift.
Who are we?
Glad you asked! We are Eliiza. Data science. Engineered for scale.
We are a passionate team of data scientists and engineers who apply data science and machine learning to solve real-world problems. Our mission is to create a bright future for Australian businesses and society in a world increasingly influenced by intelligent technologies.
We've created a culture that values diversity where people can truly be themselves! We care a lot about growing the Australian AI community in a positive direction, and we're doing several things to try and achieve that:
We provide opportunities for underrepresented groups to work in AI through our associate and intern programmes
We organise and participate in a range of community events, reading groups and meetups
We produce the AI Australia podcast
We blog about topics we care about
We stream brown bag sessions to the broader community
We're also part of Mantel Group's 'house of brands' which means it's not just the Eliiza team you'll work with, learn from and see at social events - there's another 230 of us across DigIO, Kasna & CMD Solutions!
So you're ready for something new?
We're keen to know more about you! Our team is made up of a range of people, with different experience across a huge range of data driven skill sets.
We'd love to hear from you if you have experience with:
one (or more) core language(s), ideally Scala, Python or Java
one (or more) cloud platforms, AWS, GCP, Azure
ETL/ELT concepts and technologies e.g. Data partitioning, Hive, Spark
streaming data concepts and technologies, ideally Kafka (Kinesis, Beam or Pubsub will do)
We'd be over the moon if you:
Experience with distributed/columnar databases (e.g. Snowflake, Big query, Redshift).
Experience with any of a variety of databases e.g. RDMS, NoSql, Columar, Distributed, Time series, Graph.
Knowledge of job orchestration and scheduling. Any experience with Airflow, Luigi or Oozie.
Experience with containers and container orchestration (Docker, Docker Compose or Kubernetes).
However, we value a diversity of skill-sets, and don't necessarily require that you're skilled with all of the above. If you feel you don't fit all the experience/skills listed above we still encourage you to apply or get in touch.
What's on offer if you join us?
We make sure you're always one step ahead by investing your learning and development, every year. We build our own training where it doesn't exist yet.
We hire smart people and get out of their way. By focusing on our five principles and not getting caught up in red tape, we trust you to get the job done.
You'll get all the tools you need - a new iPhone or Google phone, a new Macbook Pro or Dell, and a lot of branded swag!
But hold on, you mentioned a house of brands?
We certainly did! Mantel Group is an Australian-owned, 'house of brands' company with four technology businesses (Eliiza being one of them!) across Melbourne and Sydney. We're building a group of companies with open borders so we can support you to take on new skills without leaving an awesome team - we understand you won't have one job for life!
We may only be just two years old but Mantel Group has already been recognised #9 in the 2020 Best Places to Work in Australia and #4 in the AFR's 2020 fastest growing new companies.
Keen to chat?
Click ""Apply"" to share your details with our talent team, and we'll be in touch.
In the meantime, check out 'how we hire' to find out what's in store if you're successful and get to know us better by visiting our website and following Eliiza on LinkedIn.",-1,Eliiza,Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Infrastructure Engineer,-1,"Job Description:
Design and grow the Shopee data platform to support a variety of big data applications using open-source technologies including Kafka, Hadoop, Presto, HBase, Spark, Hive, Druid, and our own creations. Some examples include a real-time data streaming platform, a unified query platform, a cluster management system, and a machine learning platform
Dig into the source code of some open-source big data system to get the whole control and familiar with the details, configurations, designs and source code. Develop and maintain the internal release of big data systems and components as the business requirements.
Keep close and overall monitoring for all the deployments of the systems, maintain the system’s stability, improve the performance, discover the performance bottlenecks, tracking and troubleshooting, cost optimisation.
Requirements:
B. Sci. / Ms / PhD in Computer Science or a related technical field
Familiar with at least one of these languages: Java, Scala, Python, Bash under Linux / Unix. Scala is a plus
Familiar with the use and compute logical of SQL
Knowledge about the Big Data Infrastructure system technology like Distributed File System, Distributed Computing, Distributed Database will be a plus
Hands-on experiences Hadoop, Spark, Kafka, and/or Presto will be a plus
Love to use and develop open-source technologies
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"Work on an award-winning, international technology!
Endless career opportunities
An innovative, friendly team of 300+
This role will be focused on the development of our existing ClaimLogik line of products as well as working on our new cloud-first, modern suite of applications.

Intelligent Thought, our technology business is scaling and shipping our software globally. Already profitable, part of a much larger group business, with investors such as Macquarie Capital and Envest – we are all set to deliver textbook disruption to the Insurance Industry. The growth of the platform, of our customer base, and the increasing industry demand have led to the need for this role to help the team scale.

Our Philosophy
Give each employee a sense of purpose and an environment for them to connect the importance of their role to delivering a service that matters to our customers.
Challenge the ‘why’ of traditional claims processes.
Keep it simple – do only what brings value and what matters to the customer
Enable employee decisions, empower our people
Responsibilities:
Create, extend and maintain ETL pipelines to form our data lake, data warehouse and analytics platform (currently using the Microsoft Azure set of tools and service)
Help define the optimal data pipeline architecture
Influence the tool selection, platform selection, data architecture and strategy which will transform the business to be truly data-driven
Understand, analyse and size user requirements
Work with different parts of the business to provide them with the insights they need to deliver the best results
Skills & experience:
Degree or qualification in computer science or related
Advanced knowledge of relational database, including query authoring and query optimisation (MS SQL Server and PostgreSQL).
Experience building and optimising ETL pipelines
Experience designing complex data models
Experience working with cloud platforms (Azure or AWS)
Efficient time management and organisational skills
High attention to detail and accuracy
Effective communication skills to build strong working relationships; both written and verbal
Proactive and results-driven
Why Claim Central?
Claim Central Consolidated is a global insurance industry leader across, claims management, insurance technology and data and analytics. Currently operating in the United States, Australia, South Africa, Italy and New Zealand, we have pioneered digitally connected claims management services across the globe. Claim Central is a disruptor and thought leader in the industry and we were recognised as the Australian Financial Review’s 8th Most Innovative Company in Australia in 2016. This business is in a period of unprecedented growth, transitioning our technology and services into multiple geographies at a rapid pace. Our unique culture is based on teamwork, collaboration, trust, respect and performance. We also offer many benefits apart from our exceptional team culture; including flexible work arrangements, and continued professional development.

Be a part of this journey in a career-defining role.",-1,Claim Central,Matraville,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer - AI/ML,-1,"Our client provides services to a major industry across the country. The business is still early in it's days of technology development and the environment is greenfields in nature (no pun intended), effectively working like a start-up.

Their data and analytics team have worked and built leading and bleeding-edge technologies in this space and what they have created so far may be game-changing. From a machine learning perspective, the progress they have made to the business has already seen proven success in changing the future of an industry that will have positive consequences for all those involved.

You will have previously worked in a technical capacity in the data and analytics space and have experience working with an organisation where machine learning has been implemented, not just a concept that the business talks about having or the technology team would love to have. The commercial experience you will have had in the ML field will be proven examples of where you have affected the way a business or industry used to perform, to the changes that have come about from this.

Technically, you will have extensive experience in the Microsoft space - Power BI, Azure etc and you will have previously mentored and coached junior members of the teams you have been part of.

This is a rare opportunity in Brisbane where the business has truly embraced and funded projects across the ML space and would be a great chance for those in the Data Development/Data Engineering field, who are looking to move into a Data Scientist role in the future.

Please send your application through if you would like to know more.",4.0,"Emanate Technology
4.0",Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Solution designer/ ETL Engineer & Data Modeller,-1,"We are looking for a Qualified and Experienced Solution Designer to join our client for a period of 6 months with a view to extend.
You will work closely with team members and your contribution will range across gathering and analyzing information, developing and documenting improved processes and work instructions and experienced DWH Lead with skills in requirement analysis, solution designing, developing, testing and supporting ETL solutions.
A hands-on solution designer, data modeler and ETL developer for Data Warehousing and ETL application transformation projects using Informatica PowerCenter.
Knowledge on AWS, S3, Redshift, Informatica BDM, and related technologies.
Experience working with IPython, PySparks, AuCuMo, Airflow, Jenkins, Github, Athena, JIRA, Rally, Spectrum, Glue, Flyway.
Good exposure on Oracle PL/SQL, aware of DBA activities, writing and performance tuning of complex SQL queries.
Contract length: 6 months
Job Types: Full-time, Contract
Salary: $650.00 – $800.00 per day
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,nducive,Melbourne,-1,-1,-1,-1,-1,-1,-1,-1
"Data Engineer, Wollongong NSW or Mount Waverley VIC",-1,"Company Description
BlueScope is a technically advanced supplier of steel and steel products in Australia. We are an inclusive organisation and every day we showcase our technology and expertise throughout the world.

Job Description
We are looking for two Data Engineers to join our IT team, based in Wollongong NSW or Mount Waverley VIC. Use your experience in analytics to unlock business value, enabling use of big data for insights and decision-making.
Reporting to the Data Product Owner for our Australian Steel Products (ASP) business, this position will support strategic goals related to data. This will see you:
Gather business and technical requirements with the view to deliver outcomes;
Develop and implement end-to-end data collection, consolidation, modelling and visualisation solutions;
Document metadata in a dictionary and catalogue;
Ensure consumers of such information understand its accuracy, timeliness, quality and sensitivity, so that it is used appropriately; and
Identify opportunities to enhance analytics.
What are the benefits?
Work in a supportive and collaborative team environment whilst we embark on a journey to transform the way our business uses data!
Our systems landscape is broad and diverse. You will be encouraged to think creatively to develop data solutions which solve real business problems.
Working in this role you will enjoy:
the chance to learn more about data science;
salaried remuneration with attractive superannuation options;
the opportunity to participate in a performance incentive scheme; and
access to further development and career opportunities with BlueScope.
Who are we looking for?
We welcome applications from professionals with experience in data analytics and/or programming. Supported by your knowledge of project delivery methods (e.g. Agile), you will demonstrate:
experience with data mining, wrangling, mapping and visualisation techniques (e.g. Azure Data Factory, Databricks and/or DevOps etc.);
well-developed ability in gathering business and technical requirements;
skills in developing and implementing collection, consolidation, modelling and visualisation solutions; and
a passion for sharing your knowledge and desire for ongoing professional development.

Qualifications

null

Additional Information
We're proud to have been named an Inclusive Employer for 2019–2020 by the Diversity Council of Australia. We believe that our people are our strength. Having a diverse and inclusive workplace enables us to improve our capability and ensure continued, sustainable success.
We know that workplace flexibility can mean something different to everyone. Under our B-Flex initiative all of our roles have some degree of flexibility. We encourage you to discuss your needs with us.
Applications close Sunday 25th October 2020.",3.3,"BlueScope
3.3",Wollongong,-1,201 to 500 Employees,-1,Company - Private,Construction,"Construction, Repair & Maintenance",$100 to $500 million (USD),-1
ETL Data Engineer,-1,"ETL Data Engineer

Join a team that’s changing how Australia lives, works, plays and grows
We want you to be the best version of you

Work with innovative teams and explore new technologies to help solve real-world problems.

A typical day as a Data Engineer

ETL / Big Data Engineering professionals will be responsible for guiding the full lifecycle of a Data solution, including:
Working in highly client-facing roles to contribute throughout the end-to-end delivery lifecycle of complex and large-scale digital solutions
Use case and business case development
Support existing and new applications utilizing in-depth technical and data knowledge. Troubleshooting complex issues and providing advisory services to improve the client’s data landscape
Help to streamline and simplify the clients’ complex data landscape by integrating different applications and data architectures
Implementation from requirements analysis, platform selection, digital architecture design, application design and development, testing, and deployment
Interstate travel may be required

Basic qualifications:
Bachelor’s degree
Experience across systems integration, information management, data management and architecture, and business analytics
Experience with being in a team focusing on large-scale, multi-release information centric projects
Experience with waterfall and agile delivery and run / application support functions
Part of a team working on End to end implementation of at least 1 big data project

Preferred Skills:
Hand on experience in Data warehousing using ETL tools such as DataStage, Autosys and TeraData
Hands on experience in ETL job development with multiple stages like sequential file, Transformer, Lookup, join, sort and Database stages.
Strong hand on skills in design, development and implementation of various data remediation, Data migration, data integration techniques.
Strong hand on data modelling experience.
Strong hands on experience in database performance tuning including complex query optimizations and physical database tuning using Teradata.
Understanding of architectural designs and strategy related to data migration, data cleansing, data quality and data consolidation.
Proven data analysis, requirement gathering and problem-solving skills
Exposure to Unix environment and shell scripting.
Experience in Banking and Financial services industry
Desirable: Knowledge of cloud computing infrastructure (e.g. Amazon Web Services EC2, Google Cloud, Microsoft Azure)
About Accenture

Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. We combine unmatched experience and specialized capabilities across more than 40 industries — powered by the world’s largest network of Advanced Technology and Intelligent Operations centers. With 513,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises. Visit us at www.accenture.com.

Accenture is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, marital, domestic or civil partnership status, sexual orientation, gender identity, or any other basis as protected by applicable law.

Vera Goga is the Recruiter managing this role. As the team experience high volumes of applications, we appreciate your patience to allow for a fair and timely process.",3.9,"Accenture
3.9",Sydney,-1,10000+ Employees,1989,Company - Public,Consulting,Business Services,$10+ billion (USD),-1
Student Engineer,-1,"The candidate will have the ability to:
Undertake onsite inspection to collect asset condition data based on the relevant engineering standards and technical guidelines;
Undertake desktop analysis to evaluate the condition and performance of the assets;
Provide the appropriate information, advice, engineering input and support services for the sustainable management of Council’s stormwater and transport networks.
Qualifications:
The successful candidate will be enrolled in a Bachelor of Engineering with a minimum of two years completed.
Position Number: 100678
Position Hours: Fixed term (3 months), hours will be negotiated with the successful candidate, maximum of 75 hours per fortnight.
Salary: Schedule A, Salary Point 4.0. $28.64 per hour ($55,853.45 per annum, pro-rata) in accordance with Glenorchy City Council’s Enterprise Agreement 2016
Please note that all successful applicants will be required to provide a current National Police Check prior to commencement of employment.
For further information on this position, contact Patrick Marshall, Senior Civil Engineer on (03) 6216 6800.
How to apply: Applications for this position must be lodged on this submission site or on the Glenorchy City Council website www.gcc.tas.gov.au - Careers page.
To be considered for this role, all applicants must address the key selection criteria in the and provide a current resume. A copy of the position description can be found by clicking the below hyperlink or on the Glenorchy City Council website.
Applications close at 8pm on Sunday, 1st November 2020
- Student Engineer",4.0,"Glenorchy City Council
4.0",Glenorchy,-1,501 to 1000 Employees,-1,Government,-1,-1,Less than $1 million (USD),-1
Data Engineer involving DevOps,-1,"Data Engineer involving DevOps
Axiom Technologies is an Australia based entity with the history of providing Managed IT solutions to medium to large scale enterprises globally. Please visit our website for more information about what we do at www.axiomtechnologies.com
Axiom Technologies is an Equal Opportunity Employer and encourage applicants from all backgrounds and gender to apply, including, Aboriginal and Torres Strait Islander candidates
Job Requirements:
8+ years IT experience, with at least 5+ years of “Data Engineer/Deveoper” focused titles/roles,
Data Tools: Hands on experience with Apache Beam.
Testing: Hands on experience with automated testing activities/outcomes
DevOps: Experience with the processes involving Microservices facilities for artifacts developed
Platform/OS: Mid-range/Unix
Languages: Unix (Shell) Scripting/commands, SQL, Python
File formats: Text, CSV, Parquet, JSON, XML
Scheduling: Jenkins, Airflow
Auto Scripting: Designing/creation of scripts for repetitive activity. E.g. Unix scripting/SQL
Big data: Exposure to Data Lake Concepts, Hive (Schema), HDFS
Source Control tools: GIT
Delivery Models: Agile, Scrum
Ingestion Design: Create/assess Source/Target data mapping designs
Frameworks: Development and delivery frameworks
Activity Reporting/Repository: Jira, Confluence.
Quality: Accuracy and attention to detail
Industry: Financial Services/Banking
Solutions: Define solutions from High level to detail design to address automating ingestion activity. Facilitate/confirm requirements from product owners, business team members and technical associates,
Process Automation: Automating processes in file management, testing data in files, analysis and design, configuration management.
Script Automation: Ability to design/create scripts to automate/improve data copy/migration/ETL for any repetitive activity.
Languages: Java, Python
Scheduling: Control-M
Databases: Relational. E.g. POSTGRESS, Oracle – as a ETL developer
File Formats: Mainframe – experience with referencing its data formats/copybooks
Big data: Experience referencing/using Hive (Schema) to access data in HDFS
Metadata management tools: MDM, EDC and Axon
Performance: Assess, recommend, improve mappings, SQL queries, Batch feeds
Automation Tools: Other tools that may add value to an automation program and generally support development. E.g. API, REST, JDBC, Webservices, Message Queues/Load balancer,
Cloud: Experience with processing of data files to be ingested/stored in the Cloud, preferably with AWS.
Prod Support: Experience in a production support role performing root cause / impact analysis – under time constraints
Experience in a similar role
8+ Years
What next?
If you are looking for that next challenge in your career and wish to apply for this role, please forward your resume to careers.au@axiomtechnologies.com",2.0,"Axiom Technologies
2.0",Melbourne,-1,1 to 50 Employees,-1,Company - Private,Industrial Manufacturing,Manufacturing,Less than $1 million (USD),-1
Data Engineer,-1,"About the Role
We are on an exciting digital journey so it’s a great time to join ME! We are seeking a Junior Data Engineer who enjoys rolling up their sleeves, learning and growing. As part of our Enterprise Data Team, you will ensure fit for purpose data warehouse solutions are built for use across the bank and by utilising best practise ETL standards, whilst ensuring the data is trusted by our BI developers and key business consumers. Oh, and you’ll get to work on Microsoft technology stack too!
You will be involved with investigating data issues, keeping data feeds flowing and collaborating with different projects across the bank to deliver quality data solutions. How important does that sound? What’s even more important is this role contributes directly to our overall business strategy through the provision of data to enable analytics & reporting, as well as supporting business and decision system processes.

About You
You’re naturally a highly motivated and energetic person who thrives in a dynamic, ever-changing collaborative team environment. Ideally you have previous experience as an ETL developer, Data Engineer or a BI developer, and if you have a degree in computer science or similar it would really put you ahead of the rest.

With your knowledge of SQL coding, data modelling, understanding of data warehouse concepts, plus experience of working on complex ETL solutions, you’re ready to expand your horizons and launch your career into the world of IT at ME.

About ME
We’re not like other banks.
ME was created by the industry super funds to be different from the pack – with a core purpose to help all Australians get ahead financially – no conditions, asterisks or exceptions. And we know that looking after customers starts with taking care of our people.
We believe everyone deserves the same opportunities in life, regardless of gender or identity, sexuality, ethnicity, religion or disability ‒ with internal affinity groups.
Perk ME up
Once you get your feet in the door at ME, we’ll put them both in your very own ME-branded Converse shoes. You’ll also get the following financial, health and fun perks when you join the team:
4U Extras portal (discounts and cashback on 100s of items including cinemas, shopping and gym memberships
10% Myki discount
Purchased Leave programme
Internal wellness programme (Mindfully ME)
Professional education through LinkedIn Learning
Novated Leasing
Professional membership reimbursements
Health checks
Financial education (To help you manage your money smarter)
LGBTIQ+ and Women at ME affinity groups

I want those Converse shoes (and the role)
Can’t see a closing date on the advert? That’s because we’re pretty efficient here at ME and we may start looking at applications sooner rather than later, so if this role sounds like your jam, be sure to apply by submitting your resume today.

Should an applicant be the preferred candidate, background checks (including police checks, reference checks, ASIC banned and disqualified persons and bankruptcy checks) will be completed prior to the candidate's employment being confirmed. The outcomes of the background checks do not automatically bar candidates; however will be assessed against the inherent requirements of the job.
Back Share
Apply Now",3.0,"ME Bank
3.0",Melbourne,-1,501 to 1000 Employees,-1,Company - Private,Banks & Credit Unions,Finance,$100 to $500 million (USD),-1
Software Engineer - Machine Learning/Data Science,-1,"Zendesk is looking for a Software Engineer - Machine Learning/Data Science for a full time position in our Melbourne office.
As part of our engineering team, you will work at a scale where the challenges start to get seriously interesting. Our global engineering team is widely dispersed over the world, with people across nearly every continent. You will get a chance to do cool things with a diverse bunch of people while working in the Melbourne office that is home to Zendesk’s first machine learning (ML) research team.
The Data Science Team, together with Data Engineering, have built Satisfaction Prediction, Answer Bot and Content Cues — products that use Machine Learning (ML) and Artificial Intelligence (AI) to help our customers work more efficiently.
What you get to do every day:
We’re currently looking for someone to join our team as we research, develop, and productionise Machine Learning and Deep Learning models. In addition to frequenting Melbourne’s finest purveyors of coffee, ramen, and bulgogi, you may find yourself:
Building machine learning models including neural networks in TensorFlow
Writing and deploying production-grade Python
Querying and constructing datasets in AWS Athena, Spark
Evaluating and responding to real-world model performance
Scaling your ML to millions of predictions per day
Presenting your work to a broader audience
Watching your algorithm help Zendesk’s end-users
What you'll bring to the role:
A strong foundation in a quantitative discipline (e.g. machine learning, statistics, bio/eco/etc-informatics, econometrics, etc) is critical for this position. While experience in deep learning and natural language processing would be beneficial, your best qualities are:
dedication to continuous learning
collaborative work attitude
strong communication skills
You should also be comfortable with at least one programming language, such as Python, R or Scala.
Application Deadline: 18/11/2020
Job Types: Full-time, Permanent
Salary: $85,000.00 – $110,000.00 per year
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Temporarily due to COVID-19",4.5,"Zendesk
4.5",Melbourne,-1,1001 to 5000 Employees,2007,Company - Public,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),-1
Software Engineer (Machine Learning),-1,"About the Role
AdelaideMRI is building a medical reporting tool. We require an engineer to work primarily on machine learning projects to improve reporting speed and report comprehensiveness.
You will perform data analysis of medical report datasets and image datasets to infer sentence recommendations, image classifications, or other actionable results for the doctors.
Skills and Experience
Background in machine learning or image processing
Qualifications in Computer Science, Software Development or Engineering or equivalent experience
Bonus points for Python
No prior medical knowledge is required.
This position offers flexible hours and work arrangements.
Job Type: Full-time
Experience:
Software Engineering: 1 year (Preferred)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Yes",-1,Adelaide MRI,Australia,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Hey there, we’re PEXA!

We started as an idea: to deliver a single, national e-Conveyancing solution. We collaborated with the industry to create a national electronic lodgement and settlement platform: PEXA. From our humble beginnings, we’ve now grown to more than 320 employees across 5 different states. We’re still expanding at a rapid rate and constantly challenging ourselves to create great experiences for our members as they transition to fully digital conveyancing.

Why become a PEXArian?

Great question! Being a PEXArian is so much more than just a job. We are passionate, motivated & unashamedly enthusiastic at PEXA - we love what we do and we’re proud to admit it! Creating brilliant member experiences wouldn’t be possible if we didn’t also strive to create an amazing employee experience. Alongside our members, our employees are at the heart of everything we do.
Here’s a snapshot of what your life at PEXA could look like:

Your growth:
We encourage you to hit your personal and professional Learning & Development goals with our tailored programs and tools.

Your wellness:
We care about your holistic well being - a fully stocked kitchen, four wellness days, a $250 wellness subsidy as well as lunch and learn sessions to support your financial well being.

Your work/life blend:
We know that work is just one aspect of your life, we want to help you create your ideal work/life blend, rather than squeezing in life around work.

Your family:
With a range of benefits aimed at supporting your family including access to a subsidised school holiday program, extended parental leave and flexi-time to support your return to work, superannuation payments for unpaid parental leave for primary carers and a childcare allowance for pre-primary aged children, when we say, ‘welcome to the family’, we really mean it!
The impact you'd drive:
The successful candidate will be responsible for developing, and maintaining infrastructure to support the delivery of new and existing products. They will also be contributing to establish the rules and frameworks for obtaining the required approvals for new products.
On day one we’d love you to have:
Experience with Python, Spark
Event streaming/sourcing with Kafka or AWS Kinesis
Experience with data structures, formats and data security best practices
AWS experience (e.g CloudFormation, S3, ECS, Lambda, SQS, IAM, KMS, DynamoDB, Glue, Athena)
Query construction and optimisation (e.g. SQL, Elasticsearch, Splunk, DynamoDB)
Git, version control practices, and continuous integration/delivery servers
PyUnit and unit testing frameworks
Production release cycles and maintenance
Collaborating with technical and non-technical teams
Even better:
Agile methodology/delivery
GraphQL
Modern frontend technology (e.g. ReactJS, TypeScript)
Machine learning frameworks and tools (e.g. TensorFlow, PyTorch)
OAuth 2, SAML 2, JWT
Data visualisation and exploration tools (e.g. Jupyter notebooks, Tableau)
AWS SageMaker
Sounds like you?
If this role sounds like you, apply today to have your application reviewed ASAP!",3.9,"Property Exchange Australia Limited
3.9",Melbourne,-1,201 to 500 Employees,2010,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Ongoing position
Full time
Based in Sydney, NSW
Who we are
Australian Red Cross is part of the world’s largest humanitarian organisation. Our aim is to improve the lives of the most vulnerable people in Australia and across our region.
About the role
The Data Engineer role will sit within the Data and Integration Squad in IT and will own (design, implement and support) the AWS Big Data technologies such as the Data Lake and Data Warehouse and support the organisation in growing the data analytics capabilities at Red Cross. In addition to this, the data engineer role will also administer the Power BI tool and support the implementation of the data mastering capability.
What you will bring
Experience building and optimizing data pipelines, architectures and data sets.
Experience in dimensional modelling and building data vaults
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with structured, semi-structured and unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Why work for us?
Work for purpose and know that your work assists Red Cross support and empower people and communities in times of vulnerability.
Generous salary packaging options available that can increase your take home pay.
Further information
To find out more about this opportunity please see the position description below or contact Sharath Kumar Gurram on 02 8651 8839.
Position Description: Position Description - Data Engineer .pdf
Applications for this position will close at 11:55pm Thursday, 5 November 2020.",4.1,"Australian Red Cross
4.1",New South Wales,-1,1001 to 5000 Employees,-1,Nonprofit Organization,Industrial Manufacturing,Manufacturing,$500 million to $1 billion (USD),-1
Junior Fullstack Data Engineer (Python and React),-1,"Formbay is the leading Renewable Energy Certificate Trading company in Sydney. We provide Digital Workflow and Compliance solutions in the renewable energy industry and document processing.
Thanks to our meteoric growth and our commitment to be the best at all we do, we've identified the need to bring on board a new Junior Fullstack Data Engineer.
Reporting to our Principal Machine Learning Engineer, you will help build Machine Learning pipelines for our existing Digital Workflow and Compliance solutions to automate fraud detection and document processing over terabytes of photographic and documentary data – including documents, photos, GPS data and aerial/satellite photography.
Our stack is based on Python, JavaScript, Dask, Tensorflow, CUDA, Nix/NixOS, AWS, Docker, PostgreSQL and more – familiarity with these applications will give you a leg-up on the competition.
Our ideal candidate will have the following competencies:
SQL
Python
JavaScript/TypeScript
Our candidate must also be comfortable working with Linux.
Located a stone's throw away from the Queen Victoria Building in Sydney's bustling CBD, we are centrally-located with easy access to public transportation, bars, cafes and fine dining.
Formbay will provide flexible working hours, a generous remuneration package and the opportunity to work on a world-first software solution are what we can offer you. Free, twice-weekly gym sessions and really, really good coffee are also available.
No hiring/recruitment agencies need apply.",5.0,"Formbay
5.0",Sydney,-1,1 to 50 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is an experienced and qualified Data Engineer to join our IT team based in Birtinya.
Key Responsibilities:
Create and maintain data pipelines and or ETL scripts
Create and maintain data integration including API and Batch interfaces
Performed detailed data analysis
Create and maintain corporate data models
Create and maintain data visualization using Qlik.Sense , PowerBI or Simliar Toolset
Experience in defining, building and maintaining data virtualization and/or star schema data warehouses
Maintain, tune and optimise database, integration and visualisation toolsets
ABOUT YOU:
To succeed in this role, you’ll need to bring the following experience and skills:
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Excellent communication skills both oral and written, with an ability to bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking
Experience with data analysis and modelling will be beneficial

How to Apply
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kawana Waters,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Graduate Data Science / Engineer,-1,"The NRMA is an organisation looking to the future, and right now, we are on the lookout for people who can help us reach our goal: to continue to shape the way Australians move, for the next 100 years and beyond. www.mynrma.com.au.
Everyone new to the team, along with our current staff, will temporarily work from home until it is safe to return to our offices. All interviewing and on boarding will be done virtually due to COVID-19.


Your opportunity
As Graduate Data Scientist or Engineer you will be part of the Data Engineering team delivering cloud data transition program for business initiatives and supporting the entire data platform build.
Your key responsibilities will be to:
Implementing Concepts of Data Warehousing, Data Mart creations within Cloud
Use of SQL for data analysis and insights
Building AI/Machine Learning prototype for implementing and supporting existing algorithms
Data Analytical reports build, using different tool sets


Requirements for Success:
Relevant Degree - Computer Science, Computer Engineering, Software Engineering, Data Science
Excellent SQL skills and demonstrated working knowledge in Python
Demonstrated understanding in data structure and algorithms.
Knowledge and concept of data warehousing methodologies
Any reporting tools experience Tableau or Oracle Analytics Cloud, Looker is desirable
Exposure to Google/AWS/Azure/Oracle any cloud based platforms is desirable
Good communication and interpersonal skills

If you have the required skills and the passion to join our high performing team, please apply today.

Employee Benefits
To ensure our employees feel valued, empowered and celebrated we provide a range of employee benefits including:
50% discount on all NRMA insurances
Free Roadside Assistance
12 weeks paid primary and 4 weeks paid secondary parental leave
Free NRMA Blue Membership
At the NRMA Group, we are People Moving People and diversity and inclusion are part of our DNA. Together, we continue to build an inclusive culture that encourages, supports and celebrates the diverse voices of our employees. It fuels our innovation, promotes flexible ways of working and connects us closer to our members and the communities we serve.",2.5,"NRMA Motoring & Services
2.5",Sydney,-1,501 to 1000 Employees,-1,Nonprofit Organization,Casual Restaurants,"Restaurants, Bars & Food Services",$500 million to $1 billion (USD),-1
Data Centre Engineer,-1,"We are a leading world group that provides low-carbon energy and services. To tackle the climate emergency facing us all, our aim is to become the world leader in the zero-carbon energy transition ""as a service"" for our clients – particular for companies and regional authorities. We use our expertise in our key business areas (renewables, gas, services) to provide competitive and bespoke solutions.
The Data Centre Engineer will be employed as part of a 24/7 ongoing shift to coordinate and monitor third party service providers, maintain the data centre facilities and infrastructure plans, coordinate the implementation of customer requests within the data centre and monitor systems, all in accordance with the Contract KPIs and SLAs.
Coordinate and monitor third party service providers for regular maintenance & testing, service faults & call outs, ensuring works are performed in accordance with Contract SLAs
Monitor and maintain the data centre facilities and infrastructure plans and documentation, including electrical, mechanical, hydraulics, fire and BMS/EMS systems
Coordinate the implementation of internal and external customer requests within the data centre
Perform scheduled plant checks and minor maintenance works
Ensure all Work Order requests are raised and closed in a timely manner
Conduct inductions for staff, vendors and contractors
Ensure all work permits for vendor works are raised and closed
Perform inventory checks on all equipment and critical spares

Qualifications
The selected candidate must be able to demonstrate:
Electrical or HVAC background, or Graduate Electrical or Mechanical Engineer
Passionate about quality work and career minded looking for a new challenge
Can commit to a day and night shift roster (2 days of day shift, then 2 days of night shift, 4 days off)
Ideally able to commence asap
As part of carrying out the duties of this role, it is mandatory to hold Australian Citizenship.

If you are interested and meet the selection criteria apply with an up-to-date resume via the apply instructions on this website.

ENGIE Services is an EEO employer, where all applicants are treated with fairness and respect and have equal access to the opportunities available.

We will not be engaging in the services of a recruitment agency to fill this vacancy and therefore request all interested candidates apply directly to this advertisement.

Job
: Maintenance
Primary Location
: Oceania-Australia-New South Wales-Erskine Park
Organization
: ENGIE Services Australia and New Zealand
Schedule
: Full-time
Nature of Responsibility
: Senior operational / administrative role
Job Posting
: Sep 11, 2020, 6:29:59 AM",3.7,"ENGIE Services Australia & New Zealand
3.7",Sydney,-1,5001 to 10000 Employees,1995,Company - Public,Energy,"Oil, Gas, Energy & Utilities",$2 to $5 billion (USD),-1
Senior Data Engineer,-1,"Senior Data Engineer, Temporary, SYDNEY - McKell

Job Title: Senior Data Engineer

Salary: SNSW Grade 9/10 - The package includes base salary range of $111,806 to $134,667, plus employer's contribution to superannuation and annual leave loading.

Location: Head Office – Haymarket

Employment Status: Temporary through till 30th June 2021


About Service NSW:

Service NSW is making it easier for people and businesses across NSW to access government services. The role designs, builds and analyses complex data from multiple sources to identify revenue, process and business improvement opportunities; providing new information and insights to the business to inform planning, continuous improvement and performance.

About the Role

We are currently seeking to appoint a Senior Data Engineer to deliver expert advice and services in the design of a Single View of Customer and data-related services to support the achievement of business outcomes and strategic goals. We support flexible working practices with staff working remotely during this time.

In this role you will:

Design, build and support a modern data platform based in AWS and vendor technologies.
Provide expertise on data modelling for Graph data model and Customer Data Platform (CDP).
Create data pipelines, load, transformation and reporting workloads in AWS.
Work with the latest data engineering technologies like Apache Kafka, AWS Kinesis, AWS Neptune, AWS Glue and AWS Athena.
Contribute to the design and decision-making of the right tool or platform for the job according to requirements.
Provide expert advice and guidance on data quality and data engineering best practices.
Support a “bigger than you can imagine” scale of data in production environments.
Design, develop and support a metrics-driven reporting solution and a meaningful business intelligence platform.
Document the solution design and support procedures of solutions.
Produce reports, visualisations and recommendations to answer complex business problems that are presented in the most appropriate format to ensure clarity for target audience.
Analyse and define new process improvement opportunities to support continuous improvement and business outcomes; providing advice to stakeholders, on ways to improve the efficiency and reliability of data products and services.
Be very responsive to the information needs of the business by corresponding to customers in a timely manner and provide support/solutions to issues raised.
Troubleshoot and perform root cause analysis on production issues. Identify and implement long term solutions to problems. Perform scheduled maintenance, release deployment and production support activities after business hours, from time to time.
Liaise with internal and external customers to discuss and gather requirements, solutions etc. and maintain a good working relationship with the stakeholders.


Skills and Experience Required:

Solid experience with workflow technologies designing and building data pipelines, data models and data stores.
Experience working within and an understanding of Amazon AWS ecosystem, including security and performance tuning.
Hands on experience working with different types of databases, with focus on Graph and NoSQL databases.
Experience with data streaming required. Having used Kafka and related technologies is an added advantage.
Sound knowledge and experience working with batch processing, data extraction and API integration.
Hands on experience with at least one programming language: Java, Python or scripting.
Demonstrated experience working in an Agile based, fast paced, complex environment within cross-functional teams.
Experience developing systematised insights, data analytics and reporting solutions is an added advantage.
Experience with interactive visualisation of data insights is an added advantage.


Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Salary Grade 9/10, with the base salary for this role starting at 111,806 base plus superannuation

Closing Date: 6th November at 9:59am - applications will be reviewed on a rolling basis, applications may close early or extend

Please apply online, direct applications submitted via email will not be considered.

The Department of Customer Service is proud to be an EEO Employer who are fully focused on equality and believe deeply in diversity of all identities making us different and a true reflection of our NSW customers. As an inclusive workplace, we support various employee resource groups, practice flexible work and workplace adjustment.

If you do require an adjustment during the recruitment process, please notify us on your application form.",3.2,"Service NSW
3.2",Sydney,-1,501 to 1000 Employees,2012,Government,State & Regional Agencies,Government,Unknown / Non-Applicable,-1
Data Engineer - Entry / Mid Level,-1,"Work with a great team on interesting projects customers
Gain more experience in AWS, Data, DevOps cloud operations
Got a working knowledge of AWS? We will teach you the cool stuff!

Itoc is seeking an up and coming Data Engineer to join our growing Data Team in Sydney.

This is an exciting role working with databases, data lakes, data warehouses, data transformation (Python SQL) and enabling AI/ML.

You will be implementing foundational, robust and production ready data platforms to enable business data-discovery, self-service, AI/ML functions across a range of client types and industries, allowing them to do more with their data.

You'll be responsible for:

Deploying data repositories such as lakes and warehouses.
Contribute to our growing portfolio of data solutions.
Ongoing optimisation and management of data platforms.
Development of transformational logic for data pipelines
Data evangelism. We want to show our clients how to follow the best practices for data.

Desired Skills and Experience

To take up the challenge, you will have a depth of skills and experience including:

1-2+ yrs of focused data experience working with SQL and/or NoSQL solutions
A solid education in Software Engineering or equivalent industry experience.
Anything Data focused preferred.
Ability to analyse business scenarios and associated data landscape to derive potential opportunities.
Strong foundation in Python and SQL
Working knowledge of APIs
Principle knowledge of the different relational database platforms and modern data storage techniques
Knowledge of the different aspects of data environments
Collect, store, process, verify consume
Experience with version management systems (such as GIT)
Working knowledge of AWS or another cloud platform - we will teach you the cool stuff.
Great communication skills, an ability to work closely with customers, developers and engineers and the confidence to present ideas in open forums.
Relevant tertiary qualifications and/or industry certifications.
Great communication skills, an ability to work closely with clients, developers and engineers and the confidence to present ideas in open forums.

While not required, a background in consulting and professional services is highly desirable.

Itoc Description

This is an exciting and challenging career opportunity to join the growing Sydney-based Data Team of a leading cloud solution provider where you will be given support to reach your long term career goals. You will be part of a team of cloud experts and will work in an environment of continuous improvement and learning delivering innovative cloud solutions across SaaS, online business and enterprise business.

On offer is a chance to join a team with a great working environment, in an organisation that values its employees and sees the value in ensuring they are engaged. Our team are clearly passionate about what they do, that's why we won the following awards:

Customer Obsession Partner of the Year 2015: ANZ Region
Customer Obsession Leadership Partner 2015: re:Invent

As an employer of choice Itoc offers competitive remuneration, training and development programs and a great working environment. We value a healthy work life balance.

The Perks

MacBook or Dell
Continuous internal learning that will provide training and career development opportunities
Working with a collaborative, social team and leveling-up your skills faster than you will anywhere else.
Quarterly social events

Itoc

Culture and smarts are important to us. Bring your secret sauce. This is no ordinary environment, you will work along some of the Cloud’s best. All engineers at Itoc must gain at least five AWS certifications. We work hard but we have fun.

Please note you must have full working rights in Australia and be available on-shore for face to face interviews.

No recruiters please.",4.0,"Itoc
4.0",Sydney,-1,1 to 50 Employees,2013,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Date: 01-Oct-2020

Location:
Melbourne, VIC, AU

Department:Description:
Technology discounts - from Apple HP Lenovo to Windows
Flexible work arrangements - work in a way that suits you best
Salary packaging - to suit your personal and financial circumstances

Do you want to work for one of the fastest growing data teams in Australia? Do you want to work on multiple data platforms and provide new solution offerings by leveraging cloud and big data technologies?

About the team

Big data information and analytics. Three words that spark apprehension in most businesses. But our team of experts are constantly curious and excited about combining our wonderful array of technological expertise to transform data into our clients most valuable assets making their work smarter. Our data consultants are supported with resources training and tools they need to excel at their work but also the freedom and power to create their own paths forward to make a difference.

As a Senior Consultant in Big Data you will work closely with the team and stakeholders to build and deliver a Cloud based vision for a next generation Big Data analytics platform with strong focus on data quality data security and deliver the systems that process huge volumes of data.

What will you typical day look like?

You will play a pivotal role in - Designing and producing high performing and stable applications to perform complex processing of massive volumes of data in a new cloud based architecture; Building real-time data processing applications which are integrated with business systems to enable value from analytic models to drive rapid decision making; Contributing to system architecture design for a data platform (including cloud-based structures both on and off premises data warehouse components and data lakes); this could cover a range of technologies various countries/locations and lines of business; Support data strategy or technology strategy definition programs including technology stack definition and target operating model requirements

Enough about us lets talk about you:
You are someone with:
Use of traditional data analytics tools and techniques (e.g. MSSQL Oracle MySQL) and ETL software (e.g. SSIS Informatica CloverETL)
Working in large scale cloud data solutions using platforms such as AWS or Azure or GCP will be a bonus.
Experience in scripting or programming (e.g. Python Java Scala C#)
Excellent verbal and written communication skills to adapt to technical and non-technical audiences.
Educated to degree level (or have equivalent experience)
Why Deloitte?

At Deloitte we create positively differentiated work experiences that enable our people to feel valued and achieve their full potential. We value difference and embrace people with diverse backgrounds and thinking styles. Knowing that people work best in different ways we are happy to discuss alternative arrangements if the working pattern you are looking for is not specifically indicated.",3.8,"Deloitte
3.8",Melbourne,-1,10000+ Employees,1850,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Engineer,-1,"Opportunity to grow the team
Period of growth
Intuitive app
S2M are working with a FinTech who have created a unique financial product to help thousands of people better manage their finance, and is currently scaling the company to the next level!

They are looking for a Data Engineer to join, and looking for someone who wants to be hands on, with opportunity to grow the team in future.

Role:

Looking for people with strong AWS experience. You will need passion for data and a cloud, through which you will help a rapidly scaling Australian FinTech establish their data infrastructure from the ground up.
5+ years’ experience as a data engineer within the data and analytics domain
A python 3.X aficionado who is very comfortable creating and orchestrating AWS data pipelines with nothing but code
Strong project delivery toolset experience in open source data integration tools
Experience with processing large volumes of complex data including visualisation and insights generation
Ability to define and develop data integration patterns and pipelines
Ability to assess complexity of data (volume, structure, relationship etc.)
Hands on experience working with different databases (RDBMS, NoSQL, Blob storage etc)
Hands on technical expertise setting up DevOps automation
Hands on experience working technologies/platform e.g. AWS, Dockers, Containers
Experience building data profiling and data cleansing frameworks
Technical reconciliation and reporting
Knowledge and experience in end-to-end project delivery, either traditional SDLC or agile delivery methodologies (or hybrid approaches)
Exceptional communication, documentation and presentation skills
If this sounds like you, get in touch today - kate.gabb@s2m.com.au
3167410agsdf",3.1,"S2M
3.1",Sydney,-1,Unknown,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Analysts,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is seeking experienced and qualified Data Analysts to join our IT team based in our corporate office in Birtinya (Sunshine Coast) or at our meat processing facility in Kilcoy.
Key Responsibilities:
A mixture of data analysis and commercial skills to source, blend and analyse data to gain insight and answer key commercial questions
Working with strategic leaders to define and model Key Performance Indicators, and assist in building forecasting models
Working closely with data engineers and BI developers to specify data pipelines and report visualisation
Drive the creation and implementation of data quality business rule including data definition, governance and quality assurance
About You:
To succeed in this role, you’ll need to bring the following experience and skills:
Proven ability to derive insight and knowledge from data using commercial expertise is a strong requirement
Strong SQL and Excel skills are essential, along with strong data analysis and commercial insights
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Effective people communicator - engage with stakeholders on reporting needs, interpret requirements into visual solutions and train/deliver the outputs to the stakeholders getting signoff of acceptance
Bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking

How to Apply:
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kilcoy,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Network Data Engineer,-1,"Min 6+ years of experience in the relevant technologies
Australian Driving License for visiting remote locations / Data Centre for day to day technical work.
Managing Network devices (switches, routers, firewalls, load balancer, and wireless technology)
Performing MACD activities for all network devices.
Supporting BAU operation activities.
Proficient in performing in-depth details of technical troubleshooting, cause and provide recommendation to the client for incidents causing extended network outage to client’s critical locations.
Provide exceptional network services in terms of network support, break-fix, design and consulting, new projects, implementation.
Configure, administer, and document firewall infrastructure.
Manage the firewall deployment, rules migrations, and firewall administration.
Supporting Cloud Migration Activities from traditional to AWS/Azure.
Setting up VPN tunnel with Cloud and 3rd Party network devices.
Integrating and upgrading existing ISP bandwidth with support from ISP Vendor.
Setting up VPN profiles for Users.
Installing hot fix and patches to mitigate the security devices from attacks and bugs.
Reviewing and fine tuning the firewall rules and NAT rules.
Documentation and change control.
Mentoring, Motivating and Guiding support teams
Technical skills:
o LAN
o Wireless
o WAN
o MPLS
o Routing protocols (OSPF,BGP)
o DMVPN
o Azure cloud Networking
o Network Security
Fortigate Manager / Analyzer / Firewall
Cisco ASA
Firepower FTD
Cisco Any connect
Site to Site VPN
F5 Load Balancing and Scripting iRule
Job Types: Full-time, Contract
Schedule:
8 hour shift
Experience:
Scripting: 5 years (Required)
Data Network: 5 years (Required)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Required)",3.6,"Total IT Global
3.6",Sydney,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Engineer - Processing & Analysis,-1,"Job Description:
Design,build and maintain the ingestion system to support various types of data(e.g. User behavior, RDS, NoSQL db and others) to be ingested to the data warehouse more timely and accurately
Translate data requirements into scalable technical data service with low latency and high concurrency
Design,build and maintain the batch or real time data pipeline in production using Hadoop big data technology
Analyze and improve efficiency, scalability, and stability of the system
Define and manage SLA,Data quality for all data sets in allocated areas of ownership
Requirements:
Minimum B.S. degree in Computer Science or a related technical field
2+ years of working experience in programming languages,such as Java,Scala,Python
Familiar with Hadoop, Spark and Flink data processing, experience of TB data processing experience is a plus
Familiar designing and operating of a robust distributed system is a plus
Understand data mining or machine learning
Excited to work intimately with data
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"SYNOPSIS:
Lead Data Engineer
Applications close Sunday 8 November 2020
Ongoing
Contact name: Shyni Sasikala
Phone: (02) 6249 9048
Email: Shyni.Sasikala@ga.gov.au

The Data Policy and Informatics section within the Digital Science and Information branch creates, implements, and promotes policies, platforms and tools that improve and support the quality, discoverability, accessibility, and general usability of Geoscience Australia’s science data products. The section consults with internal and external research, government and industry partners to establish collaborative data frameworks, architectures and models within Geoscience Australia (GA) and across broader national and international communities of practice. The section innovates, builds and maintains tools, systems, processes and governance that enable digital data management, cataloguing and open data delivery.
GA makes accessible a wide range of geoscientific and spatial data to a wide variety of stakeholders in multiple formats, and in recent years GA's data volumes have grown exponentially. GA is focussed on making its data and metadata assets accessible so that they can be used in machine to machine interactions for data analytics and other applications in environments that range from High Performance Computing (HPC), through high-end cloud servers, to mobile devices.
We currently have two opportunities for Lead Data Engineers in the Informatics team. The Lead Data Engineer is responsible for innovating and exploring new technologies that will advance GA’s science goals and maximise the uptake and use of GA’s science data. The Lead Data Engineer reports to the team’s Assistant Director but also works closely with other developers, data scientists and engineers within the Digital Science and Innovation (DiSI) branch, as well as diverse stakeholders both within and external to GA.",3.9,"Geoscience Australia
3.9",Canberra,-1,501 to 1000 Employees,2001,Government,Federal Agencies,Government,$100 to $500 million (USD),-1
Data Engineer,-1,"The Seven Network is part of Seven West Media, one of Australia’s most prominent media companies, with a market leading presence in content across broadcast television, online and in print. Comprising some of Australia’s most renowned media brands, SWM includes not just Seven Network and its affiliate channels 7two, 7mate, 7flix and BVOD offering 7plus, but also 7NEWS.com.au, The West Australian, The Sunday Times and more.
At Seven we are here to bring all Australians closer to the moments that move us - we’re first on the scene, with our finger on the pulse, on demand, in the moment. Together, we’re responsible for creating and sustaining authentic Australian engagement.
A new and exciting opportunity has opened for a Data Engineer to join the Audience Intelligence team. Based in Sydney and reporting to the Head of Data Enablement, you’ll be responsible for:
Implementation of end to end data solutions to support Data Strategy for the SWM group.
Work closely with the Data Solution Designers to develop and maintain scalable data pipelines and build out new file and API based integrations to address requirements from the various business stakeholders.
Collaborates with engineering, analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organisation.
Work on Data Preparation for analytics and data scientist team members and assist them from an engineering perspective in building and optimising the models including building the automation of the end to end workflows
Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.
Perform data analysis required to troubleshoot data related issues and assist in the resolution of production data issues.
Work effectively with vendors for successful delivery of projects and acceptance of the solution
Work on Delivery projects using Agile Software Development methodologies
We are looking for someone who has:
Bachelor's degree in computer science, computer engineering or other technical discipline is essential
Proven experience working as a digital analytics specialist
Extensive experience with digital analytics implementation (e.g. Google Analytics, Snowplow, Adobe Analytics) and BI processes and visualisation platforms
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience in ETL and building and optimizing ‘big data’ pipelines and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Experience with big data tools: Hadoop, Spark, etc., AWS cloud services: EC2, S3, Lambda and familiar with version control systems: Git
Strong coding skills with knowledge of Unix/Linux and scripting languages such as Unix Shell scripting, Python desirable
Experience supporting and working with cross-functional teams in a fast-paced environment.
Ability to multi-task and problem solve with changing demands and priorities
Ability to work under pressure to meet deadlines and detail oriented
Your success is our success: we will provide you with opportunities for you to keep learning and growing, enabling you to challenge and develop yourself. In return, we offer a benefits program that has something in it for everyone.
Seven West Media is an equal opportunity employer and we are committed to creating a diverse and inclusive workplace.
Recruitment Agencies: Seven West Media does not accept any unsolicited agency resumes and will not be responsible for any fees related to unsolicited resumes.
Advertised: 19 Oct 2020 12:00 AM AUS Eastern Daylight Time
Applications close:

Back to search results",2.5,"Seven West Media
2.5",Sydney,-1,5001 to 10000 Employees,1956,Company - Public,TV Broadcast & Cable Networks,Media,Unknown / Non-Applicable,-1
BICON Rules Engineer,-1,"APS 5 - $73,299 - $80,410 per annum plus superannuation
Biosecurity Plant Division
Canberra, ACT
Play an active role in managing biosecurity risk to Australia
Work in a motivated and professional team with a wide range of skills and backgrounds
Full training provided

Who we are
The BICON Content Development Team maintains and improves the Biosecurity Import CONditions database (BICON) content to allow external clients to understand and comply with their biosecurity obligations and internal clients to effectively manage biosecurity risk and regulate imports. We work collaboratively with internal clients to comprehend and implement their BICON content requirements and optimise the use of BICON to publish clear import requirements and onshore management support procedures to effectively manage biosecurity risk.

The Jobs
Key duties of these positions include:

working with business content (import and permit conditions) and import programs to understand and construct decision tree structures in the BICON database, in accordance with system design and authoring conventions
executing changes to import and permit conditions in alignment with service standards while complying with system rules and authoring conventions
providing technical advice through various formats on the most appropriate means of authoring BICON content to achieve import program and stakeholder objectives
using workflow management tools to maintain detailed records of changes to import conditions and key decisions
performing administrative tasks including system reporting, data analysis and scoping tasks for the BICON content change work program
contributing to the development and maintenance of instructional material, authoring conventions and courseware
clearly documenting and reporting system issues
developing and maintaining effective working relationships with internal and external stakeholders.

What we are looking for
Knowledge and experience
Experience working with complex IT systems.
Experience working collaboratively and as part of a team.
Knowledge of the role of biosecurity is preferred but not essential.

For additional information, please read the Job Description below.
Candidate Information Package docx Opens in new window",3.9,"Department of Agriculture & Water Resources
3.9",Australia,-1,5001 to 10000 Employees,-1,Government,Federal Agencies,Government,$500 million to $1 billion (USD),-1
Cloud Data Engineer,-1,"Job no: 509605
Work type: Permanent Full Time
Location: Melbourne, Canberra, Sydney
Do you embrace digital disruption?
Do you love solving complex problems, designing sophisticated solutions and building innovative technology?
Do you believe in creating powerful actionable insights from Data and Analytics?
Do you want to work in a diverse and flexible working environment?
KPMG is one of the most trusted and respected global professional services firms. Through depth of expertise, clarity of insight and strength of purpose we help our clients solve complex challenges, steer change, strengthen, transition and grow. We are a team based practice and this extends to our clients whom we work and collaborate with, in solving complex problems. Together, we design, innovate and implement, providing enduring advice that support our clients and the services they deliver. Our clients vary in size and come from a diverse range of sectors – all sharing in a common goal: to embrace change and deliver services that make Australia a better place. We are looking for talented individuals who would like to join us on the journey.
KPMG’s Digital Delta Team
We re-imagine and re-invent organisations to become world class digital enterprises using advanced technologies, data and human insights. We help organisations to embrace Digital Strategy, Artificial Intelligence (AI) & Cognitive, the Internet of Things (IoT), Data, Analytics & Modelling, Mobile App & Web, and User Experience (UX) & User Interface (UI) and more.
We work with clients to:
Formulate strategies that re-imagine organisations
Harness innovation from the 4th industrial revolution
Actioning insights from trusted data to consistently and quickly make clear decisions
Build adaptive organisations
Thrive as a connected enterprise – front, middle and back office
This is how you’ll contribute:
We are looking for ambitious Data Engineers who are passionate about helping clients define bold ambitions and deliver on them. Joining our team will take you on a journey of personal and technical growth and provide the opportunity to inspire confidence and empower change.
As a Data Engineer you are the designer, builder and manager of the information or ""big data"" infrastructure, preparing data for analytical or operational use. You will design, construct, test and maintain a data pipeline to pull together information from different source systems; integrating, consolidating and cleansing data; and structure it for use in individual analytics applications.
The KPMG Difference
Our people are focused on creating a diverse and dynamic environment that embraces and values differences. We value the variety of unique experiences, qualities and characteristics our people possess and we share and learn from each other.
We are proud to be consistently recognised as an employer of choice for women, and for our achievements in LGBT+ workplace inclusion.
Our commitment to ‘Flexibility’ allows our people to manage the changing demands of work, personal or family life. Explore the links below to hear our people share their experience @ KPMG:
Flexibility empowers wellbeing
Flexibility enables contribution to the community
Flexibility inspires technology & innovation
Flexibility supports family

Make KPMG the clear choice for your career and be Extraordinary!

Advertised: 09 Sep 2020 AUS Eastern Standard Time
Applications close:",3.8,"KPMG
3.8",Sydney,-1,10000+ Employees,1987,Subsidiary or Business Segment,Accounting,Accounting & Legal,$2 to $5 billion (USD),-1
Computer Network and Systems Engineer,-1,"Duties Include but are not limited to:
Tasks Include:
analysing, developing, interpreting and evaluating complex system design and architecture specifications, data models and diagrams in the development, configuration and integration of computer systems
researching, analysing, evaluating and monitoring network infrastructure to ensure networks are configured to operate at optimal performance
assessing and recommending improvements to network operations and integrated hardware, software, communications and operating systems
providing specialist skills in supporting and troubleshooting network problems and emergencies
installing, configuring, testing, maintaining and administering new and upgraded networks, software database applications, servers and workstations
providing network programming in support of specific business needs and requirements
preparing and maintaining procedures and documentation for network inventory, and recording diagnosis and resolution of network faults, enhancements and modifications to networks, and maintenance instructions
monitoring network traffic, and activity, capacity and usage to ensure continued integrity and optimal network performance
Skills and Experience Required:
Must have experience working in a Managed Service environment
Demonstrated experience in IT Networks and Data Centres
Understanding of systems and architectures to meet client needs
Experience in Help Desk including break / fix
Effective and timely documentation
Effective Task Management Skills
Be solution and outcome focused and willing to learn new technologies
Excellent communication skills with staff, clients and partners
Time management, ability to prioritise and deliver to schedule
Experience with N-Able and Connectwise desired
Open Cabling license desired
Job Types: Full-time, Permanent
Salary: $30.00 per hour
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,Trans-plant training,Canberra,-1,-1,-1,-1,-1,-1,-1,-1
Software Engineer (Data),-1,"If you are looking for an opportunity to make a real impact with smart people who are genuinely doing things differently then you've come to the right place! We're growing our data engineering capabilities and are looking for awesome data engineers to join our team.
With our diverse range of clients and projects, no day will look the same - but here's a great snapshot of what you'll be doing:
Work with some of the best Data Scientists and Engineers to deliver production-grade AI and Machine Learning systems as we deliver client projects from inception to production.
Consulting with our clients and working with them to build modern data systems using the 'best of' technologies and principles.
Advising clients on data strategy, architecture and technology.
Applying best software engineering practices in coding, monitoring and alerting, using CI/CD, TDD and cloud architectures.
Working over a wide range of big data tools and environments: not limited to; Apache Kafka, Spark, Python, Scala, Hive, Airflow, AWS EMR & Glue, GCP Dataproc & Dataflow, BigQuery, Snowflake, Redshift.
Who are we?
Glad you asked! We are Eliiza. Data science. Engineered for scale.
We are a passionate team of data scientists and engineers who apply data science and machine learning to solve real-world problems. Our mission is to create a bright future for Australian businesses and society in a world increasingly influenced by intelligent technologies.
We've created a culture that values diversity where people can truly be themselves! We care a lot about growing the Australian AI community in a positive direction, and we're doing several things to try and achieve that:
We provide opportunities for underrepresented groups to work in AI through our associate and intern programmes
We organise and participate in a range of community events, reading groups and meetups
We produce the AI Australia podcast
We blog about topics we care about
We stream brown bag sessions to the broader community
We're also part of Mantel Group's 'house of brands' which means it's not just the Eliiza team you'll work with, learn from and see at social events - there's another 230 of us across DigIO, Kasna & CMD Solutions!
So you're ready for something new?
We're keen to know more about you! Our team is made up of a range of people, with different experience across a huge range of data driven skill sets.
We'd love to hear from you if you have experience with:
one (or more) core language(s), ideally Scala, Python or Java
one (or more) cloud platforms, AWS, GCP, Azure
ETL/ELT concepts and technologies e.g. Data partitioning, Hive, Spark
streaming data concepts and technologies, ideally Kafka (Kinesis, Beam or Pubsub will do)
We'd be over the moon if you:
Experience with distributed/columnar databases (e.g. Snowflake, Big query, Redshift).
Experience with any of a variety of databases e.g. RDMS, NoSql, Columar, Distributed, Time series, Graph.
Knowledge of job orchestration and scheduling. Any experience with Airflow, Luigi or Oozie.
Experience with containers and container orchestration (Docker, Docker Compose or Kubernetes).
However, we value a diversity of skill-sets, and don't necessarily require that you're skilled with all of the above. If you feel you don't fit all the experience/skills listed above we still encourage you to apply or get in touch.
What's on offer if you join us?
We make sure you're always one step ahead by investing your learning and development, every year. We build our own training where it doesn't exist yet.
We hire smart people and get out of their way. By focusing on our five principles and not getting caught up in red tape, we trust you to get the job done.
You'll get all the tools you need - a new iPhone or Google phone, a new Macbook Pro or Dell, and a lot of branded swag!
But hold on, you mentioned a house of brands?
We certainly did! Mantel Group is an Australian-owned, 'house of brands' company with four technology businesses (Eliiza being one of them!) across Melbourne and Sydney. We're building a group of companies with open borders so we can support you to take on new skills without leaving an awesome team - we understand you won't have one job for life!
We may only be just two years old but Mantel Group has already been recognised #9 in the 2020 Best Places to Work in Australia and #4 in the AFR's 2020 fastest growing new companies.
Keen to chat?
Click ""Apply"" to share your details with our talent team, and we'll be in touch.
In the meantime, check out 'how we hire' to find out what's in store if you're successful and get to know us better by visiting our website and following Eliiza on LinkedIn.",-1,Eliiza,Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Infrastructure Engineer,-1,"Job Description:
Design and grow the Shopee data platform to support a variety of big data applications using open-source technologies including Kafka, Hadoop, Presto, HBase, Spark, Hive, Druid, and our own creations. Some examples include a real-time data streaming platform, a unified query platform, a cluster management system, and a machine learning platform
Dig into the source code of some open-source big data system to get the whole control and familiar with the details, configurations, designs and source code. Develop and maintain the internal release of big data systems and components as the business requirements.
Keep close and overall monitoring for all the deployments of the systems, maintain the system’s stability, improve the performance, discover the performance bottlenecks, tracking and troubleshooting, cost optimisation.
Requirements:
B. Sci. / Ms / PhD in Computer Science or a related technical field
Familiar with at least one of these languages: Java, Scala, Python, Bash under Linux / Unix. Scala is a plus
Familiar with the use and compute logical of SQL
Knowledge about the Big Data Infrastructure system technology like Distributed File System, Distributed Computing, Distributed Database will be a plus
Hands-on experiences Hadoop, Spark, Kafka, and/or Presto will be a plus
Love to use and develop open-source technologies
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"Work on an award-winning, international technology!
Endless career opportunities
An innovative, friendly team of 300+
This role will be focused on the development of our existing ClaimLogik line of products as well as working on our new cloud-first, modern suite of applications.

Intelligent Thought, our technology business is scaling and shipping our software globally. Already profitable, part of a much larger group business, with investors such as Macquarie Capital and Envest – we are all set to deliver textbook disruption to the Insurance Industry. The growth of the platform, of our customer base, and the increasing industry demand have led to the need for this role to help the team scale.

Our Philosophy
Give each employee a sense of purpose and an environment for them to connect the importance of their role to delivering a service that matters to our customers.
Challenge the ‘why’ of traditional claims processes.
Keep it simple – do only what brings value and what matters to the customer
Enable employee decisions, empower our people
Responsibilities:
Create, extend and maintain ETL pipelines to form our data lake, data warehouse and analytics platform (currently using the Microsoft Azure set of tools and service)
Help define the optimal data pipeline architecture
Influence the tool selection, platform selection, data architecture and strategy which will transform the business to be truly data-driven
Understand, analyse and size user requirements
Work with different parts of the business to provide them with the insights they need to deliver the best results
Skills & experience:
Degree or qualification in computer science or related
Advanced knowledge of relational database, including query authoring and query optimisation (MS SQL Server and PostgreSQL).
Experience building and optimising ETL pipelines
Experience designing complex data models
Experience working with cloud platforms (Azure or AWS)
Efficient time management and organisational skills
High attention to detail and accuracy
Effective communication skills to build strong working relationships; both written and verbal
Proactive and results-driven
Why Claim Central?
Claim Central Consolidated is a global insurance industry leader across, claims management, insurance technology and data and analytics. Currently operating in the United States, Australia, South Africa, Italy and New Zealand, we have pioneered digitally connected claims management services across the globe. Claim Central is a disruptor and thought leader in the industry and we were recognised as the Australian Financial Review’s 8th Most Innovative Company in Australia in 2016. This business is in a period of unprecedented growth, transitioning our technology and services into multiple geographies at a rapid pace. Our unique culture is based on teamwork, collaboration, trust, respect and performance. We also offer many benefits apart from our exceptional team culture; including flexible work arrangements, and continued professional development.

Be a part of this journey in a career-defining role.",-1,Claim Central,Matraville,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer - AI/ML,-1,"Our client provides services to a major industry across the country. The business is still early in it's days of technology development and the environment is greenfields in nature (no pun intended), effectively working like a start-up.

Their data and analytics team have worked and built leading and bleeding-edge technologies in this space and what they have created so far may be game-changing. From a machine learning perspective, the progress they have made to the business has already seen proven success in changing the future of an industry that will have positive consequences for all those involved.

You will have previously worked in a technical capacity in the data and analytics space and have experience working with an organisation where machine learning has been implemented, not just a concept that the business talks about having or the technology team would love to have. The commercial experience you will have had in the ML field will be proven examples of where you have affected the way a business or industry used to perform, to the changes that have come about from this.

Technically, you will have extensive experience in the Microsoft space - Power BI, Azure etc and you will have previously mentored and coached junior members of the teams you have been part of.

This is a rare opportunity in Brisbane where the business has truly embraced and funded projects across the ML space and would be a great chance for those in the Data Development/Data Engineering field, who are looking to move into a Data Scientist role in the future.

Please send your application through if you would like to know more.",4.0,"Emanate Technology
4.0",Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Solution designer/ ETL Engineer & Data Modeller,-1,"We are looking for a Qualified and Experienced Solution Designer to join our client for a period of 6 months with a view to extend.
You will work closely with team members and your contribution will range across gathering and analyzing information, developing and documenting improved processes and work instructions and experienced DWH Lead with skills in requirement analysis, solution designing, developing, testing and supporting ETL solutions.
A hands-on solution designer, data modeler and ETL developer for Data Warehousing and ETL application transformation projects using Informatica PowerCenter.
Knowledge on AWS, S3, Redshift, Informatica BDM, and related technologies.
Experience working with IPython, PySparks, AuCuMo, Airflow, Jenkins, Github, Athena, JIRA, Rally, Spectrum, Glue, Flyway.
Good exposure on Oracle PL/SQL, aware of DBA activities, writing and performance tuning of complex SQL queries.
Contract length: 6 months
Job Types: Full-time, Contract
Salary: $650.00 – $800.00 per day
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,nducive,Melbourne,-1,-1,-1,-1,-1,-1,-1,-1
"Data Engineer, Wollongong NSW or Mount Waverley VIC",-1,"Company Description
BlueScope is a technically advanced supplier of steel and steel products in Australia. We are an inclusive organisation and every day we showcase our technology and expertise throughout the world.

Job Description
We are looking for two Data Engineers to join our IT team, based in Wollongong NSW or Mount Waverley VIC. Use your experience in analytics to unlock business value, enabling use of big data for insights and decision-making.
Reporting to the Data Product Owner for our Australian Steel Products (ASP) business, this position will support strategic goals related to data. This will see you:
Gather business and technical requirements with the view to deliver outcomes;
Develop and implement end-to-end data collection, consolidation, modelling and visualisation solutions;
Document metadata in a dictionary and catalogue;
Ensure consumers of such information understand its accuracy, timeliness, quality and sensitivity, so that it is used appropriately; and
Identify opportunities to enhance analytics.
What are the benefits?
Work in a supportive and collaborative team environment whilst we embark on a journey to transform the way our business uses data!
Our systems landscape is broad and diverse. You will be encouraged to think creatively to develop data solutions which solve real business problems.
Working in this role you will enjoy:
the chance to learn more about data science;
salaried remuneration with attractive superannuation options;
the opportunity to participate in a performance incentive scheme; and
access to further development and career opportunities with BlueScope.
Who are we looking for?
We welcome applications from professionals with experience in data analytics and/or programming. Supported by your knowledge of project delivery methods (e.g. Agile), you will demonstrate:
experience with data mining, wrangling, mapping and visualisation techniques (e.g. Azure Data Factory, Databricks and/or DevOps etc.);
well-developed ability in gathering business and technical requirements;
skills in developing and implementing collection, consolidation, modelling and visualisation solutions; and
a passion for sharing your knowledge and desire for ongoing professional development.

Qualifications

null

Additional Information
We're proud to have been named an Inclusive Employer for 2019–2020 by the Diversity Council of Australia. We believe that our people are our strength. Having a diverse and inclusive workplace enables us to improve our capability and ensure continued, sustainable success.
We know that workplace flexibility can mean something different to everyone. Under our B-Flex initiative all of our roles have some degree of flexibility. We encourage you to discuss your needs with us.
Applications close Sunday 25th October 2020.",3.3,"BlueScope
3.3",Wollongong,-1,201 to 500 Employees,-1,Company - Private,Construction,"Construction, Repair & Maintenance",$100 to $500 million (USD),-1
ETL Data Engineer,-1,"ETL Data Engineer

Join a team that’s changing how Australia lives, works, plays and grows
We want you to be the best version of you

Work with innovative teams and explore new technologies to help solve real-world problems.

A typical day as a Data Engineer

ETL / Big Data Engineering professionals will be responsible for guiding the full lifecycle of a Data solution, including:
Working in highly client-facing roles to contribute throughout the end-to-end delivery lifecycle of complex and large-scale digital solutions
Use case and business case development
Support existing and new applications utilizing in-depth technical and data knowledge. Troubleshooting complex issues and providing advisory services to improve the client’s data landscape
Help to streamline and simplify the clients’ complex data landscape by integrating different applications and data architectures
Implementation from requirements analysis, platform selection, digital architecture design, application design and development, testing, and deployment
Interstate travel may be required

Basic qualifications:
Bachelor’s degree
Experience across systems integration, information management, data management and architecture, and business analytics
Experience with being in a team focusing on large-scale, multi-release information centric projects
Experience with waterfall and agile delivery and run / application support functions
Part of a team working on End to end implementation of at least 1 big data project

Preferred Skills:
Hand on experience in Data warehousing using ETL tools such as DataStage, Autosys and TeraData
Hands on experience in ETL job development with multiple stages like sequential file, Transformer, Lookup, join, sort and Database stages.
Strong hand on skills in design, development and implementation of various data remediation, Data migration, data integration techniques.
Strong hand on data modelling experience.
Strong hands on experience in database performance tuning including complex query optimizations and physical database tuning using Teradata.
Understanding of architectural designs and strategy related to data migration, data cleansing, data quality and data consolidation.
Proven data analysis, requirement gathering and problem-solving skills
Exposure to Unix environment and shell scripting.
Experience in Banking and Financial services industry
Desirable: Knowledge of cloud computing infrastructure (e.g. Amazon Web Services EC2, Google Cloud, Microsoft Azure)
About Accenture

Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. We combine unmatched experience and specialized capabilities across more than 40 industries — powered by the world’s largest network of Advanced Technology and Intelligent Operations centers. With 513,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises. Visit us at www.accenture.com.

Accenture is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, marital, domestic or civil partnership status, sexual orientation, gender identity, or any other basis as protected by applicable law.

Vera Goga is the Recruiter managing this role. As the team experience high volumes of applications, we appreciate your patience to allow for a fair and timely process.",3.9,"Accenture
3.9",Sydney,-1,10000+ Employees,1989,Company - Public,Consulting,Business Services,$10+ billion (USD),-1
Student Engineer,-1,"The candidate will have the ability to:
Undertake onsite inspection to collect asset condition data based on the relevant engineering standards and technical guidelines;
Undertake desktop analysis to evaluate the condition and performance of the assets;
Provide the appropriate information, advice, engineering input and support services for the sustainable management of Council’s stormwater and transport networks.
Qualifications:
The successful candidate will be enrolled in a Bachelor of Engineering with a minimum of two years completed.
Position Number: 100678
Position Hours: Fixed term (3 months), hours will be negotiated with the successful candidate, maximum of 75 hours per fortnight.
Salary: Schedule A, Salary Point 4.0. $28.64 per hour ($55,853.45 per annum, pro-rata) in accordance with Glenorchy City Council’s Enterprise Agreement 2016
Please note that all successful applicants will be required to provide a current National Police Check prior to commencement of employment.
For further information on this position, contact Patrick Marshall, Senior Civil Engineer on (03) 6216 6800.
How to apply: Applications for this position must be lodged on this submission site or on the Glenorchy City Council website www.gcc.tas.gov.au - Careers page.
To be considered for this role, all applicants must address the key selection criteria in the and provide a current resume. A copy of the position description can be found by clicking the below hyperlink or on the Glenorchy City Council website.
Applications close at 8pm on Sunday, 1st November 2020
- Student Engineer",4.0,"Glenorchy City Council
4.0",Glenorchy,-1,501 to 1000 Employees,-1,Government,-1,-1,Less than $1 million (USD),-1
Data Engineer involving DevOps,-1,"Data Engineer involving DevOps
Axiom Technologies is an Australia based entity with the history of providing Managed IT solutions to medium to large scale enterprises globally. Please visit our website for more information about what we do at www.axiomtechnologies.com
Axiom Technologies is an Equal Opportunity Employer and encourage applicants from all backgrounds and gender to apply, including, Aboriginal and Torres Strait Islander candidates
Job Requirements:
8+ years IT experience, with at least 5+ years of “Data Engineer/Deveoper” focused titles/roles,
Data Tools: Hands on experience with Apache Beam.
Testing: Hands on experience with automated testing activities/outcomes
DevOps: Experience with the processes involving Microservices facilities for artifacts developed
Platform/OS: Mid-range/Unix
Languages: Unix (Shell) Scripting/commands, SQL, Python
File formats: Text, CSV, Parquet, JSON, XML
Scheduling: Jenkins, Airflow
Auto Scripting: Designing/creation of scripts for repetitive activity. E.g. Unix scripting/SQL
Big data: Exposure to Data Lake Concepts, Hive (Schema), HDFS
Source Control tools: GIT
Delivery Models: Agile, Scrum
Ingestion Design: Create/assess Source/Target data mapping designs
Frameworks: Development and delivery frameworks
Activity Reporting/Repository: Jira, Confluence.
Quality: Accuracy and attention to detail
Industry: Financial Services/Banking
Solutions: Define solutions from High level to detail design to address automating ingestion activity. Facilitate/confirm requirements from product owners, business team members and technical associates,
Process Automation: Automating processes in file management, testing data in files, analysis and design, configuration management.
Script Automation: Ability to design/create scripts to automate/improve data copy/migration/ETL for any repetitive activity.
Languages: Java, Python
Scheduling: Control-M
Databases: Relational. E.g. POSTGRESS, Oracle – as a ETL developer
File Formats: Mainframe – experience with referencing its data formats/copybooks
Big data: Experience referencing/using Hive (Schema) to access data in HDFS
Metadata management tools: MDM, EDC and Axon
Performance: Assess, recommend, improve mappings, SQL queries, Batch feeds
Automation Tools: Other tools that may add value to an automation program and generally support development. E.g. API, REST, JDBC, Webservices, Message Queues/Load balancer,
Cloud: Experience with processing of data files to be ingested/stored in the Cloud, preferably with AWS.
Prod Support: Experience in a production support role performing root cause / impact analysis – under time constraints
Experience in a similar role
8+ Years
What next?
If you are looking for that next challenge in your career and wish to apply for this role, please forward your resume to careers.au@axiomtechnologies.com",2.0,"Axiom Technologies
2.0",Melbourne,-1,1 to 50 Employees,-1,Company - Private,Industrial Manufacturing,Manufacturing,Less than $1 million (USD),-1
Data Engineer,-1,"About the Role
We are on an exciting digital journey so it’s a great time to join ME! We are seeking a Junior Data Engineer who enjoys rolling up their sleeves, learning and growing. As part of our Enterprise Data Team, you will ensure fit for purpose data warehouse solutions are built for use across the bank and by utilising best practise ETL standards, whilst ensuring the data is trusted by our BI developers and key business consumers. Oh, and you’ll get to work on Microsoft technology stack too!
You will be involved with investigating data issues, keeping data feeds flowing and collaborating with different projects across the bank to deliver quality data solutions. How important does that sound? What’s even more important is this role contributes directly to our overall business strategy through the provision of data to enable analytics & reporting, as well as supporting business and decision system processes.

About You
You’re naturally a highly motivated and energetic person who thrives in a dynamic, ever-changing collaborative team environment. Ideally you have previous experience as an ETL developer, Data Engineer or a BI developer, and if you have a degree in computer science or similar it would really put you ahead of the rest.

With your knowledge of SQL coding, data modelling, understanding of data warehouse concepts, plus experience of working on complex ETL solutions, you’re ready to expand your horizons and launch your career into the world of IT at ME.

About ME
We’re not like other banks.
ME was created by the industry super funds to be different from the pack – with a core purpose to help all Australians get ahead financially – no conditions, asterisks or exceptions. And we know that looking after customers starts with taking care of our people.
We believe everyone deserves the same opportunities in life, regardless of gender or identity, sexuality, ethnicity, religion or disability ‒ with internal affinity groups.
Perk ME up
Once you get your feet in the door at ME, we’ll put them both in your very own ME-branded Converse shoes. You’ll also get the following financial, health and fun perks when you join the team:
4U Extras portal (discounts and cashback on 100s of items including cinemas, shopping and gym memberships
10% Myki discount
Purchased Leave programme
Internal wellness programme (Mindfully ME)
Professional education through LinkedIn Learning
Novated Leasing
Professional membership reimbursements
Health checks
Financial education (To help you manage your money smarter)
LGBTIQ+ and Women at ME affinity groups

I want those Converse shoes (and the role)
Can’t see a closing date on the advert? That’s because we’re pretty efficient here at ME and we may start looking at applications sooner rather than later, so if this role sounds like your jam, be sure to apply by submitting your resume today.

Should an applicant be the preferred candidate, background checks (including police checks, reference checks, ASIC banned and disqualified persons and bankruptcy checks) will be completed prior to the candidate's employment being confirmed. The outcomes of the background checks do not automatically bar candidates; however will be assessed against the inherent requirements of the job.
Back Share
Apply Now",3.0,"ME Bank
3.0",Melbourne,-1,501 to 1000 Employees,-1,Company - Private,Banks & Credit Unions,Finance,$100 to $500 million (USD),-1
Software Engineer - Machine Learning/Data Science,-1,"Zendesk is looking for a Software Engineer - Machine Learning/Data Science for a full time position in our Melbourne office.
As part of our engineering team, you will work at a scale where the challenges start to get seriously interesting. Our global engineering team is widely dispersed over the world, with people across nearly every continent. You will get a chance to do cool things with a diverse bunch of people while working in the Melbourne office that is home to Zendesk’s first machine learning (ML) research team.
The Data Science Team, together with Data Engineering, have built Satisfaction Prediction, Answer Bot and Content Cues — products that use Machine Learning (ML) and Artificial Intelligence (AI) to help our customers work more efficiently.
What you get to do every day:
We’re currently looking for someone to join our team as we research, develop, and productionise Machine Learning and Deep Learning models. In addition to frequenting Melbourne’s finest purveyors of coffee, ramen, and bulgogi, you may find yourself:
Building machine learning models including neural networks in TensorFlow
Writing and deploying production-grade Python
Querying and constructing datasets in AWS Athena, Spark
Evaluating and responding to real-world model performance
Scaling your ML to millions of predictions per day
Presenting your work to a broader audience
Watching your algorithm help Zendesk’s end-users
What you'll bring to the role:
A strong foundation in a quantitative discipline (e.g. machine learning, statistics, bio/eco/etc-informatics, econometrics, etc) is critical for this position. While experience in deep learning and natural language processing would be beneficial, your best qualities are:
dedication to continuous learning
collaborative work attitude
strong communication skills
You should also be comfortable with at least one programming language, such as Python, R or Scala.
Application Deadline: 18/11/2020
Job Types: Full-time, Permanent
Salary: $85,000.00 – $110,000.00 per year
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Temporarily due to COVID-19",4.5,"Zendesk
4.5",Melbourne,-1,1001 to 5000 Employees,2007,Company - Public,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),-1
Software Engineer (Machine Learning),-1,"About the Role
AdelaideMRI is building a medical reporting tool. We require an engineer to work primarily on machine learning projects to improve reporting speed and report comprehensiveness.
You will perform data analysis of medical report datasets and image datasets to infer sentence recommendations, image classifications, or other actionable results for the doctors.
Skills and Experience
Background in machine learning or image processing
Qualifications in Computer Science, Software Development or Engineering or equivalent experience
Bonus points for Python
No prior medical knowledge is required.
This position offers flexible hours and work arrangements.
Job Type: Full-time
Experience:
Software Engineering: 1 year (Preferred)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Yes",-1,Adelaide MRI,Australia,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Hey there, we’re PEXA!

We started as an idea: to deliver a single, national e-Conveyancing solution. We collaborated with the industry to create a national electronic lodgement and settlement platform: PEXA. From our humble beginnings, we’ve now grown to more than 320 employees across 5 different states. We’re still expanding at a rapid rate and constantly challenging ourselves to create great experiences for our members as they transition to fully digital conveyancing.

Why become a PEXArian?

Great question! Being a PEXArian is so much more than just a job. We are passionate, motivated & unashamedly enthusiastic at PEXA - we love what we do and we’re proud to admit it! Creating brilliant member experiences wouldn’t be possible if we didn’t also strive to create an amazing employee experience. Alongside our members, our employees are at the heart of everything we do.
Here’s a snapshot of what your life at PEXA could look like:

Your growth:
We encourage you to hit your personal and professional Learning & Development goals with our tailored programs and tools.

Your wellness:
We care about your holistic well being - a fully stocked kitchen, four wellness days, a $250 wellness subsidy as well as lunch and learn sessions to support your financial well being.

Your work/life blend:
We know that work is just one aspect of your life, we want to help you create your ideal work/life blend, rather than squeezing in life around work.

Your family:
With a range of benefits aimed at supporting your family including access to a subsidised school holiday program, extended parental leave and flexi-time to support your return to work, superannuation payments for unpaid parental leave for primary carers and a childcare allowance for pre-primary aged children, when we say, ‘welcome to the family’, we really mean it!
The impact you'd drive:
The successful candidate will be responsible for developing, and maintaining infrastructure to support the delivery of new and existing products. They will also be contributing to establish the rules and frameworks for obtaining the required approvals for new products.
On day one we’d love you to have:
Experience with Python, Spark
Event streaming/sourcing with Kafka or AWS Kinesis
Experience with data structures, formats and data security best practices
AWS experience (e.g CloudFormation, S3, ECS, Lambda, SQS, IAM, KMS, DynamoDB, Glue, Athena)
Query construction and optimisation (e.g. SQL, Elasticsearch, Splunk, DynamoDB)
Git, version control practices, and continuous integration/delivery servers
PyUnit and unit testing frameworks
Production release cycles and maintenance
Collaborating with technical and non-technical teams
Even better:
Agile methodology/delivery
GraphQL
Modern frontend technology (e.g. ReactJS, TypeScript)
Machine learning frameworks and tools (e.g. TensorFlow, PyTorch)
OAuth 2, SAML 2, JWT
Data visualisation and exploration tools (e.g. Jupyter notebooks, Tableau)
AWS SageMaker
Sounds like you?
If this role sounds like you, apply today to have your application reviewed ASAP!",3.9,"Property Exchange Australia Limited
3.9",Melbourne,-1,201 to 500 Employees,2010,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Ongoing position
Full time
Based in Sydney, NSW
Who we are
Australian Red Cross is part of the world’s largest humanitarian organisation. Our aim is to improve the lives of the most vulnerable people in Australia and across our region.
About the role
The Data Engineer role will sit within the Data and Integration Squad in IT and will own (design, implement and support) the AWS Big Data technologies such as the Data Lake and Data Warehouse and support the organisation in growing the data analytics capabilities at Red Cross. In addition to this, the data engineer role will also administer the Power BI tool and support the implementation of the data mastering capability.
What you will bring
Experience building and optimizing data pipelines, architectures and data sets.
Experience in dimensional modelling and building data vaults
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with structured, semi-structured and unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Why work for us?
Work for purpose and know that your work assists Red Cross support and empower people and communities in times of vulnerability.
Generous salary packaging options available that can increase your take home pay.
Further information
To find out more about this opportunity please see the position description below or contact Sharath Kumar Gurram on 02 8651 8839.
Position Description: Position Description - Data Engineer .pdf
Applications for this position will close at 11:55pm Thursday, 5 November 2020.",4.1,"Australian Red Cross
4.1",New South Wales,-1,1001 to 5000 Employees,-1,Nonprofit Organization,Industrial Manufacturing,Manufacturing,$500 million to $1 billion (USD),-1
Junior Fullstack Data Engineer (Python and React),-1,"Formbay is the leading Renewable Energy Certificate Trading company in Sydney. We provide Digital Workflow and Compliance solutions in the renewable energy industry and document processing.
Thanks to our meteoric growth and our commitment to be the best at all we do, we've identified the need to bring on board a new Junior Fullstack Data Engineer.
Reporting to our Principal Machine Learning Engineer, you will help build Machine Learning pipelines for our existing Digital Workflow and Compliance solutions to automate fraud detection and document processing over terabytes of photographic and documentary data – including documents, photos, GPS data and aerial/satellite photography.
Our stack is based on Python, JavaScript, Dask, Tensorflow, CUDA, Nix/NixOS, AWS, Docker, PostgreSQL and more – familiarity with these applications will give you a leg-up on the competition.
Our ideal candidate will have the following competencies:
SQL
Python
JavaScript/TypeScript
Our candidate must also be comfortable working with Linux.
Located a stone's throw away from the Queen Victoria Building in Sydney's bustling CBD, we are centrally-located with easy access to public transportation, bars, cafes and fine dining.
Formbay will provide flexible working hours, a generous remuneration package and the opportunity to work on a world-first software solution are what we can offer you. Free, twice-weekly gym sessions and really, really good coffee are also available.
No hiring/recruitment agencies need apply.",5.0,"Formbay
5.0",Sydney,-1,1 to 50 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is an experienced and qualified Data Engineer to join our IT team based in Birtinya.
Key Responsibilities:
Create and maintain data pipelines and or ETL scripts
Create and maintain data integration including API and Batch interfaces
Performed detailed data analysis
Create and maintain corporate data models
Create and maintain data visualization using Qlik.Sense , PowerBI or Simliar Toolset
Experience in defining, building and maintaining data virtualization and/or star schema data warehouses
Maintain, tune and optimise database, integration and visualisation toolsets
ABOUT YOU:
To succeed in this role, you’ll need to bring the following experience and skills:
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Excellent communication skills both oral and written, with an ability to bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking
Experience with data analysis and modelling will be beneficial

How to Apply
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kawana Waters,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Graduate Data Science / Engineer,-1,"The NRMA is an organisation looking to the future, and right now, we are on the lookout for people who can help us reach our goal: to continue to shape the way Australians move, for the next 100 years and beyond. www.mynrma.com.au.
Everyone new to the team, along with our current staff, will temporarily work from home until it is safe to return to our offices. All interviewing and on boarding will be done virtually due to COVID-19.


Your opportunity
As Graduate Data Scientist or Engineer you will be part of the Data Engineering team delivering cloud data transition program for business initiatives and supporting the entire data platform build.
Your key responsibilities will be to:
Implementing Concepts of Data Warehousing, Data Mart creations within Cloud
Use of SQL for data analysis and insights
Building AI/Machine Learning prototype for implementing and supporting existing algorithms
Data Analytical reports build, using different tool sets


Requirements for Success:
Relevant Degree - Computer Science, Computer Engineering, Software Engineering, Data Science
Excellent SQL skills and demonstrated working knowledge in Python
Demonstrated understanding in data structure and algorithms.
Knowledge and concept of data warehousing methodologies
Any reporting tools experience Tableau or Oracle Analytics Cloud, Looker is desirable
Exposure to Google/AWS/Azure/Oracle any cloud based platforms is desirable
Good communication and interpersonal skills

If you have the required skills and the passion to join our high performing team, please apply today.

Employee Benefits
To ensure our employees feel valued, empowered and celebrated we provide a range of employee benefits including:
50% discount on all NRMA insurances
Free Roadside Assistance
12 weeks paid primary and 4 weeks paid secondary parental leave
Free NRMA Blue Membership
At the NRMA Group, we are People Moving People and diversity and inclusion are part of our DNA. Together, we continue to build an inclusive culture that encourages, supports and celebrates the diverse voices of our employees. It fuels our innovation, promotes flexible ways of working and connects us closer to our members and the communities we serve.",2.5,"NRMA Motoring & Services
2.5",Sydney,-1,501 to 1000 Employees,-1,Nonprofit Organization,Casual Restaurants,"Restaurants, Bars & Food Services",$500 million to $1 billion (USD),-1
Data Centre Engineer,-1,"We are a leading world group that provides low-carbon energy and services. To tackle the climate emergency facing us all, our aim is to become the world leader in the zero-carbon energy transition ""as a service"" for our clients – particular for companies and regional authorities. We use our expertise in our key business areas (renewables, gas, services) to provide competitive and bespoke solutions.
The Data Centre Engineer will be employed as part of a 24/7 ongoing shift to coordinate and monitor third party service providers, maintain the data centre facilities and infrastructure plans, coordinate the implementation of customer requests within the data centre and monitor systems, all in accordance with the Contract KPIs and SLAs.
Coordinate and monitor third party service providers for regular maintenance & testing, service faults & call outs, ensuring works are performed in accordance with Contract SLAs
Monitor and maintain the data centre facilities and infrastructure plans and documentation, including electrical, mechanical, hydraulics, fire and BMS/EMS systems
Coordinate the implementation of internal and external customer requests within the data centre
Perform scheduled plant checks and minor maintenance works
Ensure all Work Order requests are raised and closed in a timely manner
Conduct inductions for staff, vendors and contractors
Ensure all work permits for vendor works are raised and closed
Perform inventory checks on all equipment and critical spares

Qualifications
The selected candidate must be able to demonstrate:
Electrical or HVAC background, or Graduate Electrical or Mechanical Engineer
Passionate about quality work and career minded looking for a new challenge
Can commit to a day and night shift roster (2 days of day shift, then 2 days of night shift, 4 days off)
Ideally able to commence asap
As part of carrying out the duties of this role, it is mandatory to hold Australian Citizenship.

If you are interested and meet the selection criteria apply with an up-to-date resume via the apply instructions on this website.

ENGIE Services is an EEO employer, where all applicants are treated with fairness and respect and have equal access to the opportunities available.

We will not be engaging in the services of a recruitment agency to fill this vacancy and therefore request all interested candidates apply directly to this advertisement.

Job
: Maintenance
Primary Location
: Oceania-Australia-New South Wales-Erskine Park
Organization
: ENGIE Services Australia and New Zealand
Schedule
: Full-time
Nature of Responsibility
: Senior operational / administrative role
Job Posting
: Sep 11, 2020, 6:29:59 AM",3.7,"ENGIE Services Australia & New Zealand
3.7",Sydney,-1,5001 to 10000 Employees,1995,Company - Public,Energy,"Oil, Gas, Energy & Utilities",$2 to $5 billion (USD),-1
Senior Data Engineer,-1,"Senior Data Engineer, Temporary, SYDNEY - McKell

Job Title: Senior Data Engineer

Salary: SNSW Grade 9/10 - The package includes base salary range of $111,806 to $134,667, plus employer's contribution to superannuation and annual leave loading.

Location: Head Office – Haymarket

Employment Status: Temporary through till 30th June 2021


About Service NSW:

Service NSW is making it easier for people and businesses across NSW to access government services. The role designs, builds and analyses complex data from multiple sources to identify revenue, process and business improvement opportunities; providing new information and insights to the business to inform planning, continuous improvement and performance.

About the Role

We are currently seeking to appoint a Senior Data Engineer to deliver expert advice and services in the design of a Single View of Customer and data-related services to support the achievement of business outcomes and strategic goals. We support flexible working practices with staff working remotely during this time.

In this role you will:

Design, build and support a modern data platform based in AWS and vendor technologies.
Provide expertise on data modelling for Graph data model and Customer Data Platform (CDP).
Create data pipelines, load, transformation and reporting workloads in AWS.
Work with the latest data engineering technologies like Apache Kafka, AWS Kinesis, AWS Neptune, AWS Glue and AWS Athena.
Contribute to the design and decision-making of the right tool or platform for the job according to requirements.
Provide expert advice and guidance on data quality and data engineering best practices.
Support a “bigger than you can imagine” scale of data in production environments.
Design, develop and support a metrics-driven reporting solution and a meaningful business intelligence platform.
Document the solution design and support procedures of solutions.
Produce reports, visualisations and recommendations to answer complex business problems that are presented in the most appropriate format to ensure clarity for target audience.
Analyse and define new process improvement opportunities to support continuous improvement and business outcomes; providing advice to stakeholders, on ways to improve the efficiency and reliability of data products and services.
Be very responsive to the information needs of the business by corresponding to customers in a timely manner and provide support/solutions to issues raised.
Troubleshoot and perform root cause analysis on production issues. Identify and implement long term solutions to problems. Perform scheduled maintenance, release deployment and production support activities after business hours, from time to time.
Liaise with internal and external customers to discuss and gather requirements, solutions etc. and maintain a good working relationship with the stakeholders.


Skills and Experience Required:

Solid experience with workflow technologies designing and building data pipelines, data models and data stores.
Experience working within and an understanding of Amazon AWS ecosystem, including security and performance tuning.
Hands on experience working with different types of databases, with focus on Graph and NoSQL databases.
Experience with data streaming required. Having used Kafka and related technologies is an added advantage.
Sound knowledge and experience working with batch processing, data extraction and API integration.
Hands on experience with at least one programming language: Java, Python or scripting.
Demonstrated experience working in an Agile based, fast paced, complex environment within cross-functional teams.
Experience developing systematised insights, data analytics and reporting solutions is an added advantage.
Experience with interactive visualisation of data insights is an added advantage.


Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Salary Grade 9/10, with the base salary for this role starting at 111,806 base plus superannuation

Closing Date: 6th November at 9:59am - applications will be reviewed on a rolling basis, applications may close early or extend

Please apply online, direct applications submitted via email will not be considered.

The Department of Customer Service is proud to be an EEO Employer who are fully focused on equality and believe deeply in diversity of all identities making us different and a true reflection of our NSW customers. As an inclusive workplace, we support various employee resource groups, practice flexible work and workplace adjustment.

If you do require an adjustment during the recruitment process, please notify us on your application form.",3.2,"Service NSW
3.2",Sydney,-1,501 to 1000 Employees,2012,Government,State & Regional Agencies,Government,Unknown / Non-Applicable,-1
Data Engineer - Entry / Mid Level,-1,"Work with a great team on interesting projects customers
Gain more experience in AWS, Data, DevOps cloud operations
Got a working knowledge of AWS? We will teach you the cool stuff!

Itoc is seeking an up and coming Data Engineer to join our growing Data Team in Sydney.

This is an exciting role working with databases, data lakes, data warehouses, data transformation (Python SQL) and enabling AI/ML.

You will be implementing foundational, robust and production ready data platforms to enable business data-discovery, self-service, AI/ML functions across a range of client types and industries, allowing them to do more with their data.

You'll be responsible for:

Deploying data repositories such as lakes and warehouses.
Contribute to our growing portfolio of data solutions.
Ongoing optimisation and management of data platforms.
Development of transformational logic for data pipelines
Data evangelism. We want to show our clients how to follow the best practices for data.

Desired Skills and Experience

To take up the challenge, you will have a depth of skills and experience including:

1-2+ yrs of focused data experience working with SQL and/or NoSQL solutions
A solid education in Software Engineering or equivalent industry experience.
Anything Data focused preferred.
Ability to analyse business scenarios and associated data landscape to derive potential opportunities.
Strong foundation in Python and SQL
Working knowledge of APIs
Principle knowledge of the different relational database platforms and modern data storage techniques
Knowledge of the different aspects of data environments
Collect, store, process, verify consume
Experience with version management systems (such as GIT)
Working knowledge of AWS or another cloud platform - we will teach you the cool stuff.
Great communication skills, an ability to work closely with customers, developers and engineers and the confidence to present ideas in open forums.
Relevant tertiary qualifications and/or industry certifications.
Great communication skills, an ability to work closely with clients, developers and engineers and the confidence to present ideas in open forums.

While not required, a background in consulting and professional services is highly desirable.

Itoc Description

This is an exciting and challenging career opportunity to join the growing Sydney-based Data Team of a leading cloud solution provider where you will be given support to reach your long term career goals. You will be part of a team of cloud experts and will work in an environment of continuous improvement and learning delivering innovative cloud solutions across SaaS, online business and enterprise business.

On offer is a chance to join a team with a great working environment, in an organisation that values its employees and sees the value in ensuring they are engaged. Our team are clearly passionate about what they do, that's why we won the following awards:

Customer Obsession Partner of the Year 2015: ANZ Region
Customer Obsession Leadership Partner 2015: re:Invent

As an employer of choice Itoc offers competitive remuneration, training and development programs and a great working environment. We value a healthy work life balance.

The Perks

MacBook or Dell
Continuous internal learning that will provide training and career development opportunities
Working with a collaborative, social team and leveling-up your skills faster than you will anywhere else.
Quarterly social events

Itoc

Culture and smarts are important to us. Bring your secret sauce. This is no ordinary environment, you will work along some of the Cloud’s best. All engineers at Itoc must gain at least five AWS certifications. We work hard but we have fun.

Please note you must have full working rights in Australia and be available on-shore for face to face interviews.

No recruiters please.",4.0,"Itoc
4.0",Sydney,-1,1 to 50 Employees,2013,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Date: 01-Oct-2020

Location:
Melbourne, VIC, AU

Department:Description:
Technology discounts - from Apple HP Lenovo to Windows
Flexible work arrangements - work in a way that suits you best
Salary packaging - to suit your personal and financial circumstances

Do you want to work for one of the fastest growing data teams in Australia? Do you want to work on multiple data platforms and provide new solution offerings by leveraging cloud and big data technologies?

About the team

Big data information and analytics. Three words that spark apprehension in most businesses. But our team of experts are constantly curious and excited about combining our wonderful array of technological expertise to transform data into our clients most valuable assets making their work smarter. Our data consultants are supported with resources training and tools they need to excel at their work but also the freedom and power to create their own paths forward to make a difference.

As a Senior Consultant in Big Data you will work closely with the team and stakeholders to build and deliver a Cloud based vision for a next generation Big Data analytics platform with strong focus on data quality data security and deliver the systems that process huge volumes of data.

What will you typical day look like?

You will play a pivotal role in - Designing and producing high performing and stable applications to perform complex processing of massive volumes of data in a new cloud based architecture; Building real-time data processing applications which are integrated with business systems to enable value from analytic models to drive rapid decision making; Contributing to system architecture design for a data platform (including cloud-based structures both on and off premises data warehouse components and data lakes); this could cover a range of technologies various countries/locations and lines of business; Support data strategy or technology strategy definition programs including technology stack definition and target operating model requirements

Enough about us lets talk about you:
You are someone with:
Use of traditional data analytics tools and techniques (e.g. MSSQL Oracle MySQL) and ETL software (e.g. SSIS Informatica CloverETL)
Working in large scale cloud data solutions using platforms such as AWS or Azure or GCP will be a bonus.
Experience in scripting or programming (e.g. Python Java Scala C#)
Excellent verbal and written communication skills to adapt to technical and non-technical audiences.
Educated to degree level (or have equivalent experience)
Why Deloitte?

At Deloitte we create positively differentiated work experiences that enable our people to feel valued and achieve their full potential. We value difference and embrace people with diverse backgrounds and thinking styles. Knowing that people work best in different ways we are happy to discuss alternative arrangements if the working pattern you are looking for is not specifically indicated.",3.8,"Deloitte
3.8",Melbourne,-1,10000+ Employees,1850,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Engineer,-1,"Opportunity to grow the team
Period of growth
Intuitive app
S2M are working with a FinTech who have created a unique financial product to help thousands of people better manage their finance, and is currently scaling the company to the next level!

They are looking for a Data Engineer to join, and looking for someone who wants to be hands on, with opportunity to grow the team in future.

Role:

Looking for people with strong AWS experience. You will need passion for data and a cloud, through which you will help a rapidly scaling Australian FinTech establish their data infrastructure from the ground up.
5+ years’ experience as a data engineer within the data and analytics domain
A python 3.X aficionado who is very comfortable creating and orchestrating AWS data pipelines with nothing but code
Strong project delivery toolset experience in open source data integration tools
Experience with processing large volumes of complex data including visualisation and insights generation
Ability to define and develop data integration patterns and pipelines
Ability to assess complexity of data (volume, structure, relationship etc.)
Hands on experience working with different databases (RDBMS, NoSQL, Blob storage etc)
Hands on technical expertise setting up DevOps automation
Hands on experience working technologies/platform e.g. AWS, Dockers, Containers
Experience building data profiling and data cleansing frameworks
Technical reconciliation and reporting
Knowledge and experience in end-to-end project delivery, either traditional SDLC or agile delivery methodologies (or hybrid approaches)
Exceptional communication, documentation and presentation skills
If this sounds like you, get in touch today - kate.gabb@s2m.com.au
3167410agsdf",3.1,"S2M
3.1",Sydney,-1,Unknown,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Analysts,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is seeking experienced and qualified Data Analysts to join our IT team based in our corporate office in Birtinya (Sunshine Coast) or at our meat processing facility in Kilcoy.
Key Responsibilities:
A mixture of data analysis and commercial skills to source, blend and analyse data to gain insight and answer key commercial questions
Working with strategic leaders to define and model Key Performance Indicators, and assist in building forecasting models
Working closely with data engineers and BI developers to specify data pipelines and report visualisation
Drive the creation and implementation of data quality business rule including data definition, governance and quality assurance
About You:
To succeed in this role, you’ll need to bring the following experience and skills:
Proven ability to derive insight and knowledge from data using commercial expertise is a strong requirement
Strong SQL and Excel skills are essential, along with strong data analysis and commercial insights
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Effective people communicator - engage with stakeholders on reporting needs, interpret requirements into visual solutions and train/deliver the outputs to the stakeholders getting signoff of acceptance
Bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking

How to Apply:
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kilcoy,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Network Data Engineer,-1,"Min 6+ years of experience in the relevant technologies
Australian Driving License for visiting remote locations / Data Centre for day to day technical work.
Managing Network devices (switches, routers, firewalls, load balancer, and wireless technology)
Performing MACD activities for all network devices.
Supporting BAU operation activities.
Proficient in performing in-depth details of technical troubleshooting, cause and provide recommendation to the client for incidents causing extended network outage to client’s critical locations.
Provide exceptional network services in terms of network support, break-fix, design and consulting, new projects, implementation.
Configure, administer, and document firewall infrastructure.
Manage the firewall deployment, rules migrations, and firewall administration.
Supporting Cloud Migration Activities from traditional to AWS/Azure.
Setting up VPN tunnel with Cloud and 3rd Party network devices.
Integrating and upgrading existing ISP bandwidth with support from ISP Vendor.
Setting up VPN profiles for Users.
Installing hot fix and patches to mitigate the security devices from attacks and bugs.
Reviewing and fine tuning the firewall rules and NAT rules.
Documentation and change control.
Mentoring, Motivating and Guiding support teams
Technical skills:
o LAN
o Wireless
o WAN
o MPLS
o Routing protocols (OSPF,BGP)
o DMVPN
o Azure cloud Networking
o Network Security
Fortigate Manager / Analyzer / Firewall
Cisco ASA
Firepower FTD
Cisco Any connect
Site to Site VPN
F5 Load Balancing and Scripting iRule
Job Types: Full-time, Contract
Schedule:
8 hour shift
Experience:
Scripting: 5 years (Required)
Data Network: 5 years (Required)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Required)",3.6,"Total IT Global
3.6",Sydney,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Engineer - Processing & Analysis,-1,"Job Description:
Design,build and maintain the ingestion system to support various types of data(e.g. User behavior, RDS, NoSQL db and others) to be ingested to the data warehouse more timely and accurately
Translate data requirements into scalable technical data service with low latency and high concurrency
Design,build and maintain the batch or real time data pipeline in production using Hadoop big data technology
Analyze and improve efficiency, scalability, and stability of the system
Define and manage SLA,Data quality for all data sets in allocated areas of ownership
Requirements:
Minimum B.S. degree in Computer Science or a related technical field
2+ years of working experience in programming languages,such as Java,Scala,Python
Familiar with Hadoop, Spark and Flink data processing, experience of TB data processing experience is a plus
Familiar designing and operating of a robust distributed system is a plus
Understand data mining or machine learning
Excited to work intimately with data
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"SYNOPSIS:
Lead Data Engineer
Applications close Sunday 8 November 2020
Ongoing
Contact name: Shyni Sasikala
Phone: (02) 6249 9048
Email: Shyni.Sasikala@ga.gov.au

The Data Policy and Informatics section within the Digital Science and Information branch creates, implements, and promotes policies, platforms and tools that improve and support the quality, discoverability, accessibility, and general usability of Geoscience Australia’s science data products. The section consults with internal and external research, government and industry partners to establish collaborative data frameworks, architectures and models within Geoscience Australia (GA) and across broader national and international communities of practice. The section innovates, builds and maintains tools, systems, processes and governance that enable digital data management, cataloguing and open data delivery.
GA makes accessible a wide range of geoscientific and spatial data to a wide variety of stakeholders in multiple formats, and in recent years GA's data volumes have grown exponentially. GA is focussed on making its data and metadata assets accessible so that they can be used in machine to machine interactions for data analytics and other applications in environments that range from High Performance Computing (HPC), through high-end cloud servers, to mobile devices.
We currently have two opportunities for Lead Data Engineers in the Informatics team. The Lead Data Engineer is responsible for innovating and exploring new technologies that will advance GA’s science goals and maximise the uptake and use of GA’s science data. The Lead Data Engineer reports to the team’s Assistant Director but also works closely with other developers, data scientists and engineers within the Digital Science and Innovation (DiSI) branch, as well as diverse stakeholders both within and external to GA.",3.9,"Geoscience Australia
3.9",Canberra,-1,501 to 1000 Employees,2001,Government,Federal Agencies,Government,$100 to $500 million (USD),-1
Data Engineer,-1,"The Seven Network is part of Seven West Media, one of Australia’s most prominent media companies, with a market leading presence in content across broadcast television, online and in print. Comprising some of Australia’s most renowned media brands, SWM includes not just Seven Network and its affiliate channels 7two, 7mate, 7flix and BVOD offering 7plus, but also 7NEWS.com.au, The West Australian, The Sunday Times and more.
At Seven we are here to bring all Australians closer to the moments that move us - we’re first on the scene, with our finger on the pulse, on demand, in the moment. Together, we’re responsible for creating and sustaining authentic Australian engagement.
A new and exciting opportunity has opened for a Data Engineer to join the Audience Intelligence team. Based in Sydney and reporting to the Head of Data Enablement, you’ll be responsible for:
Implementation of end to end data solutions to support Data Strategy for the SWM group.
Work closely with the Data Solution Designers to develop and maintain scalable data pipelines and build out new file and API based integrations to address requirements from the various business stakeholders.
Collaborates with engineering, analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organisation.
Work on Data Preparation for analytics and data scientist team members and assist them from an engineering perspective in building and optimising the models including building the automation of the end to end workflows
Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.
Perform data analysis required to troubleshoot data related issues and assist in the resolution of production data issues.
Work effectively with vendors for successful delivery of projects and acceptance of the solution
Work on Delivery projects using Agile Software Development methodologies
We are looking for someone who has:
Bachelor's degree in computer science, computer engineering or other technical discipline is essential
Proven experience working as a digital analytics specialist
Extensive experience with digital analytics implementation (e.g. Google Analytics, Snowplow, Adobe Analytics) and BI processes and visualisation platforms
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience in ETL and building and optimizing ‘big data’ pipelines and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Experience with big data tools: Hadoop, Spark, etc., AWS cloud services: EC2, S3, Lambda and familiar with version control systems: Git
Strong coding skills with knowledge of Unix/Linux and scripting languages such as Unix Shell scripting, Python desirable
Experience supporting and working with cross-functional teams in a fast-paced environment.
Ability to multi-task and problem solve with changing demands and priorities
Ability to work under pressure to meet deadlines and detail oriented
Your success is our success: we will provide you with opportunities for you to keep learning and growing, enabling you to challenge and develop yourself. In return, we offer a benefits program that has something in it for everyone.
Seven West Media is an equal opportunity employer and we are committed to creating a diverse and inclusive workplace.
Recruitment Agencies: Seven West Media does not accept any unsolicited agency resumes and will not be responsible for any fees related to unsolicited resumes.
Advertised: 19 Oct 2020 12:00 AM AUS Eastern Daylight Time
Applications close:

Back to search results",2.5,"Seven West Media
2.5",Sydney,-1,5001 to 10000 Employees,1956,Company - Public,TV Broadcast & Cable Networks,Media,Unknown / Non-Applicable,-1
BICON Rules Engineer,-1,"APS 5 - $73,299 - $80,410 per annum plus superannuation
Biosecurity Plant Division
Canberra, ACT
Play an active role in managing biosecurity risk to Australia
Work in a motivated and professional team with a wide range of skills and backgrounds
Full training provided

Who we are
The BICON Content Development Team maintains and improves the Biosecurity Import CONditions database (BICON) content to allow external clients to understand and comply with their biosecurity obligations and internal clients to effectively manage biosecurity risk and regulate imports. We work collaboratively with internal clients to comprehend and implement their BICON content requirements and optimise the use of BICON to publish clear import requirements and onshore management support procedures to effectively manage biosecurity risk.

The Jobs
Key duties of these positions include:

working with business content (import and permit conditions) and import programs to understand and construct decision tree structures in the BICON database, in accordance with system design and authoring conventions
executing changes to import and permit conditions in alignment with service standards while complying with system rules and authoring conventions
providing technical advice through various formats on the most appropriate means of authoring BICON content to achieve import program and stakeholder objectives
using workflow management tools to maintain detailed records of changes to import conditions and key decisions
performing administrative tasks including system reporting, data analysis and scoping tasks for the BICON content change work program
contributing to the development and maintenance of instructional material, authoring conventions and courseware
clearly documenting and reporting system issues
developing and maintaining effective working relationships with internal and external stakeholders.

What we are looking for
Knowledge and experience
Experience working with complex IT systems.
Experience working collaboratively and as part of a team.
Knowledge of the role of biosecurity is preferred but not essential.

For additional information, please read the Job Description below.
Candidate Information Package docx Opens in new window",3.9,"Department of Agriculture & Water Resources
3.9",Australia,-1,5001 to 10000 Employees,-1,Government,Federal Agencies,Government,$500 million to $1 billion (USD),-1
Cloud Data Engineer,-1,"Job no: 509605
Work type: Permanent Full Time
Location: Melbourne, Canberra, Sydney
Do you embrace digital disruption?
Do you love solving complex problems, designing sophisticated solutions and building innovative technology?
Do you believe in creating powerful actionable insights from Data and Analytics?
Do you want to work in a diverse and flexible working environment?
KPMG is one of the most trusted and respected global professional services firms. Through depth of expertise, clarity of insight and strength of purpose we help our clients solve complex challenges, steer change, strengthen, transition and grow. We are a team based practice and this extends to our clients whom we work and collaborate with, in solving complex problems. Together, we design, innovate and implement, providing enduring advice that support our clients and the services they deliver. Our clients vary in size and come from a diverse range of sectors – all sharing in a common goal: to embrace change and deliver services that make Australia a better place. We are looking for talented individuals who would like to join us on the journey.
KPMG’s Digital Delta Team
We re-imagine and re-invent organisations to become world class digital enterprises using advanced technologies, data and human insights. We help organisations to embrace Digital Strategy, Artificial Intelligence (AI) & Cognitive, the Internet of Things (IoT), Data, Analytics & Modelling, Mobile App & Web, and User Experience (UX) & User Interface (UI) and more.
We work with clients to:
Formulate strategies that re-imagine organisations
Harness innovation from the 4th industrial revolution
Actioning insights from trusted data to consistently and quickly make clear decisions
Build adaptive organisations
Thrive as a connected enterprise – front, middle and back office
This is how you’ll contribute:
We are looking for ambitious Data Engineers who are passionate about helping clients define bold ambitions and deliver on them. Joining our team will take you on a journey of personal and technical growth and provide the opportunity to inspire confidence and empower change.
As a Data Engineer you are the designer, builder and manager of the information or ""big data"" infrastructure, preparing data for analytical or operational use. You will design, construct, test and maintain a data pipeline to pull together information from different source systems; integrating, consolidating and cleansing data; and structure it for use in individual analytics applications.
The KPMG Difference
Our people are focused on creating a diverse and dynamic environment that embraces and values differences. We value the variety of unique experiences, qualities and characteristics our people possess and we share and learn from each other.
We are proud to be consistently recognised as an employer of choice for women, and for our achievements in LGBT+ workplace inclusion.
Our commitment to ‘Flexibility’ allows our people to manage the changing demands of work, personal or family life. Explore the links below to hear our people share their experience @ KPMG:
Flexibility empowers wellbeing
Flexibility enables contribution to the community
Flexibility inspires technology & innovation
Flexibility supports family

Make KPMG the clear choice for your career and be Extraordinary!

Advertised: 09 Sep 2020 AUS Eastern Standard Time
Applications close:",3.8,"KPMG
3.8",Sydney,-1,10000+ Employees,1987,Subsidiary or Business Segment,Accounting,Accounting & Legal,$2 to $5 billion (USD),-1
Computer Network and Systems Engineer,-1,"Duties Include but are not limited to:
Tasks Include:
analysing, developing, interpreting and evaluating complex system design and architecture specifications, data models and diagrams in the development, configuration and integration of computer systems
researching, analysing, evaluating and monitoring network infrastructure to ensure networks are configured to operate at optimal performance
assessing and recommending improvements to network operations and integrated hardware, software, communications and operating systems
providing specialist skills in supporting and troubleshooting network problems and emergencies
installing, configuring, testing, maintaining and administering new and upgraded networks, software database applications, servers and workstations
providing network programming in support of specific business needs and requirements
preparing and maintaining procedures and documentation for network inventory, and recording diagnosis and resolution of network faults, enhancements and modifications to networks, and maintenance instructions
monitoring network traffic, and activity, capacity and usage to ensure continued integrity and optimal network performance
Skills and Experience Required:
Must have experience working in a Managed Service environment
Demonstrated experience in IT Networks and Data Centres
Understanding of systems and architectures to meet client needs
Experience in Help Desk including break / fix
Effective and timely documentation
Effective Task Management Skills
Be solution and outcome focused and willing to learn new technologies
Excellent communication skills with staff, clients and partners
Time management, ability to prioritise and deliver to schedule
Experience with N-Able and Connectwise desired
Open Cabling license desired
Job Types: Full-time, Permanent
Salary: $30.00 per hour
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,Trans-plant training,Canberra,-1,-1,-1,-1,-1,-1,-1,-1
Software Engineer (Data),-1,"If you are looking for an opportunity to make a real impact with smart people who are genuinely doing things differently then you've come to the right place! We're growing our data engineering capabilities and are looking for awesome data engineers to join our team.
With our diverse range of clients and projects, no day will look the same - but here's a great snapshot of what you'll be doing:
Work with some of the best Data Scientists and Engineers to deliver production-grade AI and Machine Learning systems as we deliver client projects from inception to production.
Consulting with our clients and working with them to build modern data systems using the 'best of' technologies and principles.
Advising clients on data strategy, architecture and technology.
Applying best software engineering practices in coding, monitoring and alerting, using CI/CD, TDD and cloud architectures.
Working over a wide range of big data tools and environments: not limited to; Apache Kafka, Spark, Python, Scala, Hive, Airflow, AWS EMR & Glue, GCP Dataproc & Dataflow, BigQuery, Snowflake, Redshift.
Who are we?
Glad you asked! We are Eliiza. Data science. Engineered for scale.
We are a passionate team of data scientists and engineers who apply data science and machine learning to solve real-world problems. Our mission is to create a bright future for Australian businesses and society in a world increasingly influenced by intelligent technologies.
We've created a culture that values diversity where people can truly be themselves! We care a lot about growing the Australian AI community in a positive direction, and we're doing several things to try and achieve that:
We provide opportunities for underrepresented groups to work in AI through our associate and intern programmes
We organise and participate in a range of community events, reading groups and meetups
We produce the AI Australia podcast
We blog about topics we care about
We stream brown bag sessions to the broader community
We're also part of Mantel Group's 'house of brands' which means it's not just the Eliiza team you'll work with, learn from and see at social events - there's another 230 of us across DigIO, Kasna & CMD Solutions!
So you're ready for something new?
We're keen to know more about you! Our team is made up of a range of people, with different experience across a huge range of data driven skill sets.
We'd love to hear from you if you have experience with:
one (or more) core language(s), ideally Scala, Python or Java
one (or more) cloud platforms, AWS, GCP, Azure
ETL/ELT concepts and technologies e.g. Data partitioning, Hive, Spark
streaming data concepts and technologies, ideally Kafka (Kinesis, Beam or Pubsub will do)
We'd be over the moon if you:
Experience with distributed/columnar databases (e.g. Snowflake, Big query, Redshift).
Experience with any of a variety of databases e.g. RDMS, NoSql, Columar, Distributed, Time series, Graph.
Knowledge of job orchestration and scheduling. Any experience with Airflow, Luigi or Oozie.
Experience with containers and container orchestration (Docker, Docker Compose or Kubernetes).
However, we value a diversity of skill-sets, and don't necessarily require that you're skilled with all of the above. If you feel you don't fit all the experience/skills listed above we still encourage you to apply or get in touch.
What's on offer if you join us?
We make sure you're always one step ahead by investing your learning and development, every year. We build our own training where it doesn't exist yet.
We hire smart people and get out of their way. By focusing on our five principles and not getting caught up in red tape, we trust you to get the job done.
You'll get all the tools you need - a new iPhone or Google phone, a new Macbook Pro or Dell, and a lot of branded swag!
But hold on, you mentioned a house of brands?
We certainly did! Mantel Group is an Australian-owned, 'house of brands' company with four technology businesses (Eliiza being one of them!) across Melbourne and Sydney. We're building a group of companies with open borders so we can support you to take on new skills without leaving an awesome team - we understand you won't have one job for life!
We may only be just two years old but Mantel Group has already been recognised #9 in the 2020 Best Places to Work in Australia and #4 in the AFR's 2020 fastest growing new companies.
Keen to chat?
Click ""Apply"" to share your details with our talent team, and we'll be in touch.
In the meantime, check out 'how we hire' to find out what's in store if you're successful and get to know us better by visiting our website and following Eliiza on LinkedIn.",-1,Eliiza,Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Infrastructure Engineer,-1,"Job Description:
Design and grow the Shopee data platform to support a variety of big data applications using open-source technologies including Kafka, Hadoop, Presto, HBase, Spark, Hive, Druid, and our own creations. Some examples include a real-time data streaming platform, a unified query platform, a cluster management system, and a machine learning platform
Dig into the source code of some open-source big data system to get the whole control and familiar with the details, configurations, designs and source code. Develop and maintain the internal release of big data systems and components as the business requirements.
Keep close and overall monitoring for all the deployments of the systems, maintain the system’s stability, improve the performance, discover the performance bottlenecks, tracking and troubleshooting, cost optimisation.
Requirements:
B. Sci. / Ms / PhD in Computer Science or a related technical field
Familiar with at least one of these languages: Java, Scala, Python, Bash under Linux / Unix. Scala is a plus
Familiar with the use and compute logical of SQL
Knowledge about the Big Data Infrastructure system technology like Distributed File System, Distributed Computing, Distributed Database will be a plus
Hands-on experiences Hadoop, Spark, Kafka, and/or Presto will be a plus
Love to use and develop open-source technologies
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"Work on an award-winning, international technology!
Endless career opportunities
An innovative, friendly team of 300+
This role will be focused on the development of our existing ClaimLogik line of products as well as working on our new cloud-first, modern suite of applications.

Intelligent Thought, our technology business is scaling and shipping our software globally. Already profitable, part of a much larger group business, with investors such as Macquarie Capital and Envest – we are all set to deliver textbook disruption to the Insurance Industry. The growth of the platform, of our customer base, and the increasing industry demand have led to the need for this role to help the team scale.

Our Philosophy
Give each employee a sense of purpose and an environment for them to connect the importance of their role to delivering a service that matters to our customers.
Challenge the ‘why’ of traditional claims processes.
Keep it simple – do only what brings value and what matters to the customer
Enable employee decisions, empower our people
Responsibilities:
Create, extend and maintain ETL pipelines to form our data lake, data warehouse and analytics platform (currently using the Microsoft Azure set of tools and service)
Help define the optimal data pipeline architecture
Influence the tool selection, platform selection, data architecture and strategy which will transform the business to be truly data-driven
Understand, analyse and size user requirements
Work with different parts of the business to provide them with the insights they need to deliver the best results
Skills & experience:
Degree or qualification in computer science or related
Advanced knowledge of relational database, including query authoring and query optimisation (MS SQL Server and PostgreSQL).
Experience building and optimising ETL pipelines
Experience designing complex data models
Experience working with cloud platforms (Azure or AWS)
Efficient time management and organisational skills
High attention to detail and accuracy
Effective communication skills to build strong working relationships; both written and verbal
Proactive and results-driven
Why Claim Central?
Claim Central Consolidated is a global insurance industry leader across, claims management, insurance technology and data and analytics. Currently operating in the United States, Australia, South Africa, Italy and New Zealand, we have pioneered digitally connected claims management services across the globe. Claim Central is a disruptor and thought leader in the industry and we were recognised as the Australian Financial Review’s 8th Most Innovative Company in Australia in 2016. This business is in a period of unprecedented growth, transitioning our technology and services into multiple geographies at a rapid pace. Our unique culture is based on teamwork, collaboration, trust, respect and performance. We also offer many benefits apart from our exceptional team culture; including flexible work arrangements, and continued professional development.

Be a part of this journey in a career-defining role.",-1,Claim Central,Matraville,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer - AI/ML,-1,"Our client provides services to a major industry across the country. The business is still early in it's days of technology development and the environment is greenfields in nature (no pun intended), effectively working like a start-up.

Their data and analytics team have worked and built leading and bleeding-edge technologies in this space and what they have created so far may be game-changing. From a machine learning perspective, the progress they have made to the business has already seen proven success in changing the future of an industry that will have positive consequences for all those involved.

You will have previously worked in a technical capacity in the data and analytics space and have experience working with an organisation where machine learning has been implemented, not just a concept that the business talks about having or the technology team would love to have. The commercial experience you will have had in the ML field will be proven examples of where you have affected the way a business or industry used to perform, to the changes that have come about from this.

Technically, you will have extensive experience in the Microsoft space - Power BI, Azure etc and you will have previously mentored and coached junior members of the teams you have been part of.

This is a rare opportunity in Brisbane where the business has truly embraced and funded projects across the ML space and would be a great chance for those in the Data Development/Data Engineering field, who are looking to move into a Data Scientist role in the future.

Please send your application through if you would like to know more.",4.0,"Emanate Technology
4.0",Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Solution designer/ ETL Engineer & Data Modeller,-1,"We are looking for a Qualified and Experienced Solution Designer to join our client for a period of 6 months with a view to extend.
You will work closely with team members and your contribution will range across gathering and analyzing information, developing and documenting improved processes and work instructions and experienced DWH Lead with skills in requirement analysis, solution designing, developing, testing and supporting ETL solutions.
A hands-on solution designer, data modeler and ETL developer for Data Warehousing and ETL application transformation projects using Informatica PowerCenter.
Knowledge on AWS, S3, Redshift, Informatica BDM, and related technologies.
Experience working with IPython, PySparks, AuCuMo, Airflow, Jenkins, Github, Athena, JIRA, Rally, Spectrum, Glue, Flyway.
Good exposure on Oracle PL/SQL, aware of DBA activities, writing and performance tuning of complex SQL queries.
Contract length: 6 months
Job Types: Full-time, Contract
Salary: $650.00 – $800.00 per day
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,nducive,Melbourne,-1,-1,-1,-1,-1,-1,-1,-1
"Data Engineer, Wollongong NSW or Mount Waverley VIC",-1,"Company Description
BlueScope is a technically advanced supplier of steel and steel products in Australia. We are an inclusive organisation and every day we showcase our technology and expertise throughout the world.

Job Description
We are looking for two Data Engineers to join our IT team, based in Wollongong NSW or Mount Waverley VIC. Use your experience in analytics to unlock business value, enabling use of big data for insights and decision-making.
Reporting to the Data Product Owner for our Australian Steel Products (ASP) business, this position will support strategic goals related to data. This will see you:
Gather business and technical requirements with the view to deliver outcomes;
Develop and implement end-to-end data collection, consolidation, modelling and visualisation solutions;
Document metadata in a dictionary and catalogue;
Ensure consumers of such information understand its accuracy, timeliness, quality and sensitivity, so that it is used appropriately; and
Identify opportunities to enhance analytics.
What are the benefits?
Work in a supportive and collaborative team environment whilst we embark on a journey to transform the way our business uses data!
Our systems landscape is broad and diverse. You will be encouraged to think creatively to develop data solutions which solve real business problems.
Working in this role you will enjoy:
the chance to learn more about data science;
salaried remuneration with attractive superannuation options;
the opportunity to participate in a performance incentive scheme; and
access to further development and career opportunities with BlueScope.
Who are we looking for?
We welcome applications from professionals with experience in data analytics and/or programming. Supported by your knowledge of project delivery methods (e.g. Agile), you will demonstrate:
experience with data mining, wrangling, mapping and visualisation techniques (e.g. Azure Data Factory, Databricks and/or DevOps etc.);
well-developed ability in gathering business and technical requirements;
skills in developing and implementing collection, consolidation, modelling and visualisation solutions; and
a passion for sharing your knowledge and desire for ongoing professional development.

Qualifications

null

Additional Information
We're proud to have been named an Inclusive Employer for 2019–2020 by the Diversity Council of Australia. We believe that our people are our strength. Having a diverse and inclusive workplace enables us to improve our capability and ensure continued, sustainable success.
We know that workplace flexibility can mean something different to everyone. Under our B-Flex initiative all of our roles have some degree of flexibility. We encourage you to discuss your needs with us.
Applications close Sunday 25th October 2020.",3.3,"BlueScope
3.3",Wollongong,-1,201 to 500 Employees,-1,Company - Private,Construction,"Construction, Repair & Maintenance",$100 to $500 million (USD),-1
ETL Data Engineer,-1,"ETL Data Engineer

Join a team that’s changing how Australia lives, works, plays and grows
We want you to be the best version of you

Work with innovative teams and explore new technologies to help solve real-world problems.

A typical day as a Data Engineer

ETL / Big Data Engineering professionals will be responsible for guiding the full lifecycle of a Data solution, including:
Working in highly client-facing roles to contribute throughout the end-to-end delivery lifecycle of complex and large-scale digital solutions
Use case and business case development
Support existing and new applications utilizing in-depth technical and data knowledge. Troubleshooting complex issues and providing advisory services to improve the client’s data landscape
Help to streamline and simplify the clients’ complex data landscape by integrating different applications and data architectures
Implementation from requirements analysis, platform selection, digital architecture design, application design and development, testing, and deployment
Interstate travel may be required

Basic qualifications:
Bachelor’s degree
Experience across systems integration, information management, data management and architecture, and business analytics
Experience with being in a team focusing on large-scale, multi-release information centric projects
Experience with waterfall and agile delivery and run / application support functions
Part of a team working on End to end implementation of at least 1 big data project

Preferred Skills:
Hand on experience in Data warehousing using ETL tools such as DataStage, Autosys and TeraData
Hands on experience in ETL job development with multiple stages like sequential file, Transformer, Lookup, join, sort and Database stages.
Strong hand on skills in design, development and implementation of various data remediation, Data migration, data integration techniques.
Strong hand on data modelling experience.
Strong hands on experience in database performance tuning including complex query optimizations and physical database tuning using Teradata.
Understanding of architectural designs and strategy related to data migration, data cleansing, data quality and data consolidation.
Proven data analysis, requirement gathering and problem-solving skills
Exposure to Unix environment and shell scripting.
Experience in Banking and Financial services industry
Desirable: Knowledge of cloud computing infrastructure (e.g. Amazon Web Services EC2, Google Cloud, Microsoft Azure)
About Accenture

Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. We combine unmatched experience and specialized capabilities across more than 40 industries — powered by the world’s largest network of Advanced Technology and Intelligent Operations centers. With 513,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises. Visit us at www.accenture.com.

Accenture is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, marital, domestic or civil partnership status, sexual orientation, gender identity, or any other basis as protected by applicable law.

Vera Goga is the Recruiter managing this role. As the team experience high volumes of applications, we appreciate your patience to allow for a fair and timely process.",3.9,"Accenture
3.9",Sydney,-1,10000+ Employees,1989,Company - Public,Consulting,Business Services,$10+ billion (USD),-1
Student Engineer,-1,"The candidate will have the ability to:
Undertake onsite inspection to collect asset condition data based on the relevant engineering standards and technical guidelines;
Undertake desktop analysis to evaluate the condition and performance of the assets;
Provide the appropriate information, advice, engineering input and support services for the sustainable management of Council’s stormwater and transport networks.
Qualifications:
The successful candidate will be enrolled in a Bachelor of Engineering with a minimum of two years completed.
Position Number: 100678
Position Hours: Fixed term (3 months), hours will be negotiated with the successful candidate, maximum of 75 hours per fortnight.
Salary: Schedule A, Salary Point 4.0. $28.64 per hour ($55,853.45 per annum, pro-rata) in accordance with Glenorchy City Council’s Enterprise Agreement 2016
Please note that all successful applicants will be required to provide a current National Police Check prior to commencement of employment.
For further information on this position, contact Patrick Marshall, Senior Civil Engineer on (03) 6216 6800.
How to apply: Applications for this position must be lodged on this submission site or on the Glenorchy City Council website www.gcc.tas.gov.au - Careers page.
To be considered for this role, all applicants must address the key selection criteria in the and provide a current resume. A copy of the position description can be found by clicking the below hyperlink or on the Glenorchy City Council website.
Applications close at 8pm on Sunday, 1st November 2020
- Student Engineer",4.0,"Glenorchy City Council
4.0",Glenorchy,-1,501 to 1000 Employees,-1,Government,-1,-1,Less than $1 million (USD),-1
Data Engineer involving DevOps,-1,"Data Engineer involving DevOps
Axiom Technologies is an Australia based entity with the history of providing Managed IT solutions to medium to large scale enterprises globally. Please visit our website for more information about what we do at www.axiomtechnologies.com
Axiom Technologies is an Equal Opportunity Employer and encourage applicants from all backgrounds and gender to apply, including, Aboriginal and Torres Strait Islander candidates
Job Requirements:
8+ years IT experience, with at least 5+ years of “Data Engineer/Deveoper” focused titles/roles,
Data Tools: Hands on experience with Apache Beam.
Testing: Hands on experience with automated testing activities/outcomes
DevOps: Experience with the processes involving Microservices facilities for artifacts developed
Platform/OS: Mid-range/Unix
Languages: Unix (Shell) Scripting/commands, SQL, Python
File formats: Text, CSV, Parquet, JSON, XML
Scheduling: Jenkins, Airflow
Auto Scripting: Designing/creation of scripts for repetitive activity. E.g. Unix scripting/SQL
Big data: Exposure to Data Lake Concepts, Hive (Schema), HDFS
Source Control tools: GIT
Delivery Models: Agile, Scrum
Ingestion Design: Create/assess Source/Target data mapping designs
Frameworks: Development and delivery frameworks
Activity Reporting/Repository: Jira, Confluence.
Quality: Accuracy and attention to detail
Industry: Financial Services/Banking
Solutions: Define solutions from High level to detail design to address automating ingestion activity. Facilitate/confirm requirements from product owners, business team members and technical associates,
Process Automation: Automating processes in file management, testing data in files, analysis and design, configuration management.
Script Automation: Ability to design/create scripts to automate/improve data copy/migration/ETL for any repetitive activity.
Languages: Java, Python
Scheduling: Control-M
Databases: Relational. E.g. POSTGRESS, Oracle – as a ETL developer
File Formats: Mainframe – experience with referencing its data formats/copybooks
Big data: Experience referencing/using Hive (Schema) to access data in HDFS
Metadata management tools: MDM, EDC and Axon
Performance: Assess, recommend, improve mappings, SQL queries, Batch feeds
Automation Tools: Other tools that may add value to an automation program and generally support development. E.g. API, REST, JDBC, Webservices, Message Queues/Load balancer,
Cloud: Experience with processing of data files to be ingested/stored in the Cloud, preferably with AWS.
Prod Support: Experience in a production support role performing root cause / impact analysis – under time constraints
Experience in a similar role
8+ Years
What next?
If you are looking for that next challenge in your career and wish to apply for this role, please forward your resume to careers.au@axiomtechnologies.com",2.0,"Axiom Technologies
2.0",Melbourne,-1,1 to 50 Employees,-1,Company - Private,Industrial Manufacturing,Manufacturing,Less than $1 million (USD),-1
Data Engineer,-1,"About the Role
We are on an exciting digital journey so it’s a great time to join ME! We are seeking a Junior Data Engineer who enjoys rolling up their sleeves, learning and growing. As part of our Enterprise Data Team, you will ensure fit for purpose data warehouse solutions are built for use across the bank and by utilising best practise ETL standards, whilst ensuring the data is trusted by our BI developers and key business consumers. Oh, and you’ll get to work on Microsoft technology stack too!
You will be involved with investigating data issues, keeping data feeds flowing and collaborating with different projects across the bank to deliver quality data solutions. How important does that sound? What’s even more important is this role contributes directly to our overall business strategy through the provision of data to enable analytics & reporting, as well as supporting business and decision system processes.

About You
You’re naturally a highly motivated and energetic person who thrives in a dynamic, ever-changing collaborative team environment. Ideally you have previous experience as an ETL developer, Data Engineer or a BI developer, and if you have a degree in computer science or similar it would really put you ahead of the rest.

With your knowledge of SQL coding, data modelling, understanding of data warehouse concepts, plus experience of working on complex ETL solutions, you’re ready to expand your horizons and launch your career into the world of IT at ME.

About ME
We’re not like other banks.
ME was created by the industry super funds to be different from the pack – with a core purpose to help all Australians get ahead financially – no conditions, asterisks or exceptions. And we know that looking after customers starts with taking care of our people.
We believe everyone deserves the same opportunities in life, regardless of gender or identity, sexuality, ethnicity, religion or disability ‒ with internal affinity groups.
Perk ME up
Once you get your feet in the door at ME, we’ll put them both in your very own ME-branded Converse shoes. You’ll also get the following financial, health and fun perks when you join the team:
4U Extras portal (discounts and cashback on 100s of items including cinemas, shopping and gym memberships
10% Myki discount
Purchased Leave programme
Internal wellness programme (Mindfully ME)
Professional education through LinkedIn Learning
Novated Leasing
Professional membership reimbursements
Health checks
Financial education (To help you manage your money smarter)
LGBTIQ+ and Women at ME affinity groups

I want those Converse shoes (and the role)
Can’t see a closing date on the advert? That’s because we’re pretty efficient here at ME and we may start looking at applications sooner rather than later, so if this role sounds like your jam, be sure to apply by submitting your resume today.

Should an applicant be the preferred candidate, background checks (including police checks, reference checks, ASIC banned and disqualified persons and bankruptcy checks) will be completed prior to the candidate's employment being confirmed. The outcomes of the background checks do not automatically bar candidates; however will be assessed against the inherent requirements of the job.
Back Share
Apply Now",3.0,"ME Bank
3.0",Melbourne,-1,501 to 1000 Employees,-1,Company - Private,Banks & Credit Unions,Finance,$100 to $500 million (USD),-1
Software Engineer - Machine Learning/Data Science,-1,"Zendesk is looking for a Software Engineer - Machine Learning/Data Science for a full time position in our Melbourne office.
As part of our engineering team, you will work at a scale where the challenges start to get seriously interesting. Our global engineering team is widely dispersed over the world, with people across nearly every continent. You will get a chance to do cool things with a diverse bunch of people while working in the Melbourne office that is home to Zendesk’s first machine learning (ML) research team.
The Data Science Team, together with Data Engineering, have built Satisfaction Prediction, Answer Bot and Content Cues — products that use Machine Learning (ML) and Artificial Intelligence (AI) to help our customers work more efficiently.
What you get to do every day:
We’re currently looking for someone to join our team as we research, develop, and productionise Machine Learning and Deep Learning models. In addition to frequenting Melbourne’s finest purveyors of coffee, ramen, and bulgogi, you may find yourself:
Building machine learning models including neural networks in TensorFlow
Writing and deploying production-grade Python
Querying and constructing datasets in AWS Athena, Spark
Evaluating and responding to real-world model performance
Scaling your ML to millions of predictions per day
Presenting your work to a broader audience
Watching your algorithm help Zendesk’s end-users
What you'll bring to the role:
A strong foundation in a quantitative discipline (e.g. machine learning, statistics, bio/eco/etc-informatics, econometrics, etc) is critical for this position. While experience in deep learning and natural language processing would be beneficial, your best qualities are:
dedication to continuous learning
collaborative work attitude
strong communication skills
You should also be comfortable with at least one programming language, such as Python, R or Scala.
Application Deadline: 18/11/2020
Job Types: Full-time, Permanent
Salary: $85,000.00 – $110,000.00 per year
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Temporarily due to COVID-19",4.5,"Zendesk
4.5",Melbourne,-1,1001 to 5000 Employees,2007,Company - Public,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),-1
Software Engineer (Machine Learning),-1,"About the Role
AdelaideMRI is building a medical reporting tool. We require an engineer to work primarily on machine learning projects to improve reporting speed and report comprehensiveness.
You will perform data analysis of medical report datasets and image datasets to infer sentence recommendations, image classifications, or other actionable results for the doctors.
Skills and Experience
Background in machine learning or image processing
Qualifications in Computer Science, Software Development or Engineering or equivalent experience
Bonus points for Python
No prior medical knowledge is required.
This position offers flexible hours and work arrangements.
Job Type: Full-time
Experience:
Software Engineering: 1 year (Preferred)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Yes",-1,Adelaide MRI,Australia,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Hey there, we’re PEXA!

We started as an idea: to deliver a single, national e-Conveyancing solution. We collaborated with the industry to create a national electronic lodgement and settlement platform: PEXA. From our humble beginnings, we’ve now grown to more than 320 employees across 5 different states. We’re still expanding at a rapid rate and constantly challenging ourselves to create great experiences for our members as they transition to fully digital conveyancing.

Why become a PEXArian?

Great question! Being a PEXArian is so much more than just a job. We are passionate, motivated & unashamedly enthusiastic at PEXA - we love what we do and we’re proud to admit it! Creating brilliant member experiences wouldn’t be possible if we didn’t also strive to create an amazing employee experience. Alongside our members, our employees are at the heart of everything we do.
Here’s a snapshot of what your life at PEXA could look like:

Your growth:
We encourage you to hit your personal and professional Learning & Development goals with our tailored programs and tools.

Your wellness:
We care about your holistic well being - a fully stocked kitchen, four wellness days, a $250 wellness subsidy as well as lunch and learn sessions to support your financial well being.

Your work/life blend:
We know that work is just one aspect of your life, we want to help you create your ideal work/life blend, rather than squeezing in life around work.

Your family:
With a range of benefits aimed at supporting your family including access to a subsidised school holiday program, extended parental leave and flexi-time to support your return to work, superannuation payments for unpaid parental leave for primary carers and a childcare allowance for pre-primary aged children, when we say, ‘welcome to the family’, we really mean it!
The impact you'd drive:
The successful candidate will be responsible for developing, and maintaining infrastructure to support the delivery of new and existing products. They will also be contributing to establish the rules and frameworks for obtaining the required approvals for new products.
On day one we’d love you to have:
Experience with Python, Spark
Event streaming/sourcing with Kafka or AWS Kinesis
Experience with data structures, formats and data security best practices
AWS experience (e.g CloudFormation, S3, ECS, Lambda, SQS, IAM, KMS, DynamoDB, Glue, Athena)
Query construction and optimisation (e.g. SQL, Elasticsearch, Splunk, DynamoDB)
Git, version control practices, and continuous integration/delivery servers
PyUnit and unit testing frameworks
Production release cycles and maintenance
Collaborating with technical and non-technical teams
Even better:
Agile methodology/delivery
GraphQL
Modern frontend technology (e.g. ReactJS, TypeScript)
Machine learning frameworks and tools (e.g. TensorFlow, PyTorch)
OAuth 2, SAML 2, JWT
Data visualisation and exploration tools (e.g. Jupyter notebooks, Tableau)
AWS SageMaker
Sounds like you?
If this role sounds like you, apply today to have your application reviewed ASAP!",3.9,"Property Exchange Australia Limited
3.9",Melbourne,-1,201 to 500 Employees,2010,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Ongoing position
Full time
Based in Sydney, NSW
Who we are
Australian Red Cross is part of the world’s largest humanitarian organisation. Our aim is to improve the lives of the most vulnerable people in Australia and across our region.
About the role
The Data Engineer role will sit within the Data and Integration Squad in IT and will own (design, implement and support) the AWS Big Data technologies such as the Data Lake and Data Warehouse and support the organisation in growing the data analytics capabilities at Red Cross. In addition to this, the data engineer role will also administer the Power BI tool and support the implementation of the data mastering capability.
What you will bring
Experience building and optimizing data pipelines, architectures and data sets.
Experience in dimensional modelling and building data vaults
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with structured, semi-structured and unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Why work for us?
Work for purpose and know that your work assists Red Cross support and empower people and communities in times of vulnerability.
Generous salary packaging options available that can increase your take home pay.
Further information
To find out more about this opportunity please see the position description below or contact Sharath Kumar Gurram on 02 8651 8839.
Position Description: Position Description - Data Engineer .pdf
Applications for this position will close at 11:55pm Thursday, 5 November 2020.",4.1,"Australian Red Cross
4.1",New South Wales,-1,1001 to 5000 Employees,-1,Nonprofit Organization,Industrial Manufacturing,Manufacturing,$500 million to $1 billion (USD),-1
Junior Fullstack Data Engineer (Python and React),-1,"Formbay is the leading Renewable Energy Certificate Trading company in Sydney. We provide Digital Workflow and Compliance solutions in the renewable energy industry and document processing.
Thanks to our meteoric growth and our commitment to be the best at all we do, we've identified the need to bring on board a new Junior Fullstack Data Engineer.
Reporting to our Principal Machine Learning Engineer, you will help build Machine Learning pipelines for our existing Digital Workflow and Compliance solutions to automate fraud detection and document processing over terabytes of photographic and documentary data – including documents, photos, GPS data and aerial/satellite photography.
Our stack is based on Python, JavaScript, Dask, Tensorflow, CUDA, Nix/NixOS, AWS, Docker, PostgreSQL and more – familiarity with these applications will give you a leg-up on the competition.
Our ideal candidate will have the following competencies:
SQL
Python
JavaScript/TypeScript
Our candidate must also be comfortable working with Linux.
Located a stone's throw away from the Queen Victoria Building in Sydney's bustling CBD, we are centrally-located with easy access to public transportation, bars, cafes and fine dining.
Formbay will provide flexible working hours, a generous remuneration package and the opportunity to work on a world-first software solution are what we can offer you. Free, twice-weekly gym sessions and really, really good coffee are also available.
No hiring/recruitment agencies need apply.",5.0,"Formbay
5.0",Sydney,-1,1 to 50 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is an experienced and qualified Data Engineer to join our IT team based in Birtinya.
Key Responsibilities:
Create and maintain data pipelines and or ETL scripts
Create and maintain data integration including API and Batch interfaces
Performed detailed data analysis
Create and maintain corporate data models
Create and maintain data visualization using Qlik.Sense , PowerBI or Simliar Toolset
Experience in defining, building and maintaining data virtualization and/or star schema data warehouses
Maintain, tune and optimise database, integration and visualisation toolsets
ABOUT YOU:
To succeed in this role, you’ll need to bring the following experience and skills:
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Excellent communication skills both oral and written, with an ability to bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking
Experience with data analysis and modelling will be beneficial

How to Apply
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kawana Waters,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Graduate Data Science / Engineer,-1,"The NRMA is an organisation looking to the future, and right now, we are on the lookout for people who can help us reach our goal: to continue to shape the way Australians move, for the next 100 years and beyond. www.mynrma.com.au.
Everyone new to the team, along with our current staff, will temporarily work from home until it is safe to return to our offices. All interviewing and on boarding will be done virtually due to COVID-19.


Your opportunity
As Graduate Data Scientist or Engineer you will be part of the Data Engineering team delivering cloud data transition program for business initiatives and supporting the entire data platform build.
Your key responsibilities will be to:
Implementing Concepts of Data Warehousing, Data Mart creations within Cloud
Use of SQL for data analysis and insights
Building AI/Machine Learning prototype for implementing and supporting existing algorithms
Data Analytical reports build, using different tool sets


Requirements for Success:
Relevant Degree - Computer Science, Computer Engineering, Software Engineering, Data Science
Excellent SQL skills and demonstrated working knowledge in Python
Demonstrated understanding in data structure and algorithms.
Knowledge and concept of data warehousing methodologies
Any reporting tools experience Tableau or Oracle Analytics Cloud, Looker is desirable
Exposure to Google/AWS/Azure/Oracle any cloud based platforms is desirable
Good communication and interpersonal skills

If you have the required skills and the passion to join our high performing team, please apply today.

Employee Benefits
To ensure our employees feel valued, empowered and celebrated we provide a range of employee benefits including:
50% discount on all NRMA insurances
Free Roadside Assistance
12 weeks paid primary and 4 weeks paid secondary parental leave
Free NRMA Blue Membership
At the NRMA Group, we are People Moving People and diversity and inclusion are part of our DNA. Together, we continue to build an inclusive culture that encourages, supports and celebrates the diverse voices of our employees. It fuels our innovation, promotes flexible ways of working and connects us closer to our members and the communities we serve.",2.5,"NRMA Motoring & Services
2.5",Sydney,-1,501 to 1000 Employees,-1,Nonprofit Organization,Casual Restaurants,"Restaurants, Bars & Food Services",$500 million to $1 billion (USD),-1
Data Centre Engineer,-1,"We are a leading world group that provides low-carbon energy and services. To tackle the climate emergency facing us all, our aim is to become the world leader in the zero-carbon energy transition ""as a service"" for our clients – particular for companies and regional authorities. We use our expertise in our key business areas (renewables, gas, services) to provide competitive and bespoke solutions.
The Data Centre Engineer will be employed as part of a 24/7 ongoing shift to coordinate and monitor third party service providers, maintain the data centre facilities and infrastructure plans, coordinate the implementation of customer requests within the data centre and monitor systems, all in accordance with the Contract KPIs and SLAs.
Coordinate and monitor third party service providers for regular maintenance & testing, service faults & call outs, ensuring works are performed in accordance with Contract SLAs
Monitor and maintain the data centre facilities and infrastructure plans and documentation, including electrical, mechanical, hydraulics, fire and BMS/EMS systems
Coordinate the implementation of internal and external customer requests within the data centre
Perform scheduled plant checks and minor maintenance works
Ensure all Work Order requests are raised and closed in a timely manner
Conduct inductions for staff, vendors and contractors
Ensure all work permits for vendor works are raised and closed
Perform inventory checks on all equipment and critical spares

Qualifications
The selected candidate must be able to demonstrate:
Electrical or HVAC background, or Graduate Electrical or Mechanical Engineer
Passionate about quality work and career minded looking for a new challenge
Can commit to a day and night shift roster (2 days of day shift, then 2 days of night shift, 4 days off)
Ideally able to commence asap
As part of carrying out the duties of this role, it is mandatory to hold Australian Citizenship.

If you are interested and meet the selection criteria apply with an up-to-date resume via the apply instructions on this website.

ENGIE Services is an EEO employer, where all applicants are treated with fairness and respect and have equal access to the opportunities available.

We will not be engaging in the services of a recruitment agency to fill this vacancy and therefore request all interested candidates apply directly to this advertisement.

Job
: Maintenance
Primary Location
: Oceania-Australia-New South Wales-Erskine Park
Organization
: ENGIE Services Australia and New Zealand
Schedule
: Full-time
Nature of Responsibility
: Senior operational / administrative role
Job Posting
: Sep 11, 2020, 6:29:59 AM",3.7,"ENGIE Services Australia & New Zealand
3.7",Sydney,-1,5001 to 10000 Employees,1995,Company - Public,Energy,"Oil, Gas, Energy & Utilities",$2 to $5 billion (USD),-1
Senior Data Engineer,-1,"Senior Data Engineer, Temporary, SYDNEY - McKell

Job Title: Senior Data Engineer

Salary: SNSW Grade 9/10 - The package includes base salary range of $111,806 to $134,667, plus employer's contribution to superannuation and annual leave loading.

Location: Head Office – Haymarket

Employment Status: Temporary through till 30th June 2021


About Service NSW:

Service NSW is making it easier for people and businesses across NSW to access government services. The role designs, builds and analyses complex data from multiple sources to identify revenue, process and business improvement opportunities; providing new information and insights to the business to inform planning, continuous improvement and performance.

About the Role

We are currently seeking to appoint a Senior Data Engineer to deliver expert advice and services in the design of a Single View of Customer and data-related services to support the achievement of business outcomes and strategic goals. We support flexible working practices with staff working remotely during this time.

In this role you will:

Design, build and support a modern data platform based in AWS and vendor technologies.
Provide expertise on data modelling for Graph data model and Customer Data Platform (CDP).
Create data pipelines, load, transformation and reporting workloads in AWS.
Work with the latest data engineering technologies like Apache Kafka, AWS Kinesis, AWS Neptune, AWS Glue and AWS Athena.
Contribute to the design and decision-making of the right tool or platform for the job according to requirements.
Provide expert advice and guidance on data quality and data engineering best practices.
Support a “bigger than you can imagine” scale of data in production environments.
Design, develop and support a metrics-driven reporting solution and a meaningful business intelligence platform.
Document the solution design and support procedures of solutions.
Produce reports, visualisations and recommendations to answer complex business problems that are presented in the most appropriate format to ensure clarity for target audience.
Analyse and define new process improvement opportunities to support continuous improvement and business outcomes; providing advice to stakeholders, on ways to improve the efficiency and reliability of data products and services.
Be very responsive to the information needs of the business by corresponding to customers in a timely manner and provide support/solutions to issues raised.
Troubleshoot and perform root cause analysis on production issues. Identify and implement long term solutions to problems. Perform scheduled maintenance, release deployment and production support activities after business hours, from time to time.
Liaise with internal and external customers to discuss and gather requirements, solutions etc. and maintain a good working relationship with the stakeholders.


Skills and Experience Required:

Solid experience with workflow technologies designing and building data pipelines, data models and data stores.
Experience working within and an understanding of Amazon AWS ecosystem, including security and performance tuning.
Hands on experience working with different types of databases, with focus on Graph and NoSQL databases.
Experience with data streaming required. Having used Kafka and related technologies is an added advantage.
Sound knowledge and experience working with batch processing, data extraction and API integration.
Hands on experience with at least one programming language: Java, Python or scripting.
Demonstrated experience working in an Agile based, fast paced, complex environment within cross-functional teams.
Experience developing systematised insights, data analytics and reporting solutions is an added advantage.
Experience with interactive visualisation of data insights is an added advantage.


Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Salary Grade 9/10, with the base salary for this role starting at 111,806 base plus superannuation

Closing Date: 6th November at 9:59am - applications will be reviewed on a rolling basis, applications may close early or extend

Please apply online, direct applications submitted via email will not be considered.

The Department of Customer Service is proud to be an EEO Employer who are fully focused on equality and believe deeply in diversity of all identities making us different and a true reflection of our NSW customers. As an inclusive workplace, we support various employee resource groups, practice flexible work and workplace adjustment.

If you do require an adjustment during the recruitment process, please notify us on your application form.",3.2,"Service NSW
3.2",Sydney,-1,501 to 1000 Employees,2012,Government,State & Regional Agencies,Government,Unknown / Non-Applicable,-1
Data Engineer - Entry / Mid Level,-1,"Work with a great team on interesting projects customers
Gain more experience in AWS, Data, DevOps cloud operations
Got a working knowledge of AWS? We will teach you the cool stuff!

Itoc is seeking an up and coming Data Engineer to join our growing Data Team in Sydney.

This is an exciting role working with databases, data lakes, data warehouses, data transformation (Python SQL) and enabling AI/ML.

You will be implementing foundational, robust and production ready data platforms to enable business data-discovery, self-service, AI/ML functions across a range of client types and industries, allowing them to do more with their data.

You'll be responsible for:

Deploying data repositories such as lakes and warehouses.
Contribute to our growing portfolio of data solutions.
Ongoing optimisation and management of data platforms.
Development of transformational logic for data pipelines
Data evangelism. We want to show our clients how to follow the best practices for data.

Desired Skills and Experience

To take up the challenge, you will have a depth of skills and experience including:

1-2+ yrs of focused data experience working with SQL and/or NoSQL solutions
A solid education in Software Engineering or equivalent industry experience.
Anything Data focused preferred.
Ability to analyse business scenarios and associated data landscape to derive potential opportunities.
Strong foundation in Python and SQL
Working knowledge of APIs
Principle knowledge of the different relational database platforms and modern data storage techniques
Knowledge of the different aspects of data environments
Collect, store, process, verify consume
Experience with version management systems (such as GIT)
Working knowledge of AWS or another cloud platform - we will teach you the cool stuff.
Great communication skills, an ability to work closely with customers, developers and engineers and the confidence to present ideas in open forums.
Relevant tertiary qualifications and/or industry certifications.
Great communication skills, an ability to work closely with clients, developers and engineers and the confidence to present ideas in open forums.

While not required, a background in consulting and professional services is highly desirable.

Itoc Description

This is an exciting and challenging career opportunity to join the growing Sydney-based Data Team of a leading cloud solution provider where you will be given support to reach your long term career goals. You will be part of a team of cloud experts and will work in an environment of continuous improvement and learning delivering innovative cloud solutions across SaaS, online business and enterprise business.

On offer is a chance to join a team with a great working environment, in an organisation that values its employees and sees the value in ensuring they are engaged. Our team are clearly passionate about what they do, that's why we won the following awards:

Customer Obsession Partner of the Year 2015: ANZ Region
Customer Obsession Leadership Partner 2015: re:Invent

As an employer of choice Itoc offers competitive remuneration, training and development programs and a great working environment. We value a healthy work life balance.

The Perks

MacBook or Dell
Continuous internal learning that will provide training and career development opportunities
Working with a collaborative, social team and leveling-up your skills faster than you will anywhere else.
Quarterly social events

Itoc

Culture and smarts are important to us. Bring your secret sauce. This is no ordinary environment, you will work along some of the Cloud’s best. All engineers at Itoc must gain at least five AWS certifications. We work hard but we have fun.

Please note you must have full working rights in Australia and be available on-shore for face to face interviews.

No recruiters please.",4.0,"Itoc
4.0",Sydney,-1,1 to 50 Employees,2013,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Date: 01-Oct-2020

Location:
Melbourne, VIC, AU

Department:Description:
Technology discounts - from Apple HP Lenovo to Windows
Flexible work arrangements - work in a way that suits you best
Salary packaging - to suit your personal and financial circumstances

Do you want to work for one of the fastest growing data teams in Australia? Do you want to work on multiple data platforms and provide new solution offerings by leveraging cloud and big data technologies?

About the team

Big data information and analytics. Three words that spark apprehension in most businesses. But our team of experts are constantly curious and excited about combining our wonderful array of technological expertise to transform data into our clients most valuable assets making their work smarter. Our data consultants are supported with resources training and tools they need to excel at their work but also the freedom and power to create their own paths forward to make a difference.

As a Senior Consultant in Big Data you will work closely with the team and stakeholders to build and deliver a Cloud based vision for a next generation Big Data analytics platform with strong focus on data quality data security and deliver the systems that process huge volumes of data.

What will you typical day look like?

You will play a pivotal role in - Designing and producing high performing and stable applications to perform complex processing of massive volumes of data in a new cloud based architecture; Building real-time data processing applications which are integrated with business systems to enable value from analytic models to drive rapid decision making; Contributing to system architecture design for a data platform (including cloud-based structures both on and off premises data warehouse components and data lakes); this could cover a range of technologies various countries/locations and lines of business; Support data strategy or technology strategy definition programs including technology stack definition and target operating model requirements

Enough about us lets talk about you:
You are someone with:
Use of traditional data analytics tools and techniques (e.g. MSSQL Oracle MySQL) and ETL software (e.g. SSIS Informatica CloverETL)
Working in large scale cloud data solutions using platforms such as AWS or Azure or GCP will be a bonus.
Experience in scripting or programming (e.g. Python Java Scala C#)
Excellent verbal and written communication skills to adapt to technical and non-technical audiences.
Educated to degree level (or have equivalent experience)
Why Deloitte?

At Deloitte we create positively differentiated work experiences that enable our people to feel valued and achieve their full potential. We value difference and embrace people with diverse backgrounds and thinking styles. Knowing that people work best in different ways we are happy to discuss alternative arrangements if the working pattern you are looking for is not specifically indicated.",3.8,"Deloitte
3.8",Melbourne,-1,10000+ Employees,1850,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Engineer,-1,"Opportunity to grow the team
Period of growth
Intuitive app
S2M are working with a FinTech who have created a unique financial product to help thousands of people better manage their finance, and is currently scaling the company to the next level!

They are looking for a Data Engineer to join, and looking for someone who wants to be hands on, with opportunity to grow the team in future.

Role:

Looking for people with strong AWS experience. You will need passion for data and a cloud, through which you will help a rapidly scaling Australian FinTech establish their data infrastructure from the ground up.
5+ years’ experience as a data engineer within the data and analytics domain
A python 3.X aficionado who is very comfortable creating and orchestrating AWS data pipelines with nothing but code
Strong project delivery toolset experience in open source data integration tools
Experience with processing large volumes of complex data including visualisation and insights generation
Ability to define and develop data integration patterns and pipelines
Ability to assess complexity of data (volume, structure, relationship etc.)
Hands on experience working with different databases (RDBMS, NoSQL, Blob storage etc)
Hands on technical expertise setting up DevOps automation
Hands on experience working technologies/platform e.g. AWS, Dockers, Containers
Experience building data profiling and data cleansing frameworks
Technical reconciliation and reporting
Knowledge and experience in end-to-end project delivery, either traditional SDLC or agile delivery methodologies (or hybrid approaches)
Exceptional communication, documentation and presentation skills
If this sounds like you, get in touch today - kate.gabb@s2m.com.au
3167410agsdf",3.1,"S2M
3.1",Sydney,-1,Unknown,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Analysts,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is seeking experienced and qualified Data Analysts to join our IT team based in our corporate office in Birtinya (Sunshine Coast) or at our meat processing facility in Kilcoy.
Key Responsibilities:
A mixture of data analysis and commercial skills to source, blend and analyse data to gain insight and answer key commercial questions
Working with strategic leaders to define and model Key Performance Indicators, and assist in building forecasting models
Working closely with data engineers and BI developers to specify data pipelines and report visualisation
Drive the creation and implementation of data quality business rule including data definition, governance and quality assurance
About You:
To succeed in this role, you’ll need to bring the following experience and skills:
Proven ability to derive insight and knowledge from data using commercial expertise is a strong requirement
Strong SQL and Excel skills are essential, along with strong data analysis and commercial insights
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Effective people communicator - engage with stakeholders on reporting needs, interpret requirements into visual solutions and train/deliver the outputs to the stakeholders getting signoff of acceptance
Bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking

How to Apply:
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kilcoy,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Network Data Engineer,-1,"Min 6+ years of experience in the relevant technologies
Australian Driving License for visiting remote locations / Data Centre for day to day technical work.
Managing Network devices (switches, routers, firewalls, load balancer, and wireless technology)
Performing MACD activities for all network devices.
Supporting BAU operation activities.
Proficient in performing in-depth details of technical troubleshooting, cause and provide recommendation to the client for incidents causing extended network outage to client’s critical locations.
Provide exceptional network services in terms of network support, break-fix, design and consulting, new projects, implementation.
Configure, administer, and document firewall infrastructure.
Manage the firewall deployment, rules migrations, and firewall administration.
Supporting Cloud Migration Activities from traditional to AWS/Azure.
Setting up VPN tunnel with Cloud and 3rd Party network devices.
Integrating and upgrading existing ISP bandwidth with support from ISP Vendor.
Setting up VPN profiles for Users.
Installing hot fix and patches to mitigate the security devices from attacks and bugs.
Reviewing and fine tuning the firewall rules and NAT rules.
Documentation and change control.
Mentoring, Motivating and Guiding support teams
Technical skills:
o LAN
o Wireless
o WAN
o MPLS
o Routing protocols (OSPF,BGP)
o DMVPN
o Azure cloud Networking
o Network Security
Fortigate Manager / Analyzer / Firewall
Cisco ASA
Firepower FTD
Cisco Any connect
Site to Site VPN
F5 Load Balancing and Scripting iRule
Job Types: Full-time, Contract
Schedule:
8 hour shift
Experience:
Scripting: 5 years (Required)
Data Network: 5 years (Required)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Required)",3.6,"Total IT Global
3.6",Sydney,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Engineer - Processing & Analysis,-1,"Job Description:
Design,build and maintain the ingestion system to support various types of data(e.g. User behavior, RDS, NoSQL db and others) to be ingested to the data warehouse more timely and accurately
Translate data requirements into scalable technical data service with low latency and high concurrency
Design,build and maintain the batch or real time data pipeline in production using Hadoop big data technology
Analyze and improve efficiency, scalability, and stability of the system
Define and manage SLA,Data quality for all data sets in allocated areas of ownership
Requirements:
Minimum B.S. degree in Computer Science or a related technical field
2+ years of working experience in programming languages,such as Java,Scala,Python
Familiar with Hadoop, Spark and Flink data processing, experience of TB data processing experience is a plus
Familiar designing and operating of a robust distributed system is a plus
Understand data mining or machine learning
Excited to work intimately with data
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"SYNOPSIS:
Lead Data Engineer
Applications close Sunday 8 November 2020
Ongoing
Contact name: Shyni Sasikala
Phone: (02) 6249 9048
Email: Shyni.Sasikala@ga.gov.au

The Data Policy and Informatics section within the Digital Science and Information branch creates, implements, and promotes policies, platforms and tools that improve and support the quality, discoverability, accessibility, and general usability of Geoscience Australia’s science data products. The section consults with internal and external research, government and industry partners to establish collaborative data frameworks, architectures and models within Geoscience Australia (GA) and across broader national and international communities of practice. The section innovates, builds and maintains tools, systems, processes and governance that enable digital data management, cataloguing and open data delivery.
GA makes accessible a wide range of geoscientific and spatial data to a wide variety of stakeholders in multiple formats, and in recent years GA's data volumes have grown exponentially. GA is focussed on making its data and metadata assets accessible so that they can be used in machine to machine interactions for data analytics and other applications in environments that range from High Performance Computing (HPC), through high-end cloud servers, to mobile devices.
We currently have two opportunities for Lead Data Engineers in the Informatics team. The Lead Data Engineer is responsible for innovating and exploring new technologies that will advance GA’s science goals and maximise the uptake and use of GA’s science data. The Lead Data Engineer reports to the team’s Assistant Director but also works closely with other developers, data scientists and engineers within the Digital Science and Innovation (DiSI) branch, as well as diverse stakeholders both within and external to GA.",3.9,"Geoscience Australia
3.9",Canberra,-1,501 to 1000 Employees,2001,Government,Federal Agencies,Government,$100 to $500 million (USD),-1
Data Engineer,-1,"The Seven Network is part of Seven West Media, one of Australia’s most prominent media companies, with a market leading presence in content across broadcast television, online and in print. Comprising some of Australia’s most renowned media brands, SWM includes not just Seven Network and its affiliate channels 7two, 7mate, 7flix and BVOD offering 7plus, but also 7NEWS.com.au, The West Australian, The Sunday Times and more.
At Seven we are here to bring all Australians closer to the moments that move us - we’re first on the scene, with our finger on the pulse, on demand, in the moment. Together, we’re responsible for creating and sustaining authentic Australian engagement.
A new and exciting opportunity has opened for a Data Engineer to join the Audience Intelligence team. Based in Sydney and reporting to the Head of Data Enablement, you’ll be responsible for:
Implementation of end to end data solutions to support Data Strategy for the SWM group.
Work closely with the Data Solution Designers to develop and maintain scalable data pipelines and build out new file and API based integrations to address requirements from the various business stakeholders.
Collaborates with engineering, analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organisation.
Work on Data Preparation for analytics and data scientist team members and assist them from an engineering perspective in building and optimising the models including building the automation of the end to end workflows
Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.
Perform data analysis required to troubleshoot data related issues and assist in the resolution of production data issues.
Work effectively with vendors for successful delivery of projects and acceptance of the solution
Work on Delivery projects using Agile Software Development methodologies
We are looking for someone who has:
Bachelor's degree in computer science, computer engineering or other technical discipline is essential
Proven experience working as a digital analytics specialist
Extensive experience with digital analytics implementation (e.g. Google Analytics, Snowplow, Adobe Analytics) and BI processes and visualisation platforms
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience in ETL and building and optimizing ‘big data’ pipelines and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Experience with big data tools: Hadoop, Spark, etc., AWS cloud services: EC2, S3, Lambda and familiar with version control systems: Git
Strong coding skills with knowledge of Unix/Linux and scripting languages such as Unix Shell scripting, Python desirable
Experience supporting and working with cross-functional teams in a fast-paced environment.
Ability to multi-task and problem solve with changing demands and priorities
Ability to work under pressure to meet deadlines and detail oriented
Your success is our success: we will provide you with opportunities for you to keep learning and growing, enabling you to challenge and develop yourself. In return, we offer a benefits program that has something in it for everyone.
Seven West Media is an equal opportunity employer and we are committed to creating a diverse and inclusive workplace.
Recruitment Agencies: Seven West Media does not accept any unsolicited agency resumes and will not be responsible for any fees related to unsolicited resumes.
Advertised: 19 Oct 2020 12:00 AM AUS Eastern Daylight Time
Applications close:

Back to search results",2.5,"Seven West Media
2.5",Sydney,-1,5001 to 10000 Employees,1956,Company - Public,TV Broadcast & Cable Networks,Media,Unknown / Non-Applicable,-1
BICON Rules Engineer,-1,"APS 5 - $73,299 - $80,410 per annum plus superannuation
Biosecurity Plant Division
Canberra, ACT
Play an active role in managing biosecurity risk to Australia
Work in a motivated and professional team with a wide range of skills and backgrounds
Full training provided

Who we are
The BICON Content Development Team maintains and improves the Biosecurity Import CONditions database (BICON) content to allow external clients to understand and comply with their biosecurity obligations and internal clients to effectively manage biosecurity risk and regulate imports. We work collaboratively with internal clients to comprehend and implement their BICON content requirements and optimise the use of BICON to publish clear import requirements and onshore management support procedures to effectively manage biosecurity risk.

The Jobs
Key duties of these positions include:

working with business content (import and permit conditions) and import programs to understand and construct decision tree structures in the BICON database, in accordance with system design and authoring conventions
executing changes to import and permit conditions in alignment with service standards while complying with system rules and authoring conventions
providing technical advice through various formats on the most appropriate means of authoring BICON content to achieve import program and stakeholder objectives
using workflow management tools to maintain detailed records of changes to import conditions and key decisions
performing administrative tasks including system reporting, data analysis and scoping tasks for the BICON content change work program
contributing to the development and maintenance of instructional material, authoring conventions and courseware
clearly documenting and reporting system issues
developing and maintaining effective working relationships with internal and external stakeholders.

What we are looking for
Knowledge and experience
Experience working with complex IT systems.
Experience working collaboratively and as part of a team.
Knowledge of the role of biosecurity is preferred but not essential.

For additional information, please read the Job Description below.
Candidate Information Package docx Opens in new window",3.9,"Department of Agriculture & Water Resources
3.9",Australia,-1,5001 to 10000 Employees,-1,Government,Federal Agencies,Government,$500 million to $1 billion (USD),-1
Cloud Data Engineer,-1,"Job no: 509605
Work type: Permanent Full Time
Location: Melbourne, Canberra, Sydney
Do you embrace digital disruption?
Do you love solving complex problems, designing sophisticated solutions and building innovative technology?
Do you believe in creating powerful actionable insights from Data and Analytics?
Do you want to work in a diverse and flexible working environment?
KPMG is one of the most trusted and respected global professional services firms. Through depth of expertise, clarity of insight and strength of purpose we help our clients solve complex challenges, steer change, strengthen, transition and grow. We are a team based practice and this extends to our clients whom we work and collaborate with, in solving complex problems. Together, we design, innovate and implement, providing enduring advice that support our clients and the services they deliver. Our clients vary in size and come from a diverse range of sectors – all sharing in a common goal: to embrace change and deliver services that make Australia a better place. We are looking for talented individuals who would like to join us on the journey.
KPMG’s Digital Delta Team
We re-imagine and re-invent organisations to become world class digital enterprises using advanced technologies, data and human insights. We help organisations to embrace Digital Strategy, Artificial Intelligence (AI) & Cognitive, the Internet of Things (IoT), Data, Analytics & Modelling, Mobile App & Web, and User Experience (UX) & User Interface (UI) and more.
We work with clients to:
Formulate strategies that re-imagine organisations
Harness innovation from the 4th industrial revolution
Actioning insights from trusted data to consistently and quickly make clear decisions
Build adaptive organisations
Thrive as a connected enterprise – front, middle and back office
This is how you’ll contribute:
We are looking for ambitious Data Engineers who are passionate about helping clients define bold ambitions and deliver on them. Joining our team will take you on a journey of personal and technical growth and provide the opportunity to inspire confidence and empower change.
As a Data Engineer you are the designer, builder and manager of the information or ""big data"" infrastructure, preparing data for analytical or operational use. You will design, construct, test and maintain a data pipeline to pull together information from different source systems; integrating, consolidating and cleansing data; and structure it for use in individual analytics applications.
The KPMG Difference
Our people are focused on creating a diverse and dynamic environment that embraces and values differences. We value the variety of unique experiences, qualities and characteristics our people possess and we share and learn from each other.
We are proud to be consistently recognised as an employer of choice for women, and for our achievements in LGBT+ workplace inclusion.
Our commitment to ‘Flexibility’ allows our people to manage the changing demands of work, personal or family life. Explore the links below to hear our people share their experience @ KPMG:
Flexibility empowers wellbeing
Flexibility enables contribution to the community
Flexibility inspires technology & innovation
Flexibility supports family

Make KPMG the clear choice for your career and be Extraordinary!

Advertised: 09 Sep 2020 AUS Eastern Standard Time
Applications close:",3.8,"KPMG
3.8",Sydney,-1,10000+ Employees,1987,Subsidiary or Business Segment,Accounting,Accounting & Legal,$2 to $5 billion (USD),-1
Computer Network and Systems Engineer,-1,"Duties Include but are not limited to:
Tasks Include:
analysing, developing, interpreting and evaluating complex system design and architecture specifications, data models and diagrams in the development, configuration and integration of computer systems
researching, analysing, evaluating and monitoring network infrastructure to ensure networks are configured to operate at optimal performance
assessing and recommending improvements to network operations and integrated hardware, software, communications and operating systems
providing specialist skills in supporting and troubleshooting network problems and emergencies
installing, configuring, testing, maintaining and administering new and upgraded networks, software database applications, servers and workstations
providing network programming in support of specific business needs and requirements
preparing and maintaining procedures and documentation for network inventory, and recording diagnosis and resolution of network faults, enhancements and modifications to networks, and maintenance instructions
monitoring network traffic, and activity, capacity and usage to ensure continued integrity and optimal network performance
Skills and Experience Required:
Must have experience working in a Managed Service environment
Demonstrated experience in IT Networks and Data Centres
Understanding of systems and architectures to meet client needs
Experience in Help Desk including break / fix
Effective and timely documentation
Effective Task Management Skills
Be solution and outcome focused and willing to learn new technologies
Excellent communication skills with staff, clients and partners
Time management, ability to prioritise and deliver to schedule
Experience with N-Able and Connectwise desired
Open Cabling license desired
Job Types: Full-time, Permanent
Salary: $30.00 per hour
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,Trans-plant training,Canberra,-1,-1,-1,-1,-1,-1,-1,-1
Software Engineer (Data),-1,"If you are looking for an opportunity to make a real impact with smart people who are genuinely doing things differently then you've come to the right place! We're growing our data engineering capabilities and are looking for awesome data engineers to join our team.
With our diverse range of clients and projects, no day will look the same - but here's a great snapshot of what you'll be doing:
Work with some of the best Data Scientists and Engineers to deliver production-grade AI and Machine Learning systems as we deliver client projects from inception to production.
Consulting with our clients and working with them to build modern data systems using the 'best of' technologies and principles.
Advising clients on data strategy, architecture and technology.
Applying best software engineering practices in coding, monitoring and alerting, using CI/CD, TDD and cloud architectures.
Working over a wide range of big data tools and environments: not limited to; Apache Kafka, Spark, Python, Scala, Hive, Airflow, AWS EMR & Glue, GCP Dataproc & Dataflow, BigQuery, Snowflake, Redshift.
Who are we?
Glad you asked! We are Eliiza. Data science. Engineered for scale.
We are a passionate team of data scientists and engineers who apply data science and machine learning to solve real-world problems. Our mission is to create a bright future for Australian businesses and society in a world increasingly influenced by intelligent technologies.
We've created a culture that values diversity where people can truly be themselves! We care a lot about growing the Australian AI community in a positive direction, and we're doing several things to try and achieve that:
We provide opportunities for underrepresented groups to work in AI through our associate and intern programmes
We organise and participate in a range of community events, reading groups and meetups
We produce the AI Australia podcast
We blog about topics we care about
We stream brown bag sessions to the broader community
We're also part of Mantel Group's 'house of brands' which means it's not just the Eliiza team you'll work with, learn from and see at social events - there's another 230 of us across DigIO, Kasna & CMD Solutions!
So you're ready for something new?
We're keen to know more about you! Our team is made up of a range of people, with different experience across a huge range of data driven skill sets.
We'd love to hear from you if you have experience with:
one (or more) core language(s), ideally Scala, Python or Java
one (or more) cloud platforms, AWS, GCP, Azure
ETL/ELT concepts and technologies e.g. Data partitioning, Hive, Spark
streaming data concepts and technologies, ideally Kafka (Kinesis, Beam or Pubsub will do)
We'd be over the moon if you:
Experience with distributed/columnar databases (e.g. Snowflake, Big query, Redshift).
Experience with any of a variety of databases e.g. RDMS, NoSql, Columar, Distributed, Time series, Graph.
Knowledge of job orchestration and scheduling. Any experience with Airflow, Luigi or Oozie.
Experience with containers and container orchestration (Docker, Docker Compose or Kubernetes).
However, we value a diversity of skill-sets, and don't necessarily require that you're skilled with all of the above. If you feel you don't fit all the experience/skills listed above we still encourage you to apply or get in touch.
What's on offer if you join us?
We make sure you're always one step ahead by investing your learning and development, every year. We build our own training where it doesn't exist yet.
We hire smart people and get out of their way. By focusing on our five principles and not getting caught up in red tape, we trust you to get the job done.
You'll get all the tools you need - a new iPhone or Google phone, a new Macbook Pro or Dell, and a lot of branded swag!
But hold on, you mentioned a house of brands?
We certainly did! Mantel Group is an Australian-owned, 'house of brands' company with four technology businesses (Eliiza being one of them!) across Melbourne and Sydney. We're building a group of companies with open borders so we can support you to take on new skills without leaving an awesome team - we understand you won't have one job for life!
We may only be just two years old but Mantel Group has already been recognised #9 in the 2020 Best Places to Work in Australia and #4 in the AFR's 2020 fastest growing new companies.
Keen to chat?
Click ""Apply"" to share your details with our talent team, and we'll be in touch.
In the meantime, check out 'how we hire' to find out what's in store if you're successful and get to know us better by visiting our website and following Eliiza on LinkedIn.",-1,Eliiza,Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Infrastructure Engineer,-1,"Job Description:
Design and grow the Shopee data platform to support a variety of big data applications using open-source technologies including Kafka, Hadoop, Presto, HBase, Spark, Hive, Druid, and our own creations. Some examples include a real-time data streaming platform, a unified query platform, a cluster management system, and a machine learning platform
Dig into the source code of some open-source big data system to get the whole control and familiar with the details, configurations, designs and source code. Develop and maintain the internal release of big data systems and components as the business requirements.
Keep close and overall monitoring for all the deployments of the systems, maintain the system’s stability, improve the performance, discover the performance bottlenecks, tracking and troubleshooting, cost optimisation.
Requirements:
B. Sci. / Ms / PhD in Computer Science or a related technical field
Familiar with at least one of these languages: Java, Scala, Python, Bash under Linux / Unix. Scala is a plus
Familiar with the use and compute logical of SQL
Knowledge about the Big Data Infrastructure system technology like Distributed File System, Distributed Computing, Distributed Database will be a plus
Hands-on experiences Hadoop, Spark, Kafka, and/or Presto will be a plus
Love to use and develop open-source technologies
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"Work on an award-winning, international technology!
Endless career opportunities
An innovative, friendly team of 300+
This role will be focused on the development of our existing ClaimLogik line of products as well as working on our new cloud-first, modern suite of applications.

Intelligent Thought, our technology business is scaling and shipping our software globally. Already profitable, part of a much larger group business, with investors such as Macquarie Capital and Envest – we are all set to deliver textbook disruption to the Insurance Industry. The growth of the platform, of our customer base, and the increasing industry demand have led to the need for this role to help the team scale.

Our Philosophy
Give each employee a sense of purpose and an environment for them to connect the importance of their role to delivering a service that matters to our customers.
Challenge the ‘why’ of traditional claims processes.
Keep it simple – do only what brings value and what matters to the customer
Enable employee decisions, empower our people
Responsibilities:
Create, extend and maintain ETL pipelines to form our data lake, data warehouse and analytics platform (currently using the Microsoft Azure set of tools and service)
Help define the optimal data pipeline architecture
Influence the tool selection, platform selection, data architecture and strategy which will transform the business to be truly data-driven
Understand, analyse and size user requirements
Work with different parts of the business to provide them with the insights they need to deliver the best results
Skills & experience:
Degree or qualification in computer science or related
Advanced knowledge of relational database, including query authoring and query optimisation (MS SQL Server and PostgreSQL).
Experience building and optimising ETL pipelines
Experience designing complex data models
Experience working with cloud platforms (Azure or AWS)
Efficient time management and organisational skills
High attention to detail and accuracy
Effective communication skills to build strong working relationships; both written and verbal
Proactive and results-driven
Why Claim Central?
Claim Central Consolidated is a global insurance industry leader across, claims management, insurance technology and data and analytics. Currently operating in the United States, Australia, South Africa, Italy and New Zealand, we have pioneered digitally connected claims management services across the globe. Claim Central is a disruptor and thought leader in the industry and we were recognised as the Australian Financial Review’s 8th Most Innovative Company in Australia in 2016. This business is in a period of unprecedented growth, transitioning our technology and services into multiple geographies at a rapid pace. Our unique culture is based on teamwork, collaboration, trust, respect and performance. We also offer many benefits apart from our exceptional team culture; including flexible work arrangements, and continued professional development.

Be a part of this journey in a career-defining role.",-1,Claim Central,Matraville,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer - AI/ML,-1,"Our client provides services to a major industry across the country. The business is still early in it's days of technology development and the environment is greenfields in nature (no pun intended), effectively working like a start-up.

Their data and analytics team have worked and built leading and bleeding-edge technologies in this space and what they have created so far may be game-changing. From a machine learning perspective, the progress they have made to the business has already seen proven success in changing the future of an industry that will have positive consequences for all those involved.

You will have previously worked in a technical capacity in the data and analytics space and have experience working with an organisation where machine learning has been implemented, not just a concept that the business talks about having or the technology team would love to have. The commercial experience you will have had in the ML field will be proven examples of where you have affected the way a business or industry used to perform, to the changes that have come about from this.

Technically, you will have extensive experience in the Microsoft space - Power BI, Azure etc and you will have previously mentored and coached junior members of the teams you have been part of.

This is a rare opportunity in Brisbane where the business has truly embraced and funded projects across the ML space and would be a great chance for those in the Data Development/Data Engineering field, who are looking to move into a Data Scientist role in the future.

Please send your application through if you would like to know more.",4.0,"Emanate Technology
4.0",Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Solution designer/ ETL Engineer & Data Modeller,-1,"We are looking for a Qualified and Experienced Solution Designer to join our client for a period of 6 months with a view to extend.
You will work closely with team members and your contribution will range across gathering and analyzing information, developing and documenting improved processes and work instructions and experienced DWH Lead with skills in requirement analysis, solution designing, developing, testing and supporting ETL solutions.
A hands-on solution designer, data modeler and ETL developer for Data Warehousing and ETL application transformation projects using Informatica PowerCenter.
Knowledge on AWS, S3, Redshift, Informatica BDM, and related technologies.
Experience working with IPython, PySparks, AuCuMo, Airflow, Jenkins, Github, Athena, JIRA, Rally, Spectrum, Glue, Flyway.
Good exposure on Oracle PL/SQL, aware of DBA activities, writing and performance tuning of complex SQL queries.
Contract length: 6 months
Job Types: Full-time, Contract
Salary: $650.00 – $800.00 per day
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,nducive,Melbourne,-1,-1,-1,-1,-1,-1,-1,-1
"Data Engineer, Wollongong NSW or Mount Waverley VIC",-1,"Company Description
BlueScope is a technically advanced supplier of steel and steel products in Australia. We are an inclusive organisation and every day we showcase our technology and expertise throughout the world.

Job Description
We are looking for two Data Engineers to join our IT team, based in Wollongong NSW or Mount Waverley VIC. Use your experience in analytics to unlock business value, enabling use of big data for insights and decision-making.
Reporting to the Data Product Owner for our Australian Steel Products (ASP) business, this position will support strategic goals related to data. This will see you:
Gather business and technical requirements with the view to deliver outcomes;
Develop and implement end-to-end data collection, consolidation, modelling and visualisation solutions;
Document metadata in a dictionary and catalogue;
Ensure consumers of such information understand its accuracy, timeliness, quality and sensitivity, so that it is used appropriately; and
Identify opportunities to enhance analytics.
What are the benefits?
Work in a supportive and collaborative team environment whilst we embark on a journey to transform the way our business uses data!
Our systems landscape is broad and diverse. You will be encouraged to think creatively to develop data solutions which solve real business problems.
Working in this role you will enjoy:
the chance to learn more about data science;
salaried remuneration with attractive superannuation options;
the opportunity to participate in a performance incentive scheme; and
access to further development and career opportunities with BlueScope.
Who are we looking for?
We welcome applications from professionals with experience in data analytics and/or programming. Supported by your knowledge of project delivery methods (e.g. Agile), you will demonstrate:
experience with data mining, wrangling, mapping and visualisation techniques (e.g. Azure Data Factory, Databricks and/or DevOps etc.);
well-developed ability in gathering business and technical requirements;
skills in developing and implementing collection, consolidation, modelling and visualisation solutions; and
a passion for sharing your knowledge and desire for ongoing professional development.

Qualifications

null

Additional Information
We're proud to have been named an Inclusive Employer for 2019–2020 by the Diversity Council of Australia. We believe that our people are our strength. Having a diverse and inclusive workplace enables us to improve our capability and ensure continued, sustainable success.
We know that workplace flexibility can mean something different to everyone. Under our B-Flex initiative all of our roles have some degree of flexibility. We encourage you to discuss your needs with us.
Applications close Sunday 25th October 2020.",3.3,"BlueScope
3.3",Wollongong,-1,201 to 500 Employees,-1,Company - Private,Construction,"Construction, Repair & Maintenance",$100 to $500 million (USD),-1
ETL Data Engineer,-1,"ETL Data Engineer

Join a team that’s changing how Australia lives, works, plays and grows
We want you to be the best version of you

Work with innovative teams and explore new technologies to help solve real-world problems.

A typical day as a Data Engineer

ETL / Big Data Engineering professionals will be responsible for guiding the full lifecycle of a Data solution, including:
Working in highly client-facing roles to contribute throughout the end-to-end delivery lifecycle of complex and large-scale digital solutions
Use case and business case development
Support existing and new applications utilizing in-depth technical and data knowledge. Troubleshooting complex issues and providing advisory services to improve the client’s data landscape
Help to streamline and simplify the clients’ complex data landscape by integrating different applications and data architectures
Implementation from requirements analysis, platform selection, digital architecture design, application design and development, testing, and deployment
Interstate travel may be required

Basic qualifications:
Bachelor’s degree
Experience across systems integration, information management, data management and architecture, and business analytics
Experience with being in a team focusing on large-scale, multi-release information centric projects
Experience with waterfall and agile delivery and run / application support functions
Part of a team working on End to end implementation of at least 1 big data project

Preferred Skills:
Hand on experience in Data warehousing using ETL tools such as DataStage, Autosys and TeraData
Hands on experience in ETL job development with multiple stages like sequential file, Transformer, Lookup, join, sort and Database stages.
Strong hand on skills in design, development and implementation of various data remediation, Data migration, data integration techniques.
Strong hand on data modelling experience.
Strong hands on experience in database performance tuning including complex query optimizations and physical database tuning using Teradata.
Understanding of architectural designs and strategy related to data migration, data cleansing, data quality and data consolidation.
Proven data analysis, requirement gathering and problem-solving skills
Exposure to Unix environment and shell scripting.
Experience in Banking and Financial services industry
Desirable: Knowledge of cloud computing infrastructure (e.g. Amazon Web Services EC2, Google Cloud, Microsoft Azure)
About Accenture

Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. We combine unmatched experience and specialized capabilities across more than 40 industries — powered by the world’s largest network of Advanced Technology and Intelligent Operations centers. With 513,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises. Visit us at www.accenture.com.

Accenture is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, marital, domestic or civil partnership status, sexual orientation, gender identity, or any other basis as protected by applicable law.

Vera Goga is the Recruiter managing this role. As the team experience high volumes of applications, we appreciate your patience to allow for a fair and timely process.",3.9,"Accenture
3.9",Sydney,-1,10000+ Employees,1989,Company - Public,Consulting,Business Services,$10+ billion (USD),-1
Student Engineer,-1,"The candidate will have the ability to:
Undertake onsite inspection to collect asset condition data based on the relevant engineering standards and technical guidelines;
Undertake desktop analysis to evaluate the condition and performance of the assets;
Provide the appropriate information, advice, engineering input and support services for the sustainable management of Council’s stormwater and transport networks.
Qualifications:
The successful candidate will be enrolled in a Bachelor of Engineering with a minimum of two years completed.
Position Number: 100678
Position Hours: Fixed term (3 months), hours will be negotiated with the successful candidate, maximum of 75 hours per fortnight.
Salary: Schedule A, Salary Point 4.0. $28.64 per hour ($55,853.45 per annum, pro-rata) in accordance with Glenorchy City Council’s Enterprise Agreement 2016
Please note that all successful applicants will be required to provide a current National Police Check prior to commencement of employment.
For further information on this position, contact Patrick Marshall, Senior Civil Engineer on (03) 6216 6800.
How to apply: Applications for this position must be lodged on this submission site or on the Glenorchy City Council website www.gcc.tas.gov.au - Careers page.
To be considered for this role, all applicants must address the key selection criteria in the and provide a current resume. A copy of the position description can be found by clicking the below hyperlink or on the Glenorchy City Council website.
Applications close at 8pm on Sunday, 1st November 2020
- Student Engineer",4.0,"Glenorchy City Council
4.0",Glenorchy,-1,501 to 1000 Employees,-1,Government,-1,-1,Less than $1 million (USD),-1
Data Engineer involving DevOps,-1,"Data Engineer involving DevOps
Axiom Technologies is an Australia based entity with the history of providing Managed IT solutions to medium to large scale enterprises globally. Please visit our website for more information about what we do at www.axiomtechnologies.com
Axiom Technologies is an Equal Opportunity Employer and encourage applicants from all backgrounds and gender to apply, including, Aboriginal and Torres Strait Islander candidates
Job Requirements:
8+ years IT experience, with at least 5+ years of “Data Engineer/Deveoper” focused titles/roles,
Data Tools: Hands on experience with Apache Beam.
Testing: Hands on experience with automated testing activities/outcomes
DevOps: Experience with the processes involving Microservices facilities for artifacts developed
Platform/OS: Mid-range/Unix
Languages: Unix (Shell) Scripting/commands, SQL, Python
File formats: Text, CSV, Parquet, JSON, XML
Scheduling: Jenkins, Airflow
Auto Scripting: Designing/creation of scripts for repetitive activity. E.g. Unix scripting/SQL
Big data: Exposure to Data Lake Concepts, Hive (Schema), HDFS
Source Control tools: GIT
Delivery Models: Agile, Scrum
Ingestion Design: Create/assess Source/Target data mapping designs
Frameworks: Development and delivery frameworks
Activity Reporting/Repository: Jira, Confluence.
Quality: Accuracy and attention to detail
Industry: Financial Services/Banking
Solutions: Define solutions from High level to detail design to address automating ingestion activity. Facilitate/confirm requirements from product owners, business team members and technical associates,
Process Automation: Automating processes in file management, testing data in files, analysis and design, configuration management.
Script Automation: Ability to design/create scripts to automate/improve data copy/migration/ETL for any repetitive activity.
Languages: Java, Python
Scheduling: Control-M
Databases: Relational. E.g. POSTGRESS, Oracle – as a ETL developer
File Formats: Mainframe – experience with referencing its data formats/copybooks
Big data: Experience referencing/using Hive (Schema) to access data in HDFS
Metadata management tools: MDM, EDC and Axon
Performance: Assess, recommend, improve mappings, SQL queries, Batch feeds
Automation Tools: Other tools that may add value to an automation program and generally support development. E.g. API, REST, JDBC, Webservices, Message Queues/Load balancer,
Cloud: Experience with processing of data files to be ingested/stored in the Cloud, preferably with AWS.
Prod Support: Experience in a production support role performing root cause / impact analysis – under time constraints
Experience in a similar role
8+ Years
What next?
If you are looking for that next challenge in your career and wish to apply for this role, please forward your resume to careers.au@axiomtechnologies.com",2.0,"Axiom Technologies
2.0",Melbourne,-1,1 to 50 Employees,-1,Company - Private,Industrial Manufacturing,Manufacturing,Less than $1 million (USD),-1
Data Engineer,-1,"About the Role
We are on an exciting digital journey so it’s a great time to join ME! We are seeking a Junior Data Engineer who enjoys rolling up their sleeves, learning and growing. As part of our Enterprise Data Team, you will ensure fit for purpose data warehouse solutions are built for use across the bank and by utilising best practise ETL standards, whilst ensuring the data is trusted by our BI developers and key business consumers. Oh, and you’ll get to work on Microsoft technology stack too!
You will be involved with investigating data issues, keeping data feeds flowing and collaborating with different projects across the bank to deliver quality data solutions. How important does that sound? What’s even more important is this role contributes directly to our overall business strategy through the provision of data to enable analytics & reporting, as well as supporting business and decision system processes.

About You
You’re naturally a highly motivated and energetic person who thrives in a dynamic, ever-changing collaborative team environment. Ideally you have previous experience as an ETL developer, Data Engineer or a BI developer, and if you have a degree in computer science or similar it would really put you ahead of the rest.

With your knowledge of SQL coding, data modelling, understanding of data warehouse concepts, plus experience of working on complex ETL solutions, you’re ready to expand your horizons and launch your career into the world of IT at ME.

About ME
We’re not like other banks.
ME was created by the industry super funds to be different from the pack – with a core purpose to help all Australians get ahead financially – no conditions, asterisks or exceptions. And we know that looking after customers starts with taking care of our people.
We believe everyone deserves the same opportunities in life, regardless of gender or identity, sexuality, ethnicity, religion or disability ‒ with internal affinity groups.
Perk ME up
Once you get your feet in the door at ME, we’ll put them both in your very own ME-branded Converse shoes. You’ll also get the following financial, health and fun perks when you join the team:
4U Extras portal (discounts and cashback on 100s of items including cinemas, shopping and gym memberships
10% Myki discount
Purchased Leave programme
Internal wellness programme (Mindfully ME)
Professional education through LinkedIn Learning
Novated Leasing
Professional membership reimbursements
Health checks
Financial education (To help you manage your money smarter)
LGBTIQ+ and Women at ME affinity groups

I want those Converse shoes (and the role)
Can’t see a closing date on the advert? That’s because we’re pretty efficient here at ME and we may start looking at applications sooner rather than later, so if this role sounds like your jam, be sure to apply by submitting your resume today.

Should an applicant be the preferred candidate, background checks (including police checks, reference checks, ASIC banned and disqualified persons and bankruptcy checks) will be completed prior to the candidate's employment being confirmed. The outcomes of the background checks do not automatically bar candidates; however will be assessed against the inherent requirements of the job.
Back Share
Apply Now",3.0,"ME Bank
3.0",Melbourne,-1,501 to 1000 Employees,-1,Company - Private,Banks & Credit Unions,Finance,$100 to $500 million (USD),-1
Software Engineer - Machine Learning/Data Science,-1,"Zendesk is looking for a Software Engineer - Machine Learning/Data Science for a full time position in our Melbourne office.
As part of our engineering team, you will work at a scale where the challenges start to get seriously interesting. Our global engineering team is widely dispersed over the world, with people across nearly every continent. You will get a chance to do cool things with a diverse bunch of people while working in the Melbourne office that is home to Zendesk’s first machine learning (ML) research team.
The Data Science Team, together with Data Engineering, have built Satisfaction Prediction, Answer Bot and Content Cues — products that use Machine Learning (ML) and Artificial Intelligence (AI) to help our customers work more efficiently.
What you get to do every day:
We’re currently looking for someone to join our team as we research, develop, and productionise Machine Learning and Deep Learning models. In addition to frequenting Melbourne’s finest purveyors of coffee, ramen, and bulgogi, you may find yourself:
Building machine learning models including neural networks in TensorFlow
Writing and deploying production-grade Python
Querying and constructing datasets in AWS Athena, Spark
Evaluating and responding to real-world model performance
Scaling your ML to millions of predictions per day
Presenting your work to a broader audience
Watching your algorithm help Zendesk’s end-users
What you'll bring to the role:
A strong foundation in a quantitative discipline (e.g. machine learning, statistics, bio/eco/etc-informatics, econometrics, etc) is critical for this position. While experience in deep learning and natural language processing would be beneficial, your best qualities are:
dedication to continuous learning
collaborative work attitude
strong communication skills
You should also be comfortable with at least one programming language, such as Python, R or Scala.
Application Deadline: 18/11/2020
Job Types: Full-time, Permanent
Salary: $85,000.00 – $110,000.00 per year
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Temporarily due to COVID-19",4.5,"Zendesk
4.5",Melbourne,-1,1001 to 5000 Employees,2007,Company - Public,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),-1
Software Engineer (Machine Learning),-1,"About the Role
AdelaideMRI is building a medical reporting tool. We require an engineer to work primarily on machine learning projects to improve reporting speed and report comprehensiveness.
You will perform data analysis of medical report datasets and image datasets to infer sentence recommendations, image classifications, or other actionable results for the doctors.
Skills and Experience
Background in machine learning or image processing
Qualifications in Computer Science, Software Development or Engineering or equivalent experience
Bonus points for Python
No prior medical knowledge is required.
This position offers flexible hours and work arrangements.
Job Type: Full-time
Experience:
Software Engineering: 1 year (Preferred)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Yes",-1,Adelaide MRI,Australia,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Hey there, we’re PEXA!

We started as an idea: to deliver a single, national e-Conveyancing solution. We collaborated with the industry to create a national electronic lodgement and settlement platform: PEXA. From our humble beginnings, we’ve now grown to more than 320 employees across 5 different states. We’re still expanding at a rapid rate and constantly challenging ourselves to create great experiences for our members as they transition to fully digital conveyancing.

Why become a PEXArian?

Great question! Being a PEXArian is so much more than just a job. We are passionate, motivated & unashamedly enthusiastic at PEXA - we love what we do and we’re proud to admit it! Creating brilliant member experiences wouldn’t be possible if we didn’t also strive to create an amazing employee experience. Alongside our members, our employees are at the heart of everything we do.
Here’s a snapshot of what your life at PEXA could look like:

Your growth:
We encourage you to hit your personal and professional Learning & Development goals with our tailored programs and tools.

Your wellness:
We care about your holistic well being - a fully stocked kitchen, four wellness days, a $250 wellness subsidy as well as lunch and learn sessions to support your financial well being.

Your work/life blend:
We know that work is just one aspect of your life, we want to help you create your ideal work/life blend, rather than squeezing in life around work.

Your family:
With a range of benefits aimed at supporting your family including access to a subsidised school holiday program, extended parental leave and flexi-time to support your return to work, superannuation payments for unpaid parental leave for primary carers and a childcare allowance for pre-primary aged children, when we say, ‘welcome to the family’, we really mean it!
The impact you'd drive:
The successful candidate will be responsible for developing, and maintaining infrastructure to support the delivery of new and existing products. They will also be contributing to establish the rules and frameworks for obtaining the required approvals for new products.
On day one we’d love you to have:
Experience with Python, Spark
Event streaming/sourcing with Kafka or AWS Kinesis
Experience with data structures, formats and data security best practices
AWS experience (e.g CloudFormation, S3, ECS, Lambda, SQS, IAM, KMS, DynamoDB, Glue, Athena)
Query construction and optimisation (e.g. SQL, Elasticsearch, Splunk, DynamoDB)
Git, version control practices, and continuous integration/delivery servers
PyUnit and unit testing frameworks
Production release cycles and maintenance
Collaborating with technical and non-technical teams
Even better:
Agile methodology/delivery
GraphQL
Modern frontend technology (e.g. ReactJS, TypeScript)
Machine learning frameworks and tools (e.g. TensorFlow, PyTorch)
OAuth 2, SAML 2, JWT
Data visualisation and exploration tools (e.g. Jupyter notebooks, Tableau)
AWS SageMaker
Sounds like you?
If this role sounds like you, apply today to have your application reviewed ASAP!",3.9,"Property Exchange Australia Limited
3.9",Melbourne,-1,201 to 500 Employees,2010,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Ongoing position
Full time
Based in Sydney, NSW
Who we are
Australian Red Cross is part of the world’s largest humanitarian organisation. Our aim is to improve the lives of the most vulnerable people in Australia and across our region.
About the role
The Data Engineer role will sit within the Data and Integration Squad in IT and will own (design, implement and support) the AWS Big Data technologies such as the Data Lake and Data Warehouse and support the organisation in growing the data analytics capabilities at Red Cross. In addition to this, the data engineer role will also administer the Power BI tool and support the implementation of the data mastering capability.
What you will bring
Experience building and optimizing data pipelines, architectures and data sets.
Experience in dimensional modelling and building data vaults
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with structured, semi-structured and unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Why work for us?
Work for purpose and know that your work assists Red Cross support and empower people and communities in times of vulnerability.
Generous salary packaging options available that can increase your take home pay.
Further information
To find out more about this opportunity please see the position description below or contact Sharath Kumar Gurram on 02 8651 8839.
Position Description: Position Description - Data Engineer .pdf
Applications for this position will close at 11:55pm Thursday, 5 November 2020.",4.1,"Australian Red Cross
4.1",New South Wales,-1,1001 to 5000 Employees,-1,Nonprofit Organization,Industrial Manufacturing,Manufacturing,$500 million to $1 billion (USD),-1
Junior Fullstack Data Engineer (Python and React),-1,"Formbay is the leading Renewable Energy Certificate Trading company in Sydney. We provide Digital Workflow and Compliance solutions in the renewable energy industry and document processing.
Thanks to our meteoric growth and our commitment to be the best at all we do, we've identified the need to bring on board a new Junior Fullstack Data Engineer.
Reporting to our Principal Machine Learning Engineer, you will help build Machine Learning pipelines for our existing Digital Workflow and Compliance solutions to automate fraud detection and document processing over terabytes of photographic and documentary data – including documents, photos, GPS data and aerial/satellite photography.
Our stack is based on Python, JavaScript, Dask, Tensorflow, CUDA, Nix/NixOS, AWS, Docker, PostgreSQL and more – familiarity with these applications will give you a leg-up on the competition.
Our ideal candidate will have the following competencies:
SQL
Python
JavaScript/TypeScript
Our candidate must also be comfortable working with Linux.
Located a stone's throw away from the Queen Victoria Building in Sydney's bustling CBD, we are centrally-located with easy access to public transportation, bars, cafes and fine dining.
Formbay will provide flexible working hours, a generous remuneration package and the opportunity to work on a world-first software solution are what we can offer you. Free, twice-weekly gym sessions and really, really good coffee are also available.
No hiring/recruitment agencies need apply.",5.0,"Formbay
5.0",Sydney,-1,1 to 50 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is an experienced and qualified Data Engineer to join our IT team based in Birtinya.
Key Responsibilities:
Create and maintain data pipelines and or ETL scripts
Create and maintain data integration including API and Batch interfaces
Performed detailed data analysis
Create and maintain corporate data models
Create and maintain data visualization using Qlik.Sense , PowerBI or Simliar Toolset
Experience in defining, building and maintaining data virtualization and/or star schema data warehouses
Maintain, tune and optimise database, integration and visualisation toolsets
ABOUT YOU:
To succeed in this role, you’ll need to bring the following experience and skills:
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Excellent communication skills both oral and written, with an ability to bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking
Experience with data analysis and modelling will be beneficial

How to Apply
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kawana Waters,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Graduate Data Science / Engineer,-1,"The NRMA is an organisation looking to the future, and right now, we are on the lookout for people who can help us reach our goal: to continue to shape the way Australians move, for the next 100 years and beyond. www.mynrma.com.au.
Everyone new to the team, along with our current staff, will temporarily work from home until it is safe to return to our offices. All interviewing and on boarding will be done virtually due to COVID-19.


Your opportunity
As Graduate Data Scientist or Engineer you will be part of the Data Engineering team delivering cloud data transition program for business initiatives and supporting the entire data platform build.
Your key responsibilities will be to:
Implementing Concepts of Data Warehousing, Data Mart creations within Cloud
Use of SQL for data analysis and insights
Building AI/Machine Learning prototype for implementing and supporting existing algorithms
Data Analytical reports build, using different tool sets


Requirements for Success:
Relevant Degree - Computer Science, Computer Engineering, Software Engineering, Data Science
Excellent SQL skills and demonstrated working knowledge in Python
Demonstrated understanding in data structure and algorithms.
Knowledge and concept of data warehousing methodologies
Any reporting tools experience Tableau or Oracle Analytics Cloud, Looker is desirable
Exposure to Google/AWS/Azure/Oracle any cloud based platforms is desirable
Good communication and interpersonal skills

If you have the required skills and the passion to join our high performing team, please apply today.

Employee Benefits
To ensure our employees feel valued, empowered and celebrated we provide a range of employee benefits including:
50% discount on all NRMA insurances
Free Roadside Assistance
12 weeks paid primary and 4 weeks paid secondary parental leave
Free NRMA Blue Membership
At the NRMA Group, we are People Moving People and diversity and inclusion are part of our DNA. Together, we continue to build an inclusive culture that encourages, supports and celebrates the diverse voices of our employees. It fuels our innovation, promotes flexible ways of working and connects us closer to our members and the communities we serve.",2.5,"NRMA Motoring & Services
2.5",Sydney,-1,501 to 1000 Employees,-1,Nonprofit Organization,Casual Restaurants,"Restaurants, Bars & Food Services",$500 million to $1 billion (USD),-1
Data Centre Engineer,-1,"We are a leading world group that provides low-carbon energy and services. To tackle the climate emergency facing us all, our aim is to become the world leader in the zero-carbon energy transition ""as a service"" for our clients – particular for companies and regional authorities. We use our expertise in our key business areas (renewables, gas, services) to provide competitive and bespoke solutions.
The Data Centre Engineer will be employed as part of a 24/7 ongoing shift to coordinate and monitor third party service providers, maintain the data centre facilities and infrastructure plans, coordinate the implementation of customer requests within the data centre and monitor systems, all in accordance with the Contract KPIs and SLAs.
Coordinate and monitor third party service providers for regular maintenance & testing, service faults & call outs, ensuring works are performed in accordance with Contract SLAs
Monitor and maintain the data centre facilities and infrastructure plans and documentation, including electrical, mechanical, hydraulics, fire and BMS/EMS systems
Coordinate the implementation of internal and external customer requests within the data centre
Perform scheduled plant checks and minor maintenance works
Ensure all Work Order requests are raised and closed in a timely manner
Conduct inductions for staff, vendors and contractors
Ensure all work permits for vendor works are raised and closed
Perform inventory checks on all equipment and critical spares

Qualifications
The selected candidate must be able to demonstrate:
Electrical or HVAC background, or Graduate Electrical or Mechanical Engineer
Passionate about quality work and career minded looking for a new challenge
Can commit to a day and night shift roster (2 days of day shift, then 2 days of night shift, 4 days off)
Ideally able to commence asap
As part of carrying out the duties of this role, it is mandatory to hold Australian Citizenship.

If you are interested and meet the selection criteria apply with an up-to-date resume via the apply instructions on this website.

ENGIE Services is an EEO employer, where all applicants are treated with fairness and respect and have equal access to the opportunities available.

We will not be engaging in the services of a recruitment agency to fill this vacancy and therefore request all interested candidates apply directly to this advertisement.

Job
: Maintenance
Primary Location
: Oceania-Australia-New South Wales-Erskine Park
Organization
: ENGIE Services Australia and New Zealand
Schedule
: Full-time
Nature of Responsibility
: Senior operational / administrative role
Job Posting
: Sep 11, 2020, 6:29:59 AM",3.7,"ENGIE Services Australia & New Zealand
3.7",Sydney,-1,5001 to 10000 Employees,1995,Company - Public,Energy,"Oil, Gas, Energy & Utilities",$2 to $5 billion (USD),-1
Senior Data Engineer,-1,"Senior Data Engineer, Temporary, SYDNEY - McKell

Job Title: Senior Data Engineer

Salary: SNSW Grade 9/10 - The package includes base salary range of $111,806 to $134,667, plus employer's contribution to superannuation and annual leave loading.

Location: Head Office – Haymarket

Employment Status: Temporary through till 30th June 2021


About Service NSW:

Service NSW is making it easier for people and businesses across NSW to access government services. The role designs, builds and analyses complex data from multiple sources to identify revenue, process and business improvement opportunities; providing new information and insights to the business to inform planning, continuous improvement and performance.

About the Role

We are currently seeking to appoint a Senior Data Engineer to deliver expert advice and services in the design of a Single View of Customer and data-related services to support the achievement of business outcomes and strategic goals. We support flexible working practices with staff working remotely during this time.

In this role you will:

Design, build and support a modern data platform based in AWS and vendor technologies.
Provide expertise on data modelling for Graph data model and Customer Data Platform (CDP).
Create data pipelines, load, transformation and reporting workloads in AWS.
Work with the latest data engineering technologies like Apache Kafka, AWS Kinesis, AWS Neptune, AWS Glue and AWS Athena.
Contribute to the design and decision-making of the right tool or platform for the job according to requirements.
Provide expert advice and guidance on data quality and data engineering best practices.
Support a “bigger than you can imagine” scale of data in production environments.
Design, develop and support a metrics-driven reporting solution and a meaningful business intelligence platform.
Document the solution design and support procedures of solutions.
Produce reports, visualisations and recommendations to answer complex business problems that are presented in the most appropriate format to ensure clarity for target audience.
Analyse and define new process improvement opportunities to support continuous improvement and business outcomes; providing advice to stakeholders, on ways to improve the efficiency and reliability of data products and services.
Be very responsive to the information needs of the business by corresponding to customers in a timely manner and provide support/solutions to issues raised.
Troubleshoot and perform root cause analysis on production issues. Identify and implement long term solutions to problems. Perform scheduled maintenance, release deployment and production support activities after business hours, from time to time.
Liaise with internal and external customers to discuss and gather requirements, solutions etc. and maintain a good working relationship with the stakeholders.


Skills and Experience Required:

Solid experience with workflow technologies designing and building data pipelines, data models and data stores.
Experience working within and an understanding of Amazon AWS ecosystem, including security and performance tuning.
Hands on experience working with different types of databases, with focus on Graph and NoSQL databases.
Experience with data streaming required. Having used Kafka and related technologies is an added advantage.
Sound knowledge and experience working with batch processing, data extraction and API integration.
Hands on experience with at least one programming language: Java, Python or scripting.
Demonstrated experience working in an Agile based, fast paced, complex environment within cross-functional teams.
Experience developing systematised insights, data analytics and reporting solutions is an added advantage.
Experience with interactive visualisation of data insights is an added advantage.


Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Salary Grade 9/10, with the base salary for this role starting at 111,806 base plus superannuation

Closing Date: 6th November at 9:59am - applications will be reviewed on a rolling basis, applications may close early or extend

Please apply online, direct applications submitted via email will not be considered.

The Department of Customer Service is proud to be an EEO Employer who are fully focused on equality and believe deeply in diversity of all identities making us different and a true reflection of our NSW customers. As an inclusive workplace, we support various employee resource groups, practice flexible work and workplace adjustment.

If you do require an adjustment during the recruitment process, please notify us on your application form.",3.2,"Service NSW
3.2",Sydney,-1,501 to 1000 Employees,2012,Government,State & Regional Agencies,Government,Unknown / Non-Applicable,-1
Data Engineer - Entry / Mid Level,-1,"Work with a great team on interesting projects customers
Gain more experience in AWS, Data, DevOps cloud operations
Got a working knowledge of AWS? We will teach you the cool stuff!

Itoc is seeking an up and coming Data Engineer to join our growing Data Team in Sydney.

This is an exciting role working with databases, data lakes, data warehouses, data transformation (Python SQL) and enabling AI/ML.

You will be implementing foundational, robust and production ready data platforms to enable business data-discovery, self-service, AI/ML functions across a range of client types and industries, allowing them to do more with their data.

You'll be responsible for:

Deploying data repositories such as lakes and warehouses.
Contribute to our growing portfolio of data solutions.
Ongoing optimisation and management of data platforms.
Development of transformational logic for data pipelines
Data evangelism. We want to show our clients how to follow the best practices for data.

Desired Skills and Experience

To take up the challenge, you will have a depth of skills and experience including:

1-2+ yrs of focused data experience working with SQL and/or NoSQL solutions
A solid education in Software Engineering or equivalent industry experience.
Anything Data focused preferred.
Ability to analyse business scenarios and associated data landscape to derive potential opportunities.
Strong foundation in Python and SQL
Working knowledge of APIs
Principle knowledge of the different relational database platforms and modern data storage techniques
Knowledge of the different aspects of data environments
Collect, store, process, verify consume
Experience with version management systems (such as GIT)
Working knowledge of AWS or another cloud platform - we will teach you the cool stuff.
Great communication skills, an ability to work closely with customers, developers and engineers and the confidence to present ideas in open forums.
Relevant tertiary qualifications and/or industry certifications.
Great communication skills, an ability to work closely with clients, developers and engineers and the confidence to present ideas in open forums.

While not required, a background in consulting and professional services is highly desirable.

Itoc Description

This is an exciting and challenging career opportunity to join the growing Sydney-based Data Team of a leading cloud solution provider where you will be given support to reach your long term career goals. You will be part of a team of cloud experts and will work in an environment of continuous improvement and learning delivering innovative cloud solutions across SaaS, online business and enterprise business.

On offer is a chance to join a team with a great working environment, in an organisation that values its employees and sees the value in ensuring they are engaged. Our team are clearly passionate about what they do, that's why we won the following awards:

Customer Obsession Partner of the Year 2015: ANZ Region
Customer Obsession Leadership Partner 2015: re:Invent

As an employer of choice Itoc offers competitive remuneration, training and development programs and a great working environment. We value a healthy work life balance.

The Perks

MacBook or Dell
Continuous internal learning that will provide training and career development opportunities
Working with a collaborative, social team and leveling-up your skills faster than you will anywhere else.
Quarterly social events

Itoc

Culture and smarts are important to us. Bring your secret sauce. This is no ordinary environment, you will work along some of the Cloud’s best. All engineers at Itoc must gain at least five AWS certifications. We work hard but we have fun.

Please note you must have full working rights in Australia and be available on-shore for face to face interviews.

No recruiters please.",4.0,"Itoc
4.0",Sydney,-1,1 to 50 Employees,2013,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Date: 01-Oct-2020

Location:
Melbourne, VIC, AU

Department:Description:
Technology discounts - from Apple HP Lenovo to Windows
Flexible work arrangements - work in a way that suits you best
Salary packaging - to suit your personal and financial circumstances

Do you want to work for one of the fastest growing data teams in Australia? Do you want to work on multiple data platforms and provide new solution offerings by leveraging cloud and big data technologies?

About the team

Big data information and analytics. Three words that spark apprehension in most businesses. But our team of experts are constantly curious and excited about combining our wonderful array of technological expertise to transform data into our clients most valuable assets making their work smarter. Our data consultants are supported with resources training and tools they need to excel at their work but also the freedom and power to create their own paths forward to make a difference.

As a Senior Consultant in Big Data you will work closely with the team and stakeholders to build and deliver a Cloud based vision for a next generation Big Data analytics platform with strong focus on data quality data security and deliver the systems that process huge volumes of data.

What will you typical day look like?

You will play a pivotal role in - Designing and producing high performing and stable applications to perform complex processing of massive volumes of data in a new cloud based architecture; Building real-time data processing applications which are integrated with business systems to enable value from analytic models to drive rapid decision making; Contributing to system architecture design for a data platform (including cloud-based structures both on and off premises data warehouse components and data lakes); this could cover a range of technologies various countries/locations and lines of business; Support data strategy or technology strategy definition programs including technology stack definition and target operating model requirements

Enough about us lets talk about you:
You are someone with:
Use of traditional data analytics tools and techniques (e.g. MSSQL Oracle MySQL) and ETL software (e.g. SSIS Informatica CloverETL)
Working in large scale cloud data solutions using platforms such as AWS or Azure or GCP will be a bonus.
Experience in scripting or programming (e.g. Python Java Scala C#)
Excellent verbal and written communication skills to adapt to technical and non-technical audiences.
Educated to degree level (or have equivalent experience)
Why Deloitte?

At Deloitte we create positively differentiated work experiences that enable our people to feel valued and achieve their full potential. We value difference and embrace people with diverse backgrounds and thinking styles. Knowing that people work best in different ways we are happy to discuss alternative arrangements if the working pattern you are looking for is not specifically indicated.",3.8,"Deloitte
3.8",Melbourne,-1,10000+ Employees,1850,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Engineer,-1,"Opportunity to grow the team
Period of growth
Intuitive app
S2M are working with a FinTech who have created a unique financial product to help thousands of people better manage their finance, and is currently scaling the company to the next level!

They are looking for a Data Engineer to join, and looking for someone who wants to be hands on, with opportunity to grow the team in future.

Role:

Looking for people with strong AWS experience. You will need passion for data and a cloud, through which you will help a rapidly scaling Australian FinTech establish their data infrastructure from the ground up.
5+ years’ experience as a data engineer within the data and analytics domain
A python 3.X aficionado who is very comfortable creating and orchestrating AWS data pipelines with nothing but code
Strong project delivery toolset experience in open source data integration tools
Experience with processing large volumes of complex data including visualisation and insights generation
Ability to define and develop data integration patterns and pipelines
Ability to assess complexity of data (volume, structure, relationship etc.)
Hands on experience working with different databases (RDBMS, NoSQL, Blob storage etc)
Hands on technical expertise setting up DevOps automation
Hands on experience working technologies/platform e.g. AWS, Dockers, Containers
Experience building data profiling and data cleansing frameworks
Technical reconciliation and reporting
Knowledge and experience in end-to-end project delivery, either traditional SDLC or agile delivery methodologies (or hybrid approaches)
Exceptional communication, documentation and presentation skills
If this sounds like you, get in touch today - kate.gabb@s2m.com.au
3167410agsdf",3.1,"S2M
3.1",Sydney,-1,Unknown,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Analysts,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is seeking experienced and qualified Data Analysts to join our IT team based in our corporate office in Birtinya (Sunshine Coast) or at our meat processing facility in Kilcoy.
Key Responsibilities:
A mixture of data analysis and commercial skills to source, blend and analyse data to gain insight and answer key commercial questions
Working with strategic leaders to define and model Key Performance Indicators, and assist in building forecasting models
Working closely with data engineers and BI developers to specify data pipelines and report visualisation
Drive the creation and implementation of data quality business rule including data definition, governance and quality assurance
About You:
To succeed in this role, you’ll need to bring the following experience and skills:
Proven ability to derive insight and knowledge from data using commercial expertise is a strong requirement
Strong SQL and Excel skills are essential, along with strong data analysis and commercial insights
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Effective people communicator - engage with stakeholders on reporting needs, interpret requirements into visual solutions and train/deliver the outputs to the stakeholders getting signoff of acceptance
Bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking

How to Apply:
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kilcoy,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Network Data Engineer,-1,"Min 6+ years of experience in the relevant technologies
Australian Driving License for visiting remote locations / Data Centre for day to day technical work.
Managing Network devices (switches, routers, firewalls, load balancer, and wireless technology)
Performing MACD activities for all network devices.
Supporting BAU operation activities.
Proficient in performing in-depth details of technical troubleshooting, cause and provide recommendation to the client for incidents causing extended network outage to client’s critical locations.
Provide exceptional network services in terms of network support, break-fix, design and consulting, new projects, implementation.
Configure, administer, and document firewall infrastructure.
Manage the firewall deployment, rules migrations, and firewall administration.
Supporting Cloud Migration Activities from traditional to AWS/Azure.
Setting up VPN tunnel with Cloud and 3rd Party network devices.
Integrating and upgrading existing ISP bandwidth with support from ISP Vendor.
Setting up VPN profiles for Users.
Installing hot fix and patches to mitigate the security devices from attacks and bugs.
Reviewing and fine tuning the firewall rules and NAT rules.
Documentation and change control.
Mentoring, Motivating and Guiding support teams
Technical skills:
o LAN
o Wireless
o WAN
o MPLS
o Routing protocols (OSPF,BGP)
o DMVPN
o Azure cloud Networking
o Network Security
Fortigate Manager / Analyzer / Firewall
Cisco ASA
Firepower FTD
Cisco Any connect
Site to Site VPN
F5 Load Balancing and Scripting iRule
Job Types: Full-time, Contract
Schedule:
8 hour shift
Experience:
Scripting: 5 years (Required)
Data Network: 5 years (Required)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Required)",3.6,"Total IT Global
3.6",Sydney,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Engineer - Processing & Analysis,-1,"Job Description:
Design,build and maintain the ingestion system to support various types of data(e.g. User behavior, RDS, NoSQL db and others) to be ingested to the data warehouse more timely and accurately
Translate data requirements into scalable technical data service with low latency and high concurrency
Design,build and maintain the batch or real time data pipeline in production using Hadoop big data technology
Analyze and improve efficiency, scalability, and stability of the system
Define and manage SLA,Data quality for all data sets in allocated areas of ownership
Requirements:
Minimum B.S. degree in Computer Science or a related technical field
2+ years of working experience in programming languages,such as Java,Scala,Python
Familiar with Hadoop, Spark and Flink data processing, experience of TB data processing experience is a plus
Familiar designing and operating of a robust distributed system is a plus
Understand data mining or machine learning
Excited to work intimately with data
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"SYNOPSIS:
Lead Data Engineer
Applications close Sunday 8 November 2020
Ongoing
Contact name: Shyni Sasikala
Phone: (02) 6249 9048
Email: Shyni.Sasikala@ga.gov.au

The Data Policy and Informatics section within the Digital Science and Information branch creates, implements, and promotes policies, platforms and tools that improve and support the quality, discoverability, accessibility, and general usability of Geoscience Australia’s science data products. The section consults with internal and external research, government and industry partners to establish collaborative data frameworks, architectures and models within Geoscience Australia (GA) and across broader national and international communities of practice. The section innovates, builds and maintains tools, systems, processes and governance that enable digital data management, cataloguing and open data delivery.
GA makes accessible a wide range of geoscientific and spatial data to a wide variety of stakeholders in multiple formats, and in recent years GA's data volumes have grown exponentially. GA is focussed on making its data and metadata assets accessible so that they can be used in machine to machine interactions for data analytics and other applications in environments that range from High Performance Computing (HPC), through high-end cloud servers, to mobile devices.
We currently have two opportunities for Lead Data Engineers in the Informatics team. The Lead Data Engineer is responsible for innovating and exploring new technologies that will advance GA’s science goals and maximise the uptake and use of GA’s science data. The Lead Data Engineer reports to the team’s Assistant Director but also works closely with other developers, data scientists and engineers within the Digital Science and Innovation (DiSI) branch, as well as diverse stakeholders both within and external to GA.",3.9,"Geoscience Australia
3.9",Canberra,-1,501 to 1000 Employees,2001,Government,Federal Agencies,Government,$100 to $500 million (USD),-1
Data Engineer,-1,"The Seven Network is part of Seven West Media, one of Australia’s most prominent media companies, with a market leading presence in content across broadcast television, online and in print. Comprising some of Australia’s most renowned media brands, SWM includes not just Seven Network and its affiliate channels 7two, 7mate, 7flix and BVOD offering 7plus, but also 7NEWS.com.au, The West Australian, The Sunday Times and more.
At Seven we are here to bring all Australians closer to the moments that move us - we’re first on the scene, with our finger on the pulse, on demand, in the moment. Together, we’re responsible for creating and sustaining authentic Australian engagement.
A new and exciting opportunity has opened for a Data Engineer to join the Audience Intelligence team. Based in Sydney and reporting to the Head of Data Enablement, you’ll be responsible for:
Implementation of end to end data solutions to support Data Strategy for the SWM group.
Work closely with the Data Solution Designers to develop and maintain scalable data pipelines and build out new file and API based integrations to address requirements from the various business stakeholders.
Collaborates with engineering, analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organisation.
Work on Data Preparation for analytics and data scientist team members and assist them from an engineering perspective in building and optimising the models including building the automation of the end to end workflows
Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.
Perform data analysis required to troubleshoot data related issues and assist in the resolution of production data issues.
Work effectively with vendors for successful delivery of projects and acceptance of the solution
Work on Delivery projects using Agile Software Development methodologies
We are looking for someone who has:
Bachelor's degree in computer science, computer engineering or other technical discipline is essential
Proven experience working as a digital analytics specialist
Extensive experience with digital analytics implementation (e.g. Google Analytics, Snowplow, Adobe Analytics) and BI processes and visualisation platforms
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience in ETL and building and optimizing ‘big data’ pipelines and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Experience with big data tools: Hadoop, Spark, etc., AWS cloud services: EC2, S3, Lambda and familiar with version control systems: Git
Strong coding skills with knowledge of Unix/Linux and scripting languages such as Unix Shell scripting, Python desirable
Experience supporting and working with cross-functional teams in a fast-paced environment.
Ability to multi-task and problem solve with changing demands and priorities
Ability to work under pressure to meet deadlines and detail oriented
Your success is our success: we will provide you with opportunities for you to keep learning and growing, enabling you to challenge and develop yourself. In return, we offer a benefits program that has something in it for everyone.
Seven West Media is an equal opportunity employer and we are committed to creating a diverse and inclusive workplace.
Recruitment Agencies: Seven West Media does not accept any unsolicited agency resumes and will not be responsible for any fees related to unsolicited resumes.
Advertised: 19 Oct 2020 12:00 AM AUS Eastern Daylight Time
Applications close:

Back to search results",2.5,"Seven West Media
2.5",Sydney,-1,5001 to 10000 Employees,1956,Company - Public,TV Broadcast & Cable Networks,Media,Unknown / Non-Applicable,-1
BICON Rules Engineer,-1,"APS 5 - $73,299 - $80,410 per annum plus superannuation
Biosecurity Plant Division
Canberra, ACT
Play an active role in managing biosecurity risk to Australia
Work in a motivated and professional team with a wide range of skills and backgrounds
Full training provided

Who we are
The BICON Content Development Team maintains and improves the Biosecurity Import CONditions database (BICON) content to allow external clients to understand and comply with their biosecurity obligations and internal clients to effectively manage biosecurity risk and regulate imports. We work collaboratively with internal clients to comprehend and implement their BICON content requirements and optimise the use of BICON to publish clear import requirements and onshore management support procedures to effectively manage biosecurity risk.

The Jobs
Key duties of these positions include:

working with business content (import and permit conditions) and import programs to understand and construct decision tree structures in the BICON database, in accordance with system design and authoring conventions
executing changes to import and permit conditions in alignment with service standards while complying with system rules and authoring conventions
providing technical advice through various formats on the most appropriate means of authoring BICON content to achieve import program and stakeholder objectives
using workflow management tools to maintain detailed records of changes to import conditions and key decisions
performing administrative tasks including system reporting, data analysis and scoping tasks for the BICON content change work program
contributing to the development and maintenance of instructional material, authoring conventions and courseware
clearly documenting and reporting system issues
developing and maintaining effective working relationships with internal and external stakeholders.

What we are looking for
Knowledge and experience
Experience working with complex IT systems.
Experience working collaboratively and as part of a team.
Knowledge of the role of biosecurity is preferred but not essential.

For additional information, please read the Job Description below.
Candidate Information Package docx Opens in new window",3.9,"Department of Agriculture & Water Resources
3.9",Australia,-1,5001 to 10000 Employees,-1,Government,Federal Agencies,Government,$500 million to $1 billion (USD),-1
Cloud Data Engineer,-1,"Job no: 509605
Work type: Permanent Full Time
Location: Melbourne, Canberra, Sydney
Do you embrace digital disruption?
Do you love solving complex problems, designing sophisticated solutions and building innovative technology?
Do you believe in creating powerful actionable insights from Data and Analytics?
Do you want to work in a diverse and flexible working environment?
KPMG is one of the most trusted and respected global professional services firms. Through depth of expertise, clarity of insight and strength of purpose we help our clients solve complex challenges, steer change, strengthen, transition and grow. We are a team based practice and this extends to our clients whom we work and collaborate with, in solving complex problems. Together, we design, innovate and implement, providing enduring advice that support our clients and the services they deliver. Our clients vary in size and come from a diverse range of sectors – all sharing in a common goal: to embrace change and deliver services that make Australia a better place. We are looking for talented individuals who would like to join us on the journey.
KPMG’s Digital Delta Team
We re-imagine and re-invent organisations to become world class digital enterprises using advanced technologies, data and human insights. We help organisations to embrace Digital Strategy, Artificial Intelligence (AI) & Cognitive, the Internet of Things (IoT), Data, Analytics & Modelling, Mobile App & Web, and User Experience (UX) & User Interface (UI) and more.
We work with clients to:
Formulate strategies that re-imagine organisations
Harness innovation from the 4th industrial revolution
Actioning insights from trusted data to consistently and quickly make clear decisions
Build adaptive organisations
Thrive as a connected enterprise – front, middle and back office
This is how you’ll contribute:
We are looking for ambitious Data Engineers who are passionate about helping clients define bold ambitions and deliver on them. Joining our team will take you on a journey of personal and technical growth and provide the opportunity to inspire confidence and empower change.
As a Data Engineer you are the designer, builder and manager of the information or ""big data"" infrastructure, preparing data for analytical or operational use. You will design, construct, test and maintain a data pipeline to pull together information from different source systems; integrating, consolidating and cleansing data; and structure it for use in individual analytics applications.
The KPMG Difference
Our people are focused on creating a diverse and dynamic environment that embraces and values differences. We value the variety of unique experiences, qualities and characteristics our people possess and we share and learn from each other.
We are proud to be consistently recognised as an employer of choice for women, and for our achievements in LGBT+ workplace inclusion.
Our commitment to ‘Flexibility’ allows our people to manage the changing demands of work, personal or family life. Explore the links below to hear our people share their experience @ KPMG:
Flexibility empowers wellbeing
Flexibility enables contribution to the community
Flexibility inspires technology & innovation
Flexibility supports family

Make KPMG the clear choice for your career and be Extraordinary!

Advertised: 09 Sep 2020 AUS Eastern Standard Time
Applications close:",3.8,"KPMG
3.8",Sydney,-1,10000+ Employees,1987,Subsidiary or Business Segment,Accounting,Accounting & Legal,$2 to $5 billion (USD),-1
Computer Network and Systems Engineer,-1,"Duties Include but are not limited to:
Tasks Include:
analysing, developing, interpreting and evaluating complex system design and architecture specifications, data models and diagrams in the development, configuration and integration of computer systems
researching, analysing, evaluating and monitoring network infrastructure to ensure networks are configured to operate at optimal performance
assessing and recommending improvements to network operations and integrated hardware, software, communications and operating systems
providing specialist skills in supporting and troubleshooting network problems and emergencies
installing, configuring, testing, maintaining and administering new and upgraded networks, software database applications, servers and workstations
providing network programming in support of specific business needs and requirements
preparing and maintaining procedures and documentation for network inventory, and recording diagnosis and resolution of network faults, enhancements and modifications to networks, and maintenance instructions
monitoring network traffic, and activity, capacity and usage to ensure continued integrity and optimal network performance
Skills and Experience Required:
Must have experience working in a Managed Service environment
Demonstrated experience in IT Networks and Data Centres
Understanding of systems and architectures to meet client needs
Experience in Help Desk including break / fix
Effective and timely documentation
Effective Task Management Skills
Be solution and outcome focused and willing to learn new technologies
Excellent communication skills with staff, clients and partners
Time management, ability to prioritise and deliver to schedule
Experience with N-Able and Connectwise desired
Open Cabling license desired
Job Types: Full-time, Permanent
Salary: $30.00 per hour
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,Trans-plant training,Canberra,-1,-1,-1,-1,-1,-1,-1,-1
Software Engineer (Data),-1,"If you are looking for an opportunity to make a real impact with smart people who are genuinely doing things differently then you've come to the right place! We're growing our data engineering capabilities and are looking for awesome data engineers to join our team.
With our diverse range of clients and projects, no day will look the same - but here's a great snapshot of what you'll be doing:
Work with some of the best Data Scientists and Engineers to deliver production-grade AI and Machine Learning systems as we deliver client projects from inception to production.
Consulting with our clients and working with them to build modern data systems using the 'best of' technologies and principles.
Advising clients on data strategy, architecture and technology.
Applying best software engineering practices in coding, monitoring and alerting, using CI/CD, TDD and cloud architectures.
Working over a wide range of big data tools and environments: not limited to; Apache Kafka, Spark, Python, Scala, Hive, Airflow, AWS EMR & Glue, GCP Dataproc & Dataflow, BigQuery, Snowflake, Redshift.
Who are we?
Glad you asked! We are Eliiza. Data science. Engineered for scale.
We are a passionate team of data scientists and engineers who apply data science and machine learning to solve real-world problems. Our mission is to create a bright future for Australian businesses and society in a world increasingly influenced by intelligent technologies.
We've created a culture that values diversity where people can truly be themselves! We care a lot about growing the Australian AI community in a positive direction, and we're doing several things to try and achieve that:
We provide opportunities for underrepresented groups to work in AI through our associate and intern programmes
We organise and participate in a range of community events, reading groups and meetups
We produce the AI Australia podcast
We blog about topics we care about
We stream brown bag sessions to the broader community
We're also part of Mantel Group's 'house of brands' which means it's not just the Eliiza team you'll work with, learn from and see at social events - there's another 230 of us across DigIO, Kasna & CMD Solutions!
So you're ready for something new?
We're keen to know more about you! Our team is made up of a range of people, with different experience across a huge range of data driven skill sets.
We'd love to hear from you if you have experience with:
one (or more) core language(s), ideally Scala, Python or Java
one (or more) cloud platforms, AWS, GCP, Azure
ETL/ELT concepts and technologies e.g. Data partitioning, Hive, Spark
streaming data concepts and technologies, ideally Kafka (Kinesis, Beam or Pubsub will do)
We'd be over the moon if you:
Experience with distributed/columnar databases (e.g. Snowflake, Big query, Redshift).
Experience with any of a variety of databases e.g. RDMS, NoSql, Columar, Distributed, Time series, Graph.
Knowledge of job orchestration and scheduling. Any experience with Airflow, Luigi or Oozie.
Experience with containers and container orchestration (Docker, Docker Compose or Kubernetes).
However, we value a diversity of skill-sets, and don't necessarily require that you're skilled with all of the above. If you feel you don't fit all the experience/skills listed above we still encourage you to apply or get in touch.
What's on offer if you join us?
We make sure you're always one step ahead by investing your learning and development, every year. We build our own training where it doesn't exist yet.
We hire smart people and get out of their way. By focusing on our five principles and not getting caught up in red tape, we trust you to get the job done.
You'll get all the tools you need - a new iPhone or Google phone, a new Macbook Pro or Dell, and a lot of branded swag!
But hold on, you mentioned a house of brands?
We certainly did! Mantel Group is an Australian-owned, 'house of brands' company with four technology businesses (Eliiza being one of them!) across Melbourne and Sydney. We're building a group of companies with open borders so we can support you to take on new skills without leaving an awesome team - we understand you won't have one job for life!
We may only be just two years old but Mantel Group has already been recognised #9 in the 2020 Best Places to Work in Australia and #4 in the AFR's 2020 fastest growing new companies.
Keen to chat?
Click ""Apply"" to share your details with our talent team, and we'll be in touch.
In the meantime, check out 'how we hire' to find out what's in store if you're successful and get to know us better by visiting our website and following Eliiza on LinkedIn.",-1,Eliiza,Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Infrastructure Engineer,-1,"Job Description:
Design and grow the Shopee data platform to support a variety of big data applications using open-source technologies including Kafka, Hadoop, Presto, HBase, Spark, Hive, Druid, and our own creations. Some examples include a real-time data streaming platform, a unified query platform, a cluster management system, and a machine learning platform
Dig into the source code of some open-source big data system to get the whole control and familiar with the details, configurations, designs and source code. Develop and maintain the internal release of big data systems and components as the business requirements.
Keep close and overall monitoring for all the deployments of the systems, maintain the system’s stability, improve the performance, discover the performance bottlenecks, tracking and troubleshooting, cost optimisation.
Requirements:
B. Sci. / Ms / PhD in Computer Science or a related technical field
Familiar with at least one of these languages: Java, Scala, Python, Bash under Linux / Unix. Scala is a plus
Familiar with the use and compute logical of SQL
Knowledge about the Big Data Infrastructure system technology like Distributed File System, Distributed Computing, Distributed Database will be a plus
Hands-on experiences Hadoop, Spark, Kafka, and/or Presto will be a plus
Love to use and develop open-source technologies
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"Work on an award-winning, international technology!
Endless career opportunities
An innovative, friendly team of 300+
This role will be focused on the development of our existing ClaimLogik line of products as well as working on our new cloud-first, modern suite of applications.

Intelligent Thought, our technology business is scaling and shipping our software globally. Already profitable, part of a much larger group business, with investors such as Macquarie Capital and Envest – we are all set to deliver textbook disruption to the Insurance Industry. The growth of the platform, of our customer base, and the increasing industry demand have led to the need for this role to help the team scale.

Our Philosophy
Give each employee a sense of purpose and an environment for them to connect the importance of their role to delivering a service that matters to our customers.
Challenge the ‘why’ of traditional claims processes.
Keep it simple – do only what brings value and what matters to the customer
Enable employee decisions, empower our people
Responsibilities:
Create, extend and maintain ETL pipelines to form our data lake, data warehouse and analytics platform (currently using the Microsoft Azure set of tools and service)
Help define the optimal data pipeline architecture
Influence the tool selection, platform selection, data architecture and strategy which will transform the business to be truly data-driven
Understand, analyse and size user requirements
Work with different parts of the business to provide them with the insights they need to deliver the best results
Skills & experience:
Degree or qualification in computer science or related
Advanced knowledge of relational database, including query authoring and query optimisation (MS SQL Server and PostgreSQL).
Experience building and optimising ETL pipelines
Experience designing complex data models
Experience working with cloud platforms (Azure or AWS)
Efficient time management and organisational skills
High attention to detail and accuracy
Effective communication skills to build strong working relationships; both written and verbal
Proactive and results-driven
Why Claim Central?
Claim Central Consolidated is a global insurance industry leader across, claims management, insurance technology and data and analytics. Currently operating in the United States, Australia, South Africa, Italy and New Zealand, we have pioneered digitally connected claims management services across the globe. Claim Central is a disruptor and thought leader in the industry and we were recognised as the Australian Financial Review’s 8th Most Innovative Company in Australia in 2016. This business is in a period of unprecedented growth, transitioning our technology and services into multiple geographies at a rapid pace. Our unique culture is based on teamwork, collaboration, trust, respect and performance. We also offer many benefits apart from our exceptional team culture; including flexible work arrangements, and continued professional development.

Be a part of this journey in a career-defining role.",-1,Claim Central,Matraville,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer - AI/ML,-1,"Our client provides services to a major industry across the country. The business is still early in it's days of technology development and the environment is greenfields in nature (no pun intended), effectively working like a start-up.

Their data and analytics team have worked and built leading and bleeding-edge technologies in this space and what they have created so far may be game-changing. From a machine learning perspective, the progress they have made to the business has already seen proven success in changing the future of an industry that will have positive consequences for all those involved.

You will have previously worked in a technical capacity in the data and analytics space and have experience working with an organisation where machine learning has been implemented, not just a concept that the business talks about having or the technology team would love to have. The commercial experience you will have had in the ML field will be proven examples of where you have affected the way a business or industry used to perform, to the changes that have come about from this.

Technically, you will have extensive experience in the Microsoft space - Power BI, Azure etc and you will have previously mentored and coached junior members of the teams you have been part of.

This is a rare opportunity in Brisbane where the business has truly embraced and funded projects across the ML space and would be a great chance for those in the Data Development/Data Engineering field, who are looking to move into a Data Scientist role in the future.

Please send your application through if you would like to know more.",4.0,"Emanate Technology
4.0",Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Solution designer/ ETL Engineer & Data Modeller,-1,"We are looking for a Qualified and Experienced Solution Designer to join our client for a period of 6 months with a view to extend.
You will work closely with team members and your contribution will range across gathering and analyzing information, developing and documenting improved processes and work instructions and experienced DWH Lead with skills in requirement analysis, solution designing, developing, testing and supporting ETL solutions.
A hands-on solution designer, data modeler and ETL developer for Data Warehousing and ETL application transformation projects using Informatica PowerCenter.
Knowledge on AWS, S3, Redshift, Informatica BDM, and related technologies.
Experience working with IPython, PySparks, AuCuMo, Airflow, Jenkins, Github, Athena, JIRA, Rally, Spectrum, Glue, Flyway.
Good exposure on Oracle PL/SQL, aware of DBA activities, writing and performance tuning of complex SQL queries.
Contract length: 6 months
Job Types: Full-time, Contract
Salary: $650.00 – $800.00 per day
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,nducive,Melbourne,-1,-1,-1,-1,-1,-1,-1,-1
"Data Engineer, Wollongong NSW or Mount Waverley VIC",-1,"Company Description
BlueScope is a technically advanced supplier of steel and steel products in Australia. We are an inclusive organisation and every day we showcase our technology and expertise throughout the world.

Job Description
We are looking for two Data Engineers to join our IT team, based in Wollongong NSW or Mount Waverley VIC. Use your experience in analytics to unlock business value, enabling use of big data for insights and decision-making.
Reporting to the Data Product Owner for our Australian Steel Products (ASP) business, this position will support strategic goals related to data. This will see you:
Gather business and technical requirements with the view to deliver outcomes;
Develop and implement end-to-end data collection, consolidation, modelling and visualisation solutions;
Document metadata in a dictionary and catalogue;
Ensure consumers of such information understand its accuracy, timeliness, quality and sensitivity, so that it is used appropriately; and
Identify opportunities to enhance analytics.
What are the benefits?
Work in a supportive and collaborative team environment whilst we embark on a journey to transform the way our business uses data!
Our systems landscape is broad and diverse. You will be encouraged to think creatively to develop data solutions which solve real business problems.
Working in this role you will enjoy:
the chance to learn more about data science;
salaried remuneration with attractive superannuation options;
the opportunity to participate in a performance incentive scheme; and
access to further development and career opportunities with BlueScope.
Who are we looking for?
We welcome applications from professionals with experience in data analytics and/or programming. Supported by your knowledge of project delivery methods (e.g. Agile), you will demonstrate:
experience with data mining, wrangling, mapping and visualisation techniques (e.g. Azure Data Factory, Databricks and/or DevOps etc.);
well-developed ability in gathering business and technical requirements;
skills in developing and implementing collection, consolidation, modelling and visualisation solutions; and
a passion for sharing your knowledge and desire for ongoing professional development.

Qualifications

null

Additional Information
We're proud to have been named an Inclusive Employer for 2019–2020 by the Diversity Council of Australia. We believe that our people are our strength. Having a diverse and inclusive workplace enables us to improve our capability and ensure continued, sustainable success.
We know that workplace flexibility can mean something different to everyone. Under our B-Flex initiative all of our roles have some degree of flexibility. We encourage you to discuss your needs with us.
Applications close Sunday 25th October 2020.",3.3,"BlueScope
3.3",Wollongong,-1,201 to 500 Employees,-1,Company - Private,Construction,"Construction, Repair & Maintenance",$100 to $500 million (USD),-1
ETL Data Engineer,-1,"ETL Data Engineer

Join a team that’s changing how Australia lives, works, plays and grows
We want you to be the best version of you

Work with innovative teams and explore new technologies to help solve real-world problems.

A typical day as a Data Engineer

ETL / Big Data Engineering professionals will be responsible for guiding the full lifecycle of a Data solution, including:
Working in highly client-facing roles to contribute throughout the end-to-end delivery lifecycle of complex and large-scale digital solutions
Use case and business case development
Support existing and new applications utilizing in-depth technical and data knowledge. Troubleshooting complex issues and providing advisory services to improve the client’s data landscape
Help to streamline and simplify the clients’ complex data landscape by integrating different applications and data architectures
Implementation from requirements analysis, platform selection, digital architecture design, application design and development, testing, and deployment
Interstate travel may be required

Basic qualifications:
Bachelor’s degree
Experience across systems integration, information management, data management and architecture, and business analytics
Experience with being in a team focusing on large-scale, multi-release information centric projects
Experience with waterfall and agile delivery and run / application support functions
Part of a team working on End to end implementation of at least 1 big data project

Preferred Skills:
Hand on experience in Data warehousing using ETL tools such as DataStage, Autosys and TeraData
Hands on experience in ETL job development with multiple stages like sequential file, Transformer, Lookup, join, sort and Database stages.
Strong hand on skills in design, development and implementation of various data remediation, Data migration, data integration techniques.
Strong hand on data modelling experience.
Strong hands on experience in database performance tuning including complex query optimizations and physical database tuning using Teradata.
Understanding of architectural designs and strategy related to data migration, data cleansing, data quality and data consolidation.
Proven data analysis, requirement gathering and problem-solving skills
Exposure to Unix environment and shell scripting.
Experience in Banking and Financial services industry
Desirable: Knowledge of cloud computing infrastructure (e.g. Amazon Web Services EC2, Google Cloud, Microsoft Azure)
About Accenture

Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. We combine unmatched experience and specialized capabilities across more than 40 industries — powered by the world’s largest network of Advanced Technology and Intelligent Operations centers. With 513,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises. Visit us at www.accenture.com.

Accenture is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, marital, domestic or civil partnership status, sexual orientation, gender identity, or any other basis as protected by applicable law.

Vera Goga is the Recruiter managing this role. As the team experience high volumes of applications, we appreciate your patience to allow for a fair and timely process.",3.9,"Accenture
3.9",Sydney,-1,10000+ Employees,1989,Company - Public,Consulting,Business Services,$10+ billion (USD),-1
Student Engineer,-1,"The candidate will have the ability to:
Undertake onsite inspection to collect asset condition data based on the relevant engineering standards and technical guidelines;
Undertake desktop analysis to evaluate the condition and performance of the assets;
Provide the appropriate information, advice, engineering input and support services for the sustainable management of Council’s stormwater and transport networks.
Qualifications:
The successful candidate will be enrolled in a Bachelor of Engineering with a minimum of two years completed.
Position Number: 100678
Position Hours: Fixed term (3 months), hours will be negotiated with the successful candidate, maximum of 75 hours per fortnight.
Salary: Schedule A, Salary Point 4.0. $28.64 per hour ($55,853.45 per annum, pro-rata) in accordance with Glenorchy City Council’s Enterprise Agreement 2016
Please note that all successful applicants will be required to provide a current National Police Check prior to commencement of employment.
For further information on this position, contact Patrick Marshall, Senior Civil Engineer on (03) 6216 6800.
How to apply: Applications for this position must be lodged on this submission site or on the Glenorchy City Council website www.gcc.tas.gov.au - Careers page.
To be considered for this role, all applicants must address the key selection criteria in the and provide a current resume. A copy of the position description can be found by clicking the below hyperlink or on the Glenorchy City Council website.
Applications close at 8pm on Sunday, 1st November 2020
- Student Engineer",4.0,"Glenorchy City Council
4.0",Glenorchy,-1,501 to 1000 Employees,-1,Government,-1,-1,Less than $1 million (USD),-1
Data Engineer involving DevOps,-1,"Data Engineer involving DevOps
Axiom Technologies is an Australia based entity with the history of providing Managed IT solutions to medium to large scale enterprises globally. Please visit our website for more information about what we do at www.axiomtechnologies.com
Axiom Technologies is an Equal Opportunity Employer and encourage applicants from all backgrounds and gender to apply, including, Aboriginal and Torres Strait Islander candidates
Job Requirements:
8+ years IT experience, with at least 5+ years of “Data Engineer/Deveoper” focused titles/roles,
Data Tools: Hands on experience with Apache Beam.
Testing: Hands on experience with automated testing activities/outcomes
DevOps: Experience with the processes involving Microservices facilities for artifacts developed
Platform/OS: Mid-range/Unix
Languages: Unix (Shell) Scripting/commands, SQL, Python
File formats: Text, CSV, Parquet, JSON, XML
Scheduling: Jenkins, Airflow
Auto Scripting: Designing/creation of scripts for repetitive activity. E.g. Unix scripting/SQL
Big data: Exposure to Data Lake Concepts, Hive (Schema), HDFS
Source Control tools: GIT
Delivery Models: Agile, Scrum
Ingestion Design: Create/assess Source/Target data mapping designs
Frameworks: Development and delivery frameworks
Activity Reporting/Repository: Jira, Confluence.
Quality: Accuracy and attention to detail
Industry: Financial Services/Banking
Solutions: Define solutions from High level to detail design to address automating ingestion activity. Facilitate/confirm requirements from product owners, business team members and technical associates,
Process Automation: Automating processes in file management, testing data in files, analysis and design, configuration management.
Script Automation: Ability to design/create scripts to automate/improve data copy/migration/ETL for any repetitive activity.
Languages: Java, Python
Scheduling: Control-M
Databases: Relational. E.g. POSTGRESS, Oracle – as a ETL developer
File Formats: Mainframe – experience with referencing its data formats/copybooks
Big data: Experience referencing/using Hive (Schema) to access data in HDFS
Metadata management tools: MDM, EDC and Axon
Performance: Assess, recommend, improve mappings, SQL queries, Batch feeds
Automation Tools: Other tools that may add value to an automation program and generally support development. E.g. API, REST, JDBC, Webservices, Message Queues/Load balancer,
Cloud: Experience with processing of data files to be ingested/stored in the Cloud, preferably with AWS.
Prod Support: Experience in a production support role performing root cause / impact analysis – under time constraints
Experience in a similar role
8+ Years
What next?
If you are looking for that next challenge in your career and wish to apply for this role, please forward your resume to careers.au@axiomtechnologies.com",2.0,"Axiom Technologies
2.0",Melbourne,-1,1 to 50 Employees,-1,Company - Private,Industrial Manufacturing,Manufacturing,Less than $1 million (USD),-1
Data Engineer,-1,"About the Role
We are on an exciting digital journey so it’s a great time to join ME! We are seeking a Junior Data Engineer who enjoys rolling up their sleeves, learning and growing. As part of our Enterprise Data Team, you will ensure fit for purpose data warehouse solutions are built for use across the bank and by utilising best practise ETL standards, whilst ensuring the data is trusted by our BI developers and key business consumers. Oh, and you’ll get to work on Microsoft technology stack too!
You will be involved with investigating data issues, keeping data feeds flowing and collaborating with different projects across the bank to deliver quality data solutions. How important does that sound? What’s even more important is this role contributes directly to our overall business strategy through the provision of data to enable analytics & reporting, as well as supporting business and decision system processes.

About You
You’re naturally a highly motivated and energetic person who thrives in a dynamic, ever-changing collaborative team environment. Ideally you have previous experience as an ETL developer, Data Engineer or a BI developer, and if you have a degree in computer science or similar it would really put you ahead of the rest.

With your knowledge of SQL coding, data modelling, understanding of data warehouse concepts, plus experience of working on complex ETL solutions, you’re ready to expand your horizons and launch your career into the world of IT at ME.

About ME
We’re not like other banks.
ME was created by the industry super funds to be different from the pack – with a core purpose to help all Australians get ahead financially – no conditions, asterisks or exceptions. And we know that looking after customers starts with taking care of our people.
We believe everyone deserves the same opportunities in life, regardless of gender or identity, sexuality, ethnicity, religion or disability ‒ with internal affinity groups.
Perk ME up
Once you get your feet in the door at ME, we’ll put them both in your very own ME-branded Converse shoes. You’ll also get the following financial, health and fun perks when you join the team:
4U Extras portal (discounts and cashback on 100s of items including cinemas, shopping and gym memberships
10% Myki discount
Purchased Leave programme
Internal wellness programme (Mindfully ME)
Professional education through LinkedIn Learning
Novated Leasing
Professional membership reimbursements
Health checks
Financial education (To help you manage your money smarter)
LGBTIQ+ and Women at ME affinity groups

I want those Converse shoes (and the role)
Can’t see a closing date on the advert? That’s because we’re pretty efficient here at ME and we may start looking at applications sooner rather than later, so if this role sounds like your jam, be sure to apply by submitting your resume today.

Should an applicant be the preferred candidate, background checks (including police checks, reference checks, ASIC banned and disqualified persons and bankruptcy checks) will be completed prior to the candidate's employment being confirmed. The outcomes of the background checks do not automatically bar candidates; however will be assessed against the inherent requirements of the job.
Back Share
Apply Now",3.0,"ME Bank
3.0",Melbourne,-1,501 to 1000 Employees,-1,Company - Private,Banks & Credit Unions,Finance,$100 to $500 million (USD),-1
Software Engineer - Machine Learning/Data Science,-1,"Zendesk is looking for a Software Engineer - Machine Learning/Data Science for a full time position in our Melbourne office.
As part of our engineering team, you will work at a scale where the challenges start to get seriously interesting. Our global engineering team is widely dispersed over the world, with people across nearly every continent. You will get a chance to do cool things with a diverse bunch of people while working in the Melbourne office that is home to Zendesk’s first machine learning (ML) research team.
The Data Science Team, together with Data Engineering, have built Satisfaction Prediction, Answer Bot and Content Cues — products that use Machine Learning (ML) and Artificial Intelligence (AI) to help our customers work more efficiently.
What you get to do every day:
We’re currently looking for someone to join our team as we research, develop, and productionise Machine Learning and Deep Learning models. In addition to frequenting Melbourne’s finest purveyors of coffee, ramen, and bulgogi, you may find yourself:
Building machine learning models including neural networks in TensorFlow
Writing and deploying production-grade Python
Querying and constructing datasets in AWS Athena, Spark
Evaluating and responding to real-world model performance
Scaling your ML to millions of predictions per day
Presenting your work to a broader audience
Watching your algorithm help Zendesk’s end-users
What you'll bring to the role:
A strong foundation in a quantitative discipline (e.g. machine learning, statistics, bio/eco/etc-informatics, econometrics, etc) is critical for this position. While experience in deep learning and natural language processing would be beneficial, your best qualities are:
dedication to continuous learning
collaborative work attitude
strong communication skills
You should also be comfortable with at least one programming language, such as Python, R or Scala.
Application Deadline: 18/11/2020
Job Types: Full-time, Permanent
Salary: $85,000.00 – $110,000.00 per year
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Temporarily due to COVID-19",4.5,"Zendesk
4.5",Melbourne,-1,1001 to 5000 Employees,2007,Company - Public,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),-1
Software Engineer (Machine Learning),-1,"About the Role
AdelaideMRI is building a medical reporting tool. We require an engineer to work primarily on machine learning projects to improve reporting speed and report comprehensiveness.
You will perform data analysis of medical report datasets and image datasets to infer sentence recommendations, image classifications, or other actionable results for the doctors.
Skills and Experience
Background in machine learning or image processing
Qualifications in Computer Science, Software Development or Engineering or equivalent experience
Bonus points for Python
No prior medical knowledge is required.
This position offers flexible hours and work arrangements.
Job Type: Full-time
Experience:
Software Engineering: 1 year (Preferred)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Yes",-1,Adelaide MRI,Australia,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Hey there, we’re PEXA!

We started as an idea: to deliver a single, national e-Conveyancing solution. We collaborated with the industry to create a national electronic lodgement and settlement platform: PEXA. From our humble beginnings, we’ve now grown to more than 320 employees across 5 different states. We’re still expanding at a rapid rate and constantly challenging ourselves to create great experiences for our members as they transition to fully digital conveyancing.

Why become a PEXArian?

Great question! Being a PEXArian is so much more than just a job. We are passionate, motivated & unashamedly enthusiastic at PEXA - we love what we do and we’re proud to admit it! Creating brilliant member experiences wouldn’t be possible if we didn’t also strive to create an amazing employee experience. Alongside our members, our employees are at the heart of everything we do.
Here’s a snapshot of what your life at PEXA could look like:

Your growth:
We encourage you to hit your personal and professional Learning & Development goals with our tailored programs and tools.

Your wellness:
We care about your holistic well being - a fully stocked kitchen, four wellness days, a $250 wellness subsidy as well as lunch and learn sessions to support your financial well being.

Your work/life blend:
We know that work is just one aspect of your life, we want to help you create your ideal work/life blend, rather than squeezing in life around work.

Your family:
With a range of benefits aimed at supporting your family including access to a subsidised school holiday program, extended parental leave and flexi-time to support your return to work, superannuation payments for unpaid parental leave for primary carers and a childcare allowance for pre-primary aged children, when we say, ‘welcome to the family’, we really mean it!
The impact you'd drive:
The successful candidate will be responsible for developing, and maintaining infrastructure to support the delivery of new and existing products. They will also be contributing to establish the rules and frameworks for obtaining the required approvals for new products.
On day one we’d love you to have:
Experience with Python, Spark
Event streaming/sourcing with Kafka or AWS Kinesis
Experience with data structures, formats and data security best practices
AWS experience (e.g CloudFormation, S3, ECS, Lambda, SQS, IAM, KMS, DynamoDB, Glue, Athena)
Query construction and optimisation (e.g. SQL, Elasticsearch, Splunk, DynamoDB)
Git, version control practices, and continuous integration/delivery servers
PyUnit and unit testing frameworks
Production release cycles and maintenance
Collaborating with technical and non-technical teams
Even better:
Agile methodology/delivery
GraphQL
Modern frontend technology (e.g. ReactJS, TypeScript)
Machine learning frameworks and tools (e.g. TensorFlow, PyTorch)
OAuth 2, SAML 2, JWT
Data visualisation and exploration tools (e.g. Jupyter notebooks, Tableau)
AWS SageMaker
Sounds like you?
If this role sounds like you, apply today to have your application reviewed ASAP!",3.9,"Property Exchange Australia Limited
3.9",Melbourne,-1,201 to 500 Employees,2010,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Ongoing position
Full time
Based in Sydney, NSW
Who we are
Australian Red Cross is part of the world’s largest humanitarian organisation. Our aim is to improve the lives of the most vulnerable people in Australia and across our region.
About the role
The Data Engineer role will sit within the Data and Integration Squad in IT and will own (design, implement and support) the AWS Big Data technologies such as the Data Lake and Data Warehouse and support the organisation in growing the data analytics capabilities at Red Cross. In addition to this, the data engineer role will also administer the Power BI tool and support the implementation of the data mastering capability.
What you will bring
Experience building and optimizing data pipelines, architectures and data sets.
Experience in dimensional modelling and building data vaults
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with structured, semi-structured and unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Why work for us?
Work for purpose and know that your work assists Red Cross support and empower people and communities in times of vulnerability.
Generous salary packaging options available that can increase your take home pay.
Further information
To find out more about this opportunity please see the position description below or contact Sharath Kumar Gurram on 02 8651 8839.
Position Description: Position Description - Data Engineer .pdf
Applications for this position will close at 11:55pm Thursday, 5 November 2020.",4.1,"Australian Red Cross
4.1",New South Wales,-1,1001 to 5000 Employees,-1,Nonprofit Organization,Industrial Manufacturing,Manufacturing,$500 million to $1 billion (USD),-1
Junior Fullstack Data Engineer (Python and React),-1,"Formbay is the leading Renewable Energy Certificate Trading company in Sydney. We provide Digital Workflow and Compliance solutions in the renewable energy industry and document processing.
Thanks to our meteoric growth and our commitment to be the best at all we do, we've identified the need to bring on board a new Junior Fullstack Data Engineer.
Reporting to our Principal Machine Learning Engineer, you will help build Machine Learning pipelines for our existing Digital Workflow and Compliance solutions to automate fraud detection and document processing over terabytes of photographic and documentary data – including documents, photos, GPS data and aerial/satellite photography.
Our stack is based on Python, JavaScript, Dask, Tensorflow, CUDA, Nix/NixOS, AWS, Docker, PostgreSQL and more – familiarity with these applications will give you a leg-up on the competition.
Our ideal candidate will have the following competencies:
SQL
Python
JavaScript/TypeScript
Our candidate must also be comfortable working with Linux.
Located a stone's throw away from the Queen Victoria Building in Sydney's bustling CBD, we are centrally-located with easy access to public transportation, bars, cafes and fine dining.
Formbay will provide flexible working hours, a generous remuneration package and the opportunity to work on a world-first software solution are what we can offer you. Free, twice-weekly gym sessions and really, really good coffee are also available.
No hiring/recruitment agencies need apply.",5.0,"Formbay
5.0",Sydney,-1,1 to 50 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is an experienced and qualified Data Engineer to join our IT team based in Birtinya.
Key Responsibilities:
Create and maintain data pipelines and or ETL scripts
Create and maintain data integration including API and Batch interfaces
Performed detailed data analysis
Create and maintain corporate data models
Create and maintain data visualization using Qlik.Sense , PowerBI or Simliar Toolset
Experience in defining, building and maintaining data virtualization and/or star schema data warehouses
Maintain, tune and optimise database, integration and visualisation toolsets
ABOUT YOU:
To succeed in this role, you’ll need to bring the following experience and skills:
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Excellent communication skills both oral and written, with an ability to bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking
Experience with data analysis and modelling will be beneficial

How to Apply
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kawana Waters,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Graduate Data Science / Engineer,-1,"The NRMA is an organisation looking to the future, and right now, we are on the lookout for people who can help us reach our goal: to continue to shape the way Australians move, for the next 100 years and beyond. www.mynrma.com.au.
Everyone new to the team, along with our current staff, will temporarily work from home until it is safe to return to our offices. All interviewing and on boarding will be done virtually due to COVID-19.


Your opportunity
As Graduate Data Scientist or Engineer you will be part of the Data Engineering team delivering cloud data transition program for business initiatives and supporting the entire data platform build.
Your key responsibilities will be to:
Implementing Concepts of Data Warehousing, Data Mart creations within Cloud
Use of SQL for data analysis and insights
Building AI/Machine Learning prototype for implementing and supporting existing algorithms
Data Analytical reports build, using different tool sets


Requirements for Success:
Relevant Degree - Computer Science, Computer Engineering, Software Engineering, Data Science
Excellent SQL skills and demonstrated working knowledge in Python
Demonstrated understanding in data structure and algorithms.
Knowledge and concept of data warehousing methodologies
Any reporting tools experience Tableau or Oracle Analytics Cloud, Looker is desirable
Exposure to Google/AWS/Azure/Oracle any cloud based platforms is desirable
Good communication and interpersonal skills

If you have the required skills and the passion to join our high performing team, please apply today.

Employee Benefits
To ensure our employees feel valued, empowered and celebrated we provide a range of employee benefits including:
50% discount on all NRMA insurances
Free Roadside Assistance
12 weeks paid primary and 4 weeks paid secondary parental leave
Free NRMA Blue Membership
At the NRMA Group, we are People Moving People and diversity and inclusion are part of our DNA. Together, we continue to build an inclusive culture that encourages, supports and celebrates the diverse voices of our employees. It fuels our innovation, promotes flexible ways of working and connects us closer to our members and the communities we serve.",2.5,"NRMA Motoring & Services
2.5",Sydney,-1,501 to 1000 Employees,-1,Nonprofit Organization,Casual Restaurants,"Restaurants, Bars & Food Services",$500 million to $1 billion (USD),-1
Data Centre Engineer,-1,"We are a leading world group that provides low-carbon energy and services. To tackle the climate emergency facing us all, our aim is to become the world leader in the zero-carbon energy transition ""as a service"" for our clients – particular for companies and regional authorities. We use our expertise in our key business areas (renewables, gas, services) to provide competitive and bespoke solutions.
The Data Centre Engineer will be employed as part of a 24/7 ongoing shift to coordinate and monitor third party service providers, maintain the data centre facilities and infrastructure plans, coordinate the implementation of customer requests within the data centre and monitor systems, all in accordance with the Contract KPIs and SLAs.
Coordinate and monitor third party service providers for regular maintenance & testing, service faults & call outs, ensuring works are performed in accordance with Contract SLAs
Monitor and maintain the data centre facilities and infrastructure plans and documentation, including electrical, mechanical, hydraulics, fire and BMS/EMS systems
Coordinate the implementation of internal and external customer requests within the data centre
Perform scheduled plant checks and minor maintenance works
Ensure all Work Order requests are raised and closed in a timely manner
Conduct inductions for staff, vendors and contractors
Ensure all work permits for vendor works are raised and closed
Perform inventory checks on all equipment and critical spares

Qualifications
The selected candidate must be able to demonstrate:
Electrical or HVAC background, or Graduate Electrical or Mechanical Engineer
Passionate about quality work and career minded looking for a new challenge
Can commit to a day and night shift roster (2 days of day shift, then 2 days of night shift, 4 days off)
Ideally able to commence asap
As part of carrying out the duties of this role, it is mandatory to hold Australian Citizenship.

If you are interested and meet the selection criteria apply with an up-to-date resume via the apply instructions on this website.

ENGIE Services is an EEO employer, where all applicants are treated with fairness and respect and have equal access to the opportunities available.

We will not be engaging in the services of a recruitment agency to fill this vacancy and therefore request all interested candidates apply directly to this advertisement.

Job
: Maintenance
Primary Location
: Oceania-Australia-New South Wales-Erskine Park
Organization
: ENGIE Services Australia and New Zealand
Schedule
: Full-time
Nature of Responsibility
: Senior operational / administrative role
Job Posting
: Sep 11, 2020, 6:29:59 AM",3.7,"ENGIE Services Australia & New Zealand
3.7",Sydney,-1,5001 to 10000 Employees,1995,Company - Public,Energy,"Oil, Gas, Energy & Utilities",$2 to $5 billion (USD),-1
Senior Data Engineer,-1,"Senior Data Engineer, Temporary, SYDNEY - McKell

Job Title: Senior Data Engineer

Salary: SNSW Grade 9/10 - The package includes base salary range of $111,806 to $134,667, plus employer's contribution to superannuation and annual leave loading.

Location: Head Office – Haymarket

Employment Status: Temporary through till 30th June 2021


About Service NSW:

Service NSW is making it easier for people and businesses across NSW to access government services. The role designs, builds and analyses complex data from multiple sources to identify revenue, process and business improvement opportunities; providing new information and insights to the business to inform planning, continuous improvement and performance.

About the Role

We are currently seeking to appoint a Senior Data Engineer to deliver expert advice and services in the design of a Single View of Customer and data-related services to support the achievement of business outcomes and strategic goals. We support flexible working practices with staff working remotely during this time.

In this role you will:

Design, build and support a modern data platform based in AWS and vendor technologies.
Provide expertise on data modelling for Graph data model and Customer Data Platform (CDP).
Create data pipelines, load, transformation and reporting workloads in AWS.
Work with the latest data engineering technologies like Apache Kafka, AWS Kinesis, AWS Neptune, AWS Glue and AWS Athena.
Contribute to the design and decision-making of the right tool or platform for the job according to requirements.
Provide expert advice and guidance on data quality and data engineering best practices.
Support a “bigger than you can imagine” scale of data in production environments.
Design, develop and support a metrics-driven reporting solution and a meaningful business intelligence platform.
Document the solution design and support procedures of solutions.
Produce reports, visualisations and recommendations to answer complex business problems that are presented in the most appropriate format to ensure clarity for target audience.
Analyse and define new process improvement opportunities to support continuous improvement and business outcomes; providing advice to stakeholders, on ways to improve the efficiency and reliability of data products and services.
Be very responsive to the information needs of the business by corresponding to customers in a timely manner and provide support/solutions to issues raised.
Troubleshoot and perform root cause analysis on production issues. Identify and implement long term solutions to problems. Perform scheduled maintenance, release deployment and production support activities after business hours, from time to time.
Liaise with internal and external customers to discuss and gather requirements, solutions etc. and maintain a good working relationship with the stakeholders.


Skills and Experience Required:

Solid experience with workflow technologies designing and building data pipelines, data models and data stores.
Experience working within and an understanding of Amazon AWS ecosystem, including security and performance tuning.
Hands on experience working with different types of databases, with focus on Graph and NoSQL databases.
Experience with data streaming required. Having used Kafka and related technologies is an added advantage.
Sound knowledge and experience working with batch processing, data extraction and API integration.
Hands on experience with at least one programming language: Java, Python or scripting.
Demonstrated experience working in an Agile based, fast paced, complex environment within cross-functional teams.
Experience developing systematised insights, data analytics and reporting solutions is an added advantage.
Experience with interactive visualisation of data insights is an added advantage.


Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Salary Grade 9/10, with the base salary for this role starting at 111,806 base plus superannuation

Closing Date: 6th November at 9:59am - applications will be reviewed on a rolling basis, applications may close early or extend

Please apply online, direct applications submitted via email will not be considered.

The Department of Customer Service is proud to be an EEO Employer who are fully focused on equality and believe deeply in diversity of all identities making us different and a true reflection of our NSW customers. As an inclusive workplace, we support various employee resource groups, practice flexible work and workplace adjustment.

If you do require an adjustment during the recruitment process, please notify us on your application form.",3.2,"Service NSW
3.2",Sydney,-1,501 to 1000 Employees,2012,Government,State & Regional Agencies,Government,Unknown / Non-Applicable,-1
Data Engineer - Entry / Mid Level,-1,"Work with a great team on interesting projects customers
Gain more experience in AWS, Data, DevOps cloud operations
Got a working knowledge of AWS? We will teach you the cool stuff!

Itoc is seeking an up and coming Data Engineer to join our growing Data Team in Sydney.

This is an exciting role working with databases, data lakes, data warehouses, data transformation (Python SQL) and enabling AI/ML.

You will be implementing foundational, robust and production ready data platforms to enable business data-discovery, self-service, AI/ML functions across a range of client types and industries, allowing them to do more with their data.

You'll be responsible for:

Deploying data repositories such as lakes and warehouses.
Contribute to our growing portfolio of data solutions.
Ongoing optimisation and management of data platforms.
Development of transformational logic for data pipelines
Data evangelism. We want to show our clients how to follow the best practices for data.

Desired Skills and Experience

To take up the challenge, you will have a depth of skills and experience including:

1-2+ yrs of focused data experience working with SQL and/or NoSQL solutions
A solid education in Software Engineering or equivalent industry experience.
Anything Data focused preferred.
Ability to analyse business scenarios and associated data landscape to derive potential opportunities.
Strong foundation in Python and SQL
Working knowledge of APIs
Principle knowledge of the different relational database platforms and modern data storage techniques
Knowledge of the different aspects of data environments
Collect, store, process, verify consume
Experience with version management systems (such as GIT)
Working knowledge of AWS or another cloud platform - we will teach you the cool stuff.
Great communication skills, an ability to work closely with customers, developers and engineers and the confidence to present ideas in open forums.
Relevant tertiary qualifications and/or industry certifications.
Great communication skills, an ability to work closely with clients, developers and engineers and the confidence to present ideas in open forums.

While not required, a background in consulting and professional services is highly desirable.

Itoc Description

This is an exciting and challenging career opportunity to join the growing Sydney-based Data Team of a leading cloud solution provider where you will be given support to reach your long term career goals. You will be part of a team of cloud experts and will work in an environment of continuous improvement and learning delivering innovative cloud solutions across SaaS, online business and enterprise business.

On offer is a chance to join a team with a great working environment, in an organisation that values its employees and sees the value in ensuring they are engaged. Our team are clearly passionate about what they do, that's why we won the following awards:

Customer Obsession Partner of the Year 2015: ANZ Region
Customer Obsession Leadership Partner 2015: re:Invent

As an employer of choice Itoc offers competitive remuneration, training and development programs and a great working environment. We value a healthy work life balance.

The Perks

MacBook or Dell
Continuous internal learning that will provide training and career development opportunities
Working with a collaborative, social team and leveling-up your skills faster than you will anywhere else.
Quarterly social events

Itoc

Culture and smarts are important to us. Bring your secret sauce. This is no ordinary environment, you will work along some of the Cloud’s best. All engineers at Itoc must gain at least five AWS certifications. We work hard but we have fun.

Please note you must have full working rights in Australia and be available on-shore for face to face interviews.

No recruiters please.",4.0,"Itoc
4.0",Sydney,-1,1 to 50 Employees,2013,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Date: 01-Oct-2020

Location:
Melbourne, VIC, AU

Department:Description:
Technology discounts - from Apple HP Lenovo to Windows
Flexible work arrangements - work in a way that suits you best
Salary packaging - to suit your personal and financial circumstances

Do you want to work for one of the fastest growing data teams in Australia? Do you want to work on multiple data platforms and provide new solution offerings by leveraging cloud and big data technologies?

About the team

Big data information and analytics. Three words that spark apprehension in most businesses. But our team of experts are constantly curious and excited about combining our wonderful array of technological expertise to transform data into our clients most valuable assets making their work smarter. Our data consultants are supported with resources training and tools they need to excel at their work but also the freedom and power to create their own paths forward to make a difference.

As a Senior Consultant in Big Data you will work closely with the team and stakeholders to build and deliver a Cloud based vision for a next generation Big Data analytics platform with strong focus on data quality data security and deliver the systems that process huge volumes of data.

What will you typical day look like?

You will play a pivotal role in - Designing and producing high performing and stable applications to perform complex processing of massive volumes of data in a new cloud based architecture; Building real-time data processing applications which are integrated with business systems to enable value from analytic models to drive rapid decision making; Contributing to system architecture design for a data platform (including cloud-based structures both on and off premises data warehouse components and data lakes); this could cover a range of technologies various countries/locations and lines of business; Support data strategy or technology strategy definition programs including technology stack definition and target operating model requirements

Enough about us lets talk about you:
You are someone with:
Use of traditional data analytics tools and techniques (e.g. MSSQL Oracle MySQL) and ETL software (e.g. SSIS Informatica CloverETL)
Working in large scale cloud data solutions using platforms such as AWS or Azure or GCP will be a bonus.
Experience in scripting or programming (e.g. Python Java Scala C#)
Excellent verbal and written communication skills to adapt to technical and non-technical audiences.
Educated to degree level (or have equivalent experience)
Why Deloitte?

At Deloitte we create positively differentiated work experiences that enable our people to feel valued and achieve their full potential. We value difference and embrace people with diverse backgrounds and thinking styles. Knowing that people work best in different ways we are happy to discuss alternative arrangements if the working pattern you are looking for is not specifically indicated.",3.8,"Deloitte
3.8",Melbourne,-1,10000+ Employees,1850,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Engineer,-1,"Opportunity to grow the team
Period of growth
Intuitive app
S2M are working with a FinTech who have created a unique financial product to help thousands of people better manage their finance, and is currently scaling the company to the next level!

They are looking for a Data Engineer to join, and looking for someone who wants to be hands on, with opportunity to grow the team in future.

Role:

Looking for people with strong AWS experience. You will need passion for data and a cloud, through which you will help a rapidly scaling Australian FinTech establish their data infrastructure from the ground up.
5+ years’ experience as a data engineer within the data and analytics domain
A python 3.X aficionado who is very comfortable creating and orchestrating AWS data pipelines with nothing but code
Strong project delivery toolset experience in open source data integration tools
Experience with processing large volumes of complex data including visualisation and insights generation
Ability to define and develop data integration patterns and pipelines
Ability to assess complexity of data (volume, structure, relationship etc.)
Hands on experience working with different databases (RDBMS, NoSQL, Blob storage etc)
Hands on technical expertise setting up DevOps automation
Hands on experience working technologies/platform e.g. AWS, Dockers, Containers
Experience building data profiling and data cleansing frameworks
Technical reconciliation and reporting
Knowledge and experience in end-to-end project delivery, either traditional SDLC or agile delivery methodologies (or hybrid approaches)
Exceptional communication, documentation and presentation skills
If this sounds like you, get in touch today - kate.gabb@s2m.com.au
3167410agsdf",3.1,"S2M
3.1",Sydney,-1,Unknown,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Analysts,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is seeking experienced and qualified Data Analysts to join our IT team based in our corporate office in Birtinya (Sunshine Coast) or at our meat processing facility in Kilcoy.
Key Responsibilities:
A mixture of data analysis and commercial skills to source, blend and analyse data to gain insight and answer key commercial questions
Working with strategic leaders to define and model Key Performance Indicators, and assist in building forecasting models
Working closely with data engineers and BI developers to specify data pipelines and report visualisation
Drive the creation and implementation of data quality business rule including data definition, governance and quality assurance
About You:
To succeed in this role, you’ll need to bring the following experience and skills:
Proven ability to derive insight and knowledge from data using commercial expertise is a strong requirement
Strong SQL and Excel skills are essential, along with strong data analysis and commercial insights
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Effective people communicator - engage with stakeholders on reporting needs, interpret requirements into visual solutions and train/deliver the outputs to the stakeholders getting signoff of acceptance
Bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking

How to Apply:
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kilcoy,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Network Data Engineer,-1,"Min 6+ years of experience in the relevant technologies
Australian Driving License for visiting remote locations / Data Centre for day to day technical work.
Managing Network devices (switches, routers, firewalls, load balancer, and wireless technology)
Performing MACD activities for all network devices.
Supporting BAU operation activities.
Proficient in performing in-depth details of technical troubleshooting, cause and provide recommendation to the client for incidents causing extended network outage to client’s critical locations.
Provide exceptional network services in terms of network support, break-fix, design and consulting, new projects, implementation.
Configure, administer, and document firewall infrastructure.
Manage the firewall deployment, rules migrations, and firewall administration.
Supporting Cloud Migration Activities from traditional to AWS/Azure.
Setting up VPN tunnel with Cloud and 3rd Party network devices.
Integrating and upgrading existing ISP bandwidth with support from ISP Vendor.
Setting up VPN profiles for Users.
Installing hot fix and patches to mitigate the security devices from attacks and bugs.
Reviewing and fine tuning the firewall rules and NAT rules.
Documentation and change control.
Mentoring, Motivating and Guiding support teams
Technical skills:
o LAN
o Wireless
o WAN
o MPLS
o Routing protocols (OSPF,BGP)
o DMVPN
o Azure cloud Networking
o Network Security
Fortigate Manager / Analyzer / Firewall
Cisco ASA
Firepower FTD
Cisco Any connect
Site to Site VPN
F5 Load Balancing and Scripting iRule
Job Types: Full-time, Contract
Schedule:
8 hour shift
Experience:
Scripting: 5 years (Required)
Data Network: 5 years (Required)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Required)",3.6,"Total IT Global
3.6",Sydney,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Engineer - Processing & Analysis,-1,"Job Description:
Design,build and maintain the ingestion system to support various types of data(e.g. User behavior, RDS, NoSQL db and others) to be ingested to the data warehouse more timely and accurately
Translate data requirements into scalable technical data service with low latency and high concurrency
Design,build and maintain the batch or real time data pipeline in production using Hadoop big data technology
Analyze and improve efficiency, scalability, and stability of the system
Define and manage SLA,Data quality for all data sets in allocated areas of ownership
Requirements:
Minimum B.S. degree in Computer Science or a related technical field
2+ years of working experience in programming languages,such as Java,Scala,Python
Familiar with Hadoop, Spark and Flink data processing, experience of TB data processing experience is a plus
Familiar designing and operating of a robust distributed system is a plus
Understand data mining or machine learning
Excited to work intimately with data
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"SYNOPSIS:
Lead Data Engineer
Applications close Sunday 8 November 2020
Ongoing
Contact name: Shyni Sasikala
Phone: (02) 6249 9048
Email: Shyni.Sasikala@ga.gov.au

The Data Policy and Informatics section within the Digital Science and Information branch creates, implements, and promotes policies, platforms and tools that improve and support the quality, discoverability, accessibility, and general usability of Geoscience Australia’s science data products. The section consults with internal and external research, government and industry partners to establish collaborative data frameworks, architectures and models within Geoscience Australia (GA) and across broader national and international communities of practice. The section innovates, builds and maintains tools, systems, processes and governance that enable digital data management, cataloguing and open data delivery.
GA makes accessible a wide range of geoscientific and spatial data to a wide variety of stakeholders in multiple formats, and in recent years GA's data volumes have grown exponentially. GA is focussed on making its data and metadata assets accessible so that they can be used in machine to machine interactions for data analytics and other applications in environments that range from High Performance Computing (HPC), through high-end cloud servers, to mobile devices.
We currently have two opportunities for Lead Data Engineers in the Informatics team. The Lead Data Engineer is responsible for innovating and exploring new technologies that will advance GA’s science goals and maximise the uptake and use of GA’s science data. The Lead Data Engineer reports to the team’s Assistant Director but also works closely with other developers, data scientists and engineers within the Digital Science and Innovation (DiSI) branch, as well as diverse stakeholders both within and external to GA.",3.9,"Geoscience Australia
3.9",Canberra,-1,501 to 1000 Employees,2001,Government,Federal Agencies,Government,$100 to $500 million (USD),-1
Data Engineer,-1,"The Seven Network is part of Seven West Media, one of Australia’s most prominent media companies, with a market leading presence in content across broadcast television, online and in print. Comprising some of Australia’s most renowned media brands, SWM includes not just Seven Network and its affiliate channels 7two, 7mate, 7flix and BVOD offering 7plus, but also 7NEWS.com.au, The West Australian, The Sunday Times and more.
At Seven we are here to bring all Australians closer to the moments that move us - we’re first on the scene, with our finger on the pulse, on demand, in the moment. Together, we’re responsible for creating and sustaining authentic Australian engagement.
A new and exciting opportunity has opened for a Data Engineer to join the Audience Intelligence team. Based in Sydney and reporting to the Head of Data Enablement, you’ll be responsible for:
Implementation of end to end data solutions to support Data Strategy for the SWM group.
Work closely with the Data Solution Designers to develop and maintain scalable data pipelines and build out new file and API based integrations to address requirements from the various business stakeholders.
Collaborates with engineering, analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organisation.
Work on Data Preparation for analytics and data scientist team members and assist them from an engineering perspective in building and optimising the models including building the automation of the end to end workflows
Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.
Perform data analysis required to troubleshoot data related issues and assist in the resolution of production data issues.
Work effectively with vendors for successful delivery of projects and acceptance of the solution
Work on Delivery projects using Agile Software Development methodologies
We are looking for someone who has:
Bachelor's degree in computer science, computer engineering or other technical discipline is essential
Proven experience working as a digital analytics specialist
Extensive experience with digital analytics implementation (e.g. Google Analytics, Snowplow, Adobe Analytics) and BI processes and visualisation platforms
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience in ETL and building and optimizing ‘big data’ pipelines and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Experience with big data tools: Hadoop, Spark, etc., AWS cloud services: EC2, S3, Lambda and familiar with version control systems: Git
Strong coding skills with knowledge of Unix/Linux and scripting languages such as Unix Shell scripting, Python desirable
Experience supporting and working with cross-functional teams in a fast-paced environment.
Ability to multi-task and problem solve with changing demands and priorities
Ability to work under pressure to meet deadlines and detail oriented
Your success is our success: we will provide you with opportunities for you to keep learning and growing, enabling you to challenge and develop yourself. In return, we offer a benefits program that has something in it for everyone.
Seven West Media is an equal opportunity employer and we are committed to creating a diverse and inclusive workplace.
Recruitment Agencies: Seven West Media does not accept any unsolicited agency resumes and will not be responsible for any fees related to unsolicited resumes.
Advertised: 19 Oct 2020 12:00 AM AUS Eastern Daylight Time
Applications close:

Back to search results",2.5,"Seven West Media
2.5",Sydney,-1,5001 to 10000 Employees,1956,Company - Public,TV Broadcast & Cable Networks,Media,Unknown / Non-Applicable,-1
BICON Rules Engineer,-1,"APS 5 - $73,299 - $80,410 per annum plus superannuation
Biosecurity Plant Division
Canberra, ACT
Play an active role in managing biosecurity risk to Australia
Work in a motivated and professional team with a wide range of skills and backgrounds
Full training provided

Who we are
The BICON Content Development Team maintains and improves the Biosecurity Import CONditions database (BICON) content to allow external clients to understand and comply with their biosecurity obligations and internal clients to effectively manage biosecurity risk and regulate imports. We work collaboratively with internal clients to comprehend and implement their BICON content requirements and optimise the use of BICON to publish clear import requirements and onshore management support procedures to effectively manage biosecurity risk.

The Jobs
Key duties of these positions include:

working with business content (import and permit conditions) and import programs to understand and construct decision tree structures in the BICON database, in accordance with system design and authoring conventions
executing changes to import and permit conditions in alignment with service standards while complying with system rules and authoring conventions
providing technical advice through various formats on the most appropriate means of authoring BICON content to achieve import program and stakeholder objectives
using workflow management tools to maintain detailed records of changes to import conditions and key decisions
performing administrative tasks including system reporting, data analysis and scoping tasks for the BICON content change work program
contributing to the development and maintenance of instructional material, authoring conventions and courseware
clearly documenting and reporting system issues
developing and maintaining effective working relationships with internal and external stakeholders.

What we are looking for
Knowledge and experience
Experience working with complex IT systems.
Experience working collaboratively and as part of a team.
Knowledge of the role of biosecurity is preferred but not essential.

For additional information, please read the Job Description below.
Candidate Information Package docx Opens in new window",3.9,"Department of Agriculture & Water Resources
3.9",Australia,-1,5001 to 10000 Employees,-1,Government,Federal Agencies,Government,$500 million to $1 billion (USD),-1
Cloud Data Engineer,-1,"Job no: 509605
Work type: Permanent Full Time
Location: Melbourne, Canberra, Sydney
Do you embrace digital disruption?
Do you love solving complex problems, designing sophisticated solutions and building innovative technology?
Do you believe in creating powerful actionable insights from Data and Analytics?
Do you want to work in a diverse and flexible working environment?
KPMG is one of the most trusted and respected global professional services firms. Through depth of expertise, clarity of insight and strength of purpose we help our clients solve complex challenges, steer change, strengthen, transition and grow. We are a team based practice and this extends to our clients whom we work and collaborate with, in solving complex problems. Together, we design, innovate and implement, providing enduring advice that support our clients and the services they deliver. Our clients vary in size and come from a diverse range of sectors – all sharing in a common goal: to embrace change and deliver services that make Australia a better place. We are looking for talented individuals who would like to join us on the journey.
KPMG’s Digital Delta Team
We re-imagine and re-invent organisations to become world class digital enterprises using advanced technologies, data and human insights. We help organisations to embrace Digital Strategy, Artificial Intelligence (AI) & Cognitive, the Internet of Things (IoT), Data, Analytics & Modelling, Mobile App & Web, and User Experience (UX) & User Interface (UI) and more.
We work with clients to:
Formulate strategies that re-imagine organisations
Harness innovation from the 4th industrial revolution
Actioning insights from trusted data to consistently and quickly make clear decisions
Build adaptive organisations
Thrive as a connected enterprise – front, middle and back office
This is how you’ll contribute:
We are looking for ambitious Data Engineers who are passionate about helping clients define bold ambitions and deliver on them. Joining our team will take you on a journey of personal and technical growth and provide the opportunity to inspire confidence and empower change.
As a Data Engineer you are the designer, builder and manager of the information or ""big data"" infrastructure, preparing data for analytical or operational use. You will design, construct, test and maintain a data pipeline to pull together information from different source systems; integrating, consolidating and cleansing data; and structure it for use in individual analytics applications.
The KPMG Difference
Our people are focused on creating a diverse and dynamic environment that embraces and values differences. We value the variety of unique experiences, qualities and characteristics our people possess and we share and learn from each other.
We are proud to be consistently recognised as an employer of choice for women, and for our achievements in LGBT+ workplace inclusion.
Our commitment to ‘Flexibility’ allows our people to manage the changing demands of work, personal or family life. Explore the links below to hear our people share their experience @ KPMG:
Flexibility empowers wellbeing
Flexibility enables contribution to the community
Flexibility inspires technology & innovation
Flexibility supports family

Make KPMG the clear choice for your career and be Extraordinary!

Advertised: 09 Sep 2020 AUS Eastern Standard Time
Applications close:",3.8,"KPMG
3.8",Sydney,-1,10000+ Employees,1987,Subsidiary or Business Segment,Accounting,Accounting & Legal,$2 to $5 billion (USD),-1
Computer Network and Systems Engineer,-1,"Duties Include but are not limited to:
Tasks Include:
analysing, developing, interpreting and evaluating complex system design and architecture specifications, data models and diagrams in the development, configuration and integration of computer systems
researching, analysing, evaluating and monitoring network infrastructure to ensure networks are configured to operate at optimal performance
assessing and recommending improvements to network operations and integrated hardware, software, communications and operating systems
providing specialist skills in supporting and troubleshooting network problems and emergencies
installing, configuring, testing, maintaining and administering new and upgraded networks, software database applications, servers and workstations
providing network programming in support of specific business needs and requirements
preparing and maintaining procedures and documentation for network inventory, and recording diagnosis and resolution of network faults, enhancements and modifications to networks, and maintenance instructions
monitoring network traffic, and activity, capacity and usage to ensure continued integrity and optimal network performance
Skills and Experience Required:
Must have experience working in a Managed Service environment
Demonstrated experience in IT Networks and Data Centres
Understanding of systems and architectures to meet client needs
Experience in Help Desk including break / fix
Effective and timely documentation
Effective Task Management Skills
Be solution and outcome focused and willing to learn new technologies
Excellent communication skills with staff, clients and partners
Time management, ability to prioritise and deliver to schedule
Experience with N-Able and Connectwise desired
Open Cabling license desired
Job Types: Full-time, Permanent
Salary: $30.00 per hour
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,Trans-plant training,Canberra,-1,-1,-1,-1,-1,-1,-1,-1
Software Engineer (Data),-1,"If you are looking for an opportunity to make a real impact with smart people who are genuinely doing things differently then you've come to the right place! We're growing our data engineering capabilities and are looking for awesome data engineers to join our team.
With our diverse range of clients and projects, no day will look the same - but here's a great snapshot of what you'll be doing:
Work with some of the best Data Scientists and Engineers to deliver production-grade AI and Machine Learning systems as we deliver client projects from inception to production.
Consulting with our clients and working with them to build modern data systems using the 'best of' technologies and principles.
Advising clients on data strategy, architecture and technology.
Applying best software engineering practices in coding, monitoring and alerting, using CI/CD, TDD and cloud architectures.
Working over a wide range of big data tools and environments: not limited to; Apache Kafka, Spark, Python, Scala, Hive, Airflow, AWS EMR & Glue, GCP Dataproc & Dataflow, BigQuery, Snowflake, Redshift.
Who are we?
Glad you asked! We are Eliiza. Data science. Engineered for scale.
We are a passionate team of data scientists and engineers who apply data science and machine learning to solve real-world problems. Our mission is to create a bright future for Australian businesses and society in a world increasingly influenced by intelligent technologies.
We've created a culture that values diversity where people can truly be themselves! We care a lot about growing the Australian AI community in a positive direction, and we're doing several things to try and achieve that:
We provide opportunities for underrepresented groups to work in AI through our associate and intern programmes
We organise and participate in a range of community events, reading groups and meetups
We produce the AI Australia podcast
We blog about topics we care about
We stream brown bag sessions to the broader community
We're also part of Mantel Group's 'house of brands' which means it's not just the Eliiza team you'll work with, learn from and see at social events - there's another 230 of us across DigIO, Kasna & CMD Solutions!
So you're ready for something new?
We're keen to know more about you! Our team is made up of a range of people, with different experience across a huge range of data driven skill sets.
We'd love to hear from you if you have experience with:
one (or more) core language(s), ideally Scala, Python or Java
one (or more) cloud platforms, AWS, GCP, Azure
ETL/ELT concepts and technologies e.g. Data partitioning, Hive, Spark
streaming data concepts and technologies, ideally Kafka (Kinesis, Beam or Pubsub will do)
We'd be over the moon if you:
Experience with distributed/columnar databases (e.g. Snowflake, Big query, Redshift).
Experience with any of a variety of databases e.g. RDMS, NoSql, Columar, Distributed, Time series, Graph.
Knowledge of job orchestration and scheduling. Any experience with Airflow, Luigi or Oozie.
Experience with containers and container orchestration (Docker, Docker Compose or Kubernetes).
However, we value a diversity of skill-sets, and don't necessarily require that you're skilled with all of the above. If you feel you don't fit all the experience/skills listed above we still encourage you to apply or get in touch.
What's on offer if you join us?
We make sure you're always one step ahead by investing your learning and development, every year. We build our own training where it doesn't exist yet.
We hire smart people and get out of their way. By focusing on our five principles and not getting caught up in red tape, we trust you to get the job done.
You'll get all the tools you need - a new iPhone or Google phone, a new Macbook Pro or Dell, and a lot of branded swag!
But hold on, you mentioned a house of brands?
We certainly did! Mantel Group is an Australian-owned, 'house of brands' company with four technology businesses (Eliiza being one of them!) across Melbourne and Sydney. We're building a group of companies with open borders so we can support you to take on new skills without leaving an awesome team - we understand you won't have one job for life!
We may only be just two years old but Mantel Group has already been recognised #9 in the 2020 Best Places to Work in Australia and #4 in the AFR's 2020 fastest growing new companies.
Keen to chat?
Click ""Apply"" to share your details with our talent team, and we'll be in touch.
In the meantime, check out 'how we hire' to find out what's in store if you're successful and get to know us better by visiting our website and following Eliiza on LinkedIn.",-1,Eliiza,Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Infrastructure Engineer,-1,"Job Description:
Design and grow the Shopee data platform to support a variety of big data applications using open-source technologies including Kafka, Hadoop, Presto, HBase, Spark, Hive, Druid, and our own creations. Some examples include a real-time data streaming platform, a unified query platform, a cluster management system, and a machine learning platform
Dig into the source code of some open-source big data system to get the whole control and familiar with the details, configurations, designs and source code. Develop and maintain the internal release of big data systems and components as the business requirements.
Keep close and overall monitoring for all the deployments of the systems, maintain the system’s stability, improve the performance, discover the performance bottlenecks, tracking and troubleshooting, cost optimisation.
Requirements:
B. Sci. / Ms / PhD in Computer Science or a related technical field
Familiar with at least one of these languages: Java, Scala, Python, Bash under Linux / Unix. Scala is a plus
Familiar with the use and compute logical of SQL
Knowledge about the Big Data Infrastructure system technology like Distributed File System, Distributed Computing, Distributed Database will be a plus
Hands-on experiences Hadoop, Spark, Kafka, and/or Presto will be a plus
Love to use and develop open-source technologies
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"Work on an award-winning, international technology!
Endless career opportunities
An innovative, friendly team of 300+
This role will be focused on the development of our existing ClaimLogik line of products as well as working on our new cloud-first, modern suite of applications.

Intelligent Thought, our technology business is scaling and shipping our software globally. Already profitable, part of a much larger group business, with investors such as Macquarie Capital and Envest – we are all set to deliver textbook disruption to the Insurance Industry. The growth of the platform, of our customer base, and the increasing industry demand have led to the need for this role to help the team scale.

Our Philosophy
Give each employee a sense of purpose and an environment for them to connect the importance of their role to delivering a service that matters to our customers.
Challenge the ‘why’ of traditional claims processes.
Keep it simple – do only what brings value and what matters to the customer
Enable employee decisions, empower our people
Responsibilities:
Create, extend and maintain ETL pipelines to form our data lake, data warehouse and analytics platform (currently using the Microsoft Azure set of tools and service)
Help define the optimal data pipeline architecture
Influence the tool selection, platform selection, data architecture and strategy which will transform the business to be truly data-driven
Understand, analyse and size user requirements
Work with different parts of the business to provide them with the insights they need to deliver the best results
Skills & experience:
Degree or qualification in computer science or related
Advanced knowledge of relational database, including query authoring and query optimisation (MS SQL Server and PostgreSQL).
Experience building and optimising ETL pipelines
Experience designing complex data models
Experience working with cloud platforms (Azure or AWS)
Efficient time management and organisational skills
High attention to detail and accuracy
Effective communication skills to build strong working relationships; both written and verbal
Proactive and results-driven
Why Claim Central?
Claim Central Consolidated is a global insurance industry leader across, claims management, insurance technology and data and analytics. Currently operating in the United States, Australia, South Africa, Italy and New Zealand, we have pioneered digitally connected claims management services across the globe. Claim Central is a disruptor and thought leader in the industry and we were recognised as the Australian Financial Review’s 8th Most Innovative Company in Australia in 2016. This business is in a period of unprecedented growth, transitioning our technology and services into multiple geographies at a rapid pace. Our unique culture is based on teamwork, collaboration, trust, respect and performance. We also offer many benefits apart from our exceptional team culture; including flexible work arrangements, and continued professional development.

Be a part of this journey in a career-defining role.",-1,Claim Central,Matraville,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer - AI/ML,-1,"Our client provides services to a major industry across the country. The business is still early in it's days of technology development and the environment is greenfields in nature (no pun intended), effectively working like a start-up.

Their data and analytics team have worked and built leading and bleeding-edge technologies in this space and what they have created so far may be game-changing. From a machine learning perspective, the progress they have made to the business has already seen proven success in changing the future of an industry that will have positive consequences for all those involved.

You will have previously worked in a technical capacity in the data and analytics space and have experience working with an organisation where machine learning has been implemented, not just a concept that the business talks about having or the technology team would love to have. The commercial experience you will have had in the ML field will be proven examples of where you have affected the way a business or industry used to perform, to the changes that have come about from this.

Technically, you will have extensive experience in the Microsoft space - Power BI, Azure etc and you will have previously mentored and coached junior members of the teams you have been part of.

This is a rare opportunity in Brisbane where the business has truly embraced and funded projects across the ML space and would be a great chance for those in the Data Development/Data Engineering field, who are looking to move into a Data Scientist role in the future.

Please send your application through if you would like to know more.",4.0,"Emanate Technology
4.0",Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Solution designer/ ETL Engineer & Data Modeller,-1,"We are looking for a Qualified and Experienced Solution Designer to join our client for a period of 6 months with a view to extend.
You will work closely with team members and your contribution will range across gathering and analyzing information, developing and documenting improved processes and work instructions and experienced DWH Lead with skills in requirement analysis, solution designing, developing, testing and supporting ETL solutions.
A hands-on solution designer, data modeler and ETL developer for Data Warehousing and ETL application transformation projects using Informatica PowerCenter.
Knowledge on AWS, S3, Redshift, Informatica BDM, and related technologies.
Experience working with IPython, PySparks, AuCuMo, Airflow, Jenkins, Github, Athena, JIRA, Rally, Spectrum, Glue, Flyway.
Good exposure on Oracle PL/SQL, aware of DBA activities, writing and performance tuning of complex SQL queries.
Contract length: 6 months
Job Types: Full-time, Contract
Salary: $650.00 – $800.00 per day
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,nducive,Melbourne,-1,-1,-1,-1,-1,-1,-1,-1
"Data Engineer, Wollongong NSW or Mount Waverley VIC",-1,"Company Description
BlueScope is a technically advanced supplier of steel and steel products in Australia. We are an inclusive organisation and every day we showcase our technology and expertise throughout the world.

Job Description
We are looking for two Data Engineers to join our IT team, based in Wollongong NSW or Mount Waverley VIC. Use your experience in analytics to unlock business value, enabling use of big data for insights and decision-making.
Reporting to the Data Product Owner for our Australian Steel Products (ASP) business, this position will support strategic goals related to data. This will see you:
Gather business and technical requirements with the view to deliver outcomes;
Develop and implement end-to-end data collection, consolidation, modelling and visualisation solutions;
Document metadata in a dictionary and catalogue;
Ensure consumers of such information understand its accuracy, timeliness, quality and sensitivity, so that it is used appropriately; and
Identify opportunities to enhance analytics.
What are the benefits?
Work in a supportive and collaborative team environment whilst we embark on a journey to transform the way our business uses data!
Our systems landscape is broad and diverse. You will be encouraged to think creatively to develop data solutions which solve real business problems.
Working in this role you will enjoy:
the chance to learn more about data science;
salaried remuneration with attractive superannuation options;
the opportunity to participate in a performance incentive scheme; and
access to further development and career opportunities with BlueScope.
Who are we looking for?
We welcome applications from professionals with experience in data analytics and/or programming. Supported by your knowledge of project delivery methods (e.g. Agile), you will demonstrate:
experience with data mining, wrangling, mapping and visualisation techniques (e.g. Azure Data Factory, Databricks and/or DevOps etc.);
well-developed ability in gathering business and technical requirements;
skills in developing and implementing collection, consolidation, modelling and visualisation solutions; and
a passion for sharing your knowledge and desire for ongoing professional development.

Qualifications

null

Additional Information
We're proud to have been named an Inclusive Employer for 2019–2020 by the Diversity Council of Australia. We believe that our people are our strength. Having a diverse and inclusive workplace enables us to improve our capability and ensure continued, sustainable success.
We know that workplace flexibility can mean something different to everyone. Under our B-Flex initiative all of our roles have some degree of flexibility. We encourage you to discuss your needs with us.
Applications close Sunday 25th October 2020.",3.3,"BlueScope
3.3",Wollongong,-1,201 to 500 Employees,-1,Company - Private,Construction,"Construction, Repair & Maintenance",$100 to $500 million (USD),-1
ETL Data Engineer,-1,"ETL Data Engineer

Join a team that’s changing how Australia lives, works, plays and grows
We want you to be the best version of you

Work with innovative teams and explore new technologies to help solve real-world problems.

A typical day as a Data Engineer

ETL / Big Data Engineering professionals will be responsible for guiding the full lifecycle of a Data solution, including:
Working in highly client-facing roles to contribute throughout the end-to-end delivery lifecycle of complex and large-scale digital solutions
Use case and business case development
Support existing and new applications utilizing in-depth technical and data knowledge. Troubleshooting complex issues and providing advisory services to improve the client’s data landscape
Help to streamline and simplify the clients’ complex data landscape by integrating different applications and data architectures
Implementation from requirements analysis, platform selection, digital architecture design, application design and development, testing, and deployment
Interstate travel may be required

Basic qualifications:
Bachelor’s degree
Experience across systems integration, information management, data management and architecture, and business analytics
Experience with being in a team focusing on large-scale, multi-release information centric projects
Experience with waterfall and agile delivery and run / application support functions
Part of a team working on End to end implementation of at least 1 big data project

Preferred Skills:
Hand on experience in Data warehousing using ETL tools such as DataStage, Autosys and TeraData
Hands on experience in ETL job development with multiple stages like sequential file, Transformer, Lookup, join, sort and Database stages.
Strong hand on skills in design, development and implementation of various data remediation, Data migration, data integration techniques.
Strong hand on data modelling experience.
Strong hands on experience in database performance tuning including complex query optimizations and physical database tuning using Teradata.
Understanding of architectural designs and strategy related to data migration, data cleansing, data quality and data consolidation.
Proven data analysis, requirement gathering and problem-solving skills
Exposure to Unix environment and shell scripting.
Experience in Banking and Financial services industry
Desirable: Knowledge of cloud computing infrastructure (e.g. Amazon Web Services EC2, Google Cloud, Microsoft Azure)
About Accenture

Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. We combine unmatched experience and specialized capabilities across more than 40 industries — powered by the world’s largest network of Advanced Technology and Intelligent Operations centers. With 513,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises. Visit us at www.accenture.com.

Accenture is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, marital, domestic or civil partnership status, sexual orientation, gender identity, or any other basis as protected by applicable law.

Vera Goga is the Recruiter managing this role. As the team experience high volumes of applications, we appreciate your patience to allow for a fair and timely process.",3.9,"Accenture
3.9",Sydney,-1,10000+ Employees,1989,Company - Public,Consulting,Business Services,$10+ billion (USD),-1
Student Engineer,-1,"The candidate will have the ability to:
Undertake onsite inspection to collect asset condition data based on the relevant engineering standards and technical guidelines;
Undertake desktop analysis to evaluate the condition and performance of the assets;
Provide the appropriate information, advice, engineering input and support services for the sustainable management of Council’s stormwater and transport networks.
Qualifications:
The successful candidate will be enrolled in a Bachelor of Engineering with a minimum of two years completed.
Position Number: 100678
Position Hours: Fixed term (3 months), hours will be negotiated with the successful candidate, maximum of 75 hours per fortnight.
Salary: Schedule A, Salary Point 4.0. $28.64 per hour ($55,853.45 per annum, pro-rata) in accordance with Glenorchy City Council’s Enterprise Agreement 2016
Please note that all successful applicants will be required to provide a current National Police Check prior to commencement of employment.
For further information on this position, contact Patrick Marshall, Senior Civil Engineer on (03) 6216 6800.
How to apply: Applications for this position must be lodged on this submission site or on the Glenorchy City Council website www.gcc.tas.gov.au - Careers page.
To be considered for this role, all applicants must address the key selection criteria in the and provide a current resume. A copy of the position description can be found by clicking the below hyperlink or on the Glenorchy City Council website.
Applications close at 8pm on Sunday, 1st November 2020
- Student Engineer",4.0,"Glenorchy City Council
4.0",Glenorchy,-1,501 to 1000 Employees,-1,Government,-1,-1,Less than $1 million (USD),-1
Data Engineer involving DevOps,-1,"Data Engineer involving DevOps
Axiom Technologies is an Australia based entity with the history of providing Managed IT solutions to medium to large scale enterprises globally. Please visit our website for more information about what we do at www.axiomtechnologies.com
Axiom Technologies is an Equal Opportunity Employer and encourage applicants from all backgrounds and gender to apply, including, Aboriginal and Torres Strait Islander candidates
Job Requirements:
8+ years IT experience, with at least 5+ years of “Data Engineer/Deveoper” focused titles/roles,
Data Tools: Hands on experience with Apache Beam.
Testing: Hands on experience with automated testing activities/outcomes
DevOps: Experience with the processes involving Microservices facilities for artifacts developed
Platform/OS: Mid-range/Unix
Languages: Unix (Shell) Scripting/commands, SQL, Python
File formats: Text, CSV, Parquet, JSON, XML
Scheduling: Jenkins, Airflow
Auto Scripting: Designing/creation of scripts for repetitive activity. E.g. Unix scripting/SQL
Big data: Exposure to Data Lake Concepts, Hive (Schema), HDFS
Source Control tools: GIT
Delivery Models: Agile, Scrum
Ingestion Design: Create/assess Source/Target data mapping designs
Frameworks: Development and delivery frameworks
Activity Reporting/Repository: Jira, Confluence.
Quality: Accuracy and attention to detail
Industry: Financial Services/Banking
Solutions: Define solutions from High level to detail design to address automating ingestion activity. Facilitate/confirm requirements from product owners, business team members and technical associates,
Process Automation: Automating processes in file management, testing data in files, analysis and design, configuration management.
Script Automation: Ability to design/create scripts to automate/improve data copy/migration/ETL for any repetitive activity.
Languages: Java, Python
Scheduling: Control-M
Databases: Relational. E.g. POSTGRESS, Oracle – as a ETL developer
File Formats: Mainframe – experience with referencing its data formats/copybooks
Big data: Experience referencing/using Hive (Schema) to access data in HDFS
Metadata management tools: MDM, EDC and Axon
Performance: Assess, recommend, improve mappings, SQL queries, Batch feeds
Automation Tools: Other tools that may add value to an automation program and generally support development. E.g. API, REST, JDBC, Webservices, Message Queues/Load balancer,
Cloud: Experience with processing of data files to be ingested/stored in the Cloud, preferably with AWS.
Prod Support: Experience in a production support role performing root cause / impact analysis – under time constraints
Experience in a similar role
8+ Years
What next?
If you are looking for that next challenge in your career and wish to apply for this role, please forward your resume to careers.au@axiomtechnologies.com",2.0,"Axiom Technologies
2.0",Melbourne,-1,1 to 50 Employees,-1,Company - Private,Industrial Manufacturing,Manufacturing,Less than $1 million (USD),-1
Data Engineer,-1,"About the Role
We are on an exciting digital journey so it’s a great time to join ME! We are seeking a Junior Data Engineer who enjoys rolling up their sleeves, learning and growing. As part of our Enterprise Data Team, you will ensure fit for purpose data warehouse solutions are built for use across the bank and by utilising best practise ETL standards, whilst ensuring the data is trusted by our BI developers and key business consumers. Oh, and you’ll get to work on Microsoft technology stack too!
You will be involved with investigating data issues, keeping data feeds flowing and collaborating with different projects across the bank to deliver quality data solutions. How important does that sound? What’s even more important is this role contributes directly to our overall business strategy through the provision of data to enable analytics & reporting, as well as supporting business and decision system processes.

About You
You’re naturally a highly motivated and energetic person who thrives in a dynamic, ever-changing collaborative team environment. Ideally you have previous experience as an ETL developer, Data Engineer or a BI developer, and if you have a degree in computer science or similar it would really put you ahead of the rest.

With your knowledge of SQL coding, data modelling, understanding of data warehouse concepts, plus experience of working on complex ETL solutions, you’re ready to expand your horizons and launch your career into the world of IT at ME.

About ME
We’re not like other banks.
ME was created by the industry super funds to be different from the pack – with a core purpose to help all Australians get ahead financially – no conditions, asterisks or exceptions. And we know that looking after customers starts with taking care of our people.
We believe everyone deserves the same opportunities in life, regardless of gender or identity, sexuality, ethnicity, religion or disability ‒ with internal affinity groups.
Perk ME up
Once you get your feet in the door at ME, we’ll put them both in your very own ME-branded Converse shoes. You’ll also get the following financial, health and fun perks when you join the team:
4U Extras portal (discounts and cashback on 100s of items including cinemas, shopping and gym memberships
10% Myki discount
Purchased Leave programme
Internal wellness programme (Mindfully ME)
Professional education through LinkedIn Learning
Novated Leasing
Professional membership reimbursements
Health checks
Financial education (To help you manage your money smarter)
LGBTIQ+ and Women at ME affinity groups

I want those Converse shoes (and the role)
Can’t see a closing date on the advert? That’s because we’re pretty efficient here at ME and we may start looking at applications sooner rather than later, so if this role sounds like your jam, be sure to apply by submitting your resume today.

Should an applicant be the preferred candidate, background checks (including police checks, reference checks, ASIC banned and disqualified persons and bankruptcy checks) will be completed prior to the candidate's employment being confirmed. The outcomes of the background checks do not automatically bar candidates; however will be assessed against the inherent requirements of the job.
Back Share
Apply Now",3.0,"ME Bank
3.0",Melbourne,-1,501 to 1000 Employees,-1,Company - Private,Banks & Credit Unions,Finance,$100 to $500 million (USD),-1
Software Engineer - Machine Learning/Data Science,-1,"Zendesk is looking for a Software Engineer - Machine Learning/Data Science for a full time position in our Melbourne office.
As part of our engineering team, you will work at a scale where the challenges start to get seriously interesting. Our global engineering team is widely dispersed over the world, with people across nearly every continent. You will get a chance to do cool things with a diverse bunch of people while working in the Melbourne office that is home to Zendesk’s first machine learning (ML) research team.
The Data Science Team, together with Data Engineering, have built Satisfaction Prediction, Answer Bot and Content Cues — products that use Machine Learning (ML) and Artificial Intelligence (AI) to help our customers work more efficiently.
What you get to do every day:
We’re currently looking for someone to join our team as we research, develop, and productionise Machine Learning and Deep Learning models. In addition to frequenting Melbourne’s finest purveyors of coffee, ramen, and bulgogi, you may find yourself:
Building machine learning models including neural networks in TensorFlow
Writing and deploying production-grade Python
Querying and constructing datasets in AWS Athena, Spark
Evaluating and responding to real-world model performance
Scaling your ML to millions of predictions per day
Presenting your work to a broader audience
Watching your algorithm help Zendesk’s end-users
What you'll bring to the role:
A strong foundation in a quantitative discipline (e.g. machine learning, statistics, bio/eco/etc-informatics, econometrics, etc) is critical for this position. While experience in deep learning and natural language processing would be beneficial, your best qualities are:
dedication to continuous learning
collaborative work attitude
strong communication skills
You should also be comfortable with at least one programming language, such as Python, R or Scala.
Application Deadline: 18/11/2020
Job Types: Full-time, Permanent
Salary: $85,000.00 – $110,000.00 per year
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Temporarily due to COVID-19",4.5,"Zendesk
4.5",Melbourne,-1,1001 to 5000 Employees,2007,Company - Public,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),-1
Software Engineer (Machine Learning),-1,"About the Role
AdelaideMRI is building a medical reporting tool. We require an engineer to work primarily on machine learning projects to improve reporting speed and report comprehensiveness.
You will perform data analysis of medical report datasets and image datasets to infer sentence recommendations, image classifications, or other actionable results for the doctors.
Skills and Experience
Background in machine learning or image processing
Qualifications in Computer Science, Software Development or Engineering or equivalent experience
Bonus points for Python
No prior medical knowledge is required.
This position offers flexible hours and work arrangements.
Job Type: Full-time
Experience:
Software Engineering: 1 year (Preferred)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Yes",-1,Adelaide MRI,Australia,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Hey there, we’re PEXA!

We started as an idea: to deliver a single, national e-Conveyancing solution. We collaborated with the industry to create a national electronic lodgement and settlement platform: PEXA. From our humble beginnings, we’ve now grown to more than 320 employees across 5 different states. We’re still expanding at a rapid rate and constantly challenging ourselves to create great experiences for our members as they transition to fully digital conveyancing.

Why become a PEXArian?

Great question! Being a PEXArian is so much more than just a job. We are passionate, motivated & unashamedly enthusiastic at PEXA - we love what we do and we’re proud to admit it! Creating brilliant member experiences wouldn’t be possible if we didn’t also strive to create an amazing employee experience. Alongside our members, our employees are at the heart of everything we do.
Here’s a snapshot of what your life at PEXA could look like:

Your growth:
We encourage you to hit your personal and professional Learning & Development goals with our tailored programs and tools.

Your wellness:
We care about your holistic well being - a fully stocked kitchen, four wellness days, a $250 wellness subsidy as well as lunch and learn sessions to support your financial well being.

Your work/life blend:
We know that work is just one aspect of your life, we want to help you create your ideal work/life blend, rather than squeezing in life around work.

Your family:
With a range of benefits aimed at supporting your family including access to a subsidised school holiday program, extended parental leave and flexi-time to support your return to work, superannuation payments for unpaid parental leave for primary carers and a childcare allowance for pre-primary aged children, when we say, ‘welcome to the family’, we really mean it!
The impact you'd drive:
The successful candidate will be responsible for developing, and maintaining infrastructure to support the delivery of new and existing products. They will also be contributing to establish the rules and frameworks for obtaining the required approvals for new products.
On day one we’d love you to have:
Experience with Python, Spark
Event streaming/sourcing with Kafka or AWS Kinesis
Experience with data structures, formats and data security best practices
AWS experience (e.g CloudFormation, S3, ECS, Lambda, SQS, IAM, KMS, DynamoDB, Glue, Athena)
Query construction and optimisation (e.g. SQL, Elasticsearch, Splunk, DynamoDB)
Git, version control practices, and continuous integration/delivery servers
PyUnit and unit testing frameworks
Production release cycles and maintenance
Collaborating with technical and non-technical teams
Even better:
Agile methodology/delivery
GraphQL
Modern frontend technology (e.g. ReactJS, TypeScript)
Machine learning frameworks and tools (e.g. TensorFlow, PyTorch)
OAuth 2, SAML 2, JWT
Data visualisation and exploration tools (e.g. Jupyter notebooks, Tableau)
AWS SageMaker
Sounds like you?
If this role sounds like you, apply today to have your application reviewed ASAP!",3.9,"Property Exchange Australia Limited
3.9",Melbourne,-1,201 to 500 Employees,2010,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Ongoing position
Full time
Based in Sydney, NSW
Who we are
Australian Red Cross is part of the world’s largest humanitarian organisation. Our aim is to improve the lives of the most vulnerable people in Australia and across our region.
About the role
The Data Engineer role will sit within the Data and Integration Squad in IT and will own (design, implement and support) the AWS Big Data technologies such as the Data Lake and Data Warehouse and support the organisation in growing the data analytics capabilities at Red Cross. In addition to this, the data engineer role will also administer the Power BI tool and support the implementation of the data mastering capability.
What you will bring
Experience building and optimizing data pipelines, architectures and data sets.
Experience in dimensional modelling and building data vaults
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with structured, semi-structured and unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Why work for us?
Work for purpose and know that your work assists Red Cross support and empower people and communities in times of vulnerability.
Generous salary packaging options available that can increase your take home pay.
Further information
To find out more about this opportunity please see the position description below or contact Sharath Kumar Gurram on 02 8651 8839.
Position Description: Position Description - Data Engineer .pdf
Applications for this position will close at 11:55pm Thursday, 5 November 2020.",4.1,"Australian Red Cross
4.1",New South Wales,-1,1001 to 5000 Employees,-1,Nonprofit Organization,Industrial Manufacturing,Manufacturing,$500 million to $1 billion (USD),-1
Junior Fullstack Data Engineer (Python and React),-1,"Formbay is the leading Renewable Energy Certificate Trading company in Sydney. We provide Digital Workflow and Compliance solutions in the renewable energy industry and document processing.
Thanks to our meteoric growth and our commitment to be the best at all we do, we've identified the need to bring on board a new Junior Fullstack Data Engineer.
Reporting to our Principal Machine Learning Engineer, you will help build Machine Learning pipelines for our existing Digital Workflow and Compliance solutions to automate fraud detection and document processing over terabytes of photographic and documentary data – including documents, photos, GPS data and aerial/satellite photography.
Our stack is based on Python, JavaScript, Dask, Tensorflow, CUDA, Nix/NixOS, AWS, Docker, PostgreSQL and more – familiarity with these applications will give you a leg-up on the competition.
Our ideal candidate will have the following competencies:
SQL
Python
JavaScript/TypeScript
Our candidate must also be comfortable working with Linux.
Located a stone's throw away from the Queen Victoria Building in Sydney's bustling CBD, we are centrally-located with easy access to public transportation, bars, cafes and fine dining.
Formbay will provide flexible working hours, a generous remuneration package and the opportunity to work on a world-first software solution are what we can offer you. Free, twice-weekly gym sessions and really, really good coffee are also available.
No hiring/recruitment agencies need apply.",5.0,"Formbay
5.0",Sydney,-1,1 to 50 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is an experienced and qualified Data Engineer to join our IT team based in Birtinya.
Key Responsibilities:
Create and maintain data pipelines and or ETL scripts
Create and maintain data integration including API and Batch interfaces
Performed detailed data analysis
Create and maintain corporate data models
Create and maintain data visualization using Qlik.Sense , PowerBI or Simliar Toolset
Experience in defining, building and maintaining data virtualization and/or star schema data warehouses
Maintain, tune and optimise database, integration and visualisation toolsets
ABOUT YOU:
To succeed in this role, you’ll need to bring the following experience and skills:
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Excellent communication skills both oral and written, with an ability to bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking
Experience with data analysis and modelling will be beneficial

How to Apply
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kawana Waters,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Graduate Data Science / Engineer,-1,"The NRMA is an organisation looking to the future, and right now, we are on the lookout for people who can help us reach our goal: to continue to shape the way Australians move, for the next 100 years and beyond. www.mynrma.com.au.
Everyone new to the team, along with our current staff, will temporarily work from home until it is safe to return to our offices. All interviewing and on boarding will be done virtually due to COVID-19.


Your opportunity
As Graduate Data Scientist or Engineer you will be part of the Data Engineering team delivering cloud data transition program for business initiatives and supporting the entire data platform build.
Your key responsibilities will be to:
Implementing Concepts of Data Warehousing, Data Mart creations within Cloud
Use of SQL for data analysis and insights
Building AI/Machine Learning prototype for implementing and supporting existing algorithms
Data Analytical reports build, using different tool sets


Requirements for Success:
Relevant Degree - Computer Science, Computer Engineering, Software Engineering, Data Science
Excellent SQL skills and demonstrated working knowledge in Python
Demonstrated understanding in data structure and algorithms.
Knowledge and concept of data warehousing methodologies
Any reporting tools experience Tableau or Oracle Analytics Cloud, Looker is desirable
Exposure to Google/AWS/Azure/Oracle any cloud based platforms is desirable
Good communication and interpersonal skills

If you have the required skills and the passion to join our high performing team, please apply today.

Employee Benefits
To ensure our employees feel valued, empowered and celebrated we provide a range of employee benefits including:
50% discount on all NRMA insurances
Free Roadside Assistance
12 weeks paid primary and 4 weeks paid secondary parental leave
Free NRMA Blue Membership
At the NRMA Group, we are People Moving People and diversity and inclusion are part of our DNA. Together, we continue to build an inclusive culture that encourages, supports and celebrates the diverse voices of our employees. It fuels our innovation, promotes flexible ways of working and connects us closer to our members and the communities we serve.",2.5,"NRMA Motoring & Services
2.5",Sydney,-1,501 to 1000 Employees,-1,Nonprofit Organization,Casual Restaurants,"Restaurants, Bars & Food Services",$500 million to $1 billion (USD),-1
Data Centre Engineer,-1,"We are a leading world group that provides low-carbon energy and services. To tackle the climate emergency facing us all, our aim is to become the world leader in the zero-carbon energy transition ""as a service"" for our clients – particular for companies and regional authorities. We use our expertise in our key business areas (renewables, gas, services) to provide competitive and bespoke solutions.
The Data Centre Engineer will be employed as part of a 24/7 ongoing shift to coordinate and monitor third party service providers, maintain the data centre facilities and infrastructure plans, coordinate the implementation of customer requests within the data centre and monitor systems, all in accordance with the Contract KPIs and SLAs.
Coordinate and monitor third party service providers for regular maintenance & testing, service faults & call outs, ensuring works are performed in accordance with Contract SLAs
Monitor and maintain the data centre facilities and infrastructure plans and documentation, including electrical, mechanical, hydraulics, fire and BMS/EMS systems
Coordinate the implementation of internal and external customer requests within the data centre
Perform scheduled plant checks and minor maintenance works
Ensure all Work Order requests are raised and closed in a timely manner
Conduct inductions for staff, vendors and contractors
Ensure all work permits for vendor works are raised and closed
Perform inventory checks on all equipment and critical spares

Qualifications
The selected candidate must be able to demonstrate:
Electrical or HVAC background, or Graduate Electrical or Mechanical Engineer
Passionate about quality work and career minded looking for a new challenge
Can commit to a day and night shift roster (2 days of day shift, then 2 days of night shift, 4 days off)
Ideally able to commence asap
As part of carrying out the duties of this role, it is mandatory to hold Australian Citizenship.

If you are interested and meet the selection criteria apply with an up-to-date resume via the apply instructions on this website.

ENGIE Services is an EEO employer, where all applicants are treated with fairness and respect and have equal access to the opportunities available.

We will not be engaging in the services of a recruitment agency to fill this vacancy and therefore request all interested candidates apply directly to this advertisement.

Job
: Maintenance
Primary Location
: Oceania-Australia-New South Wales-Erskine Park
Organization
: ENGIE Services Australia and New Zealand
Schedule
: Full-time
Nature of Responsibility
: Senior operational / administrative role
Job Posting
: Sep 11, 2020, 6:29:59 AM",3.7,"ENGIE Services Australia & New Zealand
3.7",Sydney,-1,5001 to 10000 Employees,1995,Company - Public,Energy,"Oil, Gas, Energy & Utilities",$2 to $5 billion (USD),-1
Senior Data Engineer,-1,"Senior Data Engineer, Temporary, SYDNEY - McKell

Job Title: Senior Data Engineer

Salary: SNSW Grade 9/10 - The package includes base salary range of $111,806 to $134,667, plus employer's contribution to superannuation and annual leave loading.

Location: Head Office – Haymarket

Employment Status: Temporary through till 30th June 2021


About Service NSW:

Service NSW is making it easier for people and businesses across NSW to access government services. The role designs, builds and analyses complex data from multiple sources to identify revenue, process and business improvement opportunities; providing new information and insights to the business to inform planning, continuous improvement and performance.

About the Role

We are currently seeking to appoint a Senior Data Engineer to deliver expert advice and services in the design of a Single View of Customer and data-related services to support the achievement of business outcomes and strategic goals. We support flexible working practices with staff working remotely during this time.

In this role you will:

Design, build and support a modern data platform based in AWS and vendor technologies.
Provide expertise on data modelling for Graph data model and Customer Data Platform (CDP).
Create data pipelines, load, transformation and reporting workloads in AWS.
Work with the latest data engineering technologies like Apache Kafka, AWS Kinesis, AWS Neptune, AWS Glue and AWS Athena.
Contribute to the design and decision-making of the right tool or platform for the job according to requirements.
Provide expert advice and guidance on data quality and data engineering best practices.
Support a “bigger than you can imagine” scale of data in production environments.
Design, develop and support a metrics-driven reporting solution and a meaningful business intelligence platform.
Document the solution design and support procedures of solutions.
Produce reports, visualisations and recommendations to answer complex business problems that are presented in the most appropriate format to ensure clarity for target audience.
Analyse and define new process improvement opportunities to support continuous improvement and business outcomes; providing advice to stakeholders, on ways to improve the efficiency and reliability of data products and services.
Be very responsive to the information needs of the business by corresponding to customers in a timely manner and provide support/solutions to issues raised.
Troubleshoot and perform root cause analysis on production issues. Identify and implement long term solutions to problems. Perform scheduled maintenance, release deployment and production support activities after business hours, from time to time.
Liaise with internal and external customers to discuss and gather requirements, solutions etc. and maintain a good working relationship with the stakeholders.


Skills and Experience Required:

Solid experience with workflow technologies designing and building data pipelines, data models and data stores.
Experience working within and an understanding of Amazon AWS ecosystem, including security and performance tuning.
Hands on experience working with different types of databases, with focus on Graph and NoSQL databases.
Experience with data streaming required. Having used Kafka and related technologies is an added advantage.
Sound knowledge and experience working with batch processing, data extraction and API integration.
Hands on experience with at least one programming language: Java, Python or scripting.
Demonstrated experience working in an Agile based, fast paced, complex environment within cross-functional teams.
Experience developing systematised insights, data analytics and reporting solutions is an added advantage.
Experience with interactive visualisation of data insights is an added advantage.


Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Salary Grade 9/10, with the base salary for this role starting at 111,806 base plus superannuation

Closing Date: 6th November at 9:59am - applications will be reviewed on a rolling basis, applications may close early or extend

Please apply online, direct applications submitted via email will not be considered.

The Department of Customer Service is proud to be an EEO Employer who are fully focused on equality and believe deeply in diversity of all identities making us different and a true reflection of our NSW customers. As an inclusive workplace, we support various employee resource groups, practice flexible work and workplace adjustment.

If you do require an adjustment during the recruitment process, please notify us on your application form.",3.2,"Service NSW
3.2",Sydney,-1,501 to 1000 Employees,2012,Government,State & Regional Agencies,Government,Unknown / Non-Applicable,-1
Data Engineer - Entry / Mid Level,-1,"Work with a great team on interesting projects customers
Gain more experience in AWS, Data, DevOps cloud operations
Got a working knowledge of AWS? We will teach you the cool stuff!

Itoc is seeking an up and coming Data Engineer to join our growing Data Team in Sydney.

This is an exciting role working with databases, data lakes, data warehouses, data transformation (Python SQL) and enabling AI/ML.

You will be implementing foundational, robust and production ready data platforms to enable business data-discovery, self-service, AI/ML functions across a range of client types and industries, allowing them to do more with their data.

You'll be responsible for:

Deploying data repositories such as lakes and warehouses.
Contribute to our growing portfolio of data solutions.
Ongoing optimisation and management of data platforms.
Development of transformational logic for data pipelines
Data evangelism. We want to show our clients how to follow the best practices for data.

Desired Skills and Experience

To take up the challenge, you will have a depth of skills and experience including:

1-2+ yrs of focused data experience working with SQL and/or NoSQL solutions
A solid education in Software Engineering or equivalent industry experience.
Anything Data focused preferred.
Ability to analyse business scenarios and associated data landscape to derive potential opportunities.
Strong foundation in Python and SQL
Working knowledge of APIs
Principle knowledge of the different relational database platforms and modern data storage techniques
Knowledge of the different aspects of data environments
Collect, store, process, verify consume
Experience with version management systems (such as GIT)
Working knowledge of AWS or another cloud platform - we will teach you the cool stuff.
Great communication skills, an ability to work closely with customers, developers and engineers and the confidence to present ideas in open forums.
Relevant tertiary qualifications and/or industry certifications.
Great communication skills, an ability to work closely with clients, developers and engineers and the confidence to present ideas in open forums.

While not required, a background in consulting and professional services is highly desirable.

Itoc Description

This is an exciting and challenging career opportunity to join the growing Sydney-based Data Team of a leading cloud solution provider where you will be given support to reach your long term career goals. You will be part of a team of cloud experts and will work in an environment of continuous improvement and learning delivering innovative cloud solutions across SaaS, online business and enterprise business.

On offer is a chance to join a team with a great working environment, in an organisation that values its employees and sees the value in ensuring they are engaged. Our team are clearly passionate about what they do, that's why we won the following awards:

Customer Obsession Partner of the Year 2015: ANZ Region
Customer Obsession Leadership Partner 2015: re:Invent

As an employer of choice Itoc offers competitive remuneration, training and development programs and a great working environment. We value a healthy work life balance.

The Perks

MacBook or Dell
Continuous internal learning that will provide training and career development opportunities
Working with a collaborative, social team and leveling-up your skills faster than you will anywhere else.
Quarterly social events

Itoc

Culture and smarts are important to us. Bring your secret sauce. This is no ordinary environment, you will work along some of the Cloud’s best. All engineers at Itoc must gain at least five AWS certifications. We work hard but we have fun.

Please note you must have full working rights in Australia and be available on-shore for face to face interviews.

No recruiters please.",4.0,"Itoc
4.0",Sydney,-1,1 to 50 Employees,2013,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Date: 01-Oct-2020

Location:
Melbourne, VIC, AU

Department:Description:
Technology discounts - from Apple HP Lenovo to Windows
Flexible work arrangements - work in a way that suits you best
Salary packaging - to suit your personal and financial circumstances

Do you want to work for one of the fastest growing data teams in Australia? Do you want to work on multiple data platforms and provide new solution offerings by leveraging cloud and big data technologies?

About the team

Big data information and analytics. Three words that spark apprehension in most businesses. But our team of experts are constantly curious and excited about combining our wonderful array of technological expertise to transform data into our clients most valuable assets making their work smarter. Our data consultants are supported with resources training and tools they need to excel at their work but also the freedom and power to create their own paths forward to make a difference.

As a Senior Consultant in Big Data you will work closely with the team and stakeholders to build and deliver a Cloud based vision for a next generation Big Data analytics platform with strong focus on data quality data security and deliver the systems that process huge volumes of data.

What will you typical day look like?

You will play a pivotal role in - Designing and producing high performing and stable applications to perform complex processing of massive volumes of data in a new cloud based architecture; Building real-time data processing applications which are integrated with business systems to enable value from analytic models to drive rapid decision making; Contributing to system architecture design for a data platform (including cloud-based structures both on and off premises data warehouse components and data lakes); this could cover a range of technologies various countries/locations and lines of business; Support data strategy or technology strategy definition programs including technology stack definition and target operating model requirements

Enough about us lets talk about you:
You are someone with:
Use of traditional data analytics tools and techniques (e.g. MSSQL Oracle MySQL) and ETL software (e.g. SSIS Informatica CloverETL)
Working in large scale cloud data solutions using platforms such as AWS or Azure or GCP will be a bonus.
Experience in scripting or programming (e.g. Python Java Scala C#)
Excellent verbal and written communication skills to adapt to technical and non-technical audiences.
Educated to degree level (or have equivalent experience)
Why Deloitte?

At Deloitte we create positively differentiated work experiences that enable our people to feel valued and achieve their full potential. We value difference and embrace people with diverse backgrounds and thinking styles. Knowing that people work best in different ways we are happy to discuss alternative arrangements if the working pattern you are looking for is not specifically indicated.",3.8,"Deloitte
3.8",Melbourne,-1,10000+ Employees,1850,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Engineer,-1,"Opportunity to grow the team
Period of growth
Intuitive app
S2M are working with a FinTech who have created a unique financial product to help thousands of people better manage their finance, and is currently scaling the company to the next level!

They are looking for a Data Engineer to join, and looking for someone who wants to be hands on, with opportunity to grow the team in future.

Role:

Looking for people with strong AWS experience. You will need passion for data and a cloud, through which you will help a rapidly scaling Australian FinTech establish their data infrastructure from the ground up.
5+ years’ experience as a data engineer within the data and analytics domain
A python 3.X aficionado who is very comfortable creating and orchestrating AWS data pipelines with nothing but code
Strong project delivery toolset experience in open source data integration tools
Experience with processing large volumes of complex data including visualisation and insights generation
Ability to define and develop data integration patterns and pipelines
Ability to assess complexity of data (volume, structure, relationship etc.)
Hands on experience working with different databases (RDBMS, NoSQL, Blob storage etc)
Hands on technical expertise setting up DevOps automation
Hands on experience working technologies/platform e.g. AWS, Dockers, Containers
Experience building data profiling and data cleansing frameworks
Technical reconciliation and reporting
Knowledge and experience in end-to-end project delivery, either traditional SDLC or agile delivery methodologies (or hybrid approaches)
Exceptional communication, documentation and presentation skills
If this sounds like you, get in touch today - kate.gabb@s2m.com.au
3167410agsdf",3.1,"S2M
3.1",Sydney,-1,Unknown,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Analysts,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is seeking experienced and qualified Data Analysts to join our IT team based in our corporate office in Birtinya (Sunshine Coast) or at our meat processing facility in Kilcoy.
Key Responsibilities:
A mixture of data analysis and commercial skills to source, blend and analyse data to gain insight and answer key commercial questions
Working with strategic leaders to define and model Key Performance Indicators, and assist in building forecasting models
Working closely with data engineers and BI developers to specify data pipelines and report visualisation
Drive the creation and implementation of data quality business rule including data definition, governance and quality assurance
About You:
To succeed in this role, you’ll need to bring the following experience and skills:
Proven ability to derive insight and knowledge from data using commercial expertise is a strong requirement
Strong SQL and Excel skills are essential, along with strong data analysis and commercial insights
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Effective people communicator - engage with stakeholders on reporting needs, interpret requirements into visual solutions and train/deliver the outputs to the stakeholders getting signoff of acceptance
Bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking

How to Apply:
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kilcoy,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Network Data Engineer,-1,"Min 6+ years of experience in the relevant technologies
Australian Driving License for visiting remote locations / Data Centre for day to day technical work.
Managing Network devices (switches, routers, firewalls, load balancer, and wireless technology)
Performing MACD activities for all network devices.
Supporting BAU operation activities.
Proficient in performing in-depth details of technical troubleshooting, cause and provide recommendation to the client for incidents causing extended network outage to client’s critical locations.
Provide exceptional network services in terms of network support, break-fix, design and consulting, new projects, implementation.
Configure, administer, and document firewall infrastructure.
Manage the firewall deployment, rules migrations, and firewall administration.
Supporting Cloud Migration Activities from traditional to AWS/Azure.
Setting up VPN tunnel with Cloud and 3rd Party network devices.
Integrating and upgrading existing ISP bandwidth with support from ISP Vendor.
Setting up VPN profiles for Users.
Installing hot fix and patches to mitigate the security devices from attacks and bugs.
Reviewing and fine tuning the firewall rules and NAT rules.
Documentation and change control.
Mentoring, Motivating and Guiding support teams
Technical skills:
o LAN
o Wireless
o WAN
o MPLS
o Routing protocols (OSPF,BGP)
o DMVPN
o Azure cloud Networking
o Network Security
Fortigate Manager / Analyzer / Firewall
Cisco ASA
Firepower FTD
Cisco Any connect
Site to Site VPN
F5 Load Balancing and Scripting iRule
Job Types: Full-time, Contract
Schedule:
8 hour shift
Experience:
Scripting: 5 years (Required)
Data Network: 5 years (Required)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Required)",3.6,"Total IT Global
3.6",Sydney,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Engineer - Processing & Analysis,-1,"Job Description:
Design,build and maintain the ingestion system to support various types of data(e.g. User behavior, RDS, NoSQL db and others) to be ingested to the data warehouse more timely and accurately
Translate data requirements into scalable technical data service with low latency and high concurrency
Design,build and maintain the batch or real time data pipeline in production using Hadoop big data technology
Analyze and improve efficiency, scalability, and stability of the system
Define and manage SLA,Data quality for all data sets in allocated areas of ownership
Requirements:
Minimum B.S. degree in Computer Science or a related technical field
2+ years of working experience in programming languages,such as Java,Scala,Python
Familiar with Hadoop, Spark and Flink data processing, experience of TB data processing experience is a plus
Familiar designing and operating of a robust distributed system is a plus
Understand data mining or machine learning
Excited to work intimately with data
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"SYNOPSIS:
Lead Data Engineer
Applications close Sunday 8 November 2020
Ongoing
Contact name: Shyni Sasikala
Phone: (02) 6249 9048
Email: Shyni.Sasikala@ga.gov.au

The Data Policy and Informatics section within the Digital Science and Information branch creates, implements, and promotes policies, platforms and tools that improve and support the quality, discoverability, accessibility, and general usability of Geoscience Australia’s science data products. The section consults with internal and external research, government and industry partners to establish collaborative data frameworks, architectures and models within Geoscience Australia (GA) and across broader national and international communities of practice. The section innovates, builds and maintains tools, systems, processes and governance that enable digital data management, cataloguing and open data delivery.
GA makes accessible a wide range of geoscientific and spatial data to a wide variety of stakeholders in multiple formats, and in recent years GA's data volumes have grown exponentially. GA is focussed on making its data and metadata assets accessible so that they can be used in machine to machine interactions for data analytics and other applications in environments that range from High Performance Computing (HPC), through high-end cloud servers, to mobile devices.
We currently have two opportunities for Lead Data Engineers in the Informatics team. The Lead Data Engineer is responsible for innovating and exploring new technologies that will advance GA’s science goals and maximise the uptake and use of GA’s science data. The Lead Data Engineer reports to the team’s Assistant Director but also works closely with other developers, data scientists and engineers within the Digital Science and Innovation (DiSI) branch, as well as diverse stakeholders both within and external to GA.",3.9,"Geoscience Australia
3.9",Canberra,-1,501 to 1000 Employees,2001,Government,Federal Agencies,Government,$100 to $500 million (USD),-1
Data Engineer,-1,"The Seven Network is part of Seven West Media, one of Australia’s most prominent media companies, with a market leading presence in content across broadcast television, online and in print. Comprising some of Australia’s most renowned media brands, SWM includes not just Seven Network and its affiliate channels 7two, 7mate, 7flix and BVOD offering 7plus, but also 7NEWS.com.au, The West Australian, The Sunday Times and more.
At Seven we are here to bring all Australians closer to the moments that move us - we’re first on the scene, with our finger on the pulse, on demand, in the moment. Together, we’re responsible for creating and sustaining authentic Australian engagement.
A new and exciting opportunity has opened for a Data Engineer to join the Audience Intelligence team. Based in Sydney and reporting to the Head of Data Enablement, you’ll be responsible for:
Implementation of end to end data solutions to support Data Strategy for the SWM group.
Work closely with the Data Solution Designers to develop and maintain scalable data pipelines and build out new file and API based integrations to address requirements from the various business stakeholders.
Collaborates with engineering, analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organisation.
Work on Data Preparation for analytics and data scientist team members and assist them from an engineering perspective in building and optimising the models including building the automation of the end to end workflows
Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.
Perform data analysis required to troubleshoot data related issues and assist in the resolution of production data issues.
Work effectively with vendors for successful delivery of projects and acceptance of the solution
Work on Delivery projects using Agile Software Development methodologies
We are looking for someone who has:
Bachelor's degree in computer science, computer engineering or other technical discipline is essential
Proven experience working as a digital analytics specialist
Extensive experience with digital analytics implementation (e.g. Google Analytics, Snowplow, Adobe Analytics) and BI processes and visualisation platforms
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience in ETL and building and optimizing ‘big data’ pipelines and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Experience with big data tools: Hadoop, Spark, etc., AWS cloud services: EC2, S3, Lambda and familiar with version control systems: Git
Strong coding skills with knowledge of Unix/Linux and scripting languages such as Unix Shell scripting, Python desirable
Experience supporting and working with cross-functional teams in a fast-paced environment.
Ability to multi-task and problem solve with changing demands and priorities
Ability to work under pressure to meet deadlines and detail oriented
Your success is our success: we will provide you with opportunities for you to keep learning and growing, enabling you to challenge and develop yourself. In return, we offer a benefits program that has something in it for everyone.
Seven West Media is an equal opportunity employer and we are committed to creating a diverse and inclusive workplace.
Recruitment Agencies: Seven West Media does not accept any unsolicited agency resumes and will not be responsible for any fees related to unsolicited resumes.
Advertised: 19 Oct 2020 12:00 AM AUS Eastern Daylight Time
Applications close:

Back to search results",2.5,"Seven West Media
2.5",Sydney,-1,5001 to 10000 Employees,1956,Company - Public,TV Broadcast & Cable Networks,Media,Unknown / Non-Applicable,-1
BICON Rules Engineer,-1,"APS 5 - $73,299 - $80,410 per annum plus superannuation
Biosecurity Plant Division
Canberra, ACT
Play an active role in managing biosecurity risk to Australia
Work in a motivated and professional team with a wide range of skills and backgrounds
Full training provided

Who we are
The BICON Content Development Team maintains and improves the Biosecurity Import CONditions database (BICON) content to allow external clients to understand and comply with their biosecurity obligations and internal clients to effectively manage biosecurity risk and regulate imports. We work collaboratively with internal clients to comprehend and implement their BICON content requirements and optimise the use of BICON to publish clear import requirements and onshore management support procedures to effectively manage biosecurity risk.

The Jobs
Key duties of these positions include:

working with business content (import and permit conditions) and import programs to understand and construct decision tree structures in the BICON database, in accordance with system design and authoring conventions
executing changes to import and permit conditions in alignment with service standards while complying with system rules and authoring conventions
providing technical advice through various formats on the most appropriate means of authoring BICON content to achieve import program and stakeholder objectives
using workflow management tools to maintain detailed records of changes to import conditions and key decisions
performing administrative tasks including system reporting, data analysis and scoping tasks for the BICON content change work program
contributing to the development and maintenance of instructional material, authoring conventions and courseware
clearly documenting and reporting system issues
developing and maintaining effective working relationships with internal and external stakeholders.

What we are looking for
Knowledge and experience
Experience working with complex IT systems.
Experience working collaboratively and as part of a team.
Knowledge of the role of biosecurity is preferred but not essential.

For additional information, please read the Job Description below.
Candidate Information Package docx Opens in new window",3.9,"Department of Agriculture & Water Resources
3.9",Australia,-1,5001 to 10000 Employees,-1,Government,Federal Agencies,Government,$500 million to $1 billion (USD),-1
Cloud Data Engineer,-1,"Job no: 509605
Work type: Permanent Full Time
Location: Melbourne, Canberra, Sydney
Do you embrace digital disruption?
Do you love solving complex problems, designing sophisticated solutions and building innovative technology?
Do you believe in creating powerful actionable insights from Data and Analytics?
Do you want to work in a diverse and flexible working environment?
KPMG is one of the most trusted and respected global professional services firms. Through depth of expertise, clarity of insight and strength of purpose we help our clients solve complex challenges, steer change, strengthen, transition and grow. We are a team based practice and this extends to our clients whom we work and collaborate with, in solving complex problems. Together, we design, innovate and implement, providing enduring advice that support our clients and the services they deliver. Our clients vary in size and come from a diverse range of sectors – all sharing in a common goal: to embrace change and deliver services that make Australia a better place. We are looking for talented individuals who would like to join us on the journey.
KPMG’s Digital Delta Team
We re-imagine and re-invent organisations to become world class digital enterprises using advanced technologies, data and human insights. We help organisations to embrace Digital Strategy, Artificial Intelligence (AI) & Cognitive, the Internet of Things (IoT), Data, Analytics & Modelling, Mobile App & Web, and User Experience (UX) & User Interface (UI) and more.
We work with clients to:
Formulate strategies that re-imagine organisations
Harness innovation from the 4th industrial revolution
Actioning insights from trusted data to consistently and quickly make clear decisions
Build adaptive organisations
Thrive as a connected enterprise – front, middle and back office
This is how you’ll contribute:
We are looking for ambitious Data Engineers who are passionate about helping clients define bold ambitions and deliver on them. Joining our team will take you on a journey of personal and technical growth and provide the opportunity to inspire confidence and empower change.
As a Data Engineer you are the designer, builder and manager of the information or ""big data"" infrastructure, preparing data for analytical or operational use. You will design, construct, test and maintain a data pipeline to pull together information from different source systems; integrating, consolidating and cleansing data; and structure it for use in individual analytics applications.
The KPMG Difference
Our people are focused on creating a diverse and dynamic environment that embraces and values differences. We value the variety of unique experiences, qualities and characteristics our people possess and we share and learn from each other.
We are proud to be consistently recognised as an employer of choice for women, and for our achievements in LGBT+ workplace inclusion.
Our commitment to ‘Flexibility’ allows our people to manage the changing demands of work, personal or family life. Explore the links below to hear our people share their experience @ KPMG:
Flexibility empowers wellbeing
Flexibility enables contribution to the community
Flexibility inspires technology & innovation
Flexibility supports family

Make KPMG the clear choice for your career and be Extraordinary!

Advertised: 09 Sep 2020 AUS Eastern Standard Time
Applications close:",3.8,"KPMG
3.8",Sydney,-1,10000+ Employees,1987,Subsidiary or Business Segment,Accounting,Accounting & Legal,$2 to $5 billion (USD),-1
Computer Network and Systems Engineer,-1,"Duties Include but are not limited to:
Tasks Include:
analysing, developing, interpreting and evaluating complex system design and architecture specifications, data models and diagrams in the development, configuration and integration of computer systems
researching, analysing, evaluating and monitoring network infrastructure to ensure networks are configured to operate at optimal performance
assessing and recommending improvements to network operations and integrated hardware, software, communications and operating systems
providing specialist skills in supporting and troubleshooting network problems and emergencies
installing, configuring, testing, maintaining and administering new and upgraded networks, software database applications, servers and workstations
providing network programming in support of specific business needs and requirements
preparing and maintaining procedures and documentation for network inventory, and recording diagnosis and resolution of network faults, enhancements and modifications to networks, and maintenance instructions
monitoring network traffic, and activity, capacity and usage to ensure continued integrity and optimal network performance
Skills and Experience Required:
Must have experience working in a Managed Service environment
Demonstrated experience in IT Networks and Data Centres
Understanding of systems and architectures to meet client needs
Experience in Help Desk including break / fix
Effective and timely documentation
Effective Task Management Skills
Be solution and outcome focused and willing to learn new technologies
Excellent communication skills with staff, clients and partners
Time management, ability to prioritise and deliver to schedule
Experience with N-Able and Connectwise desired
Open Cabling license desired
Job Types: Full-time, Permanent
Salary: $30.00 per hour
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,Trans-plant training,Canberra,-1,-1,-1,-1,-1,-1,-1,-1
Software Engineer (Data),-1,"If you are looking for an opportunity to make a real impact with smart people who are genuinely doing things differently then you've come to the right place! We're growing our data engineering capabilities and are looking for awesome data engineers to join our team.
With our diverse range of clients and projects, no day will look the same - but here's a great snapshot of what you'll be doing:
Work with some of the best Data Scientists and Engineers to deliver production-grade AI and Machine Learning systems as we deliver client projects from inception to production.
Consulting with our clients and working with them to build modern data systems using the 'best of' technologies and principles.
Advising clients on data strategy, architecture and technology.
Applying best software engineering practices in coding, monitoring and alerting, using CI/CD, TDD and cloud architectures.
Working over a wide range of big data tools and environments: not limited to; Apache Kafka, Spark, Python, Scala, Hive, Airflow, AWS EMR & Glue, GCP Dataproc & Dataflow, BigQuery, Snowflake, Redshift.
Who are we?
Glad you asked! We are Eliiza. Data science. Engineered for scale.
We are a passionate team of data scientists and engineers who apply data science and machine learning to solve real-world problems. Our mission is to create a bright future for Australian businesses and society in a world increasingly influenced by intelligent technologies.
We've created a culture that values diversity where people can truly be themselves! We care a lot about growing the Australian AI community in a positive direction, and we're doing several things to try and achieve that:
We provide opportunities for underrepresented groups to work in AI through our associate and intern programmes
We organise and participate in a range of community events, reading groups and meetups
We produce the AI Australia podcast
We blog about topics we care about
We stream brown bag sessions to the broader community
We're also part of Mantel Group's 'house of brands' which means it's not just the Eliiza team you'll work with, learn from and see at social events - there's another 230 of us across DigIO, Kasna & CMD Solutions!
So you're ready for something new?
We're keen to know more about you! Our team is made up of a range of people, with different experience across a huge range of data driven skill sets.
We'd love to hear from you if you have experience with:
one (or more) core language(s), ideally Scala, Python or Java
one (or more) cloud platforms, AWS, GCP, Azure
ETL/ELT concepts and technologies e.g. Data partitioning, Hive, Spark
streaming data concepts and technologies, ideally Kafka (Kinesis, Beam or Pubsub will do)
We'd be over the moon if you:
Experience with distributed/columnar databases (e.g. Snowflake, Big query, Redshift).
Experience with any of a variety of databases e.g. RDMS, NoSql, Columar, Distributed, Time series, Graph.
Knowledge of job orchestration and scheduling. Any experience with Airflow, Luigi or Oozie.
Experience with containers and container orchestration (Docker, Docker Compose or Kubernetes).
However, we value a diversity of skill-sets, and don't necessarily require that you're skilled with all of the above. If you feel you don't fit all the experience/skills listed above we still encourage you to apply or get in touch.
What's on offer if you join us?
We make sure you're always one step ahead by investing your learning and development, every year. We build our own training where it doesn't exist yet.
We hire smart people and get out of their way. By focusing on our five principles and not getting caught up in red tape, we trust you to get the job done.
You'll get all the tools you need - a new iPhone or Google phone, a new Macbook Pro or Dell, and a lot of branded swag!
But hold on, you mentioned a house of brands?
We certainly did! Mantel Group is an Australian-owned, 'house of brands' company with four technology businesses (Eliiza being one of them!) across Melbourne and Sydney. We're building a group of companies with open borders so we can support you to take on new skills without leaving an awesome team - we understand you won't have one job for life!
We may only be just two years old but Mantel Group has already been recognised #9 in the 2020 Best Places to Work in Australia and #4 in the AFR's 2020 fastest growing new companies.
Keen to chat?
Click ""Apply"" to share your details with our talent team, and we'll be in touch.
In the meantime, check out 'how we hire' to find out what's in store if you're successful and get to know us better by visiting our website and following Eliiza on LinkedIn.",-1,Eliiza,Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Shopee SG - Data Infrastructure Engineer,-1,"Job Description:
Design and grow the Shopee data platform to support a variety of big data applications using open-source technologies including Kafka, Hadoop, Presto, HBase, Spark, Hive, Druid, and our own creations. Some examples include a real-time data streaming platform, a unified query platform, a cluster management system, and a machine learning platform
Dig into the source code of some open-source big data system to get the whole control and familiar with the details, configurations, designs and source code. Develop and maintain the internal release of big data systems and components as the business requirements.
Keep close and overall monitoring for all the deployments of the systems, maintain the system’s stability, improve the performance, discover the performance bottlenecks, tracking and troubleshooting, cost optimisation.
Requirements:
B. Sci. / Ms / PhD in Computer Science or a related technical field
Familiar with at least one of these languages: Java, Scala, Python, Bash under Linux / Unix. Scala is a plus
Familiar with the use and compute logical of SQL
Knowledge about the Big Data Infrastructure system technology like Distributed File System, Distributed Computing, Distributed Database will be a plus
Hands-on experiences Hadoop, Spark, Kafka, and/or Presto will be a plus
Love to use and develop open-source technologies
Passionate, self-motivated, and takes ownership",3.0,"TechSkills Accelerator
3.0",Australia,-1,501 to 1000 Employees,-1,Company - Private,Municipal Governments,Government,Unknown / Non-Applicable,-1
Lead Data Engineer,-1,"Work on an award-winning, international technology!
Endless career opportunities
An innovative, friendly team of 300+
This role will be focused on the development of our existing ClaimLogik line of products as well as working on our new cloud-first, modern suite of applications.

Intelligent Thought, our technology business is scaling and shipping our software globally. Already profitable, part of a much larger group business, with investors such as Macquarie Capital and Envest – we are all set to deliver textbook disruption to the Insurance Industry. The growth of the platform, of our customer base, and the increasing industry demand have led to the need for this role to help the team scale.

Our Philosophy
Give each employee a sense of purpose and an environment for them to connect the importance of their role to delivering a service that matters to our customers.
Challenge the ‘why’ of traditional claims processes.
Keep it simple – do only what brings value and what matters to the customer
Enable employee decisions, empower our people
Responsibilities:
Create, extend and maintain ETL pipelines to form our data lake, data warehouse and analytics platform (currently using the Microsoft Azure set of tools and service)
Help define the optimal data pipeline architecture
Influence the tool selection, platform selection, data architecture and strategy which will transform the business to be truly data-driven
Understand, analyse and size user requirements
Work with different parts of the business to provide them with the insights they need to deliver the best results
Skills & experience:
Degree or qualification in computer science or related
Advanced knowledge of relational database, including query authoring and query optimisation (MS SQL Server and PostgreSQL).
Experience building and optimising ETL pipelines
Experience designing complex data models
Experience working with cloud platforms (Azure or AWS)
Efficient time management and organisational skills
High attention to detail and accuracy
Effective communication skills to build strong working relationships; both written and verbal
Proactive and results-driven
Why Claim Central?
Claim Central Consolidated is a global insurance industry leader across, claims management, insurance technology and data and analytics. Currently operating in the United States, Australia, South Africa, Italy and New Zealand, we have pioneered digitally connected claims management services across the globe. Claim Central is a disruptor and thought leader in the industry and we were recognised as the Australian Financial Review’s 8th Most Innovative Company in Australia in 2016. This business is in a period of unprecedented growth, transitioning our technology and services into multiple geographies at a rapid pace. Our unique culture is based on teamwork, collaboration, trust, respect and performance. We also offer many benefits apart from our exceptional team culture; including flexible work arrangements, and continued professional development.

Be a part of this journey in a career-defining role.",-1,Claim Central,Matraville,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer - AI/ML,-1,"Our client provides services to a major industry across the country. The business is still early in it's days of technology development and the environment is greenfields in nature (no pun intended), effectively working like a start-up.

Their data and analytics team have worked and built leading and bleeding-edge technologies in this space and what they have created so far may be game-changing. From a machine learning perspective, the progress they have made to the business has already seen proven success in changing the future of an industry that will have positive consequences for all those involved.

You will have previously worked in a technical capacity in the data and analytics space and have experience working with an organisation where machine learning has been implemented, not just a concept that the business talks about having or the technology team would love to have. The commercial experience you will have had in the ML field will be proven examples of where you have affected the way a business or industry used to perform, to the changes that have come about from this.

Technically, you will have extensive experience in the Microsoft space - Power BI, Azure etc and you will have previously mentored and coached junior members of the teams you have been part of.

This is a rare opportunity in Brisbane where the business has truly embraced and funded projects across the ML space and would be a great chance for those in the Data Development/Data Engineering field, who are looking to move into a Data Scientist role in the future.

Please send your application through if you would like to know more.",4.0,"Emanate Technology
4.0",Brisbane,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Solution designer/ ETL Engineer & Data Modeller,-1,"We are looking for a Qualified and Experienced Solution Designer to join our client for a period of 6 months with a view to extend.
You will work closely with team members and your contribution will range across gathering and analyzing information, developing and documenting improved processes and work instructions and experienced DWH Lead with skills in requirement analysis, solution designing, developing, testing and supporting ETL solutions.
A hands-on solution designer, data modeler and ETL developer for Data Warehousing and ETL application transformation projects using Informatica PowerCenter.
Knowledge on AWS, S3, Redshift, Informatica BDM, and related technologies.
Experience working with IPython, PySparks, AuCuMo, Airflow, Jenkins, Github, Athena, JIRA, Rally, Spectrum, Glue, Flyway.
Good exposure on Oracle PL/SQL, aware of DBA activities, writing and performance tuning of complex SQL queries.
Contract length: 6 months
Job Types: Full-time, Contract
Salary: $650.00 – $800.00 per day
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)",-1,nducive,Melbourne,-1,-1,-1,-1,-1,-1,-1,-1
"Data Engineer, Wollongong NSW or Mount Waverley VIC",-1,"Company Description
BlueScope is a technically advanced supplier of steel and steel products in Australia. We are an inclusive organisation and every day we showcase our technology and expertise throughout the world.

Job Description
We are looking for two Data Engineers to join our IT team, based in Wollongong NSW or Mount Waverley VIC. Use your experience in analytics to unlock business value, enabling use of big data for insights and decision-making.
Reporting to the Data Product Owner for our Australian Steel Products (ASP) business, this position will support strategic goals related to data. This will see you:
Gather business and technical requirements with the view to deliver outcomes;
Develop and implement end-to-end data collection, consolidation, modelling and visualisation solutions;
Document metadata in a dictionary and catalogue;
Ensure consumers of such information understand its accuracy, timeliness, quality and sensitivity, so that it is used appropriately; and
Identify opportunities to enhance analytics.
What are the benefits?
Work in a supportive and collaborative team environment whilst we embark on a journey to transform the way our business uses data!
Our systems landscape is broad and diverse. You will be encouraged to think creatively to develop data solutions which solve real business problems.
Working in this role you will enjoy:
the chance to learn more about data science;
salaried remuneration with attractive superannuation options;
the opportunity to participate in a performance incentive scheme; and
access to further development and career opportunities with BlueScope.
Who are we looking for?
We welcome applications from professionals with experience in data analytics and/or programming. Supported by your knowledge of project delivery methods (e.g. Agile), you will demonstrate:
experience with data mining, wrangling, mapping and visualisation techniques (e.g. Azure Data Factory, Databricks and/or DevOps etc.);
well-developed ability in gathering business and technical requirements;
skills in developing and implementing collection, consolidation, modelling and visualisation solutions; and
a passion for sharing your knowledge and desire for ongoing professional development.

Qualifications

null

Additional Information
We're proud to have been named an Inclusive Employer for 2019–2020 by the Diversity Council of Australia. We believe that our people are our strength. Having a diverse and inclusive workplace enables us to improve our capability and ensure continued, sustainable success.
We know that workplace flexibility can mean something different to everyone. Under our B-Flex initiative all of our roles have some degree of flexibility. We encourage you to discuss your needs with us.
Applications close Sunday 25th October 2020.",3.3,"BlueScope
3.3",Wollongong,-1,201 to 500 Employees,-1,Company - Private,Construction,"Construction, Repair & Maintenance",$100 to $500 million (USD),-1
ETL Data Engineer,-1,"ETL Data Engineer

Join a team that’s changing how Australia lives, works, plays and grows
We want you to be the best version of you

Work with innovative teams and explore new technologies to help solve real-world problems.

A typical day as a Data Engineer

ETL / Big Data Engineering professionals will be responsible for guiding the full lifecycle of a Data solution, including:
Working in highly client-facing roles to contribute throughout the end-to-end delivery lifecycle of complex and large-scale digital solutions
Use case and business case development
Support existing and new applications utilizing in-depth technical and data knowledge. Troubleshooting complex issues and providing advisory services to improve the client’s data landscape
Help to streamline and simplify the clients’ complex data landscape by integrating different applications and data architectures
Implementation from requirements analysis, platform selection, digital architecture design, application design and development, testing, and deployment
Interstate travel may be required

Basic qualifications:
Bachelor’s degree
Experience across systems integration, information management, data management and architecture, and business analytics
Experience with being in a team focusing on large-scale, multi-release information centric projects
Experience with waterfall and agile delivery and run / application support functions
Part of a team working on End to end implementation of at least 1 big data project

Preferred Skills:
Hand on experience in Data warehousing using ETL tools such as DataStage, Autosys and TeraData
Hands on experience in ETL job development with multiple stages like sequential file, Transformer, Lookup, join, sort and Database stages.
Strong hand on skills in design, development and implementation of various data remediation, Data migration, data integration techniques.
Strong hand on data modelling experience.
Strong hands on experience in database performance tuning including complex query optimizations and physical database tuning using Teradata.
Understanding of architectural designs and strategy related to data migration, data cleansing, data quality and data consolidation.
Proven data analysis, requirement gathering and problem-solving skills
Exposure to Unix environment and shell scripting.
Experience in Banking and Financial services industry
Desirable: Knowledge of cloud computing infrastructure (e.g. Amazon Web Services EC2, Google Cloud, Microsoft Azure)
About Accenture

Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. We combine unmatched experience and specialized capabilities across more than 40 industries — powered by the world’s largest network of Advanced Technology and Intelligent Operations centers. With 513,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises. Visit us at www.accenture.com.

Accenture is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, marital, domestic or civil partnership status, sexual orientation, gender identity, or any other basis as protected by applicable law.

Vera Goga is the Recruiter managing this role. As the team experience high volumes of applications, we appreciate your patience to allow for a fair and timely process.",3.9,"Accenture
3.9",Sydney,-1,10000+ Employees,1989,Company - Public,Consulting,Business Services,$10+ billion (USD),-1
Student Engineer,-1,"The candidate will have the ability to:
Undertake onsite inspection to collect asset condition data based on the relevant engineering standards and technical guidelines;
Undertake desktop analysis to evaluate the condition and performance of the assets;
Provide the appropriate information, advice, engineering input and support services for the sustainable management of Council’s stormwater and transport networks.
Qualifications:
The successful candidate will be enrolled in a Bachelor of Engineering with a minimum of two years completed.
Position Number: 100678
Position Hours: Fixed term (3 months), hours will be negotiated with the successful candidate, maximum of 75 hours per fortnight.
Salary: Schedule A, Salary Point 4.0. $28.64 per hour ($55,853.45 per annum, pro-rata) in accordance with Glenorchy City Council’s Enterprise Agreement 2016
Please note that all successful applicants will be required to provide a current National Police Check prior to commencement of employment.
For further information on this position, contact Patrick Marshall, Senior Civil Engineer on (03) 6216 6800.
How to apply: Applications for this position must be lodged on this submission site or on the Glenorchy City Council website www.gcc.tas.gov.au - Careers page.
To be considered for this role, all applicants must address the key selection criteria in the and provide a current resume. A copy of the position description can be found by clicking the below hyperlink or on the Glenorchy City Council website.
Applications close at 8pm on Sunday, 1st November 2020
- Student Engineer",4.0,"Glenorchy City Council
4.0",Glenorchy,-1,501 to 1000 Employees,-1,Government,-1,-1,Less than $1 million (USD),-1
Data Engineer involving DevOps,-1,"Data Engineer involving DevOps
Axiom Technologies is an Australia based entity with the history of providing Managed IT solutions to medium to large scale enterprises globally. Please visit our website for more information about what we do at www.axiomtechnologies.com
Axiom Technologies is an Equal Opportunity Employer and encourage applicants from all backgrounds and gender to apply, including, Aboriginal and Torres Strait Islander candidates
Job Requirements:
8+ years IT experience, with at least 5+ years of “Data Engineer/Deveoper” focused titles/roles,
Data Tools: Hands on experience with Apache Beam.
Testing: Hands on experience with automated testing activities/outcomes
DevOps: Experience with the processes involving Microservices facilities for artifacts developed
Platform/OS: Mid-range/Unix
Languages: Unix (Shell) Scripting/commands, SQL, Python
File formats: Text, CSV, Parquet, JSON, XML
Scheduling: Jenkins, Airflow
Auto Scripting: Designing/creation of scripts for repetitive activity. E.g. Unix scripting/SQL
Big data: Exposure to Data Lake Concepts, Hive (Schema), HDFS
Source Control tools: GIT
Delivery Models: Agile, Scrum
Ingestion Design: Create/assess Source/Target data mapping designs
Frameworks: Development and delivery frameworks
Activity Reporting/Repository: Jira, Confluence.
Quality: Accuracy and attention to detail
Industry: Financial Services/Banking
Solutions: Define solutions from High level to detail design to address automating ingestion activity. Facilitate/confirm requirements from product owners, business team members and technical associates,
Process Automation: Automating processes in file management, testing data in files, analysis and design, configuration management.
Script Automation: Ability to design/create scripts to automate/improve data copy/migration/ETL for any repetitive activity.
Languages: Java, Python
Scheduling: Control-M
Databases: Relational. E.g. POSTGRESS, Oracle – as a ETL developer
File Formats: Mainframe – experience with referencing its data formats/copybooks
Big data: Experience referencing/using Hive (Schema) to access data in HDFS
Metadata management tools: MDM, EDC and Axon
Performance: Assess, recommend, improve mappings, SQL queries, Batch feeds
Automation Tools: Other tools that may add value to an automation program and generally support development. E.g. API, REST, JDBC, Webservices, Message Queues/Load balancer,
Cloud: Experience with processing of data files to be ingested/stored in the Cloud, preferably with AWS.
Prod Support: Experience in a production support role performing root cause / impact analysis – under time constraints
Experience in a similar role
8+ Years
What next?
If you are looking for that next challenge in your career and wish to apply for this role, please forward your resume to careers.au@axiomtechnologies.com",2.0,"Axiom Technologies
2.0",Melbourne,-1,1 to 50 Employees,-1,Company - Private,Industrial Manufacturing,Manufacturing,Less than $1 million (USD),-1
Data Engineer,-1,"About the Role
We are on an exciting digital journey so it’s a great time to join ME! We are seeking a Junior Data Engineer who enjoys rolling up their sleeves, learning and growing. As part of our Enterprise Data Team, you will ensure fit for purpose data warehouse solutions are built for use across the bank and by utilising best practise ETL standards, whilst ensuring the data is trusted by our BI developers and key business consumers. Oh, and you’ll get to work on Microsoft technology stack too!
You will be involved with investigating data issues, keeping data feeds flowing and collaborating with different projects across the bank to deliver quality data solutions. How important does that sound? What’s even more important is this role contributes directly to our overall business strategy through the provision of data to enable analytics & reporting, as well as supporting business and decision system processes.

About You
You’re naturally a highly motivated and energetic person who thrives in a dynamic, ever-changing collaborative team environment. Ideally you have previous experience as an ETL developer, Data Engineer or a BI developer, and if you have a degree in computer science or similar it would really put you ahead of the rest.

With your knowledge of SQL coding, data modelling, understanding of data warehouse concepts, plus experience of working on complex ETL solutions, you’re ready to expand your horizons and launch your career into the world of IT at ME.

About ME
We’re not like other banks.
ME was created by the industry super funds to be different from the pack – with a core purpose to help all Australians get ahead financially – no conditions, asterisks or exceptions. And we know that looking after customers starts with taking care of our people.
We believe everyone deserves the same opportunities in life, regardless of gender or identity, sexuality, ethnicity, religion or disability ‒ with internal affinity groups.
Perk ME up
Once you get your feet in the door at ME, we’ll put them both in your very own ME-branded Converse shoes. You’ll also get the following financial, health and fun perks when you join the team:
4U Extras portal (discounts and cashback on 100s of items including cinemas, shopping and gym memberships
10% Myki discount
Purchased Leave programme
Internal wellness programme (Mindfully ME)
Professional education through LinkedIn Learning
Novated Leasing
Professional membership reimbursements
Health checks
Financial education (To help you manage your money smarter)
LGBTIQ+ and Women at ME affinity groups

I want those Converse shoes (and the role)
Can’t see a closing date on the advert? That’s because we’re pretty efficient here at ME and we may start looking at applications sooner rather than later, so if this role sounds like your jam, be sure to apply by submitting your resume today.

Should an applicant be the preferred candidate, background checks (including police checks, reference checks, ASIC banned and disqualified persons and bankruptcy checks) will be completed prior to the candidate's employment being confirmed. The outcomes of the background checks do not automatically bar candidates; however will be assessed against the inherent requirements of the job.
Back Share
Apply Now",3.0,"ME Bank
3.0",Melbourne,-1,501 to 1000 Employees,-1,Company - Private,Banks & Credit Unions,Finance,$100 to $500 million (USD),-1
Software Engineer - Machine Learning/Data Science,-1,"Zendesk is looking for a Software Engineer - Machine Learning/Data Science for a full time position in our Melbourne office.
As part of our engineering team, you will work at a scale where the challenges start to get seriously interesting. Our global engineering team is widely dispersed over the world, with people across nearly every continent. You will get a chance to do cool things with a diverse bunch of people while working in the Melbourne office that is home to Zendesk’s first machine learning (ML) research team.
The Data Science Team, together with Data Engineering, have built Satisfaction Prediction, Answer Bot and Content Cues — products that use Machine Learning (ML) and Artificial Intelligence (AI) to help our customers work more efficiently.
What you get to do every day:
We’re currently looking for someone to join our team as we research, develop, and productionise Machine Learning and Deep Learning models. In addition to frequenting Melbourne’s finest purveyors of coffee, ramen, and bulgogi, you may find yourself:
Building machine learning models including neural networks in TensorFlow
Writing and deploying production-grade Python
Querying and constructing datasets in AWS Athena, Spark
Evaluating and responding to real-world model performance
Scaling your ML to millions of predictions per day
Presenting your work to a broader audience
Watching your algorithm help Zendesk’s end-users
What you'll bring to the role:
A strong foundation in a quantitative discipline (e.g. machine learning, statistics, bio/eco/etc-informatics, econometrics, etc) is critical for this position. While experience in deep learning and natural language processing would be beneficial, your best qualities are:
dedication to continuous learning
collaborative work attitude
strong communication skills
You should also be comfortable with at least one programming language, such as Python, R or Scala.
Application Deadline: 18/11/2020
Job Types: Full-time, Permanent
Salary: $85,000.00 – $110,000.00 per year
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Temporarily due to COVID-19",4.5,"Zendesk
4.5",Melbourne,-1,1001 to 5000 Employees,2007,Company - Public,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),-1
Software Engineer (Machine Learning),-1,"About the Role
AdelaideMRI is building a medical reporting tool. We require an engineer to work primarily on machine learning projects to improve reporting speed and report comprehensiveness.
You will perform data analysis of medical report datasets and image datasets to infer sentence recommendations, image classifications, or other actionable results for the doctors.
Skills and Experience
Background in machine learning or image processing
Qualifications in Computer Science, Software Development or Engineering or equivalent experience
Bonus points for Python
No prior medical knowledge is required.
This position offers flexible hours and work arrangements.
Job Type: Full-time
Experience:
Software Engineering: 1 year (Preferred)
Work Eligibility:
Permitted to work permanently with no restriction on hours (e.g. citizen, permanent resident) (Preferred)
Work Remotely:
Yes",-1,Adelaide MRI,Australia,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Hey there, we’re PEXA!

We started as an idea: to deliver a single, national e-Conveyancing solution. We collaborated with the industry to create a national electronic lodgement and settlement platform: PEXA. From our humble beginnings, we’ve now grown to more than 320 employees across 5 different states. We’re still expanding at a rapid rate and constantly challenging ourselves to create great experiences for our members as they transition to fully digital conveyancing.

Why become a PEXArian?

Great question! Being a PEXArian is so much more than just a job. We are passionate, motivated & unashamedly enthusiastic at PEXA - we love what we do and we’re proud to admit it! Creating brilliant member experiences wouldn’t be possible if we didn’t also strive to create an amazing employee experience. Alongside our members, our employees are at the heart of everything we do.
Here’s a snapshot of what your life at PEXA could look like:

Your growth:
We encourage you to hit your personal and professional Learning & Development goals with our tailored programs and tools.

Your wellness:
We care about your holistic well being - a fully stocked kitchen, four wellness days, a $250 wellness subsidy as well as lunch and learn sessions to support your financial well being.

Your work/life blend:
We know that work is just one aspect of your life, we want to help you create your ideal work/life blend, rather than squeezing in life around work.

Your family:
With a range of benefits aimed at supporting your family including access to a subsidised school holiday program, extended parental leave and flexi-time to support your return to work, superannuation payments for unpaid parental leave for primary carers and a childcare allowance for pre-primary aged children, when we say, ‘welcome to the family’, we really mean it!
The impact you'd drive:
The successful candidate will be responsible for developing, and maintaining infrastructure to support the delivery of new and existing products. They will also be contributing to establish the rules and frameworks for obtaining the required approvals for new products.
On day one we’d love you to have:
Experience with Python, Spark
Event streaming/sourcing with Kafka or AWS Kinesis
Experience with data structures, formats and data security best practices
AWS experience (e.g CloudFormation, S3, ECS, Lambda, SQS, IAM, KMS, DynamoDB, Glue, Athena)
Query construction and optimisation (e.g. SQL, Elasticsearch, Splunk, DynamoDB)
Git, version control practices, and continuous integration/delivery servers
PyUnit and unit testing frameworks
Production release cycles and maintenance
Collaborating with technical and non-technical teams
Even better:
Agile methodology/delivery
GraphQL
Modern frontend technology (e.g. ReactJS, TypeScript)
Machine learning frameworks and tools (e.g. TensorFlow, PyTorch)
OAuth 2, SAML 2, JWT
Data visualisation and exploration tools (e.g. Jupyter notebooks, Tableau)
AWS SageMaker
Sounds like you?
If this role sounds like you, apply today to have your application reviewed ASAP!",3.9,"Property Exchange Australia Limited
3.9",Melbourne,-1,201 to 500 Employees,2010,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Ongoing position
Full time
Based in Sydney, NSW
Who we are
Australian Red Cross is part of the world’s largest humanitarian organisation. Our aim is to improve the lives of the most vulnerable people in Australia and across our region.
About the role
The Data Engineer role will sit within the Data and Integration Squad in IT and will own (design, implement and support) the AWS Big Data technologies such as the Data Lake and Data Warehouse and support the organisation in growing the data analytics capabilities at Red Cross. In addition to this, the data engineer role will also administer the Power BI tool and support the implementation of the data mastering capability.
What you will bring
Experience building and optimizing data pipelines, architectures and data sets.
Experience in dimensional modelling and building data vaults
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with structured, semi-structured and unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Why work for us?
Work for purpose and know that your work assists Red Cross support and empower people and communities in times of vulnerability.
Generous salary packaging options available that can increase your take home pay.
Further information
To find out more about this opportunity please see the position description below or contact Sharath Kumar Gurram on 02 8651 8839.
Position Description: Position Description - Data Engineer .pdf
Applications for this position will close at 11:55pm Thursday, 5 November 2020.",4.1,"Australian Red Cross
4.1",New South Wales,-1,1001 to 5000 Employees,-1,Nonprofit Organization,Industrial Manufacturing,Manufacturing,$500 million to $1 billion (USD),-1
Junior Fullstack Data Engineer (Python and React),-1,"Formbay is the leading Renewable Energy Certificate Trading company in Sydney. We provide Digital Workflow and Compliance solutions in the renewable energy industry and document processing.
Thanks to our meteoric growth and our commitment to be the best at all we do, we've identified the need to bring on board a new Junior Fullstack Data Engineer.
Reporting to our Principal Machine Learning Engineer, you will help build Machine Learning pipelines for our existing Digital Workflow and Compliance solutions to automate fraud detection and document processing over terabytes of photographic and documentary data – including documents, photos, GPS data and aerial/satellite photography.
Our stack is based on Python, JavaScript, Dask, Tensorflow, CUDA, Nix/NixOS, AWS, Docker, PostgreSQL and more – familiarity with these applications will give you a leg-up on the competition.
Our ideal candidate will have the following competencies:
SQL
Python
JavaScript/TypeScript
Our candidate must also be comfortable working with Linux.
Located a stone's throw away from the Queen Victoria Building in Sydney's bustling CBD, we are centrally-located with easy access to public transportation, bars, cafes and fine dining.
Formbay will provide flexible working hours, a generous remuneration package and the opportunity to work on a world-first software solution are what we can offer you. Free, twice-weekly gym sessions and really, really good coffee are also available.
No hiring/recruitment agencies need apply.",5.0,"Formbay
5.0",Sydney,-1,1 to 50 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"ABOUT US:
Kilcoy Global Foods is a nature-to-plate company with a footprint spanning Australia, the United States and China. We partner with the world’s food industry to find new and better ways to source, prepare and serve delicious meat and seafood the world loves to eat. We believe our winning culture stems from the quality of our people and the contribution they make to Kilcoy Global Foods every day. We proudly acknowledge the hard work and dedication of our 1700+ employees who are committed to first-class standards, quality and safety. Our Australian operation, located in Kilcoy, (one hour north-west of Brisbane) and the Sunshine Coast (Head Office) is the largest Grain Fed Beef Producer in Australia.
Kilcoy Global Foods is an experienced and qualified Data Engineer to join our IT team based in Birtinya.
Key Responsibilities:
Create and maintain data pipelines and or ETL scripts
Create and maintain data integration including API and Batch interfaces
Performed detailed data analysis
Create and maintain corporate data models
Create and maintain data visualization using Qlik.Sense , PowerBI or Simliar Toolset
Experience in defining, building and maintaining data virtualization and/or star schema data warehouses
Maintain, tune and optimise database, integration and visualisation toolsets
ABOUT YOU:
To succeed in this role, you’ll need to bring the following experience and skills:
Experience in meat processing or FMCG environment is highly regarded
Experience in an Agile project environment
Can demonstrate strong communication, facilitation, negotiating and influencing skills
Excellent communication skills both oral and written, with an ability to bring clarity to an operational environment with complex influencing factors
Able to effectively work with a range of stakeholders - Administrative Staff, Management and Executive Management
Strong analytical and problem-solving skills
Innovative and creative thinking
Experience with data analysis and modelling will be beneficial

How to Apply
If you have the right skills and would like to join our company and be part of our success, please complete your details and attach your resume along with a cover letter addressed to Piper Lambourn, Workforce Planning Officer.
Further information can be obtained via our website https://www.kilcoyglobalfoods.com/en_AU/
We look forward to reviewing your details and will be in touch as soon as possible.
We are an equal opportunity employer and make every effort to select the best qualified individual for the job based on job related qualifications and experiences. Some of the information we collect via your application form and resume is “personal” information as defined by the Privacy Act. All information provided via your application form and resume is treated as confidential.
You may be required to present proof of identification (Driver's Licence, Passport or Birth Certificate). If you have a scanned copy of one of these documents please attach at least one form of ID to your application. If you are having difficulty attaching documents, please contact the Recruitment Department on (07) 5422 4600 and let us know.
Apply Now",4.1,"Kilcoy Pastoral Company
4.1",Kawana Waters,-1,501 to 1000 Employees,-1,Subsidiary or Business Segment,Logistics & Supply Chain,Transportation & Logistics,Less than $1 million (USD),-1
Graduate Data Science / Engineer,-1,"The NRMA is an organisation looking to the future, and right now, we are on the lookout for people who can help us reach our goal: to continue to shape the way Australians move, for the next 100 years and beyond. www.mynrma.com.au.
Everyone new to the team, along with our current staff, will temporarily work from home until it is safe to return to our offices. All interviewing and on boarding will be done virtually due to COVID-19.


Your opportunity
As Graduate Data Scientist or Engineer you will be part of the Data Engineering team delivering cloud data transition program for business initiatives and supporting the entire data platform build.
Your key responsibilities will be to:
Implementing Concepts of Data Warehousing, Data Mart creations within Cloud
Use of SQL for data analysis and insights
Building AI/Machine Learning prototype for implementing and supporting existing algorithms
Data Analytical reports build, using different tool sets


Requirements for Success:
Relevant Degree - Computer Science, Computer Engineering, Software Engineering, Data Science
Excellent SQL skills and demonstrated working knowledge in Python
Demonstrated understanding in data structure and algorithms.
Knowledge and concept of data warehousing methodologies
Any reporting tools experience Tableau or Oracle Analytics Cloud, Looker is desirable
Exposure to Google/AWS/Azure/Oracle any cloud based platforms is desirable
Good communication and interpersonal skills

If you have the required skills and the passion to join our high performing team, please apply today.

Employee Benefits
To ensure our employees feel valued, empowered and celebrated we provide a range of employee benefits including:
50% discount on all NRMA insurances
Free Roadside Assistance
12 weeks paid primary and 4 weeks paid secondary parental leave
Free NRMA Blue Membership
At the NRMA Group, we are People Moving People and diversity and inclusion are part of our DNA. Together, we continue to build an inclusive culture that encourages, supports and celebrates the diverse voices of our employees. It fuels our innovation, promotes flexible ways of working and connects us closer to our members and the communities we serve.",2.5,"NRMA Motoring & Services
2.5",Sydney,-1,501 to 1000 Employees,-1,Nonprofit Organization,Casual Restaurants,"Restaurants, Bars & Food Services",$500 million to $1 billion (USD),-1
Data Centre Engineer,-1,"We are a leading world group that provides low-carbon energy and services. To tackle the climate emergency facing us all, our aim is to become the world leader in the zero-carbon energy transition ""as a service"" for our clients – particular for companies and regional authorities. We use our expertise in our key business areas (renewables, gas, services) to provide competitive and bespoke solutions.
The Data Centre Engineer will be employed as part of a 24/7 ongoing shift to coordinate and monitor third party service providers, maintain the data centre facilities and infrastructure plans, coordinate the implementation of customer requests within the data centre and monitor systems, all in accordance with the Contract KPIs and SLAs.
Coordinate and monitor third party service providers for regular maintenance & testing, service faults & call outs, ensuring works are performed in accordance with Contract SLAs
Monitor and maintain the data centre facilities and infrastructure plans and documentation, including electrical, mechanical, hydraulics, fire and BMS/EMS systems
Coordinate the implementation of internal and external customer requests within the data centre
Perform scheduled plant checks and minor maintenance works
Ensure all Work Order requests are raised and closed in a timely manner
Conduct inductions for staff, vendors and contractors
Ensure all work permits for vendor works are raised and closed
Perform inventory checks on all equipment and critical spares

Qualifications
The selected candidate must be able to demonstrate:
Electrical or HVAC background, or Graduate Electrical or Mechanical Engineer
Passionate about quality work and career minded looking for a new challenge
Can commit to a day and night shift roster (2 days of day shift, then 2 days of night shift, 4 days off)
Ideally able to commence asap
As part of carrying out the duties of this role, it is mandatory to hold Australian Citizenship.

If you are interested and meet the selection criteria apply with an up-to-date resume via the apply instructions on this website.

ENGIE Services is an EEO employer, where all applicants are treated with fairness and respect and have equal access to the opportunities available.

We will not be engaging in the services of a recruitment agency to fill this vacancy and therefore request all interested candidates apply directly to this advertisement.

Job
: Maintenance
Primary Location
: Oceania-Australia-New South Wales-Erskine Park
Organization
: ENGIE Services Australia and New Zealand
Schedule
: Full-time
Nature of Responsibility
: Senior operational / administrative role
Job Posting
: Sep 11, 2020, 6:29:59 AM",3.7,"ENGIE Services Australia & New Zealand
3.7",Sydney,-1,5001 to 10000 Employees,1995,Company - Public,Energy,"Oil, Gas, Energy & Utilities",$2 to $5 billion (USD),-1
Senior Data Engineer,-1,"Senior Data Engineer, Temporary, SYDNEY - McKell

Job Title: Senior Data Engineer

Salary: SNSW Grade 9/10 - The package includes base salary range of $111,806 to $134,667, plus employer's contribution to superannuation and annual leave loading.

Location: Head Office – Haymarket

Employment Status: Temporary through till 30th June 2021


About Service NSW:

Service NSW is making it easier for people and businesses across NSW to access government services. The role designs, builds and analyses complex data from multiple sources to identify revenue, process and business improvement opportunities; providing new information and insights to the business to inform planning, continuous improvement and performance.

About the Role

We are currently seeking to appoint a Senior Data Engineer to deliver expert advice and services in the design of a Single View of Customer and data-related services to support the achievement of business outcomes and strategic goals. We support flexible working practices with staff working remotely during this time.

In this role you will:

Design, build and support a modern data platform based in AWS and vendor technologies.
Provide expertise on data modelling for Graph data model and Customer Data Platform (CDP).
Create data pipelines, load, transformation and reporting workloads in AWS.
Work with the latest data engineering technologies like Apache Kafka, AWS Kinesis, AWS Neptune, AWS Glue and AWS Athena.
Contribute to the design and decision-making of the right tool or platform for the job according to requirements.
Provide expert advice and guidance on data quality and data engineering best practices.
Support a “bigger than you can imagine” scale of data in production environments.
Design, develop and support a metrics-driven reporting solution and a meaningful business intelligence platform.
Document the solution design and support procedures of solutions.
Produce reports, visualisations and recommendations to answer complex business problems that are presented in the most appropriate format to ensure clarity for target audience.
Analyse and define new process improvement opportunities to support continuous improvement and business outcomes; providing advice to stakeholders, on ways to improve the efficiency and reliability of data products and services.
Be very responsive to the information needs of the business by corresponding to customers in a timely manner and provide support/solutions to issues raised.
Troubleshoot and perform root cause analysis on production issues. Identify and implement long term solutions to problems. Perform scheduled maintenance, release deployment and production support activities after business hours, from time to time.
Liaise with internal and external customers to discuss and gather requirements, solutions etc. and maintain a good working relationship with the stakeholders.


Skills and Experience Required:

Solid experience with workflow technologies designing and building data pipelines, data models and data stores.
Experience working within and an understanding of Amazon AWS ecosystem, including security and performance tuning.
Hands on experience working with different types of databases, with focus on Graph and NoSQL databases.
Experience with data streaming required. Having used Kafka and related technologies is an added advantage.
Sound knowledge and experience working with batch processing, data extraction and API integration.
Hands on experience with at least one programming language: Java, Python or scripting.
Demonstrated experience working in an Agile based, fast paced, complex environment within cross-functional teams.
Experience developing systematised insights, data analytics and reporting solutions is an added advantage.
Experience with interactive visualisation of data insights is an added advantage.


Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Working at Department of Customer Service

The Department of Customer Service is a great place to work! Our values of accountability, trust, service and integrity drive our initiatives and culture. We support innovative programs in areas as broad as digital government, consumer protection and major public works. We are an inclusive organisation that celebrates diversity and flexible work practices and believe our people are our greatest asset.

Salary Grade 9/10, with the base salary for this role starting at 111,806 base plus superannuation

Closing Date: 6th November at 9:59am - applications will be reviewed on a rolling basis, applications may close early or extend

Please apply online, direct applications submitted via email will not be considered.

The Department of Customer Service is proud to be an EEO Employer who are fully focused on equality and believe deeply in diversity of all identities making us different and a true reflection of our NSW customers. As an inclusive workplace, we support various employee resource groups, practice flexible work and workplace adjustment.

If you do require an adjustment during the recruitment process, please notify us on your application form.",3.2,"Service NSW
3.2",Sydney,-1,501 to 1000 Employees,2012,Government,State & Regional Agencies,Government,Unknown / Non-Applicable,-1
Data Engineer - Entry / Mid Level,-1,"Work with a great team on interesting projects customers
Gain more experience in AWS, Data, DevOps cloud operations
Got a working knowledge of AWS? We will teach you the cool stuff!

Itoc is seeking an up and coming Data Engineer to join our growing Data Team in Sydney.

This is an exciting role working with databases, data lakes, data warehouses, data transformation (Python SQL) and enabling AI/ML.

You will be implementing foundational, robust and production ready data platforms to enable business data-discovery, self-service, AI/ML functions across a range of client types and industries, allowing them to do more with their data.

You'll be responsible for:

Deploying data repositories such as lakes and warehouses.
Contribute to our growing portfolio of data solutions.
Ongoing optimisation and management of data platforms.
Development of transformational logic for data pipelines
Data evangelism. We want to show our clients how to follow the best practices for data.

Desired Skills and Experience

To take up the challenge, you will have a depth of skills and experience including:

1-2+ yrs of focused data experience working with SQL and/or NoSQL solutions
A solid education in Software Engineering or equivalent industry experience.
Anything Data focused preferred.
Ability to analyse business scenarios and associated data landscape to derive potential opportunities.
Strong foundation in Python and SQL
Working knowledge of APIs
Principle knowledge of the different relational database platforms and modern data storage techniques
Knowledge of the different aspects of data environments
Collect, store, process, verify consume
Experience with version management systems (such as GIT)
Working knowledge of AWS or another cloud platform - we will teach you the cool stuff.
Great communication skills, an ability to work closely with customers, developers and engineers and the confidence to present ideas in open forums.
Relevant tertiary qualifications and/or industry certifications.
Great communication skills, an ability to work closely with clients, developers and engineers and the confidence to present ideas in open forums.

While not required, a background in consulting and professional services is highly desirable.

Itoc Description

This is an exciting and challenging career opportunity to join the growing Sydney-based Data Team of a leading cloud solution provider where you will be given support to reach your long term career goals. You will be part of a team of cloud experts and will work in an environment of continuous improvement and learning delivering innovative cloud solutions across SaaS, online business and enterprise business.

On offer is a chance to join a team with a great working environment, in an organisation that values its employees and sees the value in ensuring they are engaged. Our team are clearly passionate about what they do, that's why we won the following awards:

Customer Obsession Partner of the Year 2015: ANZ Region
Customer Obsession Leadership Partner 2015: re:Invent

As an employer of choice Itoc offers competitive remuneration, training and development programs and a great working environment. We value a healthy work life balance.

The Perks

MacBook or Dell
Continuous internal learning that will provide training and career development opportunities
Working with a collaborative, social team and leveling-up your skills faster than you will anywhere else.
Quarterly social events

Itoc

Culture and smarts are important to us. Bring your secret sauce. This is no ordinary environment, you will work along some of the Cloud’s best. All engineers at Itoc must gain at least five AWS certifications. We work hard but we have fun.

Please note you must have full working rights in Australia and be available on-shore for face to face interviews.

No recruiters please.",4.0,"Itoc
4.0",Sydney,-1,1 to 50 Employees,2013,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
