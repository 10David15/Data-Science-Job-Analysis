Job Title,Salary Estimate,Job Description,Rating,Company Name,Location,Headquarters,Size,Founded,Type of ownership,Industry,Sector,Revenue,Competitors
Data Scientist,-1,"The world is changing.

We all want something different.

At Luno, we see you as an individual.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the world, and to do so, we need the best team on board for our mission.

A bit about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 3 million customers across 40 countries.
We are Series B funded, backed by Balderton Capital and the Naspers Group.
Our platform has processed over 8 billion dollars since we've launched
We're proud to be one of the world's most international cryptocurrency teams from 26 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
The role in a nutshell:

Identifying opportunities in the business that could benefit most from cognitive applications, as well as building and enhancing organisational capabilities for deriving value from multiple data sources using data science.

What we'd like you to have:
Bachelor's degree or higher in the natural sciences or technical fields such as Mathematics, Statistics, Computer Science, Engineering or Economics
Enthusiasm to work in the cryptocurrencies space
Advanced SQL skills
Solid understanding of exploratory data analysis, predictive analytics, and optimisation using Python, R, Matlab, RapidMiner, KNIME or other data science-oriented platforms
Proficiency in the use of data science and machine learning domain-specific languages such as ""Caret"" and the ""Tidyverse"" suite of tools in R, or ""Pandas"" in Python
Strong interpersonal and communication skills
Communicating data insights using storytelling narratives
Ability to work independently, as well as within and across teams
Ability to successfully complete projects with large and/or incomplete data sets
More about what you'll be doing:
Optimising product performance by tracking and analysing customer behaviour on web and app, in collaboration with software engineers and product designers
Providing the business with reports and dashboards, on key performance metrics
Developing metrics to accurately assess the health of our Exchange platform
Comparative data-driven analysis of our Exchange against alternative platforms
Formulating business requirements into analytical objectives
Designing and running experiments to test hypotheses
Hacking through complex business problems using advanced data analysis to provide insights and recommendations
Building, maintaining, and optimising decisioning systems using advanced statistical and predictive modelling techniques
What will set you apart:
An advanced degree in Mathematics, Statistics, Computer Science or related field
At least 3 years' experience working in a similar role
A basic understanding of trading in financial markets
Experience working with a data analytics and visualisation platform such as Tableau, Cognos, QlikView, or Looker
Familiarity with using Google Analytics to understand customer behaviour
Solid knowledge of statistical and machine learning techniques
Familiarity with modern distributed data storage and processing systems such as Amazon Redshift, Big Query, Snowflake, Databricks and Apache Spark
You can gather and synthesise facts, theories, trends, patterns, inferences, and key issues in complex and variable situations
Ability to diagnose problems using formal problem-solving tools and techniques from multiple angles to generate multiple possible solutions
A sense of anticipating long-term problem areas and associated risk levels with objective rationale
Remote Life at Luno

If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
You'll be able to continuously upskill yourself with access to free online learning via MyAcademy, an international teaching marketplace with over 100000 courses from Harvard and other leading providers + share knowledge with your peers.
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity and paternity leave, and you can even take paw-ternity leave for your furry friend.
Annual Inspiration Day! Make time for that pottery course or spa day you've always wanted to do.
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"EY is a global leader in
assurance, tax, transaction and advisory services. Technology is at the heart
of what we do and deliver at EY. Technology solutions are integrated in the
client services we deliver and are key to our innovation as an organization.

Fueled by
strategic investment in technology and innovation, Client Technology seeks to
drive growth opportunities and solve complex business problems for our clients
through building a robust platform for business and powerful product engine
that are vital to innovation at scale. As part of Client Technology, you’ll
work with technologists and business experts, blending EY’s deep industry
knowledge and innovative ideas with our platforms, capabilities, and technical
expertise. As a catalyst for change and growth, you’ll be at the forefront of
integrating emerging technologies from AI to Data Analytics into every corner
of what we do at EY. That means more growth for you, exciting learning
opportunities, career choices, and the chance to make a real impact.

The selected
candidate
Develops
large and complex data architecture, composed of models, policies, rules or
standards that govern which data is collected and how it is stored, arranged,
integrated and put to use in data systems, including the design, build and
management of data infrastructure to address business requirements
Creates
sound use case driven roadmaps, depicting data architecture as-is and to-be
capabilities with the business by engaging with multidisciplinary teams, and by
identifying, managing and mitigating risk
Develops
relationships across the business to understand data requirements, applies deep
technical knowledge of data management to solve business problems in areas
where solutions may not currently exist, necessitating new solutions/ways of
working/technologies and proactively articulating these to the business
Review,
identify the latest emerging technologies, augmenting by services from the
leading cloud providers to solution and recommend the best next generation data
platform value driven approach for our clients
Your Key Responsibilities Include
Create
and maintain conceptual, logical and physical database models
Document
functional requirements and system specifications into the data architecture
and detailed design specifications for current and proposed designs
Document
and adhere to development standards and best practices in database designs
Maintain
highly effective and consistent communication within the team, peers, and the
leadership team
Reverse
engineer SQL code and modify it to solve problems/issues
Contribute
to the definition and implementation of data governance practices
Design
both data structures and data integration practices
Work
closely with the infrastructure teams to create a physical environment to
support data services
Evaluate
new and existing (internal and external) technologies and services in support
of data services and data analytics objectives
Skills And Attributes For Success
Understanding
of business process reengineering and business modeling concepts, business
systems development and analysis
Hands-on
experience in designing and implementing hybrid cloud and on-prem solutions
Experience
working with the latest versions of SQL Server
Experience
applying SAFe/Scrum/Kanban methodologies
Ability
to exercise judgment in solving technical, operational, and organizational
challenges
Expert
programming, performance tuning and troubleshooting skills, using the latest
popular programming languages for example python
Demonstrate
proactive approach to identifying issues and presenting solutions and options,
and where appropriate, leading to resolution
Minimum Qualifications
5+ years
demonstratable work experience as a Data Architect using data modeling tools
2-3 years
SQL coding experience on large projects
Must
possess expert SQL programming, performance tuning and troubleshooting skills
Create
database objects and SQL scripts
Understand
and developed data pipelines
Know how
to deformalize data for data science models
Experience
in python, spark and notebooks
Experience
designing data warehousing solutions
Experience
designing next generation data platforms utilising cloud services
In-depth
understanding of database structure principles
Seamlessly
able to translate business requirements to technology requirements
What We Look For
Strong
analytical skills and problem-solving ability
A
self-starter, independent-thinker, curious and creative person with ambition
and passion
Excellent
inter-personal, communication, collaboration, and presentation skills
Customer
focused
Excellent
time management skills
Positive
and constructive minded
Takes
responsibility for continuous self-learning
Takes the
lead and makes decisions in critical times and tough circumstances
Attention
to detail
High
levels of integrity and honesty
Curious
about new emerging technology
About EY
As a global leader in assurance, tax, transaction and consulting
services, we’re using the finance products, expertise and systems we’ve
developed to build a better working world. That starts with a culture that
believes in giving you the training, opportunities and creative freedom to make
things better. Whenever you join, however long you stay, the exceptional EY
experience lasts a lifetime.",3.8,"EY
3.8",Johannesburg,-1,10000+ Employees,1989,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Architect - Principal,-1,"We are looking for Principle Data Architect to join our Engineering team in Cape Town.

The world is changing.
We all want something different.
At Luno, we see you as individuals.

Together, we are upgrading the world of work to unleash the potential within and empower you to become the best possible version of yourself.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the financial landscape, and to do so, well we need the best team on board for our mission. In short, to achieve our goals, we need rockstars. As simple as that.

A little about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 5 million customers across 40 countries.
We're part of the Digital Currency Group, a group of companies driving progress in the cryptocurrency and blockchain space that includes Grayscale, Genesis, Coindesk and Foundry Services
Our platform has processed over $8 billion to date
We're proud to be one of the world's most international cryptocurrency teams from 43 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
How we work


Our engineering team (currently ~100 engineers) is split into organisations which we call Fleets. Each Fleet focuses on a core customer journey (onboarding, security, payments, support, new business, growth and marketing etc.). Each of these fleets contains multiple smaller teams called Pods, each of which focuses on a specific aspect of the product.

Pods will include a product owner, product designer, back-end engineers, Android, iOS and Web developers, who each bring a unique perspective to the problem you are all contributing towards.

We're agile, use scrum, continuous integration and continuous delivery, deploying to production every single day.

We're building teams to help us succeed in our mission to upgrade the world to a better financial system. You'll be joining a group of highly motivated software engineers who you'll work collaboratively with across our pods.

As a fast-growing company with offices around the world, you'll immediately see how your contributions directly impact both our internal users and client experience. Many of the problems we are solving result in trail blazing solutions which can't be found on Stack Overflow; so we're looking for engineers who flourish working in a complex domain.

In your first six months, you will:


...start at Luno by learning our processes, meeting the wider team and starting our engineering on-boarding program. After getting comfortable with the basics, you'll start learning our idiomatic patterns in a safe, easy-to-follow way - by building your own toy micro services. You'll get to practice how we do design docs, code reviews, deployments, events, logging and monitoring.

You'll meet the Pod(s) you'll be working with and quickly align on the teams' current OKRs and product roadmap. We succeed as a team, so we will provide you with regular feedback from your manager and peers and will encourage you to do the same.

What you'll do:
Work closely with our data science and platform teams on projects introducing new streams of data into our data lake
You will get to bring new ideas on how to further develop and innovate our data solutions and how to expose that data to the business
Accountable and Responsible for the design and architecture of Data systems that are robust and scalable.
Work in an Agile/Scrum framework or Agile mindset
Data backup/recovery and storage
Pick-up and learn new concepts, in both engineering and product, and be able to apply that knowledge quickly.
The ideal candidate for this role will have:
7+ years' experience in maintaining scalable data solutions and/or you are passionate about it
Ability to understand, communicate and advocate between build vs buy
Proven track record of setting up, restructuring and maintenance of databases
You know your way around ETL and you have experience with SQL
Experience in the AWS Data stack (RedShift,DynamoDB, Amazon RDS)
Familiarity with integrating data stores with BI platforms such as Looker, Tableau, or Power BI
You have experience with the concepts of CI/CD
Coding skills in e.g. Go, Python
Bachelor's degree in a related field preferred
AWS Certified DataOps Administrator
Be friendly, transparent, articulate and driven to succeed
Basic knowledge of and passion for digital currencies like Bitcoin
A work permit for South Africa if you are not a South African citizen
Don't be put off if you don't tick all of the boxes – they're a guide based on what we'd love to see but we appreciate that excellent software engineers have diverse backgrounds.

Remote Life at Luno


If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity / paternity and even (yes, you are reading it correctly) paw-ternity for your furry friend..
Annual Inspiration Day.. like that pottery course you've always been meaning to do!
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. You'll need to hold the legal right to work in South Africa already as we cannot provide visa sponsorship.

Be part of the change!",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer - EC2 Capacity Data Analytics,-1,"EC2 Capacity Data Analytics (CDA) team is looking for a Data Engineer to join our team.

Our team is part of the EC2 Capacity Engineering organization, which is responsible for providing the elasticity EC2 customers need to scale up/down compute resources in a cost-efficient manner. We predict customer usage across thousands of configuration combinations to deliver exactly what our customers require in just the right amount of time with just the right amount of capacity.

As a Data Engineer, you will build the ETL and analytics solutions for our internal customers to answer questions with data and drive critical improvements for the business. You will use best practices in software engineering, data management, data storage, data compute, and distributed systems. On any given day, we use Python, Scala, Java, SQL, Lambda, CloudFormation, Redshift and Glue as well as other public AWS services and a host of Amazon internal tools. We dont expect you to be an expert in, or necessarily even be familiar with all of the technologies listed above, but we do expect you to be excited to learn about them.

This position involves on-call responsibilities, typically for one week every two months. Our team is dedicated to supporting new team members. We care about your career growth, we try to assign projects and tasks based on what will help each team member develop into a more well-rounded engineer and enable them to take on more complex tasks in the future.

Our team values work-life balance and we are flexible when people occasionally need to work from home.

Job Duties
Develop and maintain automated ETL pipelines for big data using languages such as Scala, Spark, SQL and AWS services such as S3, Glue, Lambda, SNS, SQS, KMS. Example: ETL jobs that process a continuous flow of JSON source files and output the data in a business-friendly Parquet format that can be efficiently queried via Redshift Spectrum using SQL to answer business question.

Develop and maintain automated ETL monitoring and alarming solutions using Java/Python/Scala, Spark, SQL, and AWS services such as CloudWatch and Lambda.

Implement and support reporting and analytics infrastructure for internal business customers using AWS, services such Athena, Redshift, Spectrum, EMR, and QuickSight.

Develop and maintain data security and permissions solutions for enterprise scale data warehouse and data lake implementations including data encryption and database user access controls and logging.

Develop and maintain data warehouse and data lake metadata, data catalog, and user documentation for internal business customers.

Develop, test, and deploy code using internal software development toolsets. This includes the code for deploying infrastructure and solutions for secure data storage, ETL pipelines, data catalog, and data query.


Basic Qualifications

· Bachelors degree in Computer Science or related technical field, or equivalent work experience.
· 4+ years of overall work experience including Software Engineering, Data Engineering, Database Engineering, Business Intelligence.
· Experience with AWS technologies stack including Lambda, Glue, Redshift, RDS, S3, EMR or similar big data solutions stack

Preferred Qualifications

· Demonstrate efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data.
· Demonstrable proficiency in distributed systems and data architecture; design and implementation of batch and stream data processing pipelines; knows how to optimize the distribution, partitioning, and MPP of high-level data structures.

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer,-1,"Our client based in Johannesburg is urgently looking for a Data Engineer to be on a 3 months contract
Build data pipelines, experience in new tech like nifi, kafka, python

Joburg based, open to EE, 3 month contract with the option to extend, must be available at short notice",-1,EQplus,Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Overview
Job ID: 51456
Job Sector: Information Technology and Services
Country: South Africa
Region/State/Province/District: Gauteng
Location: Johannesburg

Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose

This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes

Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems

Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions

Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.
Research and best practices

Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development

Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.

Preferred Qualification and Experience

Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry

Knowledge/Technical Skills/Expertise

Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision

PLEASE NOTE: All our recruitment and selection processes comply with applicable local laws and regulations. We will never ask for money or any form of payment as part of our recruitment process. If you experience this, please contact our Fraudline on +27 800222050 or forward to TransactionFraudOpsSA@standardbank.co.za",4.1,"Standard Bank
4.1",Johannesburg,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"About us

At PBT Group we pride ourselves on being a Data Specialist organisation. With 20 years of experience in 27 countries over 3 continents, our team of 550 consultants have implemented more than 700 projects.",4.3,"PBT Group
4.3",Johannesburg,-1,Unknown,-1,Company - Private,Accounting,Accounting & Legal,Less than $1 million (USD),-1
Data Engineer,-1,"Kick-start your career in the online gaming world and experience the very latest in technology and innovation.

The Department:

Our mission is to provide our customers with the best online betting experience and share the thrill of gaming with them. Data is at the very heart of our business and is vital in everything we do.

Our cross-functional Data team has a big and exciting challenge ahead. We are in the process of re-platforming our traditional, on-premises RDBMS environment to a new microservice architecture in the cloud. We’re making use of the diverse set of data technologies in Microsoft Azure to offer new services, reporting structures and real-time data pipeline while serving the day-to-day requirements of a rapidly growing, data-hungry organisation.

Purpose of the Role:

This is an excellent opportunity for an individual who is looking to gain new skills. We are committed to creating a culture of learning and regularly run proof of concepts, provide internal demos, manage workshops and attend external conferences. Our data team has a wide range of skills including development for highly transactional RDBMS systems, data warehousing, data science and cloud technologies and we are always working to raise everyone’s game.

Duties include, but not limited to:

Work as part of an agile Data Engineering Team
Development of greenfield projects in Azure
Develop and maintain on-premises RDBMS/DW systems
Create robust ETL services and real-time data pipelines
Build and maintain Continuous Integration and DevOps pipelines
Test-driven development and pair programming with colleagues

Essential Criteria:

C#, .Net, Visual Studio
Git, Azure DevOps
NoSQL development (CosmosDB)
Demonstrable understanding of MS SQL Server in a highly transactional environment
Demonstrable understanding of development in Microsoft Azure
Able to understand query plans and identify performance bottlenecks
Test/Business-Driven Development
Building Continuous Integration/Deployment pipelines
Communicate effectively with both technical and non-technical stakeholders

Desirable Criteria:

Implementing Data Storage and Processing solutions in Azure (ARM Templates, Storage Accounts, Data Lake Storage, SQL DB, Cosmos DB, EventHubs, Function Apps, Log Analytics, Data Factory, Databricks, Polybase)
Implementing Security, Disaster Recovery, High Availability, Auditing, Monitoring and Alerting solutions in Azure
Automating tasks in Azure using Powershell / CLI
Predicting costs and optimizing spending in Azure
Message Queues (RabbitMQ, Kafka)
Python

Person Specifications:

Resilience
Teamwork
Technical Knowledge
Communication skills
Stress Tolerance
Please note we will apply relevance to our Talent Management and Talent Development Programme as part of our recruitment process.
Shortlisted candidates may need to complete an assessment.
This position requires trust and honesty it has access to customers financial details - therefore a credit and criminal record check will be conducted. The qualifications identified herein are an inherent job requirement; therefore, a qualification verification check will be done. By applying for this role, and supplying the necessary details, you hereby grant us permission to apply for these checks. This will be done in a confidential manner, and solely for the purposes of verification.

To view all current vacancies, please visit our website, www.digioutsource.com

Should you not hear from us within 2 weeks, please deem your application as unsuccessful.

The perfect place to work, play and grow!",3.9,"Digital Outsource Services
3.9",Cape Town,-1,1001 to 5000 Employees,1997,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
Data Engineer,-1,"At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes

Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.

Key Responsibilities

Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.

Key Traits

Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern

Position Requirements

2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.

Where will you work? This role will be based out of Durbanville, South Africa.",3.1,"Aculocity, LLC
3.1",Durbanville,-1,1 to 50 Employees,2006,Company - Private,IT Services,Information Technology,$1 to $5 million (USD),-1
Data Engineer,-1,"ENVIRONMENT:

A rapidly growing E-Commerce Platform seeks a highly talented Data Engineer to make an invaluable contribution to data democratisation and literacy vision by making accessible and easy-to-use data products and tools. You will require a Comp-Sci Degree or 3 years’ relevant industry experience, MySQL, PostgreSQL, Java, Python, in-depth understanding of OLAP, Data Marts, Star Scheme, Snowflake, be familiar with Jenkins, Travis, Circle CI, Docker, Kubernetes, experience with Kafka, Pub/Sub, Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks & significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing & Data Lake design and implementation and Lambda/Kappa architectures.

DUTIES:

Design, develop, test and maintain data architecture.

Prepare data for descriptive, predictive and prescriptive modelling.

Automate repetitive tasks and manual processes related with the data usage.

Optimize data delivery.

Design, develop and test large stream data pipelines to ingest, aggregate, clean, and distribute data models ready for analysis.

Ensure the highest standard in data integrity.

Leverage best practices in continuous integration and delivery.

Collaborate with other engineers, ML experts, analysts, and stakeholders to produce the most efficient and valuable solutions.

Implement features, technology, and processes that move us towards industry best practices, improving on scalability, efficiency, reliability, and security.

Operations and ownership of systems in production, responding to incidents.

REQUIREMENTS:

Qualifications –

Comp-Sci Degree or 3 years relevant industry experience.

Experience/Skills –

Open source relational database systems e.g. MySQL, PostgreSQL, etc.

Significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing, and Data Lake design and implementation and Lambda/Kappa architectures.

A thorough understanding of database and data warehousing principles e.g. OLAP, Data Marts, Star Schema, Snowflake, etc.

Java and Python.

Familiar with CI/CD tools such as Jenkins, Travis, Circle CI, etc.

Experience with Kafka, Pub/Sub, or other event-based systems.

Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks, etc.

Working in cloud environments and with containerisation frameworks, tools and platforms e.g. Docker, Kubernetes, GKE, etc.

A deep understanding of data pipelining, streaming, and Big Data technologies, methods, patterns, and techniques.

Troubleshooting complex database operations and performance issues.

Automating tasks using Shell Scripting or writing small applications.

ATTRIBUTES:

Works well with people and is passionate about helping people be their best.

A team player, an active listener, mentor, and able to communicate well.

Shows solid reasoning and decision making, with the ability to work under pressure.

Is passionate about technology, systems and data.

Is curious, always learning, and keeping up to date with the industry.

While we would really like to respond to every application, should you not be contacted for this position within 10 working days please consider your application unsuccessful.

COMMENTS:

When applying for jobs, ensure that you have the minimum job requirements. Only SA Citizens will be considered for this role. If you are not in the mentioned location of any of the jobs, please note your relocation plans in all applications for jobs and correspondence.",-1,Datafin IT Recruitment,Cape Town,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Cartrack is looking for passionate data science and engineering candidates that can join a growing team that is responsible for the intelligence and efficiency solution provision to over a million subscribers, many of whom are large fleets. We are in the midst of creating revolutionary platforms that will change the way that people interact with their vehicles.

You will have the opportunity to work with the very brightest global subject matter experts that are transforming the automotive industry across Fleet Management, Asset Management and Insurance Telematics solutions.

Get to know the role:

The role of a data engineer is a supporting one, but it is also an extremely vital one. As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements. We want to see candidates with mechanical tendencies and a desire to know how things work and to improve them.

The day-to-day activities:

Design, construct, install, test and maintain data management systems.
Build high-performance algorithms, predictive models, and prototypes.
Ensure that all systems meet the business/company requirements as well as industry practices.
Integrate up-and-coming data management and software engineering technologies into existing data structures.
Develop set processes for data mining, data modeling, and data production.
Create custom software components and analytics applications.
Research new uses for existing data.
Employ an array of technological languages and tools to connect systems together.
Install/update disaster recovery procedures.
Recommend different ways to constantly improve data reliability and quality.
Work on and maintain Data pipelines.

Requirements Essential:

At least 5 years’ proven experience as a Data Engineer, DevOps Engineer, Software Developer, or similar.
Proficient in Linux/Unix and shell scripting as well as in functional programming languages.
Expertise in setting up and explored with technologies such as Hadoop and Spark.
Bachelor’s degree in computer science, software/computer engineering, applied mathematics, or physics.",3.3,"Cartrack
3.3",Johannesburg,-1,501 to 1000 Employees,2004,Company - Private,Security Services,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Data Engineer,-1,"Data Engineers build and support data pipelines and datamarts built off those pipelines. Both must be scalable, repeatable and secure. The Data Engineer helps to facilitate gathering data from a variety of different sources, in the correct format, assuring that it conforms to data quality standards and assuring that downstream users can get to that data timeously. This role functions as a core member of an agile team. These professionals are responsible for the infrastructure that provides insights from raw data, handling and integrating diverse sources of data seamlessly. They enable solutions, by handling large volumes of data in batch and real-time by leveraging emerging technologies from both the big data and cloud spaces. Additional responsibilities include developing proof of concepts and implements complex big data solutions with a focus on collecting, parsing, managing, analysing and visualising large datasets. They know how to apply technologies to solve the problems of working with large volumes of data in diverse formats to deliver innovative solutions. Data Engineering is a technical job that requires substantial expertise in a broad range of software development and programming fields. These professionals have a knowledge of data analysis, end user requirements and business requirements analysis to develop a clear understanding of the business need and to incorporate these needs into a technical solution. They have a solid understanding of physical database design and the systems development lifecycle. This role must work well in a team environment.

Job Objectives

Work Complexity: * Architects Data analytics framework. * Translates complex functional and technical requirements into detailed architecture, design, and high performing software. * Leads Data and batch/real-time analytical solutions leveraging transformational technologies. * Works on multiple projects as a technical lead driving user story analysis and elaboration, design and development of software applications, testing, and builds automation tools.

Main Job Objectives: 1. Development and Operations 2. Database Development and Operations 3. Policies, Standards and Procedures 4. Communications 5. Business Continuity & Disaster Recovery 6. Research and Evaluation 7. Coaching/ Mentoring

Qualifications

Essential: 4 years Bachelors degree in computer science, computer engineering, or equivalent work experience AWS Certification at least to associate level

Experience

Essential:

5+ years Data engineering or software engineering

3-5 years demonstrated experience leading teams of engineers

2+ years Big Data experience

5+ years experience with Extract Transform and Load (ETL) processes

2+ years Could AWS experience

At least 2 years demonstrated experience with agile or other rapid application development methods - Agile exposure, Kanban or Scrum

5 years demonstrated experience with object oriented design, coding and testing patterns as well as experience in engineering (commercial or open source) software platforms and large scale data infrastructures.

Desirable:

5+ years Retail Operations experience

Knowledge and Skills

Essential: *Creating data feeds from on-premise to AWS Cloud (2 years) *Support data feeds in production on break fix basis (2 years) *Creating data marts using Talend or similar ETL development tool (4 years) *Manipulating data using python and pyspark (2 years) *Processing data using the Hadoop paradigm particularly using EMR, AWSs distribution of Hadoop (2 years) *Devop for Big Data and Business Intelligence including automated testing and deployment (2 years) * Extensive knowledge in different programming or scripting languages * Expert knowledge of data modeling and understanding of different data structures and their benefits and limitations under particular use cases.

Further technical skills required: * Capability to architect highly scalable distributed systems, using different open source tools. * Big Data batch and streaming tools * Talend (1 year) * AWS: EMR, EC2, S3 (1 year) * Python (1 year) * PySpark or Spark (1 year) - Desirable * Business Intelligence Data modelling (3 years) * SQL (3 years)",-1,Datonomy Solutions,Brackenfell,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Data Engineers build and support data pipelines and datamarts built off those pipelines. Both must be scalable, repeatable and secure. The Data Engineer helps to facilitate gathering data from a variety of different sources, in the correct format, assuring that it conforms to data quality standards and assuring that downstream users can get to that data timeously. This role functions as a core member of an agile team. These professionals are responsible for the infrastructure that provides insights from raw data, handling and integrating diverse sources of data seamlessly. They enable solutions, by handling large volumes of data in batch and real-time by leveraging emerging technologies from both the big data and cloud spaces. Additional responsibilities include developing proof of concepts and implements complex big data solutions with a focus on collecting, parsing, managing, analysing and visualising large datasets. They know how to apply technologies to solve the problems of working with large volumes of data in diverse formats to deliver innovative solutions. Data Engineering is a technical job that requires substantial expertise in a broad range of software development and programming fields. These professionals have a knowledge of data analysis, end user requirements and business requirements analysis to develop a clear understanding of the business need and to incorporate these needs into a technical solution. They have a solid understanding of physical database design and the systems development lifecycle. This role must work well in a team environment.

Job Objectives

Work Complexity: * Architects Data analytics framework. * Translates complex functional and technical requirements into detailed architecture, design, and high performing software. * Leads Data and batch/real-time analytical solutions leveraging transformational technologies. * Works on multiple projects as a technical lead driving user story analysis and elaboration, design and development of software applications, testing, and builds automation tools.

Main Job Objectives: 1. Development and Operations 2. Database Development and Operations 3. Policies, Standards and Procedures 4. Communications 5. Business Continuity & Disaster Recovery 6. Research and Evaluation 7. Coaching/ Mentoring

Qualifications

Essential: 4 years Bachelors degree in computer science, computer engineering, or equivalent work experience AWS Certification at least to associate level

Experience

Essential:

5+ years Data engineering or software engineering

3-5 years demonstrated experience leading teams of engineers

2+ years Big Data experience

5+ years experience with Extract Transform and Load (ETL) processes

2+ years Could AWS experience

At least 2 years demonstrated experience with agile or other rapid application development methods - Agile exposure, Kanban or Scrum

5 years demonstrated experience with object oriented design, coding and testing patterns as well as experience in engineering (commercial or open source) software platforms and large scale data infrastructures.

Desirable:

5+ years Retail Operations experience

Knowledge and Skills

Essential: *Creating data feeds from on-premise to AWS Cloud (2 years) *Support data feeds in production on break fix basis (2 years) *Creating data marts using Talend or similar ETL development tool (4 years) *Manipulating data using python and pyspark (2 years) *Processing data using the Hadoop paradigm particularly using EMR, AWSs distribution of Hadoop (2 years) *Devop for Big Data and Business Intelligence including automated testing and deployment (2 years) * Extensive knowledge in different programming or scripting languages * Expert knowledge of data modeling and understanding of different data structures and their benefits and limitations under particular use cases.

Further technical skills required: * Capability to architect highly scalable distributed systems, using different open source tools. * Big Data batch and streaming tools * Talend (1 year) * AWS: EMR, EC2, S3 (1 year) * Python (1 year) * PySpark or Spark (1 year) - Desirable * Business Intelligence Data modelling (3 years) * SQL (3 years)",-1,Datonomy Solutions,Brackenfell,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Our client based in the Northern Suburbs, is currently looking for a Data Engineer to join their team.

Responsibilities
Our client is a dynamic IT company that delivers value-driven IT solutions to the group. Our work lives revolve around our DNA. We take pride in our work, treat our colleagues, partners and our country with respect. We exercise collaborative decision-making and believe in having a balance in life. We do this all while having fun and enjoying what we do.

The primary focus of this position is to use technical skills to put software, systems and data together in a way that extracts meaningful insights from raw data. You will need to be helpful and supportive to your team and fellow developers. You join an energetic, focused and dynamic team.

Interact with clients to understand requirements and business problems/needs

Identify, analyse, visualise and understand supporting data to propose solid solutions

Create technical documentation for reference and reporting

Support existing solutions within GCP and Oracle

Doing standby on a rotating basis

Key Competencies and Qualifications

Matric

Tertiary qualification in IT

Preferred cloud experience in AWS/AZURE/GCP

At least 3 years of data warehouse ETL experience

Dimensional Modelling

Data analyses

Experience with data visualization and visualization tool(s)

Knowledge of the retail industry will be beneficial

Understanding and experience with version control SVN/GIT

Preferred – Korn shell scripting, Python/Java, SQL

Google Cloud Platform experience would be looked upon favourably

Having a broad understanding of different SDLC’s

Preferred agile experience

Strengths

The natural tendency to take ownership and responsibility

Strong problem solving, critical thinking, effective planning and organisational skills

Detail-oriented with excellent communication skills

You have a can-do attitude and positive outlook on life

Can cope under pressure

Curious and interested in analysing problems and possible solutions

Strong team player

Self-driven learner, passionate about new technology

Above all, be passionate about what you do

Should you wish to apply for the position, please apply directly via this job board, please ensure that you quote reference number 201620 subject heading or email body.

Please note that due to the high volume of CV's received; only shortlisted applicants will be contacted. Should you not receive communication from our offices within two weeks of submission please note that your application will not be considered for this position.

We will keep your CV on file and re-establish contact with you should opportunities in line with your expertise become available again.

Should you require any additional information give us a call on 021 012 5566.",-1,Surgo HR & Training,Cape Town,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We believe that our employees fuel our organization, essential to enable us to help our customers overcome their business challenges and achieve sustainable growth. As a result, we are committed to growing each individual and providing them with the challenges, feedback and support needed to achieve success in their career

If this sounds appealing, and like us, you get excited about data: its collection, storage, transformation or display, see if you’ve got what it takes to join our sought after DATA team.

Key Responsibilities And/or Outputs

You will represent IQbusiness at our customers, sometimes alone, and sometimes as part of an IQ team.

Providing a superior customer experience by building and maintaining relationships, working at customer offices, keeping data confidential
Design and develop – databases, SQL queries, stored procedures, reports, dashboards or integration solutions
Produce solutions for both real-time and batch environments
Test your work to ensure compliance
Solve problems, and do root cause analysis
Prioritize your workload
Assist in other areas relating to your true data function, such as data modeling, data and business analysts
Interact with a variety of individuals: senior, junior, technical and from business
Provide guidance to fellow colleagues, or even manage a team
Uphold the IQ values, which are to care, learn & share; innovate; deliver as well as to build, enhance and maintain relationships

Education

Matric pass
A tertiary qualification, preferably in an ICT relevant field
Appropriate Microsoft certifications are beneficial but not required

Requirements

3 - 6 years experience in the Data Engineering environments and technologies
Great communication skills
A passion for SQL, databases or reports
Can you write stored procedures, design complex queries and create views and triggers?
Are you able to work out the relationships in a data warehouse or the aggregation of a cube?
Do you extract and display useful information when you see patterns and trends in data?
Strong knowledge of the financial services industry, ideally in a consulting role
The use of data related software: databases, ETL and BI tools; report writing and analytical tools
We use a lot of Microsoft products. You may often be expected to use MS SQL Server, SSIS, SSRS, SSAS and Power BI to develop solutions
What other relevant software have you’ve used?
Ability to work in different project methodologies: Waterfall and/or Agile
Knowledge of full SDLC
Exposure to logical and physical data modeling

Equal Employment Opportunity

IQbusiness is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, citizenship, marital, domestic or civil partnership status, sexual orientation, or gender identity",3.7,"IQbusiness South Africa
3.7",Johannesburg,-1,1 to 50 Employees,-1,Company - Private,Consulting,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"We value a data engineer as someone who works behind the scenes to obtain, process and supply data via various methodologies and technologies, to various consumers, in ways and forms that makes sense and add value. This definition is very broad, as the field of data engineering is just as broad.

You may be the type of data engineer that develops API endpoints for the consumption of data by end users or even another data pipeline, or you may be the type of data engineer that develops highly distributed, high availability data processing pipelines in an effort to satisfy the need of the ever questioning data analysts and/or data scientists.

You have awesome knowledge about the following concepts
Data modelling
Relational data modelling in traditional relational database management systems. (Microsoft SQL Server, MySQL, PostgreSQL, etc)
Coercing unstructured and semi-structured data into a structured form.
Data pipelining knowledge - data extraction and transformation.
Data transformation knowledge for reporting and analytics purposes.
Knowledge of the MapReduce and related data processing paradigms would be a boon.
You have the following technical competencies
Writing SQL queries, that can relate, transform and aggregate data from many differing sources where natural keys may or may not exist.
Experience with writing data pipelines that move and transform data, for various uses.
Working knowledge of a general purpose programming language like Python would be a boost.
Working knowledge of columnar databases such as Google BigQuery, and SAP HANA would be a boost.
Working knowledge of highly distributed technologies such as Apache Hadoop or Apache Spark would be a boost.
Working knowledge of NoSQL technologies, such as Apache Solr would be a boost.
You have the following personal competencies
The ability to solve problems.
The ability to rotate around a problem, to see if solutions can be gained in different ways.
The ability to work in an ever changing, unstructured environment.
The ability to work as part of a team, with vastly differing skill sets and opinions.
The ability to contribute ideas to the quorum.
The ability to mentor and provide guidance for other team members.
A systems approach to thinking, as opposed to a siloed approach. The candidate needs to understand how their work affects the greater system.
The ability to work without supervision, and take accountability for the work they deliver.
The ability to liaise with a client, sifting through the fluff and extracting the actual requirements.
If this is you - apply now and we'll get in touch",-1,DotModus,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Data Engineer

Our client in the contact centre space is currently seeking a DATA ENGINEER that will work on the collecting, storing, processing, and analyzing of large datasets. The primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them. You will also be responsible for integrating them with the architecture used across the company.

Key Performance Areas:

Data reporting.
Implementing ETL processes.
Defining data retention policies.
Management of Customer Lead data.
Provision of data for advanced analytics.
Maintenance of internal client scorecards.
Assist team in resolving data-related support queries.
Optimize existing data processes through automation.
Assist with all data-related reporting and documentation.
Maintenance and optimisation of the Analytics database.
Provide technical support to and supervision of junior data administrators.
Continuous upskilling on new technologies, frameworks and market trends.
Monitoring performance and advising any necessary infrastructure changes.
Identifying, selecting and integrating any Big Data tools and frameworks required to provide real-time analytics.

Educational Requirements

IT related Degree or Diploma is a pre-requisite

Required Skills/Experience

ETL tools: Advanced SSIS
BI/Reporting : Qlikview/Power BI/ SSRS or SSAS
Programming languages: JAVA, C# , Python, SAS or R
Experience with NoSQL databases and/or campaign management tools will be advantageous.
Minimum 3 years’ applicable work experience in SQL, relational databases and data manipulation.
Experience in big data platforms (eg. Hadoop) or processing frameworks (eg. MapReduce/Spark) and querying tools (eg. Pig, Hive and Impala) will be highly beneficial.

Preferred Skills

Organizational skills
Experience in Attentional to detail.
Accountability is critical for this role.
Ability to work under pressure and meet deadlines.
Solid understanding of database design principles.
Should you not receive a response in 2 weeks please consider your application unsuccessful",-1,Rubik's Cubed Consulting,Durban,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"This well known company is looking for a Data Engineer. will be based in Rivonia
The ideal candidate will have strong experience in the following:
Data cleaning
SQL Export
Big data Sets

BSc Degree in Maths and Stats will be required
a min of 3 years experience.
Stable track record is required.

Send your Cv to marinda@prrrecruitment.co.za",-1,PRR Recruitment Services,Johannesburg,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Description

Position at Aculocity, LLC

At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes
Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.
Key Responsibilities
Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.
Key Traits
Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern
Position Requirements
2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.
Where will you work? This role will be based out of Durbanville, South Africa.",-1,GVW,Durbanville,-1,Unknown,-1,Unknown,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Information Technology, Gauteng JHB - Northern Suburbs

Market related - Market related Annually

An IT Consultancy Business based in Johannesburg is currently looking for a Business Intelligence Consultant / Data Engineering Consultant.

Requirements:

Extensive experience in data engineering
Experience in Business Intelligence, data and Power BI
Extensive experience in data governance and the Popi act
Ability to assess and make recommendations on data within the Popi act
Good understanding of T-SQL and query optimization, developing ETL strategies.
Good understanding with SQL Server 2008/2012, SSIS, SSRS and SSAS
Use SSIS to create ETL packages to validate, extract, transform, and load data into the data warehouse and data marts.
Deploy and configured the reports in the Report Server (SSRS).
Excellent experience in Tabular Modelling , PowerView, Qlikvie,w, and Power BI
Maintain ETL
Qlikview model
Create Drill-through, Drill-down, and Cross Tab Reports and Sub-Report using Report Definition Language (RDL).
Generate periodic reports based on the statistical analysis of the data using SQL Server Reporting Services (SSRS)
Advise and provide written technical documentation and recommendations

The information displayed above is not limited to advertisements. Please contact Thato for further information.

Please consider your application as unsuccessful if you have not received a response within 14 days of submitting your application. However, please keep a lookout on our website, www.bedifferent.co.za, for available positions that you may be suited for

Ad Visible Until: 29 October 2020
Ref: JHB005346/NL

Vacancy Type: Permanent",2.9,"Be Different Recruitment
2.9",Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Cloud Support Engineer (Big Data),-1,"ABOUT US

Amazon Web Services is the market leader and technology forerunner in the Cloud business. As a member of the AWS Support team you will be at the forefront of this transformational technology, assisting a global list of companies and developers that are taking advantage of a growing set of services and features to run their mission-critical applications. As a Cloud Support Engineer, you will act as the Cloud Ambassador across all the cloud products, arming our customers with required tools & tactics to get the most out of their Product and Support investment.

Would you like to use the latest cloud computing technologies? Do you have an interest in helping customers understand application architectures and integration approaches? Are you familiar with best practices for applications, servers and networks? Do you want to be part of a customer facing technology team helping to ensure the success of Amazon Web Services (AWS) as a leading technology organization?

If you fit the description, you might be the person we are looking for! We are a group of smart people, passionate about cloud computing, and believe that world class support is critical to customer success.

WHAT CAN YOU EXPECT FROM A LIFE AT AWS?

Every day will bring new and exciting challenges on the job while you:

· Learn and use groundbreaking technologies.
· Apply advanced troubleshooting techniques to provide unique solutions to our customers' individual needs.
· Interact with leading engineers around the world.
· Partner with Amazon Web Services teams to help reproduce and resolve customer issues.
· Leverage your extensive customer support experience to provide feedback to internal AWS teams on how to improve our services.
· Drive customer communication during critical events.
· Drive projects that improve support-related processes and our customers technical support experience.
· Write tutorials, how-to videos, and other technical articles for the developer community.
· Work on critical, highly complex customer problems that may span multiple AWS services.

WHY AWS SUPPORT?

· First and foremost this is a customer support role in The Cloud.
· On a typical day, a Support Engineer will be primarily responsible for solving customers cases through a variety of customer contact channels which include telephone, email, and web/live chat. You will apply advanced troubleshooting techniques to provide tailored solutions for our customers and drive customer interactions by thoughtfully working with customers to dive deep into the root cause of an issue.
· Apart from working on a broad spectrum of technical issues, an AWS Support Engineer may also coach/mentor new hires, develop & present training, partner with development teams on complex issues or contact deflection initiatives, participate in new hiring, write tools/script to help the team, or work with leadership on process improvement and strategic initiatives.
· Career development: We promote advancement opportunities across the organization to help you meet your career goals.
· Training: We have training programs to help you develop the skills required to be successful in your role.
· We hire smart people who are keen to build a career with AWS, so we are more interested in the areas that you do know instead of those you havent been exposed to yet.
· Support engineers interested in travel have presented training or participated in focused summits across our sites or at specific AWS events.
· As we operate on a follow-the-sun model, with Premium Support sites located globally, there is no after hours on-call or mandated overtime in this role.
· https://www.youtube.com/watch?v=GC3bWcFFZTo&t=24s



Basic Qualifications

The Big Data role supports our services that leverage data and produce business insights, which may include using Machine Learning/Artificial Intelligence (ML/AI). Helping our customers use and integrate Big Data services in what is arguably our industrys most exciting space. The portfolio of services covers EMR (Hadoop), DynamoDB (NoSQL), MangoDB, and Apache Cassandra.

· Advanced experience in Apache Hadoop, Apache Spark, Apache Hive, and Presto
· Advanced experience in DynamoDB or NoSQL technologies like MongoDB or Cassandra
· Advanced experience with System Administration with Linux (RHEL/CentOS) including Microsoft Active Directory, and LDAP integration.
· Experience with troubleshooting Kerberos Authentication problems.
· Experience with Network troubleshooting.
· Basic understanding of Machine Learning and statistics
· Experience with Java and Python and shell scripting
· Bachelors degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position



Preferred Qualifications

· Expert experience in the Hadoop Ecosystem including Apache Spark and Presto
· Expert experience in NoSQL
· Expert experience with blockchain technologies like Etherium Expert experience in data Data Lake architecture and administration
· Experience managing full application stacks from the OS up through custom applications
· Prior work experience with AWS - any or all of EC2, VPC, S3, RDS, EMR, Glue, SageMaker
· Excellent knowledge of Hadoop architecture, administration and support
· Expert understanding of distributed computing principles and their application in the cloud
· Good understanding of distributed computing environments Lead technical discussions on big data systems architecture and design
· Strong analysis and troubleshooting skills and experience
· AWS Certified Solutions Architect
· AWS certified Big Data Specialty
· Masters degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity and Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Response Center Engineer,-1,"Job Title
Response Center Engineer
Job Description


Philips is a world leading health technology company with a vision to make life better for people worldwide through meaningful innovation. Making good on this promise depends on our passionate, inspirational, collaborative and diverse team. We have over 80,000+ brilliant people around the world but are always looking for more. Like-minded, motivated, focused minds to join us in creating a healthier, more connected society while transforming themselves personally and professionally.

As a CCC Coordinator - Response Center Engineer you will have the opportunity to process customer calls and be responsible for screening and diagnosing professionally Healthcare equipment to support customers and colleagues remotely with solving technical issues and ensuring maximum customer satisfaction

You are responsible for:
Diagnose healthcare equipment to the quality standards set by Philips Healthcare (PH) remotely by interviewing customers or colleagues by telephone or by remotely logging in to the system
Advise Customer Care Center Coordinators and District Operations Managers and / or Team Leads about the best follow-up w.r.t. technical state of the diagnosed healthcare equipment
Advise the Customer Care Center Coordinators or Field Services Engineers about required spare parts and resources
Responsible for planning engineers related to Modality responsibility.
Responsible for coordination between CCC, CUSTOMER, Spare parts AND Engineer.
Responsible to drive Remote and FTR KPI’s to targets respectively 40% and 85%.
Will require minimal field work to keep abreast of technical capabilities.
Take calls from customers and make sure they are processed in the CCC ERP on timely manner including all relevant data
Support Field Services Engineers in the field with technical knowledge
Escalate technical issues to the Technical Support Specialist
Escalate technical issues to Business Unit support after consultation of the Technical Support Specialist
Monitor critical functions of the equipment’s in the IB and environmental conditions including RSN and True reachability.
Lead the planning and implementation of FSN’s and FCO’s accelerating remote implementation where applicable.
Submit timely and accurate service data, job sheets, reports, expense claims, radiation film badges, field problem reports and other paperwork as assigned
Keep abreast of new technologies likely to affect PH range of products
Use company property with care to ensure optimal results with minimal operational costs
Be a professional representative for PH with respect to customer problems, ensuring personal acceptability by the customer in behavior in accordance with PH policy and targets
Conform to PH safety standards including health and safety regulations and in the event of hazards or accidents to take immediate control of the situation and involve the Operations Manager and / or the responsible person to handle properly confidential issues according Philips standards and to act according General Business Principals
Follow all quality standards within the frame of valid PH business policies
Follow the company quality regulations (ISO 9001; PQA; TQM) and internal directives and procedures
You are a part of the dynamic South Africa Customer Care Centre Team .You will be reporting to the Customer Care Center Manager.

Requires a pleasant, assertive individual you can work very well in a team setting, a dynamic environment that requires flexibility and creativeness to achieve goals.

To succeed in this role, you should have the following skills and experience:
Degree level education or equivalent
Experience in maintenance and troubleshooting of technical complex systems
Fluent in English, verbal and written in addition to local language
In return, we offer you the unique combination of a critical and challenging role and a creative and empowering office environment. You will be actively encouraged to make improvements, establish best in class service and have a direct impact on the success of Philips on a daily basis.

Employment Equity

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply. Only apply for this role if you are a South African Citizen by birth or Naturalization prior to the 27 April 1994.

Why should you join Philips?

Working at Philips is more than a job. It’s a calling to create a healthier society through meaningful work, focused on improving 3 billion lives a year by delivering innovative solutions across the health continuum. Our people experience a variety of unexpected moments when their lives and careers come together in meaningful ways. Learn more by watching this video.

To find out more about what it’s like working for Philips at a personal level, visit the Working at Philips page on our career website, where you can read stories from our employee blog. Once there, you can also learn about our recruitment process, or find answers to some of the frequently asked questions.

Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.9,"Philips
3.9",Johannesburg,-1,10000+ Employees,1891,Company - Public,Health Care Services & Hospitals,Health Care,$10 to $25 million (USD),-1
Software Development Engineer - EC2 Placement,-1,"Build the systems that optimize how EC2 matches requests for Instances with the underlying compute capacity. EC2 Placement is seeking talented engineers to build the online and offline optimization systems for compute workload scheduling, and the customer capabilities to better manage those workloads. Amazon EC2 provides on-demand scalable compute capacity, and powers some of the largest services in the world. You will collaborate with a top-tier community of engineers to build systems to improve how customers are able to access EC2 compute resources.

The successful candidate will have strong software engineering experience, with a passion for thinking about, building and testing distributed systems. You have an interest in how Machine Learning and other optimization techniques can be applied to large-scale problems. You have demonstrated experience working with a team to design, build and operate large-scale systems. With strong engineering fundamentals, an analytical and data-driven approach to your work, and strong communication skills, you have the ability to collaborate well to deliver results. We move fast and work together on small teams to solve big problems.

If this opportunity sounds interesting, we would love to talk to you more about our work and the vibrant culture at AWS in Cape Town.

Basic Qualifications

· Degree in Computer Science or related field, or equivalent working experience
· 3+ years of industry experience in a software development environment
· Strong Computer Science fundamentals, including data structures, object-oriented design, algorithm design, problem solving, and complexity analysis.
· Proficiency in at least one modern programming language, such as Java, C#, Python, Scala, Kotlin

Preferred Qualifications

One or more of the following help you stand out:
· Demonstrated results designing, building and operating high-performance distributed systems in large-scale Linux environments
· Role model in writing high-quality, maintainable and secure code, mentoring others, and helping teams sharpen their development processes
· Ability to work effectively across teams to deliver results, with strong verbal and written communication skills
· Experience working with machine learning systems

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer - PBB IT,-1,"Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose


This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes
Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems
Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions
Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.

Research and best practices
Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development
Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.
Preferred Qualification and Experience
Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Aws Data Platform Engineer,-1,"Aws Data Platform Engineer

Posting Country:

South Africa

Date Posted:

15-Oct-2020

Full Time / Part Time:

Full Time

Contract Type:

Permanent

Joining Vodacom is more than a job, what we do matters. We don’t just carry minutes, texts and data – we carry people’s lives. And that’s a huge responsibility. If you think for a minute about the people you rely on…the likelihood is they rely on us.

Customers are at the heart of everything we do and we want to make a difference to the lives of our customers, and the communities in which we live and work. We support our people to give something back to the causes that mean the most to them through helping them give time and money to the charities they love.

And what’s it like to work here? We have created an environment where you can look forward to coming to work and are empowered to be at your best. We offer flexibility in how you work that helps you do your job in a way that suits you, opportunities to help you grow and progress throughout your career and a choice of benefits to suit your lifestyle.

Role Purpose
The H Band AWS Data Platform Engineer position is based within the Technology Business Unit.

The AWS Data Platform Engineer will be responsible for all Database services such as RDS, DynamoDB, etc. Should be able to migrate any databases from anywhere to AWS using any third-party tools or AWS database migration tool. Should also have understanding or expertise in creating data warehouses and data lake solutions on AWS.
Your responsibilities will include:
Apply practical knowledge of relational database design and usage with customers
Perform workload analysis and undertake performance tuning, as well as performance benchmarking in customer environments.
To develop state of the art solutions which are technically sound.
To provide a high-quality service to the Enterprise Cloud Services clients i.t.o. consultancy, solutions and delivery.
Commitment to team success and positive team dynamics including mentoring of other team members.
Passion for growing and applying technical skills in service to customers.
Be a trusted infrastructure advisor by providing objective, practical and relevant ideas, insights and advice.
Work collaboratively with consulting partners and technology teams to ensure high quality of solution delivery.
Encourage best practice and knowledge sharing with partners and cross-functional groups
Manage the overall database design and delivery of solutions.
Ability to make recommendations as they pertain to improvements in support/development initiatives and facilitate implementation with partners and cross-functional groups within the Business.
Participate in high level database solution definition and design during the implementation phase with the goal of providing reliable, stable and operationally sound applications that meet the Business requirements.
Ability to understand and translate business requirements into technical specifications
The ideal candidate will have:
A minimum of 3 years of industry related experience of which 1 year must be within a complex hosting environment.
Certifications in Database design, system architecture or cloud technologies.
Demonstrate knowledge of database systems internals including storage layouts and distributed databases/MPP architectures
Advanced SQL coding, tuning and query optimization.
Experience designing and leading database performance benchmarks.
Good knowledge of the different AWS services
Knowledge of cloud networking architecture, cloud operations, security, automation and orchestration.
Knowledge of database internals as it relates to query and system performance and tuning.
Understanding of overall system architecture, scalability, reliability, and performance in a database environment.
Excellent teamwork, time-management and organizational skills.
Perform other duties as deemed necessary and assigned by the customer and management
Strong interpersonal skills and problem-solving abilities.
Excellent documentation, communication and interpersonal skills.
Excellent analytical and problem-solving abilities.
Closing date for applications: Monday, 13 April 2020

The base location for this role is Vodacom World, Midrand

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply.
Vodacom is committed to an organisational culture that recognises, appreciates and values diversity & inclusion.

Commitment from Vodacom

Vodacom is committed to attracting, developing and retaining the very best people by offering a flexible, motivating and inclusive workplace in which talent is truly recognized, developed and rewarded. We believe that diversity plays an important role in the success of our business and we are committed to creating an inclusive work environment which respects, values, celebrates and makes the most of people’s individual differences - we are not only multinational but multicultural too. At Vodacom you will have access to our excellent flexible benefits programme that you would expect from any global company.",3.9,"Vodafone
3.9",Midrand,-1,10000+ Employees,1982,Company - Public,"Cable, Internet & Telephone Providers",Telecommunications,$10+ billion (USD),-1
Data Engineer Azure Data Factory,-1,"Enthuzex is looking for a motivated Lead Data Engineer to contribute towards the success of our Data and Analytics Technology initiatives. This is a hands-on technical role and this person will be responsible for the development and build of scalable solutions as it relates to the architecture strategies, data standards, digital data management, data integration, tools, and technology. The right candidate will play a deep dive hands-on critical development role in the digital transformation and in shaping how we acquire, ingest, transform and deliver data through the digital consumer channels.

Responsibilities:

Architect, design, develop and engineering end-to-end data pipelines across multiple data sources and systems of record.
Ensure data quality, integrity, security and completeness throughout the data lifecycle
Develop, design data models, data structures and ETL jobs for data acquisition and manipulation purposes
Develop deep understanding of the data sources, implement data standards, maintain data quality and master data management
Developing data services and API
Work closely with the cloud service providers to ensure completeness and alignment with the service offerings
Manage and maintain cloud based data and analytics platform
Deep understanding of the cloud offerings and engage in quick proof of concepts and proof of value in prototyping data and analytics solutions and derive viability
Ability to interact with the business stakeholders to understand requirements and translating into technology solutions

Expirience:

Experience in Cloud platform AWS or Azure eco-system. (Azure preferred)
Data Engineering/Development experience with SQL (Oracle, SQL Server, MySQL)
Strong development background creating pipelines and complex data transformations and manipulations using one of the languages Python, Java, R, or Scala with Databricks/Spark
Experience in NoSQL Databases and Big data technologies including Hadoop
Experience with API / RESTful data services
Worked on real-time data capture, processing and storing using technologies like Azure Event Hubs and Analytics
Experience working with different data storage options including AWS S3, Azure BLOB storage etc.
Understanding of different data formats including Parquet, Avro, CSV, ORC etc.
Prior experience with MPP databases and maintain large amount of data processing
Experience with Azure Data Factory and Azure Data Catalog is a big plus and mandatory
Experience with Microsoft/Azure ETL solutions and business Intelligence technologies is a big and mandatory
Past working experience on a fast paced and agile environment
Perform ongoing monitoring, automation and refinement of data engineering solutions
Experience in leading high visibility transformation projects that interacts with multiple business lines
Build and meet project timelines and manage delivery commitments with proper communication to management

Qualifications

Bachelor’s degree with 4+ years of relevant experience
Willingness to learn new technologies and thrive in an extremely fast paced environment
Team player and easy to work with.

Applicants must demonstrate their ability to master new enterprise level technologies. Successful applicants will exemplify Enthuzex ethical principles of uncompromising integrity, respect for others, and accountability for decisions

send cv's info@enthuzex.co.za",-1,Enthuzex,Leslie,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Scientist,-1,"The world is changing.

We all want something different.

At Luno, we see you as an individual.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the world, and to do so, we need the best team on board for our mission.

A bit about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 3 million customers across 40 countries.
We are Series B funded, backed by Balderton Capital and the Naspers Group.
Our platform has processed over 8 billion dollars since we've launched
We're proud to be one of the world's most international cryptocurrency teams from 26 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
The role in a nutshell:

Identifying opportunities in the business that could benefit most from cognitive applications, as well as building and enhancing organisational capabilities for deriving value from multiple data sources using data science.

What we'd like you to have:
Bachelor's degree or higher in the natural sciences or technical fields such as Mathematics, Statistics, Computer Science, Engineering or Economics
Enthusiasm to work in the cryptocurrencies space
Advanced SQL skills
Solid understanding of exploratory data analysis, predictive analytics, and optimisation using Python, R, Matlab, RapidMiner, KNIME or other data science-oriented platforms
Proficiency in the use of data science and machine learning domain-specific languages such as ""Caret"" and the ""Tidyverse"" suite of tools in R, or ""Pandas"" in Python
Strong interpersonal and communication skills
Communicating data insights using storytelling narratives
Ability to work independently, as well as within and across teams
Ability to successfully complete projects with large and/or incomplete data sets
More about what you'll be doing:
Optimising product performance by tracking and analysing customer behaviour on web and app, in collaboration with software engineers and product designers
Providing the business with reports and dashboards, on key performance metrics
Developing metrics to accurately assess the health of our Exchange platform
Comparative data-driven analysis of our Exchange against alternative platforms
Formulating business requirements into analytical objectives
Designing and running experiments to test hypotheses
Hacking through complex business problems using advanced data analysis to provide insights and recommendations
Building, maintaining, and optimising decisioning systems using advanced statistical and predictive modelling techniques
What will set you apart:
An advanced degree in Mathematics, Statistics, Computer Science or related field
At least 3 years' experience working in a similar role
A basic understanding of trading in financial markets
Experience working with a data analytics and visualisation platform such as Tableau, Cognos, QlikView, or Looker
Familiarity with using Google Analytics to understand customer behaviour
Solid knowledge of statistical and machine learning techniques
Familiarity with modern distributed data storage and processing systems such as Amazon Redshift, Big Query, Snowflake, Databricks and Apache Spark
You can gather and synthesise facts, theories, trends, patterns, inferences, and key issues in complex and variable situations
Ability to diagnose problems using formal problem-solving tools and techniques from multiple angles to generate multiple possible solutions
A sense of anticipating long-term problem areas and associated risk levels with objective rationale
Remote Life at Luno

If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
You'll be able to continuously upskill yourself with access to free online learning via MyAcademy, an international teaching marketplace with over 100000 courses from Harvard and other leading providers + share knowledge with your peers.
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity and paternity leave, and you can even take paw-ternity leave for your furry friend.
Annual Inspiration Day! Make time for that pottery course or spa day you've always wanted to do.
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"EY is a global leader in
assurance, tax, transaction and advisory services. Technology is at the heart
of what we do and deliver at EY. Technology solutions are integrated in the
client services we deliver and are key to our innovation as an organization.

Fueled by
strategic investment in technology and innovation, Client Technology seeks to
drive growth opportunities and solve complex business problems for our clients
through building a robust platform for business and powerful product engine
that are vital to innovation at scale. As part of Client Technology, you’ll
work with technologists and business experts, blending EY’s deep industry
knowledge and innovative ideas with our platforms, capabilities, and technical
expertise. As a catalyst for change and growth, you’ll be at the forefront of
integrating emerging technologies from AI to Data Analytics into every corner
of what we do at EY. That means more growth for you, exciting learning
opportunities, career choices, and the chance to make a real impact.

The selected
candidate
Develops
large and complex data architecture, composed of models, policies, rules or
standards that govern which data is collected and how it is stored, arranged,
integrated and put to use in data systems, including the design, build and
management of data infrastructure to address business requirements
Creates
sound use case driven roadmaps, depicting data architecture as-is and to-be
capabilities with the business by engaging with multidisciplinary teams, and by
identifying, managing and mitigating risk
Develops
relationships across the business to understand data requirements, applies deep
technical knowledge of data management to solve business problems in areas
where solutions may not currently exist, necessitating new solutions/ways of
working/technologies and proactively articulating these to the business
Review,
identify the latest emerging technologies, augmenting by services from the
leading cloud providers to solution and recommend the best next generation data
platform value driven approach for our clients
Your Key Responsibilities Include
Create
and maintain conceptual, logical and physical database models
Document
functional requirements and system specifications into the data architecture
and detailed design specifications for current and proposed designs
Document
and adhere to development standards and best practices in database designs
Maintain
highly effective and consistent communication within the team, peers, and the
leadership team
Reverse
engineer SQL code and modify it to solve problems/issues
Contribute
to the definition and implementation of data governance practices
Design
both data structures and data integration practices
Work
closely with the infrastructure teams to create a physical environment to
support data services
Evaluate
new and existing (internal and external) technologies and services in support
of data services and data analytics objectives
Skills And Attributes For Success
Understanding
of business process reengineering and business modeling concepts, business
systems development and analysis
Hands-on
experience in designing and implementing hybrid cloud and on-prem solutions
Experience
working with the latest versions of SQL Server
Experience
applying SAFe/Scrum/Kanban methodologies
Ability
to exercise judgment in solving technical, operational, and organizational
challenges
Expert
programming, performance tuning and troubleshooting skills, using the latest
popular programming languages for example python
Demonstrate
proactive approach to identifying issues and presenting solutions and options,
and where appropriate, leading to resolution
Minimum Qualifications
5+ years
demonstratable work experience as a Data Architect using data modeling tools
2-3 years
SQL coding experience on large projects
Must
possess expert SQL programming, performance tuning and troubleshooting skills
Create
database objects and SQL scripts
Understand
and developed data pipelines
Know how
to deformalize data for data science models
Experience
in python, spark and notebooks
Experience
designing data warehousing solutions
Experience
designing next generation data platforms utilising cloud services
In-depth
understanding of database structure principles
Seamlessly
able to translate business requirements to technology requirements
What We Look For
Strong
analytical skills and problem-solving ability
A
self-starter, independent-thinker, curious and creative person with ambition
and passion
Excellent
inter-personal, communication, collaboration, and presentation skills
Customer
focused
Excellent
time management skills
Positive
and constructive minded
Takes
responsibility for continuous self-learning
Takes the
lead and makes decisions in critical times and tough circumstances
Attention
to detail
High
levels of integrity and honesty
Curious
about new emerging technology
About EY
As a global leader in assurance, tax, transaction and consulting
services, we’re using the finance products, expertise and systems we’ve
developed to build a better working world. That starts with a culture that
believes in giving you the training, opportunities and creative freedom to make
things better. Whenever you join, however long you stay, the exceptional EY
experience lasts a lifetime.",3.8,"EY
3.8",Johannesburg,-1,10000+ Employees,1989,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Architect - Principal,-1,"We are looking for Principle Data Architect to join our Engineering team in Cape Town.

The world is changing.
We all want something different.
At Luno, we see you as individuals.

Together, we are upgrading the world of work to unleash the potential within and empower you to become the best possible version of yourself.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the financial landscape, and to do so, well we need the best team on board for our mission. In short, to achieve our goals, we need rockstars. As simple as that.

A little about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 5 million customers across 40 countries.
We're part of the Digital Currency Group, a group of companies driving progress in the cryptocurrency and blockchain space that includes Grayscale, Genesis, Coindesk and Foundry Services
Our platform has processed over $8 billion to date
We're proud to be one of the world's most international cryptocurrency teams from 43 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
How we work


Our engineering team (currently ~100 engineers) is split into organisations which we call Fleets. Each Fleet focuses on a core customer journey (onboarding, security, payments, support, new business, growth and marketing etc.). Each of these fleets contains multiple smaller teams called Pods, each of which focuses on a specific aspect of the product.

Pods will include a product owner, product designer, back-end engineers, Android, iOS and Web developers, who each bring a unique perspective to the problem you are all contributing towards.

We're agile, use scrum, continuous integration and continuous delivery, deploying to production every single day.

We're building teams to help us succeed in our mission to upgrade the world to a better financial system. You'll be joining a group of highly motivated software engineers who you'll work collaboratively with across our pods.

As a fast-growing company with offices around the world, you'll immediately see how your contributions directly impact both our internal users and client experience. Many of the problems we are solving result in trail blazing solutions which can't be found on Stack Overflow; so we're looking for engineers who flourish working in a complex domain.

In your first six months, you will:


...start at Luno by learning our processes, meeting the wider team and starting our engineering on-boarding program. After getting comfortable with the basics, you'll start learning our idiomatic patterns in a safe, easy-to-follow way - by building your own toy micro services. You'll get to practice how we do design docs, code reviews, deployments, events, logging and monitoring.

You'll meet the Pod(s) you'll be working with and quickly align on the teams' current OKRs and product roadmap. We succeed as a team, so we will provide you with regular feedback from your manager and peers and will encourage you to do the same.

What you'll do:
Work closely with our data science and platform teams on projects introducing new streams of data into our data lake
You will get to bring new ideas on how to further develop and innovate our data solutions and how to expose that data to the business
Accountable and Responsible for the design and architecture of Data systems that are robust and scalable.
Work in an Agile/Scrum framework or Agile mindset
Data backup/recovery and storage
Pick-up and learn new concepts, in both engineering and product, and be able to apply that knowledge quickly.
The ideal candidate for this role will have:
7+ years' experience in maintaining scalable data solutions and/or you are passionate about it
Ability to understand, communicate and advocate between build vs buy
Proven track record of setting up, restructuring and maintenance of databases
You know your way around ETL and you have experience with SQL
Experience in the AWS Data stack (RedShift,DynamoDB, Amazon RDS)
Familiarity with integrating data stores with BI platforms such as Looker, Tableau, or Power BI
You have experience with the concepts of CI/CD
Coding skills in e.g. Go, Python
Bachelor's degree in a related field preferred
AWS Certified DataOps Administrator
Be friendly, transparent, articulate and driven to succeed
Basic knowledge of and passion for digital currencies like Bitcoin
A work permit for South Africa if you are not a South African citizen
Don't be put off if you don't tick all of the boxes – they're a guide based on what we'd love to see but we appreciate that excellent software engineers have diverse backgrounds.

Remote Life at Luno


If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity / paternity and even (yes, you are reading it correctly) paw-ternity for your furry friend..
Annual Inspiration Day.. like that pottery course you've always been meaning to do!
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. You'll need to hold the legal right to work in South Africa already as we cannot provide visa sponsorship.

Be part of the change!",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer - EC2 Capacity Data Analytics,-1,"EC2 Capacity Data Analytics (CDA) team is looking for a Data Engineer to join our team.

Our team is part of the EC2 Capacity Engineering organization, which is responsible for providing the elasticity EC2 customers need to scale up/down compute resources in a cost-efficient manner. We predict customer usage across thousands of configuration combinations to deliver exactly what our customers require in just the right amount of time with just the right amount of capacity.

As a Data Engineer, you will build the ETL and analytics solutions for our internal customers to answer questions with data and drive critical improvements for the business. You will use best practices in software engineering, data management, data storage, data compute, and distributed systems. On any given day, we use Python, Scala, Java, SQL, Lambda, CloudFormation, Redshift and Glue as well as other public AWS services and a host of Amazon internal tools. We dont expect you to be an expert in, or necessarily even be familiar with all of the technologies listed above, but we do expect you to be excited to learn about them.

This position involves on-call responsibilities, typically for one week every two months. Our team is dedicated to supporting new team members. We care about your career growth, we try to assign projects and tasks based on what will help each team member develop into a more well-rounded engineer and enable them to take on more complex tasks in the future.

Our team values work-life balance and we are flexible when people occasionally need to work from home.

Job Duties
Develop and maintain automated ETL pipelines for big data using languages such as Scala, Spark, SQL and AWS services such as S3, Glue, Lambda, SNS, SQS, KMS. Example: ETL jobs that process a continuous flow of JSON source files and output the data in a business-friendly Parquet format that can be efficiently queried via Redshift Spectrum using SQL to answer business question.

Develop and maintain automated ETL monitoring and alarming solutions using Java/Python/Scala, Spark, SQL, and AWS services such as CloudWatch and Lambda.

Implement and support reporting and analytics infrastructure for internal business customers using AWS, services such Athena, Redshift, Spectrum, EMR, and QuickSight.

Develop and maintain data security and permissions solutions for enterprise scale data warehouse and data lake implementations including data encryption and database user access controls and logging.

Develop and maintain data warehouse and data lake metadata, data catalog, and user documentation for internal business customers.

Develop, test, and deploy code using internal software development toolsets. This includes the code for deploying infrastructure and solutions for secure data storage, ETL pipelines, data catalog, and data query.


Basic Qualifications

· Bachelors degree in Computer Science or related technical field, or equivalent work experience.
· 4+ years of overall work experience including Software Engineering, Data Engineering, Database Engineering, Business Intelligence.
· Experience with AWS technologies stack including Lambda, Glue, Redshift, RDS, S3, EMR or similar big data solutions stack

Preferred Qualifications

· Demonstrate efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data.
· Demonstrable proficiency in distributed systems and data architecture; design and implementation of batch and stream data processing pipelines; knows how to optimize the distribution, partitioning, and MPP of high-level data structures.

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer,-1,"Our client based in Johannesburg is urgently looking for a Data Engineer to be on a 3 months contract
Build data pipelines, experience in new tech like nifi, kafka, python

Joburg based, open to EE, 3 month contract with the option to extend, must be available at short notice",-1,EQplus,Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Overview
Job ID: 51456
Job Sector: Information Technology and Services
Country: South Africa
Region/State/Province/District: Gauteng
Location: Johannesburg

Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose

This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes

Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems

Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions

Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.
Research and best practices

Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development

Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.

Preferred Qualification and Experience

Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry

Knowledge/Technical Skills/Expertise

Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision

PLEASE NOTE: All our recruitment and selection processes comply with applicable local laws and regulations. We will never ask for money or any form of payment as part of our recruitment process. If you experience this, please contact our Fraudline on +27 800222050 or forward to TransactionFraudOpsSA@standardbank.co.za",4.1,"Standard Bank
4.1",Johannesburg,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"About us

At PBT Group we pride ourselves on being a Data Specialist organisation. With 20 years of experience in 27 countries over 3 continents, our team of 550 consultants have implemented more than 700 projects.",4.3,"PBT Group
4.3",Johannesburg,-1,Unknown,-1,Company - Private,Accounting,Accounting & Legal,Less than $1 million (USD),-1
Data Engineer,-1,"Kick-start your career in the online gaming world and experience the very latest in technology and innovation.

The Department:

Our mission is to provide our customers with the best online betting experience and share the thrill of gaming with them. Data is at the very heart of our business and is vital in everything we do.

Our cross-functional Data team has a big and exciting challenge ahead. We are in the process of re-platforming our traditional, on-premises RDBMS environment to a new microservice architecture in the cloud. We’re making use of the diverse set of data technologies in Microsoft Azure to offer new services, reporting structures and real-time data pipeline while serving the day-to-day requirements of a rapidly growing, data-hungry organisation.

Purpose of the Role:

This is an excellent opportunity for an individual who is looking to gain new skills. We are committed to creating a culture of learning and regularly run proof of concepts, provide internal demos, manage workshops and attend external conferences. Our data team has a wide range of skills including development for highly transactional RDBMS systems, data warehousing, data science and cloud technologies and we are always working to raise everyone’s game.

Duties include, but not limited to:

Work as part of an agile Data Engineering Team
Development of greenfield projects in Azure
Develop and maintain on-premises RDBMS/DW systems
Create robust ETL services and real-time data pipelines
Build and maintain Continuous Integration and DevOps pipelines
Test-driven development and pair programming with colleagues

Essential Criteria:

C#, .Net, Visual Studio
Git, Azure DevOps
NoSQL development (CosmosDB)
Demonstrable understanding of MS SQL Server in a highly transactional environment
Demonstrable understanding of development in Microsoft Azure
Able to understand query plans and identify performance bottlenecks
Test/Business-Driven Development
Building Continuous Integration/Deployment pipelines
Communicate effectively with both technical and non-technical stakeholders

Desirable Criteria:

Implementing Data Storage and Processing solutions in Azure (ARM Templates, Storage Accounts, Data Lake Storage, SQL DB, Cosmos DB, EventHubs, Function Apps, Log Analytics, Data Factory, Databricks, Polybase)
Implementing Security, Disaster Recovery, High Availability, Auditing, Monitoring and Alerting solutions in Azure
Automating tasks in Azure using Powershell / CLI
Predicting costs and optimizing spending in Azure
Message Queues (RabbitMQ, Kafka)
Python

Person Specifications:

Resilience
Teamwork
Technical Knowledge
Communication skills
Stress Tolerance
Please note we will apply relevance to our Talent Management and Talent Development Programme as part of our recruitment process.
Shortlisted candidates may need to complete an assessment.
This position requires trust and honesty it has access to customers financial details - therefore a credit and criminal record check will be conducted. The qualifications identified herein are an inherent job requirement; therefore, a qualification verification check will be done. By applying for this role, and supplying the necessary details, you hereby grant us permission to apply for these checks. This will be done in a confidential manner, and solely for the purposes of verification.

To view all current vacancies, please visit our website, www.digioutsource.com

Should you not hear from us within 2 weeks, please deem your application as unsuccessful.

The perfect place to work, play and grow!",3.9,"Digital Outsource Services
3.9",Cape Town,-1,1001 to 5000 Employees,1997,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
Data Engineer,-1,"At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes

Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.

Key Responsibilities

Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.

Key Traits

Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern

Position Requirements

2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.

Where will you work? This role will be based out of Durbanville, South Africa.",3.1,"Aculocity, LLC
3.1",Durbanville,-1,1 to 50 Employees,2006,Company - Private,IT Services,Information Technology,$1 to $5 million (USD),-1
Data Engineer,-1,"ENVIRONMENT:

A rapidly growing E-Commerce Platform seeks a highly talented Data Engineer to make an invaluable contribution to data democratisation and literacy vision by making accessible and easy-to-use data products and tools. You will require a Comp-Sci Degree or 3 years’ relevant industry experience, MySQL, PostgreSQL, Java, Python, in-depth understanding of OLAP, Data Marts, Star Scheme, Snowflake, be familiar with Jenkins, Travis, Circle CI, Docker, Kubernetes, experience with Kafka, Pub/Sub, Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks & significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing & Data Lake design and implementation and Lambda/Kappa architectures.

DUTIES:

Design, develop, test and maintain data architecture.

Prepare data for descriptive, predictive and prescriptive modelling.

Automate repetitive tasks and manual processes related with the data usage.

Optimize data delivery.

Design, develop and test large stream data pipelines to ingest, aggregate, clean, and distribute data models ready for analysis.

Ensure the highest standard in data integrity.

Leverage best practices in continuous integration and delivery.

Collaborate with other engineers, ML experts, analysts, and stakeholders to produce the most efficient and valuable solutions.

Implement features, technology, and processes that move us towards industry best practices, improving on scalability, efficiency, reliability, and security.

Operations and ownership of systems in production, responding to incidents.

REQUIREMENTS:

Qualifications –

Comp-Sci Degree or 3 years relevant industry experience.

Experience/Skills –

Open source relational database systems e.g. MySQL, PostgreSQL, etc.

Significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing, and Data Lake design and implementation and Lambda/Kappa architectures.

A thorough understanding of database and data warehousing principles e.g. OLAP, Data Marts, Star Schema, Snowflake, etc.

Java and Python.

Familiar with CI/CD tools such as Jenkins, Travis, Circle CI, etc.

Experience with Kafka, Pub/Sub, or other event-based systems.

Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks, etc.

Working in cloud environments and with containerisation frameworks, tools and platforms e.g. Docker, Kubernetes, GKE, etc.

A deep understanding of data pipelining, streaming, and Big Data technologies, methods, patterns, and techniques.

Troubleshooting complex database operations and performance issues.

Automating tasks using Shell Scripting or writing small applications.

ATTRIBUTES:

Works well with people and is passionate about helping people be their best.

A team player, an active listener, mentor, and able to communicate well.

Shows solid reasoning and decision making, with the ability to work under pressure.

Is passionate about technology, systems and data.

Is curious, always learning, and keeping up to date with the industry.

While we would really like to respond to every application, should you not be contacted for this position within 10 working days please consider your application unsuccessful.

COMMENTS:

When applying for jobs, ensure that you have the minimum job requirements. Only SA Citizens will be considered for this role. If you are not in the mentioned location of any of the jobs, please note your relocation plans in all applications for jobs and correspondence.",-1,Datafin IT Recruitment,Cape Town,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Cartrack is looking for passionate data science and engineering candidates that can join a growing team that is responsible for the intelligence and efficiency solution provision to over a million subscribers, many of whom are large fleets. We are in the midst of creating revolutionary platforms that will change the way that people interact with their vehicles.

You will have the opportunity to work with the very brightest global subject matter experts that are transforming the automotive industry across Fleet Management, Asset Management and Insurance Telematics solutions.

Get to know the role:

The role of a data engineer is a supporting one, but it is also an extremely vital one. As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements. We want to see candidates with mechanical tendencies and a desire to know how things work and to improve them.

The day-to-day activities:

Design, construct, install, test and maintain data management systems.
Build high-performance algorithms, predictive models, and prototypes.
Ensure that all systems meet the business/company requirements as well as industry practices.
Integrate up-and-coming data management and software engineering technologies into existing data structures.
Develop set processes for data mining, data modeling, and data production.
Create custom software components and analytics applications.
Research new uses for existing data.
Employ an array of technological languages and tools to connect systems together.
Install/update disaster recovery procedures.
Recommend different ways to constantly improve data reliability and quality.
Work on and maintain Data pipelines.

Requirements Essential:

At least 5 years’ proven experience as a Data Engineer, DevOps Engineer, Software Developer, or similar.
Proficient in Linux/Unix and shell scripting as well as in functional programming languages.
Expertise in setting up and explored with technologies such as Hadoop and Spark.
Bachelor’s degree in computer science, software/computer engineering, applied mathematics, or physics.",3.3,"Cartrack
3.3",Johannesburg,-1,501 to 1000 Employees,2004,Company - Private,Security Services,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Data Engineer,-1,"Data Engineers build and support data pipelines and datamarts built off those pipelines. Both must be scalable, repeatable and secure. The Data Engineer helps to facilitate gathering data from a variety of different sources, in the correct format, assuring that it conforms to data quality standards and assuring that downstream users can get to that data timeously. This role functions as a core member of an agile team. These professionals are responsible for the infrastructure that provides insights from raw data, handling and integrating diverse sources of data seamlessly. They enable solutions, by handling large volumes of data in batch and real-time by leveraging emerging technologies from both the big data and cloud spaces. Additional responsibilities include developing proof of concepts and implements complex big data solutions with a focus on collecting, parsing, managing, analysing and visualising large datasets. They know how to apply technologies to solve the problems of working with large volumes of data in diverse formats to deliver innovative solutions. Data Engineering is a technical job that requires substantial expertise in a broad range of software development and programming fields. These professionals have a knowledge of data analysis, end user requirements and business requirements analysis to develop a clear understanding of the business need and to incorporate these needs into a technical solution. They have a solid understanding of physical database design and the systems development lifecycle. This role must work well in a team environment.

Job Objectives

Work Complexity: * Architects Data analytics framework. * Translates complex functional and technical requirements into detailed architecture, design, and high performing software. * Leads Data and batch/real-time analytical solutions leveraging transformational technologies. * Works on multiple projects as a technical lead driving user story analysis and elaboration, design and development of software applications, testing, and builds automation tools.

Main Job Objectives: 1. Development and Operations 2. Database Development and Operations 3. Policies, Standards and Procedures 4. Communications 5. Business Continuity & Disaster Recovery 6. Research and Evaluation 7. Coaching/ Mentoring

Qualifications

Essential: 4 years Bachelors degree in computer science, computer engineering, or equivalent work experience AWS Certification at least to associate level

Experience

Essential:

5+ years Data engineering or software engineering

3-5 years demonstrated experience leading teams of engineers

2+ years Big Data experience

5+ years experience with Extract Transform and Load (ETL) processes

2+ years Could AWS experience

At least 2 years demonstrated experience with agile or other rapid application development methods - Agile exposure, Kanban or Scrum

5 years demonstrated experience with object oriented design, coding and testing patterns as well as experience in engineering (commercial or open source) software platforms and large scale data infrastructures.

Desirable:

5+ years Retail Operations experience

Knowledge and Skills

Essential: *Creating data feeds from on-premise to AWS Cloud (2 years) *Support data feeds in production on break fix basis (2 years) *Creating data marts using Talend or similar ETL development tool (4 years) *Manipulating data using python and pyspark (2 years) *Processing data using the Hadoop paradigm particularly using EMR, AWSs distribution of Hadoop (2 years) *Devop for Big Data and Business Intelligence including automated testing and deployment (2 years) * Extensive knowledge in different programming or scripting languages * Expert knowledge of data modeling and understanding of different data structures and their benefits and limitations under particular use cases.

Further technical skills required: * Capability to architect highly scalable distributed systems, using different open source tools. * Big Data batch and streaming tools * Talend (1 year) * AWS: EMR, EC2, S3 (1 year) * Python (1 year) * PySpark or Spark (1 year) - Desirable * Business Intelligence Data modelling (3 years) * SQL (3 years)",-1,Datonomy Solutions,Brackenfell,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We are assisting one of our clients that is based in Pretoria to fill a role of a Data Engineer

This is a 12 month contract role

Objective of this Scope of Work

The Data Engineer will drive improvement of the data management maturity levels and provide the necessary technical support within the company to support reliable and effective decision-making, appropriate usage and protection thereof.

Scope of Services Definition

The scope will include but will not be limited to:

ï†· To develop, construct, test and maintain architectures.

ï†· To ensure architectures will support the requirements of business.

ï†· To discover opportunities for data acquisition and sharing.

ï†· To develop data set processes for data modelling, mining and production.

ï†· To employ a variety of languages and tools to marry systems together.

ï†· To recommend way to improve data reliability, efficiency and quality.

ï†· To prepare data for use in predictive and prescriptive modelling.

ï†· To conduct research to answer industry and business questions.

ï†· To leverage volumes of data from internal and external to answer business questions.

ï†· To develop and manage stakeholder relations effectively to promote data management across the organisation and support reliable decision making and appropriate data usage.

ï†· To participate and provide technical support in cross organisational activities relating to any of the above mentioned data management activities.

ï†· To provide regular progress reports as per stakeholder requirements and present data management updates in various forums as required.

Minimum qualification Required:

ï†· A minimum of a Bachelors degree in Computer Science or Information Management OR equivalent;

ï†· A minimum of five to eight years experience in a data management environment",-1,HR Genie,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Our client based in the Northern Suburbs, is currently looking for a Data Engineer to join their team.

Responsibilities
Our client is a dynamic IT company that delivers value-driven IT solutions to the group. Our work lives revolve around our DNA. We take pride in our work, treat our colleagues, partners and our country with respect. We exercise collaborative decision-making and believe in having a balance in life. We do this all while having fun and enjoying what we do.

The primary focus of this position is to use technical skills to put software, systems and data together in a way that extracts meaningful insights from raw data. You will need to be helpful and supportive to your team and fellow developers. You join an energetic, focused and dynamic team.

Interact with clients to understand requirements and business problems/needs

Identify, analyse, visualise and understand supporting data to propose solid solutions

Create technical documentation for reference and reporting

Support existing solutions within GCP and Oracle

Doing standby on a rotating basis

Key Competencies and Qualifications

Matric

Tertiary qualification in IT

Preferred cloud experience in AWS/AZURE/GCP

At least 3 years of data warehouse ETL experience

Dimensional Modelling

Data analyses

Experience with data visualization and visualization tool(s)

Knowledge of the retail industry will be beneficial

Understanding and experience with version control SVN/GIT

Preferred – Korn shell scripting, Python/Java, SQL

Google Cloud Platform experience would be looked upon favourably

Having a broad understanding of different SDLC’s

Preferred agile experience

Strengths

The natural tendency to take ownership and responsibility

Strong problem solving, critical thinking, effective planning and organisational skills

Detail-oriented with excellent communication skills

You have a can-do attitude and positive outlook on life

Can cope under pressure

Curious and interested in analysing problems and possible solutions

Strong team player

Self-driven learner, passionate about new technology

Above all, be passionate about what you do

Should you wish to apply for the position, please apply directly via this job board, please ensure that you quote reference number 201620 subject heading or email body.

Please note that due to the high volume of CV's received; only shortlisted applicants will be contacted. Should you not receive communication from our offices within two weeks of submission please note that your application will not be considered for this position.

We will keep your CV on file and re-establish contact with you should opportunities in line with your expertise become available again.

Should you require any additional information give us a call on 021 012 5566.",-1,Surgo HR & Training,Cape Town,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We believe that our employees fuel our organization, essential to enable us to help our customers overcome their business challenges and achieve sustainable growth. As a result, we are committed to growing each individual and providing them with the challenges, feedback and support needed to achieve success in their career

If this sounds appealing, and like us, you get excited about data: its collection, storage, transformation or display, see if you’ve got what it takes to join our sought after DATA team.

Key Responsibilities And/or Outputs

You will represent IQbusiness at our customers, sometimes alone, and sometimes as part of an IQ team.

Providing a superior customer experience by building and maintaining relationships, working at customer offices, keeping data confidential
Design and develop – databases, SQL queries, stored procedures, reports, dashboards or integration solutions
Produce solutions for both real-time and batch environments
Test your work to ensure compliance
Solve problems, and do root cause analysis
Prioritize your workload
Assist in other areas relating to your true data function, such as data modeling, data and business analysts
Interact with a variety of individuals: senior, junior, technical and from business
Provide guidance to fellow colleagues, or even manage a team
Uphold the IQ values, which are to care, learn & share; innovate; deliver as well as to build, enhance and maintain relationships

Education

Matric pass
A tertiary qualification, preferably in an ICT relevant field
Appropriate Microsoft certifications are beneficial but not required

Requirements

3 - 6 years experience in the Data Engineering environments and technologies
Great communication skills
A passion for SQL, databases or reports
Can you write stored procedures, design complex queries and create views and triggers?
Are you able to work out the relationships in a data warehouse or the aggregation of a cube?
Do you extract and display useful information when you see patterns and trends in data?
Strong knowledge of the financial services industry, ideally in a consulting role
The use of data related software: databases, ETL and BI tools; report writing and analytical tools
We use a lot of Microsoft products. You may often be expected to use MS SQL Server, SSIS, SSRS, SSAS and Power BI to develop solutions
What other relevant software have you’ve used?
Ability to work in different project methodologies: Waterfall and/or Agile
Knowledge of full SDLC
Exposure to logical and physical data modeling

Equal Employment Opportunity

IQbusiness is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, citizenship, marital, domestic or civil partnership status, sexual orientation, or gender identity",3.7,"IQbusiness South Africa
3.7",Johannesburg,-1,1 to 50 Employees,-1,Company - Private,Consulting,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"We value a data engineer as someone who works behind the scenes to obtain, process and supply data via various methodologies and technologies, to various consumers, in ways and forms that makes sense and add value. This definition is very broad, as the field of data engineering is just as broad.

You may be the type of data engineer that develops API endpoints for the consumption of data by end users or even another data pipeline, or you may be the type of data engineer that develops highly distributed, high availability data processing pipelines in an effort to satisfy the need of the ever questioning data analysts and/or data scientists.

You have awesome knowledge about the following concepts
Data modelling
Relational data modelling in traditional relational database management systems. (Microsoft SQL Server, MySQL, PostgreSQL, etc)
Coercing unstructured and semi-structured data into a structured form.
Data pipelining knowledge - data extraction and transformation.
Data transformation knowledge for reporting and analytics purposes.
Knowledge of the MapReduce and related data processing paradigms would be a boon.
You have the following technical competencies
Writing SQL queries, that can relate, transform and aggregate data from many differing sources where natural keys may or may not exist.
Experience with writing data pipelines that move and transform data, for various uses.
Working knowledge of a general purpose programming language like Python would be a boost.
Working knowledge of columnar databases such as Google BigQuery, and SAP HANA would be a boost.
Working knowledge of highly distributed technologies such as Apache Hadoop or Apache Spark would be a boost.
Working knowledge of NoSQL technologies, such as Apache Solr would be a boost.
You have the following personal competencies
The ability to solve problems.
The ability to rotate around a problem, to see if solutions can be gained in different ways.
The ability to work in an ever changing, unstructured environment.
The ability to work as part of a team, with vastly differing skill sets and opinions.
The ability to contribute ideas to the quorum.
The ability to mentor and provide guidance for other team members.
A systems approach to thinking, as opposed to a siloed approach. The candidate needs to understand how their work affects the greater system.
The ability to work without supervision, and take accountability for the work they deliver.
The ability to liaise with a client, sifting through the fluff and extracting the actual requirements.
If this is you - apply now and we'll get in touch",-1,DotModus,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Data Engineer

Our client in the contact centre space is currently seeking a DATA ENGINEER that will work on the collecting, storing, processing, and analyzing of large datasets. The primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them. You will also be responsible for integrating them with the architecture used across the company.

Key Performance Areas:

Data reporting.
Implementing ETL processes.
Defining data retention policies.
Management of Customer Lead data.
Provision of data for advanced analytics.
Maintenance of internal client scorecards.
Assist team in resolving data-related support queries.
Optimize existing data processes through automation.
Assist with all data-related reporting and documentation.
Maintenance and optimisation of the Analytics database.
Provide technical support to and supervision of junior data administrators.
Continuous upskilling on new technologies, frameworks and market trends.
Monitoring performance and advising any necessary infrastructure changes.
Identifying, selecting and integrating any Big Data tools and frameworks required to provide real-time analytics.

Educational Requirements

IT related Degree or Diploma is a pre-requisite

Required Skills/Experience

ETL tools: Advanced SSIS
BI/Reporting : Qlikview/Power BI/ SSRS or SSAS
Programming languages: JAVA, C# , Python, SAS or R
Experience with NoSQL databases and/or campaign management tools will be advantageous.
Minimum 3 years’ applicable work experience in SQL, relational databases and data manipulation.
Experience in big data platforms (eg. Hadoop) or processing frameworks (eg. MapReduce/Spark) and querying tools (eg. Pig, Hive and Impala) will be highly beneficial.

Preferred Skills

Organizational skills
Experience in Attentional to detail.
Accountability is critical for this role.
Ability to work under pressure and meet deadlines.
Solid understanding of database design principles.
Should you not receive a response in 2 weeks please consider your application unsuccessful",-1,Rubik's Cubed Consulting,Durban,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"This well known company is looking for a Data Engineer. will be based in Rivonia
The ideal candidate will have strong experience in the following:
Data cleaning
SQL Export
Big data Sets

BSc Degree in Maths and Stats will be required
a min of 3 years experience.
Stable track record is required.

Send your Cv to marinda@prrrecruitment.co.za",-1,PRR Recruitment Services,Johannesburg,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Description

Position at Aculocity, LLC

At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes
Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.
Key Responsibilities
Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.
Key Traits
Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern
Position Requirements
2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.
Where will you work? This role will be based out of Durbanville, South Africa.",-1,GVW,Durbanville,-1,Unknown,-1,Unknown,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Information Technology, Gauteng JHB - Northern Suburbs

Market related - Market related Annually

An IT Consultancy Business based in Johannesburg is currently looking for a Business Intelligence Consultant / Data Engineering Consultant.

Requirements:

Extensive experience in data engineering
Experience in Business Intelligence, data and Power BI
Extensive experience in data governance and the Popi act
Ability to assess and make recommendations on data within the Popi act
Good understanding of T-SQL and query optimization, developing ETL strategies.
Good understanding with SQL Server 2008/2012, SSIS, SSRS and SSAS
Use SSIS to create ETL packages to validate, extract, transform, and load data into the data warehouse and data marts.
Deploy and configured the reports in the Report Server (SSRS).
Excellent experience in Tabular Modelling , PowerView, Qlikvie,w, and Power BI
Maintain ETL
Qlikview model
Create Drill-through, Drill-down, and Cross Tab Reports and Sub-Report using Report Definition Language (RDL).
Generate periodic reports based on the statistical analysis of the data using SQL Server Reporting Services (SSRS)
Advise and provide written technical documentation and recommendations

The information displayed above is not limited to advertisements. Please contact Thato for further information.

Please consider your application as unsuccessful if you have not received a response within 14 days of submitting your application. However, please keep a lookout on our website, www.bedifferent.co.za, for available positions that you may be suited for

Ad Visible Until: 29 October 2020
Ref: JHB005346/NL

Vacancy Type: Permanent",2.9,"Be Different Recruitment
2.9",Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Cloud Support Engineer (Big Data),-1,"ABOUT US

Amazon Web Services is the market leader and technology forerunner in the Cloud business. As a member of the AWS Support team you will be at the forefront of this transformational technology, assisting a global list of companies and developers that are taking advantage of a growing set of services and features to run their mission-critical applications. As a Cloud Support Engineer, you will act as the Cloud Ambassador across all the cloud products, arming our customers with required tools & tactics to get the most out of their Product and Support investment.

Would you like to use the latest cloud computing technologies? Do you have an interest in helping customers understand application architectures and integration approaches? Are you familiar with best practices for applications, servers and networks? Do you want to be part of a customer facing technology team helping to ensure the success of Amazon Web Services (AWS) as a leading technology organization?

If you fit the description, you might be the person we are looking for! We are a group of smart people, passionate about cloud computing, and believe that world class support is critical to customer success.

WHAT CAN YOU EXPECT FROM A LIFE AT AWS?

Every day will bring new and exciting challenges on the job while you:

· Learn and use groundbreaking technologies.
· Apply advanced troubleshooting techniques to provide unique solutions to our customers' individual needs.
· Interact with leading engineers around the world.
· Partner with Amazon Web Services teams to help reproduce and resolve customer issues.
· Leverage your extensive customer support experience to provide feedback to internal AWS teams on how to improve our services.
· Drive customer communication during critical events.
· Drive projects that improve support-related processes and our customers technical support experience.
· Write tutorials, how-to videos, and other technical articles for the developer community.
· Work on critical, highly complex customer problems that may span multiple AWS services.

WHY AWS SUPPORT?

· First and foremost this is a customer support role in The Cloud.
· On a typical day, a Support Engineer will be primarily responsible for solving customers cases through a variety of customer contact channels which include telephone, email, and web/live chat. You will apply advanced troubleshooting techniques to provide tailored solutions for our customers and drive customer interactions by thoughtfully working with customers to dive deep into the root cause of an issue.
· Apart from working on a broad spectrum of technical issues, an AWS Support Engineer may also coach/mentor new hires, develop & present training, partner with development teams on complex issues or contact deflection initiatives, participate in new hiring, write tools/script to help the team, or work with leadership on process improvement and strategic initiatives.
· Career development: We promote advancement opportunities across the organization to help you meet your career goals.
· Training: We have training programs to help you develop the skills required to be successful in your role.
· We hire smart people who are keen to build a career with AWS, so we are more interested in the areas that you do know instead of those you havent been exposed to yet.
· Support engineers interested in travel have presented training or participated in focused summits across our sites or at specific AWS events.
· As we operate on a follow-the-sun model, with Premium Support sites located globally, there is no after hours on-call or mandated overtime in this role.
· https://www.youtube.com/watch?v=GC3bWcFFZTo&t=24s



Basic Qualifications

The Big Data role supports our services that leverage data and produce business insights, which may include using Machine Learning/Artificial Intelligence (ML/AI). Helping our customers use and integrate Big Data services in what is arguably our industrys most exciting space. The portfolio of services covers EMR (Hadoop), DynamoDB (NoSQL), MangoDB, and Apache Cassandra.

· Advanced experience in Apache Hadoop, Apache Spark, Apache Hive, and Presto
· Advanced experience in DynamoDB or NoSQL technologies like MongoDB or Cassandra
· Advanced experience with System Administration with Linux (RHEL/CentOS) including Microsoft Active Directory, and LDAP integration.
· Experience with troubleshooting Kerberos Authentication problems.
· Experience with Network troubleshooting.
· Basic understanding of Machine Learning and statistics
· Experience with Java and Python and shell scripting
· Bachelors degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position



Preferred Qualifications

· Expert experience in the Hadoop Ecosystem including Apache Spark and Presto
· Expert experience in NoSQL
· Expert experience with blockchain technologies like Etherium Expert experience in data Data Lake architecture and administration
· Experience managing full application stacks from the OS up through custom applications
· Prior work experience with AWS - any or all of EC2, VPC, S3, RDS, EMR, Glue, SageMaker
· Excellent knowledge of Hadoop architecture, administration and support
· Expert understanding of distributed computing principles and their application in the cloud
· Good understanding of distributed computing environments Lead technical discussions on big data systems architecture and design
· Strong analysis and troubleshooting skills and experience
· AWS Certified Solutions Architect
· AWS certified Big Data Specialty
· Masters degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity and Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Response Center Engineer,-1,"Job Title
Response Center Engineer
Job Description


Philips is a world leading health technology company with a vision to make life better for people worldwide through meaningful innovation. Making good on this promise depends on our passionate, inspirational, collaborative and diverse team. We have over 80,000+ brilliant people around the world but are always looking for more. Like-minded, motivated, focused minds to join us in creating a healthier, more connected society while transforming themselves personally and professionally.

As a CCC Coordinator - Response Center Engineer you will have the opportunity to process customer calls and be responsible for screening and diagnosing professionally Healthcare equipment to support customers and colleagues remotely with solving technical issues and ensuring maximum customer satisfaction

You are responsible for:
Diagnose healthcare equipment to the quality standards set by Philips Healthcare (PH) remotely by interviewing customers or colleagues by telephone or by remotely logging in to the system
Advise Customer Care Center Coordinators and District Operations Managers and / or Team Leads about the best follow-up w.r.t. technical state of the diagnosed healthcare equipment
Advise the Customer Care Center Coordinators or Field Services Engineers about required spare parts and resources
Responsible for planning engineers related to Modality responsibility.
Responsible for coordination between CCC, CUSTOMER, Spare parts AND Engineer.
Responsible to drive Remote and FTR KPI’s to targets respectively 40% and 85%.
Will require minimal field work to keep abreast of technical capabilities.
Take calls from customers and make sure they are processed in the CCC ERP on timely manner including all relevant data
Support Field Services Engineers in the field with technical knowledge
Escalate technical issues to the Technical Support Specialist
Escalate technical issues to Business Unit support after consultation of the Technical Support Specialist
Monitor critical functions of the equipment’s in the IB and environmental conditions including RSN and True reachability.
Lead the planning and implementation of FSN’s and FCO’s accelerating remote implementation where applicable.
Submit timely and accurate service data, job sheets, reports, expense claims, radiation film badges, field problem reports and other paperwork as assigned
Keep abreast of new technologies likely to affect PH range of products
Use company property with care to ensure optimal results with minimal operational costs
Be a professional representative for PH with respect to customer problems, ensuring personal acceptability by the customer in behavior in accordance with PH policy and targets
Conform to PH safety standards including health and safety regulations and in the event of hazards or accidents to take immediate control of the situation and involve the Operations Manager and / or the responsible person to handle properly confidential issues according Philips standards and to act according General Business Principals
Follow all quality standards within the frame of valid PH business policies
Follow the company quality regulations (ISO 9001; PQA; TQM) and internal directives and procedures
You are a part of the dynamic South Africa Customer Care Centre Team .You will be reporting to the Customer Care Center Manager.

Requires a pleasant, assertive individual you can work very well in a team setting, a dynamic environment that requires flexibility and creativeness to achieve goals.

To succeed in this role, you should have the following skills and experience:
Degree level education or equivalent
Experience in maintenance and troubleshooting of technical complex systems
Fluent in English, verbal and written in addition to local language
In return, we offer you the unique combination of a critical and challenging role and a creative and empowering office environment. You will be actively encouraged to make improvements, establish best in class service and have a direct impact on the success of Philips on a daily basis.

Employment Equity

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply. Only apply for this role if you are a South African Citizen by birth or Naturalization prior to the 27 April 1994.

Why should you join Philips?

Working at Philips is more than a job. It’s a calling to create a healthier society through meaningful work, focused on improving 3 billion lives a year by delivering innovative solutions across the health continuum. Our people experience a variety of unexpected moments when their lives and careers come together in meaningful ways. Learn more by watching this video.

To find out more about what it’s like working for Philips at a personal level, visit the Working at Philips page on our career website, where you can read stories from our employee blog. Once there, you can also learn about our recruitment process, or find answers to some of the frequently asked questions.

Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.9,"Philips
3.9",Johannesburg,-1,10000+ Employees,1891,Company - Public,Health Care Services & Hospitals,Health Care,$10 to $25 million (USD),-1
Software Development Engineer - EC2 Placement,-1,"Build the systems that optimize how EC2 matches requests for Instances with the underlying compute capacity. EC2 Placement is seeking talented engineers to build the online and offline optimization systems for compute workload scheduling, and the customer capabilities to better manage those workloads. Amazon EC2 provides on-demand scalable compute capacity, and powers some of the largest services in the world. You will collaborate with a top-tier community of engineers to build systems to improve how customers are able to access EC2 compute resources.

The successful candidate will have strong software engineering experience, with a passion for thinking about, building and testing distributed systems. You have an interest in how Machine Learning and other optimization techniques can be applied to large-scale problems. You have demonstrated experience working with a team to design, build and operate large-scale systems. With strong engineering fundamentals, an analytical and data-driven approach to your work, and strong communication skills, you have the ability to collaborate well to deliver results. We move fast and work together on small teams to solve big problems.

If this opportunity sounds interesting, we would love to talk to you more about our work and the vibrant culture at AWS in Cape Town.

Basic Qualifications

· Degree in Computer Science or related field, or equivalent working experience
· 3+ years of industry experience in a software development environment
· Strong Computer Science fundamentals, including data structures, object-oriented design, algorithm design, problem solving, and complexity analysis.
· Proficiency in at least one modern programming language, such as Java, C#, Python, Scala, Kotlin

Preferred Qualifications

One or more of the following help you stand out:
· Demonstrated results designing, building and operating high-performance distributed systems in large-scale Linux environments
· Role model in writing high-quality, maintainable and secure code, mentoring others, and helping teams sharpen their development processes
· Ability to work effectively across teams to deliver results, with strong verbal and written communication skills
· Experience working with machine learning systems

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer - PBB IT,-1,"Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose


This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes
Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems
Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions
Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.

Research and best practices
Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development
Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.
Preferred Qualification and Experience
Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Aws Data Platform Engineer,-1,"Aws Data Platform Engineer

Posting Country:

South Africa

Date Posted:

15-Oct-2020

Full Time / Part Time:

Full Time

Contract Type:

Permanent

Joining Vodacom is more than a job, what we do matters. We don’t just carry minutes, texts and data – we carry people’s lives. And that’s a huge responsibility. If you think for a minute about the people you rely on…the likelihood is they rely on us.

Customers are at the heart of everything we do and we want to make a difference to the lives of our customers, and the communities in which we live and work. We support our people to give something back to the causes that mean the most to them through helping them give time and money to the charities they love.

And what’s it like to work here? We have created an environment where you can look forward to coming to work and are empowered to be at your best. We offer flexibility in how you work that helps you do your job in a way that suits you, opportunities to help you grow and progress throughout your career and a choice of benefits to suit your lifestyle.

Role Purpose
The H Band AWS Data Platform Engineer position is based within the Technology Business Unit.

The AWS Data Platform Engineer will be responsible for all Database services such as RDS, DynamoDB, etc. Should be able to migrate any databases from anywhere to AWS using any third-party tools or AWS database migration tool. Should also have understanding or expertise in creating data warehouses and data lake solutions on AWS.
Your responsibilities will include:
Apply practical knowledge of relational database design and usage with customers
Perform workload analysis and undertake performance tuning, as well as performance benchmarking in customer environments.
To develop state of the art solutions which are technically sound.
To provide a high-quality service to the Enterprise Cloud Services clients i.t.o. consultancy, solutions and delivery.
Commitment to team success and positive team dynamics including mentoring of other team members.
Passion for growing and applying technical skills in service to customers.
Be a trusted infrastructure advisor by providing objective, practical and relevant ideas, insights and advice.
Work collaboratively with consulting partners and technology teams to ensure high quality of solution delivery.
Encourage best practice and knowledge sharing with partners and cross-functional groups
Manage the overall database design and delivery of solutions.
Ability to make recommendations as they pertain to improvements in support/development initiatives and facilitate implementation with partners and cross-functional groups within the Business.
Participate in high level database solution definition and design during the implementation phase with the goal of providing reliable, stable and operationally sound applications that meet the Business requirements.
Ability to understand and translate business requirements into technical specifications
The ideal candidate will have:
A minimum of 3 years of industry related experience of which 1 year must be within a complex hosting environment.
Certifications in Database design, system architecture or cloud technologies.
Demonstrate knowledge of database systems internals including storage layouts and distributed databases/MPP architectures
Advanced SQL coding, tuning and query optimization.
Experience designing and leading database performance benchmarks.
Good knowledge of the different AWS services
Knowledge of cloud networking architecture, cloud operations, security, automation and orchestration.
Knowledge of database internals as it relates to query and system performance and tuning.
Understanding of overall system architecture, scalability, reliability, and performance in a database environment.
Excellent teamwork, time-management and organizational skills.
Perform other duties as deemed necessary and assigned by the customer and management
Strong interpersonal skills and problem-solving abilities.
Excellent documentation, communication and interpersonal skills.
Excellent analytical and problem-solving abilities.
Closing date for applications: Monday, 13 April 2020

The base location for this role is Vodacom World, Midrand

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply.
Vodacom is committed to an organisational culture that recognises, appreciates and values diversity & inclusion.

Commitment from Vodacom

Vodacom is committed to attracting, developing and retaining the very best people by offering a flexible, motivating and inclusive workplace in which talent is truly recognized, developed and rewarded. We believe that diversity plays an important role in the success of our business and we are committed to creating an inclusive work environment which respects, values, celebrates and makes the most of people’s individual differences - we are not only multinational but multicultural too. At Vodacom you will have access to our excellent flexible benefits programme that you would expect from any global company.",3.9,"Vodafone
3.9",Midrand,-1,10000+ Employees,1982,Company - Public,"Cable, Internet & Telephone Providers",Telecommunications,$10+ billion (USD),-1
Data Engineer Azure Data Factory,-1,"Enthuzex is looking for a motivated Lead Data Engineer to contribute towards the success of our Data and Analytics Technology initiatives. This is a hands-on technical role and this person will be responsible for the development and build of scalable solutions as it relates to the architecture strategies, data standards, digital data management, data integration, tools, and technology. The right candidate will play a deep dive hands-on critical development role in the digital transformation and in shaping how we acquire, ingest, transform and deliver data through the digital consumer channels.

Responsibilities:

Architect, design, develop and engineering end-to-end data pipelines across multiple data sources and systems of record.
Ensure data quality, integrity, security and completeness throughout the data lifecycle
Develop, design data models, data structures and ETL jobs for data acquisition and manipulation purposes
Develop deep understanding of the data sources, implement data standards, maintain data quality and master data management
Developing data services and API
Work closely with the cloud service providers to ensure completeness and alignment with the service offerings
Manage and maintain cloud based data and analytics platform
Deep understanding of the cloud offerings and engage in quick proof of concepts and proof of value in prototyping data and analytics solutions and derive viability
Ability to interact with the business stakeholders to understand requirements and translating into technology solutions

Expirience:

Experience in Cloud platform AWS or Azure eco-system. (Azure preferred)
Data Engineering/Development experience with SQL (Oracle, SQL Server, MySQL)
Strong development background creating pipelines and complex data transformations and manipulations using one of the languages Python, Java, R, or Scala with Databricks/Spark
Experience in NoSQL Databases and Big data technologies including Hadoop
Experience with API / RESTful data services
Worked on real-time data capture, processing and storing using technologies like Azure Event Hubs and Analytics
Experience working with different data storage options including AWS S3, Azure BLOB storage etc.
Understanding of different data formats including Parquet, Avro, CSV, ORC etc.
Prior experience with MPP databases and maintain large amount of data processing
Experience with Azure Data Factory and Azure Data Catalog is a big plus and mandatory
Experience with Microsoft/Azure ETL solutions and business Intelligence technologies is a big and mandatory
Past working experience on a fast paced and agile environment
Perform ongoing monitoring, automation and refinement of data engineering solutions
Experience in leading high visibility transformation projects that interacts with multiple business lines
Build and meet project timelines and manage delivery commitments with proper communication to management

Qualifications

Bachelor’s degree with 4+ years of relevant experience
Willingness to learn new technologies and thrive in an extremely fast paced environment
Team player and easy to work with.

Applicants must demonstrate their ability to master new enterprise level technologies. Successful applicants will exemplify Enthuzex ethical principles of uncompromising integrity, respect for others, and accountability for decisions

send cv's info@enthuzex.co.za",-1,Enthuzex,Leslie,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Scientist,-1,"The world is changing.

We all want something different.

At Luno, we see you as an individual.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the world, and to do so, we need the best team on board for our mission.

A bit about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 3 million customers across 40 countries.
We are Series B funded, backed by Balderton Capital and the Naspers Group.
Our platform has processed over 8 billion dollars since we've launched
We're proud to be one of the world's most international cryptocurrency teams from 26 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
The role in a nutshell:

Identifying opportunities in the business that could benefit most from cognitive applications, as well as building and enhancing organisational capabilities for deriving value from multiple data sources using data science.

What we'd like you to have:
Bachelor's degree or higher in the natural sciences or technical fields such as Mathematics, Statistics, Computer Science, Engineering or Economics
Enthusiasm to work in the cryptocurrencies space
Advanced SQL skills
Solid understanding of exploratory data analysis, predictive analytics, and optimisation using Python, R, Matlab, RapidMiner, KNIME or other data science-oriented platforms
Proficiency in the use of data science and machine learning domain-specific languages such as ""Caret"" and the ""Tidyverse"" suite of tools in R, or ""Pandas"" in Python
Strong interpersonal and communication skills
Communicating data insights using storytelling narratives
Ability to work independently, as well as within and across teams
Ability to successfully complete projects with large and/or incomplete data sets
More about what you'll be doing:
Optimising product performance by tracking and analysing customer behaviour on web and app, in collaboration with software engineers and product designers
Providing the business with reports and dashboards, on key performance metrics
Developing metrics to accurately assess the health of our Exchange platform
Comparative data-driven analysis of our Exchange against alternative platforms
Formulating business requirements into analytical objectives
Designing and running experiments to test hypotheses
Hacking through complex business problems using advanced data analysis to provide insights and recommendations
Building, maintaining, and optimising decisioning systems using advanced statistical and predictive modelling techniques
What will set you apart:
An advanced degree in Mathematics, Statistics, Computer Science or related field
At least 3 years' experience working in a similar role
A basic understanding of trading in financial markets
Experience working with a data analytics and visualisation platform such as Tableau, Cognos, QlikView, or Looker
Familiarity with using Google Analytics to understand customer behaviour
Solid knowledge of statistical and machine learning techniques
Familiarity with modern distributed data storage and processing systems such as Amazon Redshift, Big Query, Snowflake, Databricks and Apache Spark
You can gather and synthesise facts, theories, trends, patterns, inferences, and key issues in complex and variable situations
Ability to diagnose problems using formal problem-solving tools and techniques from multiple angles to generate multiple possible solutions
A sense of anticipating long-term problem areas and associated risk levels with objective rationale
Remote Life at Luno

If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
You'll be able to continuously upskill yourself with access to free online learning via MyAcademy, an international teaching marketplace with over 100000 courses from Harvard and other leading providers + share knowledge with your peers.
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity and paternity leave, and you can even take paw-ternity leave for your furry friend.
Annual Inspiration Day! Make time for that pottery course or spa day you've always wanted to do.
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"EY is a global leader in
assurance, tax, transaction and advisory services. Technology is at the heart
of what we do and deliver at EY. Technology solutions are integrated in the
client services we deliver and are key to our innovation as an organization.

Fueled by
strategic investment in technology and innovation, Client Technology seeks to
drive growth opportunities and solve complex business problems for our clients
through building a robust platform for business and powerful product engine
that are vital to innovation at scale. As part of Client Technology, you’ll
work with technologists and business experts, blending EY’s deep industry
knowledge and innovative ideas with our platforms, capabilities, and technical
expertise. As a catalyst for change and growth, you’ll be at the forefront of
integrating emerging technologies from AI to Data Analytics into every corner
of what we do at EY. That means more growth for you, exciting learning
opportunities, career choices, and the chance to make a real impact.

The selected
candidate
Develops
large and complex data architecture, composed of models, policies, rules or
standards that govern which data is collected and how it is stored, arranged,
integrated and put to use in data systems, including the design, build and
management of data infrastructure to address business requirements
Creates
sound use case driven roadmaps, depicting data architecture as-is and to-be
capabilities with the business by engaging with multidisciplinary teams, and by
identifying, managing and mitigating risk
Develops
relationships across the business to understand data requirements, applies deep
technical knowledge of data management to solve business problems in areas
where solutions may not currently exist, necessitating new solutions/ways of
working/technologies and proactively articulating these to the business
Review,
identify the latest emerging technologies, augmenting by services from the
leading cloud providers to solution and recommend the best next generation data
platform value driven approach for our clients
Your Key Responsibilities Include
Create
and maintain conceptual, logical and physical database models
Document
functional requirements and system specifications into the data architecture
and detailed design specifications for current and proposed designs
Document
and adhere to development standards and best practices in database designs
Maintain
highly effective and consistent communication within the team, peers, and the
leadership team
Reverse
engineer SQL code and modify it to solve problems/issues
Contribute
to the definition and implementation of data governance practices
Design
both data structures and data integration practices
Work
closely with the infrastructure teams to create a physical environment to
support data services
Evaluate
new and existing (internal and external) technologies and services in support
of data services and data analytics objectives
Skills And Attributes For Success
Understanding
of business process reengineering and business modeling concepts, business
systems development and analysis
Hands-on
experience in designing and implementing hybrid cloud and on-prem solutions
Experience
working with the latest versions of SQL Server
Experience
applying SAFe/Scrum/Kanban methodologies
Ability
to exercise judgment in solving technical, operational, and organizational
challenges
Expert
programming, performance tuning and troubleshooting skills, using the latest
popular programming languages for example python
Demonstrate
proactive approach to identifying issues and presenting solutions and options,
and where appropriate, leading to resolution
Minimum Qualifications
5+ years
demonstratable work experience as a Data Architect using data modeling tools
2-3 years
SQL coding experience on large projects
Must
possess expert SQL programming, performance tuning and troubleshooting skills
Create
database objects and SQL scripts
Understand
and developed data pipelines
Know how
to deformalize data for data science models
Experience
in python, spark and notebooks
Experience
designing data warehousing solutions
Experience
designing next generation data platforms utilising cloud services
In-depth
understanding of database structure principles
Seamlessly
able to translate business requirements to technology requirements
What We Look For
Strong
analytical skills and problem-solving ability
A
self-starter, independent-thinker, curious and creative person with ambition
and passion
Excellent
inter-personal, communication, collaboration, and presentation skills
Customer
focused
Excellent
time management skills
Positive
and constructive minded
Takes
responsibility for continuous self-learning
Takes the
lead and makes decisions in critical times and tough circumstances
Attention
to detail
High
levels of integrity and honesty
Curious
about new emerging technology
About EY
As a global leader in assurance, tax, transaction and consulting
services, we’re using the finance products, expertise and systems we’ve
developed to build a better working world. That starts with a culture that
believes in giving you the training, opportunities and creative freedom to make
things better. Whenever you join, however long you stay, the exceptional EY
experience lasts a lifetime.",3.8,"EY
3.8",Johannesburg,-1,10000+ Employees,1989,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Architect - Principal,-1,"We are looking for Principle Data Architect to join our Engineering team in Cape Town.

The world is changing.
We all want something different.
At Luno, we see you as individuals.

Together, we are upgrading the world of work to unleash the potential within and empower you to become the best possible version of yourself.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the financial landscape, and to do so, well we need the best team on board for our mission. In short, to achieve our goals, we need rockstars. As simple as that.

A little about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 5 million customers across 40 countries.
We're part of the Digital Currency Group, a group of companies driving progress in the cryptocurrency and blockchain space that includes Grayscale, Genesis, Coindesk and Foundry Services
Our platform has processed over $8 billion to date
We're proud to be one of the world's most international cryptocurrency teams from 43 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
How we work


Our engineering team (currently ~100 engineers) is split into organisations which we call Fleets. Each Fleet focuses on a core customer journey (onboarding, security, payments, support, new business, growth and marketing etc.). Each of these fleets contains multiple smaller teams called Pods, each of which focuses on a specific aspect of the product.

Pods will include a product owner, product designer, back-end engineers, Android, iOS and Web developers, who each bring a unique perspective to the problem you are all contributing towards.

We're agile, use scrum, continuous integration and continuous delivery, deploying to production every single day.

We're building teams to help us succeed in our mission to upgrade the world to a better financial system. You'll be joining a group of highly motivated software engineers who you'll work collaboratively with across our pods.

As a fast-growing company with offices around the world, you'll immediately see how your contributions directly impact both our internal users and client experience. Many of the problems we are solving result in trail blazing solutions which can't be found on Stack Overflow; so we're looking for engineers who flourish working in a complex domain.

In your first six months, you will:


...start at Luno by learning our processes, meeting the wider team and starting our engineering on-boarding program. After getting comfortable with the basics, you'll start learning our idiomatic patterns in a safe, easy-to-follow way - by building your own toy micro services. You'll get to practice how we do design docs, code reviews, deployments, events, logging and monitoring.

You'll meet the Pod(s) you'll be working with and quickly align on the teams' current OKRs and product roadmap. We succeed as a team, so we will provide you with regular feedback from your manager and peers and will encourage you to do the same.

What you'll do:
Work closely with our data science and platform teams on projects introducing new streams of data into our data lake
You will get to bring new ideas on how to further develop and innovate our data solutions and how to expose that data to the business
Accountable and Responsible for the design and architecture of Data systems that are robust and scalable.
Work in an Agile/Scrum framework or Agile mindset
Data backup/recovery and storage
Pick-up and learn new concepts, in both engineering and product, and be able to apply that knowledge quickly.
The ideal candidate for this role will have:
7+ years' experience in maintaining scalable data solutions and/or you are passionate about it
Ability to understand, communicate and advocate between build vs buy
Proven track record of setting up, restructuring and maintenance of databases
You know your way around ETL and you have experience with SQL
Experience in the AWS Data stack (RedShift,DynamoDB, Amazon RDS)
Familiarity with integrating data stores with BI platforms such as Looker, Tableau, or Power BI
You have experience with the concepts of CI/CD
Coding skills in e.g. Go, Python
Bachelor's degree in a related field preferred
AWS Certified DataOps Administrator
Be friendly, transparent, articulate and driven to succeed
Basic knowledge of and passion for digital currencies like Bitcoin
A work permit for South Africa if you are not a South African citizen
Don't be put off if you don't tick all of the boxes – they're a guide based on what we'd love to see but we appreciate that excellent software engineers have diverse backgrounds.

Remote Life at Luno


If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity / paternity and even (yes, you are reading it correctly) paw-ternity for your furry friend..
Annual Inspiration Day.. like that pottery course you've always been meaning to do!
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. You'll need to hold the legal right to work in South Africa already as we cannot provide visa sponsorship.

Be part of the change!",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer - EC2 Capacity Data Analytics,-1,"EC2 Capacity Data Analytics (CDA) team is looking for a Data Engineer to join our team.

Our team is part of the EC2 Capacity Engineering organization, which is responsible for providing the elasticity EC2 customers need to scale up/down compute resources in a cost-efficient manner. We predict customer usage across thousands of configuration combinations to deliver exactly what our customers require in just the right amount of time with just the right amount of capacity.

As a Data Engineer, you will build the ETL and analytics solutions for our internal customers to answer questions with data and drive critical improvements for the business. You will use best practices in software engineering, data management, data storage, data compute, and distributed systems. On any given day, we use Python, Scala, Java, SQL, Lambda, CloudFormation, Redshift and Glue as well as other public AWS services and a host of Amazon internal tools. We dont expect you to be an expert in, or necessarily even be familiar with all of the technologies listed above, but we do expect you to be excited to learn about them.

This position involves on-call responsibilities, typically for one week every two months. Our team is dedicated to supporting new team members. We care about your career growth, we try to assign projects and tasks based on what will help each team member develop into a more well-rounded engineer and enable them to take on more complex tasks in the future.

Our team values work-life balance and we are flexible when people occasionally need to work from home.

Job Duties
Develop and maintain automated ETL pipelines for big data using languages such as Scala, Spark, SQL and AWS services such as S3, Glue, Lambda, SNS, SQS, KMS. Example: ETL jobs that process a continuous flow of JSON source files and output the data in a business-friendly Parquet format that can be efficiently queried via Redshift Spectrum using SQL to answer business question.

Develop and maintain automated ETL monitoring and alarming solutions using Java/Python/Scala, Spark, SQL, and AWS services such as CloudWatch and Lambda.

Implement and support reporting and analytics infrastructure for internal business customers using AWS, services such Athena, Redshift, Spectrum, EMR, and QuickSight.

Develop and maintain data security and permissions solutions for enterprise scale data warehouse and data lake implementations including data encryption and database user access controls and logging.

Develop and maintain data warehouse and data lake metadata, data catalog, and user documentation for internal business customers.

Develop, test, and deploy code using internal software development toolsets. This includes the code for deploying infrastructure and solutions for secure data storage, ETL pipelines, data catalog, and data query.


Basic Qualifications

· Bachelors degree in Computer Science or related technical field, or equivalent work experience.
· 4+ years of overall work experience including Software Engineering, Data Engineering, Database Engineering, Business Intelligence.
· Experience with AWS technologies stack including Lambda, Glue, Redshift, RDS, S3, EMR or similar big data solutions stack

Preferred Qualifications

· Demonstrate efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data.
· Demonstrable proficiency in distributed systems and data architecture; design and implementation of batch and stream data processing pipelines; knows how to optimize the distribution, partitioning, and MPP of high-level data structures.

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer,-1,"Our client based in Johannesburg is urgently looking for a Data Engineer to be on a 3 months contract
Build data pipelines, experience in new tech like nifi, kafka, python

Joburg based, open to EE, 3 month contract with the option to extend, must be available at short notice",-1,EQplus,Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Overview
Job ID: 51456
Job Sector: Information Technology and Services
Country: South Africa
Region/State/Province/District: Gauteng
Location: Johannesburg

Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose

This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes

Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems

Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions

Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.
Research and best practices

Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development

Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.

Preferred Qualification and Experience

Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry

Knowledge/Technical Skills/Expertise

Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision

PLEASE NOTE: All our recruitment and selection processes comply with applicable local laws and regulations. We will never ask for money or any form of payment as part of our recruitment process. If you experience this, please contact our Fraudline on +27 800222050 or forward to TransactionFraudOpsSA@standardbank.co.za",4.1,"Standard Bank
4.1",Johannesburg,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"About us

At PBT Group we pride ourselves on being a Data Specialist organisation. With 20 years of experience in 27 countries over 3 continents, our team of 550 consultants have implemented more than 700 projects.",4.3,"PBT Group
4.3",Johannesburg,-1,Unknown,-1,Company - Private,Accounting,Accounting & Legal,Less than $1 million (USD),-1
Data Engineer,-1,"Kick-start your career in the online gaming world and experience the very latest in technology and innovation.

The Department:

Our mission is to provide our customers with the best online betting experience and share the thrill of gaming with them. Data is at the very heart of our business and is vital in everything we do.

Our cross-functional Data team has a big and exciting challenge ahead. We are in the process of re-platforming our traditional, on-premises RDBMS environment to a new microservice architecture in the cloud. We’re making use of the diverse set of data technologies in Microsoft Azure to offer new services, reporting structures and real-time data pipeline while serving the day-to-day requirements of a rapidly growing, data-hungry organisation.

Purpose of the Role:

This is an excellent opportunity for an individual who is looking to gain new skills. We are committed to creating a culture of learning and regularly run proof of concepts, provide internal demos, manage workshops and attend external conferences. Our data team has a wide range of skills including development for highly transactional RDBMS systems, data warehousing, data science and cloud technologies and we are always working to raise everyone’s game.

Duties include, but not limited to:

Work as part of an agile Data Engineering Team
Development of greenfield projects in Azure
Develop and maintain on-premises RDBMS/DW systems
Create robust ETL services and real-time data pipelines
Build and maintain Continuous Integration and DevOps pipelines
Test-driven development and pair programming with colleagues

Essential Criteria:

C#, .Net, Visual Studio
Git, Azure DevOps
NoSQL development (CosmosDB)
Demonstrable understanding of MS SQL Server in a highly transactional environment
Demonstrable understanding of development in Microsoft Azure
Able to understand query plans and identify performance bottlenecks
Test/Business-Driven Development
Building Continuous Integration/Deployment pipelines
Communicate effectively with both technical and non-technical stakeholders

Desirable Criteria:

Implementing Data Storage and Processing solutions in Azure (ARM Templates, Storage Accounts, Data Lake Storage, SQL DB, Cosmos DB, EventHubs, Function Apps, Log Analytics, Data Factory, Databricks, Polybase)
Implementing Security, Disaster Recovery, High Availability, Auditing, Monitoring and Alerting solutions in Azure
Automating tasks in Azure using Powershell / CLI
Predicting costs and optimizing spending in Azure
Message Queues (RabbitMQ, Kafka)
Python

Person Specifications:

Resilience
Teamwork
Technical Knowledge
Communication skills
Stress Tolerance
Please note we will apply relevance to our Talent Management and Talent Development Programme as part of our recruitment process.
Shortlisted candidates may need to complete an assessment.
This position requires trust and honesty it has access to customers financial details - therefore a credit and criminal record check will be conducted. The qualifications identified herein are an inherent job requirement; therefore, a qualification verification check will be done. By applying for this role, and supplying the necessary details, you hereby grant us permission to apply for these checks. This will be done in a confidential manner, and solely for the purposes of verification.

To view all current vacancies, please visit our website, www.digioutsource.com

Should you not hear from us within 2 weeks, please deem your application as unsuccessful.

The perfect place to work, play and grow!",3.9,"Digital Outsource Services
3.9",Cape Town,-1,1001 to 5000 Employees,1997,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
Data Engineer,-1,"At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes

Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.

Key Responsibilities

Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.

Key Traits

Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern

Position Requirements

2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.

Where will you work? This role will be based out of Durbanville, South Africa.",3.1,"Aculocity, LLC
3.1",Durbanville,-1,1 to 50 Employees,2006,Company - Private,IT Services,Information Technology,$1 to $5 million (USD),-1
Data Engineer,-1,"ENVIRONMENT:

A rapidly growing E-Commerce Platform seeks a highly talented Data Engineer to make an invaluable contribution to data democratisation and literacy vision by making accessible and easy-to-use data products and tools. You will require a Comp-Sci Degree or 3 years’ relevant industry experience, MySQL, PostgreSQL, Java, Python, in-depth understanding of OLAP, Data Marts, Star Scheme, Snowflake, be familiar with Jenkins, Travis, Circle CI, Docker, Kubernetes, experience with Kafka, Pub/Sub, Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks & significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing & Data Lake design and implementation and Lambda/Kappa architectures.

DUTIES:

Design, develop, test and maintain data architecture.

Prepare data for descriptive, predictive and prescriptive modelling.

Automate repetitive tasks and manual processes related with the data usage.

Optimize data delivery.

Design, develop and test large stream data pipelines to ingest, aggregate, clean, and distribute data models ready for analysis.

Ensure the highest standard in data integrity.

Leverage best practices in continuous integration and delivery.

Collaborate with other engineers, ML experts, analysts, and stakeholders to produce the most efficient and valuable solutions.

Implement features, technology, and processes that move us towards industry best practices, improving on scalability, efficiency, reliability, and security.

Operations and ownership of systems in production, responding to incidents.

REQUIREMENTS:

Qualifications –

Comp-Sci Degree or 3 years relevant industry experience.

Experience/Skills –

Open source relational database systems e.g. MySQL, PostgreSQL, etc.

Significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing, and Data Lake design and implementation and Lambda/Kappa architectures.

A thorough understanding of database and data warehousing principles e.g. OLAP, Data Marts, Star Schema, Snowflake, etc.

Java and Python.

Familiar with CI/CD tools such as Jenkins, Travis, Circle CI, etc.

Experience with Kafka, Pub/Sub, or other event-based systems.

Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks, etc.

Working in cloud environments and with containerisation frameworks, tools and platforms e.g. Docker, Kubernetes, GKE, etc.

A deep understanding of data pipelining, streaming, and Big Data technologies, methods, patterns, and techniques.

Troubleshooting complex database operations and performance issues.

Automating tasks using Shell Scripting or writing small applications.

ATTRIBUTES:

Works well with people and is passionate about helping people be their best.

A team player, an active listener, mentor, and able to communicate well.

Shows solid reasoning and decision making, with the ability to work under pressure.

Is passionate about technology, systems and data.

Is curious, always learning, and keeping up to date with the industry.

While we would really like to respond to every application, should you not be contacted for this position within 10 working days please consider your application unsuccessful.

COMMENTS:

When applying for jobs, ensure that you have the minimum job requirements. Only SA Citizens will be considered for this role. If you are not in the mentioned location of any of the jobs, please note your relocation plans in all applications for jobs and correspondence.",-1,Datafin IT Recruitment,Cape Town,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Cartrack is looking for passionate data science and engineering candidates that can join a growing team that is responsible for the intelligence and efficiency solution provision to over a million subscribers, many of whom are large fleets. We are in the midst of creating revolutionary platforms that will change the way that people interact with their vehicles.

You will have the opportunity to work with the very brightest global subject matter experts that are transforming the automotive industry across Fleet Management, Asset Management and Insurance Telematics solutions.

Get to know the role:

The role of a data engineer is a supporting one, but it is also an extremely vital one. As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements. We want to see candidates with mechanical tendencies and a desire to know how things work and to improve them.

The day-to-day activities:

Design, construct, install, test and maintain data management systems.
Build high-performance algorithms, predictive models, and prototypes.
Ensure that all systems meet the business/company requirements as well as industry practices.
Integrate up-and-coming data management and software engineering technologies into existing data structures.
Develop set processes for data mining, data modeling, and data production.
Create custom software components and analytics applications.
Research new uses for existing data.
Employ an array of technological languages and tools to connect systems together.
Install/update disaster recovery procedures.
Recommend different ways to constantly improve data reliability and quality.
Work on and maintain Data pipelines.

Requirements Essential:

At least 5 years’ proven experience as a Data Engineer, DevOps Engineer, Software Developer, or similar.
Proficient in Linux/Unix and shell scripting as well as in functional programming languages.
Expertise in setting up and explored with technologies such as Hadoop and Spark.
Bachelor’s degree in computer science, software/computer engineering, applied mathematics, or physics.",3.3,"Cartrack
3.3",Johannesburg,-1,501 to 1000 Employees,2004,Company - Private,Security Services,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Data Engineer,-1,"Data Engineers build and support data pipelines and datamarts built off those pipelines. Both must be scalable, repeatable and secure. The Data Engineer helps to facilitate gathering data from a variety of different sources, in the correct format, assuring that it conforms to data quality standards and assuring that downstream users can get to that data timeously. This role functions as a core member of an agile team. These professionals are responsible for the infrastructure that provides insights from raw data, handling and integrating diverse sources of data seamlessly. They enable solutions, by handling large volumes of data in batch and real-time by leveraging emerging technologies from both the big data and cloud spaces. Additional responsibilities include developing proof of concepts and implements complex big data solutions with a focus on collecting, parsing, managing, analysing and visualising large datasets. They know how to apply technologies to solve the problems of working with large volumes of data in diverse formats to deliver innovative solutions. Data Engineering is a technical job that requires substantial expertise in a broad range of software development and programming fields. These professionals have a knowledge of data analysis, end user requirements and business requirements analysis to develop a clear understanding of the business need and to incorporate these needs into a technical solution. They have a solid understanding of physical database design and the systems development lifecycle. This role must work well in a team environment.

Job Objectives

Work Complexity: * Architects Data analytics framework. * Translates complex functional and technical requirements into detailed architecture, design, and high performing software. * Leads Data and batch/real-time analytical solutions leveraging transformational technologies. * Works on multiple projects as a technical lead driving user story analysis and elaboration, design and development of software applications, testing, and builds automation tools.

Main Job Objectives: 1. Development and Operations 2. Database Development and Operations 3. Policies, Standards and Procedures 4. Communications 5. Business Continuity & Disaster Recovery 6. Research and Evaluation 7. Coaching/ Mentoring

Qualifications

Essential: 4 years Bachelors degree in computer science, computer engineering, or equivalent work experience AWS Certification at least to associate level

Experience

Essential:

5+ years Data engineering or software engineering

3-5 years demonstrated experience leading teams of engineers

2+ years Big Data experience

5+ years experience with Extract Transform and Load (ETL) processes

2+ years Could AWS experience

At least 2 years demonstrated experience with agile or other rapid application development methods - Agile exposure, Kanban or Scrum

5 years demonstrated experience with object oriented design, coding and testing patterns as well as experience in engineering (commercial or open source) software platforms and large scale data infrastructures.

Desirable:

5+ years Retail Operations experience

Knowledge and Skills

Essential: *Creating data feeds from on-premise to AWS Cloud (2 years) *Support data feeds in production on break fix basis (2 years) *Creating data marts using Talend or similar ETL development tool (4 years) *Manipulating data using python and pyspark (2 years) *Processing data using the Hadoop paradigm particularly using EMR, AWSs distribution of Hadoop (2 years) *Devop for Big Data and Business Intelligence including automated testing and deployment (2 years) * Extensive knowledge in different programming or scripting languages * Expert knowledge of data modeling and understanding of different data structures and their benefits and limitations under particular use cases.

Further technical skills required: * Capability to architect highly scalable distributed systems, using different open source tools. * Big Data batch and streaming tools * Talend (1 year) * AWS: EMR, EC2, S3 (1 year) * Python (1 year) * PySpark or Spark (1 year) - Desirable * Business Intelligence Data modelling (3 years) * SQL (3 years)",-1,Datonomy Solutions,Brackenfell,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We are assisting one of our clients that is based in Pretoria to fill a role of a Data Engineer

This is a 12 month contract role

Objective of this Scope of Work

The Data Engineer will drive improvement of the data management maturity levels and provide the necessary technical support within the company to support reliable and effective decision-making, appropriate usage and protection thereof.

Scope of Services Definition

The scope will include but will not be limited to:

ï†· To develop, construct, test and maintain architectures.

ï†· To ensure architectures will support the requirements of business.

ï†· To discover opportunities for data acquisition and sharing.

ï†· To develop data set processes for data modelling, mining and production.

ï†· To employ a variety of languages and tools to marry systems together.

ï†· To recommend way to improve data reliability, efficiency and quality.

ï†· To prepare data for use in predictive and prescriptive modelling.

ï†· To conduct research to answer industry and business questions.

ï†· To leverage volumes of data from internal and external to answer business questions.

ï†· To develop and manage stakeholder relations effectively to promote data management across the organisation and support reliable decision making and appropriate data usage.

ï†· To participate and provide technical support in cross organisational activities relating to any of the above mentioned data management activities.

ï†· To provide regular progress reports as per stakeholder requirements and present data management updates in various forums as required.

Minimum qualification Required:

ï†· A minimum of a Bachelors degree in Computer Science or Information Management OR equivalent;

ï†· A minimum of five to eight years experience in a data management environment",-1,HR Genie,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Our client based in the Northern Suburbs, is currently looking for a Data Engineer to join their team.

Responsibilities
Our client is a dynamic IT company that delivers value-driven IT solutions to the group. Our work lives revolve around our DNA. We take pride in our work, treat our colleagues, partners and our country with respect. We exercise collaborative decision-making and believe in having a balance in life. We do this all while having fun and enjoying what we do.

The primary focus of this position is to use technical skills to put software, systems and data together in a way that extracts meaningful insights from raw data. You will need to be helpful and supportive to your team and fellow developers. You join an energetic, focused and dynamic team.

Interact with clients to understand requirements and business problems/needs

Identify, analyse, visualise and understand supporting data to propose solid solutions

Create technical documentation for reference and reporting

Support existing solutions within GCP and Oracle

Doing standby on a rotating basis

Key Competencies and Qualifications

Matric

Tertiary qualification in IT

Preferred cloud experience in AWS/AZURE/GCP

At least 3 years of data warehouse ETL experience

Dimensional Modelling

Data analyses

Experience with data visualization and visualization tool(s)

Knowledge of the retail industry will be beneficial

Understanding and experience with version control SVN/GIT

Preferred – Korn shell scripting, Python/Java, SQL

Google Cloud Platform experience would be looked upon favourably

Having a broad understanding of different SDLC’s

Preferred agile experience

Strengths

The natural tendency to take ownership and responsibility

Strong problem solving, critical thinking, effective planning and organisational skills

Detail-oriented with excellent communication skills

You have a can-do attitude and positive outlook on life

Can cope under pressure

Curious and interested in analysing problems and possible solutions

Strong team player

Self-driven learner, passionate about new technology

Above all, be passionate about what you do

Should you wish to apply for the position, please apply directly via this job board, please ensure that you quote reference number 201620 subject heading or email body.

Please note that due to the high volume of CV's received; only shortlisted applicants will be contacted. Should you not receive communication from our offices within two weeks of submission please note that your application will not be considered for this position.

We will keep your CV on file and re-establish contact with you should opportunities in line with your expertise become available again.

Should you require any additional information give us a call on 021 012 5566.",-1,Surgo HR & Training,Cape Town,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We believe that our employees fuel our organization, essential to enable us to help our customers overcome their business challenges and achieve sustainable growth. As a result, we are committed to growing each individual and providing them with the challenges, feedback and support needed to achieve success in their career

If this sounds appealing, and like us, you get excited about data: its collection, storage, transformation or display, see if you’ve got what it takes to join our sought after DATA team.

Key Responsibilities And/or Outputs

You will represent IQbusiness at our customers, sometimes alone, and sometimes as part of an IQ team.

Providing a superior customer experience by building and maintaining relationships, working at customer offices, keeping data confidential
Design and develop – databases, SQL queries, stored procedures, reports, dashboards or integration solutions
Produce solutions for both real-time and batch environments
Test your work to ensure compliance
Solve problems, and do root cause analysis
Prioritize your workload
Assist in other areas relating to your true data function, such as data modeling, data and business analysts
Interact with a variety of individuals: senior, junior, technical and from business
Provide guidance to fellow colleagues, or even manage a team
Uphold the IQ values, which are to care, learn & share; innovate; deliver as well as to build, enhance and maintain relationships

Education

Matric pass
A tertiary qualification, preferably in an ICT relevant field
Appropriate Microsoft certifications are beneficial but not required

Requirements

3 - 6 years experience in the Data Engineering environments and technologies
Great communication skills
A passion for SQL, databases or reports
Can you write stored procedures, design complex queries and create views and triggers?
Are you able to work out the relationships in a data warehouse or the aggregation of a cube?
Do you extract and display useful information when you see patterns and trends in data?
Strong knowledge of the financial services industry, ideally in a consulting role
The use of data related software: databases, ETL and BI tools; report writing and analytical tools
We use a lot of Microsoft products. You may often be expected to use MS SQL Server, SSIS, SSRS, SSAS and Power BI to develop solutions
What other relevant software have you’ve used?
Ability to work in different project methodologies: Waterfall and/or Agile
Knowledge of full SDLC
Exposure to logical and physical data modeling

Equal Employment Opportunity

IQbusiness is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, citizenship, marital, domestic or civil partnership status, sexual orientation, or gender identity",3.7,"IQbusiness South Africa
3.7",Johannesburg,-1,1 to 50 Employees,-1,Company - Private,Consulting,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"We value a data engineer as someone who works behind the scenes to obtain, process and supply data via various methodologies and technologies, to various consumers, in ways and forms that makes sense and add value. This definition is very broad, as the field of data engineering is just as broad.

You may be the type of data engineer that develops API endpoints for the consumption of data by end users or even another data pipeline, or you may be the type of data engineer that develops highly distributed, high availability data processing pipelines in an effort to satisfy the need of the ever questioning data analysts and/or data scientists.

You have awesome knowledge about the following concepts
Data modelling
Relational data modelling in traditional relational database management systems. (Microsoft SQL Server, MySQL, PostgreSQL, etc)
Coercing unstructured and semi-structured data into a structured form.
Data pipelining knowledge - data extraction and transformation.
Data transformation knowledge for reporting and analytics purposes.
Knowledge of the MapReduce and related data processing paradigms would be a boon.
You have the following technical competencies
Writing SQL queries, that can relate, transform and aggregate data from many differing sources where natural keys may or may not exist.
Experience with writing data pipelines that move and transform data, for various uses.
Working knowledge of a general purpose programming language like Python would be a boost.
Working knowledge of columnar databases such as Google BigQuery, and SAP HANA would be a boost.
Working knowledge of highly distributed technologies such as Apache Hadoop or Apache Spark would be a boost.
Working knowledge of NoSQL technologies, such as Apache Solr would be a boost.
You have the following personal competencies
The ability to solve problems.
The ability to rotate around a problem, to see if solutions can be gained in different ways.
The ability to work in an ever changing, unstructured environment.
The ability to work as part of a team, with vastly differing skill sets and opinions.
The ability to contribute ideas to the quorum.
The ability to mentor and provide guidance for other team members.
A systems approach to thinking, as opposed to a siloed approach. The candidate needs to understand how their work affects the greater system.
The ability to work without supervision, and take accountability for the work they deliver.
The ability to liaise with a client, sifting through the fluff and extracting the actual requirements.
If this is you - apply now and we'll get in touch",-1,DotModus,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Data Engineer

Our client in the contact centre space is currently seeking a DATA ENGINEER that will work on the collecting, storing, processing, and analyzing of large datasets. The primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them. You will also be responsible for integrating them with the architecture used across the company.

Key Performance Areas:

Data reporting.
Implementing ETL processes.
Defining data retention policies.
Management of Customer Lead data.
Provision of data for advanced analytics.
Maintenance of internal client scorecards.
Assist team in resolving data-related support queries.
Optimize existing data processes through automation.
Assist with all data-related reporting and documentation.
Maintenance and optimisation of the Analytics database.
Provide technical support to and supervision of junior data administrators.
Continuous upskilling on new technologies, frameworks and market trends.
Monitoring performance and advising any necessary infrastructure changes.
Identifying, selecting and integrating any Big Data tools and frameworks required to provide real-time analytics.

Educational Requirements

IT related Degree or Diploma is a pre-requisite

Required Skills/Experience

ETL tools: Advanced SSIS
BI/Reporting : Qlikview/Power BI/ SSRS or SSAS
Programming languages: JAVA, C# , Python, SAS or R
Experience with NoSQL databases and/or campaign management tools will be advantageous.
Minimum 3 years’ applicable work experience in SQL, relational databases and data manipulation.
Experience in big data platforms (eg. Hadoop) or processing frameworks (eg. MapReduce/Spark) and querying tools (eg. Pig, Hive and Impala) will be highly beneficial.

Preferred Skills

Organizational skills
Experience in Attentional to detail.
Accountability is critical for this role.
Ability to work under pressure and meet deadlines.
Solid understanding of database design principles.
Should you not receive a response in 2 weeks please consider your application unsuccessful",-1,Rubik's Cubed Consulting,Durban,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"This well known company is looking for a Data Engineer. will be based in Rivonia
The ideal candidate will have strong experience in the following:
Data cleaning
SQL Export
Big data Sets

BSc Degree in Maths and Stats will be required
a min of 3 years experience.
Stable track record is required.

Send your Cv to marinda@prrrecruitment.co.za",-1,PRR Recruitment Services,Johannesburg,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Description

Position at Aculocity, LLC

At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes
Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.
Key Responsibilities
Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.
Key Traits
Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern
Position Requirements
2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.
Where will you work? This role will be based out of Durbanville, South Africa.",-1,GVW,Durbanville,-1,Unknown,-1,Unknown,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Information Technology, Gauteng JHB - Northern Suburbs

Market related - Market related Annually

An IT Consultancy Business based in Johannesburg is currently looking for a Business Intelligence Consultant / Data Engineering Consultant.

Requirements:

Extensive experience in data engineering
Experience in Business Intelligence, data and Power BI
Extensive experience in data governance and the Popi act
Ability to assess and make recommendations on data within the Popi act
Good understanding of T-SQL and query optimization, developing ETL strategies.
Good understanding with SQL Server 2008/2012, SSIS, SSRS and SSAS
Use SSIS to create ETL packages to validate, extract, transform, and load data into the data warehouse and data marts.
Deploy and configured the reports in the Report Server (SSRS).
Excellent experience in Tabular Modelling , PowerView, Qlikvie,w, and Power BI
Maintain ETL
Qlikview model
Create Drill-through, Drill-down, and Cross Tab Reports and Sub-Report using Report Definition Language (RDL).
Generate periodic reports based on the statistical analysis of the data using SQL Server Reporting Services (SSRS)
Advise and provide written technical documentation and recommendations

The information displayed above is not limited to advertisements. Please contact Thato for further information.

Please consider your application as unsuccessful if you have not received a response within 14 days of submitting your application. However, please keep a lookout on our website, www.bedifferent.co.za, for available positions that you may be suited for

Ad Visible Until: 29 October 2020
Ref: JHB005346/NL

Vacancy Type: Permanent",2.9,"Be Different Recruitment
2.9",Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Cloud Support Engineer (Big Data),-1,"ABOUT US

Amazon Web Services is the market leader and technology forerunner in the Cloud business. As a member of the AWS Support team you will be at the forefront of this transformational technology, assisting a global list of companies and developers that are taking advantage of a growing set of services and features to run their mission-critical applications. As a Cloud Support Engineer, you will act as the Cloud Ambassador across all the cloud products, arming our customers with required tools & tactics to get the most out of their Product and Support investment.

Would you like to use the latest cloud computing technologies? Do you have an interest in helping customers understand application architectures and integration approaches? Are you familiar with best practices for applications, servers and networks? Do you want to be part of a customer facing technology team helping to ensure the success of Amazon Web Services (AWS) as a leading technology organization?

If you fit the description, you might be the person we are looking for! We are a group of smart people, passionate about cloud computing, and believe that world class support is critical to customer success.

WHAT CAN YOU EXPECT FROM A LIFE AT AWS?

Every day will bring new and exciting challenges on the job while you:

· Learn and use groundbreaking technologies.
· Apply advanced troubleshooting techniques to provide unique solutions to our customers' individual needs.
· Interact with leading engineers around the world.
· Partner with Amazon Web Services teams to help reproduce and resolve customer issues.
· Leverage your extensive customer support experience to provide feedback to internal AWS teams on how to improve our services.
· Drive customer communication during critical events.
· Drive projects that improve support-related processes and our customers technical support experience.
· Write tutorials, how-to videos, and other technical articles for the developer community.
· Work on critical, highly complex customer problems that may span multiple AWS services.

WHY AWS SUPPORT?

· First and foremost this is a customer support role in The Cloud.
· On a typical day, a Support Engineer will be primarily responsible for solving customers cases through a variety of customer contact channels which include telephone, email, and web/live chat. You will apply advanced troubleshooting techniques to provide tailored solutions for our customers and drive customer interactions by thoughtfully working with customers to dive deep into the root cause of an issue.
· Apart from working on a broad spectrum of technical issues, an AWS Support Engineer may also coach/mentor new hires, develop & present training, partner with development teams on complex issues or contact deflection initiatives, participate in new hiring, write tools/script to help the team, or work with leadership on process improvement and strategic initiatives.
· Career development: We promote advancement opportunities across the organization to help you meet your career goals.
· Training: We have training programs to help you develop the skills required to be successful in your role.
· We hire smart people who are keen to build a career with AWS, so we are more interested in the areas that you do know instead of those you havent been exposed to yet.
· Support engineers interested in travel have presented training or participated in focused summits across our sites or at specific AWS events.
· As we operate on a follow-the-sun model, with Premium Support sites located globally, there is no after hours on-call or mandated overtime in this role.
· https://www.youtube.com/watch?v=GC3bWcFFZTo&t=24s



Basic Qualifications

The Big Data role supports our services that leverage data and produce business insights, which may include using Machine Learning/Artificial Intelligence (ML/AI). Helping our customers use and integrate Big Data services in what is arguably our industrys most exciting space. The portfolio of services covers EMR (Hadoop), DynamoDB (NoSQL), MangoDB, and Apache Cassandra.

· Advanced experience in Apache Hadoop, Apache Spark, Apache Hive, and Presto
· Advanced experience in DynamoDB or NoSQL technologies like MongoDB or Cassandra
· Advanced experience with System Administration with Linux (RHEL/CentOS) including Microsoft Active Directory, and LDAP integration.
· Experience with troubleshooting Kerberos Authentication problems.
· Experience with Network troubleshooting.
· Basic understanding of Machine Learning and statistics
· Experience with Java and Python and shell scripting
· Bachelors degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position



Preferred Qualifications

· Expert experience in the Hadoop Ecosystem including Apache Spark and Presto
· Expert experience in NoSQL
· Expert experience with blockchain technologies like Etherium Expert experience in data Data Lake architecture and administration
· Experience managing full application stacks from the OS up through custom applications
· Prior work experience with AWS - any or all of EC2, VPC, S3, RDS, EMR, Glue, SageMaker
· Excellent knowledge of Hadoop architecture, administration and support
· Expert understanding of distributed computing principles and their application in the cloud
· Good understanding of distributed computing environments Lead technical discussions on big data systems architecture and design
· Strong analysis and troubleshooting skills and experience
· AWS Certified Solutions Architect
· AWS certified Big Data Specialty
· Masters degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity and Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Response Center Engineer,-1,"Job Title
Response Center Engineer
Job Description


Philips is a world leading health technology company with a vision to make life better for people worldwide through meaningful innovation. Making good on this promise depends on our passionate, inspirational, collaborative and diverse team. We have over 80,000+ brilliant people around the world but are always looking for more. Like-minded, motivated, focused minds to join us in creating a healthier, more connected society while transforming themselves personally and professionally.

As a CCC Coordinator - Response Center Engineer you will have the opportunity to process customer calls and be responsible for screening and diagnosing professionally Healthcare equipment to support customers and colleagues remotely with solving technical issues and ensuring maximum customer satisfaction

You are responsible for:
Diagnose healthcare equipment to the quality standards set by Philips Healthcare (PH) remotely by interviewing customers or colleagues by telephone or by remotely logging in to the system
Advise Customer Care Center Coordinators and District Operations Managers and / or Team Leads about the best follow-up w.r.t. technical state of the diagnosed healthcare equipment
Advise the Customer Care Center Coordinators or Field Services Engineers about required spare parts and resources
Responsible for planning engineers related to Modality responsibility.
Responsible for coordination between CCC, CUSTOMER, Spare parts AND Engineer.
Responsible to drive Remote and FTR KPI’s to targets respectively 40% and 85%.
Will require minimal field work to keep abreast of technical capabilities.
Take calls from customers and make sure they are processed in the CCC ERP on timely manner including all relevant data
Support Field Services Engineers in the field with technical knowledge
Escalate technical issues to the Technical Support Specialist
Escalate technical issues to Business Unit support after consultation of the Technical Support Specialist
Monitor critical functions of the equipment’s in the IB and environmental conditions including RSN and True reachability.
Lead the planning and implementation of FSN’s and FCO’s accelerating remote implementation where applicable.
Submit timely and accurate service data, job sheets, reports, expense claims, radiation film badges, field problem reports and other paperwork as assigned
Keep abreast of new technologies likely to affect PH range of products
Use company property with care to ensure optimal results with minimal operational costs
Be a professional representative for PH with respect to customer problems, ensuring personal acceptability by the customer in behavior in accordance with PH policy and targets
Conform to PH safety standards including health and safety regulations and in the event of hazards or accidents to take immediate control of the situation and involve the Operations Manager and / or the responsible person to handle properly confidential issues according Philips standards and to act according General Business Principals
Follow all quality standards within the frame of valid PH business policies
Follow the company quality regulations (ISO 9001; PQA; TQM) and internal directives and procedures
You are a part of the dynamic South Africa Customer Care Centre Team .You will be reporting to the Customer Care Center Manager.

Requires a pleasant, assertive individual you can work very well in a team setting, a dynamic environment that requires flexibility and creativeness to achieve goals.

To succeed in this role, you should have the following skills and experience:
Degree level education or equivalent
Experience in maintenance and troubleshooting of technical complex systems
Fluent in English, verbal and written in addition to local language
In return, we offer you the unique combination of a critical and challenging role and a creative and empowering office environment. You will be actively encouraged to make improvements, establish best in class service and have a direct impact on the success of Philips on a daily basis.

Employment Equity

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply. Only apply for this role if you are a South African Citizen by birth or Naturalization prior to the 27 April 1994.

Why should you join Philips?

Working at Philips is more than a job. It’s a calling to create a healthier society through meaningful work, focused on improving 3 billion lives a year by delivering innovative solutions across the health continuum. Our people experience a variety of unexpected moments when their lives and careers come together in meaningful ways. Learn more by watching this video.

To find out more about what it’s like working for Philips at a personal level, visit the Working at Philips page on our career website, where you can read stories from our employee blog. Once there, you can also learn about our recruitment process, or find answers to some of the frequently asked questions.

Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.9,"Philips
3.9",Johannesburg,-1,10000+ Employees,1891,Company - Public,Health Care Services & Hospitals,Health Care,$10 to $25 million (USD),-1
Software Development Engineer - EC2 Placement,-1,"Build the systems that optimize how EC2 matches requests for Instances with the underlying compute capacity. EC2 Placement is seeking talented engineers to build the online and offline optimization systems for compute workload scheduling, and the customer capabilities to better manage those workloads. Amazon EC2 provides on-demand scalable compute capacity, and powers some of the largest services in the world. You will collaborate with a top-tier community of engineers to build systems to improve how customers are able to access EC2 compute resources.

The successful candidate will have strong software engineering experience, with a passion for thinking about, building and testing distributed systems. You have an interest in how Machine Learning and other optimization techniques can be applied to large-scale problems. You have demonstrated experience working with a team to design, build and operate large-scale systems. With strong engineering fundamentals, an analytical and data-driven approach to your work, and strong communication skills, you have the ability to collaborate well to deliver results. We move fast and work together on small teams to solve big problems.

If this opportunity sounds interesting, we would love to talk to you more about our work and the vibrant culture at AWS in Cape Town.

Basic Qualifications

· Degree in Computer Science or related field, or equivalent working experience
· 3+ years of industry experience in a software development environment
· Strong Computer Science fundamentals, including data structures, object-oriented design, algorithm design, problem solving, and complexity analysis.
· Proficiency in at least one modern programming language, such as Java, C#, Python, Scala, Kotlin

Preferred Qualifications

One or more of the following help you stand out:
· Demonstrated results designing, building and operating high-performance distributed systems in large-scale Linux environments
· Role model in writing high-quality, maintainable and secure code, mentoring others, and helping teams sharpen their development processes
· Ability to work effectively across teams to deliver results, with strong verbal and written communication skills
· Experience working with machine learning systems

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer - PBB IT,-1,"Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose


This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes
Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems
Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions
Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.

Research and best practices
Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development
Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.
Preferred Qualification and Experience
Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Aws Data Platform Engineer,-1,"Aws Data Platform Engineer

Posting Country:

South Africa

Date Posted:

15-Oct-2020

Full Time / Part Time:

Full Time

Contract Type:

Permanent

Joining Vodacom is more than a job, what we do matters. We don’t just carry minutes, texts and data – we carry people’s lives. And that’s a huge responsibility. If you think for a minute about the people you rely on…the likelihood is they rely on us.

Customers are at the heart of everything we do and we want to make a difference to the lives of our customers, and the communities in which we live and work. We support our people to give something back to the causes that mean the most to them through helping them give time and money to the charities they love.

And what’s it like to work here? We have created an environment where you can look forward to coming to work and are empowered to be at your best. We offer flexibility in how you work that helps you do your job in a way that suits you, opportunities to help you grow and progress throughout your career and a choice of benefits to suit your lifestyle.

Role Purpose
The H Band AWS Data Platform Engineer position is based within the Technology Business Unit.

The AWS Data Platform Engineer will be responsible for all Database services such as RDS, DynamoDB, etc. Should be able to migrate any databases from anywhere to AWS using any third-party tools or AWS database migration tool. Should also have understanding or expertise in creating data warehouses and data lake solutions on AWS.
Your responsibilities will include:
Apply practical knowledge of relational database design and usage with customers
Perform workload analysis and undertake performance tuning, as well as performance benchmarking in customer environments.
To develop state of the art solutions which are technically sound.
To provide a high-quality service to the Enterprise Cloud Services clients i.t.o. consultancy, solutions and delivery.
Commitment to team success and positive team dynamics including mentoring of other team members.
Passion for growing and applying technical skills in service to customers.
Be a trusted infrastructure advisor by providing objective, practical and relevant ideas, insights and advice.
Work collaboratively with consulting partners and technology teams to ensure high quality of solution delivery.
Encourage best practice and knowledge sharing with partners and cross-functional groups
Manage the overall database design and delivery of solutions.
Ability to make recommendations as they pertain to improvements in support/development initiatives and facilitate implementation with partners and cross-functional groups within the Business.
Participate in high level database solution definition and design during the implementation phase with the goal of providing reliable, stable and operationally sound applications that meet the Business requirements.
Ability to understand and translate business requirements into technical specifications
The ideal candidate will have:
A minimum of 3 years of industry related experience of which 1 year must be within a complex hosting environment.
Certifications in Database design, system architecture or cloud technologies.
Demonstrate knowledge of database systems internals including storage layouts and distributed databases/MPP architectures
Advanced SQL coding, tuning and query optimization.
Experience designing and leading database performance benchmarks.
Good knowledge of the different AWS services
Knowledge of cloud networking architecture, cloud operations, security, automation and orchestration.
Knowledge of database internals as it relates to query and system performance and tuning.
Understanding of overall system architecture, scalability, reliability, and performance in a database environment.
Excellent teamwork, time-management and organizational skills.
Perform other duties as deemed necessary and assigned by the customer and management
Strong interpersonal skills and problem-solving abilities.
Excellent documentation, communication and interpersonal skills.
Excellent analytical and problem-solving abilities.
Closing date for applications: Monday, 13 April 2020

The base location for this role is Vodacom World, Midrand

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply.
Vodacom is committed to an organisational culture that recognises, appreciates and values diversity & inclusion.

Commitment from Vodacom

Vodacom is committed to attracting, developing and retaining the very best people by offering a flexible, motivating and inclusive workplace in which talent is truly recognized, developed and rewarded. We believe that diversity plays an important role in the success of our business and we are committed to creating an inclusive work environment which respects, values, celebrates and makes the most of people’s individual differences - we are not only multinational but multicultural too. At Vodacom you will have access to our excellent flexible benefits programme that you would expect from any global company.",3.9,"Vodafone
3.9",Midrand,-1,10000+ Employees,1982,Company - Public,"Cable, Internet & Telephone Providers",Telecommunications,$10+ billion (USD),-1
Data Engineer Azure Data Factory,-1,"Enthuzex is looking for a motivated Lead Data Engineer to contribute towards the success of our Data and Analytics Technology initiatives. This is a hands-on technical role and this person will be responsible for the development and build of scalable solutions as it relates to the architecture strategies, data standards, digital data management, data integration, tools, and technology. The right candidate will play a deep dive hands-on critical development role in the digital transformation and in shaping how we acquire, ingest, transform and deliver data through the digital consumer channels.

Responsibilities:

Architect, design, develop and engineering end-to-end data pipelines across multiple data sources and systems of record.
Ensure data quality, integrity, security and completeness throughout the data lifecycle
Develop, design data models, data structures and ETL jobs for data acquisition and manipulation purposes
Develop deep understanding of the data sources, implement data standards, maintain data quality and master data management
Developing data services and API
Work closely with the cloud service providers to ensure completeness and alignment with the service offerings
Manage and maintain cloud based data and analytics platform
Deep understanding of the cloud offerings and engage in quick proof of concepts and proof of value in prototyping data and analytics solutions and derive viability
Ability to interact with the business stakeholders to understand requirements and translating into technology solutions

Expirience:

Experience in Cloud platform AWS or Azure eco-system. (Azure preferred)
Data Engineering/Development experience with SQL (Oracle, SQL Server, MySQL)
Strong development background creating pipelines and complex data transformations and manipulations using one of the languages Python, Java, R, or Scala with Databricks/Spark
Experience in NoSQL Databases and Big data technologies including Hadoop
Experience with API / RESTful data services
Worked on real-time data capture, processing and storing using technologies like Azure Event Hubs and Analytics
Experience working with different data storage options including AWS S3, Azure BLOB storage etc.
Understanding of different data formats including Parquet, Avro, CSV, ORC etc.
Prior experience with MPP databases and maintain large amount of data processing
Experience with Azure Data Factory and Azure Data Catalog is a big plus and mandatory
Experience with Microsoft/Azure ETL solutions and business Intelligence technologies is a big and mandatory
Past working experience on a fast paced and agile environment
Perform ongoing monitoring, automation and refinement of data engineering solutions
Experience in leading high visibility transformation projects that interacts with multiple business lines
Build and meet project timelines and manage delivery commitments with proper communication to management

Qualifications

Bachelor’s degree with 4+ years of relevant experience
Willingness to learn new technologies and thrive in an extremely fast paced environment
Team player and easy to work with.

Applicants must demonstrate their ability to master new enterprise level technologies. Successful applicants will exemplify Enthuzex ethical principles of uncompromising integrity, respect for others, and accountability for decisions

send cv's info@enthuzex.co.za",-1,Enthuzex,Leslie,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Scientist,-1,"The world is changing.

We all want something different.

At Luno, we see you as an individual.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the world, and to do so, we need the best team on board for our mission.

A bit about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 3 million customers across 40 countries.
We are Series B funded, backed by Balderton Capital and the Naspers Group.
Our platform has processed over 8 billion dollars since we've launched
We're proud to be one of the world's most international cryptocurrency teams from 26 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
The role in a nutshell:

Identifying opportunities in the business that could benefit most from cognitive applications, as well as building and enhancing organisational capabilities for deriving value from multiple data sources using data science.

What we'd like you to have:
Bachelor's degree or higher in the natural sciences or technical fields such as Mathematics, Statistics, Computer Science, Engineering or Economics
Enthusiasm to work in the cryptocurrencies space
Advanced SQL skills
Solid understanding of exploratory data analysis, predictive analytics, and optimisation using Python, R, Matlab, RapidMiner, KNIME or other data science-oriented platforms
Proficiency in the use of data science and machine learning domain-specific languages such as ""Caret"" and the ""Tidyverse"" suite of tools in R, or ""Pandas"" in Python
Strong interpersonal and communication skills
Communicating data insights using storytelling narratives
Ability to work independently, as well as within and across teams
Ability to successfully complete projects with large and/or incomplete data sets
More about what you'll be doing:
Optimising product performance by tracking and analysing customer behaviour on web and app, in collaboration with software engineers and product designers
Providing the business with reports and dashboards, on key performance metrics
Developing metrics to accurately assess the health of our Exchange platform
Comparative data-driven analysis of our Exchange against alternative platforms
Formulating business requirements into analytical objectives
Designing and running experiments to test hypotheses
Hacking through complex business problems using advanced data analysis to provide insights and recommendations
Building, maintaining, and optimising decisioning systems using advanced statistical and predictive modelling techniques
What will set you apart:
An advanced degree in Mathematics, Statistics, Computer Science or related field
At least 3 years' experience working in a similar role
A basic understanding of trading in financial markets
Experience working with a data analytics and visualisation platform such as Tableau, Cognos, QlikView, or Looker
Familiarity with using Google Analytics to understand customer behaviour
Solid knowledge of statistical and machine learning techniques
Familiarity with modern distributed data storage and processing systems such as Amazon Redshift, Big Query, Snowflake, Databricks and Apache Spark
You can gather and synthesise facts, theories, trends, patterns, inferences, and key issues in complex and variable situations
Ability to diagnose problems using formal problem-solving tools and techniques from multiple angles to generate multiple possible solutions
A sense of anticipating long-term problem areas and associated risk levels with objective rationale
Remote Life at Luno

If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
You'll be able to continuously upskill yourself with access to free online learning via MyAcademy, an international teaching marketplace with over 100000 courses from Harvard and other leading providers + share knowledge with your peers.
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity and paternity leave, and you can even take paw-ternity leave for your furry friend.
Annual Inspiration Day! Make time for that pottery course or spa day you've always wanted to do.
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"EY is a global leader in
assurance, tax, transaction and advisory services. Technology is at the heart
of what we do and deliver at EY. Technology solutions are integrated in the
client services we deliver and are key to our innovation as an organization.

Fueled by
strategic investment in technology and innovation, Client Technology seeks to
drive growth opportunities and solve complex business problems for our clients
through building a robust platform for business and powerful product engine
that are vital to innovation at scale. As part of Client Technology, you’ll
work with technologists and business experts, blending EY’s deep industry
knowledge and innovative ideas with our platforms, capabilities, and technical
expertise. As a catalyst for change and growth, you’ll be at the forefront of
integrating emerging technologies from AI to Data Analytics into every corner
of what we do at EY. That means more growth for you, exciting learning
opportunities, career choices, and the chance to make a real impact.

The selected
candidate
Develops
large and complex data architecture, composed of models, policies, rules or
standards that govern which data is collected and how it is stored, arranged,
integrated and put to use in data systems, including the design, build and
management of data infrastructure to address business requirements
Creates
sound use case driven roadmaps, depicting data architecture as-is and to-be
capabilities with the business by engaging with multidisciplinary teams, and by
identifying, managing and mitigating risk
Develops
relationships across the business to understand data requirements, applies deep
technical knowledge of data management to solve business problems in areas
where solutions may not currently exist, necessitating new solutions/ways of
working/technologies and proactively articulating these to the business
Review,
identify the latest emerging technologies, augmenting by services from the
leading cloud providers to solution and recommend the best next generation data
platform value driven approach for our clients
Your Key Responsibilities Include
Create
and maintain conceptual, logical and physical database models
Document
functional requirements and system specifications into the data architecture
and detailed design specifications for current and proposed designs
Document
and adhere to development standards and best practices in database designs
Maintain
highly effective and consistent communication within the team, peers, and the
leadership team
Reverse
engineer SQL code and modify it to solve problems/issues
Contribute
to the definition and implementation of data governance practices
Design
both data structures and data integration practices
Work
closely with the infrastructure teams to create a physical environment to
support data services
Evaluate
new and existing (internal and external) technologies and services in support
of data services and data analytics objectives
Skills And Attributes For Success
Understanding
of business process reengineering and business modeling concepts, business
systems development and analysis
Hands-on
experience in designing and implementing hybrid cloud and on-prem solutions
Experience
working with the latest versions of SQL Server
Experience
applying SAFe/Scrum/Kanban methodologies
Ability
to exercise judgment in solving technical, operational, and organizational
challenges
Expert
programming, performance tuning and troubleshooting skills, using the latest
popular programming languages for example python
Demonstrate
proactive approach to identifying issues and presenting solutions and options,
and where appropriate, leading to resolution
Minimum Qualifications
5+ years
demonstratable work experience as a Data Architect using data modeling tools
2-3 years
SQL coding experience on large projects
Must
possess expert SQL programming, performance tuning and troubleshooting skills
Create
database objects and SQL scripts
Understand
and developed data pipelines
Know how
to deformalize data for data science models
Experience
in python, spark and notebooks
Experience
designing data warehousing solutions
Experience
designing next generation data platforms utilising cloud services
In-depth
understanding of database structure principles
Seamlessly
able to translate business requirements to technology requirements
What We Look For
Strong
analytical skills and problem-solving ability
A
self-starter, independent-thinker, curious and creative person with ambition
and passion
Excellent
inter-personal, communication, collaboration, and presentation skills
Customer
focused
Excellent
time management skills
Positive
and constructive minded
Takes
responsibility for continuous self-learning
Takes the
lead and makes decisions in critical times and tough circumstances
Attention
to detail
High
levels of integrity and honesty
Curious
about new emerging technology
About EY
As a global leader in assurance, tax, transaction and consulting
services, we’re using the finance products, expertise and systems we’ve
developed to build a better working world. That starts with a culture that
believes in giving you the training, opportunities and creative freedom to make
things better. Whenever you join, however long you stay, the exceptional EY
experience lasts a lifetime.",3.8,"EY
3.8",Johannesburg,-1,10000+ Employees,1989,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Architect - Principal,-1,"We are looking for Principle Data Architect to join our Engineering team in Cape Town.

The world is changing.
We all want something different.
At Luno, we see you as individuals.

Together, we are upgrading the world of work to unleash the potential within and empower you to become the best possible version of yourself.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the financial landscape, and to do so, well we need the best team on board for our mission. In short, to achieve our goals, we need rockstars. As simple as that.

A little about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 5 million customers across 40 countries.
We're part of the Digital Currency Group, a group of companies driving progress in the cryptocurrency and blockchain space that includes Grayscale, Genesis, Coindesk and Foundry Services
Our platform has processed over $8 billion to date
We're proud to be one of the world's most international cryptocurrency teams from 43 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
How we work


Our engineering team (currently ~100 engineers) is split into organisations which we call Fleets. Each Fleet focuses on a core customer journey (onboarding, security, payments, support, new business, growth and marketing etc.). Each of these fleets contains multiple smaller teams called Pods, each of which focuses on a specific aspect of the product.

Pods will include a product owner, product designer, back-end engineers, Android, iOS and Web developers, who each bring a unique perspective to the problem you are all contributing towards.

We're agile, use scrum, continuous integration and continuous delivery, deploying to production every single day.

We're building teams to help us succeed in our mission to upgrade the world to a better financial system. You'll be joining a group of highly motivated software engineers who you'll work collaboratively with across our pods.

As a fast-growing company with offices around the world, you'll immediately see how your contributions directly impact both our internal users and client experience. Many of the problems we are solving result in trail blazing solutions which can't be found on Stack Overflow; so we're looking for engineers who flourish working in a complex domain.

In your first six months, you will:


...start at Luno by learning our processes, meeting the wider team and starting our engineering on-boarding program. After getting comfortable with the basics, you'll start learning our idiomatic patterns in a safe, easy-to-follow way - by building your own toy micro services. You'll get to practice how we do design docs, code reviews, deployments, events, logging and monitoring.

You'll meet the Pod(s) you'll be working with and quickly align on the teams' current OKRs and product roadmap. We succeed as a team, so we will provide you with regular feedback from your manager and peers and will encourage you to do the same.

What you'll do:
Work closely with our data science and platform teams on projects introducing new streams of data into our data lake
You will get to bring new ideas on how to further develop and innovate our data solutions and how to expose that data to the business
Accountable and Responsible for the design and architecture of Data systems that are robust and scalable.
Work in an Agile/Scrum framework or Agile mindset
Data backup/recovery and storage
Pick-up and learn new concepts, in both engineering and product, and be able to apply that knowledge quickly.
The ideal candidate for this role will have:
7+ years' experience in maintaining scalable data solutions and/or you are passionate about it
Ability to understand, communicate and advocate between build vs buy
Proven track record of setting up, restructuring and maintenance of databases
You know your way around ETL and you have experience with SQL
Experience in the AWS Data stack (RedShift,DynamoDB, Amazon RDS)
Familiarity with integrating data stores with BI platforms such as Looker, Tableau, or Power BI
You have experience with the concepts of CI/CD
Coding skills in e.g. Go, Python
Bachelor's degree in a related field preferred
AWS Certified DataOps Administrator
Be friendly, transparent, articulate and driven to succeed
Basic knowledge of and passion for digital currencies like Bitcoin
A work permit for South Africa if you are not a South African citizen
Don't be put off if you don't tick all of the boxes – they're a guide based on what we'd love to see but we appreciate that excellent software engineers have diverse backgrounds.

Remote Life at Luno


If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity / paternity and even (yes, you are reading it correctly) paw-ternity for your furry friend..
Annual Inspiration Day.. like that pottery course you've always been meaning to do!
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. You'll need to hold the legal right to work in South Africa already as we cannot provide visa sponsorship.

Be part of the change!",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer - EC2 Capacity Data Analytics,-1,"EC2 Capacity Data Analytics (CDA) team is looking for a Data Engineer to join our team.

Our team is part of the EC2 Capacity Engineering organization, which is responsible for providing the elasticity EC2 customers need to scale up/down compute resources in a cost-efficient manner. We predict customer usage across thousands of configuration combinations to deliver exactly what our customers require in just the right amount of time with just the right amount of capacity.

As a Data Engineer, you will build the ETL and analytics solutions for our internal customers to answer questions with data and drive critical improvements for the business. You will use best practices in software engineering, data management, data storage, data compute, and distributed systems. On any given day, we use Python, Scala, Java, SQL, Lambda, CloudFormation, Redshift and Glue as well as other public AWS services and a host of Amazon internal tools. We dont expect you to be an expert in, or necessarily even be familiar with all of the technologies listed above, but we do expect you to be excited to learn about them.

This position involves on-call responsibilities, typically for one week every two months. Our team is dedicated to supporting new team members. We care about your career growth, we try to assign projects and tasks based on what will help each team member develop into a more well-rounded engineer and enable them to take on more complex tasks in the future.

Our team values work-life balance and we are flexible when people occasionally need to work from home.

Job Duties
Develop and maintain automated ETL pipelines for big data using languages such as Scala, Spark, SQL and AWS services such as S3, Glue, Lambda, SNS, SQS, KMS. Example: ETL jobs that process a continuous flow of JSON source files and output the data in a business-friendly Parquet format that can be efficiently queried via Redshift Spectrum using SQL to answer business question.

Develop and maintain automated ETL monitoring and alarming solutions using Java/Python/Scala, Spark, SQL, and AWS services such as CloudWatch and Lambda.

Implement and support reporting and analytics infrastructure for internal business customers using AWS, services such Athena, Redshift, Spectrum, EMR, and QuickSight.

Develop and maintain data security and permissions solutions for enterprise scale data warehouse and data lake implementations including data encryption and database user access controls and logging.

Develop and maintain data warehouse and data lake metadata, data catalog, and user documentation for internal business customers.

Develop, test, and deploy code using internal software development toolsets. This includes the code for deploying infrastructure and solutions for secure data storage, ETL pipelines, data catalog, and data query.


Basic Qualifications

· Bachelors degree in Computer Science or related technical field, or equivalent work experience.
· 4+ years of overall work experience including Software Engineering, Data Engineering, Database Engineering, Business Intelligence.
· Experience with AWS technologies stack including Lambda, Glue, Redshift, RDS, S3, EMR or similar big data solutions stack

Preferred Qualifications

· Demonstrate efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data.
· Demonstrable proficiency in distributed systems and data architecture; design and implementation of batch and stream data processing pipelines; knows how to optimize the distribution, partitioning, and MPP of high-level data structures.

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer,-1,"Our client based in Johannesburg is urgently looking for a Data Engineer to be on a 3 months contract
Build data pipelines, experience in new tech like nifi, kafka, python

Joburg based, open to EE, 3 month contract with the option to extend, must be available at short notice",-1,EQplus,Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Overview
Job ID: 51456
Job Sector: Information Technology and Services
Country: South Africa
Region/State/Province/District: Gauteng
Location: Johannesburg

Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose

This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes

Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems

Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions

Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.
Research and best practices

Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development

Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.

Preferred Qualification and Experience

Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry

Knowledge/Technical Skills/Expertise

Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision

PLEASE NOTE: All our recruitment and selection processes comply with applicable local laws and regulations. We will never ask for money or any form of payment as part of our recruitment process. If you experience this, please contact our Fraudline on +27 800222050 or forward to TransactionFraudOpsSA@standardbank.co.za",4.1,"Standard Bank
4.1",Johannesburg,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"About us

At PBT Group we pride ourselves on being a Data Specialist organisation. With 20 years of experience in 27 countries over 3 continents, our team of 550 consultants have implemented more than 700 projects.",4.3,"PBT Group
4.3",Johannesburg,-1,Unknown,-1,Company - Private,Accounting,Accounting & Legal,Less than $1 million (USD),-1
Data Engineer,-1,"Kick-start your career in the online gaming world and experience the very latest in technology and innovation.

The Department:

Our mission is to provide our customers with the best online betting experience and share the thrill of gaming with them. Data is at the very heart of our business and is vital in everything we do.

Our cross-functional Data team has a big and exciting challenge ahead. We are in the process of re-platforming our traditional, on-premises RDBMS environment to a new microservice architecture in the cloud. We’re making use of the diverse set of data technologies in Microsoft Azure to offer new services, reporting structures and real-time data pipeline while serving the day-to-day requirements of a rapidly growing, data-hungry organisation.

Purpose of the Role:

This is an excellent opportunity for an individual who is looking to gain new skills. We are committed to creating a culture of learning and regularly run proof of concepts, provide internal demos, manage workshops and attend external conferences. Our data team has a wide range of skills including development for highly transactional RDBMS systems, data warehousing, data science and cloud technologies and we are always working to raise everyone’s game.

Duties include, but not limited to:

Work as part of an agile Data Engineering Team
Development of greenfield projects in Azure
Develop and maintain on-premises RDBMS/DW systems
Create robust ETL services and real-time data pipelines
Build and maintain Continuous Integration and DevOps pipelines
Test-driven development and pair programming with colleagues

Essential Criteria:

C#, .Net, Visual Studio
Git, Azure DevOps
NoSQL development (CosmosDB)
Demonstrable understanding of MS SQL Server in a highly transactional environment
Demonstrable understanding of development in Microsoft Azure
Able to understand query plans and identify performance bottlenecks
Test/Business-Driven Development
Building Continuous Integration/Deployment pipelines
Communicate effectively with both technical and non-technical stakeholders

Desirable Criteria:

Implementing Data Storage and Processing solutions in Azure (ARM Templates, Storage Accounts, Data Lake Storage, SQL DB, Cosmos DB, EventHubs, Function Apps, Log Analytics, Data Factory, Databricks, Polybase)
Implementing Security, Disaster Recovery, High Availability, Auditing, Monitoring and Alerting solutions in Azure
Automating tasks in Azure using Powershell / CLI
Predicting costs and optimizing spending in Azure
Message Queues (RabbitMQ, Kafka)
Python

Person Specifications:

Resilience
Teamwork
Technical Knowledge
Communication skills
Stress Tolerance
Please note we will apply relevance to our Talent Management and Talent Development Programme as part of our recruitment process.
Shortlisted candidates may need to complete an assessment.
This position requires trust and honesty it has access to customers financial details - therefore a credit and criminal record check will be conducted. The qualifications identified herein are an inherent job requirement; therefore, a qualification verification check will be done. By applying for this role, and supplying the necessary details, you hereby grant us permission to apply for these checks. This will be done in a confidential manner, and solely for the purposes of verification.

To view all current vacancies, please visit our website, www.digioutsource.com

Should you not hear from us within 2 weeks, please deem your application as unsuccessful.

The perfect place to work, play and grow!",3.9,"Digital Outsource Services
3.9",Cape Town,-1,1001 to 5000 Employees,1997,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
Data Engineer,-1,"At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes

Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.

Key Responsibilities

Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.

Key Traits

Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern

Position Requirements

2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.

Where will you work? This role will be based out of Durbanville, South Africa.",3.1,"Aculocity, LLC
3.1",Durbanville,-1,1 to 50 Employees,2006,Company - Private,IT Services,Information Technology,$1 to $5 million (USD),-1
Data Engineer,-1,"ENVIRONMENT:

A rapidly growing E-Commerce Platform seeks a highly talented Data Engineer to make an invaluable contribution to data democratisation and literacy vision by making accessible and easy-to-use data products and tools. You will require a Comp-Sci Degree or 3 years’ relevant industry experience, MySQL, PostgreSQL, Java, Python, in-depth understanding of OLAP, Data Marts, Star Scheme, Snowflake, be familiar with Jenkins, Travis, Circle CI, Docker, Kubernetes, experience with Kafka, Pub/Sub, Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks & significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing & Data Lake design and implementation and Lambda/Kappa architectures.

DUTIES:

Design, develop, test and maintain data architecture.

Prepare data for descriptive, predictive and prescriptive modelling.

Automate repetitive tasks and manual processes related with the data usage.

Optimize data delivery.

Design, develop and test large stream data pipelines to ingest, aggregate, clean, and distribute data models ready for analysis.

Ensure the highest standard in data integrity.

Leverage best practices in continuous integration and delivery.

Collaborate with other engineers, ML experts, analysts, and stakeholders to produce the most efficient and valuable solutions.

Implement features, technology, and processes that move us towards industry best practices, improving on scalability, efficiency, reliability, and security.

Operations and ownership of systems in production, responding to incidents.

REQUIREMENTS:

Qualifications –

Comp-Sci Degree or 3 years relevant industry experience.

Experience/Skills –

Open source relational database systems e.g. MySQL, PostgreSQL, etc.

Significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing, and Data Lake design and implementation and Lambda/Kappa architectures.

A thorough understanding of database and data warehousing principles e.g. OLAP, Data Marts, Star Schema, Snowflake, etc.

Java and Python.

Familiar with CI/CD tools such as Jenkins, Travis, Circle CI, etc.

Experience with Kafka, Pub/Sub, or other event-based systems.

Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks, etc.

Working in cloud environments and with containerisation frameworks, tools and platforms e.g. Docker, Kubernetes, GKE, etc.

A deep understanding of data pipelining, streaming, and Big Data technologies, methods, patterns, and techniques.

Troubleshooting complex database operations and performance issues.

Automating tasks using Shell Scripting or writing small applications.

ATTRIBUTES:

Works well with people and is passionate about helping people be their best.

A team player, an active listener, mentor, and able to communicate well.

Shows solid reasoning and decision making, with the ability to work under pressure.

Is passionate about technology, systems and data.

Is curious, always learning, and keeping up to date with the industry.

While we would really like to respond to every application, should you not be contacted for this position within 10 working days please consider your application unsuccessful.

COMMENTS:

When applying for jobs, ensure that you have the minimum job requirements. Only SA Citizens will be considered for this role. If you are not in the mentioned location of any of the jobs, please note your relocation plans in all applications for jobs and correspondence.",-1,Datafin IT Recruitment,Cape Town,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Cartrack is looking for passionate data science and engineering candidates that can join a growing team that is responsible for the intelligence and efficiency solution provision to over a million subscribers, many of whom are large fleets. We are in the midst of creating revolutionary platforms that will change the way that people interact with their vehicles.

You will have the opportunity to work with the very brightest global subject matter experts that are transforming the automotive industry across Fleet Management, Asset Management and Insurance Telematics solutions.

Get to know the role:

The role of a data engineer is a supporting one, but it is also an extremely vital one. As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements. We want to see candidates with mechanical tendencies and a desire to know how things work and to improve them.

The day-to-day activities:

Design, construct, install, test and maintain data management systems.
Build high-performance algorithms, predictive models, and prototypes.
Ensure that all systems meet the business/company requirements as well as industry practices.
Integrate up-and-coming data management and software engineering technologies into existing data structures.
Develop set processes for data mining, data modeling, and data production.
Create custom software components and analytics applications.
Research new uses for existing data.
Employ an array of technological languages and tools to connect systems together.
Install/update disaster recovery procedures.
Recommend different ways to constantly improve data reliability and quality.
Work on and maintain Data pipelines.

Requirements Essential:

At least 5 years’ proven experience as a Data Engineer, DevOps Engineer, Software Developer, or similar.
Proficient in Linux/Unix and shell scripting as well as in functional programming languages.
Expertise in setting up and explored with technologies such as Hadoop and Spark.
Bachelor’s degree in computer science, software/computer engineering, applied mathematics, or physics.",3.3,"Cartrack
3.3",Johannesburg,-1,501 to 1000 Employees,2004,Company - Private,Security Services,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Data Engineer,-1,"Data Engineers build and support data pipelines and datamarts built off those pipelines. Both must be scalable, repeatable and secure. The Data Engineer helps to facilitate gathering data from a variety of different sources, in the correct format, assuring that it conforms to data quality standards and assuring that downstream users can get to that data timeously. This role functions as a core member of an agile team. These professionals are responsible for the infrastructure that provides insights from raw data, handling and integrating diverse sources of data seamlessly. They enable solutions, by handling large volumes of data in batch and real-time by leveraging emerging technologies from both the big data and cloud spaces. Additional responsibilities include developing proof of concepts and implements complex big data solutions with a focus on collecting, parsing, managing, analysing and visualising large datasets. They know how to apply technologies to solve the problems of working with large volumes of data in diverse formats to deliver innovative solutions. Data Engineering is a technical job that requires substantial expertise in a broad range of software development and programming fields. These professionals have a knowledge of data analysis, end user requirements and business requirements analysis to develop a clear understanding of the business need and to incorporate these needs into a technical solution. They have a solid understanding of physical database design and the systems development lifecycle. This role must work well in a team environment.

Job Objectives

Work Complexity: * Architects Data analytics framework. * Translates complex functional and technical requirements into detailed architecture, design, and high performing software. * Leads Data and batch/real-time analytical solutions leveraging transformational technologies. * Works on multiple projects as a technical lead driving user story analysis and elaboration, design and development of software applications, testing, and builds automation tools.

Main Job Objectives: 1. Development and Operations 2. Database Development and Operations 3. Policies, Standards and Procedures 4. Communications 5. Business Continuity & Disaster Recovery 6. Research and Evaluation 7. Coaching/ Mentoring

Qualifications

Essential: 4 years Bachelors degree in computer science, computer engineering, or equivalent work experience AWS Certification at least to associate level

Experience

Essential:

5+ years Data engineering or software engineering

3-5 years demonstrated experience leading teams of engineers

2+ years Big Data experience

5+ years experience with Extract Transform and Load (ETL) processes

2+ years Could AWS experience

At least 2 years demonstrated experience with agile or other rapid application development methods - Agile exposure, Kanban or Scrum

5 years demonstrated experience with object oriented design, coding and testing patterns as well as experience in engineering (commercial or open source) software platforms and large scale data infrastructures.

Desirable:

5+ years Retail Operations experience

Knowledge and Skills

Essential: *Creating data feeds from on-premise to AWS Cloud (2 years) *Support data feeds in production on break fix basis (2 years) *Creating data marts using Talend or similar ETL development tool (4 years) *Manipulating data using python and pyspark (2 years) *Processing data using the Hadoop paradigm particularly using EMR, AWSs distribution of Hadoop (2 years) *Devop for Big Data and Business Intelligence including automated testing and deployment (2 years) * Extensive knowledge in different programming or scripting languages * Expert knowledge of data modeling and understanding of different data structures and their benefits and limitations under particular use cases.

Further technical skills required: * Capability to architect highly scalable distributed systems, using different open source tools. * Big Data batch and streaming tools * Talend (1 year) * AWS: EMR, EC2, S3 (1 year) * Python (1 year) * PySpark or Spark (1 year) - Desirable * Business Intelligence Data modelling (3 years) * SQL (3 years)",-1,Datonomy Solutions,Brackenfell,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We are assisting one of our clients that is based in Pretoria to fill a role of a Data Engineer

This is a 12 month contract role

Objective of this Scope of Work

The Data Engineer will drive improvement of the data management maturity levels and provide the necessary technical support within the company to support reliable and effective decision-making, appropriate usage and protection thereof.

Scope of Services Definition

The scope will include but will not be limited to:

ï†· To develop, construct, test and maintain architectures.

ï†· To ensure architectures will support the requirements of business.

ï†· To discover opportunities for data acquisition and sharing.

ï†· To develop data set processes for data modelling, mining and production.

ï†· To employ a variety of languages and tools to marry systems together.

ï†· To recommend way to improve data reliability, efficiency and quality.

ï†· To prepare data for use in predictive and prescriptive modelling.

ï†· To conduct research to answer industry and business questions.

ï†· To leverage volumes of data from internal and external to answer business questions.

ï†· To develop and manage stakeholder relations effectively to promote data management across the organisation and support reliable decision making and appropriate data usage.

ï†· To participate and provide technical support in cross organisational activities relating to any of the above mentioned data management activities.

ï†· To provide regular progress reports as per stakeholder requirements and present data management updates in various forums as required.

Minimum qualification Required:

ï†· A minimum of a Bachelors degree in Computer Science or Information Management OR equivalent;

ï†· A minimum of five to eight years experience in a data management environment",-1,HR Genie,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Our client based in the Northern Suburbs, is currently looking for a Data Engineer to join their team.

Responsibilities
Our client is a dynamic IT company that delivers value-driven IT solutions to the group. Our work lives revolve around our DNA. We take pride in our work, treat our colleagues, partners and our country with respect. We exercise collaborative decision-making and believe in having a balance in life. We do this all while having fun and enjoying what we do.

The primary focus of this position is to use technical skills to put software, systems and data together in a way that extracts meaningful insights from raw data. You will need to be helpful and supportive to your team and fellow developers. You join an energetic, focused and dynamic team.

Interact with clients to understand requirements and business problems/needs

Identify, analyse, visualise and understand supporting data to propose solid solutions

Create technical documentation for reference and reporting

Support existing solutions within GCP and Oracle

Doing standby on a rotating basis

Key Competencies and Qualifications

Matric

Tertiary qualification in IT

Preferred cloud experience in AWS/AZURE/GCP

At least 3 years of data warehouse ETL experience

Dimensional Modelling

Data analyses

Experience with data visualization and visualization tool(s)

Knowledge of the retail industry will be beneficial

Understanding and experience with version control SVN/GIT

Preferred – Korn shell scripting, Python/Java, SQL

Google Cloud Platform experience would be looked upon favourably

Having a broad understanding of different SDLC’s

Preferred agile experience

Strengths

The natural tendency to take ownership and responsibility

Strong problem solving, critical thinking, effective planning and organisational skills

Detail-oriented with excellent communication skills

You have a can-do attitude and positive outlook on life

Can cope under pressure

Curious and interested in analysing problems and possible solutions

Strong team player

Self-driven learner, passionate about new technology

Above all, be passionate about what you do

Should you wish to apply for the position, please apply directly via this job board, please ensure that you quote reference number 201620 subject heading or email body.

Please note that due to the high volume of CV's received; only shortlisted applicants will be contacted. Should you not receive communication from our offices within two weeks of submission please note that your application will not be considered for this position.

We will keep your CV on file and re-establish contact with you should opportunities in line with your expertise become available again.

Should you require any additional information give us a call on 021 012 5566.",-1,Surgo HR & Training,Cape Town,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We believe that our employees fuel our organization, essential to enable us to help our customers overcome their business challenges and achieve sustainable growth. As a result, we are committed to growing each individual and providing them with the challenges, feedback and support needed to achieve success in their career

If this sounds appealing, and like us, you get excited about data: its collection, storage, transformation or display, see if you’ve got what it takes to join our sought after DATA team.

Key Responsibilities And/or Outputs

You will represent IQbusiness at our customers, sometimes alone, and sometimes as part of an IQ team.

Providing a superior customer experience by building and maintaining relationships, working at customer offices, keeping data confidential
Design and develop – databases, SQL queries, stored procedures, reports, dashboards or integration solutions
Produce solutions for both real-time and batch environments
Test your work to ensure compliance
Solve problems, and do root cause analysis
Prioritize your workload
Assist in other areas relating to your true data function, such as data modeling, data and business analysts
Interact with a variety of individuals: senior, junior, technical and from business
Provide guidance to fellow colleagues, or even manage a team
Uphold the IQ values, which are to care, learn & share; innovate; deliver as well as to build, enhance and maintain relationships

Education

Matric pass
A tertiary qualification, preferably in an ICT relevant field
Appropriate Microsoft certifications are beneficial but not required

Requirements

3 - 6 years experience in the Data Engineering environments and technologies
Great communication skills
A passion for SQL, databases or reports
Can you write stored procedures, design complex queries and create views and triggers?
Are you able to work out the relationships in a data warehouse or the aggregation of a cube?
Do you extract and display useful information when you see patterns and trends in data?
Strong knowledge of the financial services industry, ideally in a consulting role
The use of data related software: databases, ETL and BI tools; report writing and analytical tools
We use a lot of Microsoft products. You may often be expected to use MS SQL Server, SSIS, SSRS, SSAS and Power BI to develop solutions
What other relevant software have you’ve used?
Ability to work in different project methodologies: Waterfall and/or Agile
Knowledge of full SDLC
Exposure to logical and physical data modeling

Equal Employment Opportunity

IQbusiness is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, citizenship, marital, domestic or civil partnership status, sexual orientation, or gender identity",3.7,"IQbusiness South Africa
3.7",Johannesburg,-1,1 to 50 Employees,-1,Company - Private,Consulting,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"We value a data engineer as someone who works behind the scenes to obtain, process and supply data via various methodologies and technologies, to various consumers, in ways and forms that makes sense and add value. This definition is very broad, as the field of data engineering is just as broad.

You may be the type of data engineer that develops API endpoints for the consumption of data by end users or even another data pipeline, or you may be the type of data engineer that develops highly distributed, high availability data processing pipelines in an effort to satisfy the need of the ever questioning data analysts and/or data scientists.

You have awesome knowledge about the following concepts
Data modelling
Relational data modelling in traditional relational database management systems. (Microsoft SQL Server, MySQL, PostgreSQL, etc)
Coercing unstructured and semi-structured data into a structured form.
Data pipelining knowledge - data extraction and transformation.
Data transformation knowledge for reporting and analytics purposes.
Knowledge of the MapReduce and related data processing paradigms would be a boon.
You have the following technical competencies
Writing SQL queries, that can relate, transform and aggregate data from many differing sources where natural keys may or may not exist.
Experience with writing data pipelines that move and transform data, for various uses.
Working knowledge of a general purpose programming language like Python would be a boost.
Working knowledge of columnar databases such as Google BigQuery, and SAP HANA would be a boost.
Working knowledge of highly distributed technologies such as Apache Hadoop or Apache Spark would be a boost.
Working knowledge of NoSQL technologies, such as Apache Solr would be a boost.
You have the following personal competencies
The ability to solve problems.
The ability to rotate around a problem, to see if solutions can be gained in different ways.
The ability to work in an ever changing, unstructured environment.
The ability to work as part of a team, with vastly differing skill sets and opinions.
The ability to contribute ideas to the quorum.
The ability to mentor and provide guidance for other team members.
A systems approach to thinking, as opposed to a siloed approach. The candidate needs to understand how their work affects the greater system.
The ability to work without supervision, and take accountability for the work they deliver.
The ability to liaise with a client, sifting through the fluff and extracting the actual requirements.
If this is you - apply now and we'll get in touch",-1,DotModus,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Data Engineer

Our client in the contact centre space is currently seeking a DATA ENGINEER that will work on the collecting, storing, processing, and analyzing of large datasets. The primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them. You will also be responsible for integrating them with the architecture used across the company.

Key Performance Areas:

Data reporting.
Implementing ETL processes.
Defining data retention policies.
Management of Customer Lead data.
Provision of data for advanced analytics.
Maintenance of internal client scorecards.
Assist team in resolving data-related support queries.
Optimize existing data processes through automation.
Assist with all data-related reporting and documentation.
Maintenance and optimisation of the Analytics database.
Provide technical support to and supervision of junior data administrators.
Continuous upskilling on new technologies, frameworks and market trends.
Monitoring performance and advising any necessary infrastructure changes.
Identifying, selecting and integrating any Big Data tools and frameworks required to provide real-time analytics.

Educational Requirements

IT related Degree or Diploma is a pre-requisite

Required Skills/Experience

ETL tools: Advanced SSIS
BI/Reporting : Qlikview/Power BI/ SSRS or SSAS
Programming languages: JAVA, C# , Python, SAS or R
Experience with NoSQL databases and/or campaign management tools will be advantageous.
Minimum 3 years’ applicable work experience in SQL, relational databases and data manipulation.
Experience in big data platforms (eg. Hadoop) or processing frameworks (eg. MapReduce/Spark) and querying tools (eg. Pig, Hive and Impala) will be highly beneficial.

Preferred Skills

Organizational skills
Experience in Attentional to detail.
Accountability is critical for this role.
Ability to work under pressure and meet deadlines.
Solid understanding of database design principles.
Should you not receive a response in 2 weeks please consider your application unsuccessful",-1,Rubik's Cubed Consulting,Durban,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"This well known company is looking for a Data Engineer. will be based in Rivonia
The ideal candidate will have strong experience in the following:
Data cleaning
SQL Export
Big data Sets

BSc Degree in Maths and Stats will be required
a min of 3 years experience.
Stable track record is required.

Send your Cv to marinda@prrrecruitment.co.za",-1,PRR Recruitment Services,Johannesburg,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Description

Position at Aculocity, LLC

At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes
Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.
Key Responsibilities
Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.
Key Traits
Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern
Position Requirements
2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.
Where will you work? This role will be based out of Durbanville, South Africa.",-1,GVW,Durbanville,-1,Unknown,-1,Unknown,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Information Technology, Gauteng JHB - Northern Suburbs

Market related - Market related Annually

An IT Consultancy Business based in Johannesburg is currently looking for a Business Intelligence Consultant / Data Engineering Consultant.

Requirements:

Extensive experience in data engineering
Experience in Business Intelligence, data and Power BI
Extensive experience in data governance and the Popi act
Ability to assess and make recommendations on data within the Popi act
Good understanding of T-SQL and query optimization, developing ETL strategies.
Good understanding with SQL Server 2008/2012, SSIS, SSRS and SSAS
Use SSIS to create ETL packages to validate, extract, transform, and load data into the data warehouse and data marts.
Deploy and configured the reports in the Report Server (SSRS).
Excellent experience in Tabular Modelling , PowerView, Qlikvie,w, and Power BI
Maintain ETL
Qlikview model
Create Drill-through, Drill-down, and Cross Tab Reports and Sub-Report using Report Definition Language (RDL).
Generate periodic reports based on the statistical analysis of the data using SQL Server Reporting Services (SSRS)
Advise and provide written technical documentation and recommendations

The information displayed above is not limited to advertisements. Please contact Thato for further information.

Please consider your application as unsuccessful if you have not received a response within 14 days of submitting your application. However, please keep a lookout on our website, www.bedifferent.co.za, for available positions that you may be suited for

Ad Visible Until: 29 October 2020
Ref: JHB005346/NL

Vacancy Type: Permanent",2.9,"Be Different Recruitment
2.9",Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Cloud Support Engineer (Big Data),-1,"ABOUT US

Amazon Web Services is the market leader and technology forerunner in the Cloud business. As a member of the AWS Support team you will be at the forefront of this transformational technology, assisting a global list of companies and developers that are taking advantage of a growing set of services and features to run their mission-critical applications. As a Cloud Support Engineer, you will act as the Cloud Ambassador across all the cloud products, arming our customers with required tools & tactics to get the most out of their Product and Support investment.

Would you like to use the latest cloud computing technologies? Do you have an interest in helping customers understand application architectures and integration approaches? Are you familiar with best practices for applications, servers and networks? Do you want to be part of a customer facing technology team helping to ensure the success of Amazon Web Services (AWS) as a leading technology organization?

If you fit the description, you might be the person we are looking for! We are a group of smart people, passionate about cloud computing, and believe that world class support is critical to customer success.

WHAT CAN YOU EXPECT FROM A LIFE AT AWS?

Every day will bring new and exciting challenges on the job while you:

· Learn and use groundbreaking technologies.
· Apply advanced troubleshooting techniques to provide unique solutions to our customers' individual needs.
· Interact with leading engineers around the world.
· Partner with Amazon Web Services teams to help reproduce and resolve customer issues.
· Leverage your extensive customer support experience to provide feedback to internal AWS teams on how to improve our services.
· Drive customer communication during critical events.
· Drive projects that improve support-related processes and our customers technical support experience.
· Write tutorials, how-to videos, and other technical articles for the developer community.
· Work on critical, highly complex customer problems that may span multiple AWS services.

WHY AWS SUPPORT?

· First and foremost this is a customer support role in The Cloud.
· On a typical day, a Support Engineer will be primarily responsible for solving customers cases through a variety of customer contact channels which include telephone, email, and web/live chat. You will apply advanced troubleshooting techniques to provide tailored solutions for our customers and drive customer interactions by thoughtfully working with customers to dive deep into the root cause of an issue.
· Apart from working on a broad spectrum of technical issues, an AWS Support Engineer may also coach/mentor new hires, develop & present training, partner with development teams on complex issues or contact deflection initiatives, participate in new hiring, write tools/script to help the team, or work with leadership on process improvement and strategic initiatives.
· Career development: We promote advancement opportunities across the organization to help you meet your career goals.
· Training: We have training programs to help you develop the skills required to be successful in your role.
· We hire smart people who are keen to build a career with AWS, so we are more interested in the areas that you do know instead of those you havent been exposed to yet.
· Support engineers interested in travel have presented training or participated in focused summits across our sites or at specific AWS events.
· As we operate on a follow-the-sun model, with Premium Support sites located globally, there is no after hours on-call or mandated overtime in this role.
· https://www.youtube.com/watch?v=GC3bWcFFZTo&t=24s



Basic Qualifications

The Big Data role supports our services that leverage data and produce business insights, which may include using Machine Learning/Artificial Intelligence (ML/AI). Helping our customers use and integrate Big Data services in what is arguably our industrys most exciting space. The portfolio of services covers EMR (Hadoop), DynamoDB (NoSQL), MangoDB, and Apache Cassandra.

· Advanced experience in Apache Hadoop, Apache Spark, Apache Hive, and Presto
· Advanced experience in DynamoDB or NoSQL technologies like MongoDB or Cassandra
· Advanced experience with System Administration with Linux (RHEL/CentOS) including Microsoft Active Directory, and LDAP integration.
· Experience with troubleshooting Kerberos Authentication problems.
· Experience with Network troubleshooting.
· Basic understanding of Machine Learning and statistics
· Experience with Java and Python and shell scripting
· Bachelors degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position



Preferred Qualifications

· Expert experience in the Hadoop Ecosystem including Apache Spark and Presto
· Expert experience in NoSQL
· Expert experience with blockchain technologies like Etherium Expert experience in data Data Lake architecture and administration
· Experience managing full application stacks from the OS up through custom applications
· Prior work experience with AWS - any or all of EC2, VPC, S3, RDS, EMR, Glue, SageMaker
· Excellent knowledge of Hadoop architecture, administration and support
· Expert understanding of distributed computing principles and their application in the cloud
· Good understanding of distributed computing environments Lead technical discussions on big data systems architecture and design
· Strong analysis and troubleshooting skills and experience
· AWS Certified Solutions Architect
· AWS certified Big Data Specialty
· Masters degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity and Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Response Center Engineer,-1,"Job Title
Response Center Engineer
Job Description


Philips is a world leading health technology company with a vision to make life better for people worldwide through meaningful innovation. Making good on this promise depends on our passionate, inspirational, collaborative and diverse team. We have over 80,000+ brilliant people around the world but are always looking for more. Like-minded, motivated, focused minds to join us in creating a healthier, more connected society while transforming themselves personally and professionally.

As a CCC Coordinator - Response Center Engineer you will have the opportunity to process customer calls and be responsible for screening and diagnosing professionally Healthcare equipment to support customers and colleagues remotely with solving technical issues and ensuring maximum customer satisfaction

You are responsible for:
Diagnose healthcare equipment to the quality standards set by Philips Healthcare (PH) remotely by interviewing customers or colleagues by telephone or by remotely logging in to the system
Advise Customer Care Center Coordinators and District Operations Managers and / or Team Leads about the best follow-up w.r.t. technical state of the diagnosed healthcare equipment
Advise the Customer Care Center Coordinators or Field Services Engineers about required spare parts and resources
Responsible for planning engineers related to Modality responsibility.
Responsible for coordination between CCC, CUSTOMER, Spare parts AND Engineer.
Responsible to drive Remote and FTR KPI’s to targets respectively 40% and 85%.
Will require minimal field work to keep abreast of technical capabilities.
Take calls from customers and make sure they are processed in the CCC ERP on timely manner including all relevant data
Support Field Services Engineers in the field with technical knowledge
Escalate technical issues to the Technical Support Specialist
Escalate technical issues to Business Unit support after consultation of the Technical Support Specialist
Monitor critical functions of the equipment’s in the IB and environmental conditions including RSN and True reachability.
Lead the planning and implementation of FSN’s and FCO’s accelerating remote implementation where applicable.
Submit timely and accurate service data, job sheets, reports, expense claims, radiation film badges, field problem reports and other paperwork as assigned
Keep abreast of new technologies likely to affect PH range of products
Use company property with care to ensure optimal results with minimal operational costs
Be a professional representative for PH with respect to customer problems, ensuring personal acceptability by the customer in behavior in accordance with PH policy and targets
Conform to PH safety standards including health and safety regulations and in the event of hazards or accidents to take immediate control of the situation and involve the Operations Manager and / or the responsible person to handle properly confidential issues according Philips standards and to act according General Business Principals
Follow all quality standards within the frame of valid PH business policies
Follow the company quality regulations (ISO 9001; PQA; TQM) and internal directives and procedures
You are a part of the dynamic South Africa Customer Care Centre Team .You will be reporting to the Customer Care Center Manager.

Requires a pleasant, assertive individual you can work very well in a team setting, a dynamic environment that requires flexibility and creativeness to achieve goals.

To succeed in this role, you should have the following skills and experience:
Degree level education or equivalent
Experience in maintenance and troubleshooting of technical complex systems
Fluent in English, verbal and written in addition to local language
In return, we offer you the unique combination of a critical and challenging role and a creative and empowering office environment. You will be actively encouraged to make improvements, establish best in class service and have a direct impact on the success of Philips on a daily basis.

Employment Equity

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply. Only apply for this role if you are a South African Citizen by birth or Naturalization prior to the 27 April 1994.

Why should you join Philips?

Working at Philips is more than a job. It’s a calling to create a healthier society through meaningful work, focused on improving 3 billion lives a year by delivering innovative solutions across the health continuum. Our people experience a variety of unexpected moments when their lives and careers come together in meaningful ways. Learn more by watching this video.

To find out more about what it’s like working for Philips at a personal level, visit the Working at Philips page on our career website, where you can read stories from our employee blog. Once there, you can also learn about our recruitment process, or find answers to some of the frequently asked questions.

Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.9,"Philips
3.9",Johannesburg,-1,10000+ Employees,1891,Company - Public,Health Care Services & Hospitals,Health Care,$10 to $25 million (USD),-1
Software Development Engineer - EC2 Placement,-1,"Build the systems that optimize how EC2 matches requests for Instances with the underlying compute capacity. EC2 Placement is seeking talented engineers to build the online and offline optimization systems for compute workload scheduling, and the customer capabilities to better manage those workloads. Amazon EC2 provides on-demand scalable compute capacity, and powers some of the largest services in the world. You will collaborate with a top-tier community of engineers to build systems to improve how customers are able to access EC2 compute resources.

The successful candidate will have strong software engineering experience, with a passion for thinking about, building and testing distributed systems. You have an interest in how Machine Learning and other optimization techniques can be applied to large-scale problems. You have demonstrated experience working with a team to design, build and operate large-scale systems. With strong engineering fundamentals, an analytical and data-driven approach to your work, and strong communication skills, you have the ability to collaborate well to deliver results. We move fast and work together on small teams to solve big problems.

If this opportunity sounds interesting, we would love to talk to you more about our work and the vibrant culture at AWS in Cape Town.

Basic Qualifications

· Degree in Computer Science or related field, or equivalent working experience
· 3+ years of industry experience in a software development environment
· Strong Computer Science fundamentals, including data structures, object-oriented design, algorithm design, problem solving, and complexity analysis.
· Proficiency in at least one modern programming language, such as Java, C#, Python, Scala, Kotlin

Preferred Qualifications

One or more of the following help you stand out:
· Demonstrated results designing, building and operating high-performance distributed systems in large-scale Linux environments
· Role model in writing high-quality, maintainable and secure code, mentoring others, and helping teams sharpen their development processes
· Ability to work effectively across teams to deliver results, with strong verbal and written communication skills
· Experience working with machine learning systems

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer - PBB IT,-1,"Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose


This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes
Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems
Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions
Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.

Research and best practices
Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development
Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.
Preferred Qualification and Experience
Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Aws Data Platform Engineer,-1,"Aws Data Platform Engineer

Posting Country:

South Africa

Date Posted:

15-Oct-2020

Full Time / Part Time:

Full Time

Contract Type:

Permanent

Joining Vodacom is more than a job, what we do matters. We don’t just carry minutes, texts and data – we carry people’s lives. And that’s a huge responsibility. If you think for a minute about the people you rely on…the likelihood is they rely on us.

Customers are at the heart of everything we do and we want to make a difference to the lives of our customers, and the communities in which we live and work. We support our people to give something back to the causes that mean the most to them through helping them give time and money to the charities they love.

And what’s it like to work here? We have created an environment where you can look forward to coming to work and are empowered to be at your best. We offer flexibility in how you work that helps you do your job in a way that suits you, opportunities to help you grow and progress throughout your career and a choice of benefits to suit your lifestyle.

Role Purpose
The H Band AWS Data Platform Engineer position is based within the Technology Business Unit.

The AWS Data Platform Engineer will be responsible for all Database services such as RDS, DynamoDB, etc. Should be able to migrate any databases from anywhere to AWS using any third-party tools or AWS database migration tool. Should also have understanding or expertise in creating data warehouses and data lake solutions on AWS.
Your responsibilities will include:
Apply practical knowledge of relational database design and usage with customers
Perform workload analysis and undertake performance tuning, as well as performance benchmarking in customer environments.
To develop state of the art solutions which are technically sound.
To provide a high-quality service to the Enterprise Cloud Services clients i.t.o. consultancy, solutions and delivery.
Commitment to team success and positive team dynamics including mentoring of other team members.
Passion for growing and applying technical skills in service to customers.
Be a trusted infrastructure advisor by providing objective, practical and relevant ideas, insights and advice.
Work collaboratively with consulting partners and technology teams to ensure high quality of solution delivery.
Encourage best practice and knowledge sharing with partners and cross-functional groups
Manage the overall database design and delivery of solutions.
Ability to make recommendations as they pertain to improvements in support/development initiatives and facilitate implementation with partners and cross-functional groups within the Business.
Participate in high level database solution definition and design during the implementation phase with the goal of providing reliable, stable and operationally sound applications that meet the Business requirements.
Ability to understand and translate business requirements into technical specifications
The ideal candidate will have:
A minimum of 3 years of industry related experience of which 1 year must be within a complex hosting environment.
Certifications in Database design, system architecture or cloud technologies.
Demonstrate knowledge of database systems internals including storage layouts and distributed databases/MPP architectures
Advanced SQL coding, tuning and query optimization.
Experience designing and leading database performance benchmarks.
Good knowledge of the different AWS services
Knowledge of cloud networking architecture, cloud operations, security, automation and orchestration.
Knowledge of database internals as it relates to query and system performance and tuning.
Understanding of overall system architecture, scalability, reliability, and performance in a database environment.
Excellent teamwork, time-management and organizational skills.
Perform other duties as deemed necessary and assigned by the customer and management
Strong interpersonal skills and problem-solving abilities.
Excellent documentation, communication and interpersonal skills.
Excellent analytical and problem-solving abilities.
Closing date for applications: Monday, 13 April 2020

The base location for this role is Vodacom World, Midrand

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply.
Vodacom is committed to an organisational culture that recognises, appreciates and values diversity & inclusion.

Commitment from Vodacom

Vodacom is committed to attracting, developing and retaining the very best people by offering a flexible, motivating and inclusive workplace in which talent is truly recognized, developed and rewarded. We believe that diversity plays an important role in the success of our business and we are committed to creating an inclusive work environment which respects, values, celebrates and makes the most of people’s individual differences - we are not only multinational but multicultural too. At Vodacom you will have access to our excellent flexible benefits programme that you would expect from any global company.",3.9,"Vodafone
3.9",Midrand,-1,10000+ Employees,1982,Company - Public,"Cable, Internet & Telephone Providers",Telecommunications,$10+ billion (USD),-1
Data Engineer Azure Data Factory,-1,"Enthuzex is looking for a motivated Lead Data Engineer to contribute towards the success of our Data and Analytics Technology initiatives. This is a hands-on technical role and this person will be responsible for the development and build of scalable solutions as it relates to the architecture strategies, data standards, digital data management, data integration, tools, and technology. The right candidate will play a deep dive hands-on critical development role in the digital transformation and in shaping how we acquire, ingest, transform and deliver data through the digital consumer channels.

Responsibilities:

Architect, design, develop and engineering end-to-end data pipelines across multiple data sources and systems of record.
Ensure data quality, integrity, security and completeness throughout the data lifecycle
Develop, design data models, data structures and ETL jobs for data acquisition and manipulation purposes
Develop deep understanding of the data sources, implement data standards, maintain data quality and master data management
Developing data services and API
Work closely with the cloud service providers to ensure completeness and alignment with the service offerings
Manage and maintain cloud based data and analytics platform
Deep understanding of the cloud offerings and engage in quick proof of concepts and proof of value in prototyping data and analytics solutions and derive viability
Ability to interact with the business stakeholders to understand requirements and translating into technology solutions

Expirience:

Experience in Cloud platform AWS or Azure eco-system. (Azure preferred)
Data Engineering/Development experience with SQL (Oracle, SQL Server, MySQL)
Strong development background creating pipelines and complex data transformations and manipulations using one of the languages Python, Java, R, or Scala with Databricks/Spark
Experience in NoSQL Databases and Big data technologies including Hadoop
Experience with API / RESTful data services
Worked on real-time data capture, processing and storing using technologies like Azure Event Hubs and Analytics
Experience working with different data storage options including AWS S3, Azure BLOB storage etc.
Understanding of different data formats including Parquet, Avro, CSV, ORC etc.
Prior experience with MPP databases and maintain large amount of data processing
Experience with Azure Data Factory and Azure Data Catalog is a big plus and mandatory
Experience with Microsoft/Azure ETL solutions and business Intelligence technologies is a big and mandatory
Past working experience on a fast paced and agile environment
Perform ongoing monitoring, automation and refinement of data engineering solutions
Experience in leading high visibility transformation projects that interacts with multiple business lines
Build and meet project timelines and manage delivery commitments with proper communication to management

Qualifications

Bachelor’s degree with 4+ years of relevant experience
Willingness to learn new technologies and thrive in an extremely fast paced environment
Team player and easy to work with.

Applicants must demonstrate their ability to master new enterprise level technologies. Successful applicants will exemplify Enthuzex ethical principles of uncompromising integrity, respect for others, and accountability for decisions

send cv's info@enthuzex.co.za",-1,Enthuzex,Leslie,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Scientist,-1,"The world is changing.

We all want something different.

At Luno, we see you as an individual.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the world, and to do so, we need the best team on board for our mission.

A bit about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 3 million customers across 40 countries.
We are Series B funded, backed by Balderton Capital and the Naspers Group.
Our platform has processed over 8 billion dollars since we've launched
We're proud to be one of the world's most international cryptocurrency teams from 26 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
The role in a nutshell:

Identifying opportunities in the business that could benefit most from cognitive applications, as well as building and enhancing organisational capabilities for deriving value from multiple data sources using data science.

What we'd like you to have:
Bachelor's degree or higher in the natural sciences or technical fields such as Mathematics, Statistics, Computer Science, Engineering or Economics
Enthusiasm to work in the cryptocurrencies space
Advanced SQL skills
Solid understanding of exploratory data analysis, predictive analytics, and optimisation using Python, R, Matlab, RapidMiner, KNIME or other data science-oriented platforms
Proficiency in the use of data science and machine learning domain-specific languages such as ""Caret"" and the ""Tidyverse"" suite of tools in R, or ""Pandas"" in Python
Strong interpersonal and communication skills
Communicating data insights using storytelling narratives
Ability to work independently, as well as within and across teams
Ability to successfully complete projects with large and/or incomplete data sets
More about what you'll be doing:
Optimising product performance by tracking and analysing customer behaviour on web and app, in collaboration with software engineers and product designers
Providing the business with reports and dashboards, on key performance metrics
Developing metrics to accurately assess the health of our Exchange platform
Comparative data-driven analysis of our Exchange against alternative platforms
Formulating business requirements into analytical objectives
Designing and running experiments to test hypotheses
Hacking through complex business problems using advanced data analysis to provide insights and recommendations
Building, maintaining, and optimising decisioning systems using advanced statistical and predictive modelling techniques
What will set you apart:
An advanced degree in Mathematics, Statistics, Computer Science or related field
At least 3 years' experience working in a similar role
A basic understanding of trading in financial markets
Experience working with a data analytics and visualisation platform such as Tableau, Cognos, QlikView, or Looker
Familiarity with using Google Analytics to understand customer behaviour
Solid knowledge of statistical and machine learning techniques
Familiarity with modern distributed data storage and processing systems such as Amazon Redshift, Big Query, Snowflake, Databricks and Apache Spark
You can gather and synthesise facts, theories, trends, patterns, inferences, and key issues in complex and variable situations
Ability to diagnose problems using formal problem-solving tools and techniques from multiple angles to generate multiple possible solutions
A sense of anticipating long-term problem areas and associated risk levels with objective rationale
Remote Life at Luno

If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
You'll be able to continuously upskill yourself with access to free online learning via MyAcademy, an international teaching marketplace with over 100000 courses from Harvard and other leading providers + share knowledge with your peers.
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity and paternity leave, and you can even take paw-ternity leave for your furry friend.
Annual Inspiration Day! Make time for that pottery course or spa day you've always wanted to do.
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"EY is a global leader in
assurance, tax, transaction and advisory services. Technology is at the heart
of what we do and deliver at EY. Technology solutions are integrated in the
client services we deliver and are key to our innovation as an organization.

Fueled by
strategic investment in technology and innovation, Client Technology seeks to
drive growth opportunities and solve complex business problems for our clients
through building a robust platform for business and powerful product engine
that are vital to innovation at scale. As part of Client Technology, you’ll
work with technologists and business experts, blending EY’s deep industry
knowledge and innovative ideas with our platforms, capabilities, and technical
expertise. As a catalyst for change and growth, you’ll be at the forefront of
integrating emerging technologies from AI to Data Analytics into every corner
of what we do at EY. That means more growth for you, exciting learning
opportunities, career choices, and the chance to make a real impact.

The selected
candidate
Develops
large and complex data architecture, composed of models, policies, rules or
standards that govern which data is collected and how it is stored, arranged,
integrated and put to use in data systems, including the design, build and
management of data infrastructure to address business requirements
Creates
sound use case driven roadmaps, depicting data architecture as-is and to-be
capabilities with the business by engaging with multidisciplinary teams, and by
identifying, managing and mitigating risk
Develops
relationships across the business to understand data requirements, applies deep
technical knowledge of data management to solve business problems in areas
where solutions may not currently exist, necessitating new solutions/ways of
working/technologies and proactively articulating these to the business
Review,
identify the latest emerging technologies, augmenting by services from the
leading cloud providers to solution and recommend the best next generation data
platform value driven approach for our clients
Your Key Responsibilities Include
Create
and maintain conceptual, logical and physical database models
Document
functional requirements and system specifications into the data architecture
and detailed design specifications for current and proposed designs
Document
and adhere to development standards and best practices in database designs
Maintain
highly effective and consistent communication within the team, peers, and the
leadership team
Reverse
engineer SQL code and modify it to solve problems/issues
Contribute
to the definition and implementation of data governance practices
Design
both data structures and data integration practices
Work
closely with the infrastructure teams to create a physical environment to
support data services
Evaluate
new and existing (internal and external) technologies and services in support
of data services and data analytics objectives
Skills And Attributes For Success
Understanding
of business process reengineering and business modeling concepts, business
systems development and analysis
Hands-on
experience in designing and implementing hybrid cloud and on-prem solutions
Experience
working with the latest versions of SQL Server
Experience
applying SAFe/Scrum/Kanban methodologies
Ability
to exercise judgment in solving technical, operational, and organizational
challenges
Expert
programming, performance tuning and troubleshooting skills, using the latest
popular programming languages for example python
Demonstrate
proactive approach to identifying issues and presenting solutions and options,
and where appropriate, leading to resolution
Minimum Qualifications
5+ years
demonstratable work experience as a Data Architect using data modeling tools
2-3 years
SQL coding experience on large projects
Must
possess expert SQL programming, performance tuning and troubleshooting skills
Create
database objects and SQL scripts
Understand
and developed data pipelines
Know how
to deformalize data for data science models
Experience
in python, spark and notebooks
Experience
designing data warehousing solutions
Experience
designing next generation data platforms utilising cloud services
In-depth
understanding of database structure principles
Seamlessly
able to translate business requirements to technology requirements
What We Look For
Strong
analytical skills and problem-solving ability
A
self-starter, independent-thinker, curious and creative person with ambition
and passion
Excellent
inter-personal, communication, collaboration, and presentation skills
Customer
focused
Excellent
time management skills
Positive
and constructive minded
Takes
responsibility for continuous self-learning
Takes the
lead and makes decisions in critical times and tough circumstances
Attention
to detail
High
levels of integrity and honesty
Curious
about new emerging technology
About EY
As a global leader in assurance, tax, transaction and consulting
services, we’re using the finance products, expertise and systems we’ve
developed to build a better working world. That starts with a culture that
believes in giving you the training, opportunities and creative freedom to make
things better. Whenever you join, however long you stay, the exceptional EY
experience lasts a lifetime.",3.8,"EY
3.8",Johannesburg,-1,10000+ Employees,1989,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Architect - Principal,-1,"We are looking for Principle Data Architect to join our Engineering team in Cape Town.

The world is changing.
We all want something different.
At Luno, we see you as individuals.

Together, we are upgrading the world of work to unleash the potential within and empower you to become the best possible version of yourself.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the financial landscape, and to do so, well we need the best team on board for our mission. In short, to achieve our goals, we need rockstars. As simple as that.

A little about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 5 million customers across 40 countries.
We're part of the Digital Currency Group, a group of companies driving progress in the cryptocurrency and blockchain space that includes Grayscale, Genesis, Coindesk and Foundry Services
Our platform has processed over $8 billion to date
We're proud to be one of the world's most international cryptocurrency teams from 43 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
How we work


Our engineering team (currently ~100 engineers) is split into organisations which we call Fleets. Each Fleet focuses on a core customer journey (onboarding, security, payments, support, new business, growth and marketing etc.). Each of these fleets contains multiple smaller teams called Pods, each of which focuses on a specific aspect of the product.

Pods will include a product owner, product designer, back-end engineers, Android, iOS and Web developers, who each bring a unique perspective to the problem you are all contributing towards.

We're agile, use scrum, continuous integration and continuous delivery, deploying to production every single day.

We're building teams to help us succeed in our mission to upgrade the world to a better financial system. You'll be joining a group of highly motivated software engineers who you'll work collaboratively with across our pods.

As a fast-growing company with offices around the world, you'll immediately see how your contributions directly impact both our internal users and client experience. Many of the problems we are solving result in trail blazing solutions which can't be found on Stack Overflow; so we're looking for engineers who flourish working in a complex domain.

In your first six months, you will:


...start at Luno by learning our processes, meeting the wider team and starting our engineering on-boarding program. After getting comfortable with the basics, you'll start learning our idiomatic patterns in a safe, easy-to-follow way - by building your own toy micro services. You'll get to practice how we do design docs, code reviews, deployments, events, logging and monitoring.

You'll meet the Pod(s) you'll be working with and quickly align on the teams' current OKRs and product roadmap. We succeed as a team, so we will provide you with regular feedback from your manager and peers and will encourage you to do the same.

What you'll do:
Work closely with our data science and platform teams on projects introducing new streams of data into our data lake
You will get to bring new ideas on how to further develop and innovate our data solutions and how to expose that data to the business
Accountable and Responsible for the design and architecture of Data systems that are robust and scalable.
Work in an Agile/Scrum framework or Agile mindset
Data backup/recovery and storage
Pick-up and learn new concepts, in both engineering and product, and be able to apply that knowledge quickly.
The ideal candidate for this role will have:
7+ years' experience in maintaining scalable data solutions and/or you are passionate about it
Ability to understand, communicate and advocate between build vs buy
Proven track record of setting up, restructuring and maintenance of databases
You know your way around ETL and you have experience with SQL
Experience in the AWS Data stack (RedShift,DynamoDB, Amazon RDS)
Familiarity with integrating data stores with BI platforms such as Looker, Tableau, or Power BI
You have experience with the concepts of CI/CD
Coding skills in e.g. Go, Python
Bachelor's degree in a related field preferred
AWS Certified DataOps Administrator
Be friendly, transparent, articulate and driven to succeed
Basic knowledge of and passion for digital currencies like Bitcoin
A work permit for South Africa if you are not a South African citizen
Don't be put off if you don't tick all of the boxes – they're a guide based on what we'd love to see but we appreciate that excellent software engineers have diverse backgrounds.

Remote Life at Luno


If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity / paternity and even (yes, you are reading it correctly) paw-ternity for your furry friend..
Annual Inspiration Day.. like that pottery course you've always been meaning to do!
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. You'll need to hold the legal right to work in South Africa already as we cannot provide visa sponsorship.

Be part of the change!",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer - EC2 Capacity Data Analytics,-1,"EC2 Capacity Data Analytics (CDA) team is looking for a Data Engineer to join our team.

Our team is part of the EC2 Capacity Engineering organization, which is responsible for providing the elasticity EC2 customers need to scale up/down compute resources in a cost-efficient manner. We predict customer usage across thousands of configuration combinations to deliver exactly what our customers require in just the right amount of time with just the right amount of capacity.

As a Data Engineer, you will build the ETL and analytics solutions for our internal customers to answer questions with data and drive critical improvements for the business. You will use best practices in software engineering, data management, data storage, data compute, and distributed systems. On any given day, we use Python, Scala, Java, SQL, Lambda, CloudFormation, Redshift and Glue as well as other public AWS services and a host of Amazon internal tools. We dont expect you to be an expert in, or necessarily even be familiar with all of the technologies listed above, but we do expect you to be excited to learn about them.

This position involves on-call responsibilities, typically for one week every two months. Our team is dedicated to supporting new team members. We care about your career growth, we try to assign projects and tasks based on what will help each team member develop into a more well-rounded engineer and enable them to take on more complex tasks in the future.

Our team values work-life balance and we are flexible when people occasionally need to work from home.

Job Duties
Develop and maintain automated ETL pipelines for big data using languages such as Scala, Spark, SQL and AWS services such as S3, Glue, Lambda, SNS, SQS, KMS. Example: ETL jobs that process a continuous flow of JSON source files and output the data in a business-friendly Parquet format that can be efficiently queried via Redshift Spectrum using SQL to answer business question.

Develop and maintain automated ETL monitoring and alarming solutions using Java/Python/Scala, Spark, SQL, and AWS services such as CloudWatch and Lambda.

Implement and support reporting and analytics infrastructure for internal business customers using AWS, services such Athena, Redshift, Spectrum, EMR, and QuickSight.

Develop and maintain data security and permissions solutions for enterprise scale data warehouse and data lake implementations including data encryption and database user access controls and logging.

Develop and maintain data warehouse and data lake metadata, data catalog, and user documentation for internal business customers.

Develop, test, and deploy code using internal software development toolsets. This includes the code for deploying infrastructure and solutions for secure data storage, ETL pipelines, data catalog, and data query.


Basic Qualifications

· Bachelors degree in Computer Science or related technical field, or equivalent work experience.
· 4+ years of overall work experience including Software Engineering, Data Engineering, Database Engineering, Business Intelligence.
· Experience with AWS technologies stack including Lambda, Glue, Redshift, RDS, S3, EMR or similar big data solutions stack

Preferred Qualifications

· Demonstrate efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data.
· Demonstrable proficiency in distributed systems and data architecture; design and implementation of batch and stream data processing pipelines; knows how to optimize the distribution, partitioning, and MPP of high-level data structures.

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer,-1,"Our client based in Johannesburg is urgently looking for a Data Engineer to be on a 3 months contract
Build data pipelines, experience in new tech like nifi, kafka, python

Joburg based, open to EE, 3 month contract with the option to extend, must be available at short notice",-1,EQplus,Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Overview
Job ID: 51456
Job Sector: Information Technology and Services
Country: South Africa
Region/State/Province/District: Gauteng
Location: Johannesburg

Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose

This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes

Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems

Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions

Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.
Research and best practices

Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development

Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.

Preferred Qualification and Experience

Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry

Knowledge/Technical Skills/Expertise

Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision

PLEASE NOTE: All our recruitment and selection processes comply with applicable local laws and regulations. We will never ask for money or any form of payment as part of our recruitment process. If you experience this, please contact our Fraudline on +27 800222050 or forward to TransactionFraudOpsSA@standardbank.co.za",4.1,"Standard Bank
4.1",Johannesburg,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"About us

At PBT Group we pride ourselves on being a Data Specialist organisation. With 20 years of experience in 27 countries over 3 continents, our team of 550 consultants have implemented more than 700 projects.",4.3,"PBT Group
4.3",Johannesburg,-1,Unknown,-1,Company - Private,Accounting,Accounting & Legal,Less than $1 million (USD),-1
Data Engineer,-1,"Kick-start your career in the online gaming world and experience the very latest in technology and innovation.

The Department:

Our mission is to provide our customers with the best online betting experience and share the thrill of gaming with them. Data is at the very heart of our business and is vital in everything we do.

Our cross-functional Data team has a big and exciting challenge ahead. We are in the process of re-platforming our traditional, on-premises RDBMS environment to a new microservice architecture in the cloud. We’re making use of the diverse set of data technologies in Microsoft Azure to offer new services, reporting structures and real-time data pipeline while serving the day-to-day requirements of a rapidly growing, data-hungry organisation.

Purpose of the Role:

This is an excellent opportunity for an individual who is looking to gain new skills. We are committed to creating a culture of learning and regularly run proof of concepts, provide internal demos, manage workshops and attend external conferences. Our data team has a wide range of skills including development for highly transactional RDBMS systems, data warehousing, data science and cloud technologies and we are always working to raise everyone’s game.

Duties include, but not limited to:

Work as part of an agile Data Engineering Team
Development of greenfield projects in Azure
Develop and maintain on-premises RDBMS/DW systems
Create robust ETL services and real-time data pipelines
Build and maintain Continuous Integration and DevOps pipelines
Test-driven development and pair programming with colleagues

Essential Criteria:

C#, .Net, Visual Studio
Git, Azure DevOps
NoSQL development (CosmosDB)
Demonstrable understanding of MS SQL Server in a highly transactional environment
Demonstrable understanding of development in Microsoft Azure
Able to understand query plans and identify performance bottlenecks
Test/Business-Driven Development
Building Continuous Integration/Deployment pipelines
Communicate effectively with both technical and non-technical stakeholders

Desirable Criteria:

Implementing Data Storage and Processing solutions in Azure (ARM Templates, Storage Accounts, Data Lake Storage, SQL DB, Cosmos DB, EventHubs, Function Apps, Log Analytics, Data Factory, Databricks, Polybase)
Implementing Security, Disaster Recovery, High Availability, Auditing, Monitoring and Alerting solutions in Azure
Automating tasks in Azure using Powershell / CLI
Predicting costs and optimizing spending in Azure
Message Queues (RabbitMQ, Kafka)
Python

Person Specifications:

Resilience
Teamwork
Technical Knowledge
Communication skills
Stress Tolerance
Please note we will apply relevance to our Talent Management and Talent Development Programme as part of our recruitment process.
Shortlisted candidates may need to complete an assessment.
This position requires trust and honesty it has access to customers financial details - therefore a credit and criminal record check will be conducted. The qualifications identified herein are an inherent job requirement; therefore, a qualification verification check will be done. By applying for this role, and supplying the necessary details, you hereby grant us permission to apply for these checks. This will be done in a confidential manner, and solely for the purposes of verification.

To view all current vacancies, please visit our website, www.digioutsource.com

Should you not hear from us within 2 weeks, please deem your application as unsuccessful.

The perfect place to work, play and grow!",3.9,"Digital Outsource Services
3.9",Cape Town,-1,1001 to 5000 Employees,1997,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
Data Engineer,-1,"At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes

Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.

Key Responsibilities

Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.

Key Traits

Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern

Position Requirements

2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.

Where will you work? This role will be based out of Durbanville, South Africa.",3.1,"Aculocity, LLC
3.1",Durbanville,-1,1 to 50 Employees,2006,Company - Private,IT Services,Information Technology,$1 to $5 million (USD),-1
Data Engineer,-1,"ENVIRONMENT:

A rapidly growing E-Commerce Platform seeks a highly talented Data Engineer to make an invaluable contribution to data democratisation and literacy vision by making accessible and easy-to-use data products and tools. You will require a Comp-Sci Degree or 3 years’ relevant industry experience, MySQL, PostgreSQL, Java, Python, in-depth understanding of OLAP, Data Marts, Star Scheme, Snowflake, be familiar with Jenkins, Travis, Circle CI, Docker, Kubernetes, experience with Kafka, Pub/Sub, Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks & significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing & Data Lake design and implementation and Lambda/Kappa architectures.

DUTIES:

Design, develop, test and maintain data architecture.

Prepare data for descriptive, predictive and prescriptive modelling.

Automate repetitive tasks and manual processes related with the data usage.

Optimize data delivery.

Design, develop and test large stream data pipelines to ingest, aggregate, clean, and distribute data models ready for analysis.

Ensure the highest standard in data integrity.

Leverage best practices in continuous integration and delivery.

Collaborate with other engineers, ML experts, analysts, and stakeholders to produce the most efficient and valuable solutions.

Implement features, technology, and processes that move us towards industry best practices, improving on scalability, efficiency, reliability, and security.

Operations and ownership of systems in production, responding to incidents.

REQUIREMENTS:

Qualifications –

Comp-Sci Degree or 3 years relevant industry experience.

Experience/Skills –

Open source relational database systems e.g. MySQL, PostgreSQL, etc.

Significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing, and Data Lake design and implementation and Lambda/Kappa architectures.

A thorough understanding of database and data warehousing principles e.g. OLAP, Data Marts, Star Schema, Snowflake, etc.

Java and Python.

Familiar with CI/CD tools such as Jenkins, Travis, Circle CI, etc.

Experience with Kafka, Pub/Sub, or other event-based systems.

Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks, etc.

Working in cloud environments and with containerisation frameworks, tools and platforms e.g. Docker, Kubernetes, GKE, etc.

A deep understanding of data pipelining, streaming, and Big Data technologies, methods, patterns, and techniques.

Troubleshooting complex database operations and performance issues.

Automating tasks using Shell Scripting or writing small applications.

ATTRIBUTES:

Works well with people and is passionate about helping people be their best.

A team player, an active listener, mentor, and able to communicate well.

Shows solid reasoning and decision making, with the ability to work under pressure.

Is passionate about technology, systems and data.

Is curious, always learning, and keeping up to date with the industry.

While we would really like to respond to every application, should you not be contacted for this position within 10 working days please consider your application unsuccessful.

COMMENTS:

When applying for jobs, ensure that you have the minimum job requirements. Only SA Citizens will be considered for this role. If you are not in the mentioned location of any of the jobs, please note your relocation plans in all applications for jobs and correspondence.",-1,Datafin IT Recruitment,Cape Town,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Cartrack is looking for passionate data science and engineering candidates that can join a growing team that is responsible for the intelligence and efficiency solution provision to over a million subscribers, many of whom are large fleets. We are in the midst of creating revolutionary platforms that will change the way that people interact with their vehicles.

You will have the opportunity to work with the very brightest global subject matter experts that are transforming the automotive industry across Fleet Management, Asset Management and Insurance Telematics solutions.

Get to know the role:

The role of a data engineer is a supporting one, but it is also an extremely vital one. As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements. We want to see candidates with mechanical tendencies and a desire to know how things work and to improve them.

The day-to-day activities:

Design, construct, install, test and maintain data management systems.
Build high-performance algorithms, predictive models, and prototypes.
Ensure that all systems meet the business/company requirements as well as industry practices.
Integrate up-and-coming data management and software engineering technologies into existing data structures.
Develop set processes for data mining, data modeling, and data production.
Create custom software components and analytics applications.
Research new uses for existing data.
Employ an array of technological languages and tools to connect systems together.
Install/update disaster recovery procedures.
Recommend different ways to constantly improve data reliability and quality.
Work on and maintain Data pipelines.

Requirements Essential:

At least 5 years’ proven experience as a Data Engineer, DevOps Engineer, Software Developer, or similar.
Proficient in Linux/Unix and shell scripting as well as in functional programming languages.
Expertise in setting up and explored with technologies such as Hadoop and Spark.
Bachelor’s degree in computer science, software/computer engineering, applied mathematics, or physics.",3.3,"Cartrack
3.3",Johannesburg,-1,501 to 1000 Employees,2004,Company - Private,Security Services,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Data Engineer,-1,"Data Engineers build and support data pipelines and datamarts built off those pipelines. Both must be scalable, repeatable and secure. The Data Engineer helps to facilitate gathering data from a variety of different sources, in the correct format, assuring that it conforms to data quality standards and assuring that downstream users can get to that data timeously. This role functions as a core member of an agile team. These professionals are responsible for the infrastructure that provides insights from raw data, handling and integrating diverse sources of data seamlessly. They enable solutions, by handling large volumes of data in batch and real-time by leveraging emerging technologies from both the big data and cloud spaces. Additional responsibilities include developing proof of concepts and implements complex big data solutions with a focus on collecting, parsing, managing, analysing and visualising large datasets. They know how to apply technologies to solve the problems of working with large volumes of data in diverse formats to deliver innovative solutions. Data Engineering is a technical job that requires substantial expertise in a broad range of software development and programming fields. These professionals have a knowledge of data analysis, end user requirements and business requirements analysis to develop a clear understanding of the business need and to incorporate these needs into a technical solution. They have a solid understanding of physical database design and the systems development lifecycle. This role must work well in a team environment.

Job Objectives

Work Complexity: * Architects Data analytics framework. * Translates complex functional and technical requirements into detailed architecture, design, and high performing software. * Leads Data and batch/real-time analytical solutions leveraging transformational technologies. * Works on multiple projects as a technical lead driving user story analysis and elaboration, design and development of software applications, testing, and builds automation tools.

Main Job Objectives: 1. Development and Operations 2. Database Development and Operations 3. Policies, Standards and Procedures 4. Communications 5. Business Continuity & Disaster Recovery 6. Research and Evaluation 7. Coaching/ Mentoring

Qualifications

Essential: 4 years Bachelors degree in computer science, computer engineering, or equivalent work experience AWS Certification at least to associate level

Experience

Essential:

5+ years Data engineering or software engineering

3-5 years demonstrated experience leading teams of engineers

2+ years Big Data experience

5+ years experience with Extract Transform and Load (ETL) processes

2+ years Could AWS experience

At least 2 years demonstrated experience with agile or other rapid application development methods - Agile exposure, Kanban or Scrum

5 years demonstrated experience with object oriented design, coding and testing patterns as well as experience in engineering (commercial or open source) software platforms and large scale data infrastructures.

Desirable:

5+ years Retail Operations experience

Knowledge and Skills

Essential: *Creating data feeds from on-premise to AWS Cloud (2 years) *Support data feeds in production on break fix basis (2 years) *Creating data marts using Talend or similar ETL development tool (4 years) *Manipulating data using python and pyspark (2 years) *Processing data using the Hadoop paradigm particularly using EMR, AWSs distribution of Hadoop (2 years) *Devop for Big Data and Business Intelligence including automated testing and deployment (2 years) * Extensive knowledge in different programming or scripting languages * Expert knowledge of data modeling and understanding of different data structures and their benefits and limitations under particular use cases.

Further technical skills required: * Capability to architect highly scalable distributed systems, using different open source tools. * Big Data batch and streaming tools * Talend (1 year) * AWS: EMR, EC2, S3 (1 year) * Python (1 year) * PySpark or Spark (1 year) - Desirable * Business Intelligence Data modelling (3 years) * SQL (3 years)",-1,Datonomy Solutions,Brackenfell,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We are assisting one of our clients that is based in Pretoria to fill a role of a Data Engineer

This is a 12 month contract role

Objective of this Scope of Work

The Data Engineer will drive improvement of the data management maturity levels and provide the necessary technical support within the company to support reliable and effective decision-making, appropriate usage and protection thereof.

Scope of Services Definition

The scope will include but will not be limited to:

ï†· To develop, construct, test and maintain architectures.

ï†· To ensure architectures will support the requirements of business.

ï†· To discover opportunities for data acquisition and sharing.

ï†· To develop data set processes for data modelling, mining and production.

ï†· To employ a variety of languages and tools to marry systems together.

ï†· To recommend way to improve data reliability, efficiency and quality.

ï†· To prepare data for use in predictive and prescriptive modelling.

ï†· To conduct research to answer industry and business questions.

ï†· To leverage volumes of data from internal and external to answer business questions.

ï†· To develop and manage stakeholder relations effectively to promote data management across the organisation and support reliable decision making and appropriate data usage.

ï†· To participate and provide technical support in cross organisational activities relating to any of the above mentioned data management activities.

ï†· To provide regular progress reports as per stakeholder requirements and present data management updates in various forums as required.

Minimum qualification Required:

ï†· A minimum of a Bachelors degree in Computer Science or Information Management OR equivalent;

ï†· A minimum of five to eight years experience in a data management environment",-1,HR Genie,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Our client based in the Northern Suburbs, is currently looking for a Data Engineer to join their team.

Responsibilities
Our client is a dynamic IT company that delivers value-driven IT solutions to the group. Our work lives revolve around our DNA. We take pride in our work, treat our colleagues, partners and our country with respect. We exercise collaborative decision-making and believe in having a balance in life. We do this all while having fun and enjoying what we do.

The primary focus of this position is to use technical skills to put software, systems and data together in a way that extracts meaningful insights from raw data. You will need to be helpful and supportive to your team and fellow developers. You join an energetic, focused and dynamic team.

Interact with clients to understand requirements and business problems/needs

Identify, analyse, visualise and understand supporting data to propose solid solutions

Create technical documentation for reference and reporting

Support existing solutions within GCP and Oracle

Doing standby on a rotating basis

Key Competencies and Qualifications

Matric

Tertiary qualification in IT

Preferred cloud experience in AWS/AZURE/GCP

At least 3 years of data warehouse ETL experience

Dimensional Modelling

Data analyses

Experience with data visualization and visualization tool(s)

Knowledge of the retail industry will be beneficial

Understanding and experience with version control SVN/GIT

Preferred – Korn shell scripting, Python/Java, SQL

Google Cloud Platform experience would be looked upon favourably

Having a broad understanding of different SDLC’s

Preferred agile experience

Strengths

The natural tendency to take ownership and responsibility

Strong problem solving, critical thinking, effective planning and organisational skills

Detail-oriented with excellent communication skills

You have a can-do attitude and positive outlook on life

Can cope under pressure

Curious and interested in analysing problems and possible solutions

Strong team player

Self-driven learner, passionate about new technology

Above all, be passionate about what you do

Should you wish to apply for the position, please apply directly via this job board, please ensure that you quote reference number 201620 subject heading or email body.

Please note that due to the high volume of CV's received; only shortlisted applicants will be contacted. Should you not receive communication from our offices within two weeks of submission please note that your application will not be considered for this position.

We will keep your CV on file and re-establish contact with you should opportunities in line with your expertise become available again.

Should you require any additional information give us a call on 021 012 5566.",-1,Surgo HR & Training,Cape Town,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We believe that our employees fuel our organization, essential to enable us to help our customers overcome their business challenges and achieve sustainable growth. As a result, we are committed to growing each individual and providing them with the challenges, feedback and support needed to achieve success in their career

If this sounds appealing, and like us, you get excited about data: its collection, storage, transformation or display, see if you’ve got what it takes to join our sought after DATA team.

Key Responsibilities And/or Outputs

You will represent IQbusiness at our customers, sometimes alone, and sometimes as part of an IQ team.

Providing a superior customer experience by building and maintaining relationships, working at customer offices, keeping data confidential
Design and develop – databases, SQL queries, stored procedures, reports, dashboards or integration solutions
Produce solutions for both real-time and batch environments
Test your work to ensure compliance
Solve problems, and do root cause analysis
Prioritize your workload
Assist in other areas relating to your true data function, such as data modeling, data and business analysts
Interact with a variety of individuals: senior, junior, technical and from business
Provide guidance to fellow colleagues, or even manage a team
Uphold the IQ values, which are to care, learn & share; innovate; deliver as well as to build, enhance and maintain relationships

Education

Matric pass
A tertiary qualification, preferably in an ICT relevant field
Appropriate Microsoft certifications are beneficial but not required

Requirements

3 - 6 years experience in the Data Engineering environments and technologies
Great communication skills
A passion for SQL, databases or reports
Can you write stored procedures, design complex queries and create views and triggers?
Are you able to work out the relationships in a data warehouse or the aggregation of a cube?
Do you extract and display useful information when you see patterns and trends in data?
Strong knowledge of the financial services industry, ideally in a consulting role
The use of data related software: databases, ETL and BI tools; report writing and analytical tools
We use a lot of Microsoft products. You may often be expected to use MS SQL Server, SSIS, SSRS, SSAS and Power BI to develop solutions
What other relevant software have you’ve used?
Ability to work in different project methodologies: Waterfall and/or Agile
Knowledge of full SDLC
Exposure to logical and physical data modeling

Equal Employment Opportunity

IQbusiness is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, citizenship, marital, domestic or civil partnership status, sexual orientation, or gender identity",3.7,"IQbusiness South Africa
3.7",Johannesburg,-1,1 to 50 Employees,-1,Company - Private,Consulting,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"We value a data engineer as someone who works behind the scenes to obtain, process and supply data via various methodologies and technologies, to various consumers, in ways and forms that makes sense and add value. This definition is very broad, as the field of data engineering is just as broad.

You may be the type of data engineer that develops API endpoints for the consumption of data by end users or even another data pipeline, or you may be the type of data engineer that develops highly distributed, high availability data processing pipelines in an effort to satisfy the need of the ever questioning data analysts and/or data scientists.

You have awesome knowledge about the following concepts
Data modelling
Relational data modelling in traditional relational database management systems. (Microsoft SQL Server, MySQL, PostgreSQL, etc)
Coercing unstructured and semi-structured data into a structured form.
Data pipelining knowledge - data extraction and transformation.
Data transformation knowledge for reporting and analytics purposes.
Knowledge of the MapReduce and related data processing paradigms would be a boon.
You have the following technical competencies
Writing SQL queries, that can relate, transform and aggregate data from many differing sources where natural keys may or may not exist.
Experience with writing data pipelines that move and transform data, for various uses.
Working knowledge of a general purpose programming language like Python would be a boost.
Working knowledge of columnar databases such as Google BigQuery, and SAP HANA would be a boost.
Working knowledge of highly distributed technologies such as Apache Hadoop or Apache Spark would be a boost.
Working knowledge of NoSQL technologies, such as Apache Solr would be a boost.
You have the following personal competencies
The ability to solve problems.
The ability to rotate around a problem, to see if solutions can be gained in different ways.
The ability to work in an ever changing, unstructured environment.
The ability to work as part of a team, with vastly differing skill sets and opinions.
The ability to contribute ideas to the quorum.
The ability to mentor and provide guidance for other team members.
A systems approach to thinking, as opposed to a siloed approach. The candidate needs to understand how their work affects the greater system.
The ability to work without supervision, and take accountability for the work they deliver.
The ability to liaise with a client, sifting through the fluff and extracting the actual requirements.
If this is you - apply now and we'll get in touch",-1,DotModus,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Data Engineer

Our client in the contact centre space is currently seeking a DATA ENGINEER that will work on the collecting, storing, processing, and analyzing of large datasets. The primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them. You will also be responsible for integrating them with the architecture used across the company.

Key Performance Areas:

Data reporting.
Implementing ETL processes.
Defining data retention policies.
Management of Customer Lead data.
Provision of data for advanced analytics.
Maintenance of internal client scorecards.
Assist team in resolving data-related support queries.
Optimize existing data processes through automation.
Assist with all data-related reporting and documentation.
Maintenance and optimisation of the Analytics database.
Provide technical support to and supervision of junior data administrators.
Continuous upskilling on new technologies, frameworks and market trends.
Monitoring performance and advising any necessary infrastructure changes.
Identifying, selecting and integrating any Big Data tools and frameworks required to provide real-time analytics.

Educational Requirements

IT related Degree or Diploma is a pre-requisite

Required Skills/Experience

ETL tools: Advanced SSIS
BI/Reporting : Qlikview/Power BI/ SSRS or SSAS
Programming languages: JAVA, C# , Python, SAS or R
Experience with NoSQL databases and/or campaign management tools will be advantageous.
Minimum 3 years’ applicable work experience in SQL, relational databases and data manipulation.
Experience in big data platforms (eg. Hadoop) or processing frameworks (eg. MapReduce/Spark) and querying tools (eg. Pig, Hive and Impala) will be highly beneficial.

Preferred Skills

Organizational skills
Experience in Attentional to detail.
Accountability is critical for this role.
Ability to work under pressure and meet deadlines.
Solid understanding of database design principles.
Should you not receive a response in 2 weeks please consider your application unsuccessful",-1,Rubik's Cubed Consulting,Durban,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"This well known company is looking for a Data Engineer. will be based in Rivonia
The ideal candidate will have strong experience in the following:
Data cleaning
SQL Export
Big data Sets

BSc Degree in Maths and Stats will be required
a min of 3 years experience.
Stable track record is required.

Send your Cv to marinda@prrrecruitment.co.za",-1,PRR Recruitment Services,Johannesburg,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Description

Position at Aculocity, LLC

At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes
Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.
Key Responsibilities
Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.
Key Traits
Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern
Position Requirements
2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.
Where will you work? This role will be based out of Durbanville, South Africa.",-1,GVW,Durbanville,-1,Unknown,-1,Unknown,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Information Technology, Gauteng JHB - Northern Suburbs

Market related - Market related Annually

An IT Consultancy Business based in Johannesburg is currently looking for a Business Intelligence Consultant / Data Engineering Consultant.

Requirements:

Extensive experience in data engineering
Experience in Business Intelligence, data and Power BI
Extensive experience in data governance and the Popi act
Ability to assess and make recommendations on data within the Popi act
Good understanding of T-SQL and query optimization, developing ETL strategies.
Good understanding with SQL Server 2008/2012, SSIS, SSRS and SSAS
Use SSIS to create ETL packages to validate, extract, transform, and load data into the data warehouse and data marts.
Deploy and configured the reports in the Report Server (SSRS).
Excellent experience in Tabular Modelling , PowerView, Qlikvie,w, and Power BI
Maintain ETL
Qlikview model
Create Drill-through, Drill-down, and Cross Tab Reports and Sub-Report using Report Definition Language (RDL).
Generate periodic reports based on the statistical analysis of the data using SQL Server Reporting Services (SSRS)
Advise and provide written technical documentation and recommendations

The information displayed above is not limited to advertisements. Please contact Thato for further information.

Please consider your application as unsuccessful if you have not received a response within 14 days of submitting your application. However, please keep a lookout on our website, www.bedifferent.co.za, for available positions that you may be suited for

Ad Visible Until: 29 October 2020
Ref: JHB005346/NL

Vacancy Type: Permanent",2.9,"Be Different Recruitment
2.9",Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Cloud Support Engineer (Big Data),-1,"ABOUT US

Amazon Web Services is the market leader and technology forerunner in the Cloud business. As a member of the AWS Support team you will be at the forefront of this transformational technology, assisting a global list of companies and developers that are taking advantage of a growing set of services and features to run their mission-critical applications. As a Cloud Support Engineer, you will act as the Cloud Ambassador across all the cloud products, arming our customers with required tools & tactics to get the most out of their Product and Support investment.

Would you like to use the latest cloud computing technologies? Do you have an interest in helping customers understand application architectures and integration approaches? Are you familiar with best practices for applications, servers and networks? Do you want to be part of a customer facing technology team helping to ensure the success of Amazon Web Services (AWS) as a leading technology organization?

If you fit the description, you might be the person we are looking for! We are a group of smart people, passionate about cloud computing, and believe that world class support is critical to customer success.

WHAT CAN YOU EXPECT FROM A LIFE AT AWS?

Every day will bring new and exciting challenges on the job while you:

· Learn and use groundbreaking technologies.
· Apply advanced troubleshooting techniques to provide unique solutions to our customers' individual needs.
· Interact with leading engineers around the world.
· Partner with Amazon Web Services teams to help reproduce and resolve customer issues.
· Leverage your extensive customer support experience to provide feedback to internal AWS teams on how to improve our services.
· Drive customer communication during critical events.
· Drive projects that improve support-related processes and our customers technical support experience.
· Write tutorials, how-to videos, and other technical articles for the developer community.
· Work on critical, highly complex customer problems that may span multiple AWS services.

WHY AWS SUPPORT?

· First and foremost this is a customer support role in The Cloud.
· On a typical day, a Support Engineer will be primarily responsible for solving customers cases through a variety of customer contact channels which include telephone, email, and web/live chat. You will apply advanced troubleshooting techniques to provide tailored solutions for our customers and drive customer interactions by thoughtfully working with customers to dive deep into the root cause of an issue.
· Apart from working on a broad spectrum of technical issues, an AWS Support Engineer may also coach/mentor new hires, develop & present training, partner with development teams on complex issues or contact deflection initiatives, participate in new hiring, write tools/script to help the team, or work with leadership on process improvement and strategic initiatives.
· Career development: We promote advancement opportunities across the organization to help you meet your career goals.
· Training: We have training programs to help you develop the skills required to be successful in your role.
· We hire smart people who are keen to build a career with AWS, so we are more interested in the areas that you do know instead of those you havent been exposed to yet.
· Support engineers interested in travel have presented training or participated in focused summits across our sites or at specific AWS events.
· As we operate on a follow-the-sun model, with Premium Support sites located globally, there is no after hours on-call or mandated overtime in this role.
· https://www.youtube.com/watch?v=GC3bWcFFZTo&t=24s



Basic Qualifications

The Big Data role supports our services that leverage data and produce business insights, which may include using Machine Learning/Artificial Intelligence (ML/AI). Helping our customers use and integrate Big Data services in what is arguably our industrys most exciting space. The portfolio of services covers EMR (Hadoop), DynamoDB (NoSQL), MangoDB, and Apache Cassandra.

· Advanced experience in Apache Hadoop, Apache Spark, Apache Hive, and Presto
· Advanced experience in DynamoDB or NoSQL technologies like MongoDB or Cassandra
· Advanced experience with System Administration with Linux (RHEL/CentOS) including Microsoft Active Directory, and LDAP integration.
· Experience with troubleshooting Kerberos Authentication problems.
· Experience with Network troubleshooting.
· Basic understanding of Machine Learning and statistics
· Experience with Java and Python and shell scripting
· Bachelors degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position



Preferred Qualifications

· Expert experience in the Hadoop Ecosystem including Apache Spark and Presto
· Expert experience in NoSQL
· Expert experience with blockchain technologies like Etherium Expert experience in data Data Lake architecture and administration
· Experience managing full application stacks from the OS up through custom applications
· Prior work experience with AWS - any or all of EC2, VPC, S3, RDS, EMR, Glue, SageMaker
· Excellent knowledge of Hadoop architecture, administration and support
· Expert understanding of distributed computing principles and their application in the cloud
· Good understanding of distributed computing environments Lead technical discussions on big data systems architecture and design
· Strong analysis and troubleshooting skills and experience
· AWS Certified Solutions Architect
· AWS certified Big Data Specialty
· Masters degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity and Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Response Center Engineer,-1,"Job Title
Response Center Engineer
Job Description


Philips is a world leading health technology company with a vision to make life better for people worldwide through meaningful innovation. Making good on this promise depends on our passionate, inspirational, collaborative and diverse team. We have over 80,000+ brilliant people around the world but are always looking for more. Like-minded, motivated, focused minds to join us in creating a healthier, more connected society while transforming themselves personally and professionally.

As a CCC Coordinator - Response Center Engineer you will have the opportunity to process customer calls and be responsible for screening and diagnosing professionally Healthcare equipment to support customers and colleagues remotely with solving technical issues and ensuring maximum customer satisfaction

You are responsible for:
Diagnose healthcare equipment to the quality standards set by Philips Healthcare (PH) remotely by interviewing customers or colleagues by telephone or by remotely logging in to the system
Advise Customer Care Center Coordinators and District Operations Managers and / or Team Leads about the best follow-up w.r.t. technical state of the diagnosed healthcare equipment
Advise the Customer Care Center Coordinators or Field Services Engineers about required spare parts and resources
Responsible for planning engineers related to Modality responsibility.
Responsible for coordination between CCC, CUSTOMER, Spare parts AND Engineer.
Responsible to drive Remote and FTR KPI’s to targets respectively 40% and 85%.
Will require minimal field work to keep abreast of technical capabilities.
Take calls from customers and make sure they are processed in the CCC ERP on timely manner including all relevant data
Support Field Services Engineers in the field with technical knowledge
Escalate technical issues to the Technical Support Specialist
Escalate technical issues to Business Unit support after consultation of the Technical Support Specialist
Monitor critical functions of the equipment’s in the IB and environmental conditions including RSN and True reachability.
Lead the planning and implementation of FSN’s and FCO’s accelerating remote implementation where applicable.
Submit timely and accurate service data, job sheets, reports, expense claims, radiation film badges, field problem reports and other paperwork as assigned
Keep abreast of new technologies likely to affect PH range of products
Use company property with care to ensure optimal results with minimal operational costs
Be a professional representative for PH with respect to customer problems, ensuring personal acceptability by the customer in behavior in accordance with PH policy and targets
Conform to PH safety standards including health and safety regulations and in the event of hazards or accidents to take immediate control of the situation and involve the Operations Manager and / or the responsible person to handle properly confidential issues according Philips standards and to act according General Business Principals
Follow all quality standards within the frame of valid PH business policies
Follow the company quality regulations (ISO 9001; PQA; TQM) and internal directives and procedures
You are a part of the dynamic South Africa Customer Care Centre Team .You will be reporting to the Customer Care Center Manager.

Requires a pleasant, assertive individual you can work very well in a team setting, a dynamic environment that requires flexibility and creativeness to achieve goals.

To succeed in this role, you should have the following skills and experience:
Degree level education or equivalent
Experience in maintenance and troubleshooting of technical complex systems
Fluent in English, verbal and written in addition to local language
In return, we offer you the unique combination of a critical and challenging role and a creative and empowering office environment. You will be actively encouraged to make improvements, establish best in class service and have a direct impact on the success of Philips on a daily basis.

Employment Equity

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply. Only apply for this role if you are a South African Citizen by birth or Naturalization prior to the 27 April 1994.

Why should you join Philips?

Working at Philips is more than a job. It’s a calling to create a healthier society through meaningful work, focused on improving 3 billion lives a year by delivering innovative solutions across the health continuum. Our people experience a variety of unexpected moments when their lives and careers come together in meaningful ways. Learn more by watching this video.

To find out more about what it’s like working for Philips at a personal level, visit the Working at Philips page on our career website, where you can read stories from our employee blog. Once there, you can also learn about our recruitment process, or find answers to some of the frequently asked questions.

Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.9,"Philips
3.9",Johannesburg,-1,10000+ Employees,1891,Company - Public,Health Care Services & Hospitals,Health Care,$10 to $25 million (USD),-1
Software Development Engineer - EC2 Placement,-1,"Build the systems that optimize how EC2 matches requests for Instances with the underlying compute capacity. EC2 Placement is seeking talented engineers to build the online and offline optimization systems for compute workload scheduling, and the customer capabilities to better manage those workloads. Amazon EC2 provides on-demand scalable compute capacity, and powers some of the largest services in the world. You will collaborate with a top-tier community of engineers to build systems to improve how customers are able to access EC2 compute resources.

The successful candidate will have strong software engineering experience, with a passion for thinking about, building and testing distributed systems. You have an interest in how Machine Learning and other optimization techniques can be applied to large-scale problems. You have demonstrated experience working with a team to design, build and operate large-scale systems. With strong engineering fundamentals, an analytical and data-driven approach to your work, and strong communication skills, you have the ability to collaborate well to deliver results. We move fast and work together on small teams to solve big problems.

If this opportunity sounds interesting, we would love to talk to you more about our work and the vibrant culture at AWS in Cape Town.

Basic Qualifications

· Degree in Computer Science or related field, or equivalent working experience
· 3+ years of industry experience in a software development environment
· Strong Computer Science fundamentals, including data structures, object-oriented design, algorithm design, problem solving, and complexity analysis.
· Proficiency in at least one modern programming language, such as Java, C#, Python, Scala, Kotlin

Preferred Qualifications

One or more of the following help you stand out:
· Demonstrated results designing, building and operating high-performance distributed systems in large-scale Linux environments
· Role model in writing high-quality, maintainable and secure code, mentoring others, and helping teams sharpen their development processes
· Ability to work effectively across teams to deliver results, with strong verbal and written communication skills
· Experience working with machine learning systems

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer - PBB IT,-1,"Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose


This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes
Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems
Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions
Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.

Research and best practices
Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development
Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.
Preferred Qualification and Experience
Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Aws Data Platform Engineer,-1,"Aws Data Platform Engineer

Posting Country:

South Africa

Date Posted:

15-Oct-2020

Full Time / Part Time:

Full Time

Contract Type:

Permanent

Joining Vodacom is more than a job, what we do matters. We don’t just carry minutes, texts and data – we carry people’s lives. And that’s a huge responsibility. If you think for a minute about the people you rely on…the likelihood is they rely on us.

Customers are at the heart of everything we do and we want to make a difference to the lives of our customers, and the communities in which we live and work. We support our people to give something back to the causes that mean the most to them through helping them give time and money to the charities they love.

And what’s it like to work here? We have created an environment where you can look forward to coming to work and are empowered to be at your best. We offer flexibility in how you work that helps you do your job in a way that suits you, opportunities to help you grow and progress throughout your career and a choice of benefits to suit your lifestyle.

Role Purpose
The H Band AWS Data Platform Engineer position is based within the Technology Business Unit.

The AWS Data Platform Engineer will be responsible for all Database services such as RDS, DynamoDB, etc. Should be able to migrate any databases from anywhere to AWS using any third-party tools or AWS database migration tool. Should also have understanding or expertise in creating data warehouses and data lake solutions on AWS.
Your responsibilities will include:
Apply practical knowledge of relational database design and usage with customers
Perform workload analysis and undertake performance tuning, as well as performance benchmarking in customer environments.
To develop state of the art solutions which are technically sound.
To provide a high-quality service to the Enterprise Cloud Services clients i.t.o. consultancy, solutions and delivery.
Commitment to team success and positive team dynamics including mentoring of other team members.
Passion for growing and applying technical skills in service to customers.
Be a trusted infrastructure advisor by providing objective, practical and relevant ideas, insights and advice.
Work collaboratively with consulting partners and technology teams to ensure high quality of solution delivery.
Encourage best practice and knowledge sharing with partners and cross-functional groups
Manage the overall database design and delivery of solutions.
Ability to make recommendations as they pertain to improvements in support/development initiatives and facilitate implementation with partners and cross-functional groups within the Business.
Participate in high level database solution definition and design during the implementation phase with the goal of providing reliable, stable and operationally sound applications that meet the Business requirements.
Ability to understand and translate business requirements into technical specifications
The ideal candidate will have:
A minimum of 3 years of industry related experience of which 1 year must be within a complex hosting environment.
Certifications in Database design, system architecture or cloud technologies.
Demonstrate knowledge of database systems internals including storage layouts and distributed databases/MPP architectures
Advanced SQL coding, tuning and query optimization.
Experience designing and leading database performance benchmarks.
Good knowledge of the different AWS services
Knowledge of cloud networking architecture, cloud operations, security, automation and orchestration.
Knowledge of database internals as it relates to query and system performance and tuning.
Understanding of overall system architecture, scalability, reliability, and performance in a database environment.
Excellent teamwork, time-management and organizational skills.
Perform other duties as deemed necessary and assigned by the customer and management
Strong interpersonal skills and problem-solving abilities.
Excellent documentation, communication and interpersonal skills.
Excellent analytical and problem-solving abilities.
Closing date for applications: Monday, 13 April 2020

The base location for this role is Vodacom World, Midrand

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply.
Vodacom is committed to an organisational culture that recognises, appreciates and values diversity & inclusion.

Commitment from Vodacom

Vodacom is committed to attracting, developing and retaining the very best people by offering a flexible, motivating and inclusive workplace in which talent is truly recognized, developed and rewarded. We believe that diversity plays an important role in the success of our business and we are committed to creating an inclusive work environment which respects, values, celebrates and makes the most of people’s individual differences - we are not only multinational but multicultural too. At Vodacom you will have access to our excellent flexible benefits programme that you would expect from any global company.",3.9,"Vodafone
3.9",Midrand,-1,10000+ Employees,1982,Company - Public,"Cable, Internet & Telephone Providers",Telecommunications,$10+ billion (USD),-1
Data Engineer Azure Data Factory,-1,"Enthuzex is looking for a motivated Lead Data Engineer to contribute towards the success of our Data and Analytics Technology initiatives. This is a hands-on technical role and this person will be responsible for the development and build of scalable solutions as it relates to the architecture strategies, data standards, digital data management, data integration, tools, and technology. The right candidate will play a deep dive hands-on critical development role in the digital transformation and in shaping how we acquire, ingest, transform and deliver data through the digital consumer channels.

Responsibilities:

Architect, design, develop and engineering end-to-end data pipelines across multiple data sources and systems of record.
Ensure data quality, integrity, security and completeness throughout the data lifecycle
Develop, design data models, data structures and ETL jobs for data acquisition and manipulation purposes
Develop deep understanding of the data sources, implement data standards, maintain data quality and master data management
Developing data services and API
Work closely with the cloud service providers to ensure completeness and alignment with the service offerings
Manage and maintain cloud based data and analytics platform
Deep understanding of the cloud offerings and engage in quick proof of concepts and proof of value in prototyping data and analytics solutions and derive viability
Ability to interact with the business stakeholders to understand requirements and translating into technology solutions

Expirience:

Experience in Cloud platform AWS or Azure eco-system. (Azure preferred)
Data Engineering/Development experience with SQL (Oracle, SQL Server, MySQL)
Strong development background creating pipelines and complex data transformations and manipulations using one of the languages Python, Java, R, or Scala with Databricks/Spark
Experience in NoSQL Databases and Big data technologies including Hadoop
Experience with API / RESTful data services
Worked on real-time data capture, processing and storing using technologies like Azure Event Hubs and Analytics
Experience working with different data storage options including AWS S3, Azure BLOB storage etc.
Understanding of different data formats including Parquet, Avro, CSV, ORC etc.
Prior experience with MPP databases and maintain large amount of data processing
Experience with Azure Data Factory and Azure Data Catalog is a big plus and mandatory
Experience with Microsoft/Azure ETL solutions and business Intelligence technologies is a big and mandatory
Past working experience on a fast paced and agile environment
Perform ongoing monitoring, automation and refinement of data engineering solutions
Experience in leading high visibility transformation projects that interacts with multiple business lines
Build and meet project timelines and manage delivery commitments with proper communication to management

Qualifications

Bachelor’s degree with 4+ years of relevant experience
Willingness to learn new technologies and thrive in an extremely fast paced environment
Team player and easy to work with.

Applicants must demonstrate their ability to master new enterprise level technologies. Successful applicants will exemplify Enthuzex ethical principles of uncompromising integrity, respect for others, and accountability for decisions

send cv's info@enthuzex.co.za",-1,Enthuzex,Leslie,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Scientist,-1,"The world is changing.

We all want something different.

At Luno, we see you as an individual.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the world, and to do so, we need the best team on board for our mission.

A bit about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 3 million customers across 40 countries.
We are Series B funded, backed by Balderton Capital and the Naspers Group.
Our platform has processed over 8 billion dollars since we've launched
We're proud to be one of the world's most international cryptocurrency teams from 26 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
The role in a nutshell:

Identifying opportunities in the business that could benefit most from cognitive applications, as well as building and enhancing organisational capabilities for deriving value from multiple data sources using data science.

What we'd like you to have:
Bachelor's degree or higher in the natural sciences or technical fields such as Mathematics, Statistics, Computer Science, Engineering or Economics
Enthusiasm to work in the cryptocurrencies space
Advanced SQL skills
Solid understanding of exploratory data analysis, predictive analytics, and optimisation using Python, R, Matlab, RapidMiner, KNIME or other data science-oriented platforms
Proficiency in the use of data science and machine learning domain-specific languages such as ""Caret"" and the ""Tidyverse"" suite of tools in R, or ""Pandas"" in Python
Strong interpersonal and communication skills
Communicating data insights using storytelling narratives
Ability to work independently, as well as within and across teams
Ability to successfully complete projects with large and/or incomplete data sets
More about what you'll be doing:
Optimising product performance by tracking and analysing customer behaviour on web and app, in collaboration with software engineers and product designers
Providing the business with reports and dashboards, on key performance metrics
Developing metrics to accurately assess the health of our Exchange platform
Comparative data-driven analysis of our Exchange against alternative platforms
Formulating business requirements into analytical objectives
Designing and running experiments to test hypotheses
Hacking through complex business problems using advanced data analysis to provide insights and recommendations
Building, maintaining, and optimising decisioning systems using advanced statistical and predictive modelling techniques
What will set you apart:
An advanced degree in Mathematics, Statistics, Computer Science or related field
At least 3 years' experience working in a similar role
A basic understanding of trading in financial markets
Experience working with a data analytics and visualisation platform such as Tableau, Cognos, QlikView, or Looker
Familiarity with using Google Analytics to understand customer behaviour
Solid knowledge of statistical and machine learning techniques
Familiarity with modern distributed data storage and processing systems such as Amazon Redshift, Big Query, Snowflake, Databricks and Apache Spark
You can gather and synthesise facts, theories, trends, patterns, inferences, and key issues in complex and variable situations
Ability to diagnose problems using formal problem-solving tools and techniques from multiple angles to generate multiple possible solutions
A sense of anticipating long-term problem areas and associated risk levels with objective rationale
Remote Life at Luno

If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
You'll be able to continuously upskill yourself with access to free online learning via MyAcademy, an international teaching marketplace with over 100000 courses from Harvard and other leading providers + share knowledge with your peers.
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity and paternity leave, and you can even take paw-ternity leave for your furry friend.
Annual Inspiration Day! Make time for that pottery course or spa day you've always wanted to do.
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"EY is a global leader in
assurance, tax, transaction and advisory services. Technology is at the heart
of what we do and deliver at EY. Technology solutions are integrated in the
client services we deliver and are key to our innovation as an organization.

Fueled by
strategic investment in technology and innovation, Client Technology seeks to
drive growth opportunities and solve complex business problems for our clients
through building a robust platform for business and powerful product engine
that are vital to innovation at scale. As part of Client Technology, you’ll
work with technologists and business experts, blending EY’s deep industry
knowledge and innovative ideas with our platforms, capabilities, and technical
expertise. As a catalyst for change and growth, you’ll be at the forefront of
integrating emerging technologies from AI to Data Analytics into every corner
of what we do at EY. That means more growth for you, exciting learning
opportunities, career choices, and the chance to make a real impact.

The selected
candidate
Develops
large and complex data architecture, composed of models, policies, rules or
standards that govern which data is collected and how it is stored, arranged,
integrated and put to use in data systems, including the design, build and
management of data infrastructure to address business requirements
Creates
sound use case driven roadmaps, depicting data architecture as-is and to-be
capabilities with the business by engaging with multidisciplinary teams, and by
identifying, managing and mitigating risk
Develops
relationships across the business to understand data requirements, applies deep
technical knowledge of data management to solve business problems in areas
where solutions may not currently exist, necessitating new solutions/ways of
working/technologies and proactively articulating these to the business
Review,
identify the latest emerging technologies, augmenting by services from the
leading cloud providers to solution and recommend the best next generation data
platform value driven approach for our clients
Your Key Responsibilities Include
Create
and maintain conceptual, logical and physical database models
Document
functional requirements and system specifications into the data architecture
and detailed design specifications for current and proposed designs
Document
and adhere to development standards and best practices in database designs
Maintain
highly effective and consistent communication within the team, peers, and the
leadership team
Reverse
engineer SQL code and modify it to solve problems/issues
Contribute
to the definition and implementation of data governance practices
Design
both data structures and data integration practices
Work
closely with the infrastructure teams to create a physical environment to
support data services
Evaluate
new and existing (internal and external) technologies and services in support
of data services and data analytics objectives
Skills And Attributes For Success
Understanding
of business process reengineering and business modeling concepts, business
systems development and analysis
Hands-on
experience in designing and implementing hybrid cloud and on-prem solutions
Experience
working with the latest versions of SQL Server
Experience
applying SAFe/Scrum/Kanban methodologies
Ability
to exercise judgment in solving technical, operational, and organizational
challenges
Expert
programming, performance tuning and troubleshooting skills, using the latest
popular programming languages for example python
Demonstrate
proactive approach to identifying issues and presenting solutions and options,
and where appropriate, leading to resolution
Minimum Qualifications
5+ years
demonstratable work experience as a Data Architect using data modeling tools
2-3 years
SQL coding experience on large projects
Must
possess expert SQL programming, performance tuning and troubleshooting skills
Create
database objects and SQL scripts
Understand
and developed data pipelines
Know how
to deformalize data for data science models
Experience
in python, spark and notebooks
Experience
designing data warehousing solutions
Experience
designing next generation data platforms utilising cloud services
In-depth
understanding of database structure principles
Seamlessly
able to translate business requirements to technology requirements
What We Look For
Strong
analytical skills and problem-solving ability
A
self-starter, independent-thinker, curious and creative person with ambition
and passion
Excellent
inter-personal, communication, collaboration, and presentation skills
Customer
focused
Excellent
time management skills
Positive
and constructive minded
Takes
responsibility for continuous self-learning
Takes the
lead and makes decisions in critical times and tough circumstances
Attention
to detail
High
levels of integrity and honesty
Curious
about new emerging technology
About EY
As a global leader in assurance, tax, transaction and consulting
services, we’re using the finance products, expertise and systems we’ve
developed to build a better working world. That starts with a culture that
believes in giving you the training, opportunities and creative freedom to make
things better. Whenever you join, however long you stay, the exceptional EY
experience lasts a lifetime.",3.8,"EY
3.8",Johannesburg,-1,10000+ Employees,1989,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Architect - Principal,-1,"We are looking for Principle Data Architect to join our Engineering team in Cape Town.

The world is changing.
We all want something different.
At Luno, we see you as individuals.

Together, we are upgrading the world of work to unleash the potential within and empower you to become the best possible version of yourself.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the financial landscape, and to do so, well we need the best team on board for our mission. In short, to achieve our goals, we need rockstars. As simple as that.

A little about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 5 million customers across 40 countries.
We're part of the Digital Currency Group, a group of companies driving progress in the cryptocurrency and blockchain space that includes Grayscale, Genesis, Coindesk and Foundry Services
Our platform has processed over $8 billion to date
We're proud to be one of the world's most international cryptocurrency teams from 43 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
How we work


Our engineering team (currently ~100 engineers) is split into organisations which we call Fleets. Each Fleet focuses on a core customer journey (onboarding, security, payments, support, new business, growth and marketing etc.). Each of these fleets contains multiple smaller teams called Pods, each of which focuses on a specific aspect of the product.

Pods will include a product owner, product designer, back-end engineers, Android, iOS and Web developers, who each bring a unique perspective to the problem you are all contributing towards.

We're agile, use scrum, continuous integration and continuous delivery, deploying to production every single day.

We're building teams to help us succeed in our mission to upgrade the world to a better financial system. You'll be joining a group of highly motivated software engineers who you'll work collaboratively with across our pods.

As a fast-growing company with offices around the world, you'll immediately see how your contributions directly impact both our internal users and client experience. Many of the problems we are solving result in trail blazing solutions which can't be found on Stack Overflow; so we're looking for engineers who flourish working in a complex domain.

In your first six months, you will:


...start at Luno by learning our processes, meeting the wider team and starting our engineering on-boarding program. After getting comfortable with the basics, you'll start learning our idiomatic patterns in a safe, easy-to-follow way - by building your own toy micro services. You'll get to practice how we do design docs, code reviews, deployments, events, logging and monitoring.

You'll meet the Pod(s) you'll be working with and quickly align on the teams' current OKRs and product roadmap. We succeed as a team, so we will provide you with regular feedback from your manager and peers and will encourage you to do the same.

What you'll do:
Work closely with our data science and platform teams on projects introducing new streams of data into our data lake
You will get to bring new ideas on how to further develop and innovate our data solutions and how to expose that data to the business
Accountable and Responsible for the design and architecture of Data systems that are robust and scalable.
Work in an Agile/Scrum framework or Agile mindset
Data backup/recovery and storage
Pick-up and learn new concepts, in both engineering and product, and be able to apply that knowledge quickly.
The ideal candidate for this role will have:
7+ years' experience in maintaining scalable data solutions and/or you are passionate about it
Ability to understand, communicate and advocate between build vs buy
Proven track record of setting up, restructuring and maintenance of databases
You know your way around ETL and you have experience with SQL
Experience in the AWS Data stack (RedShift,DynamoDB, Amazon RDS)
Familiarity with integrating data stores with BI platforms such as Looker, Tableau, or Power BI
You have experience with the concepts of CI/CD
Coding skills in e.g. Go, Python
Bachelor's degree in a related field preferred
AWS Certified DataOps Administrator
Be friendly, transparent, articulate and driven to succeed
Basic knowledge of and passion for digital currencies like Bitcoin
A work permit for South Africa if you are not a South African citizen
Don't be put off if you don't tick all of the boxes – they're a guide based on what we'd love to see but we appreciate that excellent software engineers have diverse backgrounds.

Remote Life at Luno


If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity / paternity and even (yes, you are reading it correctly) paw-ternity for your furry friend..
Annual Inspiration Day.. like that pottery course you've always been meaning to do!
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. You'll need to hold the legal right to work in South Africa already as we cannot provide visa sponsorship.

Be part of the change!",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer - EC2 Capacity Data Analytics,-1,"EC2 Capacity Data Analytics (CDA) team is looking for a Data Engineer to join our team.

Our team is part of the EC2 Capacity Engineering organization, which is responsible for providing the elasticity EC2 customers need to scale up/down compute resources in a cost-efficient manner. We predict customer usage across thousands of configuration combinations to deliver exactly what our customers require in just the right amount of time with just the right amount of capacity.

As a Data Engineer, you will build the ETL and analytics solutions for our internal customers to answer questions with data and drive critical improvements for the business. You will use best practices in software engineering, data management, data storage, data compute, and distributed systems. On any given day, we use Python, Scala, Java, SQL, Lambda, CloudFormation, Redshift and Glue as well as other public AWS services and a host of Amazon internal tools. We dont expect you to be an expert in, or necessarily even be familiar with all of the technologies listed above, but we do expect you to be excited to learn about them.

This position involves on-call responsibilities, typically for one week every two months. Our team is dedicated to supporting new team members. We care about your career growth, we try to assign projects and tasks based on what will help each team member develop into a more well-rounded engineer and enable them to take on more complex tasks in the future.

Our team values work-life balance and we are flexible when people occasionally need to work from home.

Job Duties
Develop and maintain automated ETL pipelines for big data using languages such as Scala, Spark, SQL and AWS services such as S3, Glue, Lambda, SNS, SQS, KMS. Example: ETL jobs that process a continuous flow of JSON source files and output the data in a business-friendly Parquet format that can be efficiently queried via Redshift Spectrum using SQL to answer business question.

Develop and maintain automated ETL monitoring and alarming solutions using Java/Python/Scala, Spark, SQL, and AWS services such as CloudWatch and Lambda.

Implement and support reporting and analytics infrastructure for internal business customers using AWS, services such Athena, Redshift, Spectrum, EMR, and QuickSight.

Develop and maintain data security and permissions solutions for enterprise scale data warehouse and data lake implementations including data encryption and database user access controls and logging.

Develop and maintain data warehouse and data lake metadata, data catalog, and user documentation for internal business customers.

Develop, test, and deploy code using internal software development toolsets. This includes the code for deploying infrastructure and solutions for secure data storage, ETL pipelines, data catalog, and data query.


Basic Qualifications

· Bachelors degree in Computer Science or related technical field, or equivalent work experience.
· 4+ years of overall work experience including Software Engineering, Data Engineering, Database Engineering, Business Intelligence.
· Experience with AWS technologies stack including Lambda, Glue, Redshift, RDS, S3, EMR or similar big data solutions stack

Preferred Qualifications

· Demonstrate efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data.
· Demonstrable proficiency in distributed systems and data architecture; design and implementation of batch and stream data processing pipelines; knows how to optimize the distribution, partitioning, and MPP of high-level data structures.

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer,-1,"Our client based in Johannesburg is urgently looking for a Data Engineer to be on a 3 months contract
Build data pipelines, experience in new tech like nifi, kafka, python

Joburg based, open to EE, 3 month contract with the option to extend, must be available at short notice",-1,EQplus,Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Overview
Job ID: 51456
Job Sector: Information Technology and Services
Country: South Africa
Region/State/Province/District: Gauteng
Location: Johannesburg

Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose

This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes

Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems

Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions

Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.
Research and best practices

Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development

Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.

Preferred Qualification and Experience

Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry

Knowledge/Technical Skills/Expertise

Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision

PLEASE NOTE: All our recruitment and selection processes comply with applicable local laws and regulations. We will never ask for money or any form of payment as part of our recruitment process. If you experience this, please contact our Fraudline on +27 800222050 or forward to TransactionFraudOpsSA@standardbank.co.za",4.1,"Standard Bank
4.1",Johannesburg,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"About us

At PBT Group we pride ourselves on being a Data Specialist organisation. With 20 years of experience in 27 countries over 3 continents, our team of 550 consultants have implemented more than 700 projects.",4.3,"PBT Group
4.3",Johannesburg,-1,Unknown,-1,Company - Private,Accounting,Accounting & Legal,Less than $1 million (USD),-1
Data Engineer,-1,"Kick-start your career in the online gaming world and experience the very latest in technology and innovation.

The Department:

Our mission is to provide our customers with the best online betting experience and share the thrill of gaming with them. Data is at the very heart of our business and is vital in everything we do.

Our cross-functional Data team has a big and exciting challenge ahead. We are in the process of re-platforming our traditional, on-premises RDBMS environment to a new microservice architecture in the cloud. We’re making use of the diverse set of data technologies in Microsoft Azure to offer new services, reporting structures and real-time data pipeline while serving the day-to-day requirements of a rapidly growing, data-hungry organisation.

Purpose of the Role:

This is an excellent opportunity for an individual who is looking to gain new skills. We are committed to creating a culture of learning and regularly run proof of concepts, provide internal demos, manage workshops and attend external conferences. Our data team has a wide range of skills including development for highly transactional RDBMS systems, data warehousing, data science and cloud technologies and we are always working to raise everyone’s game.

Duties include, but not limited to:

Work as part of an agile Data Engineering Team
Development of greenfield projects in Azure
Develop and maintain on-premises RDBMS/DW systems
Create robust ETL services and real-time data pipelines
Build and maintain Continuous Integration and DevOps pipelines
Test-driven development and pair programming with colleagues

Essential Criteria:

C#, .Net, Visual Studio
Git, Azure DevOps
NoSQL development (CosmosDB)
Demonstrable understanding of MS SQL Server in a highly transactional environment
Demonstrable understanding of development in Microsoft Azure
Able to understand query plans and identify performance bottlenecks
Test/Business-Driven Development
Building Continuous Integration/Deployment pipelines
Communicate effectively with both technical and non-technical stakeholders

Desirable Criteria:

Implementing Data Storage and Processing solutions in Azure (ARM Templates, Storage Accounts, Data Lake Storage, SQL DB, Cosmos DB, EventHubs, Function Apps, Log Analytics, Data Factory, Databricks, Polybase)
Implementing Security, Disaster Recovery, High Availability, Auditing, Monitoring and Alerting solutions in Azure
Automating tasks in Azure using Powershell / CLI
Predicting costs and optimizing spending in Azure
Message Queues (RabbitMQ, Kafka)
Python

Person Specifications:

Resilience
Teamwork
Technical Knowledge
Communication skills
Stress Tolerance
Please note we will apply relevance to our Talent Management and Talent Development Programme as part of our recruitment process.
Shortlisted candidates may need to complete an assessment.
This position requires trust and honesty it has access to customers financial details - therefore a credit and criminal record check will be conducted. The qualifications identified herein are an inherent job requirement; therefore, a qualification verification check will be done. By applying for this role, and supplying the necessary details, you hereby grant us permission to apply for these checks. This will be done in a confidential manner, and solely for the purposes of verification.

To view all current vacancies, please visit our website, www.digioutsource.com

Should you not hear from us within 2 weeks, please deem your application as unsuccessful.

The perfect place to work, play and grow!",3.9,"Digital Outsource Services
3.9",Cape Town,-1,1001 to 5000 Employees,1997,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
Data Engineer,-1,"At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes

Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.

Key Responsibilities

Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.

Key Traits

Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern

Position Requirements

2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.

Where will you work? This role will be based out of Durbanville, South Africa.",3.1,"Aculocity, LLC
3.1",Durbanville,-1,1 to 50 Employees,2006,Company - Private,IT Services,Information Technology,$1 to $5 million (USD),-1
Data Engineer,-1,"ENVIRONMENT:

A rapidly growing E-Commerce Platform seeks a highly talented Data Engineer to make an invaluable contribution to data democratisation and literacy vision by making accessible and easy-to-use data products and tools. You will require a Comp-Sci Degree or 3 years’ relevant industry experience, MySQL, PostgreSQL, Java, Python, in-depth understanding of OLAP, Data Marts, Star Scheme, Snowflake, be familiar with Jenkins, Travis, Circle CI, Docker, Kubernetes, experience with Kafka, Pub/Sub, Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks & significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing & Data Lake design and implementation and Lambda/Kappa architectures.

DUTIES:

Design, develop, test and maintain data architecture.

Prepare data for descriptive, predictive and prescriptive modelling.

Automate repetitive tasks and manual processes related with the data usage.

Optimize data delivery.

Design, develop and test large stream data pipelines to ingest, aggregate, clean, and distribute data models ready for analysis.

Ensure the highest standard in data integrity.

Leverage best practices in continuous integration and delivery.

Collaborate with other engineers, ML experts, analysts, and stakeholders to produce the most efficient and valuable solutions.

Implement features, technology, and processes that move us towards industry best practices, improving on scalability, efficiency, reliability, and security.

Operations and ownership of systems in production, responding to incidents.

REQUIREMENTS:

Qualifications –

Comp-Sci Degree or 3 years relevant industry experience.

Experience/Skills –

Open source relational database systems e.g. MySQL, PostgreSQL, etc.

Significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing, and Data Lake design and implementation and Lambda/Kappa architectures.

A thorough understanding of database and data warehousing principles e.g. OLAP, Data Marts, Star Schema, Snowflake, etc.

Java and Python.

Familiar with CI/CD tools such as Jenkins, Travis, Circle CI, etc.

Experience with Kafka, Pub/Sub, or other event-based systems.

Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks, etc.

Working in cloud environments and with containerisation frameworks, tools and platforms e.g. Docker, Kubernetes, GKE, etc.

A deep understanding of data pipelining, streaming, and Big Data technologies, methods, patterns, and techniques.

Troubleshooting complex database operations and performance issues.

Automating tasks using Shell Scripting or writing small applications.

ATTRIBUTES:

Works well with people and is passionate about helping people be their best.

A team player, an active listener, mentor, and able to communicate well.

Shows solid reasoning and decision making, with the ability to work under pressure.

Is passionate about technology, systems and data.

Is curious, always learning, and keeping up to date with the industry.

While we would really like to respond to every application, should you not be contacted for this position within 10 working days please consider your application unsuccessful.

COMMENTS:

When applying for jobs, ensure that you have the minimum job requirements. Only SA Citizens will be considered for this role. If you are not in the mentioned location of any of the jobs, please note your relocation plans in all applications for jobs and correspondence.",-1,Datafin IT Recruitment,Cape Town,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Cartrack is looking for passionate data science and engineering candidates that can join a growing team that is responsible for the intelligence and efficiency solution provision to over a million subscribers, many of whom are large fleets. We are in the midst of creating revolutionary platforms that will change the way that people interact with their vehicles.

You will have the opportunity to work with the very brightest global subject matter experts that are transforming the automotive industry across Fleet Management, Asset Management and Insurance Telematics solutions.

Get to know the role:

The role of a data engineer is a supporting one, but it is also an extremely vital one. As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements. We want to see candidates with mechanical tendencies and a desire to know how things work and to improve them.

The day-to-day activities:

Design, construct, install, test and maintain data management systems.
Build high-performance algorithms, predictive models, and prototypes.
Ensure that all systems meet the business/company requirements as well as industry practices.
Integrate up-and-coming data management and software engineering technologies into existing data structures.
Develop set processes for data mining, data modeling, and data production.
Create custom software components and analytics applications.
Research new uses for existing data.
Employ an array of technological languages and tools to connect systems together.
Install/update disaster recovery procedures.
Recommend different ways to constantly improve data reliability and quality.
Work on and maintain Data pipelines.

Requirements Essential:

At least 5 years’ proven experience as a Data Engineer, DevOps Engineer, Software Developer, or similar.
Proficient in Linux/Unix and shell scripting as well as in functional programming languages.
Expertise in setting up and explored with technologies such as Hadoop and Spark.
Bachelor’s degree in computer science, software/computer engineering, applied mathematics, or physics.",3.3,"Cartrack
3.3",Johannesburg,-1,501 to 1000 Employees,2004,Company - Private,Security Services,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Data Engineer,-1,"Data Engineers build and support data pipelines and datamarts built off those pipelines. Both must be scalable, repeatable and secure. The Data Engineer helps to facilitate gathering data from a variety of different sources, in the correct format, assuring that it conforms to data quality standards and assuring that downstream users can get to that data timeously. This role functions as a core member of an agile team. These professionals are responsible for the infrastructure that provides insights from raw data, handling and integrating diverse sources of data seamlessly. They enable solutions, by handling large volumes of data in batch and real-time by leveraging emerging technologies from both the big data and cloud spaces. Additional responsibilities include developing proof of concepts and implements complex big data solutions with a focus on collecting, parsing, managing, analysing and visualising large datasets. They know how to apply technologies to solve the problems of working with large volumes of data in diverse formats to deliver innovative solutions. Data Engineering is a technical job that requires substantial expertise in a broad range of software development and programming fields. These professionals have a knowledge of data analysis, end user requirements and business requirements analysis to develop a clear understanding of the business need and to incorporate these needs into a technical solution. They have a solid understanding of physical database design and the systems development lifecycle. This role must work well in a team environment.

Job Objectives

Work Complexity: * Architects Data analytics framework. * Translates complex functional and technical requirements into detailed architecture, design, and high performing software. * Leads Data and batch/real-time analytical solutions leveraging transformational technologies. * Works on multiple projects as a technical lead driving user story analysis and elaboration, design and development of software applications, testing, and builds automation tools.

Main Job Objectives: 1. Development and Operations 2. Database Development and Operations 3. Policies, Standards and Procedures 4. Communications 5. Business Continuity & Disaster Recovery 6. Research and Evaluation 7. Coaching/ Mentoring

Qualifications

Essential: 4 years Bachelors degree in computer science, computer engineering, or equivalent work experience AWS Certification at least to associate level

Experience

Essential:

5+ years Data engineering or software engineering

3-5 years demonstrated experience leading teams of engineers

2+ years Big Data experience

5+ years experience with Extract Transform and Load (ETL) processes

2+ years Could AWS experience

At least 2 years demonstrated experience with agile or other rapid application development methods - Agile exposure, Kanban or Scrum

5 years demonstrated experience with object oriented design, coding and testing patterns as well as experience in engineering (commercial or open source) software platforms and large scale data infrastructures.

Desirable:

5+ years Retail Operations experience

Knowledge and Skills

Essential: *Creating data feeds from on-premise to AWS Cloud (2 years) *Support data feeds in production on break fix basis (2 years) *Creating data marts using Talend or similar ETL development tool (4 years) *Manipulating data using python and pyspark (2 years) *Processing data using the Hadoop paradigm particularly using EMR, AWSs distribution of Hadoop (2 years) *Devop for Big Data and Business Intelligence including automated testing and deployment (2 years) * Extensive knowledge in different programming or scripting languages * Expert knowledge of data modeling and understanding of different data structures and their benefits and limitations under particular use cases.

Further technical skills required: * Capability to architect highly scalable distributed systems, using different open source tools. * Big Data batch and streaming tools * Talend (1 year) * AWS: EMR, EC2, S3 (1 year) * Python (1 year) * PySpark or Spark (1 year) - Desirable * Business Intelligence Data modelling (3 years) * SQL (3 years)",-1,Datonomy Solutions,Brackenfell,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We are assisting one of our clients that is based in Pretoria to fill a role of a Data Engineer

This is a 12 month contract role

Objective of this Scope of Work

The Data Engineer will drive improvement of the data management maturity levels and provide the necessary technical support within the company to support reliable and effective decision-making, appropriate usage and protection thereof.

Scope of Services Definition

The scope will include but will not be limited to:

ï†· To develop, construct, test and maintain architectures.

ï†· To ensure architectures will support the requirements of business.

ï†· To discover opportunities for data acquisition and sharing.

ï†· To develop data set processes for data modelling, mining and production.

ï†· To employ a variety of languages and tools to marry systems together.

ï†· To recommend way to improve data reliability, efficiency and quality.

ï†· To prepare data for use in predictive and prescriptive modelling.

ï†· To conduct research to answer industry and business questions.

ï†· To leverage volumes of data from internal and external to answer business questions.

ï†· To develop and manage stakeholder relations effectively to promote data management across the organisation and support reliable decision making and appropriate data usage.

ï†· To participate and provide technical support in cross organisational activities relating to any of the above mentioned data management activities.

ï†· To provide regular progress reports as per stakeholder requirements and present data management updates in various forums as required.

Minimum qualification Required:

ï†· A minimum of a Bachelors degree in Computer Science or Information Management OR equivalent;

ï†· A minimum of five to eight years experience in a data management environment",-1,HR Genie,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Our client based in the Northern Suburbs, is currently looking for a Data Engineer to join their team.

Responsibilities
Our client is a dynamic IT company that delivers value-driven IT solutions to the group. Our work lives revolve around our DNA. We take pride in our work, treat our colleagues, partners and our country with respect. We exercise collaborative decision-making and believe in having a balance in life. We do this all while having fun and enjoying what we do.

The primary focus of this position is to use technical skills to put software, systems and data together in a way that extracts meaningful insights from raw data. You will need to be helpful and supportive to your team and fellow developers. You join an energetic, focused and dynamic team.

Interact with clients to understand requirements and business problems/needs

Identify, analyse, visualise and understand supporting data to propose solid solutions

Create technical documentation for reference and reporting

Support existing solutions within GCP and Oracle

Doing standby on a rotating basis

Key Competencies and Qualifications

Matric

Tertiary qualification in IT

Preferred cloud experience in AWS/AZURE/GCP

At least 3 years of data warehouse ETL experience

Dimensional Modelling

Data analyses

Experience with data visualization and visualization tool(s)

Knowledge of the retail industry will be beneficial

Understanding and experience with version control SVN/GIT

Preferred – Korn shell scripting, Python/Java, SQL

Google Cloud Platform experience would be looked upon favourably

Having a broad understanding of different SDLC’s

Preferred agile experience

Strengths

The natural tendency to take ownership and responsibility

Strong problem solving, critical thinking, effective planning and organisational skills

Detail-oriented with excellent communication skills

You have a can-do attitude and positive outlook on life

Can cope under pressure

Curious and interested in analysing problems and possible solutions

Strong team player

Self-driven learner, passionate about new technology

Above all, be passionate about what you do

Should you wish to apply for the position, please apply directly via this job board, please ensure that you quote reference number 201620 subject heading or email body.

Please note that due to the high volume of CV's received; only shortlisted applicants will be contacted. Should you not receive communication from our offices within two weeks of submission please note that your application will not be considered for this position.

We will keep your CV on file and re-establish contact with you should opportunities in line with your expertise become available again.

Should you require any additional information give us a call on 021 012 5566.",-1,Surgo HR & Training,Cape Town,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We believe that our employees fuel our organization, essential to enable us to help our customers overcome their business challenges and achieve sustainable growth. As a result, we are committed to growing each individual and providing them with the challenges, feedback and support needed to achieve success in their career

If this sounds appealing, and like us, you get excited about data: its collection, storage, transformation or display, see if you’ve got what it takes to join our sought after DATA team.

Key Responsibilities And/or Outputs

You will represent IQbusiness at our customers, sometimes alone, and sometimes as part of an IQ team.

Providing a superior customer experience by building and maintaining relationships, working at customer offices, keeping data confidential
Design and develop – databases, SQL queries, stored procedures, reports, dashboards or integration solutions
Produce solutions for both real-time and batch environments
Test your work to ensure compliance
Solve problems, and do root cause analysis
Prioritize your workload
Assist in other areas relating to your true data function, such as data modeling, data and business analysts
Interact with a variety of individuals: senior, junior, technical and from business
Provide guidance to fellow colleagues, or even manage a team
Uphold the IQ values, which are to care, learn & share; innovate; deliver as well as to build, enhance and maintain relationships

Education

Matric pass
A tertiary qualification, preferably in an ICT relevant field
Appropriate Microsoft certifications are beneficial but not required

Requirements

3 - 6 years experience in the Data Engineering environments and technologies
Great communication skills
A passion for SQL, databases or reports
Can you write stored procedures, design complex queries and create views and triggers?
Are you able to work out the relationships in a data warehouse or the aggregation of a cube?
Do you extract and display useful information when you see patterns and trends in data?
Strong knowledge of the financial services industry, ideally in a consulting role
The use of data related software: databases, ETL and BI tools; report writing and analytical tools
We use a lot of Microsoft products. You may often be expected to use MS SQL Server, SSIS, SSRS, SSAS and Power BI to develop solutions
What other relevant software have you’ve used?
Ability to work in different project methodologies: Waterfall and/or Agile
Knowledge of full SDLC
Exposure to logical and physical data modeling

Equal Employment Opportunity

IQbusiness is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, citizenship, marital, domestic or civil partnership status, sexual orientation, or gender identity",3.7,"IQbusiness South Africa
3.7",Johannesburg,-1,1 to 50 Employees,-1,Company - Private,Consulting,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"We value a data engineer as someone who works behind the scenes to obtain, process and supply data via various methodologies and technologies, to various consumers, in ways and forms that makes sense and add value. This definition is very broad, as the field of data engineering is just as broad.

You may be the type of data engineer that develops API endpoints for the consumption of data by end users or even another data pipeline, or you may be the type of data engineer that develops highly distributed, high availability data processing pipelines in an effort to satisfy the need of the ever questioning data analysts and/or data scientists.

You have awesome knowledge about the following concepts
Data modelling
Relational data modelling in traditional relational database management systems. (Microsoft SQL Server, MySQL, PostgreSQL, etc)
Coercing unstructured and semi-structured data into a structured form.
Data pipelining knowledge - data extraction and transformation.
Data transformation knowledge for reporting and analytics purposes.
Knowledge of the MapReduce and related data processing paradigms would be a boon.
You have the following technical competencies
Writing SQL queries, that can relate, transform and aggregate data from many differing sources where natural keys may or may not exist.
Experience with writing data pipelines that move and transform data, for various uses.
Working knowledge of a general purpose programming language like Python would be a boost.
Working knowledge of columnar databases such as Google BigQuery, and SAP HANA would be a boost.
Working knowledge of highly distributed technologies such as Apache Hadoop or Apache Spark would be a boost.
Working knowledge of NoSQL technologies, such as Apache Solr would be a boost.
You have the following personal competencies
The ability to solve problems.
The ability to rotate around a problem, to see if solutions can be gained in different ways.
The ability to work in an ever changing, unstructured environment.
The ability to work as part of a team, with vastly differing skill sets and opinions.
The ability to contribute ideas to the quorum.
The ability to mentor and provide guidance for other team members.
A systems approach to thinking, as opposed to a siloed approach. The candidate needs to understand how their work affects the greater system.
The ability to work without supervision, and take accountability for the work they deliver.
The ability to liaise with a client, sifting through the fluff and extracting the actual requirements.
If this is you - apply now and we'll get in touch",-1,DotModus,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Data Engineer

Our client in the contact centre space is currently seeking a DATA ENGINEER that will work on the collecting, storing, processing, and analyzing of large datasets. The primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them. You will also be responsible for integrating them with the architecture used across the company.

Key Performance Areas:

Data reporting.
Implementing ETL processes.
Defining data retention policies.
Management of Customer Lead data.
Provision of data for advanced analytics.
Maintenance of internal client scorecards.
Assist team in resolving data-related support queries.
Optimize existing data processes through automation.
Assist with all data-related reporting and documentation.
Maintenance and optimisation of the Analytics database.
Provide technical support to and supervision of junior data administrators.
Continuous upskilling on new technologies, frameworks and market trends.
Monitoring performance and advising any necessary infrastructure changes.
Identifying, selecting and integrating any Big Data tools and frameworks required to provide real-time analytics.

Educational Requirements

IT related Degree or Diploma is a pre-requisite

Required Skills/Experience

ETL tools: Advanced SSIS
BI/Reporting : Qlikview/Power BI/ SSRS or SSAS
Programming languages: JAVA, C# , Python, SAS or R
Experience with NoSQL databases and/or campaign management tools will be advantageous.
Minimum 3 years’ applicable work experience in SQL, relational databases and data manipulation.
Experience in big data platforms (eg. Hadoop) or processing frameworks (eg. MapReduce/Spark) and querying tools (eg. Pig, Hive and Impala) will be highly beneficial.

Preferred Skills

Organizational skills
Experience in Attentional to detail.
Accountability is critical for this role.
Ability to work under pressure and meet deadlines.
Solid understanding of database design principles.
Should you not receive a response in 2 weeks please consider your application unsuccessful",-1,Rubik's Cubed Consulting,Durban,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"This well known company is looking for a Data Engineer. will be based in Rivonia
The ideal candidate will have strong experience in the following:
Data cleaning
SQL Export
Big data Sets

BSc Degree in Maths and Stats will be required
a min of 3 years experience.
Stable track record is required.

Send your Cv to marinda@prrrecruitment.co.za",-1,PRR Recruitment Services,Johannesburg,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Description

Position at Aculocity, LLC

At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes
Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.
Key Responsibilities
Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.
Key Traits
Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern
Position Requirements
2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.
Where will you work? This role will be based out of Durbanville, South Africa.",-1,GVW,Durbanville,-1,Unknown,-1,Unknown,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Information Technology, Gauteng JHB - Northern Suburbs

Market related - Market related Annually

An IT Consultancy Business based in Johannesburg is currently looking for a Business Intelligence Consultant / Data Engineering Consultant.

Requirements:

Extensive experience in data engineering
Experience in Business Intelligence, data and Power BI
Extensive experience in data governance and the Popi act
Ability to assess and make recommendations on data within the Popi act
Good understanding of T-SQL and query optimization, developing ETL strategies.
Good understanding with SQL Server 2008/2012, SSIS, SSRS and SSAS
Use SSIS to create ETL packages to validate, extract, transform, and load data into the data warehouse and data marts.
Deploy and configured the reports in the Report Server (SSRS).
Excellent experience in Tabular Modelling , PowerView, Qlikvie,w, and Power BI
Maintain ETL
Qlikview model
Create Drill-through, Drill-down, and Cross Tab Reports and Sub-Report using Report Definition Language (RDL).
Generate periodic reports based on the statistical analysis of the data using SQL Server Reporting Services (SSRS)
Advise and provide written technical documentation and recommendations

The information displayed above is not limited to advertisements. Please contact Thato for further information.

Please consider your application as unsuccessful if you have not received a response within 14 days of submitting your application. However, please keep a lookout on our website, www.bedifferent.co.za, for available positions that you may be suited for

Ad Visible Until: 29 October 2020
Ref: JHB005346/NL

Vacancy Type: Permanent",2.9,"Be Different Recruitment
2.9",Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Cloud Support Engineer (Big Data),-1,"ABOUT US

Amazon Web Services is the market leader and technology forerunner in the Cloud business. As a member of the AWS Support team you will be at the forefront of this transformational technology, assisting a global list of companies and developers that are taking advantage of a growing set of services and features to run their mission-critical applications. As a Cloud Support Engineer, you will act as the Cloud Ambassador across all the cloud products, arming our customers with required tools & tactics to get the most out of their Product and Support investment.

Would you like to use the latest cloud computing technologies? Do you have an interest in helping customers understand application architectures and integration approaches? Are you familiar with best practices for applications, servers and networks? Do you want to be part of a customer facing technology team helping to ensure the success of Amazon Web Services (AWS) as a leading technology organization?

If you fit the description, you might be the person we are looking for! We are a group of smart people, passionate about cloud computing, and believe that world class support is critical to customer success.

WHAT CAN YOU EXPECT FROM A LIFE AT AWS?

Every day will bring new and exciting challenges on the job while you:

· Learn and use groundbreaking technologies.
· Apply advanced troubleshooting techniques to provide unique solutions to our customers' individual needs.
· Interact with leading engineers around the world.
· Partner with Amazon Web Services teams to help reproduce and resolve customer issues.
· Leverage your extensive customer support experience to provide feedback to internal AWS teams on how to improve our services.
· Drive customer communication during critical events.
· Drive projects that improve support-related processes and our customers technical support experience.
· Write tutorials, how-to videos, and other technical articles for the developer community.
· Work on critical, highly complex customer problems that may span multiple AWS services.

WHY AWS SUPPORT?

· First and foremost this is a customer support role in The Cloud.
· On a typical day, a Support Engineer will be primarily responsible for solving customers cases through a variety of customer contact channels which include telephone, email, and web/live chat. You will apply advanced troubleshooting techniques to provide tailored solutions for our customers and drive customer interactions by thoughtfully working with customers to dive deep into the root cause of an issue.
· Apart from working on a broad spectrum of technical issues, an AWS Support Engineer may also coach/mentor new hires, develop & present training, partner with development teams on complex issues or contact deflection initiatives, participate in new hiring, write tools/script to help the team, or work with leadership on process improvement and strategic initiatives.
· Career development: We promote advancement opportunities across the organization to help you meet your career goals.
· Training: We have training programs to help you develop the skills required to be successful in your role.
· We hire smart people who are keen to build a career with AWS, so we are more interested in the areas that you do know instead of those you havent been exposed to yet.
· Support engineers interested in travel have presented training or participated in focused summits across our sites or at specific AWS events.
· As we operate on a follow-the-sun model, with Premium Support sites located globally, there is no after hours on-call or mandated overtime in this role.
· https://www.youtube.com/watch?v=GC3bWcFFZTo&t=24s



Basic Qualifications

The Big Data role supports our services that leverage data and produce business insights, which may include using Machine Learning/Artificial Intelligence (ML/AI). Helping our customers use and integrate Big Data services in what is arguably our industrys most exciting space. The portfolio of services covers EMR (Hadoop), DynamoDB (NoSQL), MangoDB, and Apache Cassandra.

· Advanced experience in Apache Hadoop, Apache Spark, Apache Hive, and Presto
· Advanced experience in DynamoDB or NoSQL technologies like MongoDB or Cassandra
· Advanced experience with System Administration with Linux (RHEL/CentOS) including Microsoft Active Directory, and LDAP integration.
· Experience with troubleshooting Kerberos Authentication problems.
· Experience with Network troubleshooting.
· Basic understanding of Machine Learning and statistics
· Experience with Java and Python and shell scripting
· Bachelors degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position



Preferred Qualifications

· Expert experience in the Hadoop Ecosystem including Apache Spark and Presto
· Expert experience in NoSQL
· Expert experience with blockchain technologies like Etherium Expert experience in data Data Lake architecture and administration
· Experience managing full application stacks from the OS up through custom applications
· Prior work experience with AWS - any or all of EC2, VPC, S3, RDS, EMR, Glue, SageMaker
· Excellent knowledge of Hadoop architecture, administration and support
· Expert understanding of distributed computing principles and their application in the cloud
· Good understanding of distributed computing environments Lead technical discussions on big data systems architecture and design
· Strong analysis and troubleshooting skills and experience
· AWS Certified Solutions Architect
· AWS certified Big Data Specialty
· Masters degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity and Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Response Center Engineer,-1,"Job Title
Response Center Engineer
Job Description


Philips is a world leading health technology company with a vision to make life better for people worldwide through meaningful innovation. Making good on this promise depends on our passionate, inspirational, collaborative and diverse team. We have over 80,000+ brilliant people around the world but are always looking for more. Like-minded, motivated, focused minds to join us in creating a healthier, more connected society while transforming themselves personally and professionally.

As a CCC Coordinator - Response Center Engineer you will have the opportunity to process customer calls and be responsible for screening and diagnosing professionally Healthcare equipment to support customers and colleagues remotely with solving technical issues and ensuring maximum customer satisfaction

You are responsible for:
Diagnose healthcare equipment to the quality standards set by Philips Healthcare (PH) remotely by interviewing customers or colleagues by telephone or by remotely logging in to the system
Advise Customer Care Center Coordinators and District Operations Managers and / or Team Leads about the best follow-up w.r.t. technical state of the diagnosed healthcare equipment
Advise the Customer Care Center Coordinators or Field Services Engineers about required spare parts and resources
Responsible for planning engineers related to Modality responsibility.
Responsible for coordination between CCC, CUSTOMER, Spare parts AND Engineer.
Responsible to drive Remote and FTR KPI’s to targets respectively 40% and 85%.
Will require minimal field work to keep abreast of technical capabilities.
Take calls from customers and make sure they are processed in the CCC ERP on timely manner including all relevant data
Support Field Services Engineers in the field with technical knowledge
Escalate technical issues to the Technical Support Specialist
Escalate technical issues to Business Unit support after consultation of the Technical Support Specialist
Monitor critical functions of the equipment’s in the IB and environmental conditions including RSN and True reachability.
Lead the planning and implementation of FSN’s and FCO’s accelerating remote implementation where applicable.
Submit timely and accurate service data, job sheets, reports, expense claims, radiation film badges, field problem reports and other paperwork as assigned
Keep abreast of new technologies likely to affect PH range of products
Use company property with care to ensure optimal results with minimal operational costs
Be a professional representative for PH with respect to customer problems, ensuring personal acceptability by the customer in behavior in accordance with PH policy and targets
Conform to PH safety standards including health and safety regulations and in the event of hazards or accidents to take immediate control of the situation and involve the Operations Manager and / or the responsible person to handle properly confidential issues according Philips standards and to act according General Business Principals
Follow all quality standards within the frame of valid PH business policies
Follow the company quality regulations (ISO 9001; PQA; TQM) and internal directives and procedures
You are a part of the dynamic South Africa Customer Care Centre Team .You will be reporting to the Customer Care Center Manager.

Requires a pleasant, assertive individual you can work very well in a team setting, a dynamic environment that requires flexibility and creativeness to achieve goals.

To succeed in this role, you should have the following skills and experience:
Degree level education or equivalent
Experience in maintenance and troubleshooting of technical complex systems
Fluent in English, verbal and written in addition to local language
In return, we offer you the unique combination of a critical and challenging role and a creative and empowering office environment. You will be actively encouraged to make improvements, establish best in class service and have a direct impact on the success of Philips on a daily basis.

Employment Equity

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply. Only apply for this role if you are a South African Citizen by birth or Naturalization prior to the 27 April 1994.

Why should you join Philips?

Working at Philips is more than a job. It’s a calling to create a healthier society through meaningful work, focused on improving 3 billion lives a year by delivering innovative solutions across the health continuum. Our people experience a variety of unexpected moments when their lives and careers come together in meaningful ways. Learn more by watching this video.

To find out more about what it’s like working for Philips at a personal level, visit the Working at Philips page on our career website, where you can read stories from our employee blog. Once there, you can also learn about our recruitment process, or find answers to some of the frequently asked questions.

Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.9,"Philips
3.9",Johannesburg,-1,10000+ Employees,1891,Company - Public,Health Care Services & Hospitals,Health Care,$10 to $25 million (USD),-1
Software Development Engineer - EC2 Placement,-1,"Build the systems that optimize how EC2 matches requests for Instances with the underlying compute capacity. EC2 Placement is seeking talented engineers to build the online and offline optimization systems for compute workload scheduling, and the customer capabilities to better manage those workloads. Amazon EC2 provides on-demand scalable compute capacity, and powers some of the largest services in the world. You will collaborate with a top-tier community of engineers to build systems to improve how customers are able to access EC2 compute resources.

The successful candidate will have strong software engineering experience, with a passion for thinking about, building and testing distributed systems. You have an interest in how Machine Learning and other optimization techniques can be applied to large-scale problems. You have demonstrated experience working with a team to design, build and operate large-scale systems. With strong engineering fundamentals, an analytical and data-driven approach to your work, and strong communication skills, you have the ability to collaborate well to deliver results. We move fast and work together on small teams to solve big problems.

If this opportunity sounds interesting, we would love to talk to you more about our work and the vibrant culture at AWS in Cape Town.

Basic Qualifications

· Degree in Computer Science or related field, or equivalent working experience
· 3+ years of industry experience in a software development environment
· Strong Computer Science fundamentals, including data structures, object-oriented design, algorithm design, problem solving, and complexity analysis.
· Proficiency in at least one modern programming language, such as Java, C#, Python, Scala, Kotlin

Preferred Qualifications

One or more of the following help you stand out:
· Demonstrated results designing, building and operating high-performance distributed systems in large-scale Linux environments
· Role model in writing high-quality, maintainable and secure code, mentoring others, and helping teams sharpen their development processes
· Ability to work effectively across teams to deliver results, with strong verbal and written communication skills
· Experience working with machine learning systems

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer - PBB IT,-1,"Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose


This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes
Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems
Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions
Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.

Research and best practices
Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development
Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.
Preferred Qualification and Experience
Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Aws Data Platform Engineer,-1,"Aws Data Platform Engineer

Posting Country:

South Africa

Date Posted:

15-Oct-2020

Full Time / Part Time:

Full Time

Contract Type:

Permanent

Joining Vodacom is more than a job, what we do matters. We don’t just carry minutes, texts and data – we carry people’s lives. And that’s a huge responsibility. If you think for a minute about the people you rely on…the likelihood is they rely on us.

Customers are at the heart of everything we do and we want to make a difference to the lives of our customers, and the communities in which we live and work. We support our people to give something back to the causes that mean the most to them through helping them give time and money to the charities they love.

And what’s it like to work here? We have created an environment where you can look forward to coming to work and are empowered to be at your best. We offer flexibility in how you work that helps you do your job in a way that suits you, opportunities to help you grow and progress throughout your career and a choice of benefits to suit your lifestyle.

Role Purpose
The H Band AWS Data Platform Engineer position is based within the Technology Business Unit.

The AWS Data Platform Engineer will be responsible for all Database services such as RDS, DynamoDB, etc. Should be able to migrate any databases from anywhere to AWS using any third-party tools or AWS database migration tool. Should also have understanding or expertise in creating data warehouses and data lake solutions on AWS.
Your responsibilities will include:
Apply practical knowledge of relational database design and usage with customers
Perform workload analysis and undertake performance tuning, as well as performance benchmarking in customer environments.
To develop state of the art solutions which are technically sound.
To provide a high-quality service to the Enterprise Cloud Services clients i.t.o. consultancy, solutions and delivery.
Commitment to team success and positive team dynamics including mentoring of other team members.
Passion for growing and applying technical skills in service to customers.
Be a trusted infrastructure advisor by providing objective, practical and relevant ideas, insights and advice.
Work collaboratively with consulting partners and technology teams to ensure high quality of solution delivery.
Encourage best practice and knowledge sharing with partners and cross-functional groups
Manage the overall database design and delivery of solutions.
Ability to make recommendations as they pertain to improvements in support/development initiatives and facilitate implementation with partners and cross-functional groups within the Business.
Participate in high level database solution definition and design during the implementation phase with the goal of providing reliable, stable and operationally sound applications that meet the Business requirements.
Ability to understand and translate business requirements into technical specifications
The ideal candidate will have:
A minimum of 3 years of industry related experience of which 1 year must be within a complex hosting environment.
Certifications in Database design, system architecture or cloud technologies.
Demonstrate knowledge of database systems internals including storage layouts and distributed databases/MPP architectures
Advanced SQL coding, tuning and query optimization.
Experience designing and leading database performance benchmarks.
Good knowledge of the different AWS services
Knowledge of cloud networking architecture, cloud operations, security, automation and orchestration.
Knowledge of database internals as it relates to query and system performance and tuning.
Understanding of overall system architecture, scalability, reliability, and performance in a database environment.
Excellent teamwork, time-management and organizational skills.
Perform other duties as deemed necessary and assigned by the customer and management
Strong interpersonal skills and problem-solving abilities.
Excellent documentation, communication and interpersonal skills.
Excellent analytical and problem-solving abilities.
Closing date for applications: Monday, 13 April 2020

The base location for this role is Vodacom World, Midrand

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply.
Vodacom is committed to an organisational culture that recognises, appreciates and values diversity & inclusion.

Commitment from Vodacom

Vodacom is committed to attracting, developing and retaining the very best people by offering a flexible, motivating and inclusive workplace in which talent is truly recognized, developed and rewarded. We believe that diversity plays an important role in the success of our business and we are committed to creating an inclusive work environment which respects, values, celebrates and makes the most of people’s individual differences - we are not only multinational but multicultural too. At Vodacom you will have access to our excellent flexible benefits programme that you would expect from any global company.",3.9,"Vodafone
3.9",Midrand,-1,10000+ Employees,1982,Company - Public,"Cable, Internet & Telephone Providers",Telecommunications,$10+ billion (USD),-1
Data Engineer Azure Data Factory,-1,"Enthuzex is looking for a motivated Lead Data Engineer to contribute towards the success of our Data and Analytics Technology initiatives. This is a hands-on technical role and this person will be responsible for the development and build of scalable solutions as it relates to the architecture strategies, data standards, digital data management, data integration, tools, and technology. The right candidate will play a deep dive hands-on critical development role in the digital transformation and in shaping how we acquire, ingest, transform and deliver data through the digital consumer channels.

Responsibilities:

Architect, design, develop and engineering end-to-end data pipelines across multiple data sources and systems of record.
Ensure data quality, integrity, security and completeness throughout the data lifecycle
Develop, design data models, data structures and ETL jobs for data acquisition and manipulation purposes
Develop deep understanding of the data sources, implement data standards, maintain data quality and master data management
Developing data services and API
Work closely with the cloud service providers to ensure completeness and alignment with the service offerings
Manage and maintain cloud based data and analytics platform
Deep understanding of the cloud offerings and engage in quick proof of concepts and proof of value in prototyping data and analytics solutions and derive viability
Ability to interact with the business stakeholders to understand requirements and translating into technology solutions

Expirience:

Experience in Cloud platform AWS or Azure eco-system. (Azure preferred)
Data Engineering/Development experience with SQL (Oracle, SQL Server, MySQL)
Strong development background creating pipelines and complex data transformations and manipulations using one of the languages Python, Java, R, or Scala with Databricks/Spark
Experience in NoSQL Databases and Big data technologies including Hadoop
Experience with API / RESTful data services
Worked on real-time data capture, processing and storing using technologies like Azure Event Hubs and Analytics
Experience working with different data storage options including AWS S3, Azure BLOB storage etc.
Understanding of different data formats including Parquet, Avro, CSV, ORC etc.
Prior experience with MPP databases and maintain large amount of data processing
Experience with Azure Data Factory and Azure Data Catalog is a big plus and mandatory
Experience with Microsoft/Azure ETL solutions and business Intelligence technologies is a big and mandatory
Past working experience on a fast paced and agile environment
Perform ongoing monitoring, automation and refinement of data engineering solutions
Experience in leading high visibility transformation projects that interacts with multiple business lines
Build and meet project timelines and manage delivery commitments with proper communication to management

Qualifications

Bachelor’s degree with 4+ years of relevant experience
Willingness to learn new technologies and thrive in an extremely fast paced environment
Team player and easy to work with.

Applicants must demonstrate their ability to master new enterprise level technologies. Successful applicants will exemplify Enthuzex ethical principles of uncompromising integrity, respect for others, and accountability for decisions

send cv's info@enthuzex.co.za",-1,Enthuzex,Leslie,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Scientist,-1,"The world is changing.

We all want something different.

At Luno, we see you as an individual.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the world, and to do so, we need the best team on board for our mission.

A bit about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 3 million customers across 40 countries.
We are Series B funded, backed by Balderton Capital and the Naspers Group.
Our platform has processed over 8 billion dollars since we've launched
We're proud to be one of the world's most international cryptocurrency teams from 26 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
The role in a nutshell:

Identifying opportunities in the business that could benefit most from cognitive applications, as well as building and enhancing organisational capabilities for deriving value from multiple data sources using data science.

What we'd like you to have:
Bachelor's degree or higher in the natural sciences or technical fields such as Mathematics, Statistics, Computer Science, Engineering or Economics
Enthusiasm to work in the cryptocurrencies space
Advanced SQL skills
Solid understanding of exploratory data analysis, predictive analytics, and optimisation using Python, R, Matlab, RapidMiner, KNIME or other data science-oriented platforms
Proficiency in the use of data science and machine learning domain-specific languages such as ""Caret"" and the ""Tidyverse"" suite of tools in R, or ""Pandas"" in Python
Strong interpersonal and communication skills
Communicating data insights using storytelling narratives
Ability to work independently, as well as within and across teams
Ability to successfully complete projects with large and/or incomplete data sets
More about what you'll be doing:
Optimising product performance by tracking and analysing customer behaviour on web and app, in collaboration with software engineers and product designers
Providing the business with reports and dashboards, on key performance metrics
Developing metrics to accurately assess the health of our Exchange platform
Comparative data-driven analysis of our Exchange against alternative platforms
Formulating business requirements into analytical objectives
Designing and running experiments to test hypotheses
Hacking through complex business problems using advanced data analysis to provide insights and recommendations
Building, maintaining, and optimising decisioning systems using advanced statistical and predictive modelling techniques
What will set you apart:
An advanced degree in Mathematics, Statistics, Computer Science or related field
At least 3 years' experience working in a similar role
A basic understanding of trading in financial markets
Experience working with a data analytics and visualisation platform such as Tableau, Cognos, QlikView, or Looker
Familiarity with using Google Analytics to understand customer behaviour
Solid knowledge of statistical and machine learning techniques
Familiarity with modern distributed data storage and processing systems such as Amazon Redshift, Big Query, Snowflake, Databricks and Apache Spark
You can gather and synthesise facts, theories, trends, patterns, inferences, and key issues in complex and variable situations
Ability to diagnose problems using formal problem-solving tools and techniques from multiple angles to generate multiple possible solutions
A sense of anticipating long-term problem areas and associated risk levels with objective rationale
Remote Life at Luno

If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
You'll be able to continuously upskill yourself with access to free online learning via MyAcademy, an international teaching marketplace with over 100000 courses from Harvard and other leading providers + share knowledge with your peers.
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity and paternity leave, and you can even take paw-ternity leave for your furry friend.
Annual Inspiration Day! Make time for that pottery course or spa day you've always wanted to do.
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"EY is a global leader in
assurance, tax, transaction and advisory services. Technology is at the heart
of what we do and deliver at EY. Technology solutions are integrated in the
client services we deliver and are key to our innovation as an organization.

Fueled by
strategic investment in technology and innovation, Client Technology seeks to
drive growth opportunities and solve complex business problems for our clients
through building a robust platform for business and powerful product engine
that are vital to innovation at scale. As part of Client Technology, you’ll
work with technologists and business experts, blending EY’s deep industry
knowledge and innovative ideas with our platforms, capabilities, and technical
expertise. As a catalyst for change and growth, you’ll be at the forefront of
integrating emerging technologies from AI to Data Analytics into every corner
of what we do at EY. That means more growth for you, exciting learning
opportunities, career choices, and the chance to make a real impact.

The selected
candidate
Develops
large and complex data architecture, composed of models, policies, rules or
standards that govern which data is collected and how it is stored, arranged,
integrated and put to use in data systems, including the design, build and
management of data infrastructure to address business requirements
Creates
sound use case driven roadmaps, depicting data architecture as-is and to-be
capabilities with the business by engaging with multidisciplinary teams, and by
identifying, managing and mitigating risk
Develops
relationships across the business to understand data requirements, applies deep
technical knowledge of data management to solve business problems in areas
where solutions may not currently exist, necessitating new solutions/ways of
working/technologies and proactively articulating these to the business
Review,
identify the latest emerging technologies, augmenting by services from the
leading cloud providers to solution and recommend the best next generation data
platform value driven approach for our clients
Your Key Responsibilities Include
Create
and maintain conceptual, logical and physical database models
Document
functional requirements and system specifications into the data architecture
and detailed design specifications for current and proposed designs
Document
and adhere to development standards and best practices in database designs
Maintain
highly effective and consistent communication within the team, peers, and the
leadership team
Reverse
engineer SQL code and modify it to solve problems/issues
Contribute
to the definition and implementation of data governance practices
Design
both data structures and data integration practices
Work
closely with the infrastructure teams to create a physical environment to
support data services
Evaluate
new and existing (internal and external) technologies and services in support
of data services and data analytics objectives
Skills And Attributes For Success
Understanding
of business process reengineering and business modeling concepts, business
systems development and analysis
Hands-on
experience in designing and implementing hybrid cloud and on-prem solutions
Experience
working with the latest versions of SQL Server
Experience
applying SAFe/Scrum/Kanban methodologies
Ability
to exercise judgment in solving technical, operational, and organizational
challenges
Expert
programming, performance tuning and troubleshooting skills, using the latest
popular programming languages for example python
Demonstrate
proactive approach to identifying issues and presenting solutions and options,
and where appropriate, leading to resolution
Minimum Qualifications
5+ years
demonstratable work experience as a Data Architect using data modeling tools
2-3 years
SQL coding experience on large projects
Must
possess expert SQL programming, performance tuning and troubleshooting skills
Create
database objects and SQL scripts
Understand
and developed data pipelines
Know how
to deformalize data for data science models
Experience
in python, spark and notebooks
Experience
designing data warehousing solutions
Experience
designing next generation data platforms utilising cloud services
In-depth
understanding of database structure principles
Seamlessly
able to translate business requirements to technology requirements
What We Look For
Strong
analytical skills and problem-solving ability
A
self-starter, independent-thinker, curious and creative person with ambition
and passion
Excellent
inter-personal, communication, collaboration, and presentation skills
Customer
focused
Excellent
time management skills
Positive
and constructive minded
Takes
responsibility for continuous self-learning
Takes the
lead and makes decisions in critical times and tough circumstances
Attention
to detail
High
levels of integrity and honesty
Curious
about new emerging technology
About EY
As a global leader in assurance, tax, transaction and consulting
services, we’re using the finance products, expertise and systems we’ve
developed to build a better working world. That starts with a culture that
believes in giving you the training, opportunities and creative freedom to make
things better. Whenever you join, however long you stay, the exceptional EY
experience lasts a lifetime.",3.8,"EY
3.8",Johannesburg,-1,10000+ Employees,1989,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Architect - Principal,-1,"We are looking for Principle Data Architect to join our Engineering team in Cape Town.

The world is changing.
We all want something different.
At Luno, we see you as individuals.

Together, we are upgrading the world of work to unleash the potential within and empower you to become the best possible version of yourself.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the financial landscape, and to do so, well we need the best team on board for our mission. In short, to achieve our goals, we need rockstars. As simple as that.

A little about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 5 million customers across 40 countries.
We're part of the Digital Currency Group, a group of companies driving progress in the cryptocurrency and blockchain space that includes Grayscale, Genesis, Coindesk and Foundry Services
Our platform has processed over $8 billion to date
We're proud to be one of the world's most international cryptocurrency teams from 43 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
How we work


Our engineering team (currently ~100 engineers) is split into organisations which we call Fleets. Each Fleet focuses on a core customer journey (onboarding, security, payments, support, new business, growth and marketing etc.). Each of these fleets contains multiple smaller teams called Pods, each of which focuses on a specific aspect of the product.

Pods will include a product owner, product designer, back-end engineers, Android, iOS and Web developers, who each bring a unique perspective to the problem you are all contributing towards.

We're agile, use scrum, continuous integration and continuous delivery, deploying to production every single day.

We're building teams to help us succeed in our mission to upgrade the world to a better financial system. You'll be joining a group of highly motivated software engineers who you'll work collaboratively with across our pods.

As a fast-growing company with offices around the world, you'll immediately see how your contributions directly impact both our internal users and client experience. Many of the problems we are solving result in trail blazing solutions which can't be found on Stack Overflow; so we're looking for engineers who flourish working in a complex domain.

In your first six months, you will:


...start at Luno by learning our processes, meeting the wider team and starting our engineering on-boarding program. After getting comfortable with the basics, you'll start learning our idiomatic patterns in a safe, easy-to-follow way - by building your own toy micro services. You'll get to practice how we do design docs, code reviews, deployments, events, logging and monitoring.

You'll meet the Pod(s) you'll be working with and quickly align on the teams' current OKRs and product roadmap. We succeed as a team, so we will provide you with regular feedback from your manager and peers and will encourage you to do the same.

What you'll do:
Work closely with our data science and platform teams on projects introducing new streams of data into our data lake
You will get to bring new ideas on how to further develop and innovate our data solutions and how to expose that data to the business
Accountable and Responsible for the design and architecture of Data systems that are robust and scalable.
Work in an Agile/Scrum framework or Agile mindset
Data backup/recovery and storage
Pick-up and learn new concepts, in both engineering and product, and be able to apply that knowledge quickly.
The ideal candidate for this role will have:
7+ years' experience in maintaining scalable data solutions and/or you are passionate about it
Ability to understand, communicate and advocate between build vs buy
Proven track record of setting up, restructuring and maintenance of databases
You know your way around ETL and you have experience with SQL
Experience in the AWS Data stack (RedShift,DynamoDB, Amazon RDS)
Familiarity with integrating data stores with BI platforms such as Looker, Tableau, or Power BI
You have experience with the concepts of CI/CD
Coding skills in e.g. Go, Python
Bachelor's degree in a related field preferred
AWS Certified DataOps Administrator
Be friendly, transparent, articulate and driven to succeed
Basic knowledge of and passion for digital currencies like Bitcoin
A work permit for South Africa if you are not a South African citizen
Don't be put off if you don't tick all of the boxes – they're a guide based on what we'd love to see but we appreciate that excellent software engineers have diverse backgrounds.

Remote Life at Luno


If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity / paternity and even (yes, you are reading it correctly) paw-ternity for your furry friend..
Annual Inspiration Day.. like that pottery course you've always been meaning to do!
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. You'll need to hold the legal right to work in South Africa already as we cannot provide visa sponsorship.

Be part of the change!",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer - EC2 Capacity Data Analytics,-1,"EC2 Capacity Data Analytics (CDA) team is looking for a Data Engineer to join our team.

Our team is part of the EC2 Capacity Engineering organization, which is responsible for providing the elasticity EC2 customers need to scale up/down compute resources in a cost-efficient manner. We predict customer usage across thousands of configuration combinations to deliver exactly what our customers require in just the right amount of time with just the right amount of capacity.

As a Data Engineer, you will build the ETL and analytics solutions for our internal customers to answer questions with data and drive critical improvements for the business. You will use best practices in software engineering, data management, data storage, data compute, and distributed systems. On any given day, we use Python, Scala, Java, SQL, Lambda, CloudFormation, Redshift and Glue as well as other public AWS services and a host of Amazon internal tools. We dont expect you to be an expert in, or necessarily even be familiar with all of the technologies listed above, but we do expect you to be excited to learn about them.

This position involves on-call responsibilities, typically for one week every two months. Our team is dedicated to supporting new team members. We care about your career growth, we try to assign projects and tasks based on what will help each team member develop into a more well-rounded engineer and enable them to take on more complex tasks in the future.

Our team values work-life balance and we are flexible when people occasionally need to work from home.

Job Duties
Develop and maintain automated ETL pipelines for big data using languages such as Scala, Spark, SQL and AWS services such as S3, Glue, Lambda, SNS, SQS, KMS. Example: ETL jobs that process a continuous flow of JSON source files and output the data in a business-friendly Parquet format that can be efficiently queried via Redshift Spectrum using SQL to answer business question.

Develop and maintain automated ETL monitoring and alarming solutions using Java/Python/Scala, Spark, SQL, and AWS services such as CloudWatch and Lambda.

Implement and support reporting and analytics infrastructure for internal business customers using AWS, services such Athena, Redshift, Spectrum, EMR, and QuickSight.

Develop and maintain data security and permissions solutions for enterprise scale data warehouse and data lake implementations including data encryption and database user access controls and logging.

Develop and maintain data warehouse and data lake metadata, data catalog, and user documentation for internal business customers.

Develop, test, and deploy code using internal software development toolsets. This includes the code for deploying infrastructure and solutions for secure data storage, ETL pipelines, data catalog, and data query.


Basic Qualifications

· Bachelors degree in Computer Science or related technical field, or equivalent work experience.
· 4+ years of overall work experience including Software Engineering, Data Engineering, Database Engineering, Business Intelligence.
· Experience with AWS technologies stack including Lambda, Glue, Redshift, RDS, S3, EMR or similar big data solutions stack

Preferred Qualifications

· Demonstrate efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data.
· Demonstrable proficiency in distributed systems and data architecture; design and implementation of batch and stream data processing pipelines; knows how to optimize the distribution, partitioning, and MPP of high-level data structures.

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer,-1,"Our client based in Johannesburg is urgently looking for a Data Engineer to be on a 3 months contract
Build data pipelines, experience in new tech like nifi, kafka, python

Joburg based, open to EE, 3 month contract with the option to extend, must be available at short notice",-1,EQplus,Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Overview
Job ID: 51456
Job Sector: Information Technology and Services
Country: South Africa
Region/State/Province/District: Gauteng
Location: Johannesburg

Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose

This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes

Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems

Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions

Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.
Research and best practices

Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development

Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.

Preferred Qualification and Experience

Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry

Knowledge/Technical Skills/Expertise

Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision

PLEASE NOTE: All our recruitment and selection processes comply with applicable local laws and regulations. We will never ask for money or any form of payment as part of our recruitment process. If you experience this, please contact our Fraudline on +27 800222050 or forward to TransactionFraudOpsSA@standardbank.co.za",4.1,"Standard Bank
4.1",Johannesburg,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"About us

At PBT Group we pride ourselves on being a Data Specialist organisation. With 20 years of experience in 27 countries over 3 continents, our team of 550 consultants have implemented more than 700 projects.",4.3,"PBT Group
4.3",Johannesburg,-1,Unknown,-1,Company - Private,Accounting,Accounting & Legal,Less than $1 million (USD),-1
Data Engineer,-1,"Kick-start your career in the online gaming world and experience the very latest in technology and innovation.

The Department:

Our mission is to provide our customers with the best online betting experience and share the thrill of gaming with them. Data is at the very heart of our business and is vital in everything we do.

Our cross-functional Data team has a big and exciting challenge ahead. We are in the process of re-platforming our traditional, on-premises RDBMS environment to a new microservice architecture in the cloud. We’re making use of the diverse set of data technologies in Microsoft Azure to offer new services, reporting structures and real-time data pipeline while serving the day-to-day requirements of a rapidly growing, data-hungry organisation.

Purpose of the Role:

This is an excellent opportunity for an individual who is looking to gain new skills. We are committed to creating a culture of learning and regularly run proof of concepts, provide internal demos, manage workshops and attend external conferences. Our data team has a wide range of skills including development for highly transactional RDBMS systems, data warehousing, data science and cloud technologies and we are always working to raise everyone’s game.

Duties include, but not limited to:

Work as part of an agile Data Engineering Team
Development of greenfield projects in Azure
Develop and maintain on-premises RDBMS/DW systems
Create robust ETL services and real-time data pipelines
Build and maintain Continuous Integration and DevOps pipelines
Test-driven development and pair programming with colleagues

Essential Criteria:

C#, .Net, Visual Studio
Git, Azure DevOps
NoSQL development (CosmosDB)
Demonstrable understanding of MS SQL Server in a highly transactional environment
Demonstrable understanding of development in Microsoft Azure
Able to understand query plans and identify performance bottlenecks
Test/Business-Driven Development
Building Continuous Integration/Deployment pipelines
Communicate effectively with both technical and non-technical stakeholders

Desirable Criteria:

Implementing Data Storage and Processing solutions in Azure (ARM Templates, Storage Accounts, Data Lake Storage, SQL DB, Cosmos DB, EventHubs, Function Apps, Log Analytics, Data Factory, Databricks, Polybase)
Implementing Security, Disaster Recovery, High Availability, Auditing, Monitoring and Alerting solutions in Azure
Automating tasks in Azure using Powershell / CLI
Predicting costs and optimizing spending in Azure
Message Queues (RabbitMQ, Kafka)
Python

Person Specifications:

Resilience
Teamwork
Technical Knowledge
Communication skills
Stress Tolerance
Please note we will apply relevance to our Talent Management and Talent Development Programme as part of our recruitment process.
Shortlisted candidates may need to complete an assessment.
This position requires trust and honesty it has access to customers financial details - therefore a credit and criminal record check will be conducted. The qualifications identified herein are an inherent job requirement; therefore, a qualification verification check will be done. By applying for this role, and supplying the necessary details, you hereby grant us permission to apply for these checks. This will be done in a confidential manner, and solely for the purposes of verification.

To view all current vacancies, please visit our website, www.digioutsource.com

Should you not hear from us within 2 weeks, please deem your application as unsuccessful.

The perfect place to work, play and grow!",3.9,"Digital Outsource Services
3.9",Cape Town,-1,1001 to 5000 Employees,1997,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
Data Engineer,-1,"At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes

Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.

Key Responsibilities

Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.

Key Traits

Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern

Position Requirements

2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.

Where will you work? This role will be based out of Durbanville, South Africa.",3.1,"Aculocity, LLC
3.1",Durbanville,-1,1 to 50 Employees,2006,Company - Private,IT Services,Information Technology,$1 to $5 million (USD),-1
Data Engineer,-1,"ENVIRONMENT:

A rapidly growing E-Commerce Platform seeks a highly talented Data Engineer to make an invaluable contribution to data democratisation and literacy vision by making accessible and easy-to-use data products and tools. You will require a Comp-Sci Degree or 3 years’ relevant industry experience, MySQL, PostgreSQL, Java, Python, in-depth understanding of OLAP, Data Marts, Star Scheme, Snowflake, be familiar with Jenkins, Travis, Circle CI, Docker, Kubernetes, experience with Kafka, Pub/Sub, Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks & significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing & Data Lake design and implementation and Lambda/Kappa architectures.

DUTIES:

Design, develop, test and maintain data architecture.

Prepare data for descriptive, predictive and prescriptive modelling.

Automate repetitive tasks and manual processes related with the data usage.

Optimize data delivery.

Design, develop and test large stream data pipelines to ingest, aggregate, clean, and distribute data models ready for analysis.

Ensure the highest standard in data integrity.

Leverage best practices in continuous integration and delivery.

Collaborate with other engineers, ML experts, analysts, and stakeholders to produce the most efficient and valuable solutions.

Implement features, technology, and processes that move us towards industry best practices, improving on scalability, efficiency, reliability, and security.

Operations and ownership of systems in production, responding to incidents.

REQUIREMENTS:

Qualifications –

Comp-Sci Degree or 3 years relevant industry experience.

Experience/Skills –

Open source relational database systems e.g. MySQL, PostgreSQL, etc.

Significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing, and Data Lake design and implementation and Lambda/Kappa architectures.

A thorough understanding of database and data warehousing principles e.g. OLAP, Data Marts, Star Schema, Snowflake, etc.

Java and Python.

Familiar with CI/CD tools such as Jenkins, Travis, Circle CI, etc.

Experience with Kafka, Pub/Sub, or other event-based systems.

Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks, etc.

Working in cloud environments and with containerisation frameworks, tools and platforms e.g. Docker, Kubernetes, GKE, etc.

A deep understanding of data pipelining, streaming, and Big Data technologies, methods, patterns, and techniques.

Troubleshooting complex database operations and performance issues.

Automating tasks using Shell Scripting or writing small applications.

ATTRIBUTES:

Works well with people and is passionate about helping people be their best.

A team player, an active listener, mentor, and able to communicate well.

Shows solid reasoning and decision making, with the ability to work under pressure.

Is passionate about technology, systems and data.

Is curious, always learning, and keeping up to date with the industry.

While we would really like to respond to every application, should you not be contacted for this position within 10 working days please consider your application unsuccessful.

COMMENTS:

When applying for jobs, ensure that you have the minimum job requirements. Only SA Citizens will be considered for this role. If you are not in the mentioned location of any of the jobs, please note your relocation plans in all applications for jobs and correspondence.",-1,Datafin IT Recruitment,Cape Town,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Cartrack is looking for passionate data science and engineering candidates that can join a growing team that is responsible for the intelligence and efficiency solution provision to over a million subscribers, many of whom are large fleets. We are in the midst of creating revolutionary platforms that will change the way that people interact with their vehicles.

You will have the opportunity to work with the very brightest global subject matter experts that are transforming the automotive industry across Fleet Management, Asset Management and Insurance Telematics solutions.

Get to know the role:

The role of a data engineer is a supporting one, but it is also an extremely vital one. As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements. We want to see candidates with mechanical tendencies and a desire to know how things work and to improve them.

The day-to-day activities:

Design, construct, install, test and maintain data management systems.
Build high-performance algorithms, predictive models, and prototypes.
Ensure that all systems meet the business/company requirements as well as industry practices.
Integrate up-and-coming data management and software engineering technologies into existing data structures.
Develop set processes for data mining, data modeling, and data production.
Create custom software components and analytics applications.
Research new uses for existing data.
Employ an array of technological languages and tools to connect systems together.
Install/update disaster recovery procedures.
Recommend different ways to constantly improve data reliability and quality.
Work on and maintain Data pipelines.

Requirements Essential:

At least 5 years’ proven experience as a Data Engineer, DevOps Engineer, Software Developer, or similar.
Proficient in Linux/Unix and shell scripting as well as in functional programming languages.
Expertise in setting up and explored with technologies such as Hadoop and Spark.
Bachelor’s degree in computer science, software/computer engineering, applied mathematics, or physics.",3.3,"Cartrack
3.3",Johannesburg,-1,501 to 1000 Employees,2004,Company - Private,Security Services,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Data Engineer,-1,"Data Engineers build and support data pipelines and datamarts built off those pipelines. Both must be scalable, repeatable and secure. The Data Engineer helps to facilitate gathering data from a variety of different sources, in the correct format, assuring that it conforms to data quality standards and assuring that downstream users can get to that data timeously. This role functions as a core member of an agile team. These professionals are responsible for the infrastructure that provides insights from raw data, handling and integrating diverse sources of data seamlessly. They enable solutions, by handling large volumes of data in batch and real-time by leveraging emerging technologies from both the big data and cloud spaces. Additional responsibilities include developing proof of concepts and implements complex big data solutions with a focus on collecting, parsing, managing, analysing and visualising large datasets. They know how to apply technologies to solve the problems of working with large volumes of data in diverse formats to deliver innovative solutions. Data Engineering is a technical job that requires substantial expertise in a broad range of software development and programming fields. These professionals have a knowledge of data analysis, end user requirements and business requirements analysis to develop a clear understanding of the business need and to incorporate these needs into a technical solution. They have a solid understanding of physical database design and the systems development lifecycle. This role must work well in a team environment.

Job Objectives

Work Complexity: * Architects Data analytics framework. * Translates complex functional and technical requirements into detailed architecture, design, and high performing software. * Leads Data and batch/real-time analytical solutions leveraging transformational technologies. * Works on multiple projects as a technical lead driving user story analysis and elaboration, design and development of software applications, testing, and builds automation tools.

Main Job Objectives: 1. Development and Operations 2. Database Development and Operations 3. Policies, Standards and Procedures 4. Communications 5. Business Continuity & Disaster Recovery 6. Research and Evaluation 7. Coaching/ Mentoring

Qualifications

Essential: 4 years Bachelors degree in computer science, computer engineering, or equivalent work experience AWS Certification at least to associate level

Experience

Essential:

5+ years Data engineering or software engineering

3-5 years demonstrated experience leading teams of engineers

2+ years Big Data experience

5+ years experience with Extract Transform and Load (ETL) processes

2+ years Could AWS experience

At least 2 years demonstrated experience with agile or other rapid application development methods - Agile exposure, Kanban or Scrum

5 years demonstrated experience with object oriented design, coding and testing patterns as well as experience in engineering (commercial or open source) software platforms and large scale data infrastructures.

Desirable:

5+ years Retail Operations experience

Knowledge and Skills

Essential: *Creating data feeds from on-premise to AWS Cloud (2 years) *Support data feeds in production on break fix basis (2 years) *Creating data marts using Talend or similar ETL development tool (4 years) *Manipulating data using python and pyspark (2 years) *Processing data using the Hadoop paradigm particularly using EMR, AWSs distribution of Hadoop (2 years) *Devop for Big Data and Business Intelligence including automated testing and deployment (2 years) * Extensive knowledge in different programming or scripting languages * Expert knowledge of data modeling and understanding of different data structures and their benefits and limitations under particular use cases.

Further technical skills required: * Capability to architect highly scalable distributed systems, using different open source tools. * Big Data batch and streaming tools * Talend (1 year) * AWS: EMR, EC2, S3 (1 year) * Python (1 year) * PySpark or Spark (1 year) - Desirable * Business Intelligence Data modelling (3 years) * SQL (3 years)",-1,Datonomy Solutions,Brackenfell,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We are assisting one of our clients that is based in Pretoria to fill a role of a Data Engineer

This is a 12 month contract role

Objective of this Scope of Work

The Data Engineer will drive improvement of the data management maturity levels and provide the necessary technical support within the company to support reliable and effective decision-making, appropriate usage and protection thereof.

Scope of Services Definition

The scope will include but will not be limited to:

ï†· To develop, construct, test and maintain architectures.

ï†· To ensure architectures will support the requirements of business.

ï†· To discover opportunities for data acquisition and sharing.

ï†· To develop data set processes for data modelling, mining and production.

ï†· To employ a variety of languages and tools to marry systems together.

ï†· To recommend way to improve data reliability, efficiency and quality.

ï†· To prepare data for use in predictive and prescriptive modelling.

ï†· To conduct research to answer industry and business questions.

ï†· To leverage volumes of data from internal and external to answer business questions.

ï†· To develop and manage stakeholder relations effectively to promote data management across the organisation and support reliable decision making and appropriate data usage.

ï†· To participate and provide technical support in cross organisational activities relating to any of the above mentioned data management activities.

ï†· To provide regular progress reports as per stakeholder requirements and present data management updates in various forums as required.

Minimum qualification Required:

ï†· A minimum of a Bachelors degree in Computer Science or Information Management OR equivalent;

ï†· A minimum of five to eight years experience in a data management environment",-1,HR Genie,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Our client based in the Northern Suburbs, is currently looking for a Data Engineer to join their team.

Responsibilities
Our client is a dynamic IT company that delivers value-driven IT solutions to the group. Our work lives revolve around our DNA. We take pride in our work, treat our colleagues, partners and our country with respect. We exercise collaborative decision-making and believe in having a balance in life. We do this all while having fun and enjoying what we do.

The primary focus of this position is to use technical skills to put software, systems and data together in a way that extracts meaningful insights from raw data. You will need to be helpful and supportive to your team and fellow developers. You join an energetic, focused and dynamic team.

Interact with clients to understand requirements and business problems/needs

Identify, analyse, visualise and understand supporting data to propose solid solutions

Create technical documentation for reference and reporting

Support existing solutions within GCP and Oracle

Doing standby on a rotating basis

Key Competencies and Qualifications

Matric

Tertiary qualification in IT

Preferred cloud experience in AWS/AZURE/GCP

At least 3 years of data warehouse ETL experience

Dimensional Modelling

Data analyses

Experience with data visualization and visualization tool(s)

Knowledge of the retail industry will be beneficial

Understanding and experience with version control SVN/GIT

Preferred – Korn shell scripting, Python/Java, SQL

Google Cloud Platform experience would be looked upon favourably

Having a broad understanding of different SDLC’s

Preferred agile experience

Strengths

The natural tendency to take ownership and responsibility

Strong problem solving, critical thinking, effective planning and organisational skills

Detail-oriented with excellent communication skills

You have a can-do attitude and positive outlook on life

Can cope under pressure

Curious and interested in analysing problems and possible solutions

Strong team player

Self-driven learner, passionate about new technology

Above all, be passionate about what you do

Should you wish to apply for the position, please apply directly via this job board, please ensure that you quote reference number 201620 subject heading or email body.

Please note that due to the high volume of CV's received; only shortlisted applicants will be contacted. Should you not receive communication from our offices within two weeks of submission please note that your application will not be considered for this position.

We will keep your CV on file and re-establish contact with you should opportunities in line with your expertise become available again.

Should you require any additional information give us a call on 021 012 5566.",-1,Surgo HR & Training,Cape Town,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We believe that our employees fuel our organization, essential to enable us to help our customers overcome their business challenges and achieve sustainable growth. As a result, we are committed to growing each individual and providing them with the challenges, feedback and support needed to achieve success in their career

If this sounds appealing, and like us, you get excited about data: its collection, storage, transformation or display, see if you’ve got what it takes to join our sought after DATA team.

Key Responsibilities And/or Outputs

You will represent IQbusiness at our customers, sometimes alone, and sometimes as part of an IQ team.

Providing a superior customer experience by building and maintaining relationships, working at customer offices, keeping data confidential
Design and develop – databases, SQL queries, stored procedures, reports, dashboards or integration solutions
Produce solutions for both real-time and batch environments
Test your work to ensure compliance
Solve problems, and do root cause analysis
Prioritize your workload
Assist in other areas relating to your true data function, such as data modeling, data and business analysts
Interact with a variety of individuals: senior, junior, technical and from business
Provide guidance to fellow colleagues, or even manage a team
Uphold the IQ values, which are to care, learn & share; innovate; deliver as well as to build, enhance and maintain relationships

Education

Matric pass
A tertiary qualification, preferably in an ICT relevant field
Appropriate Microsoft certifications are beneficial but not required

Requirements

3 - 6 years experience in the Data Engineering environments and technologies
Great communication skills
A passion for SQL, databases or reports
Can you write stored procedures, design complex queries and create views and triggers?
Are you able to work out the relationships in a data warehouse or the aggregation of a cube?
Do you extract and display useful information when you see patterns and trends in data?
Strong knowledge of the financial services industry, ideally in a consulting role
The use of data related software: databases, ETL and BI tools; report writing and analytical tools
We use a lot of Microsoft products. You may often be expected to use MS SQL Server, SSIS, SSRS, SSAS and Power BI to develop solutions
What other relevant software have you’ve used?
Ability to work in different project methodologies: Waterfall and/or Agile
Knowledge of full SDLC
Exposure to logical and physical data modeling

Equal Employment Opportunity

IQbusiness is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, citizenship, marital, domestic or civil partnership status, sexual orientation, or gender identity",3.7,"IQbusiness South Africa
3.7",Johannesburg,-1,1 to 50 Employees,-1,Company - Private,Consulting,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"We value a data engineer as someone who works behind the scenes to obtain, process and supply data via various methodologies and technologies, to various consumers, in ways and forms that makes sense and add value. This definition is very broad, as the field of data engineering is just as broad.

You may be the type of data engineer that develops API endpoints for the consumption of data by end users or even another data pipeline, or you may be the type of data engineer that develops highly distributed, high availability data processing pipelines in an effort to satisfy the need of the ever questioning data analysts and/or data scientists.

You have awesome knowledge about the following concepts
Data modelling
Relational data modelling in traditional relational database management systems. (Microsoft SQL Server, MySQL, PostgreSQL, etc)
Coercing unstructured and semi-structured data into a structured form.
Data pipelining knowledge - data extraction and transformation.
Data transformation knowledge for reporting and analytics purposes.
Knowledge of the MapReduce and related data processing paradigms would be a boon.
You have the following technical competencies
Writing SQL queries, that can relate, transform and aggregate data from many differing sources where natural keys may or may not exist.
Experience with writing data pipelines that move and transform data, for various uses.
Working knowledge of a general purpose programming language like Python would be a boost.
Working knowledge of columnar databases such as Google BigQuery, and SAP HANA would be a boost.
Working knowledge of highly distributed technologies such as Apache Hadoop or Apache Spark would be a boost.
Working knowledge of NoSQL technologies, such as Apache Solr would be a boost.
You have the following personal competencies
The ability to solve problems.
The ability to rotate around a problem, to see if solutions can be gained in different ways.
The ability to work in an ever changing, unstructured environment.
The ability to work as part of a team, with vastly differing skill sets and opinions.
The ability to contribute ideas to the quorum.
The ability to mentor and provide guidance for other team members.
A systems approach to thinking, as opposed to a siloed approach. The candidate needs to understand how their work affects the greater system.
The ability to work without supervision, and take accountability for the work they deliver.
The ability to liaise with a client, sifting through the fluff and extracting the actual requirements.
If this is you - apply now and we'll get in touch",-1,DotModus,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Data Engineer

Our client in the contact centre space is currently seeking a DATA ENGINEER that will work on the collecting, storing, processing, and analyzing of large datasets. The primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them. You will also be responsible for integrating them with the architecture used across the company.

Key Performance Areas:

Data reporting.
Implementing ETL processes.
Defining data retention policies.
Management of Customer Lead data.
Provision of data for advanced analytics.
Maintenance of internal client scorecards.
Assist team in resolving data-related support queries.
Optimize existing data processes through automation.
Assist with all data-related reporting and documentation.
Maintenance and optimisation of the Analytics database.
Provide technical support to and supervision of junior data administrators.
Continuous upskilling on new technologies, frameworks and market trends.
Monitoring performance and advising any necessary infrastructure changes.
Identifying, selecting and integrating any Big Data tools and frameworks required to provide real-time analytics.

Educational Requirements

IT related Degree or Diploma is a pre-requisite

Required Skills/Experience

ETL tools: Advanced SSIS
BI/Reporting : Qlikview/Power BI/ SSRS or SSAS
Programming languages: JAVA, C# , Python, SAS or R
Experience with NoSQL databases and/or campaign management tools will be advantageous.
Minimum 3 years’ applicable work experience in SQL, relational databases and data manipulation.
Experience in big data platforms (eg. Hadoop) or processing frameworks (eg. MapReduce/Spark) and querying tools (eg. Pig, Hive and Impala) will be highly beneficial.

Preferred Skills

Organizational skills
Experience in Attentional to detail.
Accountability is critical for this role.
Ability to work under pressure and meet deadlines.
Solid understanding of database design principles.
Should you not receive a response in 2 weeks please consider your application unsuccessful",-1,Rubik's Cubed Consulting,Durban,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"This well known company is looking for a Data Engineer. will be based in Rivonia
The ideal candidate will have strong experience in the following:
Data cleaning
SQL Export
Big data Sets

BSc Degree in Maths and Stats will be required
a min of 3 years experience.
Stable track record is required.

Send your Cv to marinda@prrrecruitment.co.za",-1,PRR Recruitment Services,Johannesburg,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Description

Position at Aculocity, LLC

At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes
Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.
Key Responsibilities
Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.
Key Traits
Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern
Position Requirements
2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.
Where will you work? This role will be based out of Durbanville, South Africa.",-1,GVW,Durbanville,-1,Unknown,-1,Unknown,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Information Technology, Gauteng JHB - Northern Suburbs

Market related - Market related Annually

An IT Consultancy Business based in Johannesburg is currently looking for a Business Intelligence Consultant / Data Engineering Consultant.

Requirements:

Extensive experience in data engineering
Experience in Business Intelligence, data and Power BI
Extensive experience in data governance and the Popi act
Ability to assess and make recommendations on data within the Popi act
Good understanding of T-SQL and query optimization, developing ETL strategies.
Good understanding with SQL Server 2008/2012, SSIS, SSRS and SSAS
Use SSIS to create ETL packages to validate, extract, transform, and load data into the data warehouse and data marts.
Deploy and configured the reports in the Report Server (SSRS).
Excellent experience in Tabular Modelling , PowerView, Qlikvie,w, and Power BI
Maintain ETL
Qlikview model
Create Drill-through, Drill-down, and Cross Tab Reports and Sub-Report using Report Definition Language (RDL).
Generate periodic reports based on the statistical analysis of the data using SQL Server Reporting Services (SSRS)
Advise and provide written technical documentation and recommendations

The information displayed above is not limited to advertisements. Please contact Thato for further information.

Please consider your application as unsuccessful if you have not received a response within 14 days of submitting your application. However, please keep a lookout on our website, www.bedifferent.co.za, for available positions that you may be suited for

Ad Visible Until: 29 October 2020
Ref: JHB005346/NL

Vacancy Type: Permanent",2.9,"Be Different Recruitment
2.9",Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Cloud Support Engineer (Big Data),-1,"ABOUT US

Amazon Web Services is the market leader and technology forerunner in the Cloud business. As a member of the AWS Support team you will be at the forefront of this transformational technology, assisting a global list of companies and developers that are taking advantage of a growing set of services and features to run their mission-critical applications. As a Cloud Support Engineer, you will act as the Cloud Ambassador across all the cloud products, arming our customers with required tools & tactics to get the most out of their Product and Support investment.

Would you like to use the latest cloud computing technologies? Do you have an interest in helping customers understand application architectures and integration approaches? Are you familiar with best practices for applications, servers and networks? Do you want to be part of a customer facing technology team helping to ensure the success of Amazon Web Services (AWS) as a leading technology organization?

If you fit the description, you might be the person we are looking for! We are a group of smart people, passionate about cloud computing, and believe that world class support is critical to customer success.

WHAT CAN YOU EXPECT FROM A LIFE AT AWS?

Every day will bring new and exciting challenges on the job while you:

· Learn and use groundbreaking technologies.
· Apply advanced troubleshooting techniques to provide unique solutions to our customers' individual needs.
· Interact with leading engineers around the world.
· Partner with Amazon Web Services teams to help reproduce and resolve customer issues.
· Leverage your extensive customer support experience to provide feedback to internal AWS teams on how to improve our services.
· Drive customer communication during critical events.
· Drive projects that improve support-related processes and our customers technical support experience.
· Write tutorials, how-to videos, and other technical articles for the developer community.
· Work on critical, highly complex customer problems that may span multiple AWS services.

WHY AWS SUPPORT?

· First and foremost this is a customer support role in The Cloud.
· On a typical day, a Support Engineer will be primarily responsible for solving customers cases through a variety of customer contact channels which include telephone, email, and web/live chat. You will apply advanced troubleshooting techniques to provide tailored solutions for our customers and drive customer interactions by thoughtfully working with customers to dive deep into the root cause of an issue.
· Apart from working on a broad spectrum of technical issues, an AWS Support Engineer may also coach/mentor new hires, develop & present training, partner with development teams on complex issues or contact deflection initiatives, participate in new hiring, write tools/script to help the team, or work with leadership on process improvement and strategic initiatives.
· Career development: We promote advancement opportunities across the organization to help you meet your career goals.
· Training: We have training programs to help you develop the skills required to be successful in your role.
· We hire smart people who are keen to build a career with AWS, so we are more interested in the areas that you do know instead of those you havent been exposed to yet.
· Support engineers interested in travel have presented training or participated in focused summits across our sites or at specific AWS events.
· As we operate on a follow-the-sun model, with Premium Support sites located globally, there is no after hours on-call or mandated overtime in this role.
· https://www.youtube.com/watch?v=GC3bWcFFZTo&t=24s



Basic Qualifications

The Big Data role supports our services that leverage data and produce business insights, which may include using Machine Learning/Artificial Intelligence (ML/AI). Helping our customers use and integrate Big Data services in what is arguably our industrys most exciting space. The portfolio of services covers EMR (Hadoop), DynamoDB (NoSQL), MangoDB, and Apache Cassandra.

· Advanced experience in Apache Hadoop, Apache Spark, Apache Hive, and Presto
· Advanced experience in DynamoDB or NoSQL technologies like MongoDB or Cassandra
· Advanced experience with System Administration with Linux (RHEL/CentOS) including Microsoft Active Directory, and LDAP integration.
· Experience with troubleshooting Kerberos Authentication problems.
· Experience with Network troubleshooting.
· Basic understanding of Machine Learning and statistics
· Experience with Java and Python and shell scripting
· Bachelors degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position



Preferred Qualifications

· Expert experience in the Hadoop Ecosystem including Apache Spark and Presto
· Expert experience in NoSQL
· Expert experience with blockchain technologies like Etherium Expert experience in data Data Lake architecture and administration
· Experience managing full application stacks from the OS up through custom applications
· Prior work experience with AWS - any or all of EC2, VPC, S3, RDS, EMR, Glue, SageMaker
· Excellent knowledge of Hadoop architecture, administration and support
· Expert understanding of distributed computing principles and their application in the cloud
· Good understanding of distributed computing environments Lead technical discussions on big data systems architecture and design
· Strong analysis and troubleshooting skills and experience
· AWS Certified Solutions Architect
· AWS certified Big Data Specialty
· Masters degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity and Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Response Center Engineer,-1,"Job Title
Response Center Engineer
Job Description


Philips is a world leading health technology company with a vision to make life better for people worldwide through meaningful innovation. Making good on this promise depends on our passionate, inspirational, collaborative and diverse team. We have over 80,000+ brilliant people around the world but are always looking for more. Like-minded, motivated, focused minds to join us in creating a healthier, more connected society while transforming themselves personally and professionally.

As a CCC Coordinator - Response Center Engineer you will have the opportunity to process customer calls and be responsible for screening and diagnosing professionally Healthcare equipment to support customers and colleagues remotely with solving technical issues and ensuring maximum customer satisfaction

You are responsible for:
Diagnose healthcare equipment to the quality standards set by Philips Healthcare (PH) remotely by interviewing customers or colleagues by telephone or by remotely logging in to the system
Advise Customer Care Center Coordinators and District Operations Managers and / or Team Leads about the best follow-up w.r.t. technical state of the diagnosed healthcare equipment
Advise the Customer Care Center Coordinators or Field Services Engineers about required spare parts and resources
Responsible for planning engineers related to Modality responsibility.
Responsible for coordination between CCC, CUSTOMER, Spare parts AND Engineer.
Responsible to drive Remote and FTR KPI’s to targets respectively 40% and 85%.
Will require minimal field work to keep abreast of technical capabilities.
Take calls from customers and make sure they are processed in the CCC ERP on timely manner including all relevant data
Support Field Services Engineers in the field with technical knowledge
Escalate technical issues to the Technical Support Specialist
Escalate technical issues to Business Unit support after consultation of the Technical Support Specialist
Monitor critical functions of the equipment’s in the IB and environmental conditions including RSN and True reachability.
Lead the planning and implementation of FSN’s and FCO’s accelerating remote implementation where applicable.
Submit timely and accurate service data, job sheets, reports, expense claims, radiation film badges, field problem reports and other paperwork as assigned
Keep abreast of new technologies likely to affect PH range of products
Use company property with care to ensure optimal results with minimal operational costs
Be a professional representative for PH with respect to customer problems, ensuring personal acceptability by the customer in behavior in accordance with PH policy and targets
Conform to PH safety standards including health and safety regulations and in the event of hazards or accidents to take immediate control of the situation and involve the Operations Manager and / or the responsible person to handle properly confidential issues according Philips standards and to act according General Business Principals
Follow all quality standards within the frame of valid PH business policies
Follow the company quality regulations (ISO 9001; PQA; TQM) and internal directives and procedures
You are a part of the dynamic South Africa Customer Care Centre Team .You will be reporting to the Customer Care Center Manager.

Requires a pleasant, assertive individual you can work very well in a team setting, a dynamic environment that requires flexibility and creativeness to achieve goals.

To succeed in this role, you should have the following skills and experience:
Degree level education or equivalent
Experience in maintenance and troubleshooting of technical complex systems
Fluent in English, verbal and written in addition to local language
In return, we offer you the unique combination of a critical and challenging role and a creative and empowering office environment. You will be actively encouraged to make improvements, establish best in class service and have a direct impact on the success of Philips on a daily basis.

Employment Equity

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply. Only apply for this role if you are a South African Citizen by birth or Naturalization prior to the 27 April 1994.

Why should you join Philips?

Working at Philips is more than a job. It’s a calling to create a healthier society through meaningful work, focused on improving 3 billion lives a year by delivering innovative solutions across the health continuum. Our people experience a variety of unexpected moments when their lives and careers come together in meaningful ways. Learn more by watching this video.

To find out more about what it’s like working for Philips at a personal level, visit the Working at Philips page on our career website, where you can read stories from our employee blog. Once there, you can also learn about our recruitment process, or find answers to some of the frequently asked questions.

Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.9,"Philips
3.9",Johannesburg,-1,10000+ Employees,1891,Company - Public,Health Care Services & Hospitals,Health Care,$10 to $25 million (USD),-1
Software Development Engineer - EC2 Placement,-1,"Build the systems that optimize how EC2 matches requests for Instances with the underlying compute capacity. EC2 Placement is seeking talented engineers to build the online and offline optimization systems for compute workload scheduling, and the customer capabilities to better manage those workloads. Amazon EC2 provides on-demand scalable compute capacity, and powers some of the largest services in the world. You will collaborate with a top-tier community of engineers to build systems to improve how customers are able to access EC2 compute resources.

The successful candidate will have strong software engineering experience, with a passion for thinking about, building and testing distributed systems. You have an interest in how Machine Learning and other optimization techniques can be applied to large-scale problems. You have demonstrated experience working with a team to design, build and operate large-scale systems. With strong engineering fundamentals, an analytical and data-driven approach to your work, and strong communication skills, you have the ability to collaborate well to deliver results. We move fast and work together on small teams to solve big problems.

If this opportunity sounds interesting, we would love to talk to you more about our work and the vibrant culture at AWS in Cape Town.

Basic Qualifications

· Degree in Computer Science or related field, or equivalent working experience
· 3+ years of industry experience in a software development environment
· Strong Computer Science fundamentals, including data structures, object-oriented design, algorithm design, problem solving, and complexity analysis.
· Proficiency in at least one modern programming language, such as Java, C#, Python, Scala, Kotlin

Preferred Qualifications

One or more of the following help you stand out:
· Demonstrated results designing, building and operating high-performance distributed systems in large-scale Linux environments
· Role model in writing high-quality, maintainable and secure code, mentoring others, and helping teams sharpen their development processes
· Ability to work effectively across teams to deliver results, with strong verbal and written communication skills
· Experience working with machine learning systems

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer - PBB IT,-1,"Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose


This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes
Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems
Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions
Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.

Research and best practices
Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development
Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.
Preferred Qualification and Experience
Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Aws Data Platform Engineer,-1,"Aws Data Platform Engineer

Posting Country:

South Africa

Date Posted:

15-Oct-2020

Full Time / Part Time:

Full Time

Contract Type:

Permanent

Joining Vodacom is more than a job, what we do matters. We don’t just carry minutes, texts and data – we carry people’s lives. And that’s a huge responsibility. If you think for a minute about the people you rely on…the likelihood is they rely on us.

Customers are at the heart of everything we do and we want to make a difference to the lives of our customers, and the communities in which we live and work. We support our people to give something back to the causes that mean the most to them through helping them give time and money to the charities they love.

And what’s it like to work here? We have created an environment where you can look forward to coming to work and are empowered to be at your best. We offer flexibility in how you work that helps you do your job in a way that suits you, opportunities to help you grow and progress throughout your career and a choice of benefits to suit your lifestyle.

Role Purpose
The H Band AWS Data Platform Engineer position is based within the Technology Business Unit.

The AWS Data Platform Engineer will be responsible for all Database services such as RDS, DynamoDB, etc. Should be able to migrate any databases from anywhere to AWS using any third-party tools or AWS database migration tool. Should also have understanding or expertise in creating data warehouses and data lake solutions on AWS.
Your responsibilities will include:
Apply practical knowledge of relational database design and usage with customers
Perform workload analysis and undertake performance tuning, as well as performance benchmarking in customer environments.
To develop state of the art solutions which are technically sound.
To provide a high-quality service to the Enterprise Cloud Services clients i.t.o. consultancy, solutions and delivery.
Commitment to team success and positive team dynamics including mentoring of other team members.
Passion for growing and applying technical skills in service to customers.
Be a trusted infrastructure advisor by providing objective, practical and relevant ideas, insights and advice.
Work collaboratively with consulting partners and technology teams to ensure high quality of solution delivery.
Encourage best practice and knowledge sharing with partners and cross-functional groups
Manage the overall database design and delivery of solutions.
Ability to make recommendations as they pertain to improvements in support/development initiatives and facilitate implementation with partners and cross-functional groups within the Business.
Participate in high level database solution definition and design during the implementation phase with the goal of providing reliable, stable and operationally sound applications that meet the Business requirements.
Ability to understand and translate business requirements into technical specifications
The ideal candidate will have:
A minimum of 3 years of industry related experience of which 1 year must be within a complex hosting environment.
Certifications in Database design, system architecture or cloud technologies.
Demonstrate knowledge of database systems internals including storage layouts and distributed databases/MPP architectures
Advanced SQL coding, tuning and query optimization.
Experience designing and leading database performance benchmarks.
Good knowledge of the different AWS services
Knowledge of cloud networking architecture, cloud operations, security, automation and orchestration.
Knowledge of database internals as it relates to query and system performance and tuning.
Understanding of overall system architecture, scalability, reliability, and performance in a database environment.
Excellent teamwork, time-management and organizational skills.
Perform other duties as deemed necessary and assigned by the customer and management
Strong interpersonal skills and problem-solving abilities.
Excellent documentation, communication and interpersonal skills.
Excellent analytical and problem-solving abilities.
Closing date for applications: Monday, 13 April 2020

The base location for this role is Vodacom World, Midrand

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply.
Vodacom is committed to an organisational culture that recognises, appreciates and values diversity & inclusion.

Commitment from Vodacom

Vodacom is committed to attracting, developing and retaining the very best people by offering a flexible, motivating and inclusive workplace in which talent is truly recognized, developed and rewarded. We believe that diversity plays an important role in the success of our business and we are committed to creating an inclusive work environment which respects, values, celebrates and makes the most of people’s individual differences - we are not only multinational but multicultural too. At Vodacom you will have access to our excellent flexible benefits programme that you would expect from any global company.",3.9,"Vodafone
3.9",Midrand,-1,10000+ Employees,1982,Company - Public,"Cable, Internet & Telephone Providers",Telecommunications,$10+ billion (USD),-1
Data Engineer Azure Data Factory,-1,"Enthuzex is looking for a motivated Lead Data Engineer to contribute towards the success of our Data and Analytics Technology initiatives. This is a hands-on technical role and this person will be responsible for the development and build of scalable solutions as it relates to the architecture strategies, data standards, digital data management, data integration, tools, and technology. The right candidate will play a deep dive hands-on critical development role in the digital transformation and in shaping how we acquire, ingest, transform and deliver data through the digital consumer channels.

Responsibilities:

Architect, design, develop and engineering end-to-end data pipelines across multiple data sources and systems of record.
Ensure data quality, integrity, security and completeness throughout the data lifecycle
Develop, design data models, data structures and ETL jobs for data acquisition and manipulation purposes
Develop deep understanding of the data sources, implement data standards, maintain data quality and master data management
Developing data services and API
Work closely with the cloud service providers to ensure completeness and alignment with the service offerings
Manage and maintain cloud based data and analytics platform
Deep understanding of the cloud offerings and engage in quick proof of concepts and proof of value in prototyping data and analytics solutions and derive viability
Ability to interact with the business stakeholders to understand requirements and translating into technology solutions

Expirience:

Experience in Cloud platform AWS or Azure eco-system. (Azure preferred)
Data Engineering/Development experience with SQL (Oracle, SQL Server, MySQL)
Strong development background creating pipelines and complex data transformations and manipulations using one of the languages Python, Java, R, or Scala with Databricks/Spark
Experience in NoSQL Databases and Big data technologies including Hadoop
Experience with API / RESTful data services
Worked on real-time data capture, processing and storing using technologies like Azure Event Hubs and Analytics
Experience working with different data storage options including AWS S3, Azure BLOB storage etc.
Understanding of different data formats including Parquet, Avro, CSV, ORC etc.
Prior experience with MPP databases and maintain large amount of data processing
Experience with Azure Data Factory and Azure Data Catalog is a big plus and mandatory
Experience with Microsoft/Azure ETL solutions and business Intelligence technologies is a big and mandatory
Past working experience on a fast paced and agile environment
Perform ongoing monitoring, automation and refinement of data engineering solutions
Experience in leading high visibility transformation projects that interacts with multiple business lines
Build and meet project timelines and manage delivery commitments with proper communication to management

Qualifications

Bachelor’s degree with 4+ years of relevant experience
Willingness to learn new technologies and thrive in an extremely fast paced environment
Team player and easy to work with.

Applicants must demonstrate their ability to master new enterprise level technologies. Successful applicants will exemplify Enthuzex ethical principles of uncompromising integrity, respect for others, and accountability for decisions

send cv's info@enthuzex.co.za",-1,Enthuzex,Leslie,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Scientist,-1,"The world is changing.

We all want something different.

At Luno, we see you as an individual.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the world, and to do so, we need the best team on board for our mission.

A bit about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 3 million customers across 40 countries.
We are Series B funded, backed by Balderton Capital and the Naspers Group.
Our platform has processed over 8 billion dollars since we've launched
We're proud to be one of the world's most international cryptocurrency teams from 26 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
The role in a nutshell:

Identifying opportunities in the business that could benefit most from cognitive applications, as well as building and enhancing organisational capabilities for deriving value from multiple data sources using data science.

What we'd like you to have:
Bachelor's degree or higher in the natural sciences or technical fields such as Mathematics, Statistics, Computer Science, Engineering or Economics
Enthusiasm to work in the cryptocurrencies space
Advanced SQL skills
Solid understanding of exploratory data analysis, predictive analytics, and optimisation using Python, R, Matlab, RapidMiner, KNIME or other data science-oriented platforms
Proficiency in the use of data science and machine learning domain-specific languages such as ""Caret"" and the ""Tidyverse"" suite of tools in R, or ""Pandas"" in Python
Strong interpersonal and communication skills
Communicating data insights using storytelling narratives
Ability to work independently, as well as within and across teams
Ability to successfully complete projects with large and/or incomplete data sets
More about what you'll be doing:
Optimising product performance by tracking and analysing customer behaviour on web and app, in collaboration with software engineers and product designers
Providing the business with reports and dashboards, on key performance metrics
Developing metrics to accurately assess the health of our Exchange platform
Comparative data-driven analysis of our Exchange against alternative platforms
Formulating business requirements into analytical objectives
Designing and running experiments to test hypotheses
Hacking through complex business problems using advanced data analysis to provide insights and recommendations
Building, maintaining, and optimising decisioning systems using advanced statistical and predictive modelling techniques
What will set you apart:
An advanced degree in Mathematics, Statistics, Computer Science or related field
At least 3 years' experience working in a similar role
A basic understanding of trading in financial markets
Experience working with a data analytics and visualisation platform such as Tableau, Cognos, QlikView, or Looker
Familiarity with using Google Analytics to understand customer behaviour
Solid knowledge of statistical and machine learning techniques
Familiarity with modern distributed data storage and processing systems such as Amazon Redshift, Big Query, Snowflake, Databricks and Apache Spark
You can gather and synthesise facts, theories, trends, patterns, inferences, and key issues in complex and variable situations
Ability to diagnose problems using formal problem-solving tools and techniques from multiple angles to generate multiple possible solutions
A sense of anticipating long-term problem areas and associated risk levels with objective rationale
Remote Life at Luno

If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
You'll be able to continuously upskill yourself with access to free online learning via MyAcademy, an international teaching marketplace with over 100000 courses from Harvard and other leading providers + share knowledge with your peers.
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity and paternity leave, and you can even take paw-ternity leave for your furry friend.
Annual Inspiration Day! Make time for that pottery course or spa day you've always wanted to do.
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"EY is a global leader in
assurance, tax, transaction and advisory services. Technology is at the heart
of what we do and deliver at EY. Technology solutions are integrated in the
client services we deliver and are key to our innovation as an organization.

Fueled by
strategic investment in technology and innovation, Client Technology seeks to
drive growth opportunities and solve complex business problems for our clients
through building a robust platform for business and powerful product engine
that are vital to innovation at scale. As part of Client Technology, you’ll
work with technologists and business experts, blending EY’s deep industry
knowledge and innovative ideas with our platforms, capabilities, and technical
expertise. As a catalyst for change and growth, you’ll be at the forefront of
integrating emerging technologies from AI to Data Analytics into every corner
of what we do at EY. That means more growth for you, exciting learning
opportunities, career choices, and the chance to make a real impact.

The selected
candidate
Develops
large and complex data architecture, composed of models, policies, rules or
standards that govern which data is collected and how it is stored, arranged,
integrated and put to use in data systems, including the design, build and
management of data infrastructure to address business requirements
Creates
sound use case driven roadmaps, depicting data architecture as-is and to-be
capabilities with the business by engaging with multidisciplinary teams, and by
identifying, managing and mitigating risk
Develops
relationships across the business to understand data requirements, applies deep
technical knowledge of data management to solve business problems in areas
where solutions may not currently exist, necessitating new solutions/ways of
working/technologies and proactively articulating these to the business
Review,
identify the latest emerging technologies, augmenting by services from the
leading cloud providers to solution and recommend the best next generation data
platform value driven approach for our clients
Your Key Responsibilities Include
Create
and maintain conceptual, logical and physical database models
Document
functional requirements and system specifications into the data architecture
and detailed design specifications for current and proposed designs
Document
and adhere to development standards and best practices in database designs
Maintain
highly effective and consistent communication within the team, peers, and the
leadership team
Reverse
engineer SQL code and modify it to solve problems/issues
Contribute
to the definition and implementation of data governance practices
Design
both data structures and data integration practices
Work
closely with the infrastructure teams to create a physical environment to
support data services
Evaluate
new and existing (internal and external) technologies and services in support
of data services and data analytics objectives
Skills And Attributes For Success
Understanding
of business process reengineering and business modeling concepts, business
systems development and analysis
Hands-on
experience in designing and implementing hybrid cloud and on-prem solutions
Experience
working with the latest versions of SQL Server
Experience
applying SAFe/Scrum/Kanban methodologies
Ability
to exercise judgment in solving technical, operational, and organizational
challenges
Expert
programming, performance tuning and troubleshooting skills, using the latest
popular programming languages for example python
Demonstrate
proactive approach to identifying issues and presenting solutions and options,
and where appropriate, leading to resolution
Minimum Qualifications
5+ years
demonstratable work experience as a Data Architect using data modeling tools
2-3 years
SQL coding experience on large projects
Must
possess expert SQL programming, performance tuning and troubleshooting skills
Create
database objects and SQL scripts
Understand
and developed data pipelines
Know how
to deformalize data for data science models
Experience
in python, spark and notebooks
Experience
designing data warehousing solutions
Experience
designing next generation data platforms utilising cloud services
In-depth
understanding of database structure principles
Seamlessly
able to translate business requirements to technology requirements
What We Look For
Strong
analytical skills and problem-solving ability
A
self-starter, independent-thinker, curious and creative person with ambition
and passion
Excellent
inter-personal, communication, collaboration, and presentation skills
Customer
focused
Excellent
time management skills
Positive
and constructive minded
Takes
responsibility for continuous self-learning
Takes the
lead and makes decisions in critical times and tough circumstances
Attention
to detail
High
levels of integrity and honesty
Curious
about new emerging technology
About EY
As a global leader in assurance, tax, transaction and consulting
services, we’re using the finance products, expertise and systems we’ve
developed to build a better working world. That starts with a culture that
believes in giving you the training, opportunities and creative freedom to make
things better. Whenever you join, however long you stay, the exceptional EY
experience lasts a lifetime.",3.8,"EY
3.8",Johannesburg,-1,10000+ Employees,1989,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Architect - Principal,-1,"We are looking for Principle Data Architect to join our Engineering team in Cape Town.

The world is changing.
We all want something different.
At Luno, we see you as individuals.

Together, we are upgrading the world of work to unleash the potential within and empower you to become the best possible version of yourself.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the financial landscape, and to do so, well we need the best team on board for our mission. In short, to achieve our goals, we need rockstars. As simple as that.

A little about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 5 million customers across 40 countries.
We're part of the Digital Currency Group, a group of companies driving progress in the cryptocurrency and blockchain space that includes Grayscale, Genesis, Coindesk and Foundry Services
Our platform has processed over $8 billion to date
We're proud to be one of the world's most international cryptocurrency teams from 43 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
How we work


Our engineering team (currently ~100 engineers) is split into organisations which we call Fleets. Each Fleet focuses on a core customer journey (onboarding, security, payments, support, new business, growth and marketing etc.). Each of these fleets contains multiple smaller teams called Pods, each of which focuses on a specific aspect of the product.

Pods will include a product owner, product designer, back-end engineers, Android, iOS and Web developers, who each bring a unique perspective to the problem you are all contributing towards.

We're agile, use scrum, continuous integration and continuous delivery, deploying to production every single day.

We're building teams to help us succeed in our mission to upgrade the world to a better financial system. You'll be joining a group of highly motivated software engineers who you'll work collaboratively with across our pods.

As a fast-growing company with offices around the world, you'll immediately see how your contributions directly impact both our internal users and client experience. Many of the problems we are solving result in trail blazing solutions which can't be found on Stack Overflow; so we're looking for engineers who flourish working in a complex domain.

In your first six months, you will:


...start at Luno by learning our processes, meeting the wider team and starting our engineering on-boarding program. After getting comfortable with the basics, you'll start learning our idiomatic patterns in a safe, easy-to-follow way - by building your own toy micro services. You'll get to practice how we do design docs, code reviews, deployments, events, logging and monitoring.

You'll meet the Pod(s) you'll be working with and quickly align on the teams' current OKRs and product roadmap. We succeed as a team, so we will provide you with regular feedback from your manager and peers and will encourage you to do the same.

What you'll do:
Work closely with our data science and platform teams on projects introducing new streams of data into our data lake
You will get to bring new ideas on how to further develop and innovate our data solutions and how to expose that data to the business
Accountable and Responsible for the design and architecture of Data systems that are robust and scalable.
Work in an Agile/Scrum framework or Agile mindset
Data backup/recovery and storage
Pick-up and learn new concepts, in both engineering and product, and be able to apply that knowledge quickly.
The ideal candidate for this role will have:
7+ years' experience in maintaining scalable data solutions and/or you are passionate about it
Ability to understand, communicate and advocate between build vs buy
Proven track record of setting up, restructuring and maintenance of databases
You know your way around ETL and you have experience with SQL
Experience in the AWS Data stack (RedShift,DynamoDB, Amazon RDS)
Familiarity with integrating data stores with BI platforms such as Looker, Tableau, or Power BI
You have experience with the concepts of CI/CD
Coding skills in e.g. Go, Python
Bachelor's degree in a related field preferred
AWS Certified DataOps Administrator
Be friendly, transparent, articulate and driven to succeed
Basic knowledge of and passion for digital currencies like Bitcoin
A work permit for South Africa if you are not a South African citizen
Don't be put off if you don't tick all of the boxes – they're a guide based on what we'd love to see but we appreciate that excellent software engineers have diverse backgrounds.

Remote Life at Luno


If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity / paternity and even (yes, you are reading it correctly) paw-ternity for your furry friend..
Annual Inspiration Day.. like that pottery course you've always been meaning to do!
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. You'll need to hold the legal right to work in South Africa already as we cannot provide visa sponsorship.

Be part of the change!",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer - EC2 Capacity Data Analytics,-1,"EC2 Capacity Data Analytics (CDA) team is looking for a Data Engineer to join our team.

Our team is part of the EC2 Capacity Engineering organization, which is responsible for providing the elasticity EC2 customers need to scale up/down compute resources in a cost-efficient manner. We predict customer usage across thousands of configuration combinations to deliver exactly what our customers require in just the right amount of time with just the right amount of capacity.

As a Data Engineer, you will build the ETL and analytics solutions for our internal customers to answer questions with data and drive critical improvements for the business. You will use best practices in software engineering, data management, data storage, data compute, and distributed systems. On any given day, we use Python, Scala, Java, SQL, Lambda, CloudFormation, Redshift and Glue as well as other public AWS services and a host of Amazon internal tools. We dont expect you to be an expert in, or necessarily even be familiar with all of the technologies listed above, but we do expect you to be excited to learn about them.

This position involves on-call responsibilities, typically for one week every two months. Our team is dedicated to supporting new team members. We care about your career growth, we try to assign projects and tasks based on what will help each team member develop into a more well-rounded engineer and enable them to take on more complex tasks in the future.

Our team values work-life balance and we are flexible when people occasionally need to work from home.

Job Duties
Develop and maintain automated ETL pipelines for big data using languages such as Scala, Spark, SQL and AWS services such as S3, Glue, Lambda, SNS, SQS, KMS. Example: ETL jobs that process a continuous flow of JSON source files and output the data in a business-friendly Parquet format that can be efficiently queried via Redshift Spectrum using SQL to answer business question.

Develop and maintain automated ETL monitoring and alarming solutions using Java/Python/Scala, Spark, SQL, and AWS services such as CloudWatch and Lambda.

Implement and support reporting and analytics infrastructure for internal business customers using AWS, services such Athena, Redshift, Spectrum, EMR, and QuickSight.

Develop and maintain data security and permissions solutions for enterprise scale data warehouse and data lake implementations including data encryption and database user access controls and logging.

Develop and maintain data warehouse and data lake metadata, data catalog, and user documentation for internal business customers.

Develop, test, and deploy code using internal software development toolsets. This includes the code for deploying infrastructure and solutions for secure data storage, ETL pipelines, data catalog, and data query.


Basic Qualifications

· Bachelors degree in Computer Science or related technical field, or equivalent work experience.
· 4+ years of overall work experience including Software Engineering, Data Engineering, Database Engineering, Business Intelligence.
· Experience with AWS technologies stack including Lambda, Glue, Redshift, RDS, S3, EMR or similar big data solutions stack

Preferred Qualifications

· Demonstrate efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data.
· Demonstrable proficiency in distributed systems and data architecture; design and implementation of batch and stream data processing pipelines; knows how to optimize the distribution, partitioning, and MPP of high-level data structures.

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer,-1,"Our client based in Johannesburg is urgently looking for a Data Engineer to be on a 3 months contract
Build data pipelines, experience in new tech like nifi, kafka, python

Joburg based, open to EE, 3 month contract with the option to extend, must be available at short notice",-1,EQplus,Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Overview
Job ID: 51456
Job Sector: Information Technology and Services
Country: South Africa
Region/State/Province/District: Gauteng
Location: Johannesburg

Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose

This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes

Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems

Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions

Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.
Research and best practices

Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development

Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.

Preferred Qualification and Experience

Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry

Knowledge/Technical Skills/Expertise

Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision

PLEASE NOTE: All our recruitment and selection processes comply with applicable local laws and regulations. We will never ask for money or any form of payment as part of our recruitment process. If you experience this, please contact our Fraudline on +27 800222050 or forward to TransactionFraudOpsSA@standardbank.co.za",4.1,"Standard Bank
4.1",Johannesburg,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"About us

At PBT Group we pride ourselves on being a Data Specialist organisation. With 20 years of experience in 27 countries over 3 continents, our team of 550 consultants have implemented more than 700 projects.",4.3,"PBT Group
4.3",Johannesburg,-1,Unknown,-1,Company - Private,Accounting,Accounting & Legal,Less than $1 million (USD),-1
Data Engineer,-1,"Kick-start your career in the online gaming world and experience the very latest in technology and innovation.

The Department:

Our mission is to provide our customers with the best online betting experience and share the thrill of gaming with them. Data is at the very heart of our business and is vital in everything we do.

Our cross-functional Data team has a big and exciting challenge ahead. We are in the process of re-platforming our traditional, on-premises RDBMS environment to a new microservice architecture in the cloud. We’re making use of the diverse set of data technologies in Microsoft Azure to offer new services, reporting structures and real-time data pipeline while serving the day-to-day requirements of a rapidly growing, data-hungry organisation.

Purpose of the Role:

This is an excellent opportunity for an individual who is looking to gain new skills. We are committed to creating a culture of learning and regularly run proof of concepts, provide internal demos, manage workshops and attend external conferences. Our data team has a wide range of skills including development for highly transactional RDBMS systems, data warehousing, data science and cloud technologies and we are always working to raise everyone’s game.

Duties include, but not limited to:

Work as part of an agile Data Engineering Team
Development of greenfield projects in Azure
Develop and maintain on-premises RDBMS/DW systems
Create robust ETL services and real-time data pipelines
Build and maintain Continuous Integration and DevOps pipelines
Test-driven development and pair programming with colleagues

Essential Criteria:

C#, .Net, Visual Studio
Git, Azure DevOps
NoSQL development (CosmosDB)
Demonstrable understanding of MS SQL Server in a highly transactional environment
Demonstrable understanding of development in Microsoft Azure
Able to understand query plans and identify performance bottlenecks
Test/Business-Driven Development
Building Continuous Integration/Deployment pipelines
Communicate effectively with both technical and non-technical stakeholders

Desirable Criteria:

Implementing Data Storage and Processing solutions in Azure (ARM Templates, Storage Accounts, Data Lake Storage, SQL DB, Cosmos DB, EventHubs, Function Apps, Log Analytics, Data Factory, Databricks, Polybase)
Implementing Security, Disaster Recovery, High Availability, Auditing, Monitoring and Alerting solutions in Azure
Automating tasks in Azure using Powershell / CLI
Predicting costs and optimizing spending in Azure
Message Queues (RabbitMQ, Kafka)
Python

Person Specifications:

Resilience
Teamwork
Technical Knowledge
Communication skills
Stress Tolerance
Please note we will apply relevance to our Talent Management and Talent Development Programme as part of our recruitment process.
Shortlisted candidates may need to complete an assessment.
This position requires trust and honesty it has access to customers financial details - therefore a credit and criminal record check will be conducted. The qualifications identified herein are an inherent job requirement; therefore, a qualification verification check will be done. By applying for this role, and supplying the necessary details, you hereby grant us permission to apply for these checks. This will be done in a confidential manner, and solely for the purposes of verification.

To view all current vacancies, please visit our website, www.digioutsource.com

Should you not hear from us within 2 weeks, please deem your application as unsuccessful.

The perfect place to work, play and grow!",3.9,"Digital Outsource Services
3.9",Cape Town,-1,1001 to 5000 Employees,1997,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
Data Engineer,-1,"At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes

Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.

Key Responsibilities

Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.

Key Traits

Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern

Position Requirements

2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.

Where will you work? This role will be based out of Durbanville, South Africa.",3.1,"Aculocity, LLC
3.1",Durbanville,-1,1 to 50 Employees,2006,Company - Private,IT Services,Information Technology,$1 to $5 million (USD),-1
Data Engineer,-1,"ENVIRONMENT:

A rapidly growing E-Commerce Platform seeks a highly talented Data Engineer to make an invaluable contribution to data democratisation and literacy vision by making accessible and easy-to-use data products and tools. You will require a Comp-Sci Degree or 3 years’ relevant industry experience, MySQL, PostgreSQL, Java, Python, in-depth understanding of OLAP, Data Marts, Star Scheme, Snowflake, be familiar with Jenkins, Travis, Circle CI, Docker, Kubernetes, experience with Kafka, Pub/Sub, Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks & significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing & Data Lake design and implementation and Lambda/Kappa architectures.

DUTIES:

Design, develop, test and maintain data architecture.

Prepare data for descriptive, predictive and prescriptive modelling.

Automate repetitive tasks and manual processes related with the data usage.

Optimize data delivery.

Design, develop and test large stream data pipelines to ingest, aggregate, clean, and distribute data models ready for analysis.

Ensure the highest standard in data integrity.

Leverage best practices in continuous integration and delivery.

Collaborate with other engineers, ML experts, analysts, and stakeholders to produce the most efficient and valuable solutions.

Implement features, technology, and processes that move us towards industry best practices, improving on scalability, efficiency, reliability, and security.

Operations and ownership of systems in production, responding to incidents.

REQUIREMENTS:

Qualifications –

Comp-Sci Degree or 3 years relevant industry experience.

Experience/Skills –

Open source relational database systems e.g. MySQL, PostgreSQL, etc.

Significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing, and Data Lake design and implementation and Lambda/Kappa architectures.

A thorough understanding of database and data warehousing principles e.g. OLAP, Data Marts, Star Schema, Snowflake, etc.

Java and Python.

Familiar with CI/CD tools such as Jenkins, Travis, Circle CI, etc.

Experience with Kafka, Pub/Sub, or other event-based systems.

Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks, etc.

Working in cloud environments and with containerisation frameworks, tools and platforms e.g. Docker, Kubernetes, GKE, etc.

A deep understanding of data pipelining, streaming, and Big Data technologies, methods, patterns, and techniques.

Troubleshooting complex database operations and performance issues.

Automating tasks using Shell Scripting or writing small applications.

ATTRIBUTES:

Works well with people and is passionate about helping people be their best.

A team player, an active listener, mentor, and able to communicate well.

Shows solid reasoning and decision making, with the ability to work under pressure.

Is passionate about technology, systems and data.

Is curious, always learning, and keeping up to date with the industry.

While we would really like to respond to every application, should you not be contacted for this position within 10 working days please consider your application unsuccessful.

COMMENTS:

When applying for jobs, ensure that you have the minimum job requirements. Only SA Citizens will be considered for this role. If you are not in the mentioned location of any of the jobs, please note your relocation plans in all applications for jobs and correspondence.",-1,Datafin IT Recruitment,Cape Town,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Cartrack is looking for passionate data science and engineering candidates that can join a growing team that is responsible for the intelligence and efficiency solution provision to over a million subscribers, many of whom are large fleets. We are in the midst of creating revolutionary platforms that will change the way that people interact with their vehicles.

You will have the opportunity to work with the very brightest global subject matter experts that are transforming the automotive industry across Fleet Management, Asset Management and Insurance Telematics solutions.

Get to know the role:

The role of a data engineer is a supporting one, but it is also an extremely vital one. As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements. We want to see candidates with mechanical tendencies and a desire to know how things work and to improve them.

The day-to-day activities:

Design, construct, install, test and maintain data management systems.
Build high-performance algorithms, predictive models, and prototypes.
Ensure that all systems meet the business/company requirements as well as industry practices.
Integrate up-and-coming data management and software engineering technologies into existing data structures.
Develop set processes for data mining, data modeling, and data production.
Create custom software components and analytics applications.
Research new uses for existing data.
Employ an array of technological languages and tools to connect systems together.
Install/update disaster recovery procedures.
Recommend different ways to constantly improve data reliability and quality.
Work on and maintain Data pipelines.

Requirements Essential:

At least 5 years’ proven experience as a Data Engineer, DevOps Engineer, Software Developer, or similar.
Proficient in Linux/Unix and shell scripting as well as in functional programming languages.
Expertise in setting up and explored with technologies such as Hadoop and Spark.
Bachelor’s degree in computer science, software/computer engineering, applied mathematics, or physics.",3.3,"Cartrack
3.3",Johannesburg,-1,501 to 1000 Employees,2004,Company - Private,Security Services,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Data Engineer,-1,"Data Engineers build and support data pipelines and datamarts built off those pipelines. Both must be scalable, repeatable and secure. The Data Engineer helps to facilitate gathering data from a variety of different sources, in the correct format, assuring that it conforms to data quality standards and assuring that downstream users can get to that data timeously. This role functions as a core member of an agile team. These professionals are responsible for the infrastructure that provides insights from raw data, handling and integrating diverse sources of data seamlessly. They enable solutions, by handling large volumes of data in batch and real-time by leveraging emerging technologies from both the big data and cloud spaces. Additional responsibilities include developing proof of concepts and implements complex big data solutions with a focus on collecting, parsing, managing, analysing and visualising large datasets. They know how to apply technologies to solve the problems of working with large volumes of data in diverse formats to deliver innovative solutions. Data Engineering is a technical job that requires substantial expertise in a broad range of software development and programming fields. These professionals have a knowledge of data analysis, end user requirements and business requirements analysis to develop a clear understanding of the business need and to incorporate these needs into a technical solution. They have a solid understanding of physical database design and the systems development lifecycle. This role must work well in a team environment.

Job Objectives

Work Complexity: * Architects Data analytics framework. * Translates complex functional and technical requirements into detailed architecture, design, and high performing software. * Leads Data and batch/real-time analytical solutions leveraging transformational technologies. * Works on multiple projects as a technical lead driving user story analysis and elaboration, design and development of software applications, testing, and builds automation tools.

Main Job Objectives: 1. Development and Operations 2. Database Development and Operations 3. Policies, Standards and Procedures 4. Communications 5. Business Continuity & Disaster Recovery 6. Research and Evaluation 7. Coaching/ Mentoring

Qualifications

Essential: 4 years Bachelors degree in computer science, computer engineering, or equivalent work experience AWS Certification at least to associate level

Experience

Essential:

5+ years Data engineering or software engineering

3-5 years demonstrated experience leading teams of engineers

2+ years Big Data experience

5+ years experience with Extract Transform and Load (ETL) processes

2+ years Could AWS experience

At least 2 years demonstrated experience with agile or other rapid application development methods - Agile exposure, Kanban or Scrum

5 years demonstrated experience with object oriented design, coding and testing patterns as well as experience in engineering (commercial or open source) software platforms and large scale data infrastructures.

Desirable:

5+ years Retail Operations experience

Knowledge and Skills

Essential: *Creating data feeds from on-premise to AWS Cloud (2 years) *Support data feeds in production on break fix basis (2 years) *Creating data marts using Talend or similar ETL development tool (4 years) *Manipulating data using python and pyspark (2 years) *Processing data using the Hadoop paradigm particularly using EMR, AWSs distribution of Hadoop (2 years) *Devop for Big Data and Business Intelligence including automated testing and deployment (2 years) * Extensive knowledge in different programming or scripting languages * Expert knowledge of data modeling and understanding of different data structures and their benefits and limitations under particular use cases.

Further technical skills required: * Capability to architect highly scalable distributed systems, using different open source tools. * Big Data batch and streaming tools * Talend (1 year) * AWS: EMR, EC2, S3 (1 year) * Python (1 year) * PySpark or Spark (1 year) - Desirable * Business Intelligence Data modelling (3 years) * SQL (3 years)",-1,Datonomy Solutions,Brackenfell,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We are assisting one of our clients that is based in Pretoria to fill a role of a Data Engineer

This is a 12 month contract role

Objective of this Scope of Work

The Data Engineer will drive improvement of the data management maturity levels and provide the necessary technical support within the company to support reliable and effective decision-making, appropriate usage and protection thereof.

Scope of Services Definition

The scope will include but will not be limited to:

ï†· To develop, construct, test and maintain architectures.

ï†· To ensure architectures will support the requirements of business.

ï†· To discover opportunities for data acquisition and sharing.

ï†· To develop data set processes for data modelling, mining and production.

ï†· To employ a variety of languages and tools to marry systems together.

ï†· To recommend way to improve data reliability, efficiency and quality.

ï†· To prepare data for use in predictive and prescriptive modelling.

ï†· To conduct research to answer industry and business questions.

ï†· To leverage volumes of data from internal and external to answer business questions.

ï†· To develop and manage stakeholder relations effectively to promote data management across the organisation and support reliable decision making and appropriate data usage.

ï†· To participate and provide technical support in cross organisational activities relating to any of the above mentioned data management activities.

ï†· To provide regular progress reports as per stakeholder requirements and present data management updates in various forums as required.

Minimum qualification Required:

ï†· A minimum of a Bachelors degree in Computer Science or Information Management OR equivalent;

ï†· A minimum of five to eight years experience in a data management environment",-1,HR Genie,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Our client based in the Northern Suburbs, is currently looking for a Data Engineer to join their team.

Responsibilities
Our client is a dynamic IT company that delivers value-driven IT solutions to the group. Our work lives revolve around our DNA. We take pride in our work, treat our colleagues, partners and our country with respect. We exercise collaborative decision-making and believe in having a balance in life. We do this all while having fun and enjoying what we do.

The primary focus of this position is to use technical skills to put software, systems and data together in a way that extracts meaningful insights from raw data. You will need to be helpful and supportive to your team and fellow developers. You join an energetic, focused and dynamic team.

Interact with clients to understand requirements and business problems/needs

Identify, analyse, visualise and understand supporting data to propose solid solutions

Create technical documentation for reference and reporting

Support existing solutions within GCP and Oracle

Doing standby on a rotating basis

Key Competencies and Qualifications

Matric

Tertiary qualification in IT

Preferred cloud experience in AWS/AZURE/GCP

At least 3 years of data warehouse ETL experience

Dimensional Modelling

Data analyses

Experience with data visualization and visualization tool(s)

Knowledge of the retail industry will be beneficial

Understanding and experience with version control SVN/GIT

Preferred – Korn shell scripting, Python/Java, SQL

Google Cloud Platform experience would be looked upon favourably

Having a broad understanding of different SDLC’s

Preferred agile experience

Strengths

The natural tendency to take ownership and responsibility

Strong problem solving, critical thinking, effective planning and organisational skills

Detail-oriented with excellent communication skills

You have a can-do attitude and positive outlook on life

Can cope under pressure

Curious and interested in analysing problems and possible solutions

Strong team player

Self-driven learner, passionate about new technology

Above all, be passionate about what you do

Should you wish to apply for the position, please apply directly via this job board, please ensure that you quote reference number 201620 subject heading or email body.

Please note that due to the high volume of CV's received; only shortlisted applicants will be contacted. Should you not receive communication from our offices within two weeks of submission please note that your application will not be considered for this position.

We will keep your CV on file and re-establish contact with you should opportunities in line with your expertise become available again.

Should you require any additional information give us a call on 021 012 5566.",-1,Surgo HR & Training,Cape Town,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We believe that our employees fuel our organization, essential to enable us to help our customers overcome their business challenges and achieve sustainable growth. As a result, we are committed to growing each individual and providing them with the challenges, feedback and support needed to achieve success in their career

If this sounds appealing, and like us, you get excited about data: its collection, storage, transformation or display, see if you’ve got what it takes to join our sought after DATA team.

Key Responsibilities And/or Outputs

You will represent IQbusiness at our customers, sometimes alone, and sometimes as part of an IQ team.

Providing a superior customer experience by building and maintaining relationships, working at customer offices, keeping data confidential
Design and develop – databases, SQL queries, stored procedures, reports, dashboards or integration solutions
Produce solutions for both real-time and batch environments
Test your work to ensure compliance
Solve problems, and do root cause analysis
Prioritize your workload
Assist in other areas relating to your true data function, such as data modeling, data and business analysts
Interact with a variety of individuals: senior, junior, technical and from business
Provide guidance to fellow colleagues, or even manage a team
Uphold the IQ values, which are to care, learn & share; innovate; deliver as well as to build, enhance and maintain relationships

Education

Matric pass
A tertiary qualification, preferably in an ICT relevant field
Appropriate Microsoft certifications are beneficial but not required

Requirements

3 - 6 years experience in the Data Engineering environments and technologies
Great communication skills
A passion for SQL, databases or reports
Can you write stored procedures, design complex queries and create views and triggers?
Are you able to work out the relationships in a data warehouse or the aggregation of a cube?
Do you extract and display useful information when you see patterns and trends in data?
Strong knowledge of the financial services industry, ideally in a consulting role
The use of data related software: databases, ETL and BI tools; report writing and analytical tools
We use a lot of Microsoft products. You may often be expected to use MS SQL Server, SSIS, SSRS, SSAS and Power BI to develop solutions
What other relevant software have you’ve used?
Ability to work in different project methodologies: Waterfall and/or Agile
Knowledge of full SDLC
Exposure to logical and physical data modeling

Equal Employment Opportunity

IQbusiness is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, citizenship, marital, domestic or civil partnership status, sexual orientation, or gender identity",3.7,"IQbusiness South Africa
3.7",Johannesburg,-1,1 to 50 Employees,-1,Company - Private,Consulting,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"We value a data engineer as someone who works behind the scenes to obtain, process and supply data via various methodologies and technologies, to various consumers, in ways and forms that makes sense and add value. This definition is very broad, as the field of data engineering is just as broad.

You may be the type of data engineer that develops API endpoints for the consumption of data by end users or even another data pipeline, or you may be the type of data engineer that develops highly distributed, high availability data processing pipelines in an effort to satisfy the need of the ever questioning data analysts and/or data scientists.

You have awesome knowledge about the following concepts
Data modelling
Relational data modelling in traditional relational database management systems. (Microsoft SQL Server, MySQL, PostgreSQL, etc)
Coercing unstructured and semi-structured data into a structured form.
Data pipelining knowledge - data extraction and transformation.
Data transformation knowledge for reporting and analytics purposes.
Knowledge of the MapReduce and related data processing paradigms would be a boon.
You have the following technical competencies
Writing SQL queries, that can relate, transform and aggregate data from many differing sources where natural keys may or may not exist.
Experience with writing data pipelines that move and transform data, for various uses.
Working knowledge of a general purpose programming language like Python would be a boost.
Working knowledge of columnar databases such as Google BigQuery, and SAP HANA would be a boost.
Working knowledge of highly distributed technologies such as Apache Hadoop or Apache Spark would be a boost.
Working knowledge of NoSQL technologies, such as Apache Solr would be a boost.
You have the following personal competencies
The ability to solve problems.
The ability to rotate around a problem, to see if solutions can be gained in different ways.
The ability to work in an ever changing, unstructured environment.
The ability to work as part of a team, with vastly differing skill sets and opinions.
The ability to contribute ideas to the quorum.
The ability to mentor and provide guidance for other team members.
A systems approach to thinking, as opposed to a siloed approach. The candidate needs to understand how their work affects the greater system.
The ability to work without supervision, and take accountability for the work they deliver.
The ability to liaise with a client, sifting through the fluff and extracting the actual requirements.
If this is you - apply now and we'll get in touch",-1,DotModus,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Data Engineer

Our client in the contact centre space is currently seeking a DATA ENGINEER that will work on the collecting, storing, processing, and analyzing of large datasets. The primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them. You will also be responsible for integrating them with the architecture used across the company.

Key Performance Areas:

Data reporting.
Implementing ETL processes.
Defining data retention policies.
Management of Customer Lead data.
Provision of data for advanced analytics.
Maintenance of internal client scorecards.
Assist team in resolving data-related support queries.
Optimize existing data processes through automation.
Assist with all data-related reporting and documentation.
Maintenance and optimisation of the Analytics database.
Provide technical support to and supervision of junior data administrators.
Continuous upskilling on new technologies, frameworks and market trends.
Monitoring performance and advising any necessary infrastructure changes.
Identifying, selecting and integrating any Big Data tools and frameworks required to provide real-time analytics.

Educational Requirements

IT related Degree or Diploma is a pre-requisite

Required Skills/Experience

ETL tools: Advanced SSIS
BI/Reporting : Qlikview/Power BI/ SSRS or SSAS
Programming languages: JAVA, C# , Python, SAS or R
Experience with NoSQL databases and/or campaign management tools will be advantageous.
Minimum 3 years’ applicable work experience in SQL, relational databases and data manipulation.
Experience in big data platforms (eg. Hadoop) or processing frameworks (eg. MapReduce/Spark) and querying tools (eg. Pig, Hive and Impala) will be highly beneficial.

Preferred Skills

Organizational skills
Experience in Attentional to detail.
Accountability is critical for this role.
Ability to work under pressure and meet deadlines.
Solid understanding of database design principles.
Should you not receive a response in 2 weeks please consider your application unsuccessful",-1,Rubik's Cubed Consulting,Durban,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"This well known company is looking for a Data Engineer. will be based in Rivonia
The ideal candidate will have strong experience in the following:
Data cleaning
SQL Export
Big data Sets

BSc Degree in Maths and Stats will be required
a min of 3 years experience.
Stable track record is required.

Send your Cv to marinda@prrrecruitment.co.za",-1,PRR Recruitment Services,Johannesburg,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Description

Position at Aculocity, LLC

At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes
Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.
Key Responsibilities
Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.
Key Traits
Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern
Position Requirements
2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.
Where will you work? This role will be based out of Durbanville, South Africa.",-1,GVW,Durbanville,-1,Unknown,-1,Unknown,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Information Technology, Gauteng JHB - Northern Suburbs

Market related - Market related Annually

An IT Consultancy Business based in Johannesburg is currently looking for a Business Intelligence Consultant / Data Engineering Consultant.

Requirements:

Extensive experience in data engineering
Experience in Business Intelligence, data and Power BI
Extensive experience in data governance and the Popi act
Ability to assess and make recommendations on data within the Popi act
Good understanding of T-SQL and query optimization, developing ETL strategies.
Good understanding with SQL Server 2008/2012, SSIS, SSRS and SSAS
Use SSIS to create ETL packages to validate, extract, transform, and load data into the data warehouse and data marts.
Deploy and configured the reports in the Report Server (SSRS).
Excellent experience in Tabular Modelling , PowerView, Qlikvie,w, and Power BI
Maintain ETL
Qlikview model
Create Drill-through, Drill-down, and Cross Tab Reports and Sub-Report using Report Definition Language (RDL).
Generate periodic reports based on the statistical analysis of the data using SQL Server Reporting Services (SSRS)
Advise and provide written technical documentation and recommendations

The information displayed above is not limited to advertisements. Please contact Thato for further information.

Please consider your application as unsuccessful if you have not received a response within 14 days of submitting your application. However, please keep a lookout on our website, www.bedifferent.co.za, for available positions that you may be suited for

Ad Visible Until: 29 October 2020
Ref: JHB005346/NL

Vacancy Type: Permanent",2.9,"Be Different Recruitment
2.9",Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Cloud Support Engineer (Big Data),-1,"ABOUT US

Amazon Web Services is the market leader and technology forerunner in the Cloud business. As a member of the AWS Support team you will be at the forefront of this transformational technology, assisting a global list of companies and developers that are taking advantage of a growing set of services and features to run their mission-critical applications. As a Cloud Support Engineer, you will act as the Cloud Ambassador across all the cloud products, arming our customers with required tools & tactics to get the most out of their Product and Support investment.

Would you like to use the latest cloud computing technologies? Do you have an interest in helping customers understand application architectures and integration approaches? Are you familiar with best practices for applications, servers and networks? Do you want to be part of a customer facing technology team helping to ensure the success of Amazon Web Services (AWS) as a leading technology organization?

If you fit the description, you might be the person we are looking for! We are a group of smart people, passionate about cloud computing, and believe that world class support is critical to customer success.

WHAT CAN YOU EXPECT FROM A LIFE AT AWS?

Every day will bring new and exciting challenges on the job while you:

· Learn and use groundbreaking technologies.
· Apply advanced troubleshooting techniques to provide unique solutions to our customers' individual needs.
· Interact with leading engineers around the world.
· Partner with Amazon Web Services teams to help reproduce and resolve customer issues.
· Leverage your extensive customer support experience to provide feedback to internal AWS teams on how to improve our services.
· Drive customer communication during critical events.
· Drive projects that improve support-related processes and our customers technical support experience.
· Write tutorials, how-to videos, and other technical articles for the developer community.
· Work on critical, highly complex customer problems that may span multiple AWS services.

WHY AWS SUPPORT?

· First and foremost this is a customer support role in The Cloud.
· On a typical day, a Support Engineer will be primarily responsible for solving customers cases through a variety of customer contact channels which include telephone, email, and web/live chat. You will apply advanced troubleshooting techniques to provide tailored solutions for our customers and drive customer interactions by thoughtfully working with customers to dive deep into the root cause of an issue.
· Apart from working on a broad spectrum of technical issues, an AWS Support Engineer may also coach/mentor new hires, develop & present training, partner with development teams on complex issues or contact deflection initiatives, participate in new hiring, write tools/script to help the team, or work with leadership on process improvement and strategic initiatives.
· Career development: We promote advancement opportunities across the organization to help you meet your career goals.
· Training: We have training programs to help you develop the skills required to be successful in your role.
· We hire smart people who are keen to build a career with AWS, so we are more interested in the areas that you do know instead of those you havent been exposed to yet.
· Support engineers interested in travel have presented training or participated in focused summits across our sites or at specific AWS events.
· As we operate on a follow-the-sun model, with Premium Support sites located globally, there is no after hours on-call or mandated overtime in this role.
· https://www.youtube.com/watch?v=GC3bWcFFZTo&t=24s



Basic Qualifications

The Big Data role supports our services that leverage data and produce business insights, which may include using Machine Learning/Artificial Intelligence (ML/AI). Helping our customers use and integrate Big Data services in what is arguably our industrys most exciting space. The portfolio of services covers EMR (Hadoop), DynamoDB (NoSQL), MangoDB, and Apache Cassandra.

· Advanced experience in Apache Hadoop, Apache Spark, Apache Hive, and Presto
· Advanced experience in DynamoDB or NoSQL technologies like MongoDB or Cassandra
· Advanced experience with System Administration with Linux (RHEL/CentOS) including Microsoft Active Directory, and LDAP integration.
· Experience with troubleshooting Kerberos Authentication problems.
· Experience with Network troubleshooting.
· Basic understanding of Machine Learning and statistics
· Experience with Java and Python and shell scripting
· Bachelors degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position



Preferred Qualifications

· Expert experience in the Hadoop Ecosystem including Apache Spark and Presto
· Expert experience in NoSQL
· Expert experience with blockchain technologies like Etherium Expert experience in data Data Lake architecture and administration
· Experience managing full application stacks from the OS up through custom applications
· Prior work experience with AWS - any or all of EC2, VPC, S3, RDS, EMR, Glue, SageMaker
· Excellent knowledge of Hadoop architecture, administration and support
· Expert understanding of distributed computing principles and their application in the cloud
· Good understanding of distributed computing environments Lead technical discussions on big data systems architecture and design
· Strong analysis and troubleshooting skills and experience
· AWS Certified Solutions Architect
· AWS certified Big Data Specialty
· Masters degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity and Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Response Center Engineer,-1,"Job Title
Response Center Engineer
Job Description


Philips is a world leading health technology company with a vision to make life better for people worldwide through meaningful innovation. Making good on this promise depends on our passionate, inspirational, collaborative and diverse team. We have over 80,000+ brilliant people around the world but are always looking for more. Like-minded, motivated, focused minds to join us in creating a healthier, more connected society while transforming themselves personally and professionally.

As a CCC Coordinator - Response Center Engineer you will have the opportunity to process customer calls and be responsible for screening and diagnosing professionally Healthcare equipment to support customers and colleagues remotely with solving technical issues and ensuring maximum customer satisfaction

You are responsible for:
Diagnose healthcare equipment to the quality standards set by Philips Healthcare (PH) remotely by interviewing customers or colleagues by telephone or by remotely logging in to the system
Advise Customer Care Center Coordinators and District Operations Managers and / or Team Leads about the best follow-up w.r.t. technical state of the diagnosed healthcare equipment
Advise the Customer Care Center Coordinators or Field Services Engineers about required spare parts and resources
Responsible for planning engineers related to Modality responsibility.
Responsible for coordination between CCC, CUSTOMER, Spare parts AND Engineer.
Responsible to drive Remote and FTR KPI’s to targets respectively 40% and 85%.
Will require minimal field work to keep abreast of technical capabilities.
Take calls from customers and make sure they are processed in the CCC ERP on timely manner including all relevant data
Support Field Services Engineers in the field with technical knowledge
Escalate technical issues to the Technical Support Specialist
Escalate technical issues to Business Unit support after consultation of the Technical Support Specialist
Monitor critical functions of the equipment’s in the IB and environmental conditions including RSN and True reachability.
Lead the planning and implementation of FSN’s and FCO’s accelerating remote implementation where applicable.
Submit timely and accurate service data, job sheets, reports, expense claims, radiation film badges, field problem reports and other paperwork as assigned
Keep abreast of new technologies likely to affect PH range of products
Use company property with care to ensure optimal results with minimal operational costs
Be a professional representative for PH with respect to customer problems, ensuring personal acceptability by the customer in behavior in accordance with PH policy and targets
Conform to PH safety standards including health and safety regulations and in the event of hazards or accidents to take immediate control of the situation and involve the Operations Manager and / or the responsible person to handle properly confidential issues according Philips standards and to act according General Business Principals
Follow all quality standards within the frame of valid PH business policies
Follow the company quality regulations (ISO 9001; PQA; TQM) and internal directives and procedures
You are a part of the dynamic South Africa Customer Care Centre Team .You will be reporting to the Customer Care Center Manager.

Requires a pleasant, assertive individual you can work very well in a team setting, a dynamic environment that requires flexibility and creativeness to achieve goals.

To succeed in this role, you should have the following skills and experience:
Degree level education or equivalent
Experience in maintenance and troubleshooting of technical complex systems
Fluent in English, verbal and written in addition to local language
In return, we offer you the unique combination of a critical and challenging role and a creative and empowering office environment. You will be actively encouraged to make improvements, establish best in class service and have a direct impact on the success of Philips on a daily basis.

Employment Equity

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply. Only apply for this role if you are a South African Citizen by birth or Naturalization prior to the 27 April 1994.

Why should you join Philips?

Working at Philips is more than a job. It’s a calling to create a healthier society through meaningful work, focused on improving 3 billion lives a year by delivering innovative solutions across the health continuum. Our people experience a variety of unexpected moments when their lives and careers come together in meaningful ways. Learn more by watching this video.

To find out more about what it’s like working for Philips at a personal level, visit the Working at Philips page on our career website, where you can read stories from our employee blog. Once there, you can also learn about our recruitment process, or find answers to some of the frequently asked questions.

Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.9,"Philips
3.9",Johannesburg,-1,10000+ Employees,1891,Company - Public,Health Care Services & Hospitals,Health Care,$10 to $25 million (USD),-1
Software Development Engineer - EC2 Placement,-1,"Build the systems that optimize how EC2 matches requests for Instances with the underlying compute capacity. EC2 Placement is seeking talented engineers to build the online and offline optimization systems for compute workload scheduling, and the customer capabilities to better manage those workloads. Amazon EC2 provides on-demand scalable compute capacity, and powers some of the largest services in the world. You will collaborate with a top-tier community of engineers to build systems to improve how customers are able to access EC2 compute resources.

The successful candidate will have strong software engineering experience, with a passion for thinking about, building and testing distributed systems. You have an interest in how Machine Learning and other optimization techniques can be applied to large-scale problems. You have demonstrated experience working with a team to design, build and operate large-scale systems. With strong engineering fundamentals, an analytical and data-driven approach to your work, and strong communication skills, you have the ability to collaborate well to deliver results. We move fast and work together on small teams to solve big problems.

If this opportunity sounds interesting, we would love to talk to you more about our work and the vibrant culture at AWS in Cape Town.

Basic Qualifications

· Degree in Computer Science or related field, or equivalent working experience
· 3+ years of industry experience in a software development environment
· Strong Computer Science fundamentals, including data structures, object-oriented design, algorithm design, problem solving, and complexity analysis.
· Proficiency in at least one modern programming language, such as Java, C#, Python, Scala, Kotlin

Preferred Qualifications

One or more of the following help you stand out:
· Demonstrated results designing, building and operating high-performance distributed systems in large-scale Linux environments
· Role model in writing high-quality, maintainable and secure code, mentoring others, and helping teams sharpen their development processes
· Ability to work effectively across teams to deliver results, with strong verbal and written communication skills
· Experience working with machine learning systems

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer - PBB IT,-1,"Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose


This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes
Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems
Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions
Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.

Research and best practices
Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development
Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.
Preferred Qualification and Experience
Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Aws Data Platform Engineer,-1,"Aws Data Platform Engineer

Posting Country:

South Africa

Date Posted:

15-Oct-2020

Full Time / Part Time:

Full Time

Contract Type:

Permanent

Joining Vodacom is more than a job, what we do matters. We don’t just carry minutes, texts and data – we carry people’s lives. And that’s a huge responsibility. If you think for a minute about the people you rely on…the likelihood is they rely on us.

Customers are at the heart of everything we do and we want to make a difference to the lives of our customers, and the communities in which we live and work. We support our people to give something back to the causes that mean the most to them through helping them give time and money to the charities they love.

And what’s it like to work here? We have created an environment where you can look forward to coming to work and are empowered to be at your best. We offer flexibility in how you work that helps you do your job in a way that suits you, opportunities to help you grow and progress throughout your career and a choice of benefits to suit your lifestyle.

Role Purpose
The H Band AWS Data Platform Engineer position is based within the Technology Business Unit.

The AWS Data Platform Engineer will be responsible for all Database services such as RDS, DynamoDB, etc. Should be able to migrate any databases from anywhere to AWS using any third-party tools or AWS database migration tool. Should also have understanding or expertise in creating data warehouses and data lake solutions on AWS.
Your responsibilities will include:
Apply practical knowledge of relational database design and usage with customers
Perform workload analysis and undertake performance tuning, as well as performance benchmarking in customer environments.
To develop state of the art solutions which are technically sound.
To provide a high-quality service to the Enterprise Cloud Services clients i.t.o. consultancy, solutions and delivery.
Commitment to team success and positive team dynamics including mentoring of other team members.
Passion for growing and applying technical skills in service to customers.
Be a trusted infrastructure advisor by providing objective, practical and relevant ideas, insights and advice.
Work collaboratively with consulting partners and technology teams to ensure high quality of solution delivery.
Encourage best practice and knowledge sharing with partners and cross-functional groups
Manage the overall database design and delivery of solutions.
Ability to make recommendations as they pertain to improvements in support/development initiatives and facilitate implementation with partners and cross-functional groups within the Business.
Participate in high level database solution definition and design during the implementation phase with the goal of providing reliable, stable and operationally sound applications that meet the Business requirements.
Ability to understand and translate business requirements into technical specifications
The ideal candidate will have:
A minimum of 3 years of industry related experience of which 1 year must be within a complex hosting environment.
Certifications in Database design, system architecture or cloud technologies.
Demonstrate knowledge of database systems internals including storage layouts and distributed databases/MPP architectures
Advanced SQL coding, tuning and query optimization.
Experience designing and leading database performance benchmarks.
Good knowledge of the different AWS services
Knowledge of cloud networking architecture, cloud operations, security, automation and orchestration.
Knowledge of database internals as it relates to query and system performance and tuning.
Understanding of overall system architecture, scalability, reliability, and performance in a database environment.
Excellent teamwork, time-management and organizational skills.
Perform other duties as deemed necessary and assigned by the customer and management
Strong interpersonal skills and problem-solving abilities.
Excellent documentation, communication and interpersonal skills.
Excellent analytical and problem-solving abilities.
Closing date for applications: Monday, 13 April 2020

The base location for this role is Vodacom World, Midrand

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply.
Vodacom is committed to an organisational culture that recognises, appreciates and values diversity & inclusion.

Commitment from Vodacom

Vodacom is committed to attracting, developing and retaining the very best people by offering a flexible, motivating and inclusive workplace in which talent is truly recognized, developed and rewarded. We believe that diversity plays an important role in the success of our business and we are committed to creating an inclusive work environment which respects, values, celebrates and makes the most of people’s individual differences - we are not only multinational but multicultural too. At Vodacom you will have access to our excellent flexible benefits programme that you would expect from any global company.",3.9,"Vodafone
3.9",Midrand,-1,10000+ Employees,1982,Company - Public,"Cable, Internet & Telephone Providers",Telecommunications,$10+ billion (USD),-1
Data Engineer Azure Data Factory,-1,"Enthuzex is looking for a motivated Lead Data Engineer to contribute towards the success of our Data and Analytics Technology initiatives. This is a hands-on technical role and this person will be responsible for the development and build of scalable solutions as it relates to the architecture strategies, data standards, digital data management, data integration, tools, and technology. The right candidate will play a deep dive hands-on critical development role in the digital transformation and in shaping how we acquire, ingest, transform and deliver data through the digital consumer channels.

Responsibilities:

Architect, design, develop and engineering end-to-end data pipelines across multiple data sources and systems of record.
Ensure data quality, integrity, security and completeness throughout the data lifecycle
Develop, design data models, data structures and ETL jobs for data acquisition and manipulation purposes
Develop deep understanding of the data sources, implement data standards, maintain data quality and master data management
Developing data services and API
Work closely with the cloud service providers to ensure completeness and alignment with the service offerings
Manage and maintain cloud based data and analytics platform
Deep understanding of the cloud offerings and engage in quick proof of concepts and proof of value in prototyping data and analytics solutions and derive viability
Ability to interact with the business stakeholders to understand requirements and translating into technology solutions

Expirience:

Experience in Cloud platform AWS or Azure eco-system. (Azure preferred)
Data Engineering/Development experience with SQL (Oracle, SQL Server, MySQL)
Strong development background creating pipelines and complex data transformations and manipulations using one of the languages Python, Java, R, or Scala with Databricks/Spark
Experience in NoSQL Databases and Big data technologies including Hadoop
Experience with API / RESTful data services
Worked on real-time data capture, processing and storing using technologies like Azure Event Hubs and Analytics
Experience working with different data storage options including AWS S3, Azure BLOB storage etc.
Understanding of different data formats including Parquet, Avro, CSV, ORC etc.
Prior experience with MPP databases and maintain large amount of data processing
Experience with Azure Data Factory and Azure Data Catalog is a big plus and mandatory
Experience with Microsoft/Azure ETL solutions and business Intelligence technologies is a big and mandatory
Past working experience on a fast paced and agile environment
Perform ongoing monitoring, automation and refinement of data engineering solutions
Experience in leading high visibility transformation projects that interacts with multiple business lines
Build and meet project timelines and manage delivery commitments with proper communication to management

Qualifications

Bachelor’s degree with 4+ years of relevant experience
Willingness to learn new technologies and thrive in an extremely fast paced environment
Team player and easy to work with.

Applicants must demonstrate their ability to master new enterprise level technologies. Successful applicants will exemplify Enthuzex ethical principles of uncompromising integrity, respect for others, and accountability for decisions

send cv's info@enthuzex.co.za",-1,Enthuzex,Leslie,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Scientist,-1,"The world is changing.

We all want something different.

At Luno, we see you as an individual.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the world, and to do so, we need the best team on board for our mission.

A bit about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 3 million customers across 40 countries.
We are Series B funded, backed by Balderton Capital and the Naspers Group.
Our platform has processed over 8 billion dollars since we've launched
We're proud to be one of the world's most international cryptocurrency teams from 26 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
The role in a nutshell:

Identifying opportunities in the business that could benefit most from cognitive applications, as well as building and enhancing organisational capabilities for deriving value from multiple data sources using data science.

What we'd like you to have:
Bachelor's degree or higher in the natural sciences or technical fields such as Mathematics, Statistics, Computer Science, Engineering or Economics
Enthusiasm to work in the cryptocurrencies space
Advanced SQL skills
Solid understanding of exploratory data analysis, predictive analytics, and optimisation using Python, R, Matlab, RapidMiner, KNIME or other data science-oriented platforms
Proficiency in the use of data science and machine learning domain-specific languages such as ""Caret"" and the ""Tidyverse"" suite of tools in R, or ""Pandas"" in Python
Strong interpersonal and communication skills
Communicating data insights using storytelling narratives
Ability to work independently, as well as within and across teams
Ability to successfully complete projects with large and/or incomplete data sets
More about what you'll be doing:
Optimising product performance by tracking and analysing customer behaviour on web and app, in collaboration with software engineers and product designers
Providing the business with reports and dashboards, on key performance metrics
Developing metrics to accurately assess the health of our Exchange platform
Comparative data-driven analysis of our Exchange against alternative platforms
Formulating business requirements into analytical objectives
Designing and running experiments to test hypotheses
Hacking through complex business problems using advanced data analysis to provide insights and recommendations
Building, maintaining, and optimising decisioning systems using advanced statistical and predictive modelling techniques
What will set you apart:
An advanced degree in Mathematics, Statistics, Computer Science or related field
At least 3 years' experience working in a similar role
A basic understanding of trading in financial markets
Experience working with a data analytics and visualisation platform such as Tableau, Cognos, QlikView, or Looker
Familiarity with using Google Analytics to understand customer behaviour
Solid knowledge of statistical and machine learning techniques
Familiarity with modern distributed data storage and processing systems such as Amazon Redshift, Big Query, Snowflake, Databricks and Apache Spark
You can gather and synthesise facts, theories, trends, patterns, inferences, and key issues in complex and variable situations
Ability to diagnose problems using formal problem-solving tools and techniques from multiple angles to generate multiple possible solutions
A sense of anticipating long-term problem areas and associated risk levels with objective rationale
Remote Life at Luno

If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
You'll be able to continuously upskill yourself with access to free online learning via MyAcademy, an international teaching marketplace with over 100000 courses from Harvard and other leading providers + share knowledge with your peers.
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity and paternity leave, and you can even take paw-ternity leave for your furry friend.
Annual Inspiration Day! Make time for that pottery course or spa day you've always wanted to do.
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"EY is a global leader in
assurance, tax, transaction and advisory services. Technology is at the heart
of what we do and deliver at EY. Technology solutions are integrated in the
client services we deliver and are key to our innovation as an organization.

Fueled by
strategic investment in technology and innovation, Client Technology seeks to
drive growth opportunities and solve complex business problems for our clients
through building a robust platform for business and powerful product engine
that are vital to innovation at scale. As part of Client Technology, you’ll
work with technologists and business experts, blending EY’s deep industry
knowledge and innovative ideas with our platforms, capabilities, and technical
expertise. As a catalyst for change and growth, you’ll be at the forefront of
integrating emerging technologies from AI to Data Analytics into every corner
of what we do at EY. That means more growth for you, exciting learning
opportunities, career choices, and the chance to make a real impact.

The selected
candidate
Develops
large and complex data architecture, composed of models, policies, rules or
standards that govern which data is collected and how it is stored, arranged,
integrated and put to use in data systems, including the design, build and
management of data infrastructure to address business requirements
Creates
sound use case driven roadmaps, depicting data architecture as-is and to-be
capabilities with the business by engaging with multidisciplinary teams, and by
identifying, managing and mitigating risk
Develops
relationships across the business to understand data requirements, applies deep
technical knowledge of data management to solve business problems in areas
where solutions may not currently exist, necessitating new solutions/ways of
working/technologies and proactively articulating these to the business
Review,
identify the latest emerging technologies, augmenting by services from the
leading cloud providers to solution and recommend the best next generation data
platform value driven approach for our clients
Your Key Responsibilities Include
Create
and maintain conceptual, logical and physical database models
Document
functional requirements and system specifications into the data architecture
and detailed design specifications for current and proposed designs
Document
and adhere to development standards and best practices in database designs
Maintain
highly effective and consistent communication within the team, peers, and the
leadership team
Reverse
engineer SQL code and modify it to solve problems/issues
Contribute
to the definition and implementation of data governance practices
Design
both data structures and data integration practices
Work
closely with the infrastructure teams to create a physical environment to
support data services
Evaluate
new and existing (internal and external) technologies and services in support
of data services and data analytics objectives
Skills And Attributes For Success
Understanding
of business process reengineering and business modeling concepts, business
systems development and analysis
Hands-on
experience in designing and implementing hybrid cloud and on-prem solutions
Experience
working with the latest versions of SQL Server
Experience
applying SAFe/Scrum/Kanban methodologies
Ability
to exercise judgment in solving technical, operational, and organizational
challenges
Expert
programming, performance tuning and troubleshooting skills, using the latest
popular programming languages for example python
Demonstrate
proactive approach to identifying issues and presenting solutions and options,
and where appropriate, leading to resolution
Minimum Qualifications
5+ years
demonstratable work experience as a Data Architect using data modeling tools
2-3 years
SQL coding experience on large projects
Must
possess expert SQL programming, performance tuning and troubleshooting skills
Create
database objects and SQL scripts
Understand
and developed data pipelines
Know how
to deformalize data for data science models
Experience
in python, spark and notebooks
Experience
designing data warehousing solutions
Experience
designing next generation data platforms utilising cloud services
In-depth
understanding of database structure principles
Seamlessly
able to translate business requirements to technology requirements
What We Look For
Strong
analytical skills and problem-solving ability
A
self-starter, independent-thinker, curious and creative person with ambition
and passion
Excellent
inter-personal, communication, collaboration, and presentation skills
Customer
focused
Excellent
time management skills
Positive
and constructive minded
Takes
responsibility for continuous self-learning
Takes the
lead and makes decisions in critical times and tough circumstances
Attention
to detail
High
levels of integrity and honesty
Curious
about new emerging technology
About EY
As a global leader in assurance, tax, transaction and consulting
services, we’re using the finance products, expertise and systems we’ve
developed to build a better working world. That starts with a culture that
believes in giving you the training, opportunities and creative freedom to make
things better. Whenever you join, however long you stay, the exceptional EY
experience lasts a lifetime.",3.8,"EY
3.8",Johannesburg,-1,10000+ Employees,1989,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Architect - Principal,-1,"We are looking for Principle Data Architect to join our Engineering team in Cape Town.

The world is changing.
We all want something different.
At Luno, we see you as individuals.

Together, we are upgrading the world of work to unleash the potential within and empower you to become the best possible version of yourself.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the financial landscape, and to do so, well we need the best team on board for our mission. In short, to achieve our goals, we need rockstars. As simple as that.

A little about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 5 million customers across 40 countries.
We're part of the Digital Currency Group, a group of companies driving progress in the cryptocurrency and blockchain space that includes Grayscale, Genesis, Coindesk and Foundry Services
Our platform has processed over $8 billion to date
We're proud to be one of the world's most international cryptocurrency teams from 43 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
How we work


Our engineering team (currently ~100 engineers) is split into organisations which we call Fleets. Each Fleet focuses on a core customer journey (onboarding, security, payments, support, new business, growth and marketing etc.). Each of these fleets contains multiple smaller teams called Pods, each of which focuses on a specific aspect of the product.

Pods will include a product owner, product designer, back-end engineers, Android, iOS and Web developers, who each bring a unique perspective to the problem you are all contributing towards.

We're agile, use scrum, continuous integration and continuous delivery, deploying to production every single day.

We're building teams to help us succeed in our mission to upgrade the world to a better financial system. You'll be joining a group of highly motivated software engineers who you'll work collaboratively with across our pods.

As a fast-growing company with offices around the world, you'll immediately see how your contributions directly impact both our internal users and client experience. Many of the problems we are solving result in trail blazing solutions which can't be found on Stack Overflow; so we're looking for engineers who flourish working in a complex domain.

In your first six months, you will:


...start at Luno by learning our processes, meeting the wider team and starting our engineering on-boarding program. After getting comfortable with the basics, you'll start learning our idiomatic patterns in a safe, easy-to-follow way - by building your own toy micro services. You'll get to practice how we do design docs, code reviews, deployments, events, logging and monitoring.

You'll meet the Pod(s) you'll be working with and quickly align on the teams' current OKRs and product roadmap. We succeed as a team, so we will provide you with regular feedback from your manager and peers and will encourage you to do the same.

What you'll do:
Work closely with our data science and platform teams on projects introducing new streams of data into our data lake
You will get to bring new ideas on how to further develop and innovate our data solutions and how to expose that data to the business
Accountable and Responsible for the design and architecture of Data systems that are robust and scalable.
Work in an Agile/Scrum framework or Agile mindset
Data backup/recovery and storage
Pick-up and learn new concepts, in both engineering and product, and be able to apply that knowledge quickly.
The ideal candidate for this role will have:
7+ years' experience in maintaining scalable data solutions and/or you are passionate about it
Ability to understand, communicate and advocate between build vs buy
Proven track record of setting up, restructuring and maintenance of databases
You know your way around ETL and you have experience with SQL
Experience in the AWS Data stack (RedShift,DynamoDB, Amazon RDS)
Familiarity with integrating data stores with BI platforms such as Looker, Tableau, or Power BI
You have experience with the concepts of CI/CD
Coding skills in e.g. Go, Python
Bachelor's degree in a related field preferred
AWS Certified DataOps Administrator
Be friendly, transparent, articulate and driven to succeed
Basic knowledge of and passion for digital currencies like Bitcoin
A work permit for South Africa if you are not a South African citizen
Don't be put off if you don't tick all of the boxes – they're a guide based on what we'd love to see but we appreciate that excellent software engineers have diverse backgrounds.

Remote Life at Luno


If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity / paternity and even (yes, you are reading it correctly) paw-ternity for your furry friend..
Annual Inspiration Day.. like that pottery course you've always been meaning to do!
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. You'll need to hold the legal right to work in South Africa already as we cannot provide visa sponsorship.

Be part of the change!",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer - EC2 Capacity Data Analytics,-1,"EC2 Capacity Data Analytics (CDA) team is looking for a Data Engineer to join our team.

Our team is part of the EC2 Capacity Engineering organization, which is responsible for providing the elasticity EC2 customers need to scale up/down compute resources in a cost-efficient manner. We predict customer usage across thousands of configuration combinations to deliver exactly what our customers require in just the right amount of time with just the right amount of capacity.

As a Data Engineer, you will build the ETL and analytics solutions for our internal customers to answer questions with data and drive critical improvements for the business. You will use best practices in software engineering, data management, data storage, data compute, and distributed systems. On any given day, we use Python, Scala, Java, SQL, Lambda, CloudFormation, Redshift and Glue as well as other public AWS services and a host of Amazon internal tools. We dont expect you to be an expert in, or necessarily even be familiar with all of the technologies listed above, but we do expect you to be excited to learn about them.

This position involves on-call responsibilities, typically for one week every two months. Our team is dedicated to supporting new team members. We care about your career growth, we try to assign projects and tasks based on what will help each team member develop into a more well-rounded engineer and enable them to take on more complex tasks in the future.

Our team values work-life balance and we are flexible when people occasionally need to work from home.

Job Duties
Develop and maintain automated ETL pipelines for big data using languages such as Scala, Spark, SQL and AWS services such as S3, Glue, Lambda, SNS, SQS, KMS. Example: ETL jobs that process a continuous flow of JSON source files and output the data in a business-friendly Parquet format that can be efficiently queried via Redshift Spectrum using SQL to answer business question.

Develop and maintain automated ETL monitoring and alarming solutions using Java/Python/Scala, Spark, SQL, and AWS services such as CloudWatch and Lambda.

Implement and support reporting and analytics infrastructure for internal business customers using AWS, services such Athena, Redshift, Spectrum, EMR, and QuickSight.

Develop and maintain data security and permissions solutions for enterprise scale data warehouse and data lake implementations including data encryption and database user access controls and logging.

Develop and maintain data warehouse and data lake metadata, data catalog, and user documentation for internal business customers.

Develop, test, and deploy code using internal software development toolsets. This includes the code for deploying infrastructure and solutions for secure data storage, ETL pipelines, data catalog, and data query.


Basic Qualifications

· Bachelors degree in Computer Science or related technical field, or equivalent work experience.
· 4+ years of overall work experience including Software Engineering, Data Engineering, Database Engineering, Business Intelligence.
· Experience with AWS technologies stack including Lambda, Glue, Redshift, RDS, S3, EMR or similar big data solutions stack

Preferred Qualifications

· Demonstrate efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data.
· Demonstrable proficiency in distributed systems and data architecture; design and implementation of batch and stream data processing pipelines; knows how to optimize the distribution, partitioning, and MPP of high-level data structures.

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer,-1,"Our client based in Johannesburg is urgently looking for a Data Engineer to be on a 3 months contract
Build data pipelines, experience in new tech like nifi, kafka, python

Joburg based, open to EE, 3 month contract with the option to extend, must be available at short notice",-1,EQplus,Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Overview
Job ID: 51456
Job Sector: Information Technology and Services
Country: South Africa
Region/State/Province/District: Gauteng
Location: Johannesburg

Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose

This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes

Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems

Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions

Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.
Research and best practices

Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development

Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.

Preferred Qualification and Experience

Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry

Knowledge/Technical Skills/Expertise

Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision

PLEASE NOTE: All our recruitment and selection processes comply with applicable local laws and regulations. We will never ask for money or any form of payment as part of our recruitment process. If you experience this, please contact our Fraudline on +27 800222050 or forward to TransactionFraudOpsSA@standardbank.co.za",4.1,"Standard Bank
4.1",Johannesburg,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"About us

At PBT Group we pride ourselves on being a Data Specialist organisation. With 20 years of experience in 27 countries over 3 continents, our team of 550 consultants have implemented more than 700 projects.",4.3,"PBT Group
4.3",Johannesburg,-1,Unknown,-1,Company - Private,Accounting,Accounting & Legal,Less than $1 million (USD),-1
Data Engineer,-1,"Kick-start your career in the online gaming world and experience the very latest in technology and innovation.

The Department:

Our mission is to provide our customers with the best online betting experience and share the thrill of gaming with them. Data is at the very heart of our business and is vital in everything we do.

Our cross-functional Data team has a big and exciting challenge ahead. We are in the process of re-platforming our traditional, on-premises RDBMS environment to a new microservice architecture in the cloud. We’re making use of the diverse set of data technologies in Microsoft Azure to offer new services, reporting structures and real-time data pipeline while serving the day-to-day requirements of a rapidly growing, data-hungry organisation.

Purpose of the Role:

This is an excellent opportunity for an individual who is looking to gain new skills. We are committed to creating a culture of learning and regularly run proof of concepts, provide internal demos, manage workshops and attend external conferences. Our data team has a wide range of skills including development for highly transactional RDBMS systems, data warehousing, data science and cloud technologies and we are always working to raise everyone’s game.

Duties include, but not limited to:

Work as part of an agile Data Engineering Team
Development of greenfield projects in Azure
Develop and maintain on-premises RDBMS/DW systems
Create robust ETL services and real-time data pipelines
Build and maintain Continuous Integration and DevOps pipelines
Test-driven development and pair programming with colleagues

Essential Criteria:

C#, .Net, Visual Studio
Git, Azure DevOps
NoSQL development (CosmosDB)
Demonstrable understanding of MS SQL Server in a highly transactional environment
Demonstrable understanding of development in Microsoft Azure
Able to understand query plans and identify performance bottlenecks
Test/Business-Driven Development
Building Continuous Integration/Deployment pipelines
Communicate effectively with both technical and non-technical stakeholders

Desirable Criteria:

Implementing Data Storage and Processing solutions in Azure (ARM Templates, Storage Accounts, Data Lake Storage, SQL DB, Cosmos DB, EventHubs, Function Apps, Log Analytics, Data Factory, Databricks, Polybase)
Implementing Security, Disaster Recovery, High Availability, Auditing, Monitoring and Alerting solutions in Azure
Automating tasks in Azure using Powershell / CLI
Predicting costs and optimizing spending in Azure
Message Queues (RabbitMQ, Kafka)
Python

Person Specifications:

Resilience
Teamwork
Technical Knowledge
Communication skills
Stress Tolerance
Please note we will apply relevance to our Talent Management and Talent Development Programme as part of our recruitment process.
Shortlisted candidates may need to complete an assessment.
This position requires trust and honesty it has access to customers financial details - therefore a credit and criminal record check will be conducted. The qualifications identified herein are an inherent job requirement; therefore, a qualification verification check will be done. By applying for this role, and supplying the necessary details, you hereby grant us permission to apply for these checks. This will be done in a confidential manner, and solely for the purposes of verification.

To view all current vacancies, please visit our website, www.digioutsource.com

Should you not hear from us within 2 weeks, please deem your application as unsuccessful.

The perfect place to work, play and grow!",3.9,"Digital Outsource Services
3.9",Cape Town,-1,1001 to 5000 Employees,1997,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
Data Engineer,-1,"At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes

Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.

Key Responsibilities

Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.

Key Traits

Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern

Position Requirements

2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.

Where will you work? This role will be based out of Durbanville, South Africa.",3.1,"Aculocity, LLC
3.1",Durbanville,-1,1 to 50 Employees,2006,Company - Private,IT Services,Information Technology,$1 to $5 million (USD),-1
Data Engineer,-1,"ENVIRONMENT:

A rapidly growing E-Commerce Platform seeks a highly talented Data Engineer to make an invaluable contribution to data democratisation and literacy vision by making accessible and easy-to-use data products and tools. You will require a Comp-Sci Degree or 3 years’ relevant industry experience, MySQL, PostgreSQL, Java, Python, in-depth understanding of OLAP, Data Marts, Star Scheme, Snowflake, be familiar with Jenkins, Travis, Circle CI, Docker, Kubernetes, experience with Kafka, Pub/Sub, Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks & significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing & Data Lake design and implementation and Lambda/Kappa architectures.

DUTIES:

Design, develop, test and maintain data architecture.

Prepare data for descriptive, predictive and prescriptive modelling.

Automate repetitive tasks and manual processes related with the data usage.

Optimize data delivery.

Design, develop and test large stream data pipelines to ingest, aggregate, clean, and distribute data models ready for analysis.

Ensure the highest standard in data integrity.

Leverage best practices in continuous integration and delivery.

Collaborate with other engineers, ML experts, analysts, and stakeholders to produce the most efficient and valuable solutions.

Implement features, technology, and processes that move us towards industry best practices, improving on scalability, efficiency, reliability, and security.

Operations and ownership of systems in production, responding to incidents.

REQUIREMENTS:

Qualifications –

Comp-Sci Degree or 3 years relevant industry experience.

Experience/Skills –

Open source relational database systems e.g. MySQL, PostgreSQL, etc.

Significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing, and Data Lake design and implementation and Lambda/Kappa architectures.

A thorough understanding of database and data warehousing principles e.g. OLAP, Data Marts, Star Schema, Snowflake, etc.

Java and Python.

Familiar with CI/CD tools such as Jenkins, Travis, Circle CI, etc.

Experience with Kafka, Pub/Sub, or other event-based systems.

Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks, etc.

Working in cloud environments and with containerisation frameworks, tools and platforms e.g. Docker, Kubernetes, GKE, etc.

A deep understanding of data pipelining, streaming, and Big Data technologies, methods, patterns, and techniques.

Troubleshooting complex database operations and performance issues.

Automating tasks using Shell Scripting or writing small applications.

ATTRIBUTES:

Works well with people and is passionate about helping people be their best.

A team player, an active listener, mentor, and able to communicate well.

Shows solid reasoning and decision making, with the ability to work under pressure.

Is passionate about technology, systems and data.

Is curious, always learning, and keeping up to date with the industry.

While we would really like to respond to every application, should you not be contacted for this position within 10 working days please consider your application unsuccessful.

COMMENTS:

When applying for jobs, ensure that you have the minimum job requirements. Only SA Citizens will be considered for this role. If you are not in the mentioned location of any of the jobs, please note your relocation plans in all applications for jobs and correspondence.",-1,Datafin IT Recruitment,Cape Town,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Cartrack is looking for passionate data science and engineering candidates that can join a growing team that is responsible for the intelligence and efficiency solution provision to over a million subscribers, many of whom are large fleets. We are in the midst of creating revolutionary platforms that will change the way that people interact with their vehicles.

You will have the opportunity to work with the very brightest global subject matter experts that are transforming the automotive industry across Fleet Management, Asset Management and Insurance Telematics solutions.

Get to know the role:

The role of a data engineer is a supporting one, but it is also an extremely vital one. As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements. We want to see candidates with mechanical tendencies and a desire to know how things work and to improve them.

The day-to-day activities:

Design, construct, install, test and maintain data management systems.
Build high-performance algorithms, predictive models, and prototypes.
Ensure that all systems meet the business/company requirements as well as industry practices.
Integrate up-and-coming data management and software engineering technologies into existing data structures.
Develop set processes for data mining, data modeling, and data production.
Create custom software components and analytics applications.
Research new uses for existing data.
Employ an array of technological languages and tools to connect systems together.
Install/update disaster recovery procedures.
Recommend different ways to constantly improve data reliability and quality.
Work on and maintain Data pipelines.

Requirements Essential:

At least 5 years’ proven experience as a Data Engineer, DevOps Engineer, Software Developer, or similar.
Proficient in Linux/Unix and shell scripting as well as in functional programming languages.
Expertise in setting up and explored with technologies such as Hadoop and Spark.
Bachelor’s degree in computer science, software/computer engineering, applied mathematics, or physics.",3.3,"Cartrack
3.3",Johannesburg,-1,501 to 1000 Employees,2004,Company - Private,Security Services,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Data Engineer,-1,"Data Engineers build and support data pipelines and datamarts built off those pipelines. Both must be scalable, repeatable and secure. The Data Engineer helps to facilitate gathering data from a variety of different sources, in the correct format, assuring that it conforms to data quality standards and assuring that downstream users can get to that data timeously. This role functions as a core member of an agile team. These professionals are responsible for the infrastructure that provides insights from raw data, handling and integrating diverse sources of data seamlessly. They enable solutions, by handling large volumes of data in batch and real-time by leveraging emerging technologies from both the big data and cloud spaces. Additional responsibilities include developing proof of concepts and implements complex big data solutions with a focus on collecting, parsing, managing, analysing and visualising large datasets. They know how to apply technologies to solve the problems of working with large volumes of data in diverse formats to deliver innovative solutions. Data Engineering is a technical job that requires substantial expertise in a broad range of software development and programming fields. These professionals have a knowledge of data analysis, end user requirements and business requirements analysis to develop a clear understanding of the business need and to incorporate these needs into a technical solution. They have a solid understanding of physical database design and the systems development lifecycle. This role must work well in a team environment.

Job Objectives

Work Complexity: * Architects Data analytics framework. * Translates complex functional and technical requirements into detailed architecture, design, and high performing software. * Leads Data and batch/real-time analytical solutions leveraging transformational technologies. * Works on multiple projects as a technical lead driving user story analysis and elaboration, design and development of software applications, testing, and builds automation tools.

Main Job Objectives: 1. Development and Operations 2. Database Development and Operations 3. Policies, Standards and Procedures 4. Communications 5. Business Continuity & Disaster Recovery 6. Research and Evaluation 7. Coaching/ Mentoring

Qualifications

Essential: 4 years Bachelors degree in computer science, computer engineering, or equivalent work experience AWS Certification at least to associate level

Experience

Essential:

5+ years Data engineering or software engineering

3-5 years demonstrated experience leading teams of engineers

2+ years Big Data experience

5+ years experience with Extract Transform and Load (ETL) processes

2+ years Could AWS experience

At least 2 years demonstrated experience with agile or other rapid application development methods - Agile exposure, Kanban or Scrum

5 years demonstrated experience with object oriented design, coding and testing patterns as well as experience in engineering (commercial or open source) software platforms and large scale data infrastructures.

Desirable:

5+ years Retail Operations experience

Knowledge and Skills

Essential: *Creating data feeds from on-premise to AWS Cloud (2 years) *Support data feeds in production on break fix basis (2 years) *Creating data marts using Talend or similar ETL development tool (4 years) *Manipulating data using python and pyspark (2 years) *Processing data using the Hadoop paradigm particularly using EMR, AWSs distribution of Hadoop (2 years) *Devop for Big Data and Business Intelligence including automated testing and deployment (2 years) * Extensive knowledge in different programming or scripting languages * Expert knowledge of data modeling and understanding of different data structures and their benefits and limitations under particular use cases.

Further technical skills required: * Capability to architect highly scalable distributed systems, using different open source tools. * Big Data batch and streaming tools * Talend (1 year) * AWS: EMR, EC2, S3 (1 year) * Python (1 year) * PySpark or Spark (1 year) - Desirable * Business Intelligence Data modelling (3 years) * SQL (3 years)",-1,Datonomy Solutions,Brackenfell,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We are assisting one of our clients that is based in Pretoria to fill a role of a Data Engineer

This is a 12 month contract role

Objective of this Scope of Work

The Data Engineer will drive improvement of the data management maturity levels and provide the necessary technical support within the company to support reliable and effective decision-making, appropriate usage and protection thereof.

Scope of Services Definition

The scope will include but will not be limited to:

ï†· To develop, construct, test and maintain architectures.

ï†· To ensure architectures will support the requirements of business.

ï†· To discover opportunities for data acquisition and sharing.

ï†· To develop data set processes for data modelling, mining and production.

ï†· To employ a variety of languages and tools to marry systems together.

ï†· To recommend way to improve data reliability, efficiency and quality.

ï†· To prepare data for use in predictive and prescriptive modelling.

ï†· To conduct research to answer industry and business questions.

ï†· To leverage volumes of data from internal and external to answer business questions.

ï†· To develop and manage stakeholder relations effectively to promote data management across the organisation and support reliable decision making and appropriate data usage.

ï†· To participate and provide technical support in cross organisational activities relating to any of the above mentioned data management activities.

ï†· To provide regular progress reports as per stakeholder requirements and present data management updates in various forums as required.

Minimum qualification Required:

ï†· A minimum of a Bachelors degree in Computer Science or Information Management OR equivalent;

ï†· A minimum of five to eight years experience in a data management environment",-1,HR Genie,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Our client based in the Northern Suburbs, is currently looking for a Data Engineer to join their team.

Responsibilities
Our client is a dynamic IT company that delivers value-driven IT solutions to the group. Our work lives revolve around our DNA. We take pride in our work, treat our colleagues, partners and our country with respect. We exercise collaborative decision-making and believe in having a balance in life. We do this all while having fun and enjoying what we do.

The primary focus of this position is to use technical skills to put software, systems and data together in a way that extracts meaningful insights from raw data. You will need to be helpful and supportive to your team and fellow developers. You join an energetic, focused and dynamic team.

Interact with clients to understand requirements and business problems/needs

Identify, analyse, visualise and understand supporting data to propose solid solutions

Create technical documentation for reference and reporting

Support existing solutions within GCP and Oracle

Doing standby on a rotating basis

Key Competencies and Qualifications

Matric

Tertiary qualification in IT

Preferred cloud experience in AWS/AZURE/GCP

At least 3 years of data warehouse ETL experience

Dimensional Modelling

Data analyses

Experience with data visualization and visualization tool(s)

Knowledge of the retail industry will be beneficial

Understanding and experience with version control SVN/GIT

Preferred – Korn shell scripting, Python/Java, SQL

Google Cloud Platform experience would be looked upon favourably

Having a broad understanding of different SDLC’s

Preferred agile experience

Strengths

The natural tendency to take ownership and responsibility

Strong problem solving, critical thinking, effective planning and organisational skills

Detail-oriented with excellent communication skills

You have a can-do attitude and positive outlook on life

Can cope under pressure

Curious and interested in analysing problems and possible solutions

Strong team player

Self-driven learner, passionate about new technology

Above all, be passionate about what you do

Should you wish to apply for the position, please apply directly via this job board, please ensure that you quote reference number 201620 subject heading or email body.

Please note that due to the high volume of CV's received; only shortlisted applicants will be contacted. Should you not receive communication from our offices within two weeks of submission please note that your application will not be considered for this position.

We will keep your CV on file and re-establish contact with you should opportunities in line with your expertise become available again.

Should you require any additional information give us a call on 021 012 5566.",-1,Surgo HR & Training,Cape Town,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We believe that our employees fuel our organization, essential to enable us to help our customers overcome their business challenges and achieve sustainable growth. As a result, we are committed to growing each individual and providing them with the challenges, feedback and support needed to achieve success in their career

If this sounds appealing, and like us, you get excited about data: its collection, storage, transformation or display, see if you’ve got what it takes to join our sought after DATA team.

Key Responsibilities And/or Outputs

You will represent IQbusiness at our customers, sometimes alone, and sometimes as part of an IQ team.

Providing a superior customer experience by building and maintaining relationships, working at customer offices, keeping data confidential
Design and develop – databases, SQL queries, stored procedures, reports, dashboards or integration solutions
Produce solutions for both real-time and batch environments
Test your work to ensure compliance
Solve problems, and do root cause analysis
Prioritize your workload
Assist in other areas relating to your true data function, such as data modeling, data and business analysts
Interact with a variety of individuals: senior, junior, technical and from business
Provide guidance to fellow colleagues, or even manage a team
Uphold the IQ values, which are to care, learn & share; innovate; deliver as well as to build, enhance and maintain relationships

Education

Matric pass
A tertiary qualification, preferably in an ICT relevant field
Appropriate Microsoft certifications are beneficial but not required

Requirements

3 - 6 years experience in the Data Engineering environments and technologies
Great communication skills
A passion for SQL, databases or reports
Can you write stored procedures, design complex queries and create views and triggers?
Are you able to work out the relationships in a data warehouse or the aggregation of a cube?
Do you extract and display useful information when you see patterns and trends in data?
Strong knowledge of the financial services industry, ideally in a consulting role
The use of data related software: databases, ETL and BI tools; report writing and analytical tools
We use a lot of Microsoft products. You may often be expected to use MS SQL Server, SSIS, SSRS, SSAS and Power BI to develop solutions
What other relevant software have you’ve used?
Ability to work in different project methodologies: Waterfall and/or Agile
Knowledge of full SDLC
Exposure to logical and physical data modeling

Equal Employment Opportunity

IQbusiness is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, citizenship, marital, domestic or civil partnership status, sexual orientation, or gender identity",3.7,"IQbusiness South Africa
3.7",Johannesburg,-1,1 to 50 Employees,-1,Company - Private,Consulting,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"We value a data engineer as someone who works behind the scenes to obtain, process and supply data via various methodologies and technologies, to various consumers, in ways and forms that makes sense and add value. This definition is very broad, as the field of data engineering is just as broad.

You may be the type of data engineer that develops API endpoints for the consumption of data by end users or even another data pipeline, or you may be the type of data engineer that develops highly distributed, high availability data processing pipelines in an effort to satisfy the need of the ever questioning data analysts and/or data scientists.

You have awesome knowledge about the following concepts
Data modelling
Relational data modelling in traditional relational database management systems. (Microsoft SQL Server, MySQL, PostgreSQL, etc)
Coercing unstructured and semi-structured data into a structured form.
Data pipelining knowledge - data extraction and transformation.
Data transformation knowledge for reporting and analytics purposes.
Knowledge of the MapReduce and related data processing paradigms would be a boon.
You have the following technical competencies
Writing SQL queries, that can relate, transform and aggregate data from many differing sources where natural keys may or may not exist.
Experience with writing data pipelines that move and transform data, for various uses.
Working knowledge of a general purpose programming language like Python would be a boost.
Working knowledge of columnar databases such as Google BigQuery, and SAP HANA would be a boost.
Working knowledge of highly distributed technologies such as Apache Hadoop or Apache Spark would be a boost.
Working knowledge of NoSQL technologies, such as Apache Solr would be a boost.
You have the following personal competencies
The ability to solve problems.
The ability to rotate around a problem, to see if solutions can be gained in different ways.
The ability to work in an ever changing, unstructured environment.
The ability to work as part of a team, with vastly differing skill sets and opinions.
The ability to contribute ideas to the quorum.
The ability to mentor and provide guidance for other team members.
A systems approach to thinking, as opposed to a siloed approach. The candidate needs to understand how their work affects the greater system.
The ability to work without supervision, and take accountability for the work they deliver.
The ability to liaise with a client, sifting through the fluff and extracting the actual requirements.
If this is you - apply now and we'll get in touch",-1,DotModus,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Data Engineer

Our client in the contact centre space is currently seeking a DATA ENGINEER that will work on the collecting, storing, processing, and analyzing of large datasets. The primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them. You will also be responsible for integrating them with the architecture used across the company.

Key Performance Areas:

Data reporting.
Implementing ETL processes.
Defining data retention policies.
Management of Customer Lead data.
Provision of data for advanced analytics.
Maintenance of internal client scorecards.
Assist team in resolving data-related support queries.
Optimize existing data processes through automation.
Assist with all data-related reporting and documentation.
Maintenance and optimisation of the Analytics database.
Provide technical support to and supervision of junior data administrators.
Continuous upskilling on new technologies, frameworks and market trends.
Monitoring performance and advising any necessary infrastructure changes.
Identifying, selecting and integrating any Big Data tools and frameworks required to provide real-time analytics.

Educational Requirements

IT related Degree or Diploma is a pre-requisite

Required Skills/Experience

ETL tools: Advanced SSIS
BI/Reporting : Qlikview/Power BI/ SSRS or SSAS
Programming languages: JAVA, C# , Python, SAS or R
Experience with NoSQL databases and/or campaign management tools will be advantageous.
Minimum 3 years’ applicable work experience in SQL, relational databases and data manipulation.
Experience in big data platforms (eg. Hadoop) or processing frameworks (eg. MapReduce/Spark) and querying tools (eg. Pig, Hive and Impala) will be highly beneficial.

Preferred Skills

Organizational skills
Experience in Attentional to detail.
Accountability is critical for this role.
Ability to work under pressure and meet deadlines.
Solid understanding of database design principles.
Should you not receive a response in 2 weeks please consider your application unsuccessful",-1,Rubik's Cubed Consulting,Durban,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"This well known company is looking for a Data Engineer. will be based in Rivonia
The ideal candidate will have strong experience in the following:
Data cleaning
SQL Export
Big data Sets

BSc Degree in Maths and Stats will be required
a min of 3 years experience.
Stable track record is required.

Send your Cv to marinda@prrrecruitment.co.za",-1,PRR Recruitment Services,Johannesburg,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Description

Position at Aculocity, LLC

At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes
Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.
Key Responsibilities
Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.
Key Traits
Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern
Position Requirements
2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.
Where will you work? This role will be based out of Durbanville, South Africa.",-1,GVW,Durbanville,-1,Unknown,-1,Unknown,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Information Technology, Gauteng JHB - Northern Suburbs

Market related - Market related Annually

An IT Consultancy Business based in Johannesburg is currently looking for a Business Intelligence Consultant / Data Engineering Consultant.

Requirements:

Extensive experience in data engineering
Experience in Business Intelligence, data and Power BI
Extensive experience in data governance and the Popi act
Ability to assess and make recommendations on data within the Popi act
Good understanding of T-SQL and query optimization, developing ETL strategies.
Good understanding with SQL Server 2008/2012, SSIS, SSRS and SSAS
Use SSIS to create ETL packages to validate, extract, transform, and load data into the data warehouse and data marts.
Deploy and configured the reports in the Report Server (SSRS).
Excellent experience in Tabular Modelling , PowerView, Qlikvie,w, and Power BI
Maintain ETL
Qlikview model
Create Drill-through, Drill-down, and Cross Tab Reports and Sub-Report using Report Definition Language (RDL).
Generate periodic reports based on the statistical analysis of the data using SQL Server Reporting Services (SSRS)
Advise and provide written technical documentation and recommendations

The information displayed above is not limited to advertisements. Please contact Thato for further information.

Please consider your application as unsuccessful if you have not received a response within 14 days of submitting your application. However, please keep a lookout on our website, www.bedifferent.co.za, for available positions that you may be suited for

Ad Visible Until: 29 October 2020
Ref: JHB005346/NL

Vacancy Type: Permanent",2.9,"Be Different Recruitment
2.9",Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Cloud Support Engineer (Big Data),-1,"ABOUT US

Amazon Web Services is the market leader and technology forerunner in the Cloud business. As a member of the AWS Support team you will be at the forefront of this transformational technology, assisting a global list of companies and developers that are taking advantage of a growing set of services and features to run their mission-critical applications. As a Cloud Support Engineer, you will act as the Cloud Ambassador across all the cloud products, arming our customers with required tools & tactics to get the most out of their Product and Support investment.

Would you like to use the latest cloud computing technologies? Do you have an interest in helping customers understand application architectures and integration approaches? Are you familiar with best practices for applications, servers and networks? Do you want to be part of a customer facing technology team helping to ensure the success of Amazon Web Services (AWS) as a leading technology organization?

If you fit the description, you might be the person we are looking for! We are a group of smart people, passionate about cloud computing, and believe that world class support is critical to customer success.

WHAT CAN YOU EXPECT FROM A LIFE AT AWS?

Every day will bring new and exciting challenges on the job while you:

· Learn and use groundbreaking technologies.
· Apply advanced troubleshooting techniques to provide unique solutions to our customers' individual needs.
· Interact with leading engineers around the world.
· Partner with Amazon Web Services teams to help reproduce and resolve customer issues.
· Leverage your extensive customer support experience to provide feedback to internal AWS teams on how to improve our services.
· Drive customer communication during critical events.
· Drive projects that improve support-related processes and our customers technical support experience.
· Write tutorials, how-to videos, and other technical articles for the developer community.
· Work on critical, highly complex customer problems that may span multiple AWS services.

WHY AWS SUPPORT?

· First and foremost this is a customer support role in The Cloud.
· On a typical day, a Support Engineer will be primarily responsible for solving customers cases through a variety of customer contact channels which include telephone, email, and web/live chat. You will apply advanced troubleshooting techniques to provide tailored solutions for our customers and drive customer interactions by thoughtfully working with customers to dive deep into the root cause of an issue.
· Apart from working on a broad spectrum of technical issues, an AWS Support Engineer may also coach/mentor new hires, develop & present training, partner with development teams on complex issues or contact deflection initiatives, participate in new hiring, write tools/script to help the team, or work with leadership on process improvement and strategic initiatives.
· Career development: We promote advancement opportunities across the organization to help you meet your career goals.
· Training: We have training programs to help you develop the skills required to be successful in your role.
· We hire smart people who are keen to build a career with AWS, so we are more interested in the areas that you do know instead of those you havent been exposed to yet.
· Support engineers interested in travel have presented training or participated in focused summits across our sites or at specific AWS events.
· As we operate on a follow-the-sun model, with Premium Support sites located globally, there is no after hours on-call or mandated overtime in this role.
· https://www.youtube.com/watch?v=GC3bWcFFZTo&t=24s



Basic Qualifications

The Big Data role supports our services that leverage data and produce business insights, which may include using Machine Learning/Artificial Intelligence (ML/AI). Helping our customers use and integrate Big Data services in what is arguably our industrys most exciting space. The portfolio of services covers EMR (Hadoop), DynamoDB (NoSQL), MangoDB, and Apache Cassandra.

· Advanced experience in Apache Hadoop, Apache Spark, Apache Hive, and Presto
· Advanced experience in DynamoDB or NoSQL technologies like MongoDB or Cassandra
· Advanced experience with System Administration with Linux (RHEL/CentOS) including Microsoft Active Directory, and LDAP integration.
· Experience with troubleshooting Kerberos Authentication problems.
· Experience with Network troubleshooting.
· Basic understanding of Machine Learning and statistics
· Experience with Java and Python and shell scripting
· Bachelors degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position



Preferred Qualifications

· Expert experience in the Hadoop Ecosystem including Apache Spark and Presto
· Expert experience in NoSQL
· Expert experience with blockchain technologies like Etherium Expert experience in data Data Lake architecture and administration
· Experience managing full application stacks from the OS up through custom applications
· Prior work experience with AWS - any or all of EC2, VPC, S3, RDS, EMR, Glue, SageMaker
· Excellent knowledge of Hadoop architecture, administration and support
· Expert understanding of distributed computing principles and their application in the cloud
· Good understanding of distributed computing environments Lead technical discussions on big data systems architecture and design
· Strong analysis and troubleshooting skills and experience
· AWS Certified Solutions Architect
· AWS certified Big Data Specialty
· Masters degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity and Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Response Center Engineer,-1,"Job Title
Response Center Engineer
Job Description


Philips is a world leading health technology company with a vision to make life better for people worldwide through meaningful innovation. Making good on this promise depends on our passionate, inspirational, collaborative and diverse team. We have over 80,000+ brilliant people around the world but are always looking for more. Like-minded, motivated, focused minds to join us in creating a healthier, more connected society while transforming themselves personally and professionally.

As a CCC Coordinator - Response Center Engineer you will have the opportunity to process customer calls and be responsible for screening and diagnosing professionally Healthcare equipment to support customers and colleagues remotely with solving technical issues and ensuring maximum customer satisfaction

You are responsible for:
Diagnose healthcare equipment to the quality standards set by Philips Healthcare (PH) remotely by interviewing customers or colleagues by telephone or by remotely logging in to the system
Advise Customer Care Center Coordinators and District Operations Managers and / or Team Leads about the best follow-up w.r.t. technical state of the diagnosed healthcare equipment
Advise the Customer Care Center Coordinators or Field Services Engineers about required spare parts and resources
Responsible for planning engineers related to Modality responsibility.
Responsible for coordination between CCC, CUSTOMER, Spare parts AND Engineer.
Responsible to drive Remote and FTR KPI’s to targets respectively 40% and 85%.
Will require minimal field work to keep abreast of technical capabilities.
Take calls from customers and make sure they are processed in the CCC ERP on timely manner including all relevant data
Support Field Services Engineers in the field with technical knowledge
Escalate technical issues to the Technical Support Specialist
Escalate technical issues to Business Unit support after consultation of the Technical Support Specialist
Monitor critical functions of the equipment’s in the IB and environmental conditions including RSN and True reachability.
Lead the planning and implementation of FSN’s and FCO’s accelerating remote implementation where applicable.
Submit timely and accurate service data, job sheets, reports, expense claims, radiation film badges, field problem reports and other paperwork as assigned
Keep abreast of new technologies likely to affect PH range of products
Use company property with care to ensure optimal results with minimal operational costs
Be a professional representative for PH with respect to customer problems, ensuring personal acceptability by the customer in behavior in accordance with PH policy and targets
Conform to PH safety standards including health and safety regulations and in the event of hazards or accidents to take immediate control of the situation and involve the Operations Manager and / or the responsible person to handle properly confidential issues according Philips standards and to act according General Business Principals
Follow all quality standards within the frame of valid PH business policies
Follow the company quality regulations (ISO 9001; PQA; TQM) and internal directives and procedures
You are a part of the dynamic South Africa Customer Care Centre Team .You will be reporting to the Customer Care Center Manager.

Requires a pleasant, assertive individual you can work very well in a team setting, a dynamic environment that requires flexibility and creativeness to achieve goals.

To succeed in this role, you should have the following skills and experience:
Degree level education or equivalent
Experience in maintenance and troubleshooting of technical complex systems
Fluent in English, verbal and written in addition to local language
In return, we offer you the unique combination of a critical and challenging role and a creative and empowering office environment. You will be actively encouraged to make improvements, establish best in class service and have a direct impact on the success of Philips on a daily basis.

Employment Equity

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply. Only apply for this role if you are a South African Citizen by birth or Naturalization prior to the 27 April 1994.

Why should you join Philips?

Working at Philips is more than a job. It’s a calling to create a healthier society through meaningful work, focused on improving 3 billion lives a year by delivering innovative solutions across the health continuum. Our people experience a variety of unexpected moments when their lives and careers come together in meaningful ways. Learn more by watching this video.

To find out more about what it’s like working for Philips at a personal level, visit the Working at Philips page on our career website, where you can read stories from our employee blog. Once there, you can also learn about our recruitment process, or find answers to some of the frequently asked questions.

Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.9,"Philips
3.9",Johannesburg,-1,10000+ Employees,1891,Company - Public,Health Care Services & Hospitals,Health Care,$10 to $25 million (USD),-1
Software Development Engineer - EC2 Placement,-1,"Build the systems that optimize how EC2 matches requests for Instances with the underlying compute capacity. EC2 Placement is seeking talented engineers to build the online and offline optimization systems for compute workload scheduling, and the customer capabilities to better manage those workloads. Amazon EC2 provides on-demand scalable compute capacity, and powers some of the largest services in the world. You will collaborate with a top-tier community of engineers to build systems to improve how customers are able to access EC2 compute resources.

The successful candidate will have strong software engineering experience, with a passion for thinking about, building and testing distributed systems. You have an interest in how Machine Learning and other optimization techniques can be applied to large-scale problems. You have demonstrated experience working with a team to design, build and operate large-scale systems. With strong engineering fundamentals, an analytical and data-driven approach to your work, and strong communication skills, you have the ability to collaborate well to deliver results. We move fast and work together on small teams to solve big problems.

If this opportunity sounds interesting, we would love to talk to you more about our work and the vibrant culture at AWS in Cape Town.

Basic Qualifications

· Degree in Computer Science or related field, or equivalent working experience
· 3+ years of industry experience in a software development environment
· Strong Computer Science fundamentals, including data structures, object-oriented design, algorithm design, problem solving, and complexity analysis.
· Proficiency in at least one modern programming language, such as Java, C#, Python, Scala, Kotlin

Preferred Qualifications

One or more of the following help you stand out:
· Demonstrated results designing, building and operating high-performance distributed systems in large-scale Linux environments
· Role model in writing high-quality, maintainable and secure code, mentoring others, and helping teams sharpen their development processes
· Ability to work effectively across teams to deliver results, with strong verbal and written communication skills
· Experience working with machine learning systems

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer - PBB IT,-1,"Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose


This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes
Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems
Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions
Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.

Research and best practices
Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development
Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.
Preferred Qualification and Experience
Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Aws Data Platform Engineer,-1,"Aws Data Platform Engineer

Posting Country:

South Africa

Date Posted:

15-Oct-2020

Full Time / Part Time:

Full Time

Contract Type:

Permanent

Joining Vodacom is more than a job, what we do matters. We don’t just carry minutes, texts and data – we carry people’s lives. And that’s a huge responsibility. If you think for a minute about the people you rely on…the likelihood is they rely on us.

Customers are at the heart of everything we do and we want to make a difference to the lives of our customers, and the communities in which we live and work. We support our people to give something back to the causes that mean the most to them through helping them give time and money to the charities they love.

And what’s it like to work here? We have created an environment where you can look forward to coming to work and are empowered to be at your best. We offer flexibility in how you work that helps you do your job in a way that suits you, opportunities to help you grow and progress throughout your career and a choice of benefits to suit your lifestyle.

Role Purpose
The H Band AWS Data Platform Engineer position is based within the Technology Business Unit.

The AWS Data Platform Engineer will be responsible for all Database services such as RDS, DynamoDB, etc. Should be able to migrate any databases from anywhere to AWS using any third-party tools or AWS database migration tool. Should also have understanding or expertise in creating data warehouses and data lake solutions on AWS.
Your responsibilities will include:
Apply practical knowledge of relational database design and usage with customers
Perform workload analysis and undertake performance tuning, as well as performance benchmarking in customer environments.
To develop state of the art solutions which are technically sound.
To provide a high-quality service to the Enterprise Cloud Services clients i.t.o. consultancy, solutions and delivery.
Commitment to team success and positive team dynamics including mentoring of other team members.
Passion for growing and applying technical skills in service to customers.
Be a trusted infrastructure advisor by providing objective, practical and relevant ideas, insights and advice.
Work collaboratively with consulting partners and technology teams to ensure high quality of solution delivery.
Encourage best practice and knowledge sharing with partners and cross-functional groups
Manage the overall database design and delivery of solutions.
Ability to make recommendations as they pertain to improvements in support/development initiatives and facilitate implementation with partners and cross-functional groups within the Business.
Participate in high level database solution definition and design during the implementation phase with the goal of providing reliable, stable and operationally sound applications that meet the Business requirements.
Ability to understand and translate business requirements into technical specifications
The ideal candidate will have:
A minimum of 3 years of industry related experience of which 1 year must be within a complex hosting environment.
Certifications in Database design, system architecture or cloud technologies.
Demonstrate knowledge of database systems internals including storage layouts and distributed databases/MPP architectures
Advanced SQL coding, tuning and query optimization.
Experience designing and leading database performance benchmarks.
Good knowledge of the different AWS services
Knowledge of cloud networking architecture, cloud operations, security, automation and orchestration.
Knowledge of database internals as it relates to query and system performance and tuning.
Understanding of overall system architecture, scalability, reliability, and performance in a database environment.
Excellent teamwork, time-management and organizational skills.
Perform other duties as deemed necessary and assigned by the customer and management
Strong interpersonal skills and problem-solving abilities.
Excellent documentation, communication and interpersonal skills.
Excellent analytical and problem-solving abilities.
Closing date for applications: Monday, 13 April 2020

The base location for this role is Vodacom World, Midrand

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply.
Vodacom is committed to an organisational culture that recognises, appreciates and values diversity & inclusion.

Commitment from Vodacom

Vodacom is committed to attracting, developing and retaining the very best people by offering a flexible, motivating and inclusive workplace in which talent is truly recognized, developed and rewarded. We believe that diversity plays an important role in the success of our business and we are committed to creating an inclusive work environment which respects, values, celebrates and makes the most of people’s individual differences - we are not only multinational but multicultural too. At Vodacom you will have access to our excellent flexible benefits programme that you would expect from any global company.",3.9,"Vodafone
3.9",Midrand,-1,10000+ Employees,1982,Company - Public,"Cable, Internet & Telephone Providers",Telecommunications,$10+ billion (USD),-1
Data Engineer Azure Data Factory,-1,"Enthuzex is looking for a motivated Lead Data Engineer to contribute towards the success of our Data and Analytics Technology initiatives. This is a hands-on technical role and this person will be responsible for the development and build of scalable solutions as it relates to the architecture strategies, data standards, digital data management, data integration, tools, and technology. The right candidate will play a deep dive hands-on critical development role in the digital transformation and in shaping how we acquire, ingest, transform and deliver data through the digital consumer channels.

Responsibilities:

Architect, design, develop and engineering end-to-end data pipelines across multiple data sources and systems of record.
Ensure data quality, integrity, security and completeness throughout the data lifecycle
Develop, design data models, data structures and ETL jobs for data acquisition and manipulation purposes
Develop deep understanding of the data sources, implement data standards, maintain data quality and master data management
Developing data services and API
Work closely with the cloud service providers to ensure completeness and alignment with the service offerings
Manage and maintain cloud based data and analytics platform
Deep understanding of the cloud offerings and engage in quick proof of concepts and proof of value in prototyping data and analytics solutions and derive viability
Ability to interact with the business stakeholders to understand requirements and translating into technology solutions

Expirience:

Experience in Cloud platform AWS or Azure eco-system. (Azure preferred)
Data Engineering/Development experience with SQL (Oracle, SQL Server, MySQL)
Strong development background creating pipelines and complex data transformations and manipulations using one of the languages Python, Java, R, or Scala with Databricks/Spark
Experience in NoSQL Databases and Big data technologies including Hadoop
Experience with API / RESTful data services
Worked on real-time data capture, processing and storing using technologies like Azure Event Hubs and Analytics
Experience working with different data storage options including AWS S3, Azure BLOB storage etc.
Understanding of different data formats including Parquet, Avro, CSV, ORC etc.
Prior experience with MPP databases and maintain large amount of data processing
Experience with Azure Data Factory and Azure Data Catalog is a big plus and mandatory
Experience with Microsoft/Azure ETL solutions and business Intelligence technologies is a big and mandatory
Past working experience on a fast paced and agile environment
Perform ongoing monitoring, automation and refinement of data engineering solutions
Experience in leading high visibility transformation projects that interacts with multiple business lines
Build and meet project timelines and manage delivery commitments with proper communication to management

Qualifications

Bachelor’s degree with 4+ years of relevant experience
Willingness to learn new technologies and thrive in an extremely fast paced environment
Team player and easy to work with.

Applicants must demonstrate their ability to master new enterprise level technologies. Successful applicants will exemplify Enthuzex ethical principles of uncompromising integrity, respect for others, and accountability for decisions

send cv's info@enthuzex.co.za",-1,Enthuzex,Leslie,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Scientist,-1,"The world is changing.

We all want something different.

At Luno, we see you as an individual.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the world, and to do so, we need the best team on board for our mission.

A bit about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 3 million customers across 40 countries.
We are Series B funded, backed by Balderton Capital and the Naspers Group.
Our platform has processed over 8 billion dollars since we've launched
We're proud to be one of the world's most international cryptocurrency teams from 26 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
The role in a nutshell:

Identifying opportunities in the business that could benefit most from cognitive applications, as well as building and enhancing organisational capabilities for deriving value from multiple data sources using data science.

What we'd like you to have:
Bachelor's degree or higher in the natural sciences or technical fields such as Mathematics, Statistics, Computer Science, Engineering or Economics
Enthusiasm to work in the cryptocurrencies space
Advanced SQL skills
Solid understanding of exploratory data analysis, predictive analytics, and optimisation using Python, R, Matlab, RapidMiner, KNIME or other data science-oriented platforms
Proficiency in the use of data science and machine learning domain-specific languages such as ""Caret"" and the ""Tidyverse"" suite of tools in R, or ""Pandas"" in Python
Strong interpersonal and communication skills
Communicating data insights using storytelling narratives
Ability to work independently, as well as within and across teams
Ability to successfully complete projects with large and/or incomplete data sets
More about what you'll be doing:
Optimising product performance by tracking and analysing customer behaviour on web and app, in collaboration with software engineers and product designers
Providing the business with reports and dashboards, on key performance metrics
Developing metrics to accurately assess the health of our Exchange platform
Comparative data-driven analysis of our Exchange against alternative platforms
Formulating business requirements into analytical objectives
Designing and running experiments to test hypotheses
Hacking through complex business problems using advanced data analysis to provide insights and recommendations
Building, maintaining, and optimising decisioning systems using advanced statistical and predictive modelling techniques
What will set you apart:
An advanced degree in Mathematics, Statistics, Computer Science or related field
At least 3 years' experience working in a similar role
A basic understanding of trading in financial markets
Experience working with a data analytics and visualisation platform such as Tableau, Cognos, QlikView, or Looker
Familiarity with using Google Analytics to understand customer behaviour
Solid knowledge of statistical and machine learning techniques
Familiarity with modern distributed data storage and processing systems such as Amazon Redshift, Big Query, Snowflake, Databricks and Apache Spark
You can gather and synthesise facts, theories, trends, patterns, inferences, and key issues in complex and variable situations
Ability to diagnose problems using formal problem-solving tools and techniques from multiple angles to generate multiple possible solutions
A sense of anticipating long-term problem areas and associated risk levels with objective rationale
Remote Life at Luno

If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
You'll be able to continuously upskill yourself with access to free online learning via MyAcademy, an international teaching marketplace with over 100000 courses from Harvard and other leading providers + share knowledge with your peers.
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity and paternity leave, and you can even take paw-ternity leave for your furry friend.
Annual Inspiration Day! Make time for that pottery course or spa day you've always wanted to do.
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"EY is a global leader in
assurance, tax, transaction and advisory services. Technology is at the heart
of what we do and deliver at EY. Technology solutions are integrated in the
client services we deliver and are key to our innovation as an organization.

Fueled by
strategic investment in technology and innovation, Client Technology seeks to
drive growth opportunities and solve complex business problems for our clients
through building a robust platform for business and powerful product engine
that are vital to innovation at scale. As part of Client Technology, you’ll
work with technologists and business experts, blending EY’s deep industry
knowledge and innovative ideas with our platforms, capabilities, and technical
expertise. As a catalyst for change and growth, you’ll be at the forefront of
integrating emerging technologies from AI to Data Analytics into every corner
of what we do at EY. That means more growth for you, exciting learning
opportunities, career choices, and the chance to make a real impact.

The selected
candidate
Develops
large and complex data architecture, composed of models, policies, rules or
standards that govern which data is collected and how it is stored, arranged,
integrated and put to use in data systems, including the design, build and
management of data infrastructure to address business requirements
Creates
sound use case driven roadmaps, depicting data architecture as-is and to-be
capabilities with the business by engaging with multidisciplinary teams, and by
identifying, managing and mitigating risk
Develops
relationships across the business to understand data requirements, applies deep
technical knowledge of data management to solve business problems in areas
where solutions may not currently exist, necessitating new solutions/ways of
working/technologies and proactively articulating these to the business
Review,
identify the latest emerging technologies, augmenting by services from the
leading cloud providers to solution and recommend the best next generation data
platform value driven approach for our clients
Your Key Responsibilities Include
Create
and maintain conceptual, logical and physical database models
Document
functional requirements and system specifications into the data architecture
and detailed design specifications for current and proposed designs
Document
and adhere to development standards and best practices in database designs
Maintain
highly effective and consistent communication within the team, peers, and the
leadership team
Reverse
engineer SQL code and modify it to solve problems/issues
Contribute
to the definition and implementation of data governance practices
Design
both data structures and data integration practices
Work
closely with the infrastructure teams to create a physical environment to
support data services
Evaluate
new and existing (internal and external) technologies and services in support
of data services and data analytics objectives
Skills And Attributes For Success
Understanding
of business process reengineering and business modeling concepts, business
systems development and analysis
Hands-on
experience in designing and implementing hybrid cloud and on-prem solutions
Experience
working with the latest versions of SQL Server
Experience
applying SAFe/Scrum/Kanban methodologies
Ability
to exercise judgment in solving technical, operational, and organizational
challenges
Expert
programming, performance tuning and troubleshooting skills, using the latest
popular programming languages for example python
Demonstrate
proactive approach to identifying issues and presenting solutions and options,
and where appropriate, leading to resolution
Minimum Qualifications
5+ years
demonstratable work experience as a Data Architect using data modeling tools
2-3 years
SQL coding experience on large projects
Must
possess expert SQL programming, performance tuning and troubleshooting skills
Create
database objects and SQL scripts
Understand
and developed data pipelines
Know how
to deformalize data for data science models
Experience
in python, spark and notebooks
Experience
designing data warehousing solutions
Experience
designing next generation data platforms utilising cloud services
In-depth
understanding of database structure principles
Seamlessly
able to translate business requirements to technology requirements
What We Look For
Strong
analytical skills and problem-solving ability
A
self-starter, independent-thinker, curious and creative person with ambition
and passion
Excellent
inter-personal, communication, collaboration, and presentation skills
Customer
focused
Excellent
time management skills
Positive
and constructive minded
Takes
responsibility for continuous self-learning
Takes the
lead and makes decisions in critical times and tough circumstances
Attention
to detail
High
levels of integrity and honesty
Curious
about new emerging technology
About EY
As a global leader in assurance, tax, transaction and consulting
services, we’re using the finance products, expertise and systems we’ve
developed to build a better working world. That starts with a culture that
believes in giving you the training, opportunities and creative freedom to make
things better. Whenever you join, however long you stay, the exceptional EY
experience lasts a lifetime.",3.8,"EY
3.8",Johannesburg,-1,10000+ Employees,1989,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Architect - Principal,-1,"We are looking for Principle Data Architect to join our Engineering team in Cape Town.

The world is changing.
We all want something different.
At Luno, we see you as individuals.

Together, we are upgrading the world of work to unleash the potential within and empower you to become the best possible version of yourself.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the financial landscape, and to do so, well we need the best team on board for our mission. In short, to achieve our goals, we need rockstars. As simple as that.

A little about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 5 million customers across 40 countries.
We're part of the Digital Currency Group, a group of companies driving progress in the cryptocurrency and blockchain space that includes Grayscale, Genesis, Coindesk and Foundry Services
Our platform has processed over $8 billion to date
We're proud to be one of the world's most international cryptocurrency teams from 43 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
How we work


Our engineering team (currently ~100 engineers) is split into organisations which we call Fleets. Each Fleet focuses on a core customer journey (onboarding, security, payments, support, new business, growth and marketing etc.). Each of these fleets contains multiple smaller teams called Pods, each of which focuses on a specific aspect of the product.

Pods will include a product owner, product designer, back-end engineers, Android, iOS and Web developers, who each bring a unique perspective to the problem you are all contributing towards.

We're agile, use scrum, continuous integration and continuous delivery, deploying to production every single day.

We're building teams to help us succeed in our mission to upgrade the world to a better financial system. You'll be joining a group of highly motivated software engineers who you'll work collaboratively with across our pods.

As a fast-growing company with offices around the world, you'll immediately see how your contributions directly impact both our internal users and client experience. Many of the problems we are solving result in trail blazing solutions which can't be found on Stack Overflow; so we're looking for engineers who flourish working in a complex domain.

In your first six months, you will:


...start at Luno by learning our processes, meeting the wider team and starting our engineering on-boarding program. After getting comfortable with the basics, you'll start learning our idiomatic patterns in a safe, easy-to-follow way - by building your own toy micro services. You'll get to practice how we do design docs, code reviews, deployments, events, logging and monitoring.

You'll meet the Pod(s) you'll be working with and quickly align on the teams' current OKRs and product roadmap. We succeed as a team, so we will provide you with regular feedback from your manager and peers and will encourage you to do the same.

What you'll do:
Work closely with our data science and platform teams on projects introducing new streams of data into our data lake
You will get to bring new ideas on how to further develop and innovate our data solutions and how to expose that data to the business
Accountable and Responsible for the design and architecture of Data systems that are robust and scalable.
Work in an Agile/Scrum framework or Agile mindset
Data backup/recovery and storage
Pick-up and learn new concepts, in both engineering and product, and be able to apply that knowledge quickly.
The ideal candidate for this role will have:
7+ years' experience in maintaining scalable data solutions and/or you are passionate about it
Ability to understand, communicate and advocate between build vs buy
Proven track record of setting up, restructuring and maintenance of databases
You know your way around ETL and you have experience with SQL
Experience in the AWS Data stack (RedShift,DynamoDB, Amazon RDS)
Familiarity with integrating data stores with BI platforms such as Looker, Tableau, or Power BI
You have experience with the concepts of CI/CD
Coding skills in e.g. Go, Python
Bachelor's degree in a related field preferred
AWS Certified DataOps Administrator
Be friendly, transparent, articulate and driven to succeed
Basic knowledge of and passion for digital currencies like Bitcoin
A work permit for South Africa if you are not a South African citizen
Don't be put off if you don't tick all of the boxes – they're a guide based on what we'd love to see but we appreciate that excellent software engineers have diverse backgrounds.

Remote Life at Luno


If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity / paternity and even (yes, you are reading it correctly) paw-ternity for your furry friend..
Annual Inspiration Day.. like that pottery course you've always been meaning to do!
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. You'll need to hold the legal right to work in South Africa already as we cannot provide visa sponsorship.

Be part of the change!",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer - EC2 Capacity Data Analytics,-1,"EC2 Capacity Data Analytics (CDA) team is looking for a Data Engineer to join our team.

Our team is part of the EC2 Capacity Engineering organization, which is responsible for providing the elasticity EC2 customers need to scale up/down compute resources in a cost-efficient manner. We predict customer usage across thousands of configuration combinations to deliver exactly what our customers require in just the right amount of time with just the right amount of capacity.

As a Data Engineer, you will build the ETL and analytics solutions for our internal customers to answer questions with data and drive critical improvements for the business. You will use best practices in software engineering, data management, data storage, data compute, and distributed systems. On any given day, we use Python, Scala, Java, SQL, Lambda, CloudFormation, Redshift and Glue as well as other public AWS services and a host of Amazon internal tools. We dont expect you to be an expert in, or necessarily even be familiar with all of the technologies listed above, but we do expect you to be excited to learn about them.

This position involves on-call responsibilities, typically for one week every two months. Our team is dedicated to supporting new team members. We care about your career growth, we try to assign projects and tasks based on what will help each team member develop into a more well-rounded engineer and enable them to take on more complex tasks in the future.

Our team values work-life balance and we are flexible when people occasionally need to work from home.

Job Duties
Develop and maintain automated ETL pipelines for big data using languages such as Scala, Spark, SQL and AWS services such as S3, Glue, Lambda, SNS, SQS, KMS. Example: ETL jobs that process a continuous flow of JSON source files and output the data in a business-friendly Parquet format that can be efficiently queried via Redshift Spectrum using SQL to answer business question.

Develop and maintain automated ETL monitoring and alarming solutions using Java/Python/Scala, Spark, SQL, and AWS services such as CloudWatch and Lambda.

Implement and support reporting and analytics infrastructure for internal business customers using AWS, services such Athena, Redshift, Spectrum, EMR, and QuickSight.

Develop and maintain data security and permissions solutions for enterprise scale data warehouse and data lake implementations including data encryption and database user access controls and logging.

Develop and maintain data warehouse and data lake metadata, data catalog, and user documentation for internal business customers.

Develop, test, and deploy code using internal software development toolsets. This includes the code for deploying infrastructure and solutions for secure data storage, ETL pipelines, data catalog, and data query.


Basic Qualifications

· Bachelors degree in Computer Science or related technical field, or equivalent work experience.
· 4+ years of overall work experience including Software Engineering, Data Engineering, Database Engineering, Business Intelligence.
· Experience with AWS technologies stack including Lambda, Glue, Redshift, RDS, S3, EMR or similar big data solutions stack

Preferred Qualifications

· Demonstrate efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data.
· Demonstrable proficiency in distributed systems and data architecture; design and implementation of batch and stream data processing pipelines; knows how to optimize the distribution, partitioning, and MPP of high-level data structures.

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer,-1,"Our client based in Johannesburg is urgently looking for a Data Engineer to be on a 3 months contract
Build data pipelines, experience in new tech like nifi, kafka, python

Joburg based, open to EE, 3 month contract with the option to extend, must be available at short notice",-1,EQplus,Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Overview
Job ID: 51456
Job Sector: Information Technology and Services
Country: South Africa
Region/State/Province/District: Gauteng
Location: Johannesburg

Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose

This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes

Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems

Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions

Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.
Research and best practices

Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development

Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.

Preferred Qualification and Experience

Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry

Knowledge/Technical Skills/Expertise

Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision

PLEASE NOTE: All our recruitment and selection processes comply with applicable local laws and regulations. We will never ask for money or any form of payment as part of our recruitment process. If you experience this, please contact our Fraudline on +27 800222050 or forward to TransactionFraudOpsSA@standardbank.co.za",4.1,"Standard Bank
4.1",Johannesburg,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"About us

At PBT Group we pride ourselves on being a Data Specialist organisation. With 20 years of experience in 27 countries over 3 continents, our team of 550 consultants have implemented more than 700 projects.",4.3,"PBT Group
4.3",Johannesburg,-1,Unknown,-1,Company - Private,Accounting,Accounting & Legal,Less than $1 million (USD),-1
Data Engineer,-1,"Kick-start your career in the online gaming world and experience the very latest in technology and innovation.

The Department:

Our mission is to provide our customers with the best online betting experience and share the thrill of gaming with them. Data is at the very heart of our business and is vital in everything we do.

Our cross-functional Data team has a big and exciting challenge ahead. We are in the process of re-platforming our traditional, on-premises RDBMS environment to a new microservice architecture in the cloud. We’re making use of the diverse set of data technologies in Microsoft Azure to offer new services, reporting structures and real-time data pipeline while serving the day-to-day requirements of a rapidly growing, data-hungry organisation.

Purpose of the Role:

This is an excellent opportunity for an individual who is looking to gain new skills. We are committed to creating a culture of learning and regularly run proof of concepts, provide internal demos, manage workshops and attend external conferences. Our data team has a wide range of skills including development for highly transactional RDBMS systems, data warehousing, data science and cloud technologies and we are always working to raise everyone’s game.

Duties include, but not limited to:

Work as part of an agile Data Engineering Team
Development of greenfield projects in Azure
Develop and maintain on-premises RDBMS/DW systems
Create robust ETL services and real-time data pipelines
Build and maintain Continuous Integration and DevOps pipelines
Test-driven development and pair programming with colleagues

Essential Criteria:

C#, .Net, Visual Studio
Git, Azure DevOps
NoSQL development (CosmosDB)
Demonstrable understanding of MS SQL Server in a highly transactional environment
Demonstrable understanding of development in Microsoft Azure
Able to understand query plans and identify performance bottlenecks
Test/Business-Driven Development
Building Continuous Integration/Deployment pipelines
Communicate effectively with both technical and non-technical stakeholders

Desirable Criteria:

Implementing Data Storage and Processing solutions in Azure (ARM Templates, Storage Accounts, Data Lake Storage, SQL DB, Cosmos DB, EventHubs, Function Apps, Log Analytics, Data Factory, Databricks, Polybase)
Implementing Security, Disaster Recovery, High Availability, Auditing, Monitoring and Alerting solutions in Azure
Automating tasks in Azure using Powershell / CLI
Predicting costs and optimizing spending in Azure
Message Queues (RabbitMQ, Kafka)
Python

Person Specifications:

Resilience
Teamwork
Technical Knowledge
Communication skills
Stress Tolerance
Please note we will apply relevance to our Talent Management and Talent Development Programme as part of our recruitment process.
Shortlisted candidates may need to complete an assessment.
This position requires trust and honesty it has access to customers financial details - therefore a credit and criminal record check will be conducted. The qualifications identified herein are an inherent job requirement; therefore, a qualification verification check will be done. By applying for this role, and supplying the necessary details, you hereby grant us permission to apply for these checks. This will be done in a confidential manner, and solely for the purposes of verification.

To view all current vacancies, please visit our website, www.digioutsource.com

Should you not hear from us within 2 weeks, please deem your application as unsuccessful.

The perfect place to work, play and grow!",3.9,"Digital Outsource Services
3.9",Cape Town,-1,1001 to 5000 Employees,1997,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
Data Engineer,-1,"At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes

Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.

Key Responsibilities

Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.

Key Traits

Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern

Position Requirements

2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.

Where will you work? This role will be based out of Durbanville, South Africa.",3.1,"Aculocity, LLC
3.1",Durbanville,-1,1 to 50 Employees,2006,Company - Private,IT Services,Information Technology,$1 to $5 million (USD),-1
Data Engineer,-1,"ENVIRONMENT:

A rapidly growing E-Commerce Platform seeks a highly talented Data Engineer to make an invaluable contribution to data democratisation and literacy vision by making accessible and easy-to-use data products and tools. You will require a Comp-Sci Degree or 3 years’ relevant industry experience, MySQL, PostgreSQL, Java, Python, in-depth understanding of OLAP, Data Marts, Star Scheme, Snowflake, be familiar with Jenkins, Travis, Circle CI, Docker, Kubernetes, experience with Kafka, Pub/Sub, Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks & significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing & Data Lake design and implementation and Lambda/Kappa architectures.

DUTIES:

Design, develop, test and maintain data architecture.

Prepare data for descriptive, predictive and prescriptive modelling.

Automate repetitive tasks and manual processes related with the data usage.

Optimize data delivery.

Design, develop and test large stream data pipelines to ingest, aggregate, clean, and distribute data models ready for analysis.

Ensure the highest standard in data integrity.

Leverage best practices in continuous integration and delivery.

Collaborate with other engineers, ML experts, analysts, and stakeholders to produce the most efficient and valuable solutions.

Implement features, technology, and processes that move us towards industry best practices, improving on scalability, efficiency, reliability, and security.

Operations and ownership of systems in production, responding to incidents.

REQUIREMENTS:

Qualifications –

Comp-Sci Degree or 3 years relevant industry experience.

Experience/Skills –

Open source relational database systems e.g. MySQL, PostgreSQL, etc.

Significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing, and Data Lake design and implementation and Lambda/Kappa architectures.

A thorough understanding of database and data warehousing principles e.g. OLAP, Data Marts, Star Schema, Snowflake, etc.

Java and Python.

Familiar with CI/CD tools such as Jenkins, Travis, Circle CI, etc.

Experience with Kafka, Pub/Sub, or other event-based systems.

Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks, etc.

Working in cloud environments and with containerisation frameworks, tools and platforms e.g. Docker, Kubernetes, GKE, etc.

A deep understanding of data pipelining, streaming, and Big Data technologies, methods, patterns, and techniques.

Troubleshooting complex database operations and performance issues.

Automating tasks using Shell Scripting or writing small applications.

ATTRIBUTES:

Works well with people and is passionate about helping people be their best.

A team player, an active listener, mentor, and able to communicate well.

Shows solid reasoning and decision making, with the ability to work under pressure.

Is passionate about technology, systems and data.

Is curious, always learning, and keeping up to date with the industry.

While we would really like to respond to every application, should you not be contacted for this position within 10 working days please consider your application unsuccessful.

COMMENTS:

When applying for jobs, ensure that you have the minimum job requirements. Only SA Citizens will be considered for this role. If you are not in the mentioned location of any of the jobs, please note your relocation plans in all applications for jobs and correspondence.",-1,Datafin IT Recruitment,Cape Town,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Cartrack is looking for passionate data science and engineering candidates that can join a growing team that is responsible for the intelligence and efficiency solution provision to over a million subscribers, many of whom are large fleets. We are in the midst of creating revolutionary platforms that will change the way that people interact with their vehicles.

You will have the opportunity to work with the very brightest global subject matter experts that are transforming the automotive industry across Fleet Management, Asset Management and Insurance Telematics solutions.

Get to know the role:

The role of a data engineer is a supporting one, but it is also an extremely vital one. As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements. We want to see candidates with mechanical tendencies and a desire to know how things work and to improve them.

The day-to-day activities:

Design, construct, install, test and maintain data management systems.
Build high-performance algorithms, predictive models, and prototypes.
Ensure that all systems meet the business/company requirements as well as industry practices.
Integrate up-and-coming data management and software engineering technologies into existing data structures.
Develop set processes for data mining, data modeling, and data production.
Create custom software components and analytics applications.
Research new uses for existing data.
Employ an array of technological languages and tools to connect systems together.
Install/update disaster recovery procedures.
Recommend different ways to constantly improve data reliability and quality.
Work on and maintain Data pipelines.

Requirements Essential:

At least 5 years’ proven experience as a Data Engineer, DevOps Engineer, Software Developer, or similar.
Proficient in Linux/Unix and shell scripting as well as in functional programming languages.
Expertise in setting up and explored with technologies such as Hadoop and Spark.
Bachelor’s degree in computer science, software/computer engineering, applied mathematics, or physics.",3.3,"Cartrack
3.3",Johannesburg,-1,501 to 1000 Employees,2004,Company - Private,Security Services,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Data Engineer,-1,"Data Engineers build and support data pipelines and datamarts built off those pipelines. Both must be scalable, repeatable and secure. The Data Engineer helps to facilitate gathering data from a variety of different sources, in the correct format, assuring that it conforms to data quality standards and assuring that downstream users can get to that data timeously. This role functions as a core member of an agile team. These professionals are responsible for the infrastructure that provides insights from raw data, handling and integrating diverse sources of data seamlessly. They enable solutions, by handling large volumes of data in batch and real-time by leveraging emerging technologies from both the big data and cloud spaces. Additional responsibilities include developing proof of concepts and implements complex big data solutions with a focus on collecting, parsing, managing, analysing and visualising large datasets. They know how to apply technologies to solve the problems of working with large volumes of data in diverse formats to deliver innovative solutions. Data Engineering is a technical job that requires substantial expertise in a broad range of software development and programming fields. These professionals have a knowledge of data analysis, end user requirements and business requirements analysis to develop a clear understanding of the business need and to incorporate these needs into a technical solution. They have a solid understanding of physical database design and the systems development lifecycle. This role must work well in a team environment.

Job Objectives

Work Complexity: * Architects Data analytics framework. * Translates complex functional and technical requirements into detailed architecture, design, and high performing software. * Leads Data and batch/real-time analytical solutions leveraging transformational technologies. * Works on multiple projects as a technical lead driving user story analysis and elaboration, design and development of software applications, testing, and builds automation tools.

Main Job Objectives: 1. Development and Operations 2. Database Development and Operations 3. Policies, Standards and Procedures 4. Communications 5. Business Continuity & Disaster Recovery 6. Research and Evaluation 7. Coaching/ Mentoring

Qualifications

Essential: 4 years Bachelors degree in computer science, computer engineering, or equivalent work experience AWS Certification at least to associate level

Experience

Essential:

5+ years Data engineering or software engineering

3-5 years demonstrated experience leading teams of engineers

2+ years Big Data experience

5+ years experience with Extract Transform and Load (ETL) processes

2+ years Could AWS experience

At least 2 years demonstrated experience with agile or other rapid application development methods - Agile exposure, Kanban or Scrum

5 years demonstrated experience with object oriented design, coding and testing patterns as well as experience in engineering (commercial or open source) software platforms and large scale data infrastructures.

Desirable:

5+ years Retail Operations experience

Knowledge and Skills

Essential: *Creating data feeds from on-premise to AWS Cloud (2 years) *Support data feeds in production on break fix basis (2 years) *Creating data marts using Talend or similar ETL development tool (4 years) *Manipulating data using python and pyspark (2 years) *Processing data using the Hadoop paradigm particularly using EMR, AWSs distribution of Hadoop (2 years) *Devop for Big Data and Business Intelligence including automated testing and deployment (2 years) * Extensive knowledge in different programming or scripting languages * Expert knowledge of data modeling and understanding of different data structures and their benefits and limitations under particular use cases.

Further technical skills required: * Capability to architect highly scalable distributed systems, using different open source tools. * Big Data batch and streaming tools * Talend (1 year) * AWS: EMR, EC2, S3 (1 year) * Python (1 year) * PySpark or Spark (1 year) - Desirable * Business Intelligence Data modelling (3 years) * SQL (3 years)",-1,Datonomy Solutions,Brackenfell,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We are assisting one of our clients that is based in Pretoria to fill a role of a Data Engineer

This is a 12 month contract role

Objective of this Scope of Work

The Data Engineer will drive improvement of the data management maturity levels and provide the necessary technical support within the company to support reliable and effective decision-making, appropriate usage and protection thereof.

Scope of Services Definition

The scope will include but will not be limited to:

ï†· To develop, construct, test and maintain architectures.

ï†· To ensure architectures will support the requirements of business.

ï†· To discover opportunities for data acquisition and sharing.

ï†· To develop data set processes for data modelling, mining and production.

ï†· To employ a variety of languages and tools to marry systems together.

ï†· To recommend way to improve data reliability, efficiency and quality.

ï†· To prepare data for use in predictive and prescriptive modelling.

ï†· To conduct research to answer industry and business questions.

ï†· To leverage volumes of data from internal and external to answer business questions.

ï†· To develop and manage stakeholder relations effectively to promote data management across the organisation and support reliable decision making and appropriate data usage.

ï†· To participate and provide technical support in cross organisational activities relating to any of the above mentioned data management activities.

ï†· To provide regular progress reports as per stakeholder requirements and present data management updates in various forums as required.

Minimum qualification Required:

ï†· A minimum of a Bachelors degree in Computer Science or Information Management OR equivalent;

ï†· A minimum of five to eight years experience in a data management environment",-1,HR Genie,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Our client based in the Northern Suburbs, is currently looking for a Data Engineer to join their team.

Responsibilities
Our client is a dynamic IT company that delivers value-driven IT solutions to the group. Our work lives revolve around our DNA. We take pride in our work, treat our colleagues, partners and our country with respect. We exercise collaborative decision-making and believe in having a balance in life. We do this all while having fun and enjoying what we do.

The primary focus of this position is to use technical skills to put software, systems and data together in a way that extracts meaningful insights from raw data. You will need to be helpful and supportive to your team and fellow developers. You join an energetic, focused and dynamic team.

Interact with clients to understand requirements and business problems/needs

Identify, analyse, visualise and understand supporting data to propose solid solutions

Create technical documentation for reference and reporting

Support existing solutions within GCP and Oracle

Doing standby on a rotating basis

Key Competencies and Qualifications

Matric

Tertiary qualification in IT

Preferred cloud experience in AWS/AZURE/GCP

At least 3 years of data warehouse ETL experience

Dimensional Modelling

Data analyses

Experience with data visualization and visualization tool(s)

Knowledge of the retail industry will be beneficial

Understanding and experience with version control SVN/GIT

Preferred – Korn shell scripting, Python/Java, SQL

Google Cloud Platform experience would be looked upon favourably

Having a broad understanding of different SDLC’s

Preferred agile experience

Strengths

The natural tendency to take ownership and responsibility

Strong problem solving, critical thinking, effective planning and organisational skills

Detail-oriented with excellent communication skills

You have a can-do attitude and positive outlook on life

Can cope under pressure

Curious and interested in analysing problems and possible solutions

Strong team player

Self-driven learner, passionate about new technology

Above all, be passionate about what you do

Should you wish to apply for the position, please apply directly via this job board, please ensure that you quote reference number 201620 subject heading or email body.

Please note that due to the high volume of CV's received; only shortlisted applicants will be contacted. Should you not receive communication from our offices within two weeks of submission please note that your application will not be considered for this position.

We will keep your CV on file and re-establish contact with you should opportunities in line with your expertise become available again.

Should you require any additional information give us a call on 021 012 5566.",-1,Surgo HR & Training,Cape Town,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We believe that our employees fuel our organization, essential to enable us to help our customers overcome their business challenges and achieve sustainable growth. As a result, we are committed to growing each individual and providing them with the challenges, feedback and support needed to achieve success in their career

If this sounds appealing, and like us, you get excited about data: its collection, storage, transformation or display, see if you’ve got what it takes to join our sought after DATA team.

Key Responsibilities And/or Outputs

You will represent IQbusiness at our customers, sometimes alone, and sometimes as part of an IQ team.

Providing a superior customer experience by building and maintaining relationships, working at customer offices, keeping data confidential
Design and develop – databases, SQL queries, stored procedures, reports, dashboards or integration solutions
Produce solutions for both real-time and batch environments
Test your work to ensure compliance
Solve problems, and do root cause analysis
Prioritize your workload
Assist in other areas relating to your true data function, such as data modeling, data and business analysts
Interact with a variety of individuals: senior, junior, technical and from business
Provide guidance to fellow colleagues, or even manage a team
Uphold the IQ values, which are to care, learn & share; innovate; deliver as well as to build, enhance and maintain relationships

Education

Matric pass
A tertiary qualification, preferably in an ICT relevant field
Appropriate Microsoft certifications are beneficial but not required

Requirements

3 - 6 years experience in the Data Engineering environments and technologies
Great communication skills
A passion for SQL, databases or reports
Can you write stored procedures, design complex queries and create views and triggers?
Are you able to work out the relationships in a data warehouse or the aggregation of a cube?
Do you extract and display useful information when you see patterns and trends in data?
Strong knowledge of the financial services industry, ideally in a consulting role
The use of data related software: databases, ETL and BI tools; report writing and analytical tools
We use a lot of Microsoft products. You may often be expected to use MS SQL Server, SSIS, SSRS, SSAS and Power BI to develop solutions
What other relevant software have you’ve used?
Ability to work in different project methodologies: Waterfall and/or Agile
Knowledge of full SDLC
Exposure to logical and physical data modeling

Equal Employment Opportunity

IQbusiness is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, citizenship, marital, domestic or civil partnership status, sexual orientation, or gender identity",3.7,"IQbusiness South Africa
3.7",Johannesburg,-1,1 to 50 Employees,-1,Company - Private,Consulting,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"We value a data engineer as someone who works behind the scenes to obtain, process and supply data via various methodologies and technologies, to various consumers, in ways and forms that makes sense and add value. This definition is very broad, as the field of data engineering is just as broad.

You may be the type of data engineer that develops API endpoints for the consumption of data by end users or even another data pipeline, or you may be the type of data engineer that develops highly distributed, high availability data processing pipelines in an effort to satisfy the need of the ever questioning data analysts and/or data scientists.

You have awesome knowledge about the following concepts
Data modelling
Relational data modelling in traditional relational database management systems. (Microsoft SQL Server, MySQL, PostgreSQL, etc)
Coercing unstructured and semi-structured data into a structured form.
Data pipelining knowledge - data extraction and transformation.
Data transformation knowledge for reporting and analytics purposes.
Knowledge of the MapReduce and related data processing paradigms would be a boon.
You have the following technical competencies
Writing SQL queries, that can relate, transform and aggregate data from many differing sources where natural keys may or may not exist.
Experience with writing data pipelines that move and transform data, for various uses.
Working knowledge of a general purpose programming language like Python would be a boost.
Working knowledge of columnar databases such as Google BigQuery, and SAP HANA would be a boost.
Working knowledge of highly distributed technologies such as Apache Hadoop or Apache Spark would be a boost.
Working knowledge of NoSQL technologies, such as Apache Solr would be a boost.
You have the following personal competencies
The ability to solve problems.
The ability to rotate around a problem, to see if solutions can be gained in different ways.
The ability to work in an ever changing, unstructured environment.
The ability to work as part of a team, with vastly differing skill sets and opinions.
The ability to contribute ideas to the quorum.
The ability to mentor and provide guidance for other team members.
A systems approach to thinking, as opposed to a siloed approach. The candidate needs to understand how their work affects the greater system.
The ability to work without supervision, and take accountability for the work they deliver.
The ability to liaise with a client, sifting through the fluff and extracting the actual requirements.
If this is you - apply now and we'll get in touch",-1,DotModus,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Data Engineer

Our client in the contact centre space is currently seeking a DATA ENGINEER that will work on the collecting, storing, processing, and analyzing of large datasets. The primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them. You will also be responsible for integrating them with the architecture used across the company.

Key Performance Areas:

Data reporting.
Implementing ETL processes.
Defining data retention policies.
Management of Customer Lead data.
Provision of data for advanced analytics.
Maintenance of internal client scorecards.
Assist team in resolving data-related support queries.
Optimize existing data processes through automation.
Assist with all data-related reporting and documentation.
Maintenance and optimisation of the Analytics database.
Provide technical support to and supervision of junior data administrators.
Continuous upskilling on new technologies, frameworks and market trends.
Monitoring performance and advising any necessary infrastructure changes.
Identifying, selecting and integrating any Big Data tools and frameworks required to provide real-time analytics.

Educational Requirements

IT related Degree or Diploma is a pre-requisite

Required Skills/Experience

ETL tools: Advanced SSIS
BI/Reporting : Qlikview/Power BI/ SSRS or SSAS
Programming languages: JAVA, C# , Python, SAS or R
Experience with NoSQL databases and/or campaign management tools will be advantageous.
Minimum 3 years’ applicable work experience in SQL, relational databases and data manipulation.
Experience in big data platforms (eg. Hadoop) or processing frameworks (eg. MapReduce/Spark) and querying tools (eg. Pig, Hive and Impala) will be highly beneficial.

Preferred Skills

Organizational skills
Experience in Attentional to detail.
Accountability is critical for this role.
Ability to work under pressure and meet deadlines.
Solid understanding of database design principles.
Should you not receive a response in 2 weeks please consider your application unsuccessful",-1,Rubik's Cubed Consulting,Durban,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"This well known company is looking for a Data Engineer. will be based in Rivonia
The ideal candidate will have strong experience in the following:
Data cleaning
SQL Export
Big data Sets

BSc Degree in Maths and Stats will be required
a min of 3 years experience.
Stable track record is required.

Send your Cv to marinda@prrrecruitment.co.za",-1,PRR Recruitment Services,Johannesburg,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Description

Position at Aculocity, LLC

At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes
Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.
Key Responsibilities
Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.
Key Traits
Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern
Position Requirements
2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.
Where will you work? This role will be based out of Durbanville, South Africa.",-1,GVW,Durbanville,-1,Unknown,-1,Unknown,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Information Technology, Gauteng JHB - Northern Suburbs

Market related - Market related Annually

An IT Consultancy Business based in Johannesburg is currently looking for a Business Intelligence Consultant / Data Engineering Consultant.

Requirements:

Extensive experience in data engineering
Experience in Business Intelligence, data and Power BI
Extensive experience in data governance and the Popi act
Ability to assess and make recommendations on data within the Popi act
Good understanding of T-SQL and query optimization, developing ETL strategies.
Good understanding with SQL Server 2008/2012, SSIS, SSRS and SSAS
Use SSIS to create ETL packages to validate, extract, transform, and load data into the data warehouse and data marts.
Deploy and configured the reports in the Report Server (SSRS).
Excellent experience in Tabular Modelling , PowerView, Qlikvie,w, and Power BI
Maintain ETL
Qlikview model
Create Drill-through, Drill-down, and Cross Tab Reports and Sub-Report using Report Definition Language (RDL).
Generate periodic reports based on the statistical analysis of the data using SQL Server Reporting Services (SSRS)
Advise and provide written technical documentation and recommendations

The information displayed above is not limited to advertisements. Please contact Thato for further information.

Please consider your application as unsuccessful if you have not received a response within 14 days of submitting your application. However, please keep a lookout on our website, www.bedifferent.co.za, for available positions that you may be suited for

Ad Visible Until: 29 October 2020
Ref: JHB005346/NL

Vacancy Type: Permanent",2.9,"Be Different Recruitment
2.9",Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Cloud Support Engineer (Big Data),-1,"ABOUT US

Amazon Web Services is the market leader and technology forerunner in the Cloud business. As a member of the AWS Support team you will be at the forefront of this transformational technology, assisting a global list of companies and developers that are taking advantage of a growing set of services and features to run their mission-critical applications. As a Cloud Support Engineer, you will act as the Cloud Ambassador across all the cloud products, arming our customers with required tools & tactics to get the most out of their Product and Support investment.

Would you like to use the latest cloud computing technologies? Do you have an interest in helping customers understand application architectures and integration approaches? Are you familiar with best practices for applications, servers and networks? Do you want to be part of a customer facing technology team helping to ensure the success of Amazon Web Services (AWS) as a leading technology organization?

If you fit the description, you might be the person we are looking for! We are a group of smart people, passionate about cloud computing, and believe that world class support is critical to customer success.

WHAT CAN YOU EXPECT FROM A LIFE AT AWS?

Every day will bring new and exciting challenges on the job while you:

· Learn and use groundbreaking technologies.
· Apply advanced troubleshooting techniques to provide unique solutions to our customers' individual needs.
· Interact with leading engineers around the world.
· Partner with Amazon Web Services teams to help reproduce and resolve customer issues.
· Leverage your extensive customer support experience to provide feedback to internal AWS teams on how to improve our services.
· Drive customer communication during critical events.
· Drive projects that improve support-related processes and our customers technical support experience.
· Write tutorials, how-to videos, and other technical articles for the developer community.
· Work on critical, highly complex customer problems that may span multiple AWS services.

WHY AWS SUPPORT?

· First and foremost this is a customer support role in The Cloud.
· On a typical day, a Support Engineer will be primarily responsible for solving customers cases through a variety of customer contact channels which include telephone, email, and web/live chat. You will apply advanced troubleshooting techniques to provide tailored solutions for our customers and drive customer interactions by thoughtfully working with customers to dive deep into the root cause of an issue.
· Apart from working on a broad spectrum of technical issues, an AWS Support Engineer may also coach/mentor new hires, develop & present training, partner with development teams on complex issues or contact deflection initiatives, participate in new hiring, write tools/script to help the team, or work with leadership on process improvement and strategic initiatives.
· Career development: We promote advancement opportunities across the organization to help you meet your career goals.
· Training: We have training programs to help you develop the skills required to be successful in your role.
· We hire smart people who are keen to build a career with AWS, so we are more interested in the areas that you do know instead of those you havent been exposed to yet.
· Support engineers interested in travel have presented training or participated in focused summits across our sites or at specific AWS events.
· As we operate on a follow-the-sun model, with Premium Support sites located globally, there is no after hours on-call or mandated overtime in this role.
· https://www.youtube.com/watch?v=GC3bWcFFZTo&t=24s



Basic Qualifications

The Big Data role supports our services that leverage data and produce business insights, which may include using Machine Learning/Artificial Intelligence (ML/AI). Helping our customers use and integrate Big Data services in what is arguably our industrys most exciting space. The portfolio of services covers EMR (Hadoop), DynamoDB (NoSQL), MangoDB, and Apache Cassandra.

· Advanced experience in Apache Hadoop, Apache Spark, Apache Hive, and Presto
· Advanced experience in DynamoDB or NoSQL technologies like MongoDB or Cassandra
· Advanced experience with System Administration with Linux (RHEL/CentOS) including Microsoft Active Directory, and LDAP integration.
· Experience with troubleshooting Kerberos Authentication problems.
· Experience with Network troubleshooting.
· Basic understanding of Machine Learning and statistics
· Experience with Java and Python and shell scripting
· Bachelors degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position



Preferred Qualifications

· Expert experience in the Hadoop Ecosystem including Apache Spark and Presto
· Expert experience in NoSQL
· Expert experience with blockchain technologies like Etherium Expert experience in data Data Lake architecture and administration
· Experience managing full application stacks from the OS up through custom applications
· Prior work experience with AWS - any or all of EC2, VPC, S3, RDS, EMR, Glue, SageMaker
· Excellent knowledge of Hadoop architecture, administration and support
· Expert understanding of distributed computing principles and their application in the cloud
· Good understanding of distributed computing environments Lead technical discussions on big data systems architecture and design
· Strong analysis and troubleshooting skills and experience
· AWS Certified Solutions Architect
· AWS certified Big Data Specialty
· Masters degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity and Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Response Center Engineer,-1,"Job Title
Response Center Engineer
Job Description


Philips is a world leading health technology company with a vision to make life better for people worldwide through meaningful innovation. Making good on this promise depends on our passionate, inspirational, collaborative and diverse team. We have over 80,000+ brilliant people around the world but are always looking for more. Like-minded, motivated, focused minds to join us in creating a healthier, more connected society while transforming themselves personally and professionally.

As a CCC Coordinator - Response Center Engineer you will have the opportunity to process customer calls and be responsible for screening and diagnosing professionally Healthcare equipment to support customers and colleagues remotely with solving technical issues and ensuring maximum customer satisfaction

You are responsible for:
Diagnose healthcare equipment to the quality standards set by Philips Healthcare (PH) remotely by interviewing customers or colleagues by telephone or by remotely logging in to the system
Advise Customer Care Center Coordinators and District Operations Managers and / or Team Leads about the best follow-up w.r.t. technical state of the diagnosed healthcare equipment
Advise the Customer Care Center Coordinators or Field Services Engineers about required spare parts and resources
Responsible for planning engineers related to Modality responsibility.
Responsible for coordination between CCC, CUSTOMER, Spare parts AND Engineer.
Responsible to drive Remote and FTR KPI’s to targets respectively 40% and 85%.
Will require minimal field work to keep abreast of technical capabilities.
Take calls from customers and make sure they are processed in the CCC ERP on timely manner including all relevant data
Support Field Services Engineers in the field with technical knowledge
Escalate technical issues to the Technical Support Specialist
Escalate technical issues to Business Unit support after consultation of the Technical Support Specialist
Monitor critical functions of the equipment’s in the IB and environmental conditions including RSN and True reachability.
Lead the planning and implementation of FSN’s and FCO’s accelerating remote implementation where applicable.
Submit timely and accurate service data, job sheets, reports, expense claims, radiation film badges, field problem reports and other paperwork as assigned
Keep abreast of new technologies likely to affect PH range of products
Use company property with care to ensure optimal results with minimal operational costs
Be a professional representative for PH with respect to customer problems, ensuring personal acceptability by the customer in behavior in accordance with PH policy and targets
Conform to PH safety standards including health and safety regulations and in the event of hazards or accidents to take immediate control of the situation and involve the Operations Manager and / or the responsible person to handle properly confidential issues according Philips standards and to act according General Business Principals
Follow all quality standards within the frame of valid PH business policies
Follow the company quality regulations (ISO 9001; PQA; TQM) and internal directives and procedures
You are a part of the dynamic South Africa Customer Care Centre Team .You will be reporting to the Customer Care Center Manager.

Requires a pleasant, assertive individual you can work very well in a team setting, a dynamic environment that requires flexibility and creativeness to achieve goals.

To succeed in this role, you should have the following skills and experience:
Degree level education or equivalent
Experience in maintenance and troubleshooting of technical complex systems
Fluent in English, verbal and written in addition to local language
In return, we offer you the unique combination of a critical and challenging role and a creative and empowering office environment. You will be actively encouraged to make improvements, establish best in class service and have a direct impact on the success of Philips on a daily basis.

Employment Equity

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply. Only apply for this role if you are a South African Citizen by birth or Naturalization prior to the 27 April 1994.

Why should you join Philips?

Working at Philips is more than a job. It’s a calling to create a healthier society through meaningful work, focused on improving 3 billion lives a year by delivering innovative solutions across the health continuum. Our people experience a variety of unexpected moments when their lives and careers come together in meaningful ways. Learn more by watching this video.

To find out more about what it’s like working for Philips at a personal level, visit the Working at Philips page on our career website, where you can read stories from our employee blog. Once there, you can also learn about our recruitment process, or find answers to some of the frequently asked questions.

Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.9,"Philips
3.9",Johannesburg,-1,10000+ Employees,1891,Company - Public,Health Care Services & Hospitals,Health Care,$10 to $25 million (USD),-1
Software Development Engineer - EC2 Placement,-1,"Build the systems that optimize how EC2 matches requests for Instances with the underlying compute capacity. EC2 Placement is seeking talented engineers to build the online and offline optimization systems for compute workload scheduling, and the customer capabilities to better manage those workloads. Amazon EC2 provides on-demand scalable compute capacity, and powers some of the largest services in the world. You will collaborate with a top-tier community of engineers to build systems to improve how customers are able to access EC2 compute resources.

The successful candidate will have strong software engineering experience, with a passion for thinking about, building and testing distributed systems. You have an interest in how Machine Learning and other optimization techniques can be applied to large-scale problems. You have demonstrated experience working with a team to design, build and operate large-scale systems. With strong engineering fundamentals, an analytical and data-driven approach to your work, and strong communication skills, you have the ability to collaborate well to deliver results. We move fast and work together on small teams to solve big problems.

If this opportunity sounds interesting, we would love to talk to you more about our work and the vibrant culture at AWS in Cape Town.

Basic Qualifications

· Degree in Computer Science or related field, or equivalent working experience
· 3+ years of industry experience in a software development environment
· Strong Computer Science fundamentals, including data structures, object-oriented design, algorithm design, problem solving, and complexity analysis.
· Proficiency in at least one modern programming language, such as Java, C#, Python, Scala, Kotlin

Preferred Qualifications

One or more of the following help you stand out:
· Demonstrated results designing, building and operating high-performance distributed systems in large-scale Linux environments
· Role model in writing high-quality, maintainable and secure code, mentoring others, and helping teams sharpen their development processes
· Ability to work effectively across teams to deliver results, with strong verbal and written communication skills
· Experience working with machine learning systems

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer - PBB IT,-1,"Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose


This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes
Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems
Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions
Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.

Research and best practices
Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development
Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.
Preferred Qualification and Experience
Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Aws Data Platform Engineer,-1,"Aws Data Platform Engineer

Posting Country:

South Africa

Date Posted:

15-Oct-2020

Full Time / Part Time:

Full Time

Contract Type:

Permanent

Joining Vodacom is more than a job, what we do matters. We don’t just carry minutes, texts and data – we carry people’s lives. And that’s a huge responsibility. If you think for a minute about the people you rely on…the likelihood is they rely on us.

Customers are at the heart of everything we do and we want to make a difference to the lives of our customers, and the communities in which we live and work. We support our people to give something back to the causes that mean the most to them through helping them give time and money to the charities they love.

And what’s it like to work here? We have created an environment where you can look forward to coming to work and are empowered to be at your best. We offer flexibility in how you work that helps you do your job in a way that suits you, opportunities to help you grow and progress throughout your career and a choice of benefits to suit your lifestyle.

Role Purpose
The H Band AWS Data Platform Engineer position is based within the Technology Business Unit.

The AWS Data Platform Engineer will be responsible for all Database services such as RDS, DynamoDB, etc. Should be able to migrate any databases from anywhere to AWS using any third-party tools or AWS database migration tool. Should also have understanding or expertise in creating data warehouses and data lake solutions on AWS.
Your responsibilities will include:
Apply practical knowledge of relational database design and usage with customers
Perform workload analysis and undertake performance tuning, as well as performance benchmarking in customer environments.
To develop state of the art solutions which are technically sound.
To provide a high-quality service to the Enterprise Cloud Services clients i.t.o. consultancy, solutions and delivery.
Commitment to team success and positive team dynamics including mentoring of other team members.
Passion for growing and applying technical skills in service to customers.
Be a trusted infrastructure advisor by providing objective, practical and relevant ideas, insights and advice.
Work collaboratively with consulting partners and technology teams to ensure high quality of solution delivery.
Encourage best practice and knowledge sharing with partners and cross-functional groups
Manage the overall database design and delivery of solutions.
Ability to make recommendations as they pertain to improvements in support/development initiatives and facilitate implementation with partners and cross-functional groups within the Business.
Participate in high level database solution definition and design during the implementation phase with the goal of providing reliable, stable and operationally sound applications that meet the Business requirements.
Ability to understand and translate business requirements into technical specifications
The ideal candidate will have:
A minimum of 3 years of industry related experience of which 1 year must be within a complex hosting environment.
Certifications in Database design, system architecture or cloud technologies.
Demonstrate knowledge of database systems internals including storage layouts and distributed databases/MPP architectures
Advanced SQL coding, tuning and query optimization.
Experience designing and leading database performance benchmarks.
Good knowledge of the different AWS services
Knowledge of cloud networking architecture, cloud operations, security, automation and orchestration.
Knowledge of database internals as it relates to query and system performance and tuning.
Understanding of overall system architecture, scalability, reliability, and performance in a database environment.
Excellent teamwork, time-management and organizational skills.
Perform other duties as deemed necessary and assigned by the customer and management
Strong interpersonal skills and problem-solving abilities.
Excellent documentation, communication and interpersonal skills.
Excellent analytical and problem-solving abilities.
Closing date for applications: Monday, 13 April 2020

The base location for this role is Vodacom World, Midrand

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply.
Vodacom is committed to an organisational culture that recognises, appreciates and values diversity & inclusion.

Commitment from Vodacom

Vodacom is committed to attracting, developing and retaining the very best people by offering a flexible, motivating and inclusive workplace in which talent is truly recognized, developed and rewarded. We believe that diversity plays an important role in the success of our business and we are committed to creating an inclusive work environment which respects, values, celebrates and makes the most of people’s individual differences - we are not only multinational but multicultural too. At Vodacom you will have access to our excellent flexible benefits programme that you would expect from any global company.",3.9,"Vodafone
3.9",Midrand,-1,10000+ Employees,1982,Company - Public,"Cable, Internet & Telephone Providers",Telecommunications,$10+ billion (USD),-1
Data Engineer Azure Data Factory,-1,"Enthuzex is looking for a motivated Lead Data Engineer to contribute towards the success of our Data and Analytics Technology initiatives. This is a hands-on technical role and this person will be responsible for the development and build of scalable solutions as it relates to the architecture strategies, data standards, digital data management, data integration, tools, and technology. The right candidate will play a deep dive hands-on critical development role in the digital transformation and in shaping how we acquire, ingest, transform and deliver data through the digital consumer channels.

Responsibilities:

Architect, design, develop and engineering end-to-end data pipelines across multiple data sources and systems of record.
Ensure data quality, integrity, security and completeness throughout the data lifecycle
Develop, design data models, data structures and ETL jobs for data acquisition and manipulation purposes
Develop deep understanding of the data sources, implement data standards, maintain data quality and master data management
Developing data services and API
Work closely with the cloud service providers to ensure completeness and alignment with the service offerings
Manage and maintain cloud based data and analytics platform
Deep understanding of the cloud offerings and engage in quick proof of concepts and proof of value in prototyping data and analytics solutions and derive viability
Ability to interact with the business stakeholders to understand requirements and translating into technology solutions

Expirience:

Experience in Cloud platform AWS or Azure eco-system. (Azure preferred)
Data Engineering/Development experience with SQL (Oracle, SQL Server, MySQL)
Strong development background creating pipelines and complex data transformations and manipulations using one of the languages Python, Java, R, or Scala with Databricks/Spark
Experience in NoSQL Databases and Big data technologies including Hadoop
Experience with API / RESTful data services
Worked on real-time data capture, processing and storing using technologies like Azure Event Hubs and Analytics
Experience working with different data storage options including AWS S3, Azure BLOB storage etc.
Understanding of different data formats including Parquet, Avro, CSV, ORC etc.
Prior experience with MPP databases and maintain large amount of data processing
Experience with Azure Data Factory and Azure Data Catalog is a big plus and mandatory
Experience with Microsoft/Azure ETL solutions and business Intelligence technologies is a big and mandatory
Past working experience on a fast paced and agile environment
Perform ongoing monitoring, automation and refinement of data engineering solutions
Experience in leading high visibility transformation projects that interacts with multiple business lines
Build and meet project timelines and manage delivery commitments with proper communication to management

Qualifications

Bachelor’s degree with 4+ years of relevant experience
Willingness to learn new technologies and thrive in an extremely fast paced environment
Team player and easy to work with.

Applicants must demonstrate their ability to master new enterprise level technologies. Successful applicants will exemplify Enthuzex ethical principles of uncompromising integrity, respect for others, and accountability for decisions

send cv's info@enthuzex.co.za",-1,Enthuzex,Leslie,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Scientist,-1,"The world is changing.

We all want something different.

At Luno, we see you as an individual.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the world, and to do so, we need the best team on board for our mission.

A bit about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 3 million customers across 40 countries.
We are Series B funded, backed by Balderton Capital and the Naspers Group.
Our platform has processed over 8 billion dollars since we've launched
We're proud to be one of the world's most international cryptocurrency teams from 26 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
The role in a nutshell:

Identifying opportunities in the business that could benefit most from cognitive applications, as well as building and enhancing organisational capabilities for deriving value from multiple data sources using data science.

What we'd like you to have:
Bachelor's degree or higher in the natural sciences or technical fields such as Mathematics, Statistics, Computer Science, Engineering or Economics
Enthusiasm to work in the cryptocurrencies space
Advanced SQL skills
Solid understanding of exploratory data analysis, predictive analytics, and optimisation using Python, R, Matlab, RapidMiner, KNIME or other data science-oriented platforms
Proficiency in the use of data science and machine learning domain-specific languages such as ""Caret"" and the ""Tidyverse"" suite of tools in R, or ""Pandas"" in Python
Strong interpersonal and communication skills
Communicating data insights using storytelling narratives
Ability to work independently, as well as within and across teams
Ability to successfully complete projects with large and/or incomplete data sets
More about what you'll be doing:
Optimising product performance by tracking and analysing customer behaviour on web and app, in collaboration with software engineers and product designers
Providing the business with reports and dashboards, on key performance metrics
Developing metrics to accurately assess the health of our Exchange platform
Comparative data-driven analysis of our Exchange against alternative platforms
Formulating business requirements into analytical objectives
Designing and running experiments to test hypotheses
Hacking through complex business problems using advanced data analysis to provide insights and recommendations
Building, maintaining, and optimising decisioning systems using advanced statistical and predictive modelling techniques
What will set you apart:
An advanced degree in Mathematics, Statistics, Computer Science or related field
At least 3 years' experience working in a similar role
A basic understanding of trading in financial markets
Experience working with a data analytics and visualisation platform such as Tableau, Cognos, QlikView, or Looker
Familiarity with using Google Analytics to understand customer behaviour
Solid knowledge of statistical and machine learning techniques
Familiarity with modern distributed data storage and processing systems such as Amazon Redshift, Big Query, Snowflake, Databricks and Apache Spark
You can gather and synthesise facts, theories, trends, patterns, inferences, and key issues in complex and variable situations
Ability to diagnose problems using formal problem-solving tools and techniques from multiple angles to generate multiple possible solutions
A sense of anticipating long-term problem areas and associated risk levels with objective rationale
Remote Life at Luno

If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
You'll be able to continuously upskill yourself with access to free online learning via MyAcademy, an international teaching marketplace with over 100000 courses from Harvard and other leading providers + share knowledge with your peers.
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity and paternity leave, and you can even take paw-ternity leave for your furry friend.
Annual Inspiration Day! Make time for that pottery course or spa day you've always wanted to do.
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"EY is a global leader in
assurance, tax, transaction and advisory services. Technology is at the heart
of what we do and deliver at EY. Technology solutions are integrated in the
client services we deliver and are key to our innovation as an organization.

Fueled by
strategic investment in technology and innovation, Client Technology seeks to
drive growth opportunities and solve complex business problems for our clients
through building a robust platform for business and powerful product engine
that are vital to innovation at scale. As part of Client Technology, you’ll
work with technologists and business experts, blending EY’s deep industry
knowledge and innovative ideas with our platforms, capabilities, and technical
expertise. As a catalyst for change and growth, you’ll be at the forefront of
integrating emerging technologies from AI to Data Analytics into every corner
of what we do at EY. That means more growth for you, exciting learning
opportunities, career choices, and the chance to make a real impact.

The selected
candidate
Develops
large and complex data architecture, composed of models, policies, rules or
standards that govern which data is collected and how it is stored, arranged,
integrated and put to use in data systems, including the design, build and
management of data infrastructure to address business requirements
Creates
sound use case driven roadmaps, depicting data architecture as-is and to-be
capabilities with the business by engaging with multidisciplinary teams, and by
identifying, managing and mitigating risk
Develops
relationships across the business to understand data requirements, applies deep
technical knowledge of data management to solve business problems in areas
where solutions may not currently exist, necessitating new solutions/ways of
working/technologies and proactively articulating these to the business
Review,
identify the latest emerging technologies, augmenting by services from the
leading cloud providers to solution and recommend the best next generation data
platform value driven approach for our clients
Your Key Responsibilities Include
Create
and maintain conceptual, logical and physical database models
Document
functional requirements and system specifications into the data architecture
and detailed design specifications for current and proposed designs
Document
and adhere to development standards and best practices in database designs
Maintain
highly effective and consistent communication within the team, peers, and the
leadership team
Reverse
engineer SQL code and modify it to solve problems/issues
Contribute
to the definition and implementation of data governance practices
Design
both data structures and data integration practices
Work
closely with the infrastructure teams to create a physical environment to
support data services
Evaluate
new and existing (internal and external) technologies and services in support
of data services and data analytics objectives
Skills And Attributes For Success
Understanding
of business process reengineering and business modeling concepts, business
systems development and analysis
Hands-on
experience in designing and implementing hybrid cloud and on-prem solutions
Experience
working with the latest versions of SQL Server
Experience
applying SAFe/Scrum/Kanban methodologies
Ability
to exercise judgment in solving technical, operational, and organizational
challenges
Expert
programming, performance tuning and troubleshooting skills, using the latest
popular programming languages for example python
Demonstrate
proactive approach to identifying issues and presenting solutions and options,
and where appropriate, leading to resolution
Minimum Qualifications
5+ years
demonstratable work experience as a Data Architect using data modeling tools
2-3 years
SQL coding experience on large projects
Must
possess expert SQL programming, performance tuning and troubleshooting skills
Create
database objects and SQL scripts
Understand
and developed data pipelines
Know how
to deformalize data for data science models
Experience
in python, spark and notebooks
Experience
designing data warehousing solutions
Experience
designing next generation data platforms utilising cloud services
In-depth
understanding of database structure principles
Seamlessly
able to translate business requirements to technology requirements
What We Look For
Strong
analytical skills and problem-solving ability
A
self-starter, independent-thinker, curious and creative person with ambition
and passion
Excellent
inter-personal, communication, collaboration, and presentation skills
Customer
focused
Excellent
time management skills
Positive
and constructive minded
Takes
responsibility for continuous self-learning
Takes the
lead and makes decisions in critical times and tough circumstances
Attention
to detail
High
levels of integrity and honesty
Curious
about new emerging technology
About EY
As a global leader in assurance, tax, transaction and consulting
services, we’re using the finance products, expertise and systems we’ve
developed to build a better working world. That starts with a culture that
believes in giving you the training, opportunities and creative freedom to make
things better. Whenever you join, however long you stay, the exceptional EY
experience lasts a lifetime.",3.8,"EY
3.8",Johannesburg,-1,10000+ Employees,1989,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Architect - Principal,-1,"We are looking for Principle Data Architect to join our Engineering team in Cape Town.

The world is changing.
We all want something different.
At Luno, we see you as individuals.

Together, we are upgrading the world of work to unleash the potential within and empower you to become the best possible version of yourself.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the financial landscape, and to do so, well we need the best team on board for our mission. In short, to achieve our goals, we need rockstars. As simple as that.

A little about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 5 million customers across 40 countries.
We're part of the Digital Currency Group, a group of companies driving progress in the cryptocurrency and blockchain space that includes Grayscale, Genesis, Coindesk and Foundry Services
Our platform has processed over $8 billion to date
We're proud to be one of the world's most international cryptocurrency teams from 43 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
How we work


Our engineering team (currently ~100 engineers) is split into organisations which we call Fleets. Each Fleet focuses on a core customer journey (onboarding, security, payments, support, new business, growth and marketing etc.). Each of these fleets contains multiple smaller teams called Pods, each of which focuses on a specific aspect of the product.

Pods will include a product owner, product designer, back-end engineers, Android, iOS and Web developers, who each bring a unique perspective to the problem you are all contributing towards.

We're agile, use scrum, continuous integration and continuous delivery, deploying to production every single day.

We're building teams to help us succeed in our mission to upgrade the world to a better financial system. You'll be joining a group of highly motivated software engineers who you'll work collaboratively with across our pods.

As a fast-growing company with offices around the world, you'll immediately see how your contributions directly impact both our internal users and client experience. Many of the problems we are solving result in trail blazing solutions which can't be found on Stack Overflow; so we're looking for engineers who flourish working in a complex domain.

In your first six months, you will:


...start at Luno by learning our processes, meeting the wider team and starting our engineering on-boarding program. After getting comfortable with the basics, you'll start learning our idiomatic patterns in a safe, easy-to-follow way - by building your own toy micro services. You'll get to practice how we do design docs, code reviews, deployments, events, logging and monitoring.

You'll meet the Pod(s) you'll be working with and quickly align on the teams' current OKRs and product roadmap. We succeed as a team, so we will provide you with regular feedback from your manager and peers and will encourage you to do the same.

What you'll do:
Work closely with our data science and platform teams on projects introducing new streams of data into our data lake
You will get to bring new ideas on how to further develop and innovate our data solutions and how to expose that data to the business
Accountable and Responsible for the design and architecture of Data systems that are robust and scalable.
Work in an Agile/Scrum framework or Agile mindset
Data backup/recovery and storage
Pick-up and learn new concepts, in both engineering and product, and be able to apply that knowledge quickly.
The ideal candidate for this role will have:
7+ years' experience in maintaining scalable data solutions and/or you are passionate about it
Ability to understand, communicate and advocate between build vs buy
Proven track record of setting up, restructuring and maintenance of databases
You know your way around ETL and you have experience with SQL
Experience in the AWS Data stack (RedShift,DynamoDB, Amazon RDS)
Familiarity with integrating data stores with BI platforms such as Looker, Tableau, or Power BI
You have experience with the concepts of CI/CD
Coding skills in e.g. Go, Python
Bachelor's degree in a related field preferred
AWS Certified DataOps Administrator
Be friendly, transparent, articulate and driven to succeed
Basic knowledge of and passion for digital currencies like Bitcoin
A work permit for South Africa if you are not a South African citizen
Don't be put off if you don't tick all of the boxes – they're a guide based on what we'd love to see but we appreciate that excellent software engineers have diverse backgrounds.

Remote Life at Luno


If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity / paternity and even (yes, you are reading it correctly) paw-ternity for your furry friend..
Annual Inspiration Day.. like that pottery course you've always been meaning to do!
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. You'll need to hold the legal right to work in South Africa already as we cannot provide visa sponsorship.

Be part of the change!",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer - EC2 Capacity Data Analytics,-1,"EC2 Capacity Data Analytics (CDA) team is looking for a Data Engineer to join our team.

Our team is part of the EC2 Capacity Engineering organization, which is responsible for providing the elasticity EC2 customers need to scale up/down compute resources in a cost-efficient manner. We predict customer usage across thousands of configuration combinations to deliver exactly what our customers require in just the right amount of time with just the right amount of capacity.

As a Data Engineer, you will build the ETL and analytics solutions for our internal customers to answer questions with data and drive critical improvements for the business. You will use best practices in software engineering, data management, data storage, data compute, and distributed systems. On any given day, we use Python, Scala, Java, SQL, Lambda, CloudFormation, Redshift and Glue as well as other public AWS services and a host of Amazon internal tools. We dont expect you to be an expert in, or necessarily even be familiar with all of the technologies listed above, but we do expect you to be excited to learn about them.

This position involves on-call responsibilities, typically for one week every two months. Our team is dedicated to supporting new team members. We care about your career growth, we try to assign projects and tasks based on what will help each team member develop into a more well-rounded engineer and enable them to take on more complex tasks in the future.

Our team values work-life balance and we are flexible when people occasionally need to work from home.

Job Duties
Develop and maintain automated ETL pipelines for big data using languages such as Scala, Spark, SQL and AWS services such as S3, Glue, Lambda, SNS, SQS, KMS. Example: ETL jobs that process a continuous flow of JSON source files and output the data in a business-friendly Parquet format that can be efficiently queried via Redshift Spectrum using SQL to answer business question.

Develop and maintain automated ETL monitoring and alarming solutions using Java/Python/Scala, Spark, SQL, and AWS services such as CloudWatch and Lambda.

Implement and support reporting and analytics infrastructure for internal business customers using AWS, services such Athena, Redshift, Spectrum, EMR, and QuickSight.

Develop and maintain data security and permissions solutions for enterprise scale data warehouse and data lake implementations including data encryption and database user access controls and logging.

Develop and maintain data warehouse and data lake metadata, data catalog, and user documentation for internal business customers.

Develop, test, and deploy code using internal software development toolsets. This includes the code for deploying infrastructure and solutions for secure data storage, ETL pipelines, data catalog, and data query.


Basic Qualifications

· Bachelors degree in Computer Science or related technical field, or equivalent work experience.
· 4+ years of overall work experience including Software Engineering, Data Engineering, Database Engineering, Business Intelligence.
· Experience with AWS technologies stack including Lambda, Glue, Redshift, RDS, S3, EMR or similar big data solutions stack

Preferred Qualifications

· Demonstrate efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data.
· Demonstrable proficiency in distributed systems and data architecture; design and implementation of batch and stream data processing pipelines; knows how to optimize the distribution, partitioning, and MPP of high-level data structures.

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer,-1,"Our client based in Johannesburg is urgently looking for a Data Engineer to be on a 3 months contract
Build data pipelines, experience in new tech like nifi, kafka, python

Joburg based, open to EE, 3 month contract with the option to extend, must be available at short notice",-1,EQplus,Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Overview
Job ID: 51456
Job Sector: Information Technology and Services
Country: South Africa
Region/State/Province/District: Gauteng
Location: Johannesburg

Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose

This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes

Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems

Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions

Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.
Research and best practices

Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development

Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.

Preferred Qualification and Experience

Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry

Knowledge/Technical Skills/Expertise

Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision

PLEASE NOTE: All our recruitment and selection processes comply with applicable local laws and regulations. We will never ask for money or any form of payment as part of our recruitment process. If you experience this, please contact our Fraudline on +27 800222050 or forward to TransactionFraudOpsSA@standardbank.co.za",4.1,"Standard Bank
4.1",Johannesburg,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"About us

At PBT Group we pride ourselves on being a Data Specialist organisation. With 20 years of experience in 27 countries over 3 continents, our team of 550 consultants have implemented more than 700 projects.",4.3,"PBT Group
4.3",Johannesburg,-1,Unknown,-1,Company - Private,Accounting,Accounting & Legal,Less than $1 million (USD),-1
Data Engineer,-1,"Kick-start your career in the online gaming world and experience the very latest in technology and innovation.

The Department:

Our mission is to provide our customers with the best online betting experience and share the thrill of gaming with them. Data is at the very heart of our business and is vital in everything we do.

Our cross-functional Data team has a big and exciting challenge ahead. We are in the process of re-platforming our traditional, on-premises RDBMS environment to a new microservice architecture in the cloud. We’re making use of the diverse set of data technologies in Microsoft Azure to offer new services, reporting structures and real-time data pipeline while serving the day-to-day requirements of a rapidly growing, data-hungry organisation.

Purpose of the Role:

This is an excellent opportunity for an individual who is looking to gain new skills. We are committed to creating a culture of learning and regularly run proof of concepts, provide internal demos, manage workshops and attend external conferences. Our data team has a wide range of skills including development for highly transactional RDBMS systems, data warehousing, data science and cloud technologies and we are always working to raise everyone’s game.

Duties include, but not limited to:

Work as part of an agile Data Engineering Team
Development of greenfield projects in Azure
Develop and maintain on-premises RDBMS/DW systems
Create robust ETL services and real-time data pipelines
Build and maintain Continuous Integration and DevOps pipelines
Test-driven development and pair programming with colleagues

Essential Criteria:

C#, .Net, Visual Studio
Git, Azure DevOps
NoSQL development (CosmosDB)
Demonstrable understanding of MS SQL Server in a highly transactional environment
Demonstrable understanding of development in Microsoft Azure
Able to understand query plans and identify performance bottlenecks
Test/Business-Driven Development
Building Continuous Integration/Deployment pipelines
Communicate effectively with both technical and non-technical stakeholders

Desirable Criteria:

Implementing Data Storage and Processing solutions in Azure (ARM Templates, Storage Accounts, Data Lake Storage, SQL DB, Cosmos DB, EventHubs, Function Apps, Log Analytics, Data Factory, Databricks, Polybase)
Implementing Security, Disaster Recovery, High Availability, Auditing, Monitoring and Alerting solutions in Azure
Automating tasks in Azure using Powershell / CLI
Predicting costs and optimizing spending in Azure
Message Queues (RabbitMQ, Kafka)
Python

Person Specifications:

Resilience
Teamwork
Technical Knowledge
Communication skills
Stress Tolerance
Please note we will apply relevance to our Talent Management and Talent Development Programme as part of our recruitment process.
Shortlisted candidates may need to complete an assessment.
This position requires trust and honesty it has access to customers financial details - therefore a credit and criminal record check will be conducted. The qualifications identified herein are an inherent job requirement; therefore, a qualification verification check will be done. By applying for this role, and supplying the necessary details, you hereby grant us permission to apply for these checks. This will be done in a confidential manner, and solely for the purposes of verification.

To view all current vacancies, please visit our website, www.digioutsource.com

Should you not hear from us within 2 weeks, please deem your application as unsuccessful.

The perfect place to work, play and grow!",3.9,"Digital Outsource Services
3.9",Cape Town,-1,1001 to 5000 Employees,1997,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
Data Engineer,-1,"At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes

Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.

Key Responsibilities

Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.

Key Traits

Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern

Position Requirements

2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.

Where will you work? This role will be based out of Durbanville, South Africa.",3.1,"Aculocity, LLC
3.1",Durbanville,-1,1 to 50 Employees,2006,Company - Private,IT Services,Information Technology,$1 to $5 million (USD),-1
Data Engineer,-1,"ENVIRONMENT:

A rapidly growing E-Commerce Platform seeks a highly talented Data Engineer to make an invaluable contribution to data democratisation and literacy vision by making accessible and easy-to-use data products and tools. You will require a Comp-Sci Degree or 3 years’ relevant industry experience, MySQL, PostgreSQL, Java, Python, in-depth understanding of OLAP, Data Marts, Star Scheme, Snowflake, be familiar with Jenkins, Travis, Circle CI, Docker, Kubernetes, experience with Kafka, Pub/Sub, Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks & significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing & Data Lake design and implementation and Lambda/Kappa architectures.

DUTIES:

Design, develop, test and maintain data architecture.

Prepare data for descriptive, predictive and prescriptive modelling.

Automate repetitive tasks and manual processes related with the data usage.

Optimize data delivery.

Design, develop and test large stream data pipelines to ingest, aggregate, clean, and distribute data models ready for analysis.

Ensure the highest standard in data integrity.

Leverage best practices in continuous integration and delivery.

Collaborate with other engineers, ML experts, analysts, and stakeholders to produce the most efficient and valuable solutions.

Implement features, technology, and processes that move us towards industry best practices, improving on scalability, efficiency, reliability, and security.

Operations and ownership of systems in production, responding to incidents.

REQUIREMENTS:

Qualifications –

Comp-Sci Degree or 3 years relevant industry experience.

Experience/Skills –

Open source relational database systems e.g. MySQL, PostgreSQL, etc.

Significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing, and Data Lake design and implementation and Lambda/Kappa architectures.

A thorough understanding of database and data warehousing principles e.g. OLAP, Data Marts, Star Schema, Snowflake, etc.

Java and Python.

Familiar with CI/CD tools such as Jenkins, Travis, Circle CI, etc.

Experience with Kafka, Pub/Sub, or other event-based systems.

Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks, etc.

Working in cloud environments and with containerisation frameworks, tools and platforms e.g. Docker, Kubernetes, GKE, etc.

A deep understanding of data pipelining, streaming, and Big Data technologies, methods, patterns, and techniques.

Troubleshooting complex database operations and performance issues.

Automating tasks using Shell Scripting or writing small applications.

ATTRIBUTES:

Works well with people and is passionate about helping people be their best.

A team player, an active listener, mentor, and able to communicate well.

Shows solid reasoning and decision making, with the ability to work under pressure.

Is passionate about technology, systems and data.

Is curious, always learning, and keeping up to date with the industry.

While we would really like to respond to every application, should you not be contacted for this position within 10 working days please consider your application unsuccessful.

COMMENTS:

When applying for jobs, ensure that you have the minimum job requirements. Only SA Citizens will be considered for this role. If you are not in the mentioned location of any of the jobs, please note your relocation plans in all applications for jobs and correspondence.",-1,Datafin IT Recruitment,Cape Town,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Cartrack is looking for passionate data science and engineering candidates that can join a growing team that is responsible for the intelligence and efficiency solution provision to over a million subscribers, many of whom are large fleets. We are in the midst of creating revolutionary platforms that will change the way that people interact with their vehicles.

You will have the opportunity to work with the very brightest global subject matter experts that are transforming the automotive industry across Fleet Management, Asset Management and Insurance Telematics solutions.

Get to know the role:

The role of a data engineer is a supporting one, but it is also an extremely vital one. As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements. We want to see candidates with mechanical tendencies and a desire to know how things work and to improve them.

The day-to-day activities:

Design, construct, install, test and maintain data management systems.
Build high-performance algorithms, predictive models, and prototypes.
Ensure that all systems meet the business/company requirements as well as industry practices.
Integrate up-and-coming data management and software engineering technologies into existing data structures.
Develop set processes for data mining, data modeling, and data production.
Create custom software components and analytics applications.
Research new uses for existing data.
Employ an array of technological languages and tools to connect systems together.
Install/update disaster recovery procedures.
Recommend different ways to constantly improve data reliability and quality.
Work on and maintain Data pipelines.

Requirements Essential:

At least 5 years’ proven experience as a Data Engineer, DevOps Engineer, Software Developer, or similar.
Proficient in Linux/Unix and shell scripting as well as in functional programming languages.
Expertise in setting up and explored with technologies such as Hadoop and Spark.
Bachelor’s degree in computer science, software/computer engineering, applied mathematics, or physics.",3.3,"Cartrack
3.3",Johannesburg,-1,501 to 1000 Employees,2004,Company - Private,Security Services,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Data Engineer,-1,"Data Engineers build and support data pipelines and datamarts built off those pipelines. Both must be scalable, repeatable and secure. The Data Engineer helps to facilitate gathering data from a variety of different sources, in the correct format, assuring that it conforms to data quality standards and assuring that downstream users can get to that data timeously. This role functions as a core member of an agile team. These professionals are responsible for the infrastructure that provides insights from raw data, handling and integrating diverse sources of data seamlessly. They enable solutions, by handling large volumes of data in batch and real-time by leveraging emerging technologies from both the big data and cloud spaces. Additional responsibilities include developing proof of concepts and implements complex big data solutions with a focus on collecting, parsing, managing, analysing and visualising large datasets. They know how to apply technologies to solve the problems of working with large volumes of data in diverse formats to deliver innovative solutions. Data Engineering is a technical job that requires substantial expertise in a broad range of software development and programming fields. These professionals have a knowledge of data analysis, end user requirements and business requirements analysis to develop a clear understanding of the business need and to incorporate these needs into a technical solution. They have a solid understanding of physical database design and the systems development lifecycle. This role must work well in a team environment.

Job Objectives

Work Complexity: * Architects Data analytics framework. * Translates complex functional and technical requirements into detailed architecture, design, and high performing software. * Leads Data and batch/real-time analytical solutions leveraging transformational technologies. * Works on multiple projects as a technical lead driving user story analysis and elaboration, design and development of software applications, testing, and builds automation tools.

Main Job Objectives: 1. Development and Operations 2. Database Development and Operations 3. Policies, Standards and Procedures 4. Communications 5. Business Continuity & Disaster Recovery 6. Research and Evaluation 7. Coaching/ Mentoring

Qualifications

Essential: 4 years Bachelors degree in computer science, computer engineering, or equivalent work experience AWS Certification at least to associate level

Experience

Essential:

5+ years Data engineering or software engineering

3-5 years demonstrated experience leading teams of engineers

2+ years Big Data experience

5+ years experience with Extract Transform and Load (ETL) processes

2+ years Could AWS experience

At least 2 years demonstrated experience with agile or other rapid application development methods - Agile exposure, Kanban or Scrum

5 years demonstrated experience with object oriented design, coding and testing patterns as well as experience in engineering (commercial or open source) software platforms and large scale data infrastructures.

Desirable:

5+ years Retail Operations experience

Knowledge and Skills

Essential: *Creating data feeds from on-premise to AWS Cloud (2 years) *Support data feeds in production on break fix basis (2 years) *Creating data marts using Talend or similar ETL development tool (4 years) *Manipulating data using python and pyspark (2 years) *Processing data using the Hadoop paradigm particularly using EMR, AWSs distribution of Hadoop (2 years) *Devop for Big Data and Business Intelligence including automated testing and deployment (2 years) * Extensive knowledge in different programming or scripting languages * Expert knowledge of data modeling and understanding of different data structures and their benefits and limitations under particular use cases.

Further technical skills required: * Capability to architect highly scalable distributed systems, using different open source tools. * Big Data batch and streaming tools * Talend (1 year) * AWS: EMR, EC2, S3 (1 year) * Python (1 year) * PySpark or Spark (1 year) - Desirable * Business Intelligence Data modelling (3 years) * SQL (3 years)",-1,Datonomy Solutions,Brackenfell,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We are assisting one of our clients that is based in Pretoria to fill a role of a Data Engineer

This is a 12 month contract role

Objective of this Scope of Work

The Data Engineer will drive improvement of the data management maturity levels and provide the necessary technical support within the company to support reliable and effective decision-making, appropriate usage and protection thereof.

Scope of Services Definition

The scope will include but will not be limited to:

ï†· To develop, construct, test and maintain architectures.

ï†· To ensure architectures will support the requirements of business.

ï†· To discover opportunities for data acquisition and sharing.

ï†· To develop data set processes for data modelling, mining and production.

ï†· To employ a variety of languages and tools to marry systems together.

ï†· To recommend way to improve data reliability, efficiency and quality.

ï†· To prepare data for use in predictive and prescriptive modelling.

ï†· To conduct research to answer industry and business questions.

ï†· To leverage volumes of data from internal and external to answer business questions.

ï†· To develop and manage stakeholder relations effectively to promote data management across the organisation and support reliable decision making and appropriate data usage.

ï†· To participate and provide technical support in cross organisational activities relating to any of the above mentioned data management activities.

ï†· To provide regular progress reports as per stakeholder requirements and present data management updates in various forums as required.

Minimum qualification Required:

ï†· A minimum of a Bachelors degree in Computer Science or Information Management OR equivalent;

ï†· A minimum of five to eight years experience in a data management environment",-1,HR Genie,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Our client based in the Northern Suburbs, is currently looking for a Data Engineer to join their team.

Responsibilities
Our client is a dynamic IT company that delivers value-driven IT solutions to the group. Our work lives revolve around our DNA. We take pride in our work, treat our colleagues, partners and our country with respect. We exercise collaborative decision-making and believe in having a balance in life. We do this all while having fun and enjoying what we do.

The primary focus of this position is to use technical skills to put software, systems and data together in a way that extracts meaningful insights from raw data. You will need to be helpful and supportive to your team and fellow developers. You join an energetic, focused and dynamic team.

Interact with clients to understand requirements and business problems/needs

Identify, analyse, visualise and understand supporting data to propose solid solutions

Create technical documentation for reference and reporting

Support existing solutions within GCP and Oracle

Doing standby on a rotating basis

Key Competencies and Qualifications

Matric

Tertiary qualification in IT

Preferred cloud experience in AWS/AZURE/GCP

At least 3 years of data warehouse ETL experience

Dimensional Modelling

Data analyses

Experience with data visualization and visualization tool(s)

Knowledge of the retail industry will be beneficial

Understanding and experience with version control SVN/GIT

Preferred – Korn shell scripting, Python/Java, SQL

Google Cloud Platform experience would be looked upon favourably

Having a broad understanding of different SDLC’s

Preferred agile experience

Strengths

The natural tendency to take ownership and responsibility

Strong problem solving, critical thinking, effective planning and organisational skills

Detail-oriented with excellent communication skills

You have a can-do attitude and positive outlook on life

Can cope under pressure

Curious and interested in analysing problems and possible solutions

Strong team player

Self-driven learner, passionate about new technology

Above all, be passionate about what you do

Should you wish to apply for the position, please apply directly via this job board, please ensure that you quote reference number 201620 subject heading or email body.

Please note that due to the high volume of CV's received; only shortlisted applicants will be contacted. Should you not receive communication from our offices within two weeks of submission please note that your application will not be considered for this position.

We will keep your CV on file and re-establish contact with you should opportunities in line with your expertise become available again.

Should you require any additional information give us a call on 021 012 5566.",-1,Surgo HR & Training,Cape Town,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We believe that our employees fuel our organization, essential to enable us to help our customers overcome their business challenges and achieve sustainable growth. As a result, we are committed to growing each individual and providing them with the challenges, feedback and support needed to achieve success in their career

If this sounds appealing, and like us, you get excited about data: its collection, storage, transformation or display, see if you’ve got what it takes to join our sought after DATA team.

Key Responsibilities And/or Outputs

You will represent IQbusiness at our customers, sometimes alone, and sometimes as part of an IQ team.

Providing a superior customer experience by building and maintaining relationships, working at customer offices, keeping data confidential
Design and develop – databases, SQL queries, stored procedures, reports, dashboards or integration solutions
Produce solutions for both real-time and batch environments
Test your work to ensure compliance
Solve problems, and do root cause analysis
Prioritize your workload
Assist in other areas relating to your true data function, such as data modeling, data and business analysts
Interact with a variety of individuals: senior, junior, technical and from business
Provide guidance to fellow colleagues, or even manage a team
Uphold the IQ values, which are to care, learn & share; innovate; deliver as well as to build, enhance and maintain relationships

Education

Matric pass
A tertiary qualification, preferably in an ICT relevant field
Appropriate Microsoft certifications are beneficial but not required

Requirements

3 - 6 years experience in the Data Engineering environments and technologies
Great communication skills
A passion for SQL, databases or reports
Can you write stored procedures, design complex queries and create views and triggers?
Are you able to work out the relationships in a data warehouse or the aggregation of a cube?
Do you extract and display useful information when you see patterns and trends in data?
Strong knowledge of the financial services industry, ideally in a consulting role
The use of data related software: databases, ETL and BI tools; report writing and analytical tools
We use a lot of Microsoft products. You may often be expected to use MS SQL Server, SSIS, SSRS, SSAS and Power BI to develop solutions
What other relevant software have you’ve used?
Ability to work in different project methodologies: Waterfall and/or Agile
Knowledge of full SDLC
Exposure to logical and physical data modeling

Equal Employment Opportunity

IQbusiness is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, citizenship, marital, domestic or civil partnership status, sexual orientation, or gender identity",3.7,"IQbusiness South Africa
3.7",Johannesburg,-1,1 to 50 Employees,-1,Company - Private,Consulting,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"We value a data engineer as someone who works behind the scenes to obtain, process and supply data via various methodologies and technologies, to various consumers, in ways and forms that makes sense and add value. This definition is very broad, as the field of data engineering is just as broad.

You may be the type of data engineer that develops API endpoints for the consumption of data by end users or even another data pipeline, or you may be the type of data engineer that develops highly distributed, high availability data processing pipelines in an effort to satisfy the need of the ever questioning data analysts and/or data scientists.

You have awesome knowledge about the following concepts
Data modelling
Relational data modelling in traditional relational database management systems. (Microsoft SQL Server, MySQL, PostgreSQL, etc)
Coercing unstructured and semi-structured data into a structured form.
Data pipelining knowledge - data extraction and transformation.
Data transformation knowledge for reporting and analytics purposes.
Knowledge of the MapReduce and related data processing paradigms would be a boon.
You have the following technical competencies
Writing SQL queries, that can relate, transform and aggregate data from many differing sources where natural keys may or may not exist.
Experience with writing data pipelines that move and transform data, for various uses.
Working knowledge of a general purpose programming language like Python would be a boost.
Working knowledge of columnar databases such as Google BigQuery, and SAP HANA would be a boost.
Working knowledge of highly distributed technologies such as Apache Hadoop or Apache Spark would be a boost.
Working knowledge of NoSQL technologies, such as Apache Solr would be a boost.
You have the following personal competencies
The ability to solve problems.
The ability to rotate around a problem, to see if solutions can be gained in different ways.
The ability to work in an ever changing, unstructured environment.
The ability to work as part of a team, with vastly differing skill sets and opinions.
The ability to contribute ideas to the quorum.
The ability to mentor and provide guidance for other team members.
A systems approach to thinking, as opposed to a siloed approach. The candidate needs to understand how their work affects the greater system.
The ability to work without supervision, and take accountability for the work they deliver.
The ability to liaise with a client, sifting through the fluff and extracting the actual requirements.
If this is you - apply now and we'll get in touch",-1,DotModus,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Data Engineer

Our client in the contact centre space is currently seeking a DATA ENGINEER that will work on the collecting, storing, processing, and analyzing of large datasets. The primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them. You will also be responsible for integrating them with the architecture used across the company.

Key Performance Areas:

Data reporting.
Implementing ETL processes.
Defining data retention policies.
Management of Customer Lead data.
Provision of data for advanced analytics.
Maintenance of internal client scorecards.
Assist team in resolving data-related support queries.
Optimize existing data processes through automation.
Assist with all data-related reporting and documentation.
Maintenance and optimisation of the Analytics database.
Provide technical support to and supervision of junior data administrators.
Continuous upskilling on new technologies, frameworks and market trends.
Monitoring performance and advising any necessary infrastructure changes.
Identifying, selecting and integrating any Big Data tools and frameworks required to provide real-time analytics.

Educational Requirements

IT related Degree or Diploma is a pre-requisite

Required Skills/Experience

ETL tools: Advanced SSIS
BI/Reporting : Qlikview/Power BI/ SSRS or SSAS
Programming languages: JAVA, C# , Python, SAS or R
Experience with NoSQL databases and/or campaign management tools will be advantageous.
Minimum 3 years’ applicable work experience in SQL, relational databases and data manipulation.
Experience in big data platforms (eg. Hadoop) or processing frameworks (eg. MapReduce/Spark) and querying tools (eg. Pig, Hive and Impala) will be highly beneficial.

Preferred Skills

Organizational skills
Experience in Attentional to detail.
Accountability is critical for this role.
Ability to work under pressure and meet deadlines.
Solid understanding of database design principles.
Should you not receive a response in 2 weeks please consider your application unsuccessful",-1,Rubik's Cubed Consulting,Durban,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"This well known company is looking for a Data Engineer. will be based in Rivonia
The ideal candidate will have strong experience in the following:
Data cleaning
SQL Export
Big data Sets

BSc Degree in Maths and Stats will be required
a min of 3 years experience.
Stable track record is required.

Send your Cv to marinda@prrrecruitment.co.za",-1,PRR Recruitment Services,Johannesburg,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Description

Position at Aculocity, LLC

At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes
Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.
Key Responsibilities
Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.
Key Traits
Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern
Position Requirements
2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.
Where will you work? This role will be based out of Durbanville, South Africa.",-1,GVW,Durbanville,-1,Unknown,-1,Unknown,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Information Technology, Gauteng JHB - Northern Suburbs

Market related - Market related Annually

An IT Consultancy Business based in Johannesburg is currently looking for a Business Intelligence Consultant / Data Engineering Consultant.

Requirements:

Extensive experience in data engineering
Experience in Business Intelligence, data and Power BI
Extensive experience in data governance and the Popi act
Ability to assess and make recommendations on data within the Popi act
Good understanding of T-SQL and query optimization, developing ETL strategies.
Good understanding with SQL Server 2008/2012, SSIS, SSRS and SSAS
Use SSIS to create ETL packages to validate, extract, transform, and load data into the data warehouse and data marts.
Deploy and configured the reports in the Report Server (SSRS).
Excellent experience in Tabular Modelling , PowerView, Qlikvie,w, and Power BI
Maintain ETL
Qlikview model
Create Drill-through, Drill-down, and Cross Tab Reports and Sub-Report using Report Definition Language (RDL).
Generate periodic reports based on the statistical analysis of the data using SQL Server Reporting Services (SSRS)
Advise and provide written technical documentation and recommendations

The information displayed above is not limited to advertisements. Please contact Thato for further information.

Please consider your application as unsuccessful if you have not received a response within 14 days of submitting your application. However, please keep a lookout on our website, www.bedifferent.co.za, for available positions that you may be suited for

Ad Visible Until: 29 October 2020
Ref: JHB005346/NL

Vacancy Type: Permanent",2.9,"Be Different Recruitment
2.9",Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Cloud Support Engineer (Big Data),-1,"ABOUT US

Amazon Web Services is the market leader and technology forerunner in the Cloud business. As a member of the AWS Support team you will be at the forefront of this transformational technology, assisting a global list of companies and developers that are taking advantage of a growing set of services and features to run their mission-critical applications. As a Cloud Support Engineer, you will act as the Cloud Ambassador across all the cloud products, arming our customers with required tools & tactics to get the most out of their Product and Support investment.

Would you like to use the latest cloud computing technologies? Do you have an interest in helping customers understand application architectures and integration approaches? Are you familiar with best practices for applications, servers and networks? Do you want to be part of a customer facing technology team helping to ensure the success of Amazon Web Services (AWS) as a leading technology organization?

If you fit the description, you might be the person we are looking for! We are a group of smart people, passionate about cloud computing, and believe that world class support is critical to customer success.

WHAT CAN YOU EXPECT FROM A LIFE AT AWS?

Every day will bring new and exciting challenges on the job while you:

· Learn and use groundbreaking technologies.
· Apply advanced troubleshooting techniques to provide unique solutions to our customers' individual needs.
· Interact with leading engineers around the world.
· Partner with Amazon Web Services teams to help reproduce and resolve customer issues.
· Leverage your extensive customer support experience to provide feedback to internal AWS teams on how to improve our services.
· Drive customer communication during critical events.
· Drive projects that improve support-related processes and our customers technical support experience.
· Write tutorials, how-to videos, and other technical articles for the developer community.
· Work on critical, highly complex customer problems that may span multiple AWS services.

WHY AWS SUPPORT?

· First and foremost this is a customer support role in The Cloud.
· On a typical day, a Support Engineer will be primarily responsible for solving customers cases through a variety of customer contact channels which include telephone, email, and web/live chat. You will apply advanced troubleshooting techniques to provide tailored solutions for our customers and drive customer interactions by thoughtfully working with customers to dive deep into the root cause of an issue.
· Apart from working on a broad spectrum of technical issues, an AWS Support Engineer may also coach/mentor new hires, develop & present training, partner with development teams on complex issues or contact deflection initiatives, participate in new hiring, write tools/script to help the team, or work with leadership on process improvement and strategic initiatives.
· Career development: We promote advancement opportunities across the organization to help you meet your career goals.
· Training: We have training programs to help you develop the skills required to be successful in your role.
· We hire smart people who are keen to build a career with AWS, so we are more interested in the areas that you do know instead of those you havent been exposed to yet.
· Support engineers interested in travel have presented training or participated in focused summits across our sites or at specific AWS events.
· As we operate on a follow-the-sun model, with Premium Support sites located globally, there is no after hours on-call or mandated overtime in this role.
· https://www.youtube.com/watch?v=GC3bWcFFZTo&t=24s



Basic Qualifications

The Big Data role supports our services that leverage data and produce business insights, which may include using Machine Learning/Artificial Intelligence (ML/AI). Helping our customers use and integrate Big Data services in what is arguably our industrys most exciting space. The portfolio of services covers EMR (Hadoop), DynamoDB (NoSQL), MangoDB, and Apache Cassandra.

· Advanced experience in Apache Hadoop, Apache Spark, Apache Hive, and Presto
· Advanced experience in DynamoDB or NoSQL technologies like MongoDB or Cassandra
· Advanced experience with System Administration with Linux (RHEL/CentOS) including Microsoft Active Directory, and LDAP integration.
· Experience with troubleshooting Kerberos Authentication problems.
· Experience with Network troubleshooting.
· Basic understanding of Machine Learning and statistics
· Experience with Java and Python and shell scripting
· Bachelors degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position



Preferred Qualifications

· Expert experience in the Hadoop Ecosystem including Apache Spark and Presto
· Expert experience in NoSQL
· Expert experience with blockchain technologies like Etherium Expert experience in data Data Lake architecture and administration
· Experience managing full application stacks from the OS up through custom applications
· Prior work experience with AWS - any or all of EC2, VPC, S3, RDS, EMR, Glue, SageMaker
· Excellent knowledge of Hadoop architecture, administration and support
· Expert understanding of distributed computing principles and their application in the cloud
· Good understanding of distributed computing environments Lead technical discussions on big data systems architecture and design
· Strong analysis and troubleshooting skills and experience
· AWS Certified Solutions Architect
· AWS certified Big Data Specialty
· Masters degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity and Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Response Center Engineer,-1,"Job Title
Response Center Engineer
Job Description


Philips is a world leading health technology company with a vision to make life better for people worldwide through meaningful innovation. Making good on this promise depends on our passionate, inspirational, collaborative and diverse team. We have over 80,000+ brilliant people around the world but are always looking for more. Like-minded, motivated, focused minds to join us in creating a healthier, more connected society while transforming themselves personally and professionally.

As a CCC Coordinator - Response Center Engineer you will have the opportunity to process customer calls and be responsible for screening and diagnosing professionally Healthcare equipment to support customers and colleagues remotely with solving technical issues and ensuring maximum customer satisfaction

You are responsible for:
Diagnose healthcare equipment to the quality standards set by Philips Healthcare (PH) remotely by interviewing customers or colleagues by telephone or by remotely logging in to the system
Advise Customer Care Center Coordinators and District Operations Managers and / or Team Leads about the best follow-up w.r.t. technical state of the diagnosed healthcare equipment
Advise the Customer Care Center Coordinators or Field Services Engineers about required spare parts and resources
Responsible for planning engineers related to Modality responsibility.
Responsible for coordination between CCC, CUSTOMER, Spare parts AND Engineer.
Responsible to drive Remote and FTR KPI’s to targets respectively 40% and 85%.
Will require minimal field work to keep abreast of technical capabilities.
Take calls from customers and make sure they are processed in the CCC ERP on timely manner including all relevant data
Support Field Services Engineers in the field with technical knowledge
Escalate technical issues to the Technical Support Specialist
Escalate technical issues to Business Unit support after consultation of the Technical Support Specialist
Monitor critical functions of the equipment’s in the IB and environmental conditions including RSN and True reachability.
Lead the planning and implementation of FSN’s and FCO’s accelerating remote implementation where applicable.
Submit timely and accurate service data, job sheets, reports, expense claims, radiation film badges, field problem reports and other paperwork as assigned
Keep abreast of new technologies likely to affect PH range of products
Use company property with care to ensure optimal results with minimal operational costs
Be a professional representative for PH with respect to customer problems, ensuring personal acceptability by the customer in behavior in accordance with PH policy and targets
Conform to PH safety standards including health and safety regulations and in the event of hazards or accidents to take immediate control of the situation and involve the Operations Manager and / or the responsible person to handle properly confidential issues according Philips standards and to act according General Business Principals
Follow all quality standards within the frame of valid PH business policies
Follow the company quality regulations (ISO 9001; PQA; TQM) and internal directives and procedures
You are a part of the dynamic South Africa Customer Care Centre Team .You will be reporting to the Customer Care Center Manager.

Requires a pleasant, assertive individual you can work very well in a team setting, a dynamic environment that requires flexibility and creativeness to achieve goals.

To succeed in this role, you should have the following skills and experience:
Degree level education or equivalent
Experience in maintenance and troubleshooting of technical complex systems
Fluent in English, verbal and written in addition to local language
In return, we offer you the unique combination of a critical and challenging role and a creative and empowering office environment. You will be actively encouraged to make improvements, establish best in class service and have a direct impact on the success of Philips on a daily basis.

Employment Equity

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply. Only apply for this role if you are a South African Citizen by birth or Naturalization prior to the 27 April 1994.

Why should you join Philips?

Working at Philips is more than a job. It’s a calling to create a healthier society through meaningful work, focused on improving 3 billion lives a year by delivering innovative solutions across the health continuum. Our people experience a variety of unexpected moments when their lives and careers come together in meaningful ways. Learn more by watching this video.

To find out more about what it’s like working for Philips at a personal level, visit the Working at Philips page on our career website, where you can read stories from our employee blog. Once there, you can also learn about our recruitment process, or find answers to some of the frequently asked questions.

Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.9,"Philips
3.9",Johannesburg,-1,10000+ Employees,1891,Company - Public,Health Care Services & Hospitals,Health Care,$10 to $25 million (USD),-1
Software Development Engineer - EC2 Placement,-1,"Build the systems that optimize how EC2 matches requests for Instances with the underlying compute capacity. EC2 Placement is seeking talented engineers to build the online and offline optimization systems for compute workload scheduling, and the customer capabilities to better manage those workloads. Amazon EC2 provides on-demand scalable compute capacity, and powers some of the largest services in the world. You will collaborate with a top-tier community of engineers to build systems to improve how customers are able to access EC2 compute resources.

The successful candidate will have strong software engineering experience, with a passion for thinking about, building and testing distributed systems. You have an interest in how Machine Learning and other optimization techniques can be applied to large-scale problems. You have demonstrated experience working with a team to design, build and operate large-scale systems. With strong engineering fundamentals, an analytical and data-driven approach to your work, and strong communication skills, you have the ability to collaborate well to deliver results. We move fast and work together on small teams to solve big problems.

If this opportunity sounds interesting, we would love to talk to you more about our work and the vibrant culture at AWS in Cape Town.

Basic Qualifications

· Degree in Computer Science or related field, or equivalent working experience
· 3+ years of industry experience in a software development environment
· Strong Computer Science fundamentals, including data structures, object-oriented design, algorithm design, problem solving, and complexity analysis.
· Proficiency in at least one modern programming language, such as Java, C#, Python, Scala, Kotlin

Preferred Qualifications

One or more of the following help you stand out:
· Demonstrated results designing, building and operating high-performance distributed systems in large-scale Linux environments
· Role model in writing high-quality, maintainable and secure code, mentoring others, and helping teams sharpen their development processes
· Ability to work effectively across teams to deliver results, with strong verbal and written communication skills
· Experience working with machine learning systems

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer - PBB IT,-1,"Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose


This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes
Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems
Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions
Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.

Research and best practices
Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development
Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.
Preferred Qualification and Experience
Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Aws Data Platform Engineer,-1,"Aws Data Platform Engineer

Posting Country:

South Africa

Date Posted:

15-Oct-2020

Full Time / Part Time:

Full Time

Contract Type:

Permanent

Joining Vodacom is more than a job, what we do matters. We don’t just carry minutes, texts and data – we carry people’s lives. And that’s a huge responsibility. If you think for a minute about the people you rely on…the likelihood is they rely on us.

Customers are at the heart of everything we do and we want to make a difference to the lives of our customers, and the communities in which we live and work. We support our people to give something back to the causes that mean the most to them through helping them give time and money to the charities they love.

And what’s it like to work here? We have created an environment where you can look forward to coming to work and are empowered to be at your best. We offer flexibility in how you work that helps you do your job in a way that suits you, opportunities to help you grow and progress throughout your career and a choice of benefits to suit your lifestyle.

Role Purpose
The H Band AWS Data Platform Engineer position is based within the Technology Business Unit.

The AWS Data Platform Engineer will be responsible for all Database services such as RDS, DynamoDB, etc. Should be able to migrate any databases from anywhere to AWS using any third-party tools or AWS database migration tool. Should also have understanding or expertise in creating data warehouses and data lake solutions on AWS.
Your responsibilities will include:
Apply practical knowledge of relational database design and usage with customers
Perform workload analysis and undertake performance tuning, as well as performance benchmarking in customer environments.
To develop state of the art solutions which are technically sound.
To provide a high-quality service to the Enterprise Cloud Services clients i.t.o. consultancy, solutions and delivery.
Commitment to team success and positive team dynamics including mentoring of other team members.
Passion for growing and applying technical skills in service to customers.
Be a trusted infrastructure advisor by providing objective, practical and relevant ideas, insights and advice.
Work collaboratively with consulting partners and technology teams to ensure high quality of solution delivery.
Encourage best practice and knowledge sharing with partners and cross-functional groups
Manage the overall database design and delivery of solutions.
Ability to make recommendations as they pertain to improvements in support/development initiatives and facilitate implementation with partners and cross-functional groups within the Business.
Participate in high level database solution definition and design during the implementation phase with the goal of providing reliable, stable and operationally sound applications that meet the Business requirements.
Ability to understand and translate business requirements into technical specifications
The ideal candidate will have:
A minimum of 3 years of industry related experience of which 1 year must be within a complex hosting environment.
Certifications in Database design, system architecture or cloud technologies.
Demonstrate knowledge of database systems internals including storage layouts and distributed databases/MPP architectures
Advanced SQL coding, tuning and query optimization.
Experience designing and leading database performance benchmarks.
Good knowledge of the different AWS services
Knowledge of cloud networking architecture, cloud operations, security, automation and orchestration.
Knowledge of database internals as it relates to query and system performance and tuning.
Understanding of overall system architecture, scalability, reliability, and performance in a database environment.
Excellent teamwork, time-management and organizational skills.
Perform other duties as deemed necessary and assigned by the customer and management
Strong interpersonal skills and problem-solving abilities.
Excellent documentation, communication and interpersonal skills.
Excellent analytical and problem-solving abilities.
Closing date for applications: Monday, 13 April 2020

The base location for this role is Vodacom World, Midrand

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply.
Vodacom is committed to an organisational culture that recognises, appreciates and values diversity & inclusion.

Commitment from Vodacom

Vodacom is committed to attracting, developing and retaining the very best people by offering a flexible, motivating and inclusive workplace in which talent is truly recognized, developed and rewarded. We believe that diversity plays an important role in the success of our business and we are committed to creating an inclusive work environment which respects, values, celebrates and makes the most of people’s individual differences - we are not only multinational but multicultural too. At Vodacom you will have access to our excellent flexible benefits programme that you would expect from any global company.",3.9,"Vodafone
3.9",Midrand,-1,10000+ Employees,1982,Company - Public,"Cable, Internet & Telephone Providers",Telecommunications,$10+ billion (USD),-1
Data Engineer Azure Data Factory,-1,"Enthuzex is looking for a motivated Lead Data Engineer to contribute towards the success of our Data and Analytics Technology initiatives. This is a hands-on technical role and this person will be responsible for the development and build of scalable solutions as it relates to the architecture strategies, data standards, digital data management, data integration, tools, and technology. The right candidate will play a deep dive hands-on critical development role in the digital transformation and in shaping how we acquire, ingest, transform and deliver data through the digital consumer channels.

Responsibilities:

Architect, design, develop and engineering end-to-end data pipelines across multiple data sources and systems of record.
Ensure data quality, integrity, security and completeness throughout the data lifecycle
Develop, design data models, data structures and ETL jobs for data acquisition and manipulation purposes
Develop deep understanding of the data sources, implement data standards, maintain data quality and master data management
Developing data services and API
Work closely with the cloud service providers to ensure completeness and alignment with the service offerings
Manage and maintain cloud based data and analytics platform
Deep understanding of the cloud offerings and engage in quick proof of concepts and proof of value in prototyping data and analytics solutions and derive viability
Ability to interact with the business stakeholders to understand requirements and translating into technology solutions

Expirience:

Experience in Cloud platform AWS or Azure eco-system. (Azure preferred)
Data Engineering/Development experience with SQL (Oracle, SQL Server, MySQL)
Strong development background creating pipelines and complex data transformations and manipulations using one of the languages Python, Java, R, or Scala with Databricks/Spark
Experience in NoSQL Databases and Big data technologies including Hadoop
Experience with API / RESTful data services
Worked on real-time data capture, processing and storing using technologies like Azure Event Hubs and Analytics
Experience working with different data storage options including AWS S3, Azure BLOB storage etc.
Understanding of different data formats including Parquet, Avro, CSV, ORC etc.
Prior experience with MPP databases and maintain large amount of data processing
Experience with Azure Data Factory and Azure Data Catalog is a big plus and mandatory
Experience with Microsoft/Azure ETL solutions and business Intelligence technologies is a big and mandatory
Past working experience on a fast paced and agile environment
Perform ongoing monitoring, automation and refinement of data engineering solutions
Experience in leading high visibility transformation projects that interacts with multiple business lines
Build and meet project timelines and manage delivery commitments with proper communication to management

Qualifications

Bachelor’s degree with 4+ years of relevant experience
Willingness to learn new technologies and thrive in an extremely fast paced environment
Team player and easy to work with.

Applicants must demonstrate their ability to master new enterprise level technologies. Successful applicants will exemplify Enthuzex ethical principles of uncompromising integrity, respect for others, and accountability for decisions

send cv's info@enthuzex.co.za",-1,Enthuzex,Leslie,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Scientist,-1,"The world is changing.

We all want something different.

At Luno, we see you as an individual.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the world, and to do so, we need the best team on board for our mission.

A bit about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 3 million customers across 40 countries.
We are Series B funded, backed by Balderton Capital and the Naspers Group.
Our platform has processed over 8 billion dollars since we've launched
We're proud to be one of the world's most international cryptocurrency teams from 26 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
The role in a nutshell:

Identifying opportunities in the business that could benefit most from cognitive applications, as well as building and enhancing organisational capabilities for deriving value from multiple data sources using data science.

What we'd like you to have:
Bachelor's degree or higher in the natural sciences or technical fields such as Mathematics, Statistics, Computer Science, Engineering or Economics
Enthusiasm to work in the cryptocurrencies space
Advanced SQL skills
Solid understanding of exploratory data analysis, predictive analytics, and optimisation using Python, R, Matlab, RapidMiner, KNIME or other data science-oriented platforms
Proficiency in the use of data science and machine learning domain-specific languages such as ""Caret"" and the ""Tidyverse"" suite of tools in R, or ""Pandas"" in Python
Strong interpersonal and communication skills
Communicating data insights using storytelling narratives
Ability to work independently, as well as within and across teams
Ability to successfully complete projects with large and/or incomplete data sets
More about what you'll be doing:
Optimising product performance by tracking and analysing customer behaviour on web and app, in collaboration with software engineers and product designers
Providing the business with reports and dashboards, on key performance metrics
Developing metrics to accurately assess the health of our Exchange platform
Comparative data-driven analysis of our Exchange against alternative platforms
Formulating business requirements into analytical objectives
Designing and running experiments to test hypotheses
Hacking through complex business problems using advanced data analysis to provide insights and recommendations
Building, maintaining, and optimising decisioning systems using advanced statistical and predictive modelling techniques
What will set you apart:
An advanced degree in Mathematics, Statistics, Computer Science or related field
At least 3 years' experience working in a similar role
A basic understanding of trading in financial markets
Experience working with a data analytics and visualisation platform such as Tableau, Cognos, QlikView, or Looker
Familiarity with using Google Analytics to understand customer behaviour
Solid knowledge of statistical and machine learning techniques
Familiarity with modern distributed data storage and processing systems such as Amazon Redshift, Big Query, Snowflake, Databricks and Apache Spark
You can gather and synthesise facts, theories, trends, patterns, inferences, and key issues in complex and variable situations
Ability to diagnose problems using formal problem-solving tools and techniques from multiple angles to generate multiple possible solutions
A sense of anticipating long-term problem areas and associated risk levels with objective rationale
Remote Life at Luno

If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
You'll be able to continuously upskill yourself with access to free online learning via MyAcademy, an international teaching marketplace with over 100000 courses from Harvard and other leading providers + share knowledge with your peers.
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity and paternity leave, and you can even take paw-ternity leave for your furry friend.
Annual Inspiration Day! Make time for that pottery course or spa day you've always wanted to do.
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"EY is a global leader in
assurance, tax, transaction and advisory services. Technology is at the heart
of what we do and deliver at EY. Technology solutions are integrated in the
client services we deliver and are key to our innovation as an organization.

Fueled by
strategic investment in technology and innovation, Client Technology seeks to
drive growth opportunities and solve complex business problems for our clients
through building a robust platform for business and powerful product engine
that are vital to innovation at scale. As part of Client Technology, you’ll
work with technologists and business experts, blending EY’s deep industry
knowledge and innovative ideas with our platforms, capabilities, and technical
expertise. As a catalyst for change and growth, you’ll be at the forefront of
integrating emerging technologies from AI to Data Analytics into every corner
of what we do at EY. That means more growth for you, exciting learning
opportunities, career choices, and the chance to make a real impact.

The selected
candidate
Develops
large and complex data architecture, composed of models, policies, rules or
standards that govern which data is collected and how it is stored, arranged,
integrated and put to use in data systems, including the design, build and
management of data infrastructure to address business requirements
Creates
sound use case driven roadmaps, depicting data architecture as-is and to-be
capabilities with the business by engaging with multidisciplinary teams, and by
identifying, managing and mitigating risk
Develops
relationships across the business to understand data requirements, applies deep
technical knowledge of data management to solve business problems in areas
where solutions may not currently exist, necessitating new solutions/ways of
working/technologies and proactively articulating these to the business
Review,
identify the latest emerging technologies, augmenting by services from the
leading cloud providers to solution and recommend the best next generation data
platform value driven approach for our clients
Your Key Responsibilities Include
Create
and maintain conceptual, logical and physical database models
Document
functional requirements and system specifications into the data architecture
and detailed design specifications for current and proposed designs
Document
and adhere to development standards and best practices in database designs
Maintain
highly effective and consistent communication within the team, peers, and the
leadership team
Reverse
engineer SQL code and modify it to solve problems/issues
Contribute
to the definition and implementation of data governance practices
Design
both data structures and data integration practices
Work
closely with the infrastructure teams to create a physical environment to
support data services
Evaluate
new and existing (internal and external) technologies and services in support
of data services and data analytics objectives
Skills And Attributes For Success
Understanding
of business process reengineering and business modeling concepts, business
systems development and analysis
Hands-on
experience in designing and implementing hybrid cloud and on-prem solutions
Experience
working with the latest versions of SQL Server
Experience
applying SAFe/Scrum/Kanban methodologies
Ability
to exercise judgment in solving technical, operational, and organizational
challenges
Expert
programming, performance tuning and troubleshooting skills, using the latest
popular programming languages for example python
Demonstrate
proactive approach to identifying issues and presenting solutions and options,
and where appropriate, leading to resolution
Minimum Qualifications
5+ years
demonstratable work experience as a Data Architect using data modeling tools
2-3 years
SQL coding experience on large projects
Must
possess expert SQL programming, performance tuning and troubleshooting skills
Create
database objects and SQL scripts
Understand
and developed data pipelines
Know how
to deformalize data for data science models
Experience
in python, spark and notebooks
Experience
designing data warehousing solutions
Experience
designing next generation data platforms utilising cloud services
In-depth
understanding of database structure principles
Seamlessly
able to translate business requirements to technology requirements
What We Look For
Strong
analytical skills and problem-solving ability
A
self-starter, independent-thinker, curious and creative person with ambition
and passion
Excellent
inter-personal, communication, collaboration, and presentation skills
Customer
focused
Excellent
time management skills
Positive
and constructive minded
Takes
responsibility for continuous self-learning
Takes the
lead and makes decisions in critical times and tough circumstances
Attention
to detail
High
levels of integrity and honesty
Curious
about new emerging technology
About EY
As a global leader in assurance, tax, transaction and consulting
services, we’re using the finance products, expertise and systems we’ve
developed to build a better working world. That starts with a culture that
believes in giving you the training, opportunities and creative freedom to make
things better. Whenever you join, however long you stay, the exceptional EY
experience lasts a lifetime.",3.8,"EY
3.8",Johannesburg,-1,10000+ Employees,1989,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Architect - Principal,-1,"We are looking for Principle Data Architect to join our Engineering team in Cape Town.

The world is changing.
We all want something different.
At Luno, we see you as individuals.

Together, we are upgrading the world of work to unleash the potential within and empower you to become the best possible version of yourself.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the financial landscape, and to do so, well we need the best team on board for our mission. In short, to achieve our goals, we need rockstars. As simple as that.

A little about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 5 million customers across 40 countries.
We're part of the Digital Currency Group, a group of companies driving progress in the cryptocurrency and blockchain space that includes Grayscale, Genesis, Coindesk and Foundry Services
Our platform has processed over $8 billion to date
We're proud to be one of the world's most international cryptocurrency teams from 43 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
How we work


Our engineering team (currently ~100 engineers) is split into organisations which we call Fleets. Each Fleet focuses on a core customer journey (onboarding, security, payments, support, new business, growth and marketing etc.). Each of these fleets contains multiple smaller teams called Pods, each of which focuses on a specific aspect of the product.

Pods will include a product owner, product designer, back-end engineers, Android, iOS and Web developers, who each bring a unique perspective to the problem you are all contributing towards.

We're agile, use scrum, continuous integration and continuous delivery, deploying to production every single day.

We're building teams to help us succeed in our mission to upgrade the world to a better financial system. You'll be joining a group of highly motivated software engineers who you'll work collaboratively with across our pods.

As a fast-growing company with offices around the world, you'll immediately see how your contributions directly impact both our internal users and client experience. Many of the problems we are solving result in trail blazing solutions which can't be found on Stack Overflow; so we're looking for engineers who flourish working in a complex domain.

In your first six months, you will:


...start at Luno by learning our processes, meeting the wider team and starting our engineering on-boarding program. After getting comfortable with the basics, you'll start learning our idiomatic patterns in a safe, easy-to-follow way - by building your own toy micro services. You'll get to practice how we do design docs, code reviews, deployments, events, logging and monitoring.

You'll meet the Pod(s) you'll be working with and quickly align on the teams' current OKRs and product roadmap. We succeed as a team, so we will provide you with regular feedback from your manager and peers and will encourage you to do the same.

What you'll do:
Work closely with our data science and platform teams on projects introducing new streams of data into our data lake
You will get to bring new ideas on how to further develop and innovate our data solutions and how to expose that data to the business
Accountable and Responsible for the design and architecture of Data systems that are robust and scalable.
Work in an Agile/Scrum framework or Agile mindset
Data backup/recovery and storage
Pick-up and learn new concepts, in both engineering and product, and be able to apply that knowledge quickly.
The ideal candidate for this role will have:
7+ years' experience in maintaining scalable data solutions and/or you are passionate about it
Ability to understand, communicate and advocate between build vs buy
Proven track record of setting up, restructuring and maintenance of databases
You know your way around ETL and you have experience with SQL
Experience in the AWS Data stack (RedShift,DynamoDB, Amazon RDS)
Familiarity with integrating data stores with BI platforms such as Looker, Tableau, or Power BI
You have experience with the concepts of CI/CD
Coding skills in e.g. Go, Python
Bachelor's degree in a related field preferred
AWS Certified DataOps Administrator
Be friendly, transparent, articulate and driven to succeed
Basic knowledge of and passion for digital currencies like Bitcoin
A work permit for South Africa if you are not a South African citizen
Don't be put off if you don't tick all of the boxes – they're a guide based on what we'd love to see but we appreciate that excellent software engineers have diverse backgrounds.

Remote Life at Luno


If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity / paternity and even (yes, you are reading it correctly) paw-ternity for your furry friend..
Annual Inspiration Day.. like that pottery course you've always been meaning to do!
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. You'll need to hold the legal right to work in South Africa already as we cannot provide visa sponsorship.

Be part of the change!",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer - EC2 Capacity Data Analytics,-1,"EC2 Capacity Data Analytics (CDA) team is looking for a Data Engineer to join our team.

Our team is part of the EC2 Capacity Engineering organization, which is responsible for providing the elasticity EC2 customers need to scale up/down compute resources in a cost-efficient manner. We predict customer usage across thousands of configuration combinations to deliver exactly what our customers require in just the right amount of time with just the right amount of capacity.

As a Data Engineer, you will build the ETL and analytics solutions for our internal customers to answer questions with data and drive critical improvements for the business. You will use best practices in software engineering, data management, data storage, data compute, and distributed systems. On any given day, we use Python, Scala, Java, SQL, Lambda, CloudFormation, Redshift and Glue as well as other public AWS services and a host of Amazon internal tools. We dont expect you to be an expert in, or necessarily even be familiar with all of the technologies listed above, but we do expect you to be excited to learn about them.

This position involves on-call responsibilities, typically for one week every two months. Our team is dedicated to supporting new team members. We care about your career growth, we try to assign projects and tasks based on what will help each team member develop into a more well-rounded engineer and enable them to take on more complex tasks in the future.

Our team values work-life balance and we are flexible when people occasionally need to work from home.

Job Duties
Develop and maintain automated ETL pipelines for big data using languages such as Scala, Spark, SQL and AWS services such as S3, Glue, Lambda, SNS, SQS, KMS. Example: ETL jobs that process a continuous flow of JSON source files and output the data in a business-friendly Parquet format that can be efficiently queried via Redshift Spectrum using SQL to answer business question.

Develop and maintain automated ETL monitoring and alarming solutions using Java/Python/Scala, Spark, SQL, and AWS services such as CloudWatch and Lambda.

Implement and support reporting and analytics infrastructure for internal business customers using AWS, services such Athena, Redshift, Spectrum, EMR, and QuickSight.

Develop and maintain data security and permissions solutions for enterprise scale data warehouse and data lake implementations including data encryption and database user access controls and logging.

Develop and maintain data warehouse and data lake metadata, data catalog, and user documentation for internal business customers.

Develop, test, and deploy code using internal software development toolsets. This includes the code for deploying infrastructure and solutions for secure data storage, ETL pipelines, data catalog, and data query.


Basic Qualifications

· Bachelors degree in Computer Science or related technical field, or equivalent work experience.
· 4+ years of overall work experience including Software Engineering, Data Engineering, Database Engineering, Business Intelligence.
· Experience with AWS technologies stack including Lambda, Glue, Redshift, RDS, S3, EMR or similar big data solutions stack

Preferred Qualifications

· Demonstrate efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data.
· Demonstrable proficiency in distributed systems and data architecture; design and implementation of batch and stream data processing pipelines; knows how to optimize the distribution, partitioning, and MPP of high-level data structures.

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer,-1,"Our client based in Johannesburg is urgently looking for a Data Engineer to be on a 3 months contract
Build data pipelines, experience in new tech like nifi, kafka, python

Joburg based, open to EE, 3 month contract with the option to extend, must be available at short notice",-1,EQplus,Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Overview
Job ID: 51456
Job Sector: Information Technology and Services
Country: South Africa
Region/State/Province/District: Gauteng
Location: Johannesburg

Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose

This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes

Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems

Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions

Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.
Research and best practices

Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development

Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.

Preferred Qualification and Experience

Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry

Knowledge/Technical Skills/Expertise

Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision

PLEASE NOTE: All our recruitment and selection processes comply with applicable local laws and regulations. We will never ask for money or any form of payment as part of our recruitment process. If you experience this, please contact our Fraudline on +27 800222050 or forward to TransactionFraudOpsSA@standardbank.co.za",4.1,"Standard Bank
4.1",Johannesburg,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"About us

At PBT Group we pride ourselves on being a Data Specialist organisation. With 20 years of experience in 27 countries over 3 continents, our team of 550 consultants have implemented more than 700 projects.",4.3,"PBT Group
4.3",Johannesburg,-1,Unknown,-1,Company - Private,Accounting,Accounting & Legal,Less than $1 million (USD),-1
Data Engineer,-1,"Kick-start your career in the online gaming world and experience the very latest in technology and innovation.

The Department:

Our mission is to provide our customers with the best online betting experience and share the thrill of gaming with them. Data is at the very heart of our business and is vital in everything we do.

Our cross-functional Data team has a big and exciting challenge ahead. We are in the process of re-platforming our traditional, on-premises RDBMS environment to a new microservice architecture in the cloud. We’re making use of the diverse set of data technologies in Microsoft Azure to offer new services, reporting structures and real-time data pipeline while serving the day-to-day requirements of a rapidly growing, data-hungry organisation.

Purpose of the Role:

This is an excellent opportunity for an individual who is looking to gain new skills. We are committed to creating a culture of learning and regularly run proof of concepts, provide internal demos, manage workshops and attend external conferences. Our data team has a wide range of skills including development for highly transactional RDBMS systems, data warehousing, data science and cloud technologies and we are always working to raise everyone’s game.

Duties include, but not limited to:

Work as part of an agile Data Engineering Team
Development of greenfield projects in Azure
Develop and maintain on-premises RDBMS/DW systems
Create robust ETL services and real-time data pipelines
Build and maintain Continuous Integration and DevOps pipelines
Test-driven development and pair programming with colleagues

Essential Criteria:

C#, .Net, Visual Studio
Git, Azure DevOps
NoSQL development (CosmosDB)
Demonstrable understanding of MS SQL Server in a highly transactional environment
Demonstrable understanding of development in Microsoft Azure
Able to understand query plans and identify performance bottlenecks
Test/Business-Driven Development
Building Continuous Integration/Deployment pipelines
Communicate effectively with both technical and non-technical stakeholders

Desirable Criteria:

Implementing Data Storage and Processing solutions in Azure (ARM Templates, Storage Accounts, Data Lake Storage, SQL DB, Cosmos DB, EventHubs, Function Apps, Log Analytics, Data Factory, Databricks, Polybase)
Implementing Security, Disaster Recovery, High Availability, Auditing, Monitoring and Alerting solutions in Azure
Automating tasks in Azure using Powershell / CLI
Predicting costs and optimizing spending in Azure
Message Queues (RabbitMQ, Kafka)
Python

Person Specifications:

Resilience
Teamwork
Technical Knowledge
Communication skills
Stress Tolerance
Please note we will apply relevance to our Talent Management and Talent Development Programme as part of our recruitment process.
Shortlisted candidates may need to complete an assessment.
This position requires trust and honesty it has access to customers financial details - therefore a credit and criminal record check will be conducted. The qualifications identified herein are an inherent job requirement; therefore, a qualification verification check will be done. By applying for this role, and supplying the necessary details, you hereby grant us permission to apply for these checks. This will be done in a confidential manner, and solely for the purposes of verification.

To view all current vacancies, please visit our website, www.digioutsource.com

Should you not hear from us within 2 weeks, please deem your application as unsuccessful.

The perfect place to work, play and grow!",3.9,"Digital Outsource Services
3.9",Cape Town,-1,1001 to 5000 Employees,1997,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
Data Engineer,-1,"At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes

Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.

Key Responsibilities

Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.

Key Traits

Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern

Position Requirements

2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.

Where will you work? This role will be based out of Durbanville, South Africa.",3.1,"Aculocity, LLC
3.1",Durbanville,-1,1 to 50 Employees,2006,Company - Private,IT Services,Information Technology,$1 to $5 million (USD),-1
Data Engineer,-1,"ENVIRONMENT:

A rapidly growing E-Commerce Platform seeks a highly talented Data Engineer to make an invaluable contribution to data democratisation and literacy vision by making accessible and easy-to-use data products and tools. You will require a Comp-Sci Degree or 3 years’ relevant industry experience, MySQL, PostgreSQL, Java, Python, in-depth understanding of OLAP, Data Marts, Star Scheme, Snowflake, be familiar with Jenkins, Travis, Circle CI, Docker, Kubernetes, experience with Kafka, Pub/Sub, Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks & significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing & Data Lake design and implementation and Lambda/Kappa architectures.

DUTIES:

Design, develop, test and maintain data architecture.

Prepare data for descriptive, predictive and prescriptive modelling.

Automate repetitive tasks and manual processes related with the data usage.

Optimize data delivery.

Design, develop and test large stream data pipelines to ingest, aggregate, clean, and distribute data models ready for analysis.

Ensure the highest standard in data integrity.

Leverage best practices in continuous integration and delivery.

Collaborate with other engineers, ML experts, analysts, and stakeholders to produce the most efficient and valuable solutions.

Implement features, technology, and processes that move us towards industry best practices, improving on scalability, efficiency, reliability, and security.

Operations and ownership of systems in production, responding to incidents.

REQUIREMENTS:

Qualifications –

Comp-Sci Degree or 3 years relevant industry experience.

Experience/Skills –

Open source relational database systems e.g. MySQL, PostgreSQL, etc.

Significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing, and Data Lake design and implementation and Lambda/Kappa architectures.

A thorough understanding of database and data warehousing principles e.g. OLAP, Data Marts, Star Schema, Snowflake, etc.

Java and Python.

Familiar with CI/CD tools such as Jenkins, Travis, Circle CI, etc.

Experience with Kafka, Pub/Sub, or other event-based systems.

Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks, etc.

Working in cloud environments and with containerisation frameworks, tools and platforms e.g. Docker, Kubernetes, GKE, etc.

A deep understanding of data pipelining, streaming, and Big Data technologies, methods, patterns, and techniques.

Troubleshooting complex database operations and performance issues.

Automating tasks using Shell Scripting or writing small applications.

ATTRIBUTES:

Works well with people and is passionate about helping people be their best.

A team player, an active listener, mentor, and able to communicate well.

Shows solid reasoning and decision making, with the ability to work under pressure.

Is passionate about technology, systems and data.

Is curious, always learning, and keeping up to date with the industry.

While we would really like to respond to every application, should you not be contacted for this position within 10 working days please consider your application unsuccessful.

COMMENTS:

When applying for jobs, ensure that you have the minimum job requirements. Only SA Citizens will be considered for this role. If you are not in the mentioned location of any of the jobs, please note your relocation plans in all applications for jobs and correspondence.",-1,Datafin IT Recruitment,Cape Town,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Cartrack is looking for passionate data science and engineering candidates that can join a growing team that is responsible for the intelligence and efficiency solution provision to over a million subscribers, many of whom are large fleets. We are in the midst of creating revolutionary platforms that will change the way that people interact with their vehicles.

You will have the opportunity to work with the very brightest global subject matter experts that are transforming the automotive industry across Fleet Management, Asset Management and Insurance Telematics solutions.

Get to know the role:

The role of a data engineer is a supporting one, but it is also an extremely vital one. As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements. We want to see candidates with mechanical tendencies and a desire to know how things work and to improve them.

The day-to-day activities:

Design, construct, install, test and maintain data management systems.
Build high-performance algorithms, predictive models, and prototypes.
Ensure that all systems meet the business/company requirements as well as industry practices.
Integrate up-and-coming data management and software engineering technologies into existing data structures.
Develop set processes for data mining, data modeling, and data production.
Create custom software components and analytics applications.
Research new uses for existing data.
Employ an array of technological languages and tools to connect systems together.
Install/update disaster recovery procedures.
Recommend different ways to constantly improve data reliability and quality.
Work on and maintain Data pipelines.

Requirements Essential:

At least 5 years’ proven experience as a Data Engineer, DevOps Engineer, Software Developer, or similar.
Proficient in Linux/Unix and shell scripting as well as in functional programming languages.
Expertise in setting up and explored with technologies such as Hadoop and Spark.
Bachelor’s degree in computer science, software/computer engineering, applied mathematics, or physics.",3.3,"Cartrack
3.3",Johannesburg,-1,501 to 1000 Employees,2004,Company - Private,Security Services,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Data Engineer,-1,"Data Engineers build and support data pipelines and datamarts built off those pipelines. Both must be scalable, repeatable and secure. The Data Engineer helps to facilitate gathering data from a variety of different sources, in the correct format, assuring that it conforms to data quality standards and assuring that downstream users can get to that data timeously. This role functions as a core member of an agile team. These professionals are responsible for the infrastructure that provides insights from raw data, handling and integrating diverse sources of data seamlessly. They enable solutions, by handling large volumes of data in batch and real-time by leveraging emerging technologies from both the big data and cloud spaces. Additional responsibilities include developing proof of concepts and implements complex big data solutions with a focus on collecting, parsing, managing, analysing and visualising large datasets. They know how to apply technologies to solve the problems of working with large volumes of data in diverse formats to deliver innovative solutions. Data Engineering is a technical job that requires substantial expertise in a broad range of software development and programming fields. These professionals have a knowledge of data analysis, end user requirements and business requirements analysis to develop a clear understanding of the business need and to incorporate these needs into a technical solution. They have a solid understanding of physical database design and the systems development lifecycle. This role must work well in a team environment.

Job Objectives

Work Complexity: * Architects Data analytics framework. * Translates complex functional and technical requirements into detailed architecture, design, and high performing software. * Leads Data and batch/real-time analytical solutions leveraging transformational technologies. * Works on multiple projects as a technical lead driving user story analysis and elaboration, design and development of software applications, testing, and builds automation tools.

Main Job Objectives: 1. Development and Operations 2. Database Development and Operations 3. Policies, Standards and Procedures 4. Communications 5. Business Continuity & Disaster Recovery 6. Research and Evaluation 7. Coaching/ Mentoring

Qualifications

Essential: 4 years Bachelors degree in computer science, computer engineering, or equivalent work experience AWS Certification at least to associate level

Experience

Essential:

5+ years Data engineering or software engineering

3-5 years demonstrated experience leading teams of engineers

2+ years Big Data experience

5+ years experience with Extract Transform and Load (ETL) processes

2+ years Could AWS experience

At least 2 years demonstrated experience with agile or other rapid application development methods - Agile exposure, Kanban or Scrum

5 years demonstrated experience with object oriented design, coding and testing patterns as well as experience in engineering (commercial or open source) software platforms and large scale data infrastructures.

Desirable:

5+ years Retail Operations experience

Knowledge and Skills

Essential: *Creating data feeds from on-premise to AWS Cloud (2 years) *Support data feeds in production on break fix basis (2 years) *Creating data marts using Talend or similar ETL development tool (4 years) *Manipulating data using python and pyspark (2 years) *Processing data using the Hadoop paradigm particularly using EMR, AWSs distribution of Hadoop (2 years) *Devop for Big Data and Business Intelligence including automated testing and deployment (2 years) * Extensive knowledge in different programming or scripting languages * Expert knowledge of data modeling and understanding of different data structures and their benefits and limitations under particular use cases.

Further technical skills required: * Capability to architect highly scalable distributed systems, using different open source tools. * Big Data batch and streaming tools * Talend (1 year) * AWS: EMR, EC2, S3 (1 year) * Python (1 year) * PySpark or Spark (1 year) - Desirable * Business Intelligence Data modelling (3 years) * SQL (3 years)",-1,Datonomy Solutions,Brackenfell,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We are assisting one of our clients that is based in Pretoria to fill a role of a Data Engineer

This is a 12 month contract role

Objective of this Scope of Work

The Data Engineer will drive improvement of the data management maturity levels and provide the necessary technical support within the company to support reliable and effective decision-making, appropriate usage and protection thereof.

Scope of Services Definition

The scope will include but will not be limited to:

ï†· To develop, construct, test and maintain architectures.

ï†· To ensure architectures will support the requirements of business.

ï†· To discover opportunities for data acquisition and sharing.

ï†· To develop data set processes for data modelling, mining and production.

ï†· To employ a variety of languages and tools to marry systems together.

ï†· To recommend way to improve data reliability, efficiency and quality.

ï†· To prepare data for use in predictive and prescriptive modelling.

ï†· To conduct research to answer industry and business questions.

ï†· To leverage volumes of data from internal and external to answer business questions.

ï†· To develop and manage stakeholder relations effectively to promote data management across the organisation and support reliable decision making and appropriate data usage.

ï†· To participate and provide technical support in cross organisational activities relating to any of the above mentioned data management activities.

ï†· To provide regular progress reports as per stakeholder requirements and present data management updates in various forums as required.

Minimum qualification Required:

ï†· A minimum of a Bachelors degree in Computer Science or Information Management OR equivalent;

ï†· A minimum of five to eight years experience in a data management environment",-1,HR Genie,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Our client based in the Northern Suburbs, is currently looking for a Data Engineer to join their team.

Responsibilities
Our client is a dynamic IT company that delivers value-driven IT solutions to the group. Our work lives revolve around our DNA. We take pride in our work, treat our colleagues, partners and our country with respect. We exercise collaborative decision-making and believe in having a balance in life. We do this all while having fun and enjoying what we do.

The primary focus of this position is to use technical skills to put software, systems and data together in a way that extracts meaningful insights from raw data. You will need to be helpful and supportive to your team and fellow developers. You join an energetic, focused and dynamic team.

Interact with clients to understand requirements and business problems/needs

Identify, analyse, visualise and understand supporting data to propose solid solutions

Create technical documentation for reference and reporting

Support existing solutions within GCP and Oracle

Doing standby on a rotating basis

Key Competencies and Qualifications

Matric

Tertiary qualification in IT

Preferred cloud experience in AWS/AZURE/GCP

At least 3 years of data warehouse ETL experience

Dimensional Modelling

Data analyses

Experience with data visualization and visualization tool(s)

Knowledge of the retail industry will be beneficial

Understanding and experience with version control SVN/GIT

Preferred – Korn shell scripting, Python/Java, SQL

Google Cloud Platform experience would be looked upon favourably

Having a broad understanding of different SDLC’s

Preferred agile experience

Strengths

The natural tendency to take ownership and responsibility

Strong problem solving, critical thinking, effective planning and organisational skills

Detail-oriented with excellent communication skills

You have a can-do attitude and positive outlook on life

Can cope under pressure

Curious and interested in analysing problems and possible solutions

Strong team player

Self-driven learner, passionate about new technology

Above all, be passionate about what you do

Should you wish to apply for the position, please apply directly via this job board, please ensure that you quote reference number 201620 subject heading or email body.

Please note that due to the high volume of CV's received; only shortlisted applicants will be contacted. Should you not receive communication from our offices within two weeks of submission please note that your application will not be considered for this position.

We will keep your CV on file and re-establish contact with you should opportunities in line with your expertise become available again.

Should you require any additional information give us a call on 021 012 5566.",-1,Surgo HR & Training,Cape Town,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We believe that our employees fuel our organization, essential to enable us to help our customers overcome their business challenges and achieve sustainable growth. As a result, we are committed to growing each individual and providing them with the challenges, feedback and support needed to achieve success in their career

If this sounds appealing, and like us, you get excited about data: its collection, storage, transformation or display, see if you’ve got what it takes to join our sought after DATA team.

Key Responsibilities And/or Outputs

You will represent IQbusiness at our customers, sometimes alone, and sometimes as part of an IQ team.

Providing a superior customer experience by building and maintaining relationships, working at customer offices, keeping data confidential
Design and develop – databases, SQL queries, stored procedures, reports, dashboards or integration solutions
Produce solutions for both real-time and batch environments
Test your work to ensure compliance
Solve problems, and do root cause analysis
Prioritize your workload
Assist in other areas relating to your true data function, such as data modeling, data and business analysts
Interact with a variety of individuals: senior, junior, technical and from business
Provide guidance to fellow colleagues, or even manage a team
Uphold the IQ values, which are to care, learn & share; innovate; deliver as well as to build, enhance and maintain relationships

Education

Matric pass
A tertiary qualification, preferably in an ICT relevant field
Appropriate Microsoft certifications are beneficial but not required

Requirements

3 - 6 years experience in the Data Engineering environments and technologies
Great communication skills
A passion for SQL, databases or reports
Can you write stored procedures, design complex queries and create views and triggers?
Are you able to work out the relationships in a data warehouse or the aggregation of a cube?
Do you extract and display useful information when you see patterns and trends in data?
Strong knowledge of the financial services industry, ideally in a consulting role
The use of data related software: databases, ETL and BI tools; report writing and analytical tools
We use a lot of Microsoft products. You may often be expected to use MS SQL Server, SSIS, SSRS, SSAS and Power BI to develop solutions
What other relevant software have you’ve used?
Ability to work in different project methodologies: Waterfall and/or Agile
Knowledge of full SDLC
Exposure to logical and physical data modeling

Equal Employment Opportunity

IQbusiness is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, citizenship, marital, domestic or civil partnership status, sexual orientation, or gender identity",3.7,"IQbusiness South Africa
3.7",Johannesburg,-1,1 to 50 Employees,-1,Company - Private,Consulting,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"We value a data engineer as someone who works behind the scenes to obtain, process and supply data via various methodologies and technologies, to various consumers, in ways and forms that makes sense and add value. This definition is very broad, as the field of data engineering is just as broad.

You may be the type of data engineer that develops API endpoints for the consumption of data by end users or even another data pipeline, or you may be the type of data engineer that develops highly distributed, high availability data processing pipelines in an effort to satisfy the need of the ever questioning data analysts and/or data scientists.

You have awesome knowledge about the following concepts
Data modelling
Relational data modelling in traditional relational database management systems. (Microsoft SQL Server, MySQL, PostgreSQL, etc)
Coercing unstructured and semi-structured data into a structured form.
Data pipelining knowledge - data extraction and transformation.
Data transformation knowledge for reporting and analytics purposes.
Knowledge of the MapReduce and related data processing paradigms would be a boon.
You have the following technical competencies
Writing SQL queries, that can relate, transform and aggregate data from many differing sources where natural keys may or may not exist.
Experience with writing data pipelines that move and transform data, for various uses.
Working knowledge of a general purpose programming language like Python would be a boost.
Working knowledge of columnar databases such as Google BigQuery, and SAP HANA would be a boost.
Working knowledge of highly distributed technologies such as Apache Hadoop or Apache Spark would be a boost.
Working knowledge of NoSQL technologies, such as Apache Solr would be a boost.
You have the following personal competencies
The ability to solve problems.
The ability to rotate around a problem, to see if solutions can be gained in different ways.
The ability to work in an ever changing, unstructured environment.
The ability to work as part of a team, with vastly differing skill sets and opinions.
The ability to contribute ideas to the quorum.
The ability to mentor and provide guidance for other team members.
A systems approach to thinking, as opposed to a siloed approach. The candidate needs to understand how their work affects the greater system.
The ability to work without supervision, and take accountability for the work they deliver.
The ability to liaise with a client, sifting through the fluff and extracting the actual requirements.
If this is you - apply now and we'll get in touch",-1,DotModus,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Data Engineer

Our client in the contact centre space is currently seeking a DATA ENGINEER that will work on the collecting, storing, processing, and analyzing of large datasets. The primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them. You will also be responsible for integrating them with the architecture used across the company.

Key Performance Areas:

Data reporting.
Implementing ETL processes.
Defining data retention policies.
Management of Customer Lead data.
Provision of data for advanced analytics.
Maintenance of internal client scorecards.
Assist team in resolving data-related support queries.
Optimize existing data processes through automation.
Assist with all data-related reporting and documentation.
Maintenance and optimisation of the Analytics database.
Provide technical support to and supervision of junior data administrators.
Continuous upskilling on new technologies, frameworks and market trends.
Monitoring performance and advising any necessary infrastructure changes.
Identifying, selecting and integrating any Big Data tools and frameworks required to provide real-time analytics.

Educational Requirements

IT related Degree or Diploma is a pre-requisite

Required Skills/Experience

ETL tools: Advanced SSIS
BI/Reporting : Qlikview/Power BI/ SSRS or SSAS
Programming languages: JAVA, C# , Python, SAS or R
Experience with NoSQL databases and/or campaign management tools will be advantageous.
Minimum 3 years’ applicable work experience in SQL, relational databases and data manipulation.
Experience in big data platforms (eg. Hadoop) or processing frameworks (eg. MapReduce/Spark) and querying tools (eg. Pig, Hive and Impala) will be highly beneficial.

Preferred Skills

Organizational skills
Experience in Attentional to detail.
Accountability is critical for this role.
Ability to work under pressure and meet deadlines.
Solid understanding of database design principles.
Should you not receive a response in 2 weeks please consider your application unsuccessful",-1,Rubik's Cubed Consulting,Durban,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"This well known company is looking for a Data Engineer. will be based in Rivonia
The ideal candidate will have strong experience in the following:
Data cleaning
SQL Export
Big data Sets

BSc Degree in Maths and Stats will be required
a min of 3 years experience.
Stable track record is required.

Send your Cv to marinda@prrrecruitment.co.za",-1,PRR Recruitment Services,Johannesburg,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Description

Position at Aculocity, LLC

At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes
Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.
Key Responsibilities
Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.
Key Traits
Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern
Position Requirements
2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.
Where will you work? This role will be based out of Durbanville, South Africa.",-1,GVW,Durbanville,-1,Unknown,-1,Unknown,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Information Technology, Gauteng JHB - Northern Suburbs

Market related - Market related Annually

An IT Consultancy Business based in Johannesburg is currently looking for a Business Intelligence Consultant / Data Engineering Consultant.

Requirements:

Extensive experience in data engineering
Experience in Business Intelligence, data and Power BI
Extensive experience in data governance and the Popi act
Ability to assess and make recommendations on data within the Popi act
Good understanding of T-SQL and query optimization, developing ETL strategies.
Good understanding with SQL Server 2008/2012, SSIS, SSRS and SSAS
Use SSIS to create ETL packages to validate, extract, transform, and load data into the data warehouse and data marts.
Deploy and configured the reports in the Report Server (SSRS).
Excellent experience in Tabular Modelling , PowerView, Qlikvie,w, and Power BI
Maintain ETL
Qlikview model
Create Drill-through, Drill-down, and Cross Tab Reports and Sub-Report using Report Definition Language (RDL).
Generate periodic reports based on the statistical analysis of the data using SQL Server Reporting Services (SSRS)
Advise and provide written technical documentation and recommendations

The information displayed above is not limited to advertisements. Please contact Thato for further information.

Please consider your application as unsuccessful if you have not received a response within 14 days of submitting your application. However, please keep a lookout on our website, www.bedifferent.co.za, for available positions that you may be suited for

Ad Visible Until: 29 October 2020
Ref: JHB005346/NL

Vacancy Type: Permanent",2.9,"Be Different Recruitment
2.9",Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Cloud Support Engineer (Big Data),-1,"ABOUT US

Amazon Web Services is the market leader and technology forerunner in the Cloud business. As a member of the AWS Support team you will be at the forefront of this transformational technology, assisting a global list of companies and developers that are taking advantage of a growing set of services and features to run their mission-critical applications. As a Cloud Support Engineer, you will act as the Cloud Ambassador across all the cloud products, arming our customers with required tools & tactics to get the most out of their Product and Support investment.

Would you like to use the latest cloud computing technologies? Do you have an interest in helping customers understand application architectures and integration approaches? Are you familiar with best practices for applications, servers and networks? Do you want to be part of a customer facing technology team helping to ensure the success of Amazon Web Services (AWS) as a leading technology organization?

If you fit the description, you might be the person we are looking for! We are a group of smart people, passionate about cloud computing, and believe that world class support is critical to customer success.

WHAT CAN YOU EXPECT FROM A LIFE AT AWS?

Every day will bring new and exciting challenges on the job while you:

· Learn and use groundbreaking technologies.
· Apply advanced troubleshooting techniques to provide unique solutions to our customers' individual needs.
· Interact with leading engineers around the world.
· Partner with Amazon Web Services teams to help reproduce and resolve customer issues.
· Leverage your extensive customer support experience to provide feedback to internal AWS teams on how to improve our services.
· Drive customer communication during critical events.
· Drive projects that improve support-related processes and our customers technical support experience.
· Write tutorials, how-to videos, and other technical articles for the developer community.
· Work on critical, highly complex customer problems that may span multiple AWS services.

WHY AWS SUPPORT?

· First and foremost this is a customer support role in The Cloud.
· On a typical day, a Support Engineer will be primarily responsible for solving customers cases through a variety of customer contact channels which include telephone, email, and web/live chat. You will apply advanced troubleshooting techniques to provide tailored solutions for our customers and drive customer interactions by thoughtfully working with customers to dive deep into the root cause of an issue.
· Apart from working on a broad spectrum of technical issues, an AWS Support Engineer may also coach/mentor new hires, develop & present training, partner with development teams on complex issues or contact deflection initiatives, participate in new hiring, write tools/script to help the team, or work with leadership on process improvement and strategic initiatives.
· Career development: We promote advancement opportunities across the organization to help you meet your career goals.
· Training: We have training programs to help you develop the skills required to be successful in your role.
· We hire smart people who are keen to build a career with AWS, so we are more interested in the areas that you do know instead of those you havent been exposed to yet.
· Support engineers interested in travel have presented training or participated in focused summits across our sites or at specific AWS events.
· As we operate on a follow-the-sun model, with Premium Support sites located globally, there is no after hours on-call or mandated overtime in this role.
· https://www.youtube.com/watch?v=GC3bWcFFZTo&t=24s



Basic Qualifications

The Big Data role supports our services that leverage data and produce business insights, which may include using Machine Learning/Artificial Intelligence (ML/AI). Helping our customers use and integrate Big Data services in what is arguably our industrys most exciting space. The portfolio of services covers EMR (Hadoop), DynamoDB (NoSQL), MangoDB, and Apache Cassandra.

· Advanced experience in Apache Hadoop, Apache Spark, Apache Hive, and Presto
· Advanced experience in DynamoDB or NoSQL technologies like MongoDB or Cassandra
· Advanced experience with System Administration with Linux (RHEL/CentOS) including Microsoft Active Directory, and LDAP integration.
· Experience with troubleshooting Kerberos Authentication problems.
· Experience with Network troubleshooting.
· Basic understanding of Machine Learning and statistics
· Experience with Java and Python and shell scripting
· Bachelors degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position



Preferred Qualifications

· Expert experience in the Hadoop Ecosystem including Apache Spark and Presto
· Expert experience in NoSQL
· Expert experience with blockchain technologies like Etherium Expert experience in data Data Lake architecture and administration
· Experience managing full application stacks from the OS up through custom applications
· Prior work experience with AWS - any or all of EC2, VPC, S3, RDS, EMR, Glue, SageMaker
· Excellent knowledge of Hadoop architecture, administration and support
· Expert understanding of distributed computing principles and their application in the cloud
· Good understanding of distributed computing environments Lead technical discussions on big data systems architecture and design
· Strong analysis and troubleshooting skills and experience
· AWS Certified Solutions Architect
· AWS certified Big Data Specialty
· Masters degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity and Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Response Center Engineer,-1,"Job Title
Response Center Engineer
Job Description


Philips is a world leading health technology company with a vision to make life better for people worldwide through meaningful innovation. Making good on this promise depends on our passionate, inspirational, collaborative and diverse team. We have over 80,000+ brilliant people around the world but are always looking for more. Like-minded, motivated, focused minds to join us in creating a healthier, more connected society while transforming themselves personally and professionally.

As a CCC Coordinator - Response Center Engineer you will have the opportunity to process customer calls and be responsible for screening and diagnosing professionally Healthcare equipment to support customers and colleagues remotely with solving technical issues and ensuring maximum customer satisfaction

You are responsible for:
Diagnose healthcare equipment to the quality standards set by Philips Healthcare (PH) remotely by interviewing customers or colleagues by telephone or by remotely logging in to the system
Advise Customer Care Center Coordinators and District Operations Managers and / or Team Leads about the best follow-up w.r.t. technical state of the diagnosed healthcare equipment
Advise the Customer Care Center Coordinators or Field Services Engineers about required spare parts and resources
Responsible for planning engineers related to Modality responsibility.
Responsible for coordination between CCC, CUSTOMER, Spare parts AND Engineer.
Responsible to drive Remote and FTR KPI’s to targets respectively 40% and 85%.
Will require minimal field work to keep abreast of technical capabilities.
Take calls from customers and make sure they are processed in the CCC ERP on timely manner including all relevant data
Support Field Services Engineers in the field with technical knowledge
Escalate technical issues to the Technical Support Specialist
Escalate technical issues to Business Unit support after consultation of the Technical Support Specialist
Monitor critical functions of the equipment’s in the IB and environmental conditions including RSN and True reachability.
Lead the planning and implementation of FSN’s and FCO’s accelerating remote implementation where applicable.
Submit timely and accurate service data, job sheets, reports, expense claims, radiation film badges, field problem reports and other paperwork as assigned
Keep abreast of new technologies likely to affect PH range of products
Use company property with care to ensure optimal results with minimal operational costs
Be a professional representative for PH with respect to customer problems, ensuring personal acceptability by the customer in behavior in accordance with PH policy and targets
Conform to PH safety standards including health and safety regulations and in the event of hazards or accidents to take immediate control of the situation and involve the Operations Manager and / or the responsible person to handle properly confidential issues according Philips standards and to act according General Business Principals
Follow all quality standards within the frame of valid PH business policies
Follow the company quality regulations (ISO 9001; PQA; TQM) and internal directives and procedures
You are a part of the dynamic South Africa Customer Care Centre Team .You will be reporting to the Customer Care Center Manager.

Requires a pleasant, assertive individual you can work very well in a team setting, a dynamic environment that requires flexibility and creativeness to achieve goals.

To succeed in this role, you should have the following skills and experience:
Degree level education or equivalent
Experience in maintenance and troubleshooting of technical complex systems
Fluent in English, verbal and written in addition to local language
In return, we offer you the unique combination of a critical and challenging role and a creative and empowering office environment. You will be actively encouraged to make improvements, establish best in class service and have a direct impact on the success of Philips on a daily basis.

Employment Equity

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply. Only apply for this role if you are a South African Citizen by birth or Naturalization prior to the 27 April 1994.

Why should you join Philips?

Working at Philips is more than a job. It’s a calling to create a healthier society through meaningful work, focused on improving 3 billion lives a year by delivering innovative solutions across the health continuum. Our people experience a variety of unexpected moments when their lives and careers come together in meaningful ways. Learn more by watching this video.

To find out more about what it’s like working for Philips at a personal level, visit the Working at Philips page on our career website, where you can read stories from our employee blog. Once there, you can also learn about our recruitment process, or find answers to some of the frequently asked questions.

Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.9,"Philips
3.9",Johannesburg,-1,10000+ Employees,1891,Company - Public,Health Care Services & Hospitals,Health Care,$10 to $25 million (USD),-1
Software Development Engineer - EC2 Placement,-1,"Build the systems that optimize how EC2 matches requests for Instances with the underlying compute capacity. EC2 Placement is seeking talented engineers to build the online and offline optimization systems for compute workload scheduling, and the customer capabilities to better manage those workloads. Amazon EC2 provides on-demand scalable compute capacity, and powers some of the largest services in the world. You will collaborate with a top-tier community of engineers to build systems to improve how customers are able to access EC2 compute resources.

The successful candidate will have strong software engineering experience, with a passion for thinking about, building and testing distributed systems. You have an interest in how Machine Learning and other optimization techniques can be applied to large-scale problems. You have demonstrated experience working with a team to design, build and operate large-scale systems. With strong engineering fundamentals, an analytical and data-driven approach to your work, and strong communication skills, you have the ability to collaborate well to deliver results. We move fast and work together on small teams to solve big problems.

If this opportunity sounds interesting, we would love to talk to you more about our work and the vibrant culture at AWS in Cape Town.

Basic Qualifications

· Degree in Computer Science or related field, or equivalent working experience
· 3+ years of industry experience in a software development environment
· Strong Computer Science fundamentals, including data structures, object-oriented design, algorithm design, problem solving, and complexity analysis.
· Proficiency in at least one modern programming language, such as Java, C#, Python, Scala, Kotlin

Preferred Qualifications

One or more of the following help you stand out:
· Demonstrated results designing, building and operating high-performance distributed systems in large-scale Linux environments
· Role model in writing high-quality, maintainable and secure code, mentoring others, and helping teams sharpen their development processes
· Ability to work effectively across teams to deliver results, with strong verbal and written communication skills
· Experience working with machine learning systems

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer - PBB IT,-1,"Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose


This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes
Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems
Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions
Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.

Research and best practices
Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development
Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.
Preferred Qualification and Experience
Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Aws Data Platform Engineer,-1,"Aws Data Platform Engineer

Posting Country:

South Africa

Date Posted:

15-Oct-2020

Full Time / Part Time:

Full Time

Contract Type:

Permanent

Joining Vodacom is more than a job, what we do matters. We don’t just carry minutes, texts and data – we carry people’s lives. And that’s a huge responsibility. If you think for a minute about the people you rely on…the likelihood is they rely on us.

Customers are at the heart of everything we do and we want to make a difference to the lives of our customers, and the communities in which we live and work. We support our people to give something back to the causes that mean the most to them through helping them give time and money to the charities they love.

And what’s it like to work here? We have created an environment where you can look forward to coming to work and are empowered to be at your best. We offer flexibility in how you work that helps you do your job in a way that suits you, opportunities to help you grow and progress throughout your career and a choice of benefits to suit your lifestyle.

Role Purpose
The H Band AWS Data Platform Engineer position is based within the Technology Business Unit.

The AWS Data Platform Engineer will be responsible for all Database services such as RDS, DynamoDB, etc. Should be able to migrate any databases from anywhere to AWS using any third-party tools or AWS database migration tool. Should also have understanding or expertise in creating data warehouses and data lake solutions on AWS.
Your responsibilities will include:
Apply practical knowledge of relational database design and usage with customers
Perform workload analysis and undertake performance tuning, as well as performance benchmarking in customer environments.
To develop state of the art solutions which are technically sound.
To provide a high-quality service to the Enterprise Cloud Services clients i.t.o. consultancy, solutions and delivery.
Commitment to team success and positive team dynamics including mentoring of other team members.
Passion for growing and applying technical skills in service to customers.
Be a trusted infrastructure advisor by providing objective, practical and relevant ideas, insights and advice.
Work collaboratively with consulting partners and technology teams to ensure high quality of solution delivery.
Encourage best practice and knowledge sharing with partners and cross-functional groups
Manage the overall database design and delivery of solutions.
Ability to make recommendations as they pertain to improvements in support/development initiatives and facilitate implementation with partners and cross-functional groups within the Business.
Participate in high level database solution definition and design during the implementation phase with the goal of providing reliable, stable and operationally sound applications that meet the Business requirements.
Ability to understand and translate business requirements into technical specifications
The ideal candidate will have:
A minimum of 3 years of industry related experience of which 1 year must be within a complex hosting environment.
Certifications in Database design, system architecture or cloud technologies.
Demonstrate knowledge of database systems internals including storage layouts and distributed databases/MPP architectures
Advanced SQL coding, tuning and query optimization.
Experience designing and leading database performance benchmarks.
Good knowledge of the different AWS services
Knowledge of cloud networking architecture, cloud operations, security, automation and orchestration.
Knowledge of database internals as it relates to query and system performance and tuning.
Understanding of overall system architecture, scalability, reliability, and performance in a database environment.
Excellent teamwork, time-management and organizational skills.
Perform other duties as deemed necessary and assigned by the customer and management
Strong interpersonal skills and problem-solving abilities.
Excellent documentation, communication and interpersonal skills.
Excellent analytical and problem-solving abilities.
Closing date for applications: Monday, 13 April 2020

The base location for this role is Vodacom World, Midrand

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply.
Vodacom is committed to an organisational culture that recognises, appreciates and values diversity & inclusion.

Commitment from Vodacom

Vodacom is committed to attracting, developing and retaining the very best people by offering a flexible, motivating and inclusive workplace in which talent is truly recognized, developed and rewarded. We believe that diversity plays an important role in the success of our business and we are committed to creating an inclusive work environment which respects, values, celebrates and makes the most of people’s individual differences - we are not only multinational but multicultural too. At Vodacom you will have access to our excellent flexible benefits programme that you would expect from any global company.",3.9,"Vodafone
3.9",Midrand,-1,10000+ Employees,1982,Company - Public,"Cable, Internet & Telephone Providers",Telecommunications,$10+ billion (USD),-1
Data Engineer Azure Data Factory,-1,"Enthuzex is looking for a motivated Lead Data Engineer to contribute towards the success of our Data and Analytics Technology initiatives. This is a hands-on technical role and this person will be responsible for the development and build of scalable solutions as it relates to the architecture strategies, data standards, digital data management, data integration, tools, and technology. The right candidate will play a deep dive hands-on critical development role in the digital transformation and in shaping how we acquire, ingest, transform and deliver data through the digital consumer channels.

Responsibilities:

Architect, design, develop and engineering end-to-end data pipelines across multiple data sources and systems of record.
Ensure data quality, integrity, security and completeness throughout the data lifecycle
Develop, design data models, data structures and ETL jobs for data acquisition and manipulation purposes
Develop deep understanding of the data sources, implement data standards, maintain data quality and master data management
Developing data services and API
Work closely with the cloud service providers to ensure completeness and alignment with the service offerings
Manage and maintain cloud based data and analytics platform
Deep understanding of the cloud offerings and engage in quick proof of concepts and proof of value in prototyping data and analytics solutions and derive viability
Ability to interact with the business stakeholders to understand requirements and translating into technology solutions

Expirience:

Experience in Cloud platform AWS or Azure eco-system. (Azure preferred)
Data Engineering/Development experience with SQL (Oracle, SQL Server, MySQL)
Strong development background creating pipelines and complex data transformations and manipulations using one of the languages Python, Java, R, or Scala with Databricks/Spark
Experience in NoSQL Databases and Big data technologies including Hadoop
Experience with API / RESTful data services
Worked on real-time data capture, processing and storing using technologies like Azure Event Hubs and Analytics
Experience working with different data storage options including AWS S3, Azure BLOB storage etc.
Understanding of different data formats including Parquet, Avro, CSV, ORC etc.
Prior experience with MPP databases and maintain large amount of data processing
Experience with Azure Data Factory and Azure Data Catalog is a big plus and mandatory
Experience with Microsoft/Azure ETL solutions and business Intelligence technologies is a big and mandatory
Past working experience on a fast paced and agile environment
Perform ongoing monitoring, automation and refinement of data engineering solutions
Experience in leading high visibility transformation projects that interacts with multiple business lines
Build and meet project timelines and manage delivery commitments with proper communication to management

Qualifications

Bachelor’s degree with 4+ years of relevant experience
Willingness to learn new technologies and thrive in an extremely fast paced environment
Team player and easy to work with.

Applicants must demonstrate their ability to master new enterprise level technologies. Successful applicants will exemplify Enthuzex ethical principles of uncompromising integrity, respect for others, and accountability for decisions

send cv's info@enthuzex.co.za",-1,Enthuzex,Leslie,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Scientist,-1,"The world is changing.

We all want something different.

At Luno, we see you as an individual.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the world, and to do so, we need the best team on board for our mission.

A bit about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 3 million customers across 40 countries.
We are Series B funded, backed by Balderton Capital and the Naspers Group.
Our platform has processed over 8 billion dollars since we've launched
We're proud to be one of the world's most international cryptocurrency teams from 26 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
The role in a nutshell:

Identifying opportunities in the business that could benefit most from cognitive applications, as well as building and enhancing organisational capabilities for deriving value from multiple data sources using data science.

What we'd like you to have:
Bachelor's degree or higher in the natural sciences or technical fields such as Mathematics, Statistics, Computer Science, Engineering or Economics
Enthusiasm to work in the cryptocurrencies space
Advanced SQL skills
Solid understanding of exploratory data analysis, predictive analytics, and optimisation using Python, R, Matlab, RapidMiner, KNIME or other data science-oriented platforms
Proficiency in the use of data science and machine learning domain-specific languages such as ""Caret"" and the ""Tidyverse"" suite of tools in R, or ""Pandas"" in Python
Strong interpersonal and communication skills
Communicating data insights using storytelling narratives
Ability to work independently, as well as within and across teams
Ability to successfully complete projects with large and/or incomplete data sets
More about what you'll be doing:
Optimising product performance by tracking and analysing customer behaviour on web and app, in collaboration with software engineers and product designers
Providing the business with reports and dashboards, on key performance metrics
Developing metrics to accurately assess the health of our Exchange platform
Comparative data-driven analysis of our Exchange against alternative platforms
Formulating business requirements into analytical objectives
Designing and running experiments to test hypotheses
Hacking through complex business problems using advanced data analysis to provide insights and recommendations
Building, maintaining, and optimising decisioning systems using advanced statistical and predictive modelling techniques
What will set you apart:
An advanced degree in Mathematics, Statistics, Computer Science or related field
At least 3 years' experience working in a similar role
A basic understanding of trading in financial markets
Experience working with a data analytics and visualisation platform such as Tableau, Cognos, QlikView, or Looker
Familiarity with using Google Analytics to understand customer behaviour
Solid knowledge of statistical and machine learning techniques
Familiarity with modern distributed data storage and processing systems such as Amazon Redshift, Big Query, Snowflake, Databricks and Apache Spark
You can gather and synthesise facts, theories, trends, patterns, inferences, and key issues in complex and variable situations
Ability to diagnose problems using formal problem-solving tools and techniques from multiple angles to generate multiple possible solutions
A sense of anticipating long-term problem areas and associated risk levels with objective rationale
Remote Life at Luno

If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
You'll be able to continuously upskill yourself with access to free online learning via MyAcademy, an international teaching marketplace with over 100000 courses from Harvard and other leading providers + share knowledge with your peers.
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity and paternity leave, and you can even take paw-ternity leave for your furry friend.
Annual Inspiration Day! Make time for that pottery course or spa day you've always wanted to do.
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"EY is a global leader in
assurance, tax, transaction and advisory services. Technology is at the heart
of what we do and deliver at EY. Technology solutions are integrated in the
client services we deliver and are key to our innovation as an organization.

Fueled by
strategic investment in technology and innovation, Client Technology seeks to
drive growth opportunities and solve complex business problems for our clients
through building a robust platform for business and powerful product engine
that are vital to innovation at scale. As part of Client Technology, you’ll
work with technologists and business experts, blending EY’s deep industry
knowledge and innovative ideas with our platforms, capabilities, and technical
expertise. As a catalyst for change and growth, you’ll be at the forefront of
integrating emerging technologies from AI to Data Analytics into every corner
of what we do at EY. That means more growth for you, exciting learning
opportunities, career choices, and the chance to make a real impact.

The selected
candidate
Develops
large and complex data architecture, composed of models, policies, rules or
standards that govern which data is collected and how it is stored, arranged,
integrated and put to use in data systems, including the design, build and
management of data infrastructure to address business requirements
Creates
sound use case driven roadmaps, depicting data architecture as-is and to-be
capabilities with the business by engaging with multidisciplinary teams, and by
identifying, managing and mitigating risk
Develops
relationships across the business to understand data requirements, applies deep
technical knowledge of data management to solve business problems in areas
where solutions may not currently exist, necessitating new solutions/ways of
working/technologies and proactively articulating these to the business
Review,
identify the latest emerging technologies, augmenting by services from the
leading cloud providers to solution and recommend the best next generation data
platform value driven approach for our clients
Your Key Responsibilities Include
Create
and maintain conceptual, logical and physical database models
Document
functional requirements and system specifications into the data architecture
and detailed design specifications for current and proposed designs
Document
and adhere to development standards and best practices in database designs
Maintain
highly effective and consistent communication within the team, peers, and the
leadership team
Reverse
engineer SQL code and modify it to solve problems/issues
Contribute
to the definition and implementation of data governance practices
Design
both data structures and data integration practices
Work
closely with the infrastructure teams to create a physical environment to
support data services
Evaluate
new and existing (internal and external) technologies and services in support
of data services and data analytics objectives
Skills And Attributes For Success
Understanding
of business process reengineering and business modeling concepts, business
systems development and analysis
Hands-on
experience in designing and implementing hybrid cloud and on-prem solutions
Experience
working with the latest versions of SQL Server
Experience
applying SAFe/Scrum/Kanban methodologies
Ability
to exercise judgment in solving technical, operational, and organizational
challenges
Expert
programming, performance tuning and troubleshooting skills, using the latest
popular programming languages for example python
Demonstrate
proactive approach to identifying issues and presenting solutions and options,
and where appropriate, leading to resolution
Minimum Qualifications
5+ years
demonstratable work experience as a Data Architect using data modeling tools
2-3 years
SQL coding experience on large projects
Must
possess expert SQL programming, performance tuning and troubleshooting skills
Create
database objects and SQL scripts
Understand
and developed data pipelines
Know how
to deformalize data for data science models
Experience
in python, spark and notebooks
Experience
designing data warehousing solutions
Experience
designing next generation data platforms utilising cloud services
In-depth
understanding of database structure principles
Seamlessly
able to translate business requirements to technology requirements
What We Look For
Strong
analytical skills and problem-solving ability
A
self-starter, independent-thinker, curious and creative person with ambition
and passion
Excellent
inter-personal, communication, collaboration, and presentation skills
Customer
focused
Excellent
time management skills
Positive
and constructive minded
Takes
responsibility for continuous self-learning
Takes the
lead and makes decisions in critical times and tough circumstances
Attention
to detail
High
levels of integrity and honesty
Curious
about new emerging technology
About EY
As a global leader in assurance, tax, transaction and consulting
services, we’re using the finance products, expertise and systems we’ve
developed to build a better working world. That starts with a culture that
believes in giving you the training, opportunities and creative freedom to make
things better. Whenever you join, however long you stay, the exceptional EY
experience lasts a lifetime.",3.8,"EY
3.8",Johannesburg,-1,10000+ Employees,1989,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Architect - Principal,-1,"We are looking for Principle Data Architect to join our Engineering team in Cape Town.

The world is changing.
We all want something different.
At Luno, we see you as individuals.

Together, we are upgrading the world of work to unleash the potential within and empower you to become the best possible version of yourself.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the financial landscape, and to do so, well we need the best team on board for our mission. In short, to achieve our goals, we need rockstars. As simple as that.

A little about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 5 million customers across 40 countries.
We're part of the Digital Currency Group, a group of companies driving progress in the cryptocurrency and blockchain space that includes Grayscale, Genesis, Coindesk and Foundry Services
Our platform has processed over $8 billion to date
We're proud to be one of the world's most international cryptocurrency teams from 43 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
How we work


Our engineering team (currently ~100 engineers) is split into organisations which we call Fleets. Each Fleet focuses on a core customer journey (onboarding, security, payments, support, new business, growth and marketing etc.). Each of these fleets contains multiple smaller teams called Pods, each of which focuses on a specific aspect of the product.

Pods will include a product owner, product designer, back-end engineers, Android, iOS and Web developers, who each bring a unique perspective to the problem you are all contributing towards.

We're agile, use scrum, continuous integration and continuous delivery, deploying to production every single day.

We're building teams to help us succeed in our mission to upgrade the world to a better financial system. You'll be joining a group of highly motivated software engineers who you'll work collaboratively with across our pods.

As a fast-growing company with offices around the world, you'll immediately see how your contributions directly impact both our internal users and client experience. Many of the problems we are solving result in trail blazing solutions which can't be found on Stack Overflow; so we're looking for engineers who flourish working in a complex domain.

In your first six months, you will:


...start at Luno by learning our processes, meeting the wider team and starting our engineering on-boarding program. After getting comfortable with the basics, you'll start learning our idiomatic patterns in a safe, easy-to-follow way - by building your own toy micro services. You'll get to practice how we do design docs, code reviews, deployments, events, logging and monitoring.

You'll meet the Pod(s) you'll be working with and quickly align on the teams' current OKRs and product roadmap. We succeed as a team, so we will provide you with regular feedback from your manager and peers and will encourage you to do the same.

What you'll do:
Work closely with our data science and platform teams on projects introducing new streams of data into our data lake
You will get to bring new ideas on how to further develop and innovate our data solutions and how to expose that data to the business
Accountable and Responsible for the design and architecture of Data systems that are robust and scalable.
Work in an Agile/Scrum framework or Agile mindset
Data backup/recovery and storage
Pick-up and learn new concepts, in both engineering and product, and be able to apply that knowledge quickly.
The ideal candidate for this role will have:
7+ years' experience in maintaining scalable data solutions and/or you are passionate about it
Ability to understand, communicate and advocate between build vs buy
Proven track record of setting up, restructuring and maintenance of databases
You know your way around ETL and you have experience with SQL
Experience in the AWS Data stack (RedShift,DynamoDB, Amazon RDS)
Familiarity with integrating data stores with BI platforms such as Looker, Tableau, or Power BI
You have experience with the concepts of CI/CD
Coding skills in e.g. Go, Python
Bachelor's degree in a related field preferred
AWS Certified DataOps Administrator
Be friendly, transparent, articulate and driven to succeed
Basic knowledge of and passion for digital currencies like Bitcoin
A work permit for South Africa if you are not a South African citizen
Don't be put off if you don't tick all of the boxes – they're a guide based on what we'd love to see but we appreciate that excellent software engineers have diverse backgrounds.

Remote Life at Luno


If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity / paternity and even (yes, you are reading it correctly) paw-ternity for your furry friend..
Annual Inspiration Day.. like that pottery course you've always been meaning to do!
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. You'll need to hold the legal right to work in South Africa already as we cannot provide visa sponsorship.

Be part of the change!",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer - EC2 Capacity Data Analytics,-1,"EC2 Capacity Data Analytics (CDA) team is looking for a Data Engineer to join our team.

Our team is part of the EC2 Capacity Engineering organization, which is responsible for providing the elasticity EC2 customers need to scale up/down compute resources in a cost-efficient manner. We predict customer usage across thousands of configuration combinations to deliver exactly what our customers require in just the right amount of time with just the right amount of capacity.

As a Data Engineer, you will build the ETL and analytics solutions for our internal customers to answer questions with data and drive critical improvements for the business. You will use best practices in software engineering, data management, data storage, data compute, and distributed systems. On any given day, we use Python, Scala, Java, SQL, Lambda, CloudFormation, Redshift and Glue as well as other public AWS services and a host of Amazon internal tools. We dont expect you to be an expert in, or necessarily even be familiar with all of the technologies listed above, but we do expect you to be excited to learn about them.

This position involves on-call responsibilities, typically for one week every two months. Our team is dedicated to supporting new team members. We care about your career growth, we try to assign projects and tasks based on what will help each team member develop into a more well-rounded engineer and enable them to take on more complex tasks in the future.

Our team values work-life balance and we are flexible when people occasionally need to work from home.

Job Duties
Develop and maintain automated ETL pipelines for big data using languages such as Scala, Spark, SQL and AWS services such as S3, Glue, Lambda, SNS, SQS, KMS. Example: ETL jobs that process a continuous flow of JSON source files and output the data in a business-friendly Parquet format that can be efficiently queried via Redshift Spectrum using SQL to answer business question.

Develop and maintain automated ETL monitoring and alarming solutions using Java/Python/Scala, Spark, SQL, and AWS services such as CloudWatch and Lambda.

Implement and support reporting and analytics infrastructure for internal business customers using AWS, services such Athena, Redshift, Spectrum, EMR, and QuickSight.

Develop and maintain data security and permissions solutions for enterprise scale data warehouse and data lake implementations including data encryption and database user access controls and logging.

Develop and maintain data warehouse and data lake metadata, data catalog, and user documentation for internal business customers.

Develop, test, and deploy code using internal software development toolsets. This includes the code for deploying infrastructure and solutions for secure data storage, ETL pipelines, data catalog, and data query.


Basic Qualifications

· Bachelors degree in Computer Science or related technical field, or equivalent work experience.
· 4+ years of overall work experience including Software Engineering, Data Engineering, Database Engineering, Business Intelligence.
· Experience with AWS technologies stack including Lambda, Glue, Redshift, RDS, S3, EMR or similar big data solutions stack

Preferred Qualifications

· Demonstrate efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data.
· Demonstrable proficiency in distributed systems and data architecture; design and implementation of batch and stream data processing pipelines; knows how to optimize the distribution, partitioning, and MPP of high-level data structures.

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer,-1,"Our client based in Johannesburg is urgently looking for a Data Engineer to be on a 3 months contract
Build data pipelines, experience in new tech like nifi, kafka, python

Joburg based, open to EE, 3 month contract with the option to extend, must be available at short notice",-1,EQplus,Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Overview
Job ID: 51456
Job Sector: Information Technology and Services
Country: South Africa
Region/State/Province/District: Gauteng
Location: Johannesburg

Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose

This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes

Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems

Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions

Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.
Research and best practices

Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development

Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.

Preferred Qualification and Experience

Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry

Knowledge/Technical Skills/Expertise

Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision

PLEASE NOTE: All our recruitment and selection processes comply with applicable local laws and regulations. We will never ask for money or any form of payment as part of our recruitment process. If you experience this, please contact our Fraudline on +27 800222050 or forward to TransactionFraudOpsSA@standardbank.co.za",4.1,"Standard Bank
4.1",Johannesburg,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"About us

At PBT Group we pride ourselves on being a Data Specialist organisation. With 20 years of experience in 27 countries over 3 continents, our team of 550 consultants have implemented more than 700 projects.",4.3,"PBT Group
4.3",Johannesburg,-1,Unknown,-1,Company - Private,Accounting,Accounting & Legal,Less than $1 million (USD),-1
Data Engineer,-1,"Kick-start your career in the online gaming world and experience the very latest in technology and innovation.

The Department:

Our mission is to provide our customers with the best online betting experience and share the thrill of gaming with them. Data is at the very heart of our business and is vital in everything we do.

Our cross-functional Data team has a big and exciting challenge ahead. We are in the process of re-platforming our traditional, on-premises RDBMS environment to a new microservice architecture in the cloud. We’re making use of the diverse set of data technologies in Microsoft Azure to offer new services, reporting structures and real-time data pipeline while serving the day-to-day requirements of a rapidly growing, data-hungry organisation.

Purpose of the Role:

This is an excellent opportunity for an individual who is looking to gain new skills. We are committed to creating a culture of learning and regularly run proof of concepts, provide internal demos, manage workshops and attend external conferences. Our data team has a wide range of skills including development for highly transactional RDBMS systems, data warehousing, data science and cloud technologies and we are always working to raise everyone’s game.

Duties include, but not limited to:

Work as part of an agile Data Engineering Team
Development of greenfield projects in Azure
Develop and maintain on-premises RDBMS/DW systems
Create robust ETL services and real-time data pipelines
Build and maintain Continuous Integration and DevOps pipelines
Test-driven development and pair programming with colleagues

Essential Criteria:

C#, .Net, Visual Studio
Git, Azure DevOps
NoSQL development (CosmosDB)
Demonstrable understanding of MS SQL Server in a highly transactional environment
Demonstrable understanding of development in Microsoft Azure
Able to understand query plans and identify performance bottlenecks
Test/Business-Driven Development
Building Continuous Integration/Deployment pipelines
Communicate effectively with both technical and non-technical stakeholders

Desirable Criteria:

Implementing Data Storage and Processing solutions in Azure (ARM Templates, Storage Accounts, Data Lake Storage, SQL DB, Cosmos DB, EventHubs, Function Apps, Log Analytics, Data Factory, Databricks, Polybase)
Implementing Security, Disaster Recovery, High Availability, Auditing, Monitoring and Alerting solutions in Azure
Automating tasks in Azure using Powershell / CLI
Predicting costs and optimizing spending in Azure
Message Queues (RabbitMQ, Kafka)
Python

Person Specifications:

Resilience
Teamwork
Technical Knowledge
Communication skills
Stress Tolerance
Please note we will apply relevance to our Talent Management and Talent Development Programme as part of our recruitment process.
Shortlisted candidates may need to complete an assessment.
This position requires trust and honesty it has access to customers financial details - therefore a credit and criminal record check will be conducted. The qualifications identified herein are an inherent job requirement; therefore, a qualification verification check will be done. By applying for this role, and supplying the necessary details, you hereby grant us permission to apply for these checks. This will be done in a confidential manner, and solely for the purposes of verification.

To view all current vacancies, please visit our website, www.digioutsource.com

Should you not hear from us within 2 weeks, please deem your application as unsuccessful.

The perfect place to work, play and grow!",3.9,"Digital Outsource Services
3.9",Cape Town,-1,1001 to 5000 Employees,1997,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
Data Engineer,-1,"At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes

Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.

Key Responsibilities

Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.

Key Traits

Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern

Position Requirements

2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.

Where will you work? This role will be based out of Durbanville, South Africa.",3.1,"Aculocity, LLC
3.1",Durbanville,-1,1 to 50 Employees,2006,Company - Private,IT Services,Information Technology,$1 to $5 million (USD),-1
Data Engineer,-1,"ENVIRONMENT:

A rapidly growing E-Commerce Platform seeks a highly talented Data Engineer to make an invaluable contribution to data democratisation and literacy vision by making accessible and easy-to-use data products and tools. You will require a Comp-Sci Degree or 3 years’ relevant industry experience, MySQL, PostgreSQL, Java, Python, in-depth understanding of OLAP, Data Marts, Star Scheme, Snowflake, be familiar with Jenkins, Travis, Circle CI, Docker, Kubernetes, experience with Kafka, Pub/Sub, Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks & significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing & Data Lake design and implementation and Lambda/Kappa architectures.

DUTIES:

Design, develop, test and maintain data architecture.

Prepare data for descriptive, predictive and prescriptive modelling.

Automate repetitive tasks and manual processes related with the data usage.

Optimize data delivery.

Design, develop and test large stream data pipelines to ingest, aggregate, clean, and distribute data models ready for analysis.

Ensure the highest standard in data integrity.

Leverage best practices in continuous integration and delivery.

Collaborate with other engineers, ML experts, analysts, and stakeholders to produce the most efficient and valuable solutions.

Implement features, technology, and processes that move us towards industry best practices, improving on scalability, efficiency, reliability, and security.

Operations and ownership of systems in production, responding to incidents.

REQUIREMENTS:

Qualifications –

Comp-Sci Degree or 3 years relevant industry experience.

Experience/Skills –

Open source relational database systems e.g. MySQL, PostgreSQL, etc.

Significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing, and Data Lake design and implementation and Lambda/Kappa architectures.

A thorough understanding of database and data warehousing principles e.g. OLAP, Data Marts, Star Schema, Snowflake, etc.

Java and Python.

Familiar with CI/CD tools such as Jenkins, Travis, Circle CI, etc.

Experience with Kafka, Pub/Sub, or other event-based systems.

Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks, etc.

Working in cloud environments and with containerisation frameworks, tools and platforms e.g. Docker, Kubernetes, GKE, etc.

A deep understanding of data pipelining, streaming, and Big Data technologies, methods, patterns, and techniques.

Troubleshooting complex database operations and performance issues.

Automating tasks using Shell Scripting or writing small applications.

ATTRIBUTES:

Works well with people and is passionate about helping people be their best.

A team player, an active listener, mentor, and able to communicate well.

Shows solid reasoning and decision making, with the ability to work under pressure.

Is passionate about technology, systems and data.

Is curious, always learning, and keeping up to date with the industry.

While we would really like to respond to every application, should you not be contacted for this position within 10 working days please consider your application unsuccessful.

COMMENTS:

When applying for jobs, ensure that you have the minimum job requirements. Only SA Citizens will be considered for this role. If you are not in the mentioned location of any of the jobs, please note your relocation plans in all applications for jobs and correspondence.",-1,Datafin IT Recruitment,Cape Town,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Cartrack is looking for passionate data science and engineering candidates that can join a growing team that is responsible for the intelligence and efficiency solution provision to over a million subscribers, many of whom are large fleets. We are in the midst of creating revolutionary platforms that will change the way that people interact with their vehicles.

You will have the opportunity to work with the very brightest global subject matter experts that are transforming the automotive industry across Fleet Management, Asset Management and Insurance Telematics solutions.

Get to know the role:

The role of a data engineer is a supporting one, but it is also an extremely vital one. As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements. We want to see candidates with mechanical tendencies and a desire to know how things work and to improve them.

The day-to-day activities:

Design, construct, install, test and maintain data management systems.
Build high-performance algorithms, predictive models, and prototypes.
Ensure that all systems meet the business/company requirements as well as industry practices.
Integrate up-and-coming data management and software engineering technologies into existing data structures.
Develop set processes for data mining, data modeling, and data production.
Create custom software components and analytics applications.
Research new uses for existing data.
Employ an array of technological languages and tools to connect systems together.
Install/update disaster recovery procedures.
Recommend different ways to constantly improve data reliability and quality.
Work on and maintain Data pipelines.

Requirements Essential:

At least 5 years’ proven experience as a Data Engineer, DevOps Engineer, Software Developer, or similar.
Proficient in Linux/Unix and shell scripting as well as in functional programming languages.
Expertise in setting up and explored with technologies such as Hadoop and Spark.
Bachelor’s degree in computer science, software/computer engineering, applied mathematics, or physics.",3.3,"Cartrack
3.3",Johannesburg,-1,501 to 1000 Employees,2004,Company - Private,Security Services,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Data Engineer,-1,"Data Engineers build and support data pipelines and datamarts built off those pipelines. Both must be scalable, repeatable and secure. The Data Engineer helps to facilitate gathering data from a variety of different sources, in the correct format, assuring that it conforms to data quality standards and assuring that downstream users can get to that data timeously. This role functions as a core member of an agile team. These professionals are responsible for the infrastructure that provides insights from raw data, handling and integrating diverse sources of data seamlessly. They enable solutions, by handling large volumes of data in batch and real-time by leveraging emerging technologies from both the big data and cloud spaces. Additional responsibilities include developing proof of concepts and implements complex big data solutions with a focus on collecting, parsing, managing, analysing and visualising large datasets. They know how to apply technologies to solve the problems of working with large volumes of data in diverse formats to deliver innovative solutions. Data Engineering is a technical job that requires substantial expertise in a broad range of software development and programming fields. These professionals have a knowledge of data analysis, end user requirements and business requirements analysis to develop a clear understanding of the business need and to incorporate these needs into a technical solution. They have a solid understanding of physical database design and the systems development lifecycle. This role must work well in a team environment.

Job Objectives

Work Complexity: * Architects Data analytics framework. * Translates complex functional and technical requirements into detailed architecture, design, and high performing software. * Leads Data and batch/real-time analytical solutions leveraging transformational technologies. * Works on multiple projects as a technical lead driving user story analysis and elaboration, design and development of software applications, testing, and builds automation tools.

Main Job Objectives: 1. Development and Operations 2. Database Development and Operations 3. Policies, Standards and Procedures 4. Communications 5. Business Continuity & Disaster Recovery 6. Research and Evaluation 7. Coaching/ Mentoring

Qualifications

Essential: 4 years Bachelors degree in computer science, computer engineering, or equivalent work experience AWS Certification at least to associate level

Experience

Essential:

5+ years Data engineering or software engineering

3-5 years demonstrated experience leading teams of engineers

2+ years Big Data experience

5+ years experience with Extract Transform and Load (ETL) processes

2+ years Could AWS experience

At least 2 years demonstrated experience with agile or other rapid application development methods - Agile exposure, Kanban or Scrum

5 years demonstrated experience with object oriented design, coding and testing patterns as well as experience in engineering (commercial or open source) software platforms and large scale data infrastructures.

Desirable:

5+ years Retail Operations experience

Knowledge and Skills

Essential: *Creating data feeds from on-premise to AWS Cloud (2 years) *Support data feeds in production on break fix basis (2 years) *Creating data marts using Talend or similar ETL development tool (4 years) *Manipulating data using python and pyspark (2 years) *Processing data using the Hadoop paradigm particularly using EMR, AWSs distribution of Hadoop (2 years) *Devop for Big Data and Business Intelligence including automated testing and deployment (2 years) * Extensive knowledge in different programming or scripting languages * Expert knowledge of data modeling and understanding of different data structures and their benefits and limitations under particular use cases.

Further technical skills required: * Capability to architect highly scalable distributed systems, using different open source tools. * Big Data batch and streaming tools * Talend (1 year) * AWS: EMR, EC2, S3 (1 year) * Python (1 year) * PySpark or Spark (1 year) - Desirable * Business Intelligence Data modelling (3 years) * SQL (3 years)",-1,Datonomy Solutions,Brackenfell,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We are assisting one of our clients that is based in Pretoria to fill a role of a Data Engineer

This is a 12 month contract role

Objective of this Scope of Work

The Data Engineer will drive improvement of the data management maturity levels and provide the necessary technical support within the company to support reliable and effective decision-making, appropriate usage and protection thereof.

Scope of Services Definition

The scope will include but will not be limited to:

ï†· To develop, construct, test and maintain architectures.

ï†· To ensure architectures will support the requirements of business.

ï†· To discover opportunities for data acquisition and sharing.

ï†· To develop data set processes for data modelling, mining and production.

ï†· To employ a variety of languages and tools to marry systems together.

ï†· To recommend way to improve data reliability, efficiency and quality.

ï†· To prepare data for use in predictive and prescriptive modelling.

ï†· To conduct research to answer industry and business questions.

ï†· To leverage volumes of data from internal and external to answer business questions.

ï†· To develop and manage stakeholder relations effectively to promote data management across the organisation and support reliable decision making and appropriate data usage.

ï†· To participate and provide technical support in cross organisational activities relating to any of the above mentioned data management activities.

ï†· To provide regular progress reports as per stakeholder requirements and present data management updates in various forums as required.

Minimum qualification Required:

ï†· A minimum of a Bachelors degree in Computer Science or Information Management OR equivalent;

ï†· A minimum of five to eight years experience in a data management environment",-1,HR Genie,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Our client based in the Northern Suburbs, is currently looking for a Data Engineer to join their team.

Responsibilities
Our client is a dynamic IT company that delivers value-driven IT solutions to the group. Our work lives revolve around our DNA. We take pride in our work, treat our colleagues, partners and our country with respect. We exercise collaborative decision-making and believe in having a balance in life. We do this all while having fun and enjoying what we do.

The primary focus of this position is to use technical skills to put software, systems and data together in a way that extracts meaningful insights from raw data. You will need to be helpful and supportive to your team and fellow developers. You join an energetic, focused and dynamic team.

Interact with clients to understand requirements and business problems/needs

Identify, analyse, visualise and understand supporting data to propose solid solutions

Create technical documentation for reference and reporting

Support existing solutions within GCP and Oracle

Doing standby on a rotating basis

Key Competencies and Qualifications

Matric

Tertiary qualification in IT

Preferred cloud experience in AWS/AZURE/GCP

At least 3 years of data warehouse ETL experience

Dimensional Modelling

Data analyses

Experience with data visualization and visualization tool(s)

Knowledge of the retail industry will be beneficial

Understanding and experience with version control SVN/GIT

Preferred – Korn shell scripting, Python/Java, SQL

Google Cloud Platform experience would be looked upon favourably

Having a broad understanding of different SDLC’s

Preferred agile experience

Strengths

The natural tendency to take ownership and responsibility

Strong problem solving, critical thinking, effective planning and organisational skills

Detail-oriented with excellent communication skills

You have a can-do attitude and positive outlook on life

Can cope under pressure

Curious and interested in analysing problems and possible solutions

Strong team player

Self-driven learner, passionate about new technology

Above all, be passionate about what you do

Should you wish to apply for the position, please apply directly via this job board, please ensure that you quote reference number 201620 subject heading or email body.

Please note that due to the high volume of CV's received; only shortlisted applicants will be contacted. Should you not receive communication from our offices within two weeks of submission please note that your application will not be considered for this position.

We will keep your CV on file and re-establish contact with you should opportunities in line with your expertise become available again.

Should you require any additional information give us a call on 021 012 5566.",-1,Surgo HR & Training,Cape Town,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We believe that our employees fuel our organization, essential to enable us to help our customers overcome their business challenges and achieve sustainable growth. As a result, we are committed to growing each individual and providing them with the challenges, feedback and support needed to achieve success in their career

If this sounds appealing, and like us, you get excited about data: its collection, storage, transformation or display, see if you’ve got what it takes to join our sought after DATA team.

Key Responsibilities And/or Outputs

You will represent IQbusiness at our customers, sometimes alone, and sometimes as part of an IQ team.

Providing a superior customer experience by building and maintaining relationships, working at customer offices, keeping data confidential
Design and develop – databases, SQL queries, stored procedures, reports, dashboards or integration solutions
Produce solutions for both real-time and batch environments
Test your work to ensure compliance
Solve problems, and do root cause analysis
Prioritize your workload
Assist in other areas relating to your true data function, such as data modeling, data and business analysts
Interact with a variety of individuals: senior, junior, technical and from business
Provide guidance to fellow colleagues, or even manage a team
Uphold the IQ values, which are to care, learn & share; innovate; deliver as well as to build, enhance and maintain relationships

Education

Matric pass
A tertiary qualification, preferably in an ICT relevant field
Appropriate Microsoft certifications are beneficial but not required

Requirements

3 - 6 years experience in the Data Engineering environments and technologies
Great communication skills
A passion for SQL, databases or reports
Can you write stored procedures, design complex queries and create views and triggers?
Are you able to work out the relationships in a data warehouse or the aggregation of a cube?
Do you extract and display useful information when you see patterns and trends in data?
Strong knowledge of the financial services industry, ideally in a consulting role
The use of data related software: databases, ETL and BI tools; report writing and analytical tools
We use a lot of Microsoft products. You may often be expected to use MS SQL Server, SSIS, SSRS, SSAS and Power BI to develop solutions
What other relevant software have you’ve used?
Ability to work in different project methodologies: Waterfall and/or Agile
Knowledge of full SDLC
Exposure to logical and physical data modeling

Equal Employment Opportunity

IQbusiness is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, citizenship, marital, domestic or civil partnership status, sexual orientation, or gender identity",3.7,"IQbusiness South Africa
3.7",Johannesburg,-1,1 to 50 Employees,-1,Company - Private,Consulting,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"We value a data engineer as someone who works behind the scenes to obtain, process and supply data via various methodologies and technologies, to various consumers, in ways and forms that makes sense and add value. This definition is very broad, as the field of data engineering is just as broad.

You may be the type of data engineer that develops API endpoints for the consumption of data by end users or even another data pipeline, or you may be the type of data engineer that develops highly distributed, high availability data processing pipelines in an effort to satisfy the need of the ever questioning data analysts and/or data scientists.

You have awesome knowledge about the following concepts
Data modelling
Relational data modelling in traditional relational database management systems. (Microsoft SQL Server, MySQL, PostgreSQL, etc)
Coercing unstructured and semi-structured data into a structured form.
Data pipelining knowledge - data extraction and transformation.
Data transformation knowledge for reporting and analytics purposes.
Knowledge of the MapReduce and related data processing paradigms would be a boon.
You have the following technical competencies
Writing SQL queries, that can relate, transform and aggregate data from many differing sources where natural keys may or may not exist.
Experience with writing data pipelines that move and transform data, for various uses.
Working knowledge of a general purpose programming language like Python would be a boost.
Working knowledge of columnar databases such as Google BigQuery, and SAP HANA would be a boost.
Working knowledge of highly distributed technologies such as Apache Hadoop or Apache Spark would be a boost.
Working knowledge of NoSQL technologies, such as Apache Solr would be a boost.
You have the following personal competencies
The ability to solve problems.
The ability to rotate around a problem, to see if solutions can be gained in different ways.
The ability to work in an ever changing, unstructured environment.
The ability to work as part of a team, with vastly differing skill sets and opinions.
The ability to contribute ideas to the quorum.
The ability to mentor and provide guidance for other team members.
A systems approach to thinking, as opposed to a siloed approach. The candidate needs to understand how their work affects the greater system.
The ability to work without supervision, and take accountability for the work they deliver.
The ability to liaise with a client, sifting through the fluff and extracting the actual requirements.
If this is you - apply now and we'll get in touch",-1,DotModus,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Data Engineer

Our client in the contact centre space is currently seeking a DATA ENGINEER that will work on the collecting, storing, processing, and analyzing of large datasets. The primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them. You will also be responsible for integrating them with the architecture used across the company.

Key Performance Areas:

Data reporting.
Implementing ETL processes.
Defining data retention policies.
Management of Customer Lead data.
Provision of data for advanced analytics.
Maintenance of internal client scorecards.
Assist team in resolving data-related support queries.
Optimize existing data processes through automation.
Assist with all data-related reporting and documentation.
Maintenance and optimisation of the Analytics database.
Provide technical support to and supervision of junior data administrators.
Continuous upskilling on new technologies, frameworks and market trends.
Monitoring performance and advising any necessary infrastructure changes.
Identifying, selecting and integrating any Big Data tools and frameworks required to provide real-time analytics.

Educational Requirements

IT related Degree or Diploma is a pre-requisite

Required Skills/Experience

ETL tools: Advanced SSIS
BI/Reporting : Qlikview/Power BI/ SSRS or SSAS
Programming languages: JAVA, C# , Python, SAS or R
Experience with NoSQL databases and/or campaign management tools will be advantageous.
Minimum 3 years’ applicable work experience in SQL, relational databases and data manipulation.
Experience in big data platforms (eg. Hadoop) or processing frameworks (eg. MapReduce/Spark) and querying tools (eg. Pig, Hive and Impala) will be highly beneficial.

Preferred Skills

Organizational skills
Experience in Attentional to detail.
Accountability is critical for this role.
Ability to work under pressure and meet deadlines.
Solid understanding of database design principles.
Should you not receive a response in 2 weeks please consider your application unsuccessful",-1,Rubik's Cubed Consulting,Durban,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"This well known company is looking for a Data Engineer. will be based in Rivonia
The ideal candidate will have strong experience in the following:
Data cleaning
SQL Export
Big data Sets

BSc Degree in Maths and Stats will be required
a min of 3 years experience.
Stable track record is required.

Send your Cv to marinda@prrrecruitment.co.za",-1,PRR Recruitment Services,Johannesburg,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Description

Position at Aculocity, LLC

At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes
Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.
Key Responsibilities
Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.
Key Traits
Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern
Position Requirements
2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.
Where will you work? This role will be based out of Durbanville, South Africa.",-1,GVW,Durbanville,-1,Unknown,-1,Unknown,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Information Technology, Gauteng JHB - Northern Suburbs

Market related - Market related Annually

An IT Consultancy Business based in Johannesburg is currently looking for a Business Intelligence Consultant / Data Engineering Consultant.

Requirements:

Extensive experience in data engineering
Experience in Business Intelligence, data and Power BI
Extensive experience in data governance and the Popi act
Ability to assess and make recommendations on data within the Popi act
Good understanding of T-SQL and query optimization, developing ETL strategies.
Good understanding with SQL Server 2008/2012, SSIS, SSRS and SSAS
Use SSIS to create ETL packages to validate, extract, transform, and load data into the data warehouse and data marts.
Deploy and configured the reports in the Report Server (SSRS).
Excellent experience in Tabular Modelling , PowerView, Qlikvie,w, and Power BI
Maintain ETL
Qlikview model
Create Drill-through, Drill-down, and Cross Tab Reports and Sub-Report using Report Definition Language (RDL).
Generate periodic reports based on the statistical analysis of the data using SQL Server Reporting Services (SSRS)
Advise and provide written technical documentation and recommendations

The information displayed above is not limited to advertisements. Please contact Thato for further information.

Please consider your application as unsuccessful if you have not received a response within 14 days of submitting your application. However, please keep a lookout on our website, www.bedifferent.co.za, for available positions that you may be suited for

Ad Visible Until: 29 October 2020
Ref: JHB005346/NL

Vacancy Type: Permanent",2.9,"Be Different Recruitment
2.9",Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Cloud Support Engineer (Big Data),-1,"ABOUT US

Amazon Web Services is the market leader and technology forerunner in the Cloud business. As a member of the AWS Support team you will be at the forefront of this transformational technology, assisting a global list of companies and developers that are taking advantage of a growing set of services and features to run their mission-critical applications. As a Cloud Support Engineer, you will act as the Cloud Ambassador across all the cloud products, arming our customers with required tools & tactics to get the most out of their Product and Support investment.

Would you like to use the latest cloud computing technologies? Do you have an interest in helping customers understand application architectures and integration approaches? Are you familiar with best practices for applications, servers and networks? Do you want to be part of a customer facing technology team helping to ensure the success of Amazon Web Services (AWS) as a leading technology organization?

If you fit the description, you might be the person we are looking for! We are a group of smart people, passionate about cloud computing, and believe that world class support is critical to customer success.

WHAT CAN YOU EXPECT FROM A LIFE AT AWS?

Every day will bring new and exciting challenges on the job while you:

· Learn and use groundbreaking technologies.
· Apply advanced troubleshooting techniques to provide unique solutions to our customers' individual needs.
· Interact with leading engineers around the world.
· Partner with Amazon Web Services teams to help reproduce and resolve customer issues.
· Leverage your extensive customer support experience to provide feedback to internal AWS teams on how to improve our services.
· Drive customer communication during critical events.
· Drive projects that improve support-related processes and our customers technical support experience.
· Write tutorials, how-to videos, and other technical articles for the developer community.
· Work on critical, highly complex customer problems that may span multiple AWS services.

WHY AWS SUPPORT?

· First and foremost this is a customer support role in The Cloud.
· On a typical day, a Support Engineer will be primarily responsible for solving customers cases through a variety of customer contact channels which include telephone, email, and web/live chat. You will apply advanced troubleshooting techniques to provide tailored solutions for our customers and drive customer interactions by thoughtfully working with customers to dive deep into the root cause of an issue.
· Apart from working on a broad spectrum of technical issues, an AWS Support Engineer may also coach/mentor new hires, develop & present training, partner with development teams on complex issues or contact deflection initiatives, participate in new hiring, write tools/script to help the team, or work with leadership on process improvement and strategic initiatives.
· Career development: We promote advancement opportunities across the organization to help you meet your career goals.
· Training: We have training programs to help you develop the skills required to be successful in your role.
· We hire smart people who are keen to build a career with AWS, so we are more interested in the areas that you do know instead of those you havent been exposed to yet.
· Support engineers interested in travel have presented training or participated in focused summits across our sites or at specific AWS events.
· As we operate on a follow-the-sun model, with Premium Support sites located globally, there is no after hours on-call or mandated overtime in this role.
· https://www.youtube.com/watch?v=GC3bWcFFZTo&t=24s



Basic Qualifications

The Big Data role supports our services that leverage data and produce business insights, which may include using Machine Learning/Artificial Intelligence (ML/AI). Helping our customers use and integrate Big Data services in what is arguably our industrys most exciting space. The portfolio of services covers EMR (Hadoop), DynamoDB (NoSQL), MangoDB, and Apache Cassandra.

· Advanced experience in Apache Hadoop, Apache Spark, Apache Hive, and Presto
· Advanced experience in DynamoDB or NoSQL technologies like MongoDB or Cassandra
· Advanced experience with System Administration with Linux (RHEL/CentOS) including Microsoft Active Directory, and LDAP integration.
· Experience with troubleshooting Kerberos Authentication problems.
· Experience with Network troubleshooting.
· Basic understanding of Machine Learning and statistics
· Experience with Java and Python and shell scripting
· Bachelors degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position



Preferred Qualifications

· Expert experience in the Hadoop Ecosystem including Apache Spark and Presto
· Expert experience in NoSQL
· Expert experience with blockchain technologies like Etherium Expert experience in data Data Lake architecture and administration
· Experience managing full application stacks from the OS up through custom applications
· Prior work experience with AWS - any or all of EC2, VPC, S3, RDS, EMR, Glue, SageMaker
· Excellent knowledge of Hadoop architecture, administration and support
· Expert understanding of distributed computing principles and their application in the cloud
· Good understanding of distributed computing environments Lead technical discussions on big data systems architecture and design
· Strong analysis and troubleshooting skills and experience
· AWS Certified Solutions Architect
· AWS certified Big Data Specialty
· Masters degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity and Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Response Center Engineer,-1,"Job Title
Response Center Engineer
Job Description


Philips is a world leading health technology company with a vision to make life better for people worldwide through meaningful innovation. Making good on this promise depends on our passionate, inspirational, collaborative and diverse team. We have over 80,000+ brilliant people around the world but are always looking for more. Like-minded, motivated, focused minds to join us in creating a healthier, more connected society while transforming themselves personally and professionally.

As a CCC Coordinator - Response Center Engineer you will have the opportunity to process customer calls and be responsible for screening and diagnosing professionally Healthcare equipment to support customers and colleagues remotely with solving technical issues and ensuring maximum customer satisfaction

You are responsible for:
Diagnose healthcare equipment to the quality standards set by Philips Healthcare (PH) remotely by interviewing customers or colleagues by telephone or by remotely logging in to the system
Advise Customer Care Center Coordinators and District Operations Managers and / or Team Leads about the best follow-up w.r.t. technical state of the diagnosed healthcare equipment
Advise the Customer Care Center Coordinators or Field Services Engineers about required spare parts and resources
Responsible for planning engineers related to Modality responsibility.
Responsible for coordination between CCC, CUSTOMER, Spare parts AND Engineer.
Responsible to drive Remote and FTR KPI’s to targets respectively 40% and 85%.
Will require minimal field work to keep abreast of technical capabilities.
Take calls from customers and make sure they are processed in the CCC ERP on timely manner including all relevant data
Support Field Services Engineers in the field with technical knowledge
Escalate technical issues to the Technical Support Specialist
Escalate technical issues to Business Unit support after consultation of the Technical Support Specialist
Monitor critical functions of the equipment’s in the IB and environmental conditions including RSN and True reachability.
Lead the planning and implementation of FSN’s and FCO’s accelerating remote implementation where applicable.
Submit timely and accurate service data, job sheets, reports, expense claims, radiation film badges, field problem reports and other paperwork as assigned
Keep abreast of new technologies likely to affect PH range of products
Use company property with care to ensure optimal results with minimal operational costs
Be a professional representative for PH with respect to customer problems, ensuring personal acceptability by the customer in behavior in accordance with PH policy and targets
Conform to PH safety standards including health and safety regulations and in the event of hazards or accidents to take immediate control of the situation and involve the Operations Manager and / or the responsible person to handle properly confidential issues according Philips standards and to act according General Business Principals
Follow all quality standards within the frame of valid PH business policies
Follow the company quality regulations (ISO 9001; PQA; TQM) and internal directives and procedures
You are a part of the dynamic South Africa Customer Care Centre Team .You will be reporting to the Customer Care Center Manager.

Requires a pleasant, assertive individual you can work very well in a team setting, a dynamic environment that requires flexibility and creativeness to achieve goals.

To succeed in this role, you should have the following skills and experience:
Degree level education or equivalent
Experience in maintenance and troubleshooting of technical complex systems
Fluent in English, verbal and written in addition to local language
In return, we offer you the unique combination of a critical and challenging role and a creative and empowering office environment. You will be actively encouraged to make improvements, establish best in class service and have a direct impact on the success of Philips on a daily basis.

Employment Equity

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply. Only apply for this role if you are a South African Citizen by birth or Naturalization prior to the 27 April 1994.

Why should you join Philips?

Working at Philips is more than a job. It’s a calling to create a healthier society through meaningful work, focused on improving 3 billion lives a year by delivering innovative solutions across the health continuum. Our people experience a variety of unexpected moments when their lives and careers come together in meaningful ways. Learn more by watching this video.

To find out more about what it’s like working for Philips at a personal level, visit the Working at Philips page on our career website, where you can read stories from our employee blog. Once there, you can also learn about our recruitment process, or find answers to some of the frequently asked questions.

Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.9,"Philips
3.9",Johannesburg,-1,10000+ Employees,1891,Company - Public,Health Care Services & Hospitals,Health Care,$10 to $25 million (USD),-1
Software Development Engineer - EC2 Placement,-1,"Build the systems that optimize how EC2 matches requests for Instances with the underlying compute capacity. EC2 Placement is seeking talented engineers to build the online and offline optimization systems for compute workload scheduling, and the customer capabilities to better manage those workloads. Amazon EC2 provides on-demand scalable compute capacity, and powers some of the largest services in the world. You will collaborate with a top-tier community of engineers to build systems to improve how customers are able to access EC2 compute resources.

The successful candidate will have strong software engineering experience, with a passion for thinking about, building and testing distributed systems. You have an interest in how Machine Learning and other optimization techniques can be applied to large-scale problems. You have demonstrated experience working with a team to design, build and operate large-scale systems. With strong engineering fundamentals, an analytical and data-driven approach to your work, and strong communication skills, you have the ability to collaborate well to deliver results. We move fast and work together on small teams to solve big problems.

If this opportunity sounds interesting, we would love to talk to you more about our work and the vibrant culture at AWS in Cape Town.

Basic Qualifications

· Degree in Computer Science or related field, or equivalent working experience
· 3+ years of industry experience in a software development environment
· Strong Computer Science fundamentals, including data structures, object-oriented design, algorithm design, problem solving, and complexity analysis.
· Proficiency in at least one modern programming language, such as Java, C#, Python, Scala, Kotlin

Preferred Qualifications

One or more of the following help you stand out:
· Demonstrated results designing, building and operating high-performance distributed systems in large-scale Linux environments
· Role model in writing high-quality, maintainable and secure code, mentoring others, and helping teams sharpen their development processes
· Ability to work effectively across teams to deliver results, with strong verbal and written communication skills
· Experience working with machine learning systems

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer - PBB IT,-1,"Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose


This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes
Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems
Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions
Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.

Research and best practices
Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development
Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.
Preferred Qualification and Experience
Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Aws Data Platform Engineer,-1,"Aws Data Platform Engineer

Posting Country:

South Africa

Date Posted:

15-Oct-2020

Full Time / Part Time:

Full Time

Contract Type:

Permanent

Joining Vodacom is more than a job, what we do matters. We don’t just carry minutes, texts and data – we carry people’s lives. And that’s a huge responsibility. If you think for a minute about the people you rely on…the likelihood is they rely on us.

Customers are at the heart of everything we do and we want to make a difference to the lives of our customers, and the communities in which we live and work. We support our people to give something back to the causes that mean the most to them through helping them give time and money to the charities they love.

And what’s it like to work here? We have created an environment where you can look forward to coming to work and are empowered to be at your best. We offer flexibility in how you work that helps you do your job in a way that suits you, opportunities to help you grow and progress throughout your career and a choice of benefits to suit your lifestyle.

Role Purpose
The H Band AWS Data Platform Engineer position is based within the Technology Business Unit.

The AWS Data Platform Engineer will be responsible for all Database services such as RDS, DynamoDB, etc. Should be able to migrate any databases from anywhere to AWS using any third-party tools or AWS database migration tool. Should also have understanding or expertise in creating data warehouses and data lake solutions on AWS.
Your responsibilities will include:
Apply practical knowledge of relational database design and usage with customers
Perform workload analysis and undertake performance tuning, as well as performance benchmarking in customer environments.
To develop state of the art solutions which are technically sound.
To provide a high-quality service to the Enterprise Cloud Services clients i.t.o. consultancy, solutions and delivery.
Commitment to team success and positive team dynamics including mentoring of other team members.
Passion for growing and applying technical skills in service to customers.
Be a trusted infrastructure advisor by providing objective, practical and relevant ideas, insights and advice.
Work collaboratively with consulting partners and technology teams to ensure high quality of solution delivery.
Encourage best practice and knowledge sharing with partners and cross-functional groups
Manage the overall database design and delivery of solutions.
Ability to make recommendations as they pertain to improvements in support/development initiatives and facilitate implementation with partners and cross-functional groups within the Business.
Participate in high level database solution definition and design during the implementation phase with the goal of providing reliable, stable and operationally sound applications that meet the Business requirements.
Ability to understand and translate business requirements into technical specifications
The ideal candidate will have:
A minimum of 3 years of industry related experience of which 1 year must be within a complex hosting environment.
Certifications in Database design, system architecture or cloud technologies.
Demonstrate knowledge of database systems internals including storage layouts and distributed databases/MPP architectures
Advanced SQL coding, tuning and query optimization.
Experience designing and leading database performance benchmarks.
Good knowledge of the different AWS services
Knowledge of cloud networking architecture, cloud operations, security, automation and orchestration.
Knowledge of database internals as it relates to query and system performance and tuning.
Understanding of overall system architecture, scalability, reliability, and performance in a database environment.
Excellent teamwork, time-management and organizational skills.
Perform other duties as deemed necessary and assigned by the customer and management
Strong interpersonal skills and problem-solving abilities.
Excellent documentation, communication and interpersonal skills.
Excellent analytical and problem-solving abilities.
Closing date for applications: Monday, 13 April 2020

The base location for this role is Vodacom World, Midrand

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply.
Vodacom is committed to an organisational culture that recognises, appreciates and values diversity & inclusion.

Commitment from Vodacom

Vodacom is committed to attracting, developing and retaining the very best people by offering a flexible, motivating and inclusive workplace in which talent is truly recognized, developed and rewarded. We believe that diversity plays an important role in the success of our business and we are committed to creating an inclusive work environment which respects, values, celebrates and makes the most of people’s individual differences - we are not only multinational but multicultural too. At Vodacom you will have access to our excellent flexible benefits programme that you would expect from any global company.",3.9,"Vodafone
3.9",Midrand,-1,10000+ Employees,1982,Company - Public,"Cable, Internet & Telephone Providers",Telecommunications,$10+ billion (USD),-1
Data Engineer Azure Data Factory,-1,"Enthuzex is looking for a motivated Lead Data Engineer to contribute towards the success of our Data and Analytics Technology initiatives. This is a hands-on technical role and this person will be responsible for the development and build of scalable solutions as it relates to the architecture strategies, data standards, digital data management, data integration, tools, and technology. The right candidate will play a deep dive hands-on critical development role in the digital transformation and in shaping how we acquire, ingest, transform and deliver data through the digital consumer channels.

Responsibilities:

Architect, design, develop and engineering end-to-end data pipelines across multiple data sources and systems of record.
Ensure data quality, integrity, security and completeness throughout the data lifecycle
Develop, design data models, data structures and ETL jobs for data acquisition and manipulation purposes
Develop deep understanding of the data sources, implement data standards, maintain data quality and master data management
Developing data services and API
Work closely with the cloud service providers to ensure completeness and alignment with the service offerings
Manage and maintain cloud based data and analytics platform
Deep understanding of the cloud offerings and engage in quick proof of concepts and proof of value in prototyping data and analytics solutions and derive viability
Ability to interact with the business stakeholders to understand requirements and translating into technology solutions

Expirience:

Experience in Cloud platform AWS or Azure eco-system. (Azure preferred)
Data Engineering/Development experience with SQL (Oracle, SQL Server, MySQL)
Strong development background creating pipelines and complex data transformations and manipulations using one of the languages Python, Java, R, or Scala with Databricks/Spark
Experience in NoSQL Databases and Big data technologies including Hadoop
Experience with API / RESTful data services
Worked on real-time data capture, processing and storing using technologies like Azure Event Hubs and Analytics
Experience working with different data storage options including AWS S3, Azure BLOB storage etc.
Understanding of different data formats including Parquet, Avro, CSV, ORC etc.
Prior experience with MPP databases and maintain large amount of data processing
Experience with Azure Data Factory and Azure Data Catalog is a big plus and mandatory
Experience with Microsoft/Azure ETL solutions and business Intelligence technologies is a big and mandatory
Past working experience on a fast paced and agile environment
Perform ongoing monitoring, automation and refinement of data engineering solutions
Experience in leading high visibility transformation projects that interacts with multiple business lines
Build and meet project timelines and manage delivery commitments with proper communication to management

Qualifications

Bachelor’s degree with 4+ years of relevant experience
Willingness to learn new technologies and thrive in an extremely fast paced environment
Team player and easy to work with.

Applicants must demonstrate their ability to master new enterprise level technologies. Successful applicants will exemplify Enthuzex ethical principles of uncompromising integrity, respect for others, and accountability for decisions

send cv's info@enthuzex.co.za",-1,Enthuzex,Leslie,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Scientist,-1,"The world is changing.

We all want something different.

At Luno, we see you as an individual.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the world, and to do so, we need the best team on board for our mission.

A bit about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 3 million customers across 40 countries.
We are Series B funded, backed by Balderton Capital and the Naspers Group.
Our platform has processed over 8 billion dollars since we've launched
We're proud to be one of the world's most international cryptocurrency teams from 26 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
The role in a nutshell:

Identifying opportunities in the business that could benefit most from cognitive applications, as well as building and enhancing organisational capabilities for deriving value from multiple data sources using data science.

What we'd like you to have:
Bachelor's degree or higher in the natural sciences or technical fields such as Mathematics, Statistics, Computer Science, Engineering or Economics
Enthusiasm to work in the cryptocurrencies space
Advanced SQL skills
Solid understanding of exploratory data analysis, predictive analytics, and optimisation using Python, R, Matlab, RapidMiner, KNIME or other data science-oriented platforms
Proficiency in the use of data science and machine learning domain-specific languages such as ""Caret"" and the ""Tidyverse"" suite of tools in R, or ""Pandas"" in Python
Strong interpersonal and communication skills
Communicating data insights using storytelling narratives
Ability to work independently, as well as within and across teams
Ability to successfully complete projects with large and/or incomplete data sets
More about what you'll be doing:
Optimising product performance by tracking and analysing customer behaviour on web and app, in collaboration with software engineers and product designers
Providing the business with reports and dashboards, on key performance metrics
Developing metrics to accurately assess the health of our Exchange platform
Comparative data-driven analysis of our Exchange against alternative platforms
Formulating business requirements into analytical objectives
Designing and running experiments to test hypotheses
Hacking through complex business problems using advanced data analysis to provide insights and recommendations
Building, maintaining, and optimising decisioning systems using advanced statistical and predictive modelling techniques
What will set you apart:
An advanced degree in Mathematics, Statistics, Computer Science or related field
At least 3 years' experience working in a similar role
A basic understanding of trading in financial markets
Experience working with a data analytics and visualisation platform such as Tableau, Cognos, QlikView, or Looker
Familiarity with using Google Analytics to understand customer behaviour
Solid knowledge of statistical and machine learning techniques
Familiarity with modern distributed data storage and processing systems such as Amazon Redshift, Big Query, Snowflake, Databricks and Apache Spark
You can gather and synthesise facts, theories, trends, patterns, inferences, and key issues in complex and variable situations
Ability to diagnose problems using formal problem-solving tools and techniques from multiple angles to generate multiple possible solutions
A sense of anticipating long-term problem areas and associated risk levels with objective rationale
Remote Life at Luno

If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
You'll be able to continuously upskill yourself with access to free online learning via MyAcademy, an international teaching marketplace with over 100000 courses from Harvard and other leading providers + share knowledge with your peers.
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity and paternity leave, and you can even take paw-ternity leave for your furry friend.
Annual Inspiration Day! Make time for that pottery course or spa day you've always wanted to do.
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"EY is a global leader in
assurance, tax, transaction and advisory services. Technology is at the heart
of what we do and deliver at EY. Technology solutions are integrated in the
client services we deliver and are key to our innovation as an organization.

Fueled by
strategic investment in technology and innovation, Client Technology seeks to
drive growth opportunities and solve complex business problems for our clients
through building a robust platform for business and powerful product engine
that are vital to innovation at scale. As part of Client Technology, you’ll
work with technologists and business experts, blending EY’s deep industry
knowledge and innovative ideas with our platforms, capabilities, and technical
expertise. As a catalyst for change and growth, you’ll be at the forefront of
integrating emerging technologies from AI to Data Analytics into every corner
of what we do at EY. That means more growth for you, exciting learning
opportunities, career choices, and the chance to make a real impact.

The selected
candidate
Develops
large and complex data architecture, composed of models, policies, rules or
standards that govern which data is collected and how it is stored, arranged,
integrated and put to use in data systems, including the design, build and
management of data infrastructure to address business requirements
Creates
sound use case driven roadmaps, depicting data architecture as-is and to-be
capabilities with the business by engaging with multidisciplinary teams, and by
identifying, managing and mitigating risk
Develops
relationships across the business to understand data requirements, applies deep
technical knowledge of data management to solve business problems in areas
where solutions may not currently exist, necessitating new solutions/ways of
working/technologies and proactively articulating these to the business
Review,
identify the latest emerging technologies, augmenting by services from the
leading cloud providers to solution and recommend the best next generation data
platform value driven approach for our clients
Your Key Responsibilities Include
Create
and maintain conceptual, logical and physical database models
Document
functional requirements and system specifications into the data architecture
and detailed design specifications for current and proposed designs
Document
and adhere to development standards and best practices in database designs
Maintain
highly effective and consistent communication within the team, peers, and the
leadership team
Reverse
engineer SQL code and modify it to solve problems/issues
Contribute
to the definition and implementation of data governance practices
Design
both data structures and data integration practices
Work
closely with the infrastructure teams to create a physical environment to
support data services
Evaluate
new and existing (internal and external) technologies and services in support
of data services and data analytics objectives
Skills And Attributes For Success
Understanding
of business process reengineering and business modeling concepts, business
systems development and analysis
Hands-on
experience in designing and implementing hybrid cloud and on-prem solutions
Experience
working with the latest versions of SQL Server
Experience
applying SAFe/Scrum/Kanban methodologies
Ability
to exercise judgment in solving technical, operational, and organizational
challenges
Expert
programming, performance tuning and troubleshooting skills, using the latest
popular programming languages for example python
Demonstrate
proactive approach to identifying issues and presenting solutions and options,
and where appropriate, leading to resolution
Minimum Qualifications
5+ years
demonstratable work experience as a Data Architect using data modeling tools
2-3 years
SQL coding experience on large projects
Must
possess expert SQL programming, performance tuning and troubleshooting skills
Create
database objects and SQL scripts
Understand
and developed data pipelines
Know how
to deformalize data for data science models
Experience
in python, spark and notebooks
Experience
designing data warehousing solutions
Experience
designing next generation data platforms utilising cloud services
In-depth
understanding of database structure principles
Seamlessly
able to translate business requirements to technology requirements
What We Look For
Strong
analytical skills and problem-solving ability
A
self-starter, independent-thinker, curious and creative person with ambition
and passion
Excellent
inter-personal, communication, collaboration, and presentation skills
Customer
focused
Excellent
time management skills
Positive
and constructive minded
Takes
responsibility for continuous self-learning
Takes the
lead and makes decisions in critical times and tough circumstances
Attention
to detail
High
levels of integrity and honesty
Curious
about new emerging technology
About EY
As a global leader in assurance, tax, transaction and consulting
services, we’re using the finance products, expertise and systems we’ve
developed to build a better working world. That starts with a culture that
believes in giving you the training, opportunities and creative freedom to make
things better. Whenever you join, however long you stay, the exceptional EY
experience lasts a lifetime.",3.8,"EY
3.8",Johannesburg,-1,10000+ Employees,1989,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Architect - Principal,-1,"We are looking for Principle Data Architect to join our Engineering team in Cape Town.

The world is changing.
We all want something different.
At Luno, we see you as individuals.

Together, we are upgrading the world of work to unleash the potential within and empower you to become the best possible version of yourself.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the financial landscape, and to do so, well we need the best team on board for our mission. In short, to achieve our goals, we need rockstars. As simple as that.

A little about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 5 million customers across 40 countries.
We're part of the Digital Currency Group, a group of companies driving progress in the cryptocurrency and blockchain space that includes Grayscale, Genesis, Coindesk and Foundry Services
Our platform has processed over $8 billion to date
We're proud to be one of the world's most international cryptocurrency teams from 43 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
How we work


Our engineering team (currently ~100 engineers) is split into organisations which we call Fleets. Each Fleet focuses on a core customer journey (onboarding, security, payments, support, new business, growth and marketing etc.). Each of these fleets contains multiple smaller teams called Pods, each of which focuses on a specific aspect of the product.

Pods will include a product owner, product designer, back-end engineers, Android, iOS and Web developers, who each bring a unique perspective to the problem you are all contributing towards.

We're agile, use scrum, continuous integration and continuous delivery, deploying to production every single day.

We're building teams to help us succeed in our mission to upgrade the world to a better financial system. You'll be joining a group of highly motivated software engineers who you'll work collaboratively with across our pods.

As a fast-growing company with offices around the world, you'll immediately see how your contributions directly impact both our internal users and client experience. Many of the problems we are solving result in trail blazing solutions which can't be found on Stack Overflow; so we're looking for engineers who flourish working in a complex domain.

In your first six months, you will:


...start at Luno by learning our processes, meeting the wider team and starting our engineering on-boarding program. After getting comfortable with the basics, you'll start learning our idiomatic patterns in a safe, easy-to-follow way - by building your own toy micro services. You'll get to practice how we do design docs, code reviews, deployments, events, logging and monitoring.

You'll meet the Pod(s) you'll be working with and quickly align on the teams' current OKRs and product roadmap. We succeed as a team, so we will provide you with regular feedback from your manager and peers and will encourage you to do the same.

What you'll do:
Work closely with our data science and platform teams on projects introducing new streams of data into our data lake
You will get to bring new ideas on how to further develop and innovate our data solutions and how to expose that data to the business
Accountable and Responsible for the design and architecture of Data systems that are robust and scalable.
Work in an Agile/Scrum framework or Agile mindset
Data backup/recovery and storage
Pick-up and learn new concepts, in both engineering and product, and be able to apply that knowledge quickly.
The ideal candidate for this role will have:
7+ years' experience in maintaining scalable data solutions and/or you are passionate about it
Ability to understand, communicate and advocate between build vs buy
Proven track record of setting up, restructuring and maintenance of databases
You know your way around ETL and you have experience with SQL
Experience in the AWS Data stack (RedShift,DynamoDB, Amazon RDS)
Familiarity with integrating data stores with BI platforms such as Looker, Tableau, or Power BI
You have experience with the concepts of CI/CD
Coding skills in e.g. Go, Python
Bachelor's degree in a related field preferred
AWS Certified DataOps Administrator
Be friendly, transparent, articulate and driven to succeed
Basic knowledge of and passion for digital currencies like Bitcoin
A work permit for South Africa if you are not a South African citizen
Don't be put off if you don't tick all of the boxes – they're a guide based on what we'd love to see but we appreciate that excellent software engineers have diverse backgrounds.

Remote Life at Luno


If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity / paternity and even (yes, you are reading it correctly) paw-ternity for your furry friend..
Annual Inspiration Day.. like that pottery course you've always been meaning to do!
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. You'll need to hold the legal right to work in South Africa already as we cannot provide visa sponsorship.

Be part of the change!",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer - EC2 Capacity Data Analytics,-1,"EC2 Capacity Data Analytics (CDA) team is looking for a Data Engineer to join our team.

Our team is part of the EC2 Capacity Engineering organization, which is responsible for providing the elasticity EC2 customers need to scale up/down compute resources in a cost-efficient manner. We predict customer usage across thousands of configuration combinations to deliver exactly what our customers require in just the right amount of time with just the right amount of capacity.

As a Data Engineer, you will build the ETL and analytics solutions for our internal customers to answer questions with data and drive critical improvements for the business. You will use best practices in software engineering, data management, data storage, data compute, and distributed systems. On any given day, we use Python, Scala, Java, SQL, Lambda, CloudFormation, Redshift and Glue as well as other public AWS services and a host of Amazon internal tools. We dont expect you to be an expert in, or necessarily even be familiar with all of the technologies listed above, but we do expect you to be excited to learn about them.

This position involves on-call responsibilities, typically for one week every two months. Our team is dedicated to supporting new team members. We care about your career growth, we try to assign projects and tasks based on what will help each team member develop into a more well-rounded engineer and enable them to take on more complex tasks in the future.

Our team values work-life balance and we are flexible when people occasionally need to work from home.

Job Duties
Develop and maintain automated ETL pipelines for big data using languages such as Scala, Spark, SQL and AWS services such as S3, Glue, Lambda, SNS, SQS, KMS. Example: ETL jobs that process a continuous flow of JSON source files and output the data in a business-friendly Parquet format that can be efficiently queried via Redshift Spectrum using SQL to answer business question.

Develop and maintain automated ETL monitoring and alarming solutions using Java/Python/Scala, Spark, SQL, and AWS services such as CloudWatch and Lambda.

Implement and support reporting and analytics infrastructure for internal business customers using AWS, services such Athena, Redshift, Spectrum, EMR, and QuickSight.

Develop and maintain data security and permissions solutions for enterprise scale data warehouse and data lake implementations including data encryption and database user access controls and logging.

Develop and maintain data warehouse and data lake metadata, data catalog, and user documentation for internal business customers.

Develop, test, and deploy code using internal software development toolsets. This includes the code for deploying infrastructure and solutions for secure data storage, ETL pipelines, data catalog, and data query.


Basic Qualifications

· Bachelors degree in Computer Science or related technical field, or equivalent work experience.
· 4+ years of overall work experience including Software Engineering, Data Engineering, Database Engineering, Business Intelligence.
· Experience with AWS technologies stack including Lambda, Glue, Redshift, RDS, S3, EMR or similar big data solutions stack

Preferred Qualifications

· Demonstrate efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data.
· Demonstrable proficiency in distributed systems and data architecture; design and implementation of batch and stream data processing pipelines; knows how to optimize the distribution, partitioning, and MPP of high-level data structures.

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer,-1,"Our client based in Johannesburg is urgently looking for a Data Engineer to be on a 3 months contract
Build data pipelines, experience in new tech like nifi, kafka, python

Joburg based, open to EE, 3 month contract with the option to extend, must be available at short notice",-1,EQplus,Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Overview
Job ID: 51456
Job Sector: Information Technology and Services
Country: South Africa
Region/State/Province/District: Gauteng
Location: Johannesburg

Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose

This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes

Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems

Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions

Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.
Research and best practices

Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development

Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.

Preferred Qualification and Experience

Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry

Knowledge/Technical Skills/Expertise

Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision

PLEASE NOTE: All our recruitment and selection processes comply with applicable local laws and regulations. We will never ask for money or any form of payment as part of our recruitment process. If you experience this, please contact our Fraudline on +27 800222050 or forward to TransactionFraudOpsSA@standardbank.co.za",4.1,"Standard Bank
4.1",Johannesburg,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"About us

At PBT Group we pride ourselves on being a Data Specialist organisation. With 20 years of experience in 27 countries over 3 continents, our team of 550 consultants have implemented more than 700 projects.",4.3,"PBT Group
4.3",Johannesburg,-1,Unknown,-1,Company - Private,Accounting,Accounting & Legal,Less than $1 million (USD),-1
Data Engineer,-1,"Kick-start your career in the online gaming world and experience the very latest in technology and innovation.

The Department:

Our mission is to provide our customers with the best online betting experience and share the thrill of gaming with them. Data is at the very heart of our business and is vital in everything we do.

Our cross-functional Data team has a big and exciting challenge ahead. We are in the process of re-platforming our traditional, on-premises RDBMS environment to a new microservice architecture in the cloud. We’re making use of the diverse set of data technologies in Microsoft Azure to offer new services, reporting structures and real-time data pipeline while serving the day-to-day requirements of a rapidly growing, data-hungry organisation.

Purpose of the Role:

This is an excellent opportunity for an individual who is looking to gain new skills. We are committed to creating a culture of learning and regularly run proof of concepts, provide internal demos, manage workshops and attend external conferences. Our data team has a wide range of skills including development for highly transactional RDBMS systems, data warehousing, data science and cloud technologies and we are always working to raise everyone’s game.

Duties include, but not limited to:

Work as part of an agile Data Engineering Team
Development of greenfield projects in Azure
Develop and maintain on-premises RDBMS/DW systems
Create robust ETL services and real-time data pipelines
Build and maintain Continuous Integration and DevOps pipelines
Test-driven development and pair programming with colleagues

Essential Criteria:

C#, .Net, Visual Studio
Git, Azure DevOps
NoSQL development (CosmosDB)
Demonstrable understanding of MS SQL Server in a highly transactional environment
Demonstrable understanding of development in Microsoft Azure
Able to understand query plans and identify performance bottlenecks
Test/Business-Driven Development
Building Continuous Integration/Deployment pipelines
Communicate effectively with both technical and non-technical stakeholders

Desirable Criteria:

Implementing Data Storage and Processing solutions in Azure (ARM Templates, Storage Accounts, Data Lake Storage, SQL DB, Cosmos DB, EventHubs, Function Apps, Log Analytics, Data Factory, Databricks, Polybase)
Implementing Security, Disaster Recovery, High Availability, Auditing, Monitoring and Alerting solutions in Azure
Automating tasks in Azure using Powershell / CLI
Predicting costs and optimizing spending in Azure
Message Queues (RabbitMQ, Kafka)
Python

Person Specifications:

Resilience
Teamwork
Technical Knowledge
Communication skills
Stress Tolerance
Please note we will apply relevance to our Talent Management and Talent Development Programme as part of our recruitment process.
Shortlisted candidates may need to complete an assessment.
This position requires trust and honesty it has access to customers financial details - therefore a credit and criminal record check will be conducted. The qualifications identified herein are an inherent job requirement; therefore, a qualification verification check will be done. By applying for this role, and supplying the necessary details, you hereby grant us permission to apply for these checks. This will be done in a confidential manner, and solely for the purposes of verification.

To view all current vacancies, please visit our website, www.digioutsource.com

Should you not hear from us within 2 weeks, please deem your application as unsuccessful.

The perfect place to work, play and grow!",3.9,"Digital Outsource Services
3.9",Cape Town,-1,1001 to 5000 Employees,1997,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
Data Engineer,-1,"At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes

Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.

Key Responsibilities

Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.

Key Traits

Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern

Position Requirements

2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.

Where will you work? This role will be based out of Durbanville, South Africa.",3.1,"Aculocity, LLC
3.1",Durbanville,-1,1 to 50 Employees,2006,Company - Private,IT Services,Information Technology,$1 to $5 million (USD),-1
Data Engineer,-1,"ENVIRONMENT:

A rapidly growing E-Commerce Platform seeks a highly talented Data Engineer to make an invaluable contribution to data democratisation and literacy vision by making accessible and easy-to-use data products and tools. You will require a Comp-Sci Degree or 3 years’ relevant industry experience, MySQL, PostgreSQL, Java, Python, in-depth understanding of OLAP, Data Marts, Star Scheme, Snowflake, be familiar with Jenkins, Travis, Circle CI, Docker, Kubernetes, experience with Kafka, Pub/Sub, Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks & significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing & Data Lake design and implementation and Lambda/Kappa architectures.

DUTIES:

Design, develop, test and maintain data architecture.

Prepare data for descriptive, predictive and prescriptive modelling.

Automate repetitive tasks and manual processes related with the data usage.

Optimize data delivery.

Design, develop and test large stream data pipelines to ingest, aggregate, clean, and distribute data models ready for analysis.

Ensure the highest standard in data integrity.

Leverage best practices in continuous integration and delivery.

Collaborate with other engineers, ML experts, analysts, and stakeholders to produce the most efficient and valuable solutions.

Implement features, technology, and processes that move us towards industry best practices, improving on scalability, efficiency, reliability, and security.

Operations and ownership of systems in production, responding to incidents.

REQUIREMENTS:

Qualifications –

Comp-Sci Degree or 3 years relevant industry experience.

Experience/Skills –

Open source relational database systems e.g. MySQL, PostgreSQL, etc.

Significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing, and Data Lake design and implementation and Lambda/Kappa architectures.

A thorough understanding of database and data warehousing principles e.g. OLAP, Data Marts, Star Schema, Snowflake, etc.

Java and Python.

Familiar with CI/CD tools such as Jenkins, Travis, Circle CI, etc.

Experience with Kafka, Pub/Sub, or other event-based systems.

Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks, etc.

Working in cloud environments and with containerisation frameworks, tools and platforms e.g. Docker, Kubernetes, GKE, etc.

A deep understanding of data pipelining, streaming, and Big Data technologies, methods, patterns, and techniques.

Troubleshooting complex database operations and performance issues.

Automating tasks using Shell Scripting or writing small applications.

ATTRIBUTES:

Works well with people and is passionate about helping people be their best.

A team player, an active listener, mentor, and able to communicate well.

Shows solid reasoning and decision making, with the ability to work under pressure.

Is passionate about technology, systems and data.

Is curious, always learning, and keeping up to date with the industry.

While we would really like to respond to every application, should you not be contacted for this position within 10 working days please consider your application unsuccessful.

COMMENTS:

When applying for jobs, ensure that you have the minimum job requirements. Only SA Citizens will be considered for this role. If you are not in the mentioned location of any of the jobs, please note your relocation plans in all applications for jobs and correspondence.",-1,Datafin IT Recruitment,Cape Town,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Cartrack is looking for passionate data science and engineering candidates that can join a growing team that is responsible for the intelligence and efficiency solution provision to over a million subscribers, many of whom are large fleets. We are in the midst of creating revolutionary platforms that will change the way that people interact with their vehicles.

You will have the opportunity to work with the very brightest global subject matter experts that are transforming the automotive industry across Fleet Management, Asset Management and Insurance Telematics solutions.

Get to know the role:

The role of a data engineer is a supporting one, but it is also an extremely vital one. As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements. We want to see candidates with mechanical tendencies and a desire to know how things work and to improve them.

The day-to-day activities:

Design, construct, install, test and maintain data management systems.
Build high-performance algorithms, predictive models, and prototypes.
Ensure that all systems meet the business/company requirements as well as industry practices.
Integrate up-and-coming data management and software engineering technologies into existing data structures.
Develop set processes for data mining, data modeling, and data production.
Create custom software components and analytics applications.
Research new uses for existing data.
Employ an array of technological languages and tools to connect systems together.
Install/update disaster recovery procedures.
Recommend different ways to constantly improve data reliability and quality.
Work on and maintain Data pipelines.

Requirements Essential:

At least 5 years’ proven experience as a Data Engineer, DevOps Engineer, Software Developer, or similar.
Proficient in Linux/Unix and shell scripting as well as in functional programming languages.
Expertise in setting up and explored with technologies such as Hadoop and Spark.
Bachelor’s degree in computer science, software/computer engineering, applied mathematics, or physics.",3.3,"Cartrack
3.3",Johannesburg,-1,501 to 1000 Employees,2004,Company - Private,Security Services,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Data Engineer,-1,"Data Engineers build and support data pipelines and datamarts built off those pipelines. Both must be scalable, repeatable and secure. The Data Engineer helps to facilitate gathering data from a variety of different sources, in the correct format, assuring that it conforms to data quality standards and assuring that downstream users can get to that data timeously. This role functions as a core member of an agile team. These professionals are responsible for the infrastructure that provides insights from raw data, handling and integrating diverse sources of data seamlessly. They enable solutions, by handling large volumes of data in batch and real-time by leveraging emerging technologies from both the big data and cloud spaces. Additional responsibilities include developing proof of concepts and implements complex big data solutions with a focus on collecting, parsing, managing, analysing and visualising large datasets. They know how to apply technologies to solve the problems of working with large volumes of data in diverse formats to deliver innovative solutions. Data Engineering is a technical job that requires substantial expertise in a broad range of software development and programming fields. These professionals have a knowledge of data analysis, end user requirements and business requirements analysis to develop a clear understanding of the business need and to incorporate these needs into a technical solution. They have a solid understanding of physical database design and the systems development lifecycle. This role must work well in a team environment.

Job Objectives

Work Complexity: * Architects Data analytics framework. * Translates complex functional and technical requirements into detailed architecture, design, and high performing software. * Leads Data and batch/real-time analytical solutions leveraging transformational technologies. * Works on multiple projects as a technical lead driving user story analysis and elaboration, design and development of software applications, testing, and builds automation tools.

Main Job Objectives: 1. Development and Operations 2. Database Development and Operations 3. Policies, Standards and Procedures 4. Communications 5. Business Continuity & Disaster Recovery 6. Research and Evaluation 7. Coaching/ Mentoring

Qualifications

Essential: 4 years Bachelors degree in computer science, computer engineering, or equivalent work experience AWS Certification at least to associate level

Experience

Essential:

5+ years Data engineering or software engineering

3-5 years demonstrated experience leading teams of engineers

2+ years Big Data experience

5+ years experience with Extract Transform and Load (ETL) processes

2+ years Could AWS experience

At least 2 years demonstrated experience with agile or other rapid application development methods - Agile exposure, Kanban or Scrum

5 years demonstrated experience with object oriented design, coding and testing patterns as well as experience in engineering (commercial or open source) software platforms and large scale data infrastructures.

Desirable:

5+ years Retail Operations experience

Knowledge and Skills

Essential: *Creating data feeds from on-premise to AWS Cloud (2 years) *Support data feeds in production on break fix basis (2 years) *Creating data marts using Talend or similar ETL development tool (4 years) *Manipulating data using python and pyspark (2 years) *Processing data using the Hadoop paradigm particularly using EMR, AWSs distribution of Hadoop (2 years) *Devop for Big Data and Business Intelligence including automated testing and deployment (2 years) * Extensive knowledge in different programming or scripting languages * Expert knowledge of data modeling and understanding of different data structures and their benefits and limitations under particular use cases.

Further technical skills required: * Capability to architect highly scalable distributed systems, using different open source tools. * Big Data batch and streaming tools * Talend (1 year) * AWS: EMR, EC2, S3 (1 year) * Python (1 year) * PySpark or Spark (1 year) - Desirable * Business Intelligence Data modelling (3 years) * SQL (3 years)",-1,Datonomy Solutions,Brackenfell,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We are assisting one of our clients that is based in Pretoria to fill a role of a Data Engineer

This is a 12 month contract role

Objective of this Scope of Work

The Data Engineer will drive improvement of the data management maturity levels and provide the necessary technical support within the company to support reliable and effective decision-making, appropriate usage and protection thereof.

Scope of Services Definition

The scope will include but will not be limited to:

ï†· To develop, construct, test and maintain architectures.

ï†· To ensure architectures will support the requirements of business.

ï†· To discover opportunities for data acquisition and sharing.

ï†· To develop data set processes for data modelling, mining and production.

ï†· To employ a variety of languages and tools to marry systems together.

ï†· To recommend way to improve data reliability, efficiency and quality.

ï†· To prepare data for use in predictive and prescriptive modelling.

ï†· To conduct research to answer industry and business questions.

ï†· To leverage volumes of data from internal and external to answer business questions.

ï†· To develop and manage stakeholder relations effectively to promote data management across the organisation and support reliable decision making and appropriate data usage.

ï†· To participate and provide technical support in cross organisational activities relating to any of the above mentioned data management activities.

ï†· To provide regular progress reports as per stakeholder requirements and present data management updates in various forums as required.

Minimum qualification Required:

ï†· A minimum of a Bachelors degree in Computer Science or Information Management OR equivalent;

ï†· A minimum of five to eight years experience in a data management environment",-1,HR Genie,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Our client based in the Northern Suburbs, is currently looking for a Data Engineer to join their team.

Responsibilities
Our client is a dynamic IT company that delivers value-driven IT solutions to the group. Our work lives revolve around our DNA. We take pride in our work, treat our colleagues, partners and our country with respect. We exercise collaborative decision-making and believe in having a balance in life. We do this all while having fun and enjoying what we do.

The primary focus of this position is to use technical skills to put software, systems and data together in a way that extracts meaningful insights from raw data. You will need to be helpful and supportive to your team and fellow developers. You join an energetic, focused and dynamic team.

Interact with clients to understand requirements and business problems/needs

Identify, analyse, visualise and understand supporting data to propose solid solutions

Create technical documentation for reference and reporting

Support existing solutions within GCP and Oracle

Doing standby on a rotating basis

Key Competencies and Qualifications

Matric

Tertiary qualification in IT

Preferred cloud experience in AWS/AZURE/GCP

At least 3 years of data warehouse ETL experience

Dimensional Modelling

Data analyses

Experience with data visualization and visualization tool(s)

Knowledge of the retail industry will be beneficial

Understanding and experience with version control SVN/GIT

Preferred – Korn shell scripting, Python/Java, SQL

Google Cloud Platform experience would be looked upon favourably

Having a broad understanding of different SDLC’s

Preferred agile experience

Strengths

The natural tendency to take ownership and responsibility

Strong problem solving, critical thinking, effective planning and organisational skills

Detail-oriented with excellent communication skills

You have a can-do attitude and positive outlook on life

Can cope under pressure

Curious and interested in analysing problems and possible solutions

Strong team player

Self-driven learner, passionate about new technology

Above all, be passionate about what you do

Should you wish to apply for the position, please apply directly via this job board, please ensure that you quote reference number 201620 subject heading or email body.

Please note that due to the high volume of CV's received; only shortlisted applicants will be contacted. Should you not receive communication from our offices within two weeks of submission please note that your application will not be considered for this position.

We will keep your CV on file and re-establish contact with you should opportunities in line with your expertise become available again.

Should you require any additional information give us a call on 021 012 5566.",-1,Surgo HR & Training,Cape Town,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We believe that our employees fuel our organization, essential to enable us to help our customers overcome their business challenges and achieve sustainable growth. As a result, we are committed to growing each individual and providing them with the challenges, feedback and support needed to achieve success in their career

If this sounds appealing, and like us, you get excited about data: its collection, storage, transformation or display, see if you’ve got what it takes to join our sought after DATA team.

Key Responsibilities And/or Outputs

You will represent IQbusiness at our customers, sometimes alone, and sometimes as part of an IQ team.

Providing a superior customer experience by building and maintaining relationships, working at customer offices, keeping data confidential
Design and develop – databases, SQL queries, stored procedures, reports, dashboards or integration solutions
Produce solutions for both real-time and batch environments
Test your work to ensure compliance
Solve problems, and do root cause analysis
Prioritize your workload
Assist in other areas relating to your true data function, such as data modeling, data and business analysts
Interact with a variety of individuals: senior, junior, technical and from business
Provide guidance to fellow colleagues, or even manage a team
Uphold the IQ values, which are to care, learn & share; innovate; deliver as well as to build, enhance and maintain relationships

Education

Matric pass
A tertiary qualification, preferably in an ICT relevant field
Appropriate Microsoft certifications are beneficial but not required

Requirements

3 - 6 years experience in the Data Engineering environments and technologies
Great communication skills
A passion for SQL, databases or reports
Can you write stored procedures, design complex queries and create views and triggers?
Are you able to work out the relationships in a data warehouse or the aggregation of a cube?
Do you extract and display useful information when you see patterns and trends in data?
Strong knowledge of the financial services industry, ideally in a consulting role
The use of data related software: databases, ETL and BI tools; report writing and analytical tools
We use a lot of Microsoft products. You may often be expected to use MS SQL Server, SSIS, SSRS, SSAS and Power BI to develop solutions
What other relevant software have you’ve used?
Ability to work in different project methodologies: Waterfall and/or Agile
Knowledge of full SDLC
Exposure to logical and physical data modeling

Equal Employment Opportunity

IQbusiness is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, citizenship, marital, domestic or civil partnership status, sexual orientation, or gender identity",3.7,"IQbusiness South Africa
3.7",Johannesburg,-1,1 to 50 Employees,-1,Company - Private,Consulting,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"We value a data engineer as someone who works behind the scenes to obtain, process and supply data via various methodologies and technologies, to various consumers, in ways and forms that makes sense and add value. This definition is very broad, as the field of data engineering is just as broad.

You may be the type of data engineer that develops API endpoints for the consumption of data by end users or even another data pipeline, or you may be the type of data engineer that develops highly distributed, high availability data processing pipelines in an effort to satisfy the need of the ever questioning data analysts and/or data scientists.

You have awesome knowledge about the following concepts
Data modelling
Relational data modelling in traditional relational database management systems. (Microsoft SQL Server, MySQL, PostgreSQL, etc)
Coercing unstructured and semi-structured data into a structured form.
Data pipelining knowledge - data extraction and transformation.
Data transformation knowledge for reporting and analytics purposes.
Knowledge of the MapReduce and related data processing paradigms would be a boon.
You have the following technical competencies
Writing SQL queries, that can relate, transform and aggregate data from many differing sources where natural keys may or may not exist.
Experience with writing data pipelines that move and transform data, for various uses.
Working knowledge of a general purpose programming language like Python would be a boost.
Working knowledge of columnar databases such as Google BigQuery, and SAP HANA would be a boost.
Working knowledge of highly distributed technologies such as Apache Hadoop or Apache Spark would be a boost.
Working knowledge of NoSQL technologies, such as Apache Solr would be a boost.
You have the following personal competencies
The ability to solve problems.
The ability to rotate around a problem, to see if solutions can be gained in different ways.
The ability to work in an ever changing, unstructured environment.
The ability to work as part of a team, with vastly differing skill sets and opinions.
The ability to contribute ideas to the quorum.
The ability to mentor and provide guidance for other team members.
A systems approach to thinking, as opposed to a siloed approach. The candidate needs to understand how their work affects the greater system.
The ability to work without supervision, and take accountability for the work they deliver.
The ability to liaise with a client, sifting through the fluff and extracting the actual requirements.
If this is you - apply now and we'll get in touch",-1,DotModus,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Data Engineer

Our client in the contact centre space is currently seeking a DATA ENGINEER that will work on the collecting, storing, processing, and analyzing of large datasets. The primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them. You will also be responsible for integrating them with the architecture used across the company.

Key Performance Areas:

Data reporting.
Implementing ETL processes.
Defining data retention policies.
Management of Customer Lead data.
Provision of data for advanced analytics.
Maintenance of internal client scorecards.
Assist team in resolving data-related support queries.
Optimize existing data processes through automation.
Assist with all data-related reporting and documentation.
Maintenance and optimisation of the Analytics database.
Provide technical support to and supervision of junior data administrators.
Continuous upskilling on new technologies, frameworks and market trends.
Monitoring performance and advising any necessary infrastructure changes.
Identifying, selecting and integrating any Big Data tools and frameworks required to provide real-time analytics.

Educational Requirements

IT related Degree or Diploma is a pre-requisite

Required Skills/Experience

ETL tools: Advanced SSIS
BI/Reporting : Qlikview/Power BI/ SSRS or SSAS
Programming languages: JAVA, C# , Python, SAS or R
Experience with NoSQL databases and/or campaign management tools will be advantageous.
Minimum 3 years’ applicable work experience in SQL, relational databases and data manipulation.
Experience in big data platforms (eg. Hadoop) or processing frameworks (eg. MapReduce/Spark) and querying tools (eg. Pig, Hive and Impala) will be highly beneficial.

Preferred Skills

Organizational skills
Experience in Attentional to detail.
Accountability is critical for this role.
Ability to work under pressure and meet deadlines.
Solid understanding of database design principles.
Should you not receive a response in 2 weeks please consider your application unsuccessful",-1,Rubik's Cubed Consulting,Durban,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"This well known company is looking for a Data Engineer. will be based in Rivonia
The ideal candidate will have strong experience in the following:
Data cleaning
SQL Export
Big data Sets

BSc Degree in Maths and Stats will be required
a min of 3 years experience.
Stable track record is required.

Send your Cv to marinda@prrrecruitment.co.za",-1,PRR Recruitment Services,Johannesburg,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Description

Position at Aculocity, LLC

At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes
Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.
Key Responsibilities
Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.
Key Traits
Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern
Position Requirements
2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.
Where will you work? This role will be based out of Durbanville, South Africa.",-1,GVW,Durbanville,-1,Unknown,-1,Unknown,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Information Technology, Gauteng JHB - Northern Suburbs

Market related - Market related Annually

An IT Consultancy Business based in Johannesburg is currently looking for a Business Intelligence Consultant / Data Engineering Consultant.

Requirements:

Extensive experience in data engineering
Experience in Business Intelligence, data and Power BI
Extensive experience in data governance and the Popi act
Ability to assess and make recommendations on data within the Popi act
Good understanding of T-SQL and query optimization, developing ETL strategies.
Good understanding with SQL Server 2008/2012, SSIS, SSRS and SSAS
Use SSIS to create ETL packages to validate, extract, transform, and load data into the data warehouse and data marts.
Deploy and configured the reports in the Report Server (SSRS).
Excellent experience in Tabular Modelling , PowerView, Qlikvie,w, and Power BI
Maintain ETL
Qlikview model
Create Drill-through, Drill-down, and Cross Tab Reports and Sub-Report using Report Definition Language (RDL).
Generate periodic reports based on the statistical analysis of the data using SQL Server Reporting Services (SSRS)
Advise and provide written technical documentation and recommendations

The information displayed above is not limited to advertisements. Please contact Thato for further information.

Please consider your application as unsuccessful if you have not received a response within 14 days of submitting your application. However, please keep a lookout on our website, www.bedifferent.co.za, for available positions that you may be suited for

Ad Visible Until: 29 October 2020
Ref: JHB005346/NL

Vacancy Type: Permanent",2.9,"Be Different Recruitment
2.9",Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Cloud Support Engineer (Big Data),-1,"ABOUT US

Amazon Web Services is the market leader and technology forerunner in the Cloud business. As a member of the AWS Support team you will be at the forefront of this transformational technology, assisting a global list of companies and developers that are taking advantage of a growing set of services and features to run their mission-critical applications. As a Cloud Support Engineer, you will act as the Cloud Ambassador across all the cloud products, arming our customers with required tools & tactics to get the most out of their Product and Support investment.

Would you like to use the latest cloud computing technologies? Do you have an interest in helping customers understand application architectures and integration approaches? Are you familiar with best practices for applications, servers and networks? Do you want to be part of a customer facing technology team helping to ensure the success of Amazon Web Services (AWS) as a leading technology organization?

If you fit the description, you might be the person we are looking for! We are a group of smart people, passionate about cloud computing, and believe that world class support is critical to customer success.

WHAT CAN YOU EXPECT FROM A LIFE AT AWS?

Every day will bring new and exciting challenges on the job while you:

· Learn and use groundbreaking technologies.
· Apply advanced troubleshooting techniques to provide unique solutions to our customers' individual needs.
· Interact with leading engineers around the world.
· Partner with Amazon Web Services teams to help reproduce and resolve customer issues.
· Leverage your extensive customer support experience to provide feedback to internal AWS teams on how to improve our services.
· Drive customer communication during critical events.
· Drive projects that improve support-related processes and our customers technical support experience.
· Write tutorials, how-to videos, and other technical articles for the developer community.
· Work on critical, highly complex customer problems that may span multiple AWS services.

WHY AWS SUPPORT?

· First and foremost this is a customer support role in The Cloud.
· On a typical day, a Support Engineer will be primarily responsible for solving customers cases through a variety of customer contact channels which include telephone, email, and web/live chat. You will apply advanced troubleshooting techniques to provide tailored solutions for our customers and drive customer interactions by thoughtfully working with customers to dive deep into the root cause of an issue.
· Apart from working on a broad spectrum of technical issues, an AWS Support Engineer may also coach/mentor new hires, develop & present training, partner with development teams on complex issues or contact deflection initiatives, participate in new hiring, write tools/script to help the team, or work with leadership on process improvement and strategic initiatives.
· Career development: We promote advancement opportunities across the organization to help you meet your career goals.
· Training: We have training programs to help you develop the skills required to be successful in your role.
· We hire smart people who are keen to build a career with AWS, so we are more interested in the areas that you do know instead of those you havent been exposed to yet.
· Support engineers interested in travel have presented training or participated in focused summits across our sites or at specific AWS events.
· As we operate on a follow-the-sun model, with Premium Support sites located globally, there is no after hours on-call or mandated overtime in this role.
· https://www.youtube.com/watch?v=GC3bWcFFZTo&t=24s



Basic Qualifications

The Big Data role supports our services that leverage data and produce business insights, which may include using Machine Learning/Artificial Intelligence (ML/AI). Helping our customers use and integrate Big Data services in what is arguably our industrys most exciting space. The portfolio of services covers EMR (Hadoop), DynamoDB (NoSQL), MangoDB, and Apache Cassandra.

· Advanced experience in Apache Hadoop, Apache Spark, Apache Hive, and Presto
· Advanced experience in DynamoDB or NoSQL technologies like MongoDB or Cassandra
· Advanced experience with System Administration with Linux (RHEL/CentOS) including Microsoft Active Directory, and LDAP integration.
· Experience with troubleshooting Kerberos Authentication problems.
· Experience with Network troubleshooting.
· Basic understanding of Machine Learning and statistics
· Experience with Java and Python and shell scripting
· Bachelors degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position



Preferred Qualifications

· Expert experience in the Hadoop Ecosystem including Apache Spark and Presto
· Expert experience in NoSQL
· Expert experience with blockchain technologies like Etherium Expert experience in data Data Lake architecture and administration
· Experience managing full application stacks from the OS up through custom applications
· Prior work experience with AWS - any or all of EC2, VPC, S3, RDS, EMR, Glue, SageMaker
· Excellent knowledge of Hadoop architecture, administration and support
· Expert understanding of distributed computing principles and their application in the cloud
· Good understanding of distributed computing environments Lead technical discussions on big data systems architecture and design
· Strong analysis and troubleshooting skills and experience
· AWS Certified Solutions Architect
· AWS certified Big Data Specialty
· Masters degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity and Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Response Center Engineer,-1,"Job Title
Response Center Engineer
Job Description


Philips is a world leading health technology company with a vision to make life better for people worldwide through meaningful innovation. Making good on this promise depends on our passionate, inspirational, collaborative and diverse team. We have over 80,000+ brilliant people around the world but are always looking for more. Like-minded, motivated, focused minds to join us in creating a healthier, more connected society while transforming themselves personally and professionally.

As a CCC Coordinator - Response Center Engineer you will have the opportunity to process customer calls and be responsible for screening and diagnosing professionally Healthcare equipment to support customers and colleagues remotely with solving technical issues and ensuring maximum customer satisfaction

You are responsible for:
Diagnose healthcare equipment to the quality standards set by Philips Healthcare (PH) remotely by interviewing customers or colleagues by telephone or by remotely logging in to the system
Advise Customer Care Center Coordinators and District Operations Managers and / or Team Leads about the best follow-up w.r.t. technical state of the diagnosed healthcare equipment
Advise the Customer Care Center Coordinators or Field Services Engineers about required spare parts and resources
Responsible for planning engineers related to Modality responsibility.
Responsible for coordination between CCC, CUSTOMER, Spare parts AND Engineer.
Responsible to drive Remote and FTR KPI’s to targets respectively 40% and 85%.
Will require minimal field work to keep abreast of technical capabilities.
Take calls from customers and make sure they are processed in the CCC ERP on timely manner including all relevant data
Support Field Services Engineers in the field with technical knowledge
Escalate technical issues to the Technical Support Specialist
Escalate technical issues to Business Unit support after consultation of the Technical Support Specialist
Monitor critical functions of the equipment’s in the IB and environmental conditions including RSN and True reachability.
Lead the planning and implementation of FSN’s and FCO’s accelerating remote implementation where applicable.
Submit timely and accurate service data, job sheets, reports, expense claims, radiation film badges, field problem reports and other paperwork as assigned
Keep abreast of new technologies likely to affect PH range of products
Use company property with care to ensure optimal results with minimal operational costs
Be a professional representative for PH with respect to customer problems, ensuring personal acceptability by the customer in behavior in accordance with PH policy and targets
Conform to PH safety standards including health and safety regulations and in the event of hazards or accidents to take immediate control of the situation and involve the Operations Manager and / or the responsible person to handle properly confidential issues according Philips standards and to act according General Business Principals
Follow all quality standards within the frame of valid PH business policies
Follow the company quality regulations (ISO 9001; PQA; TQM) and internal directives and procedures
You are a part of the dynamic South Africa Customer Care Centre Team .You will be reporting to the Customer Care Center Manager.

Requires a pleasant, assertive individual you can work very well in a team setting, a dynamic environment that requires flexibility and creativeness to achieve goals.

To succeed in this role, you should have the following skills and experience:
Degree level education or equivalent
Experience in maintenance and troubleshooting of technical complex systems
Fluent in English, verbal and written in addition to local language
In return, we offer you the unique combination of a critical and challenging role and a creative and empowering office environment. You will be actively encouraged to make improvements, establish best in class service and have a direct impact on the success of Philips on a daily basis.

Employment Equity

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply. Only apply for this role if you are a South African Citizen by birth or Naturalization prior to the 27 April 1994.

Why should you join Philips?

Working at Philips is more than a job. It’s a calling to create a healthier society through meaningful work, focused on improving 3 billion lives a year by delivering innovative solutions across the health continuum. Our people experience a variety of unexpected moments when their lives and careers come together in meaningful ways. Learn more by watching this video.

To find out more about what it’s like working for Philips at a personal level, visit the Working at Philips page on our career website, where you can read stories from our employee blog. Once there, you can also learn about our recruitment process, or find answers to some of the frequently asked questions.

Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.9,"Philips
3.9",Johannesburg,-1,10000+ Employees,1891,Company - Public,Health Care Services & Hospitals,Health Care,$10 to $25 million (USD),-1
Software Development Engineer - EC2 Placement,-1,"Build the systems that optimize how EC2 matches requests for Instances with the underlying compute capacity. EC2 Placement is seeking talented engineers to build the online and offline optimization systems for compute workload scheduling, and the customer capabilities to better manage those workloads. Amazon EC2 provides on-demand scalable compute capacity, and powers some of the largest services in the world. You will collaborate with a top-tier community of engineers to build systems to improve how customers are able to access EC2 compute resources.

The successful candidate will have strong software engineering experience, with a passion for thinking about, building and testing distributed systems. You have an interest in how Machine Learning and other optimization techniques can be applied to large-scale problems. You have demonstrated experience working with a team to design, build and operate large-scale systems. With strong engineering fundamentals, an analytical and data-driven approach to your work, and strong communication skills, you have the ability to collaborate well to deliver results. We move fast and work together on small teams to solve big problems.

If this opportunity sounds interesting, we would love to talk to you more about our work and the vibrant culture at AWS in Cape Town.

Basic Qualifications

· Degree in Computer Science or related field, or equivalent working experience
· 3+ years of industry experience in a software development environment
· Strong Computer Science fundamentals, including data structures, object-oriented design, algorithm design, problem solving, and complexity analysis.
· Proficiency in at least one modern programming language, such as Java, C#, Python, Scala, Kotlin

Preferred Qualifications

One or more of the following help you stand out:
· Demonstrated results designing, building and operating high-performance distributed systems in large-scale Linux environments
· Role model in writing high-quality, maintainable and secure code, mentoring others, and helping teams sharpen their development processes
· Ability to work effectively across teams to deliver results, with strong verbal and written communication skills
· Experience working with machine learning systems

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer - PBB IT,-1,"Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose


This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes
Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems
Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions
Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.

Research and best practices
Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development
Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.
Preferred Qualification and Experience
Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Aws Data Platform Engineer,-1,"Aws Data Platform Engineer

Posting Country:

South Africa

Date Posted:

15-Oct-2020

Full Time / Part Time:

Full Time

Contract Type:

Permanent

Joining Vodacom is more than a job, what we do matters. We don’t just carry minutes, texts and data – we carry people’s lives. And that’s a huge responsibility. If you think for a minute about the people you rely on…the likelihood is they rely on us.

Customers are at the heart of everything we do and we want to make a difference to the lives of our customers, and the communities in which we live and work. We support our people to give something back to the causes that mean the most to them through helping them give time and money to the charities they love.

And what’s it like to work here? We have created an environment where you can look forward to coming to work and are empowered to be at your best. We offer flexibility in how you work that helps you do your job in a way that suits you, opportunities to help you grow and progress throughout your career and a choice of benefits to suit your lifestyle.

Role Purpose
The H Band AWS Data Platform Engineer position is based within the Technology Business Unit.

The AWS Data Platform Engineer will be responsible for all Database services such as RDS, DynamoDB, etc. Should be able to migrate any databases from anywhere to AWS using any third-party tools or AWS database migration tool. Should also have understanding or expertise in creating data warehouses and data lake solutions on AWS.
Your responsibilities will include:
Apply practical knowledge of relational database design and usage with customers
Perform workload analysis and undertake performance tuning, as well as performance benchmarking in customer environments.
To develop state of the art solutions which are technically sound.
To provide a high-quality service to the Enterprise Cloud Services clients i.t.o. consultancy, solutions and delivery.
Commitment to team success and positive team dynamics including mentoring of other team members.
Passion for growing and applying technical skills in service to customers.
Be a trusted infrastructure advisor by providing objective, practical and relevant ideas, insights and advice.
Work collaboratively with consulting partners and technology teams to ensure high quality of solution delivery.
Encourage best practice and knowledge sharing with partners and cross-functional groups
Manage the overall database design and delivery of solutions.
Ability to make recommendations as they pertain to improvements in support/development initiatives and facilitate implementation with partners and cross-functional groups within the Business.
Participate in high level database solution definition and design during the implementation phase with the goal of providing reliable, stable and operationally sound applications that meet the Business requirements.
Ability to understand and translate business requirements into technical specifications
The ideal candidate will have:
A minimum of 3 years of industry related experience of which 1 year must be within a complex hosting environment.
Certifications in Database design, system architecture or cloud technologies.
Demonstrate knowledge of database systems internals including storage layouts and distributed databases/MPP architectures
Advanced SQL coding, tuning and query optimization.
Experience designing and leading database performance benchmarks.
Good knowledge of the different AWS services
Knowledge of cloud networking architecture, cloud operations, security, automation and orchestration.
Knowledge of database internals as it relates to query and system performance and tuning.
Understanding of overall system architecture, scalability, reliability, and performance in a database environment.
Excellent teamwork, time-management and organizational skills.
Perform other duties as deemed necessary and assigned by the customer and management
Strong interpersonal skills and problem-solving abilities.
Excellent documentation, communication and interpersonal skills.
Excellent analytical and problem-solving abilities.
Closing date for applications: Monday, 13 April 2020

The base location for this role is Vodacom World, Midrand

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply.
Vodacom is committed to an organisational culture that recognises, appreciates and values diversity & inclusion.

Commitment from Vodacom

Vodacom is committed to attracting, developing and retaining the very best people by offering a flexible, motivating and inclusive workplace in which talent is truly recognized, developed and rewarded. We believe that diversity plays an important role in the success of our business and we are committed to creating an inclusive work environment which respects, values, celebrates and makes the most of people’s individual differences - we are not only multinational but multicultural too. At Vodacom you will have access to our excellent flexible benefits programme that you would expect from any global company.",3.9,"Vodafone
3.9",Midrand,-1,10000+ Employees,1982,Company - Public,"Cable, Internet & Telephone Providers",Telecommunications,$10+ billion (USD),-1
Data Engineer Azure Data Factory,-1,"Enthuzex is looking for a motivated Lead Data Engineer to contribute towards the success of our Data and Analytics Technology initiatives. This is a hands-on technical role and this person will be responsible for the development and build of scalable solutions as it relates to the architecture strategies, data standards, digital data management, data integration, tools, and technology. The right candidate will play a deep dive hands-on critical development role in the digital transformation and in shaping how we acquire, ingest, transform and deliver data through the digital consumer channels.

Responsibilities:

Architect, design, develop and engineering end-to-end data pipelines across multiple data sources and systems of record.
Ensure data quality, integrity, security and completeness throughout the data lifecycle
Develop, design data models, data structures and ETL jobs for data acquisition and manipulation purposes
Develop deep understanding of the data sources, implement data standards, maintain data quality and master data management
Developing data services and API
Work closely with the cloud service providers to ensure completeness and alignment with the service offerings
Manage and maintain cloud based data and analytics platform
Deep understanding of the cloud offerings and engage in quick proof of concepts and proof of value in prototyping data and analytics solutions and derive viability
Ability to interact with the business stakeholders to understand requirements and translating into technology solutions

Expirience:

Experience in Cloud platform AWS or Azure eco-system. (Azure preferred)
Data Engineering/Development experience with SQL (Oracle, SQL Server, MySQL)
Strong development background creating pipelines and complex data transformations and manipulations using one of the languages Python, Java, R, or Scala with Databricks/Spark
Experience in NoSQL Databases and Big data technologies including Hadoop
Experience with API / RESTful data services
Worked on real-time data capture, processing and storing using technologies like Azure Event Hubs and Analytics
Experience working with different data storage options including AWS S3, Azure BLOB storage etc.
Understanding of different data formats including Parquet, Avro, CSV, ORC etc.
Prior experience with MPP databases and maintain large amount of data processing
Experience with Azure Data Factory and Azure Data Catalog is a big plus and mandatory
Experience with Microsoft/Azure ETL solutions and business Intelligence technologies is a big and mandatory
Past working experience on a fast paced and agile environment
Perform ongoing monitoring, automation and refinement of data engineering solutions
Experience in leading high visibility transformation projects that interacts with multiple business lines
Build and meet project timelines and manage delivery commitments with proper communication to management

Qualifications

Bachelor’s degree with 4+ years of relevant experience
Willingness to learn new technologies and thrive in an extremely fast paced environment
Team player and easy to work with.

Applicants must demonstrate their ability to master new enterprise level technologies. Successful applicants will exemplify Enthuzex ethical principles of uncompromising integrity, respect for others, and accountability for decisions

send cv's info@enthuzex.co.za",-1,Enthuzex,Leslie,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Scientist,-1,"The world is changing.

We all want something different.

At Luno, we see you as an individual.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the world, and to do so, we need the best team on board for our mission.

A bit about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 3 million customers across 40 countries.
We are Series B funded, backed by Balderton Capital and the Naspers Group.
Our platform has processed over 8 billion dollars since we've launched
We're proud to be one of the world's most international cryptocurrency teams from 26 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
The role in a nutshell:

Identifying opportunities in the business that could benefit most from cognitive applications, as well as building and enhancing organisational capabilities for deriving value from multiple data sources using data science.

What we'd like you to have:
Bachelor's degree or higher in the natural sciences or technical fields such as Mathematics, Statistics, Computer Science, Engineering or Economics
Enthusiasm to work in the cryptocurrencies space
Advanced SQL skills
Solid understanding of exploratory data analysis, predictive analytics, and optimisation using Python, R, Matlab, RapidMiner, KNIME or other data science-oriented platforms
Proficiency in the use of data science and machine learning domain-specific languages such as ""Caret"" and the ""Tidyverse"" suite of tools in R, or ""Pandas"" in Python
Strong interpersonal and communication skills
Communicating data insights using storytelling narratives
Ability to work independently, as well as within and across teams
Ability to successfully complete projects with large and/or incomplete data sets
More about what you'll be doing:
Optimising product performance by tracking and analysing customer behaviour on web and app, in collaboration with software engineers and product designers
Providing the business with reports and dashboards, on key performance metrics
Developing metrics to accurately assess the health of our Exchange platform
Comparative data-driven analysis of our Exchange against alternative platforms
Formulating business requirements into analytical objectives
Designing and running experiments to test hypotheses
Hacking through complex business problems using advanced data analysis to provide insights and recommendations
Building, maintaining, and optimising decisioning systems using advanced statistical and predictive modelling techniques
What will set you apart:
An advanced degree in Mathematics, Statistics, Computer Science or related field
At least 3 years' experience working in a similar role
A basic understanding of trading in financial markets
Experience working with a data analytics and visualisation platform such as Tableau, Cognos, QlikView, or Looker
Familiarity with using Google Analytics to understand customer behaviour
Solid knowledge of statistical and machine learning techniques
Familiarity with modern distributed data storage and processing systems such as Amazon Redshift, Big Query, Snowflake, Databricks and Apache Spark
You can gather and synthesise facts, theories, trends, patterns, inferences, and key issues in complex and variable situations
Ability to diagnose problems using formal problem-solving tools and techniques from multiple angles to generate multiple possible solutions
A sense of anticipating long-term problem areas and associated risk levels with objective rationale
Remote Life at Luno

If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
You'll be able to continuously upskill yourself with access to free online learning via MyAcademy, an international teaching marketplace with over 100000 courses from Harvard and other leading providers + share knowledge with your peers.
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity and paternity leave, and you can even take paw-ternity leave for your furry friend.
Annual Inspiration Day! Make time for that pottery course or spa day you've always wanted to do.
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"EY is a global leader in
assurance, tax, transaction and advisory services. Technology is at the heart
of what we do and deliver at EY. Technology solutions are integrated in the
client services we deliver and are key to our innovation as an organization.

Fueled by
strategic investment in technology and innovation, Client Technology seeks to
drive growth opportunities and solve complex business problems for our clients
through building a robust platform for business and powerful product engine
that are vital to innovation at scale. As part of Client Technology, you’ll
work with technologists and business experts, blending EY’s deep industry
knowledge and innovative ideas with our platforms, capabilities, and technical
expertise. As a catalyst for change and growth, you’ll be at the forefront of
integrating emerging technologies from AI to Data Analytics into every corner
of what we do at EY. That means more growth for you, exciting learning
opportunities, career choices, and the chance to make a real impact.

The selected
candidate
Develops
large and complex data architecture, composed of models, policies, rules or
standards that govern which data is collected and how it is stored, arranged,
integrated and put to use in data systems, including the design, build and
management of data infrastructure to address business requirements
Creates
sound use case driven roadmaps, depicting data architecture as-is and to-be
capabilities with the business by engaging with multidisciplinary teams, and by
identifying, managing and mitigating risk
Develops
relationships across the business to understand data requirements, applies deep
technical knowledge of data management to solve business problems in areas
where solutions may not currently exist, necessitating new solutions/ways of
working/technologies and proactively articulating these to the business
Review,
identify the latest emerging technologies, augmenting by services from the
leading cloud providers to solution and recommend the best next generation data
platform value driven approach for our clients
Your Key Responsibilities Include
Create
and maintain conceptual, logical and physical database models
Document
functional requirements and system specifications into the data architecture
and detailed design specifications for current and proposed designs
Document
and adhere to development standards and best practices in database designs
Maintain
highly effective and consistent communication within the team, peers, and the
leadership team
Reverse
engineer SQL code and modify it to solve problems/issues
Contribute
to the definition and implementation of data governance practices
Design
both data structures and data integration practices
Work
closely with the infrastructure teams to create a physical environment to
support data services
Evaluate
new and existing (internal and external) technologies and services in support
of data services and data analytics objectives
Skills And Attributes For Success
Understanding
of business process reengineering and business modeling concepts, business
systems development and analysis
Hands-on
experience in designing and implementing hybrid cloud and on-prem solutions
Experience
working with the latest versions of SQL Server
Experience
applying SAFe/Scrum/Kanban methodologies
Ability
to exercise judgment in solving technical, operational, and organizational
challenges
Expert
programming, performance tuning and troubleshooting skills, using the latest
popular programming languages for example python
Demonstrate
proactive approach to identifying issues and presenting solutions and options,
and where appropriate, leading to resolution
Minimum Qualifications
5+ years
demonstratable work experience as a Data Architect using data modeling tools
2-3 years
SQL coding experience on large projects
Must
possess expert SQL programming, performance tuning and troubleshooting skills
Create
database objects and SQL scripts
Understand
and developed data pipelines
Know how
to deformalize data for data science models
Experience
in python, spark and notebooks
Experience
designing data warehousing solutions
Experience
designing next generation data platforms utilising cloud services
In-depth
understanding of database structure principles
Seamlessly
able to translate business requirements to technology requirements
What We Look For
Strong
analytical skills and problem-solving ability
A
self-starter, independent-thinker, curious and creative person with ambition
and passion
Excellent
inter-personal, communication, collaboration, and presentation skills
Customer
focused
Excellent
time management skills
Positive
and constructive minded
Takes
responsibility for continuous self-learning
Takes the
lead and makes decisions in critical times and tough circumstances
Attention
to detail
High
levels of integrity and honesty
Curious
about new emerging technology
About EY
As a global leader in assurance, tax, transaction and consulting
services, we’re using the finance products, expertise and systems we’ve
developed to build a better working world. That starts with a culture that
believes in giving you the training, opportunities and creative freedom to make
things better. Whenever you join, however long you stay, the exceptional EY
experience lasts a lifetime.",3.8,"EY
3.8",Johannesburg,-1,10000+ Employees,1989,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Architect - Principal,-1,"We are looking for Principle Data Architect to join our Engineering team in Cape Town.

The world is changing.
We all want something different.
At Luno, we see you as individuals.

Together, we are upgrading the world of work to unleash the potential within and empower you to become the best possible version of yourself.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the financial landscape, and to do so, well we need the best team on board for our mission. In short, to achieve our goals, we need rockstars. As simple as that.

A little about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 5 million customers across 40 countries.
We're part of the Digital Currency Group, a group of companies driving progress in the cryptocurrency and blockchain space that includes Grayscale, Genesis, Coindesk and Foundry Services
Our platform has processed over $8 billion to date
We're proud to be one of the world's most international cryptocurrency teams from 43 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
How we work


Our engineering team (currently ~100 engineers) is split into organisations which we call Fleets. Each Fleet focuses on a core customer journey (onboarding, security, payments, support, new business, growth and marketing etc.). Each of these fleets contains multiple smaller teams called Pods, each of which focuses on a specific aspect of the product.

Pods will include a product owner, product designer, back-end engineers, Android, iOS and Web developers, who each bring a unique perspective to the problem you are all contributing towards.

We're agile, use scrum, continuous integration and continuous delivery, deploying to production every single day.

We're building teams to help us succeed in our mission to upgrade the world to a better financial system. You'll be joining a group of highly motivated software engineers who you'll work collaboratively with across our pods.

As a fast-growing company with offices around the world, you'll immediately see how your contributions directly impact both our internal users and client experience. Many of the problems we are solving result in trail blazing solutions which can't be found on Stack Overflow; so we're looking for engineers who flourish working in a complex domain.

In your first six months, you will:


...start at Luno by learning our processes, meeting the wider team and starting our engineering on-boarding program. After getting comfortable with the basics, you'll start learning our idiomatic patterns in a safe, easy-to-follow way - by building your own toy micro services. You'll get to practice how we do design docs, code reviews, deployments, events, logging and monitoring.

You'll meet the Pod(s) you'll be working with and quickly align on the teams' current OKRs and product roadmap. We succeed as a team, so we will provide you with regular feedback from your manager and peers and will encourage you to do the same.

What you'll do:
Work closely with our data science and platform teams on projects introducing new streams of data into our data lake
You will get to bring new ideas on how to further develop and innovate our data solutions and how to expose that data to the business
Accountable and Responsible for the design and architecture of Data systems that are robust and scalable.
Work in an Agile/Scrum framework or Agile mindset
Data backup/recovery and storage
Pick-up and learn new concepts, in both engineering and product, and be able to apply that knowledge quickly.
The ideal candidate for this role will have:
7+ years' experience in maintaining scalable data solutions and/or you are passionate about it
Ability to understand, communicate and advocate between build vs buy
Proven track record of setting up, restructuring and maintenance of databases
You know your way around ETL and you have experience with SQL
Experience in the AWS Data stack (RedShift,DynamoDB, Amazon RDS)
Familiarity with integrating data stores with BI platforms such as Looker, Tableau, or Power BI
You have experience with the concepts of CI/CD
Coding skills in e.g. Go, Python
Bachelor's degree in a related field preferred
AWS Certified DataOps Administrator
Be friendly, transparent, articulate and driven to succeed
Basic knowledge of and passion for digital currencies like Bitcoin
A work permit for South Africa if you are not a South African citizen
Don't be put off if you don't tick all of the boxes – they're a guide based on what we'd love to see but we appreciate that excellent software engineers have diverse backgrounds.

Remote Life at Luno


If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity / paternity and even (yes, you are reading it correctly) paw-ternity for your furry friend..
Annual Inspiration Day.. like that pottery course you've always been meaning to do!
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. You'll need to hold the legal right to work in South Africa already as we cannot provide visa sponsorship.

Be part of the change!",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer - EC2 Capacity Data Analytics,-1,"EC2 Capacity Data Analytics (CDA) team is looking for a Data Engineer to join our team.

Our team is part of the EC2 Capacity Engineering organization, which is responsible for providing the elasticity EC2 customers need to scale up/down compute resources in a cost-efficient manner. We predict customer usage across thousands of configuration combinations to deliver exactly what our customers require in just the right amount of time with just the right amount of capacity.

As a Data Engineer, you will build the ETL and analytics solutions for our internal customers to answer questions with data and drive critical improvements for the business. You will use best practices in software engineering, data management, data storage, data compute, and distributed systems. On any given day, we use Python, Scala, Java, SQL, Lambda, CloudFormation, Redshift and Glue as well as other public AWS services and a host of Amazon internal tools. We dont expect you to be an expert in, or necessarily even be familiar with all of the technologies listed above, but we do expect you to be excited to learn about them.

This position involves on-call responsibilities, typically for one week every two months. Our team is dedicated to supporting new team members. We care about your career growth, we try to assign projects and tasks based on what will help each team member develop into a more well-rounded engineer and enable them to take on more complex tasks in the future.

Our team values work-life balance and we are flexible when people occasionally need to work from home.

Job Duties
Develop and maintain automated ETL pipelines for big data using languages such as Scala, Spark, SQL and AWS services such as S3, Glue, Lambda, SNS, SQS, KMS. Example: ETL jobs that process a continuous flow of JSON source files and output the data in a business-friendly Parquet format that can be efficiently queried via Redshift Spectrum using SQL to answer business question.

Develop and maintain automated ETL monitoring and alarming solutions using Java/Python/Scala, Spark, SQL, and AWS services such as CloudWatch and Lambda.

Implement and support reporting and analytics infrastructure for internal business customers using AWS, services such Athena, Redshift, Spectrum, EMR, and QuickSight.

Develop and maintain data security and permissions solutions for enterprise scale data warehouse and data lake implementations including data encryption and database user access controls and logging.

Develop and maintain data warehouse and data lake metadata, data catalog, and user documentation for internal business customers.

Develop, test, and deploy code using internal software development toolsets. This includes the code for deploying infrastructure and solutions for secure data storage, ETL pipelines, data catalog, and data query.


Basic Qualifications

· Bachelors degree in Computer Science or related technical field, or equivalent work experience.
· 4+ years of overall work experience including Software Engineering, Data Engineering, Database Engineering, Business Intelligence.
· Experience with AWS technologies stack including Lambda, Glue, Redshift, RDS, S3, EMR or similar big data solutions stack

Preferred Qualifications

· Demonstrate efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data.
· Demonstrable proficiency in distributed systems and data architecture; design and implementation of batch and stream data processing pipelines; knows how to optimize the distribution, partitioning, and MPP of high-level data structures.

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer,-1,"Our client based in Johannesburg is urgently looking for a Data Engineer to be on a 3 months contract
Build data pipelines, experience in new tech like nifi, kafka, python

Joburg based, open to EE, 3 month contract with the option to extend, must be available at short notice",-1,EQplus,Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Overview
Job ID: 51456
Job Sector: Information Technology and Services
Country: South Africa
Region/State/Province/District: Gauteng
Location: Johannesburg

Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose

This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes

Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems

Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions

Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.
Research and best practices

Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development

Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.

Preferred Qualification and Experience

Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry

Knowledge/Technical Skills/Expertise

Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision

PLEASE NOTE: All our recruitment and selection processes comply with applicable local laws and regulations. We will never ask for money or any form of payment as part of our recruitment process. If you experience this, please contact our Fraudline on +27 800222050 or forward to TransactionFraudOpsSA@standardbank.co.za",4.1,"Standard Bank
4.1",Johannesburg,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"About us

At PBT Group we pride ourselves on being a Data Specialist organisation. With 20 years of experience in 27 countries over 3 continents, our team of 550 consultants have implemented more than 700 projects.",4.3,"PBT Group
4.3",Johannesburg,-1,Unknown,-1,Company - Private,Accounting,Accounting & Legal,Less than $1 million (USD),-1
Data Engineer,-1,"Kick-start your career in the online gaming world and experience the very latest in technology and innovation.

The Department:

Our mission is to provide our customers with the best online betting experience and share the thrill of gaming with them. Data is at the very heart of our business and is vital in everything we do.

Our cross-functional Data team has a big and exciting challenge ahead. We are in the process of re-platforming our traditional, on-premises RDBMS environment to a new microservice architecture in the cloud. We’re making use of the diverse set of data technologies in Microsoft Azure to offer new services, reporting structures and real-time data pipeline while serving the day-to-day requirements of a rapidly growing, data-hungry organisation.

Purpose of the Role:

This is an excellent opportunity for an individual who is looking to gain new skills. We are committed to creating a culture of learning and regularly run proof of concepts, provide internal demos, manage workshops and attend external conferences. Our data team has a wide range of skills including development for highly transactional RDBMS systems, data warehousing, data science and cloud technologies and we are always working to raise everyone’s game.

Duties include, but not limited to:

Work as part of an agile Data Engineering Team
Development of greenfield projects in Azure
Develop and maintain on-premises RDBMS/DW systems
Create robust ETL services and real-time data pipelines
Build and maintain Continuous Integration and DevOps pipelines
Test-driven development and pair programming with colleagues

Essential Criteria:

C#, .Net, Visual Studio
Git, Azure DevOps
NoSQL development (CosmosDB)
Demonstrable understanding of MS SQL Server in a highly transactional environment
Demonstrable understanding of development in Microsoft Azure
Able to understand query plans and identify performance bottlenecks
Test/Business-Driven Development
Building Continuous Integration/Deployment pipelines
Communicate effectively with both technical and non-technical stakeholders

Desirable Criteria:

Implementing Data Storage and Processing solutions in Azure (ARM Templates, Storage Accounts, Data Lake Storage, SQL DB, Cosmos DB, EventHubs, Function Apps, Log Analytics, Data Factory, Databricks, Polybase)
Implementing Security, Disaster Recovery, High Availability, Auditing, Monitoring and Alerting solutions in Azure
Automating tasks in Azure using Powershell / CLI
Predicting costs and optimizing spending in Azure
Message Queues (RabbitMQ, Kafka)
Python

Person Specifications:

Resilience
Teamwork
Technical Knowledge
Communication skills
Stress Tolerance
Please note we will apply relevance to our Talent Management and Talent Development Programme as part of our recruitment process.
Shortlisted candidates may need to complete an assessment.
This position requires trust and honesty it has access to customers financial details - therefore a credit and criminal record check will be conducted. The qualifications identified herein are an inherent job requirement; therefore, a qualification verification check will be done. By applying for this role, and supplying the necessary details, you hereby grant us permission to apply for these checks. This will be done in a confidential manner, and solely for the purposes of verification.

To view all current vacancies, please visit our website, www.digioutsource.com

Should you not hear from us within 2 weeks, please deem your application as unsuccessful.

The perfect place to work, play and grow!",3.9,"Digital Outsource Services
3.9",Cape Town,-1,1001 to 5000 Employees,1997,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
Data Engineer,-1,"At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes

Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.

Key Responsibilities

Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.

Key Traits

Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern

Position Requirements

2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.

Where will you work? This role will be based out of Durbanville, South Africa.",3.1,"Aculocity, LLC
3.1",Durbanville,-1,1 to 50 Employees,2006,Company - Private,IT Services,Information Technology,$1 to $5 million (USD),-1
Data Engineer,-1,"ENVIRONMENT:

A rapidly growing E-Commerce Platform seeks a highly talented Data Engineer to make an invaluable contribution to data democratisation and literacy vision by making accessible and easy-to-use data products and tools. You will require a Comp-Sci Degree or 3 years’ relevant industry experience, MySQL, PostgreSQL, Java, Python, in-depth understanding of OLAP, Data Marts, Star Scheme, Snowflake, be familiar with Jenkins, Travis, Circle CI, Docker, Kubernetes, experience with Kafka, Pub/Sub, Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks & significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing & Data Lake design and implementation and Lambda/Kappa architectures.

DUTIES:

Design, develop, test and maintain data architecture.

Prepare data for descriptive, predictive and prescriptive modelling.

Automate repetitive tasks and manual processes related with the data usage.

Optimize data delivery.

Design, develop and test large stream data pipelines to ingest, aggregate, clean, and distribute data models ready for analysis.

Ensure the highest standard in data integrity.

Leverage best practices in continuous integration and delivery.

Collaborate with other engineers, ML experts, analysts, and stakeholders to produce the most efficient and valuable solutions.

Implement features, technology, and processes that move us towards industry best practices, improving on scalability, efficiency, reliability, and security.

Operations and ownership of systems in production, responding to incidents.

REQUIREMENTS:

Qualifications –

Comp-Sci Degree or 3 years relevant industry experience.

Experience/Skills –

Open source relational database systems e.g. MySQL, PostgreSQL, etc.

Significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing, and Data Lake design and implementation and Lambda/Kappa architectures.

A thorough understanding of database and data warehousing principles e.g. OLAP, Data Marts, Star Schema, Snowflake, etc.

Java and Python.

Familiar with CI/CD tools such as Jenkins, Travis, Circle CI, etc.

Experience with Kafka, Pub/Sub, or other event-based systems.

Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks, etc.

Working in cloud environments and with containerisation frameworks, tools and platforms e.g. Docker, Kubernetes, GKE, etc.

A deep understanding of data pipelining, streaming, and Big Data technologies, methods, patterns, and techniques.

Troubleshooting complex database operations and performance issues.

Automating tasks using Shell Scripting or writing small applications.

ATTRIBUTES:

Works well with people and is passionate about helping people be their best.

A team player, an active listener, mentor, and able to communicate well.

Shows solid reasoning and decision making, with the ability to work under pressure.

Is passionate about technology, systems and data.

Is curious, always learning, and keeping up to date with the industry.

While we would really like to respond to every application, should you not be contacted for this position within 10 working days please consider your application unsuccessful.

COMMENTS:

When applying for jobs, ensure that you have the minimum job requirements. Only SA Citizens will be considered for this role. If you are not in the mentioned location of any of the jobs, please note your relocation plans in all applications for jobs and correspondence.",-1,Datafin IT Recruitment,Cape Town,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Cartrack is looking for passionate data science and engineering candidates that can join a growing team that is responsible for the intelligence and efficiency solution provision to over a million subscribers, many of whom are large fleets. We are in the midst of creating revolutionary platforms that will change the way that people interact with their vehicles.

You will have the opportunity to work with the very brightest global subject matter experts that are transforming the automotive industry across Fleet Management, Asset Management and Insurance Telematics solutions.

Get to know the role:

The role of a data engineer is a supporting one, but it is also an extremely vital one. As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements. We want to see candidates with mechanical tendencies and a desire to know how things work and to improve them.

The day-to-day activities:

Design, construct, install, test and maintain data management systems.
Build high-performance algorithms, predictive models, and prototypes.
Ensure that all systems meet the business/company requirements as well as industry practices.
Integrate up-and-coming data management and software engineering technologies into existing data structures.
Develop set processes for data mining, data modeling, and data production.
Create custom software components and analytics applications.
Research new uses for existing data.
Employ an array of technological languages and tools to connect systems together.
Install/update disaster recovery procedures.
Recommend different ways to constantly improve data reliability and quality.
Work on and maintain Data pipelines.

Requirements Essential:

At least 5 years’ proven experience as a Data Engineer, DevOps Engineer, Software Developer, or similar.
Proficient in Linux/Unix and shell scripting as well as in functional programming languages.
Expertise in setting up and explored with technologies such as Hadoop and Spark.
Bachelor’s degree in computer science, software/computer engineering, applied mathematics, or physics.",3.3,"Cartrack
3.3",Johannesburg,-1,501 to 1000 Employees,2004,Company - Private,Security Services,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Data Engineer,-1,"Data Engineers build and support data pipelines and datamarts built off those pipelines. Both must be scalable, repeatable and secure. The Data Engineer helps to facilitate gathering data from a variety of different sources, in the correct format, assuring that it conforms to data quality standards and assuring that downstream users can get to that data timeously. This role functions as a core member of an agile team. These professionals are responsible for the infrastructure that provides insights from raw data, handling and integrating diverse sources of data seamlessly. They enable solutions, by handling large volumes of data in batch and real-time by leveraging emerging technologies from both the big data and cloud spaces. Additional responsibilities include developing proof of concepts and implements complex big data solutions with a focus on collecting, parsing, managing, analysing and visualising large datasets. They know how to apply technologies to solve the problems of working with large volumes of data in diverse formats to deliver innovative solutions. Data Engineering is a technical job that requires substantial expertise in a broad range of software development and programming fields. These professionals have a knowledge of data analysis, end user requirements and business requirements analysis to develop a clear understanding of the business need and to incorporate these needs into a technical solution. They have a solid understanding of physical database design and the systems development lifecycle. This role must work well in a team environment.

Job Objectives

Work Complexity: * Architects Data analytics framework. * Translates complex functional and technical requirements into detailed architecture, design, and high performing software. * Leads Data and batch/real-time analytical solutions leveraging transformational technologies. * Works on multiple projects as a technical lead driving user story analysis and elaboration, design and development of software applications, testing, and builds automation tools.

Main Job Objectives: 1. Development and Operations 2. Database Development and Operations 3. Policies, Standards and Procedures 4. Communications 5. Business Continuity & Disaster Recovery 6. Research and Evaluation 7. Coaching/ Mentoring

Qualifications

Essential: 4 years Bachelors degree in computer science, computer engineering, or equivalent work experience AWS Certification at least to associate level

Experience

Essential:

5+ years Data engineering or software engineering

3-5 years demonstrated experience leading teams of engineers

2+ years Big Data experience

5+ years experience with Extract Transform and Load (ETL) processes

2+ years Could AWS experience

At least 2 years demonstrated experience with agile or other rapid application development methods - Agile exposure, Kanban or Scrum

5 years demonstrated experience with object oriented design, coding and testing patterns as well as experience in engineering (commercial or open source) software platforms and large scale data infrastructures.

Desirable:

5+ years Retail Operations experience

Knowledge and Skills

Essential: *Creating data feeds from on-premise to AWS Cloud (2 years) *Support data feeds in production on break fix basis (2 years) *Creating data marts using Talend or similar ETL development tool (4 years) *Manipulating data using python and pyspark (2 years) *Processing data using the Hadoop paradigm particularly using EMR, AWSs distribution of Hadoop (2 years) *Devop for Big Data and Business Intelligence including automated testing and deployment (2 years) * Extensive knowledge in different programming or scripting languages * Expert knowledge of data modeling and understanding of different data structures and their benefits and limitations under particular use cases.

Further technical skills required: * Capability to architect highly scalable distributed systems, using different open source tools. * Big Data batch and streaming tools * Talend (1 year) * AWS: EMR, EC2, S3 (1 year) * Python (1 year) * PySpark or Spark (1 year) - Desirable * Business Intelligence Data modelling (3 years) * SQL (3 years)",-1,Datonomy Solutions,Brackenfell,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We are assisting one of our clients that is based in Pretoria to fill a role of a Data Engineer

This is a 12 month contract role

Objective of this Scope of Work

The Data Engineer will drive improvement of the data management maturity levels and provide the necessary technical support within the company to support reliable and effective decision-making, appropriate usage and protection thereof.

Scope of Services Definition

The scope will include but will not be limited to:

ï†· To develop, construct, test and maintain architectures.

ï†· To ensure architectures will support the requirements of business.

ï†· To discover opportunities for data acquisition and sharing.

ï†· To develop data set processes for data modelling, mining and production.

ï†· To employ a variety of languages and tools to marry systems together.

ï†· To recommend way to improve data reliability, efficiency and quality.

ï†· To prepare data for use in predictive and prescriptive modelling.

ï†· To conduct research to answer industry and business questions.

ï†· To leverage volumes of data from internal and external to answer business questions.

ï†· To develop and manage stakeholder relations effectively to promote data management across the organisation and support reliable decision making and appropriate data usage.

ï†· To participate and provide technical support in cross organisational activities relating to any of the above mentioned data management activities.

ï†· To provide regular progress reports as per stakeholder requirements and present data management updates in various forums as required.

Minimum qualification Required:

ï†· A minimum of a Bachelors degree in Computer Science or Information Management OR equivalent;

ï†· A minimum of five to eight years experience in a data management environment",-1,HR Genie,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Our client based in the Northern Suburbs, is currently looking for a Data Engineer to join their team.

Responsibilities
Our client is a dynamic IT company that delivers value-driven IT solutions to the group. Our work lives revolve around our DNA. We take pride in our work, treat our colleagues, partners and our country with respect. We exercise collaborative decision-making and believe in having a balance in life. We do this all while having fun and enjoying what we do.

The primary focus of this position is to use technical skills to put software, systems and data together in a way that extracts meaningful insights from raw data. You will need to be helpful and supportive to your team and fellow developers. You join an energetic, focused and dynamic team.

Interact with clients to understand requirements and business problems/needs

Identify, analyse, visualise and understand supporting data to propose solid solutions

Create technical documentation for reference and reporting

Support existing solutions within GCP and Oracle

Doing standby on a rotating basis

Key Competencies and Qualifications

Matric

Tertiary qualification in IT

Preferred cloud experience in AWS/AZURE/GCP

At least 3 years of data warehouse ETL experience

Dimensional Modelling

Data analyses

Experience with data visualization and visualization tool(s)

Knowledge of the retail industry will be beneficial

Understanding and experience with version control SVN/GIT

Preferred – Korn shell scripting, Python/Java, SQL

Google Cloud Platform experience would be looked upon favourably

Having a broad understanding of different SDLC’s

Preferred agile experience

Strengths

The natural tendency to take ownership and responsibility

Strong problem solving, critical thinking, effective planning and organisational skills

Detail-oriented with excellent communication skills

You have a can-do attitude and positive outlook on life

Can cope under pressure

Curious and interested in analysing problems and possible solutions

Strong team player

Self-driven learner, passionate about new technology

Above all, be passionate about what you do

Should you wish to apply for the position, please apply directly via this job board, please ensure that you quote reference number 201620 subject heading or email body.

Please note that due to the high volume of CV's received; only shortlisted applicants will be contacted. Should you not receive communication from our offices within two weeks of submission please note that your application will not be considered for this position.

We will keep your CV on file and re-establish contact with you should opportunities in line with your expertise become available again.

Should you require any additional information give us a call on 021 012 5566.",-1,Surgo HR & Training,Cape Town,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We believe that our employees fuel our organization, essential to enable us to help our customers overcome their business challenges and achieve sustainable growth. As a result, we are committed to growing each individual and providing them with the challenges, feedback and support needed to achieve success in their career

If this sounds appealing, and like us, you get excited about data: its collection, storage, transformation or display, see if you’ve got what it takes to join our sought after DATA team.

Key Responsibilities And/or Outputs

You will represent IQbusiness at our customers, sometimes alone, and sometimes as part of an IQ team.

Providing a superior customer experience by building and maintaining relationships, working at customer offices, keeping data confidential
Design and develop – databases, SQL queries, stored procedures, reports, dashboards or integration solutions
Produce solutions for both real-time and batch environments
Test your work to ensure compliance
Solve problems, and do root cause analysis
Prioritize your workload
Assist in other areas relating to your true data function, such as data modeling, data and business analysts
Interact with a variety of individuals: senior, junior, technical and from business
Provide guidance to fellow colleagues, or even manage a team
Uphold the IQ values, which are to care, learn & share; innovate; deliver as well as to build, enhance and maintain relationships

Education

Matric pass
A tertiary qualification, preferably in an ICT relevant field
Appropriate Microsoft certifications are beneficial but not required

Requirements

3 - 6 years experience in the Data Engineering environments and technologies
Great communication skills
A passion for SQL, databases or reports
Can you write stored procedures, design complex queries and create views and triggers?
Are you able to work out the relationships in a data warehouse or the aggregation of a cube?
Do you extract and display useful information when you see patterns and trends in data?
Strong knowledge of the financial services industry, ideally in a consulting role
The use of data related software: databases, ETL and BI tools; report writing and analytical tools
We use a lot of Microsoft products. You may often be expected to use MS SQL Server, SSIS, SSRS, SSAS and Power BI to develop solutions
What other relevant software have you’ve used?
Ability to work in different project methodologies: Waterfall and/or Agile
Knowledge of full SDLC
Exposure to logical and physical data modeling

Equal Employment Opportunity

IQbusiness is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, citizenship, marital, domestic or civil partnership status, sexual orientation, or gender identity",3.7,"IQbusiness South Africa
3.7",Johannesburg,-1,1 to 50 Employees,-1,Company - Private,Consulting,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"We value a data engineer as someone who works behind the scenes to obtain, process and supply data via various methodologies and technologies, to various consumers, in ways and forms that makes sense and add value. This definition is very broad, as the field of data engineering is just as broad.

You may be the type of data engineer that develops API endpoints for the consumption of data by end users or even another data pipeline, or you may be the type of data engineer that develops highly distributed, high availability data processing pipelines in an effort to satisfy the need of the ever questioning data analysts and/or data scientists.

You have awesome knowledge about the following concepts
Data modelling
Relational data modelling in traditional relational database management systems. (Microsoft SQL Server, MySQL, PostgreSQL, etc)
Coercing unstructured and semi-structured data into a structured form.
Data pipelining knowledge - data extraction and transformation.
Data transformation knowledge for reporting and analytics purposes.
Knowledge of the MapReduce and related data processing paradigms would be a boon.
You have the following technical competencies
Writing SQL queries, that can relate, transform and aggregate data from many differing sources where natural keys may or may not exist.
Experience with writing data pipelines that move and transform data, for various uses.
Working knowledge of a general purpose programming language like Python would be a boost.
Working knowledge of columnar databases such as Google BigQuery, and SAP HANA would be a boost.
Working knowledge of highly distributed technologies such as Apache Hadoop or Apache Spark would be a boost.
Working knowledge of NoSQL technologies, such as Apache Solr would be a boost.
You have the following personal competencies
The ability to solve problems.
The ability to rotate around a problem, to see if solutions can be gained in different ways.
The ability to work in an ever changing, unstructured environment.
The ability to work as part of a team, with vastly differing skill sets and opinions.
The ability to contribute ideas to the quorum.
The ability to mentor and provide guidance for other team members.
A systems approach to thinking, as opposed to a siloed approach. The candidate needs to understand how their work affects the greater system.
The ability to work without supervision, and take accountability for the work they deliver.
The ability to liaise with a client, sifting through the fluff and extracting the actual requirements.
If this is you - apply now and we'll get in touch",-1,DotModus,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Data Engineer

Our client in the contact centre space is currently seeking a DATA ENGINEER that will work on the collecting, storing, processing, and analyzing of large datasets. The primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them. You will also be responsible for integrating them with the architecture used across the company.

Key Performance Areas:

Data reporting.
Implementing ETL processes.
Defining data retention policies.
Management of Customer Lead data.
Provision of data for advanced analytics.
Maintenance of internal client scorecards.
Assist team in resolving data-related support queries.
Optimize existing data processes through automation.
Assist with all data-related reporting and documentation.
Maintenance and optimisation of the Analytics database.
Provide technical support to and supervision of junior data administrators.
Continuous upskilling on new technologies, frameworks and market trends.
Monitoring performance and advising any necessary infrastructure changes.
Identifying, selecting and integrating any Big Data tools and frameworks required to provide real-time analytics.

Educational Requirements

IT related Degree or Diploma is a pre-requisite

Required Skills/Experience

ETL tools: Advanced SSIS
BI/Reporting : Qlikview/Power BI/ SSRS or SSAS
Programming languages: JAVA, C# , Python, SAS or R
Experience with NoSQL databases and/or campaign management tools will be advantageous.
Minimum 3 years’ applicable work experience in SQL, relational databases and data manipulation.
Experience in big data platforms (eg. Hadoop) or processing frameworks (eg. MapReduce/Spark) and querying tools (eg. Pig, Hive and Impala) will be highly beneficial.

Preferred Skills

Organizational skills
Experience in Attentional to detail.
Accountability is critical for this role.
Ability to work under pressure and meet deadlines.
Solid understanding of database design principles.
Should you not receive a response in 2 weeks please consider your application unsuccessful",-1,Rubik's Cubed Consulting,Durban,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"This well known company is looking for a Data Engineer. will be based in Rivonia
The ideal candidate will have strong experience in the following:
Data cleaning
SQL Export
Big data Sets

BSc Degree in Maths and Stats will be required
a min of 3 years experience.
Stable track record is required.

Send your Cv to marinda@prrrecruitment.co.za",-1,PRR Recruitment Services,Johannesburg,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Description

Position at Aculocity, LLC

At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes
Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.
Key Responsibilities
Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.
Key Traits
Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern
Position Requirements
2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.
Where will you work? This role will be based out of Durbanville, South Africa.",-1,GVW,Durbanville,-1,Unknown,-1,Unknown,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Information Technology, Gauteng JHB - Northern Suburbs

Market related - Market related Annually

An IT Consultancy Business based in Johannesburg is currently looking for a Business Intelligence Consultant / Data Engineering Consultant.

Requirements:

Extensive experience in data engineering
Experience in Business Intelligence, data and Power BI
Extensive experience in data governance and the Popi act
Ability to assess and make recommendations on data within the Popi act
Good understanding of T-SQL and query optimization, developing ETL strategies.
Good understanding with SQL Server 2008/2012, SSIS, SSRS and SSAS
Use SSIS to create ETL packages to validate, extract, transform, and load data into the data warehouse and data marts.
Deploy and configured the reports in the Report Server (SSRS).
Excellent experience in Tabular Modelling , PowerView, Qlikvie,w, and Power BI
Maintain ETL
Qlikview model
Create Drill-through, Drill-down, and Cross Tab Reports and Sub-Report using Report Definition Language (RDL).
Generate periodic reports based on the statistical analysis of the data using SQL Server Reporting Services (SSRS)
Advise and provide written technical documentation and recommendations

The information displayed above is not limited to advertisements. Please contact Thato for further information.

Please consider your application as unsuccessful if you have not received a response within 14 days of submitting your application. However, please keep a lookout on our website, www.bedifferent.co.za, for available positions that you may be suited for

Ad Visible Until: 29 October 2020
Ref: JHB005346/NL

Vacancy Type: Permanent",2.9,"Be Different Recruitment
2.9",Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Cloud Support Engineer (Big Data),-1,"ABOUT US

Amazon Web Services is the market leader and technology forerunner in the Cloud business. As a member of the AWS Support team you will be at the forefront of this transformational technology, assisting a global list of companies and developers that are taking advantage of a growing set of services and features to run their mission-critical applications. As a Cloud Support Engineer, you will act as the Cloud Ambassador across all the cloud products, arming our customers with required tools & tactics to get the most out of their Product and Support investment.

Would you like to use the latest cloud computing technologies? Do you have an interest in helping customers understand application architectures and integration approaches? Are you familiar with best practices for applications, servers and networks? Do you want to be part of a customer facing technology team helping to ensure the success of Amazon Web Services (AWS) as a leading technology organization?

If you fit the description, you might be the person we are looking for! We are a group of smart people, passionate about cloud computing, and believe that world class support is critical to customer success.

WHAT CAN YOU EXPECT FROM A LIFE AT AWS?

Every day will bring new and exciting challenges on the job while you:

· Learn and use groundbreaking technologies.
· Apply advanced troubleshooting techniques to provide unique solutions to our customers' individual needs.
· Interact with leading engineers around the world.
· Partner with Amazon Web Services teams to help reproduce and resolve customer issues.
· Leverage your extensive customer support experience to provide feedback to internal AWS teams on how to improve our services.
· Drive customer communication during critical events.
· Drive projects that improve support-related processes and our customers technical support experience.
· Write tutorials, how-to videos, and other technical articles for the developer community.
· Work on critical, highly complex customer problems that may span multiple AWS services.

WHY AWS SUPPORT?

· First and foremost this is a customer support role in The Cloud.
· On a typical day, a Support Engineer will be primarily responsible for solving customers cases through a variety of customer contact channels which include telephone, email, and web/live chat. You will apply advanced troubleshooting techniques to provide tailored solutions for our customers and drive customer interactions by thoughtfully working with customers to dive deep into the root cause of an issue.
· Apart from working on a broad spectrum of technical issues, an AWS Support Engineer may also coach/mentor new hires, develop & present training, partner with development teams on complex issues or contact deflection initiatives, participate in new hiring, write tools/script to help the team, or work with leadership on process improvement and strategic initiatives.
· Career development: We promote advancement opportunities across the organization to help you meet your career goals.
· Training: We have training programs to help you develop the skills required to be successful in your role.
· We hire smart people who are keen to build a career with AWS, so we are more interested in the areas that you do know instead of those you havent been exposed to yet.
· Support engineers interested in travel have presented training or participated in focused summits across our sites or at specific AWS events.
· As we operate on a follow-the-sun model, with Premium Support sites located globally, there is no after hours on-call or mandated overtime in this role.
· https://www.youtube.com/watch?v=GC3bWcFFZTo&t=24s



Basic Qualifications

The Big Data role supports our services that leverage data and produce business insights, which may include using Machine Learning/Artificial Intelligence (ML/AI). Helping our customers use and integrate Big Data services in what is arguably our industrys most exciting space. The portfolio of services covers EMR (Hadoop), DynamoDB (NoSQL), MangoDB, and Apache Cassandra.

· Advanced experience in Apache Hadoop, Apache Spark, Apache Hive, and Presto
· Advanced experience in DynamoDB or NoSQL technologies like MongoDB or Cassandra
· Advanced experience with System Administration with Linux (RHEL/CentOS) including Microsoft Active Directory, and LDAP integration.
· Experience with troubleshooting Kerberos Authentication problems.
· Experience with Network troubleshooting.
· Basic understanding of Machine Learning and statistics
· Experience with Java and Python and shell scripting
· Bachelors degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position



Preferred Qualifications

· Expert experience in the Hadoop Ecosystem including Apache Spark and Presto
· Expert experience in NoSQL
· Expert experience with blockchain technologies like Etherium Expert experience in data Data Lake architecture and administration
· Experience managing full application stacks from the OS up through custom applications
· Prior work experience with AWS - any or all of EC2, VPC, S3, RDS, EMR, Glue, SageMaker
· Excellent knowledge of Hadoop architecture, administration and support
· Expert understanding of distributed computing principles and their application in the cloud
· Good understanding of distributed computing environments Lead technical discussions on big data systems architecture and design
· Strong analysis and troubleshooting skills and experience
· AWS Certified Solutions Architect
· AWS certified Big Data Specialty
· Masters degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity and Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Response Center Engineer,-1,"Job Title
Response Center Engineer
Job Description


Philips is a world leading health technology company with a vision to make life better for people worldwide through meaningful innovation. Making good on this promise depends on our passionate, inspirational, collaborative and diverse team. We have over 80,000+ brilliant people around the world but are always looking for more. Like-minded, motivated, focused minds to join us in creating a healthier, more connected society while transforming themselves personally and professionally.

As a CCC Coordinator - Response Center Engineer you will have the opportunity to process customer calls and be responsible for screening and diagnosing professionally Healthcare equipment to support customers and colleagues remotely with solving technical issues and ensuring maximum customer satisfaction

You are responsible for:
Diagnose healthcare equipment to the quality standards set by Philips Healthcare (PH) remotely by interviewing customers or colleagues by telephone or by remotely logging in to the system
Advise Customer Care Center Coordinators and District Operations Managers and / or Team Leads about the best follow-up w.r.t. technical state of the diagnosed healthcare equipment
Advise the Customer Care Center Coordinators or Field Services Engineers about required spare parts and resources
Responsible for planning engineers related to Modality responsibility.
Responsible for coordination between CCC, CUSTOMER, Spare parts AND Engineer.
Responsible to drive Remote and FTR KPI’s to targets respectively 40% and 85%.
Will require minimal field work to keep abreast of technical capabilities.
Take calls from customers and make sure they are processed in the CCC ERP on timely manner including all relevant data
Support Field Services Engineers in the field with technical knowledge
Escalate technical issues to the Technical Support Specialist
Escalate technical issues to Business Unit support after consultation of the Technical Support Specialist
Monitor critical functions of the equipment’s in the IB and environmental conditions including RSN and True reachability.
Lead the planning and implementation of FSN’s and FCO’s accelerating remote implementation where applicable.
Submit timely and accurate service data, job sheets, reports, expense claims, radiation film badges, field problem reports and other paperwork as assigned
Keep abreast of new technologies likely to affect PH range of products
Use company property with care to ensure optimal results with minimal operational costs
Be a professional representative for PH with respect to customer problems, ensuring personal acceptability by the customer in behavior in accordance with PH policy and targets
Conform to PH safety standards including health and safety regulations and in the event of hazards or accidents to take immediate control of the situation and involve the Operations Manager and / or the responsible person to handle properly confidential issues according Philips standards and to act according General Business Principals
Follow all quality standards within the frame of valid PH business policies
Follow the company quality regulations (ISO 9001; PQA; TQM) and internal directives and procedures
You are a part of the dynamic South Africa Customer Care Centre Team .You will be reporting to the Customer Care Center Manager.

Requires a pleasant, assertive individual you can work very well in a team setting, a dynamic environment that requires flexibility and creativeness to achieve goals.

To succeed in this role, you should have the following skills and experience:
Degree level education or equivalent
Experience in maintenance and troubleshooting of technical complex systems
Fluent in English, verbal and written in addition to local language
In return, we offer you the unique combination of a critical and challenging role and a creative and empowering office environment. You will be actively encouraged to make improvements, establish best in class service and have a direct impact on the success of Philips on a daily basis.

Employment Equity

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply. Only apply for this role if you are a South African Citizen by birth or Naturalization prior to the 27 April 1994.

Why should you join Philips?

Working at Philips is more than a job. It’s a calling to create a healthier society through meaningful work, focused on improving 3 billion lives a year by delivering innovative solutions across the health continuum. Our people experience a variety of unexpected moments when their lives and careers come together in meaningful ways. Learn more by watching this video.

To find out more about what it’s like working for Philips at a personal level, visit the Working at Philips page on our career website, where you can read stories from our employee blog. Once there, you can also learn about our recruitment process, or find answers to some of the frequently asked questions.

Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.9,"Philips
3.9",Johannesburg,-1,10000+ Employees,1891,Company - Public,Health Care Services & Hospitals,Health Care,$10 to $25 million (USD),-1
Software Development Engineer - EC2 Placement,-1,"Build the systems that optimize how EC2 matches requests for Instances with the underlying compute capacity. EC2 Placement is seeking talented engineers to build the online and offline optimization systems for compute workload scheduling, and the customer capabilities to better manage those workloads. Amazon EC2 provides on-demand scalable compute capacity, and powers some of the largest services in the world. You will collaborate with a top-tier community of engineers to build systems to improve how customers are able to access EC2 compute resources.

The successful candidate will have strong software engineering experience, with a passion for thinking about, building and testing distributed systems. You have an interest in how Machine Learning and other optimization techniques can be applied to large-scale problems. You have demonstrated experience working with a team to design, build and operate large-scale systems. With strong engineering fundamentals, an analytical and data-driven approach to your work, and strong communication skills, you have the ability to collaborate well to deliver results. We move fast and work together on small teams to solve big problems.

If this opportunity sounds interesting, we would love to talk to you more about our work and the vibrant culture at AWS in Cape Town.

Basic Qualifications

· Degree in Computer Science or related field, or equivalent working experience
· 3+ years of industry experience in a software development environment
· Strong Computer Science fundamentals, including data structures, object-oriented design, algorithm design, problem solving, and complexity analysis.
· Proficiency in at least one modern programming language, such as Java, C#, Python, Scala, Kotlin

Preferred Qualifications

One or more of the following help you stand out:
· Demonstrated results designing, building and operating high-performance distributed systems in large-scale Linux environments
· Role model in writing high-quality, maintainable and secure code, mentoring others, and helping teams sharpen their development processes
· Ability to work effectively across teams to deliver results, with strong verbal and written communication skills
· Experience working with machine learning systems

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer - PBB IT,-1,"Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose


This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes
Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems
Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions
Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.

Research and best practices
Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development
Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.
Preferred Qualification and Experience
Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Aws Data Platform Engineer,-1,"Aws Data Platform Engineer

Posting Country:

South Africa

Date Posted:

15-Oct-2020

Full Time / Part Time:

Full Time

Contract Type:

Permanent

Joining Vodacom is more than a job, what we do matters. We don’t just carry minutes, texts and data – we carry people’s lives. And that’s a huge responsibility. If you think for a minute about the people you rely on…the likelihood is they rely on us.

Customers are at the heart of everything we do and we want to make a difference to the lives of our customers, and the communities in which we live and work. We support our people to give something back to the causes that mean the most to them through helping them give time and money to the charities they love.

And what’s it like to work here? We have created an environment where you can look forward to coming to work and are empowered to be at your best. We offer flexibility in how you work that helps you do your job in a way that suits you, opportunities to help you grow and progress throughout your career and a choice of benefits to suit your lifestyle.

Role Purpose
The H Band AWS Data Platform Engineer position is based within the Technology Business Unit.

The AWS Data Platform Engineer will be responsible for all Database services such as RDS, DynamoDB, etc. Should be able to migrate any databases from anywhere to AWS using any third-party tools or AWS database migration tool. Should also have understanding or expertise in creating data warehouses and data lake solutions on AWS.
Your responsibilities will include:
Apply practical knowledge of relational database design and usage with customers
Perform workload analysis and undertake performance tuning, as well as performance benchmarking in customer environments.
To develop state of the art solutions which are technically sound.
To provide a high-quality service to the Enterprise Cloud Services clients i.t.o. consultancy, solutions and delivery.
Commitment to team success and positive team dynamics including mentoring of other team members.
Passion for growing and applying technical skills in service to customers.
Be a trusted infrastructure advisor by providing objective, practical and relevant ideas, insights and advice.
Work collaboratively with consulting partners and technology teams to ensure high quality of solution delivery.
Encourage best practice and knowledge sharing with partners and cross-functional groups
Manage the overall database design and delivery of solutions.
Ability to make recommendations as they pertain to improvements in support/development initiatives and facilitate implementation with partners and cross-functional groups within the Business.
Participate in high level database solution definition and design during the implementation phase with the goal of providing reliable, stable and operationally sound applications that meet the Business requirements.
Ability to understand and translate business requirements into technical specifications
The ideal candidate will have:
A minimum of 3 years of industry related experience of which 1 year must be within a complex hosting environment.
Certifications in Database design, system architecture or cloud technologies.
Demonstrate knowledge of database systems internals including storage layouts and distributed databases/MPP architectures
Advanced SQL coding, tuning and query optimization.
Experience designing and leading database performance benchmarks.
Good knowledge of the different AWS services
Knowledge of cloud networking architecture, cloud operations, security, automation and orchestration.
Knowledge of database internals as it relates to query and system performance and tuning.
Understanding of overall system architecture, scalability, reliability, and performance in a database environment.
Excellent teamwork, time-management and organizational skills.
Perform other duties as deemed necessary and assigned by the customer and management
Strong interpersonal skills and problem-solving abilities.
Excellent documentation, communication and interpersonal skills.
Excellent analytical and problem-solving abilities.
Closing date for applications: Monday, 13 April 2020

The base location for this role is Vodacom World, Midrand

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply.
Vodacom is committed to an organisational culture that recognises, appreciates and values diversity & inclusion.

Commitment from Vodacom

Vodacom is committed to attracting, developing and retaining the very best people by offering a flexible, motivating and inclusive workplace in which talent is truly recognized, developed and rewarded. We believe that diversity plays an important role in the success of our business and we are committed to creating an inclusive work environment which respects, values, celebrates and makes the most of people’s individual differences - we are not only multinational but multicultural too. At Vodacom you will have access to our excellent flexible benefits programme that you would expect from any global company.",3.9,"Vodafone
3.9",Midrand,-1,10000+ Employees,1982,Company - Public,"Cable, Internet & Telephone Providers",Telecommunications,$10+ billion (USD),-1
Data Engineer Azure Data Factory,-1,"Enthuzex is looking for a motivated Lead Data Engineer to contribute towards the success of our Data and Analytics Technology initiatives. This is a hands-on technical role and this person will be responsible for the development and build of scalable solutions as it relates to the architecture strategies, data standards, digital data management, data integration, tools, and technology. The right candidate will play a deep dive hands-on critical development role in the digital transformation and in shaping how we acquire, ingest, transform and deliver data through the digital consumer channels.

Responsibilities:

Architect, design, develop and engineering end-to-end data pipelines across multiple data sources and systems of record.
Ensure data quality, integrity, security and completeness throughout the data lifecycle
Develop, design data models, data structures and ETL jobs for data acquisition and manipulation purposes
Develop deep understanding of the data sources, implement data standards, maintain data quality and master data management
Developing data services and API
Work closely with the cloud service providers to ensure completeness and alignment with the service offerings
Manage and maintain cloud based data and analytics platform
Deep understanding of the cloud offerings and engage in quick proof of concepts and proof of value in prototyping data and analytics solutions and derive viability
Ability to interact with the business stakeholders to understand requirements and translating into technology solutions

Expirience:

Experience in Cloud platform AWS or Azure eco-system. (Azure preferred)
Data Engineering/Development experience with SQL (Oracle, SQL Server, MySQL)
Strong development background creating pipelines and complex data transformations and manipulations using one of the languages Python, Java, R, or Scala with Databricks/Spark
Experience in NoSQL Databases and Big data technologies including Hadoop
Experience with API / RESTful data services
Worked on real-time data capture, processing and storing using technologies like Azure Event Hubs and Analytics
Experience working with different data storage options including AWS S3, Azure BLOB storage etc.
Understanding of different data formats including Parquet, Avro, CSV, ORC etc.
Prior experience with MPP databases and maintain large amount of data processing
Experience with Azure Data Factory and Azure Data Catalog is a big plus and mandatory
Experience with Microsoft/Azure ETL solutions and business Intelligence technologies is a big and mandatory
Past working experience on a fast paced and agile environment
Perform ongoing monitoring, automation and refinement of data engineering solutions
Experience in leading high visibility transformation projects that interacts with multiple business lines
Build and meet project timelines and manage delivery commitments with proper communication to management

Qualifications

Bachelor’s degree with 4+ years of relevant experience
Willingness to learn new technologies and thrive in an extremely fast paced environment
Team player and easy to work with.

Applicants must demonstrate their ability to master new enterprise level technologies. Successful applicants will exemplify Enthuzex ethical principles of uncompromising integrity, respect for others, and accountability for decisions

send cv's info@enthuzex.co.za",-1,Enthuzex,Leslie,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Scientist,-1,"The world is changing.

We all want something different.

At Luno, we see you as an individual.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the world, and to do so, we need the best team on board for our mission.

A bit about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 3 million customers across 40 countries.
We are Series B funded, backed by Balderton Capital and the Naspers Group.
Our platform has processed over 8 billion dollars since we've launched
We're proud to be one of the world's most international cryptocurrency teams from 26 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
The role in a nutshell:

Identifying opportunities in the business that could benefit most from cognitive applications, as well as building and enhancing organisational capabilities for deriving value from multiple data sources using data science.

What we'd like you to have:
Bachelor's degree or higher in the natural sciences or technical fields such as Mathematics, Statistics, Computer Science, Engineering or Economics
Enthusiasm to work in the cryptocurrencies space
Advanced SQL skills
Solid understanding of exploratory data analysis, predictive analytics, and optimisation using Python, R, Matlab, RapidMiner, KNIME or other data science-oriented platforms
Proficiency in the use of data science and machine learning domain-specific languages such as ""Caret"" and the ""Tidyverse"" suite of tools in R, or ""Pandas"" in Python
Strong interpersonal and communication skills
Communicating data insights using storytelling narratives
Ability to work independently, as well as within and across teams
Ability to successfully complete projects with large and/or incomplete data sets
More about what you'll be doing:
Optimising product performance by tracking and analysing customer behaviour on web and app, in collaboration with software engineers and product designers
Providing the business with reports and dashboards, on key performance metrics
Developing metrics to accurately assess the health of our Exchange platform
Comparative data-driven analysis of our Exchange against alternative platforms
Formulating business requirements into analytical objectives
Designing and running experiments to test hypotheses
Hacking through complex business problems using advanced data analysis to provide insights and recommendations
Building, maintaining, and optimising decisioning systems using advanced statistical and predictive modelling techniques
What will set you apart:
An advanced degree in Mathematics, Statistics, Computer Science or related field
At least 3 years' experience working in a similar role
A basic understanding of trading in financial markets
Experience working with a data analytics and visualisation platform such as Tableau, Cognos, QlikView, or Looker
Familiarity with using Google Analytics to understand customer behaviour
Solid knowledge of statistical and machine learning techniques
Familiarity with modern distributed data storage and processing systems such as Amazon Redshift, Big Query, Snowflake, Databricks and Apache Spark
You can gather and synthesise facts, theories, trends, patterns, inferences, and key issues in complex and variable situations
Ability to diagnose problems using formal problem-solving tools and techniques from multiple angles to generate multiple possible solutions
A sense of anticipating long-term problem areas and associated risk levels with objective rationale
Remote Life at Luno

If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
You'll be able to continuously upskill yourself with access to free online learning via MyAcademy, an international teaching marketplace with over 100000 courses from Harvard and other leading providers + share knowledge with your peers.
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity and paternity leave, and you can even take paw-ternity leave for your furry friend.
Annual Inspiration Day! Make time for that pottery course or spa day you've always wanted to do.
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"EY is a global leader in
assurance, tax, transaction and advisory services. Technology is at the heart
of what we do and deliver at EY. Technology solutions are integrated in the
client services we deliver and are key to our innovation as an organization.

Fueled by
strategic investment in technology and innovation, Client Technology seeks to
drive growth opportunities and solve complex business problems for our clients
through building a robust platform for business and powerful product engine
that are vital to innovation at scale. As part of Client Technology, you’ll
work with technologists and business experts, blending EY’s deep industry
knowledge and innovative ideas with our platforms, capabilities, and technical
expertise. As a catalyst for change and growth, you’ll be at the forefront of
integrating emerging technologies from AI to Data Analytics into every corner
of what we do at EY. That means more growth for you, exciting learning
opportunities, career choices, and the chance to make a real impact.

The selected
candidate
Develops
large and complex data architecture, composed of models, policies, rules or
standards that govern which data is collected and how it is stored, arranged,
integrated and put to use in data systems, including the design, build and
management of data infrastructure to address business requirements
Creates
sound use case driven roadmaps, depicting data architecture as-is and to-be
capabilities with the business by engaging with multidisciplinary teams, and by
identifying, managing and mitigating risk
Develops
relationships across the business to understand data requirements, applies deep
technical knowledge of data management to solve business problems in areas
where solutions may not currently exist, necessitating new solutions/ways of
working/technologies and proactively articulating these to the business
Review,
identify the latest emerging technologies, augmenting by services from the
leading cloud providers to solution and recommend the best next generation data
platform value driven approach for our clients
Your Key Responsibilities Include
Create
and maintain conceptual, logical and physical database models
Document
functional requirements and system specifications into the data architecture
and detailed design specifications for current and proposed designs
Document
and adhere to development standards and best practices in database designs
Maintain
highly effective and consistent communication within the team, peers, and the
leadership team
Reverse
engineer SQL code and modify it to solve problems/issues
Contribute
to the definition and implementation of data governance practices
Design
both data structures and data integration practices
Work
closely with the infrastructure teams to create a physical environment to
support data services
Evaluate
new and existing (internal and external) technologies and services in support
of data services and data analytics objectives
Skills And Attributes For Success
Understanding
of business process reengineering and business modeling concepts, business
systems development and analysis
Hands-on
experience in designing and implementing hybrid cloud and on-prem solutions
Experience
working with the latest versions of SQL Server
Experience
applying SAFe/Scrum/Kanban methodologies
Ability
to exercise judgment in solving technical, operational, and organizational
challenges
Expert
programming, performance tuning and troubleshooting skills, using the latest
popular programming languages for example python
Demonstrate
proactive approach to identifying issues and presenting solutions and options,
and where appropriate, leading to resolution
Minimum Qualifications
5+ years
demonstratable work experience as a Data Architect using data modeling tools
2-3 years
SQL coding experience on large projects
Must
possess expert SQL programming, performance tuning and troubleshooting skills
Create
database objects and SQL scripts
Understand
and developed data pipelines
Know how
to deformalize data for data science models
Experience
in python, spark and notebooks
Experience
designing data warehousing solutions
Experience
designing next generation data platforms utilising cloud services
In-depth
understanding of database structure principles
Seamlessly
able to translate business requirements to technology requirements
What We Look For
Strong
analytical skills and problem-solving ability
A
self-starter, independent-thinker, curious and creative person with ambition
and passion
Excellent
inter-personal, communication, collaboration, and presentation skills
Customer
focused
Excellent
time management skills
Positive
and constructive minded
Takes
responsibility for continuous self-learning
Takes the
lead and makes decisions in critical times and tough circumstances
Attention
to detail
High
levels of integrity and honesty
Curious
about new emerging technology
About EY
As a global leader in assurance, tax, transaction and consulting
services, we’re using the finance products, expertise and systems we’ve
developed to build a better working world. That starts with a culture that
believes in giving you the training, opportunities and creative freedom to make
things better. Whenever you join, however long you stay, the exceptional EY
experience lasts a lifetime.",3.8,"EY
3.8",Johannesburg,-1,10000+ Employees,1989,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Architect - Principal,-1,"We are looking for Principle Data Architect to join our Engineering team in Cape Town.

The world is changing.
We all want something different.
At Luno, we see you as individuals.

Together, we are upgrading the world of work to unleash the potential within and empower you to become the best possible version of yourself.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the financial landscape, and to do so, well we need the best team on board for our mission. In short, to achieve our goals, we need rockstars. As simple as that.

A little about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 5 million customers across 40 countries.
We're part of the Digital Currency Group, a group of companies driving progress in the cryptocurrency and blockchain space that includes Grayscale, Genesis, Coindesk and Foundry Services
Our platform has processed over $8 billion to date
We're proud to be one of the world's most international cryptocurrency teams from 43 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
How we work


Our engineering team (currently ~100 engineers) is split into organisations which we call Fleets. Each Fleet focuses on a core customer journey (onboarding, security, payments, support, new business, growth and marketing etc.). Each of these fleets contains multiple smaller teams called Pods, each of which focuses on a specific aspect of the product.

Pods will include a product owner, product designer, back-end engineers, Android, iOS and Web developers, who each bring a unique perspective to the problem you are all contributing towards.

We're agile, use scrum, continuous integration and continuous delivery, deploying to production every single day.

We're building teams to help us succeed in our mission to upgrade the world to a better financial system. You'll be joining a group of highly motivated software engineers who you'll work collaboratively with across our pods.

As a fast-growing company with offices around the world, you'll immediately see how your contributions directly impact both our internal users and client experience. Many of the problems we are solving result in trail blazing solutions which can't be found on Stack Overflow; so we're looking for engineers who flourish working in a complex domain.

In your first six months, you will:


...start at Luno by learning our processes, meeting the wider team and starting our engineering on-boarding program. After getting comfortable with the basics, you'll start learning our idiomatic patterns in a safe, easy-to-follow way - by building your own toy micro services. You'll get to practice how we do design docs, code reviews, deployments, events, logging and monitoring.

You'll meet the Pod(s) you'll be working with and quickly align on the teams' current OKRs and product roadmap. We succeed as a team, so we will provide you with regular feedback from your manager and peers and will encourage you to do the same.

What you'll do:
Work closely with our data science and platform teams on projects introducing new streams of data into our data lake
You will get to bring new ideas on how to further develop and innovate our data solutions and how to expose that data to the business
Accountable and Responsible for the design and architecture of Data systems that are robust and scalable.
Work in an Agile/Scrum framework or Agile mindset
Data backup/recovery and storage
Pick-up and learn new concepts, in both engineering and product, and be able to apply that knowledge quickly.
The ideal candidate for this role will have:
7+ years' experience in maintaining scalable data solutions and/or you are passionate about it
Ability to understand, communicate and advocate between build vs buy
Proven track record of setting up, restructuring and maintenance of databases
You know your way around ETL and you have experience with SQL
Experience in the AWS Data stack (RedShift,DynamoDB, Amazon RDS)
Familiarity with integrating data stores with BI platforms such as Looker, Tableau, or Power BI
You have experience with the concepts of CI/CD
Coding skills in e.g. Go, Python
Bachelor's degree in a related field preferred
AWS Certified DataOps Administrator
Be friendly, transparent, articulate and driven to succeed
Basic knowledge of and passion for digital currencies like Bitcoin
A work permit for South Africa if you are not a South African citizen
Don't be put off if you don't tick all of the boxes – they're a guide based on what we'd love to see but we appreciate that excellent software engineers have diverse backgrounds.

Remote Life at Luno


If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity / paternity and even (yes, you are reading it correctly) paw-ternity for your furry friend..
Annual Inspiration Day.. like that pottery course you've always been meaning to do!
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. You'll need to hold the legal right to work in South Africa already as we cannot provide visa sponsorship.

Be part of the change!",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer - EC2 Capacity Data Analytics,-1,"EC2 Capacity Data Analytics (CDA) team is looking for a Data Engineer to join our team.

Our team is part of the EC2 Capacity Engineering organization, which is responsible for providing the elasticity EC2 customers need to scale up/down compute resources in a cost-efficient manner. We predict customer usage across thousands of configuration combinations to deliver exactly what our customers require in just the right amount of time with just the right amount of capacity.

As a Data Engineer, you will build the ETL and analytics solutions for our internal customers to answer questions with data and drive critical improvements for the business. You will use best practices in software engineering, data management, data storage, data compute, and distributed systems. On any given day, we use Python, Scala, Java, SQL, Lambda, CloudFormation, Redshift and Glue as well as other public AWS services and a host of Amazon internal tools. We dont expect you to be an expert in, or necessarily even be familiar with all of the technologies listed above, but we do expect you to be excited to learn about them.

This position involves on-call responsibilities, typically for one week every two months. Our team is dedicated to supporting new team members. We care about your career growth, we try to assign projects and tasks based on what will help each team member develop into a more well-rounded engineer and enable them to take on more complex tasks in the future.

Our team values work-life balance and we are flexible when people occasionally need to work from home.

Job Duties
Develop and maintain automated ETL pipelines for big data using languages such as Scala, Spark, SQL and AWS services such as S3, Glue, Lambda, SNS, SQS, KMS. Example: ETL jobs that process a continuous flow of JSON source files and output the data in a business-friendly Parquet format that can be efficiently queried via Redshift Spectrum using SQL to answer business question.

Develop and maintain automated ETL monitoring and alarming solutions using Java/Python/Scala, Spark, SQL, and AWS services such as CloudWatch and Lambda.

Implement and support reporting and analytics infrastructure for internal business customers using AWS, services such Athena, Redshift, Spectrum, EMR, and QuickSight.

Develop and maintain data security and permissions solutions for enterprise scale data warehouse and data lake implementations including data encryption and database user access controls and logging.

Develop and maintain data warehouse and data lake metadata, data catalog, and user documentation for internal business customers.

Develop, test, and deploy code using internal software development toolsets. This includes the code for deploying infrastructure and solutions for secure data storage, ETL pipelines, data catalog, and data query.


Basic Qualifications

· Bachelors degree in Computer Science or related technical field, or equivalent work experience.
· 4+ years of overall work experience including Software Engineering, Data Engineering, Database Engineering, Business Intelligence.
· Experience with AWS technologies stack including Lambda, Glue, Redshift, RDS, S3, EMR or similar big data solutions stack

Preferred Qualifications

· Demonstrate efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data.
· Demonstrable proficiency in distributed systems and data architecture; design and implementation of batch and stream data processing pipelines; knows how to optimize the distribution, partitioning, and MPP of high-level data structures.

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer,-1,"Our client based in Johannesburg is urgently looking for a Data Engineer to be on a 3 months contract
Build data pipelines, experience in new tech like nifi, kafka, python

Joburg based, open to EE, 3 month contract with the option to extend, must be available at short notice",-1,EQplus,Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Overview
Job ID: 51456
Job Sector: Information Technology and Services
Country: South Africa
Region/State/Province/District: Gauteng
Location: Johannesburg

Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose

This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes

Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems

Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions

Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.
Research and best practices

Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development

Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.

Preferred Qualification and Experience

Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry

Knowledge/Technical Skills/Expertise

Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision

PLEASE NOTE: All our recruitment and selection processes comply with applicable local laws and regulations. We will never ask for money or any form of payment as part of our recruitment process. If you experience this, please contact our Fraudline on +27 800222050 or forward to TransactionFraudOpsSA@standardbank.co.za",4.1,"Standard Bank
4.1",Johannesburg,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"About us

At PBT Group we pride ourselves on being a Data Specialist organisation. With 20 years of experience in 27 countries over 3 continents, our team of 550 consultants have implemented more than 700 projects.",4.3,"PBT Group
4.3",Johannesburg,-1,Unknown,-1,Company - Private,Accounting,Accounting & Legal,Less than $1 million (USD),-1
Data Engineer,-1,"Kick-start your career in the online gaming world and experience the very latest in technology and innovation.

The Department:

Our mission is to provide our customers with the best online betting experience and share the thrill of gaming with them. Data is at the very heart of our business and is vital in everything we do.

Our cross-functional Data team has a big and exciting challenge ahead. We are in the process of re-platforming our traditional, on-premises RDBMS environment to a new microservice architecture in the cloud. We’re making use of the diverse set of data technologies in Microsoft Azure to offer new services, reporting structures and real-time data pipeline while serving the day-to-day requirements of a rapidly growing, data-hungry organisation.

Purpose of the Role:

This is an excellent opportunity for an individual who is looking to gain new skills. We are committed to creating a culture of learning and regularly run proof of concepts, provide internal demos, manage workshops and attend external conferences. Our data team has a wide range of skills including development for highly transactional RDBMS systems, data warehousing, data science and cloud technologies and we are always working to raise everyone’s game.

Duties include, but not limited to:

Work as part of an agile Data Engineering Team
Development of greenfield projects in Azure
Develop and maintain on-premises RDBMS/DW systems
Create robust ETL services and real-time data pipelines
Build and maintain Continuous Integration and DevOps pipelines
Test-driven development and pair programming with colleagues

Essential Criteria:

C#, .Net, Visual Studio
Git, Azure DevOps
NoSQL development (CosmosDB)
Demonstrable understanding of MS SQL Server in a highly transactional environment
Demonstrable understanding of development in Microsoft Azure
Able to understand query plans and identify performance bottlenecks
Test/Business-Driven Development
Building Continuous Integration/Deployment pipelines
Communicate effectively with both technical and non-technical stakeholders

Desirable Criteria:

Implementing Data Storage and Processing solutions in Azure (ARM Templates, Storage Accounts, Data Lake Storage, SQL DB, Cosmos DB, EventHubs, Function Apps, Log Analytics, Data Factory, Databricks, Polybase)
Implementing Security, Disaster Recovery, High Availability, Auditing, Monitoring and Alerting solutions in Azure
Automating tasks in Azure using Powershell / CLI
Predicting costs and optimizing spending in Azure
Message Queues (RabbitMQ, Kafka)
Python

Person Specifications:

Resilience
Teamwork
Technical Knowledge
Communication skills
Stress Tolerance
Please note we will apply relevance to our Talent Management and Talent Development Programme as part of our recruitment process.
Shortlisted candidates may need to complete an assessment.
This position requires trust and honesty it has access to customers financial details - therefore a credit and criminal record check will be conducted. The qualifications identified herein are an inherent job requirement; therefore, a qualification verification check will be done. By applying for this role, and supplying the necessary details, you hereby grant us permission to apply for these checks. This will be done in a confidential manner, and solely for the purposes of verification.

To view all current vacancies, please visit our website, www.digioutsource.com

Should you not hear from us within 2 weeks, please deem your application as unsuccessful.

The perfect place to work, play and grow!",3.9,"Digital Outsource Services
3.9",Cape Town,-1,1001 to 5000 Employees,1997,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
Data Engineer,-1,"At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes

Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.

Key Responsibilities

Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.

Key Traits

Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern

Position Requirements

2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.

Where will you work? This role will be based out of Durbanville, South Africa.",3.1,"Aculocity, LLC
3.1",Durbanville,-1,1 to 50 Employees,2006,Company - Private,IT Services,Information Technology,$1 to $5 million (USD),-1
Data Engineer,-1,"ENVIRONMENT:

A rapidly growing E-Commerce Platform seeks a highly talented Data Engineer to make an invaluable contribution to data democratisation and literacy vision by making accessible and easy-to-use data products and tools. You will require a Comp-Sci Degree or 3 years’ relevant industry experience, MySQL, PostgreSQL, Java, Python, in-depth understanding of OLAP, Data Marts, Star Scheme, Snowflake, be familiar with Jenkins, Travis, Circle CI, Docker, Kubernetes, experience with Kafka, Pub/Sub, Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks & significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing & Data Lake design and implementation and Lambda/Kappa architectures.

DUTIES:

Design, develop, test and maintain data architecture.

Prepare data for descriptive, predictive and prescriptive modelling.

Automate repetitive tasks and manual processes related with the data usage.

Optimize data delivery.

Design, develop and test large stream data pipelines to ingest, aggregate, clean, and distribute data models ready for analysis.

Ensure the highest standard in data integrity.

Leverage best practices in continuous integration and delivery.

Collaborate with other engineers, ML experts, analysts, and stakeholders to produce the most efficient and valuable solutions.

Implement features, technology, and processes that move us towards industry best practices, improving on scalability, efficiency, reliability, and security.

Operations and ownership of systems in production, responding to incidents.

REQUIREMENTS:

Qualifications –

Comp-Sci Degree or 3 years relevant industry experience.

Experience/Skills –

Open source relational database systems e.g. MySQL, PostgreSQL, etc.

Significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing, and Data Lake design and implementation and Lambda/Kappa architectures.

A thorough understanding of database and data warehousing principles e.g. OLAP, Data Marts, Star Schema, Snowflake, etc.

Java and Python.

Familiar with CI/CD tools such as Jenkins, Travis, Circle CI, etc.

Experience with Kafka, Pub/Sub, or other event-based systems.

Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks, etc.

Working in cloud environments and with containerisation frameworks, tools and platforms e.g. Docker, Kubernetes, GKE, etc.

A deep understanding of data pipelining, streaming, and Big Data technologies, methods, patterns, and techniques.

Troubleshooting complex database operations and performance issues.

Automating tasks using Shell Scripting or writing small applications.

ATTRIBUTES:

Works well with people and is passionate about helping people be their best.

A team player, an active listener, mentor, and able to communicate well.

Shows solid reasoning and decision making, with the ability to work under pressure.

Is passionate about technology, systems and data.

Is curious, always learning, and keeping up to date with the industry.

While we would really like to respond to every application, should you not be contacted for this position within 10 working days please consider your application unsuccessful.

COMMENTS:

When applying for jobs, ensure that you have the minimum job requirements. Only SA Citizens will be considered for this role. If you are not in the mentioned location of any of the jobs, please note your relocation plans in all applications for jobs and correspondence.",-1,Datafin IT Recruitment,Cape Town,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Cartrack is looking for passionate data science and engineering candidates that can join a growing team that is responsible for the intelligence and efficiency solution provision to over a million subscribers, many of whom are large fleets. We are in the midst of creating revolutionary platforms that will change the way that people interact with their vehicles.

You will have the opportunity to work with the very brightest global subject matter experts that are transforming the automotive industry across Fleet Management, Asset Management and Insurance Telematics solutions.

Get to know the role:

The role of a data engineer is a supporting one, but it is also an extremely vital one. As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements. We want to see candidates with mechanical tendencies and a desire to know how things work and to improve them.

The day-to-day activities:

Design, construct, install, test and maintain data management systems.
Build high-performance algorithms, predictive models, and prototypes.
Ensure that all systems meet the business/company requirements as well as industry practices.
Integrate up-and-coming data management and software engineering technologies into existing data structures.
Develop set processes for data mining, data modeling, and data production.
Create custom software components and analytics applications.
Research new uses for existing data.
Employ an array of technological languages and tools to connect systems together.
Install/update disaster recovery procedures.
Recommend different ways to constantly improve data reliability and quality.
Work on and maintain Data pipelines.

Requirements Essential:

At least 5 years’ proven experience as a Data Engineer, DevOps Engineer, Software Developer, or similar.
Proficient in Linux/Unix and shell scripting as well as in functional programming languages.
Expertise in setting up and explored with technologies such as Hadoop and Spark.
Bachelor’s degree in computer science, software/computer engineering, applied mathematics, or physics.",3.3,"Cartrack
3.3",Johannesburg,-1,501 to 1000 Employees,2004,Company - Private,Security Services,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Data Engineer,-1,"Data Engineers build and support data pipelines and datamarts built off those pipelines. Both must be scalable, repeatable and secure. The Data Engineer helps to facilitate gathering data from a variety of different sources, in the correct format, assuring that it conforms to data quality standards and assuring that downstream users can get to that data timeously. This role functions as a core member of an agile team. These professionals are responsible for the infrastructure that provides insights from raw data, handling and integrating diverse sources of data seamlessly. They enable solutions, by handling large volumes of data in batch and real-time by leveraging emerging technologies from both the big data and cloud spaces. Additional responsibilities include developing proof of concepts and implements complex big data solutions with a focus on collecting, parsing, managing, analysing and visualising large datasets. They know how to apply technologies to solve the problems of working with large volumes of data in diverse formats to deliver innovative solutions. Data Engineering is a technical job that requires substantial expertise in a broad range of software development and programming fields. These professionals have a knowledge of data analysis, end user requirements and business requirements analysis to develop a clear understanding of the business need and to incorporate these needs into a technical solution. They have a solid understanding of physical database design and the systems development lifecycle. This role must work well in a team environment.

Job Objectives

Work Complexity: * Architects Data analytics framework. * Translates complex functional and technical requirements into detailed architecture, design, and high performing software. * Leads Data and batch/real-time analytical solutions leveraging transformational technologies. * Works on multiple projects as a technical lead driving user story analysis and elaboration, design and development of software applications, testing, and builds automation tools.

Main Job Objectives: 1. Development and Operations 2. Database Development and Operations 3. Policies, Standards and Procedures 4. Communications 5. Business Continuity & Disaster Recovery 6. Research and Evaluation 7. Coaching/ Mentoring

Qualifications

Essential: 4 years Bachelors degree in computer science, computer engineering, or equivalent work experience AWS Certification at least to associate level

Experience

Essential:

5+ years Data engineering or software engineering

3-5 years demonstrated experience leading teams of engineers

2+ years Big Data experience

5+ years experience with Extract Transform and Load (ETL) processes

2+ years Could AWS experience

At least 2 years demonstrated experience with agile or other rapid application development methods - Agile exposure, Kanban or Scrum

5 years demonstrated experience with object oriented design, coding and testing patterns as well as experience in engineering (commercial or open source) software platforms and large scale data infrastructures.

Desirable:

5+ years Retail Operations experience

Knowledge and Skills

Essential: *Creating data feeds from on-premise to AWS Cloud (2 years) *Support data feeds in production on break fix basis (2 years) *Creating data marts using Talend or similar ETL development tool (4 years) *Manipulating data using python and pyspark (2 years) *Processing data using the Hadoop paradigm particularly using EMR, AWSs distribution of Hadoop (2 years) *Devop for Big Data and Business Intelligence including automated testing and deployment (2 years) * Extensive knowledge in different programming or scripting languages * Expert knowledge of data modeling and understanding of different data structures and their benefits and limitations under particular use cases.

Further technical skills required: * Capability to architect highly scalable distributed systems, using different open source tools. * Big Data batch and streaming tools * Talend (1 year) * AWS: EMR, EC2, S3 (1 year) * Python (1 year) * PySpark or Spark (1 year) - Desirable * Business Intelligence Data modelling (3 years) * SQL (3 years)",-1,Datonomy Solutions,Brackenfell,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We are assisting one of our clients that is based in Pretoria to fill a role of a Data Engineer

This is a 12 month contract role

Objective of this Scope of Work

The Data Engineer will drive improvement of the data management maturity levels and provide the necessary technical support within the company to support reliable and effective decision-making, appropriate usage and protection thereof.

Scope of Services Definition

The scope will include but will not be limited to:

ï†· To develop, construct, test and maintain architectures.

ï†· To ensure architectures will support the requirements of business.

ï†· To discover opportunities for data acquisition and sharing.

ï†· To develop data set processes for data modelling, mining and production.

ï†· To employ a variety of languages and tools to marry systems together.

ï†· To recommend way to improve data reliability, efficiency and quality.

ï†· To prepare data for use in predictive and prescriptive modelling.

ï†· To conduct research to answer industry and business questions.

ï†· To leverage volumes of data from internal and external to answer business questions.

ï†· To develop and manage stakeholder relations effectively to promote data management across the organisation and support reliable decision making and appropriate data usage.

ï†· To participate and provide technical support in cross organisational activities relating to any of the above mentioned data management activities.

ï†· To provide regular progress reports as per stakeholder requirements and present data management updates in various forums as required.

Minimum qualification Required:

ï†· A minimum of a Bachelors degree in Computer Science or Information Management OR equivalent;

ï†· A minimum of five to eight years experience in a data management environment",-1,HR Genie,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Our client based in the Northern Suburbs, is currently looking for a Data Engineer to join their team.

Responsibilities
Our client is a dynamic IT company that delivers value-driven IT solutions to the group. Our work lives revolve around our DNA. We take pride in our work, treat our colleagues, partners and our country with respect. We exercise collaborative decision-making and believe in having a balance in life. We do this all while having fun and enjoying what we do.

The primary focus of this position is to use technical skills to put software, systems and data together in a way that extracts meaningful insights from raw data. You will need to be helpful and supportive to your team and fellow developers. You join an energetic, focused and dynamic team.

Interact with clients to understand requirements and business problems/needs

Identify, analyse, visualise and understand supporting data to propose solid solutions

Create technical documentation for reference and reporting

Support existing solutions within GCP and Oracle

Doing standby on a rotating basis

Key Competencies and Qualifications

Matric

Tertiary qualification in IT

Preferred cloud experience in AWS/AZURE/GCP

At least 3 years of data warehouse ETL experience

Dimensional Modelling

Data analyses

Experience with data visualization and visualization tool(s)

Knowledge of the retail industry will be beneficial

Understanding and experience with version control SVN/GIT

Preferred – Korn shell scripting, Python/Java, SQL

Google Cloud Platform experience would be looked upon favourably

Having a broad understanding of different SDLC’s

Preferred agile experience

Strengths

The natural tendency to take ownership and responsibility

Strong problem solving, critical thinking, effective planning and organisational skills

Detail-oriented with excellent communication skills

You have a can-do attitude and positive outlook on life

Can cope under pressure

Curious and interested in analysing problems and possible solutions

Strong team player

Self-driven learner, passionate about new technology

Above all, be passionate about what you do

Should you wish to apply for the position, please apply directly via this job board, please ensure that you quote reference number 201620 subject heading or email body.

Please note that due to the high volume of CV's received; only shortlisted applicants will be contacted. Should you not receive communication from our offices within two weeks of submission please note that your application will not be considered for this position.

We will keep your CV on file and re-establish contact with you should opportunities in line with your expertise become available again.

Should you require any additional information give us a call on 021 012 5566.",-1,Surgo HR & Training,Cape Town,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We believe that our employees fuel our organization, essential to enable us to help our customers overcome their business challenges and achieve sustainable growth. As a result, we are committed to growing each individual and providing them with the challenges, feedback and support needed to achieve success in their career

If this sounds appealing, and like us, you get excited about data: its collection, storage, transformation or display, see if you’ve got what it takes to join our sought after DATA team.

Key Responsibilities And/or Outputs

You will represent IQbusiness at our customers, sometimes alone, and sometimes as part of an IQ team.

Providing a superior customer experience by building and maintaining relationships, working at customer offices, keeping data confidential
Design and develop – databases, SQL queries, stored procedures, reports, dashboards or integration solutions
Produce solutions for both real-time and batch environments
Test your work to ensure compliance
Solve problems, and do root cause analysis
Prioritize your workload
Assist in other areas relating to your true data function, such as data modeling, data and business analysts
Interact with a variety of individuals: senior, junior, technical and from business
Provide guidance to fellow colleagues, or even manage a team
Uphold the IQ values, which are to care, learn & share; innovate; deliver as well as to build, enhance and maintain relationships

Education

Matric pass
A tertiary qualification, preferably in an ICT relevant field
Appropriate Microsoft certifications are beneficial but not required

Requirements

3 - 6 years experience in the Data Engineering environments and technologies
Great communication skills
A passion for SQL, databases or reports
Can you write stored procedures, design complex queries and create views and triggers?
Are you able to work out the relationships in a data warehouse or the aggregation of a cube?
Do you extract and display useful information when you see patterns and trends in data?
Strong knowledge of the financial services industry, ideally in a consulting role
The use of data related software: databases, ETL and BI tools; report writing and analytical tools
We use a lot of Microsoft products. You may often be expected to use MS SQL Server, SSIS, SSRS, SSAS and Power BI to develop solutions
What other relevant software have you’ve used?
Ability to work in different project methodologies: Waterfall and/or Agile
Knowledge of full SDLC
Exposure to logical and physical data modeling

Equal Employment Opportunity

IQbusiness is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, citizenship, marital, domestic or civil partnership status, sexual orientation, or gender identity",3.7,"IQbusiness South Africa
3.7",Johannesburg,-1,1 to 50 Employees,-1,Company - Private,Consulting,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"We value a data engineer as someone who works behind the scenes to obtain, process and supply data via various methodologies and technologies, to various consumers, in ways and forms that makes sense and add value. This definition is very broad, as the field of data engineering is just as broad.

You may be the type of data engineer that develops API endpoints for the consumption of data by end users or even another data pipeline, or you may be the type of data engineer that develops highly distributed, high availability data processing pipelines in an effort to satisfy the need of the ever questioning data analysts and/or data scientists.

You have awesome knowledge about the following concepts
Data modelling
Relational data modelling in traditional relational database management systems. (Microsoft SQL Server, MySQL, PostgreSQL, etc)
Coercing unstructured and semi-structured data into a structured form.
Data pipelining knowledge - data extraction and transformation.
Data transformation knowledge for reporting and analytics purposes.
Knowledge of the MapReduce and related data processing paradigms would be a boon.
You have the following technical competencies
Writing SQL queries, that can relate, transform and aggregate data from many differing sources where natural keys may or may not exist.
Experience with writing data pipelines that move and transform data, for various uses.
Working knowledge of a general purpose programming language like Python would be a boost.
Working knowledge of columnar databases such as Google BigQuery, and SAP HANA would be a boost.
Working knowledge of highly distributed technologies such as Apache Hadoop or Apache Spark would be a boost.
Working knowledge of NoSQL technologies, such as Apache Solr would be a boost.
You have the following personal competencies
The ability to solve problems.
The ability to rotate around a problem, to see if solutions can be gained in different ways.
The ability to work in an ever changing, unstructured environment.
The ability to work as part of a team, with vastly differing skill sets and opinions.
The ability to contribute ideas to the quorum.
The ability to mentor and provide guidance for other team members.
A systems approach to thinking, as opposed to a siloed approach. The candidate needs to understand how their work affects the greater system.
The ability to work without supervision, and take accountability for the work they deliver.
The ability to liaise with a client, sifting through the fluff and extracting the actual requirements.
If this is you - apply now and we'll get in touch",-1,DotModus,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Data Engineer

Our client in the contact centre space is currently seeking a DATA ENGINEER that will work on the collecting, storing, processing, and analyzing of large datasets. The primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them. You will also be responsible for integrating them with the architecture used across the company.

Key Performance Areas:

Data reporting.
Implementing ETL processes.
Defining data retention policies.
Management of Customer Lead data.
Provision of data for advanced analytics.
Maintenance of internal client scorecards.
Assist team in resolving data-related support queries.
Optimize existing data processes through automation.
Assist with all data-related reporting and documentation.
Maintenance and optimisation of the Analytics database.
Provide technical support to and supervision of junior data administrators.
Continuous upskilling on new technologies, frameworks and market trends.
Monitoring performance and advising any necessary infrastructure changes.
Identifying, selecting and integrating any Big Data tools and frameworks required to provide real-time analytics.

Educational Requirements

IT related Degree or Diploma is a pre-requisite

Required Skills/Experience

ETL tools: Advanced SSIS
BI/Reporting : Qlikview/Power BI/ SSRS or SSAS
Programming languages: JAVA, C# , Python, SAS or R
Experience with NoSQL databases and/or campaign management tools will be advantageous.
Minimum 3 years’ applicable work experience in SQL, relational databases and data manipulation.
Experience in big data platforms (eg. Hadoop) or processing frameworks (eg. MapReduce/Spark) and querying tools (eg. Pig, Hive and Impala) will be highly beneficial.

Preferred Skills

Organizational skills
Experience in Attentional to detail.
Accountability is critical for this role.
Ability to work under pressure and meet deadlines.
Solid understanding of database design principles.
Should you not receive a response in 2 weeks please consider your application unsuccessful",-1,Rubik's Cubed Consulting,Durban,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"This well known company is looking for a Data Engineer. will be based in Rivonia
The ideal candidate will have strong experience in the following:
Data cleaning
SQL Export
Big data Sets

BSc Degree in Maths and Stats will be required
a min of 3 years experience.
Stable track record is required.

Send your Cv to marinda@prrrecruitment.co.za",-1,PRR Recruitment Services,Johannesburg,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Description

Position at Aculocity, LLC

At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes
Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.
Key Responsibilities
Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.
Key Traits
Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern
Position Requirements
2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.
Where will you work? This role will be based out of Durbanville, South Africa.",-1,GVW,Durbanville,-1,Unknown,-1,Unknown,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Information Technology, Gauteng JHB - Northern Suburbs

Market related - Market related Annually

An IT Consultancy Business based in Johannesburg is currently looking for a Business Intelligence Consultant / Data Engineering Consultant.

Requirements:

Extensive experience in data engineering
Experience in Business Intelligence, data and Power BI
Extensive experience in data governance and the Popi act
Ability to assess and make recommendations on data within the Popi act
Good understanding of T-SQL and query optimization, developing ETL strategies.
Good understanding with SQL Server 2008/2012, SSIS, SSRS and SSAS
Use SSIS to create ETL packages to validate, extract, transform, and load data into the data warehouse and data marts.
Deploy and configured the reports in the Report Server (SSRS).
Excellent experience in Tabular Modelling , PowerView, Qlikvie,w, and Power BI
Maintain ETL
Qlikview model
Create Drill-through, Drill-down, and Cross Tab Reports and Sub-Report using Report Definition Language (RDL).
Generate periodic reports based on the statistical analysis of the data using SQL Server Reporting Services (SSRS)
Advise and provide written technical documentation and recommendations

The information displayed above is not limited to advertisements. Please contact Thato for further information.

Please consider your application as unsuccessful if you have not received a response within 14 days of submitting your application. However, please keep a lookout on our website, www.bedifferent.co.za, for available positions that you may be suited for

Ad Visible Until: 29 October 2020
Ref: JHB005346/NL

Vacancy Type: Permanent",2.9,"Be Different Recruitment
2.9",Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Cloud Support Engineer (Big Data),-1,"ABOUT US

Amazon Web Services is the market leader and technology forerunner in the Cloud business. As a member of the AWS Support team you will be at the forefront of this transformational technology, assisting a global list of companies and developers that are taking advantage of a growing set of services and features to run their mission-critical applications. As a Cloud Support Engineer, you will act as the Cloud Ambassador across all the cloud products, arming our customers with required tools & tactics to get the most out of their Product and Support investment.

Would you like to use the latest cloud computing technologies? Do you have an interest in helping customers understand application architectures and integration approaches? Are you familiar with best practices for applications, servers and networks? Do you want to be part of a customer facing technology team helping to ensure the success of Amazon Web Services (AWS) as a leading technology organization?

If you fit the description, you might be the person we are looking for! We are a group of smart people, passionate about cloud computing, and believe that world class support is critical to customer success.

WHAT CAN YOU EXPECT FROM A LIFE AT AWS?

Every day will bring new and exciting challenges on the job while you:

· Learn and use groundbreaking technologies.
· Apply advanced troubleshooting techniques to provide unique solutions to our customers' individual needs.
· Interact with leading engineers around the world.
· Partner with Amazon Web Services teams to help reproduce and resolve customer issues.
· Leverage your extensive customer support experience to provide feedback to internal AWS teams on how to improve our services.
· Drive customer communication during critical events.
· Drive projects that improve support-related processes and our customers technical support experience.
· Write tutorials, how-to videos, and other technical articles for the developer community.
· Work on critical, highly complex customer problems that may span multiple AWS services.

WHY AWS SUPPORT?

· First and foremost this is a customer support role in The Cloud.
· On a typical day, a Support Engineer will be primarily responsible for solving customers cases through a variety of customer contact channels which include telephone, email, and web/live chat. You will apply advanced troubleshooting techniques to provide tailored solutions for our customers and drive customer interactions by thoughtfully working with customers to dive deep into the root cause of an issue.
· Apart from working on a broad spectrum of technical issues, an AWS Support Engineer may also coach/mentor new hires, develop & present training, partner with development teams on complex issues or contact deflection initiatives, participate in new hiring, write tools/script to help the team, or work with leadership on process improvement and strategic initiatives.
· Career development: We promote advancement opportunities across the organization to help you meet your career goals.
· Training: We have training programs to help you develop the skills required to be successful in your role.
· We hire smart people who are keen to build a career with AWS, so we are more interested in the areas that you do know instead of those you havent been exposed to yet.
· Support engineers interested in travel have presented training or participated in focused summits across our sites or at specific AWS events.
· As we operate on a follow-the-sun model, with Premium Support sites located globally, there is no after hours on-call or mandated overtime in this role.
· https://www.youtube.com/watch?v=GC3bWcFFZTo&t=24s



Basic Qualifications

The Big Data role supports our services that leverage data and produce business insights, which may include using Machine Learning/Artificial Intelligence (ML/AI). Helping our customers use and integrate Big Data services in what is arguably our industrys most exciting space. The portfolio of services covers EMR (Hadoop), DynamoDB (NoSQL), MangoDB, and Apache Cassandra.

· Advanced experience in Apache Hadoop, Apache Spark, Apache Hive, and Presto
· Advanced experience in DynamoDB or NoSQL technologies like MongoDB or Cassandra
· Advanced experience with System Administration with Linux (RHEL/CentOS) including Microsoft Active Directory, and LDAP integration.
· Experience with troubleshooting Kerberos Authentication problems.
· Experience with Network troubleshooting.
· Basic understanding of Machine Learning and statistics
· Experience with Java and Python and shell scripting
· Bachelors degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position



Preferred Qualifications

· Expert experience in the Hadoop Ecosystem including Apache Spark and Presto
· Expert experience in NoSQL
· Expert experience with blockchain technologies like Etherium Expert experience in data Data Lake architecture and administration
· Experience managing full application stacks from the OS up through custom applications
· Prior work experience with AWS - any or all of EC2, VPC, S3, RDS, EMR, Glue, SageMaker
· Excellent knowledge of Hadoop architecture, administration and support
· Expert understanding of distributed computing principles and their application in the cloud
· Good understanding of distributed computing environments Lead technical discussions on big data systems architecture and design
· Strong analysis and troubleshooting skills and experience
· AWS Certified Solutions Architect
· AWS certified Big Data Specialty
· Masters degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity and Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Response Center Engineer,-1,"Job Title
Response Center Engineer
Job Description


Philips is a world leading health technology company with a vision to make life better for people worldwide through meaningful innovation. Making good on this promise depends on our passionate, inspirational, collaborative and diverse team. We have over 80,000+ brilliant people around the world but are always looking for more. Like-minded, motivated, focused minds to join us in creating a healthier, more connected society while transforming themselves personally and professionally.

As a CCC Coordinator - Response Center Engineer you will have the opportunity to process customer calls and be responsible for screening and diagnosing professionally Healthcare equipment to support customers and colleagues remotely with solving technical issues and ensuring maximum customer satisfaction

You are responsible for:
Diagnose healthcare equipment to the quality standards set by Philips Healthcare (PH) remotely by interviewing customers or colleagues by telephone or by remotely logging in to the system
Advise Customer Care Center Coordinators and District Operations Managers and / or Team Leads about the best follow-up w.r.t. technical state of the diagnosed healthcare equipment
Advise the Customer Care Center Coordinators or Field Services Engineers about required spare parts and resources
Responsible for planning engineers related to Modality responsibility.
Responsible for coordination between CCC, CUSTOMER, Spare parts AND Engineer.
Responsible to drive Remote and FTR KPI’s to targets respectively 40% and 85%.
Will require minimal field work to keep abreast of technical capabilities.
Take calls from customers and make sure they are processed in the CCC ERP on timely manner including all relevant data
Support Field Services Engineers in the field with technical knowledge
Escalate technical issues to the Technical Support Specialist
Escalate technical issues to Business Unit support after consultation of the Technical Support Specialist
Monitor critical functions of the equipment’s in the IB and environmental conditions including RSN and True reachability.
Lead the planning and implementation of FSN’s and FCO’s accelerating remote implementation where applicable.
Submit timely and accurate service data, job sheets, reports, expense claims, radiation film badges, field problem reports and other paperwork as assigned
Keep abreast of new technologies likely to affect PH range of products
Use company property with care to ensure optimal results with minimal operational costs
Be a professional representative for PH with respect to customer problems, ensuring personal acceptability by the customer in behavior in accordance with PH policy and targets
Conform to PH safety standards including health and safety regulations and in the event of hazards or accidents to take immediate control of the situation and involve the Operations Manager and / or the responsible person to handle properly confidential issues according Philips standards and to act according General Business Principals
Follow all quality standards within the frame of valid PH business policies
Follow the company quality regulations (ISO 9001; PQA; TQM) and internal directives and procedures
You are a part of the dynamic South Africa Customer Care Centre Team .You will be reporting to the Customer Care Center Manager.

Requires a pleasant, assertive individual you can work very well in a team setting, a dynamic environment that requires flexibility and creativeness to achieve goals.

To succeed in this role, you should have the following skills and experience:
Degree level education or equivalent
Experience in maintenance and troubleshooting of technical complex systems
Fluent in English, verbal and written in addition to local language
In return, we offer you the unique combination of a critical and challenging role and a creative and empowering office environment. You will be actively encouraged to make improvements, establish best in class service and have a direct impact on the success of Philips on a daily basis.

Employment Equity

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply. Only apply for this role if you are a South African Citizen by birth or Naturalization prior to the 27 April 1994.

Why should you join Philips?

Working at Philips is more than a job. It’s a calling to create a healthier society through meaningful work, focused on improving 3 billion lives a year by delivering innovative solutions across the health continuum. Our people experience a variety of unexpected moments when their lives and careers come together in meaningful ways. Learn more by watching this video.

To find out more about what it’s like working for Philips at a personal level, visit the Working at Philips page on our career website, where you can read stories from our employee blog. Once there, you can also learn about our recruitment process, or find answers to some of the frequently asked questions.

Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.9,"Philips
3.9",Johannesburg,-1,10000+ Employees,1891,Company - Public,Health Care Services & Hospitals,Health Care,$10 to $25 million (USD),-1
Software Development Engineer - EC2 Placement,-1,"Build the systems that optimize how EC2 matches requests for Instances with the underlying compute capacity. EC2 Placement is seeking talented engineers to build the online and offline optimization systems for compute workload scheduling, and the customer capabilities to better manage those workloads. Amazon EC2 provides on-demand scalable compute capacity, and powers some of the largest services in the world. You will collaborate with a top-tier community of engineers to build systems to improve how customers are able to access EC2 compute resources.

The successful candidate will have strong software engineering experience, with a passion for thinking about, building and testing distributed systems. You have an interest in how Machine Learning and other optimization techniques can be applied to large-scale problems. You have demonstrated experience working with a team to design, build and operate large-scale systems. With strong engineering fundamentals, an analytical and data-driven approach to your work, and strong communication skills, you have the ability to collaborate well to deliver results. We move fast and work together on small teams to solve big problems.

If this opportunity sounds interesting, we would love to talk to you more about our work and the vibrant culture at AWS in Cape Town.

Basic Qualifications

· Degree in Computer Science or related field, or equivalent working experience
· 3+ years of industry experience in a software development environment
· Strong Computer Science fundamentals, including data structures, object-oriented design, algorithm design, problem solving, and complexity analysis.
· Proficiency in at least one modern programming language, such as Java, C#, Python, Scala, Kotlin

Preferred Qualifications

One or more of the following help you stand out:
· Demonstrated results designing, building and operating high-performance distributed systems in large-scale Linux environments
· Role model in writing high-quality, maintainable and secure code, mentoring others, and helping teams sharpen their development processes
· Ability to work effectively across teams to deliver results, with strong verbal and written communication skills
· Experience working with machine learning systems

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer - PBB IT,-1,"Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose


This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes
Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems
Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions
Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.

Research and best practices
Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development
Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.
Preferred Qualification and Experience
Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Aws Data Platform Engineer,-1,"Aws Data Platform Engineer

Posting Country:

South Africa

Date Posted:

15-Oct-2020

Full Time / Part Time:

Full Time

Contract Type:

Permanent

Joining Vodacom is more than a job, what we do matters. We don’t just carry minutes, texts and data – we carry people’s lives. And that’s a huge responsibility. If you think for a minute about the people you rely on…the likelihood is they rely on us.

Customers are at the heart of everything we do and we want to make a difference to the lives of our customers, and the communities in which we live and work. We support our people to give something back to the causes that mean the most to them through helping them give time and money to the charities they love.

And what’s it like to work here? We have created an environment where you can look forward to coming to work and are empowered to be at your best. We offer flexibility in how you work that helps you do your job in a way that suits you, opportunities to help you grow and progress throughout your career and a choice of benefits to suit your lifestyle.

Role Purpose
The H Band AWS Data Platform Engineer position is based within the Technology Business Unit.

The AWS Data Platform Engineer will be responsible for all Database services such as RDS, DynamoDB, etc. Should be able to migrate any databases from anywhere to AWS using any third-party tools or AWS database migration tool. Should also have understanding or expertise in creating data warehouses and data lake solutions on AWS.
Your responsibilities will include:
Apply practical knowledge of relational database design and usage with customers
Perform workload analysis and undertake performance tuning, as well as performance benchmarking in customer environments.
To develop state of the art solutions which are technically sound.
To provide a high-quality service to the Enterprise Cloud Services clients i.t.o. consultancy, solutions and delivery.
Commitment to team success and positive team dynamics including mentoring of other team members.
Passion for growing and applying technical skills in service to customers.
Be a trusted infrastructure advisor by providing objective, practical and relevant ideas, insights and advice.
Work collaboratively with consulting partners and technology teams to ensure high quality of solution delivery.
Encourage best practice and knowledge sharing with partners and cross-functional groups
Manage the overall database design and delivery of solutions.
Ability to make recommendations as they pertain to improvements in support/development initiatives and facilitate implementation with partners and cross-functional groups within the Business.
Participate in high level database solution definition and design during the implementation phase with the goal of providing reliable, stable and operationally sound applications that meet the Business requirements.
Ability to understand and translate business requirements into technical specifications
The ideal candidate will have:
A minimum of 3 years of industry related experience of which 1 year must be within a complex hosting environment.
Certifications in Database design, system architecture or cloud technologies.
Demonstrate knowledge of database systems internals including storage layouts and distributed databases/MPP architectures
Advanced SQL coding, tuning and query optimization.
Experience designing and leading database performance benchmarks.
Good knowledge of the different AWS services
Knowledge of cloud networking architecture, cloud operations, security, automation and orchestration.
Knowledge of database internals as it relates to query and system performance and tuning.
Understanding of overall system architecture, scalability, reliability, and performance in a database environment.
Excellent teamwork, time-management and organizational skills.
Perform other duties as deemed necessary and assigned by the customer and management
Strong interpersonal skills and problem-solving abilities.
Excellent documentation, communication and interpersonal skills.
Excellent analytical and problem-solving abilities.
Closing date for applications: Monday, 13 April 2020

The base location for this role is Vodacom World, Midrand

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply.
Vodacom is committed to an organisational culture that recognises, appreciates and values diversity & inclusion.

Commitment from Vodacom

Vodacom is committed to attracting, developing and retaining the very best people by offering a flexible, motivating and inclusive workplace in which talent is truly recognized, developed and rewarded. We believe that diversity plays an important role in the success of our business and we are committed to creating an inclusive work environment which respects, values, celebrates and makes the most of people’s individual differences - we are not only multinational but multicultural too. At Vodacom you will have access to our excellent flexible benefits programme that you would expect from any global company.",3.9,"Vodafone
3.9",Midrand,-1,10000+ Employees,1982,Company - Public,"Cable, Internet & Telephone Providers",Telecommunications,$10+ billion (USD),-1
Data Engineer Azure Data Factory,-1,"Enthuzex is looking for a motivated Lead Data Engineer to contribute towards the success of our Data and Analytics Technology initiatives. This is a hands-on technical role and this person will be responsible for the development and build of scalable solutions as it relates to the architecture strategies, data standards, digital data management, data integration, tools, and technology. The right candidate will play a deep dive hands-on critical development role in the digital transformation and in shaping how we acquire, ingest, transform and deliver data through the digital consumer channels.

Responsibilities:

Architect, design, develop and engineering end-to-end data pipelines across multiple data sources and systems of record.
Ensure data quality, integrity, security and completeness throughout the data lifecycle
Develop, design data models, data structures and ETL jobs for data acquisition and manipulation purposes
Develop deep understanding of the data sources, implement data standards, maintain data quality and master data management
Developing data services and API
Work closely with the cloud service providers to ensure completeness and alignment with the service offerings
Manage and maintain cloud based data and analytics platform
Deep understanding of the cloud offerings and engage in quick proof of concepts and proof of value in prototyping data and analytics solutions and derive viability
Ability to interact with the business stakeholders to understand requirements and translating into technology solutions

Expirience:

Experience in Cloud platform AWS or Azure eco-system. (Azure preferred)
Data Engineering/Development experience with SQL (Oracle, SQL Server, MySQL)
Strong development background creating pipelines and complex data transformations and manipulations using one of the languages Python, Java, R, or Scala with Databricks/Spark
Experience in NoSQL Databases and Big data technologies including Hadoop
Experience with API / RESTful data services
Worked on real-time data capture, processing and storing using technologies like Azure Event Hubs and Analytics
Experience working with different data storage options including AWS S3, Azure BLOB storage etc.
Understanding of different data formats including Parquet, Avro, CSV, ORC etc.
Prior experience with MPP databases and maintain large amount of data processing
Experience with Azure Data Factory and Azure Data Catalog is a big plus and mandatory
Experience with Microsoft/Azure ETL solutions and business Intelligence technologies is a big and mandatory
Past working experience on a fast paced and agile environment
Perform ongoing monitoring, automation and refinement of data engineering solutions
Experience in leading high visibility transformation projects that interacts with multiple business lines
Build and meet project timelines and manage delivery commitments with proper communication to management

Qualifications

Bachelor’s degree with 4+ years of relevant experience
Willingness to learn new technologies and thrive in an extremely fast paced environment
Team player and easy to work with.

Applicants must demonstrate their ability to master new enterprise level technologies. Successful applicants will exemplify Enthuzex ethical principles of uncompromising integrity, respect for others, and accountability for decisions

send cv's info@enthuzex.co.za",-1,Enthuzex,Leslie,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Scientist,-1,"The world is changing.

We all want something different.

At Luno, we see you as an individual.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the world, and to do so, we need the best team on board for our mission.

A bit about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 3 million customers across 40 countries.
We are Series B funded, backed by Balderton Capital and the Naspers Group.
Our platform has processed over 8 billion dollars since we've launched
We're proud to be one of the world's most international cryptocurrency teams from 26 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
The role in a nutshell:

Identifying opportunities in the business that could benefit most from cognitive applications, as well as building and enhancing organisational capabilities for deriving value from multiple data sources using data science.

What we'd like you to have:
Bachelor's degree or higher in the natural sciences or technical fields such as Mathematics, Statistics, Computer Science, Engineering or Economics
Enthusiasm to work in the cryptocurrencies space
Advanced SQL skills
Solid understanding of exploratory data analysis, predictive analytics, and optimisation using Python, R, Matlab, RapidMiner, KNIME or other data science-oriented platforms
Proficiency in the use of data science and machine learning domain-specific languages such as ""Caret"" and the ""Tidyverse"" suite of tools in R, or ""Pandas"" in Python
Strong interpersonal and communication skills
Communicating data insights using storytelling narratives
Ability to work independently, as well as within and across teams
Ability to successfully complete projects with large and/or incomplete data sets
More about what you'll be doing:
Optimising product performance by tracking and analysing customer behaviour on web and app, in collaboration with software engineers and product designers
Providing the business with reports and dashboards, on key performance metrics
Developing metrics to accurately assess the health of our Exchange platform
Comparative data-driven analysis of our Exchange against alternative platforms
Formulating business requirements into analytical objectives
Designing and running experiments to test hypotheses
Hacking through complex business problems using advanced data analysis to provide insights and recommendations
Building, maintaining, and optimising decisioning systems using advanced statistical and predictive modelling techniques
What will set you apart:
An advanced degree in Mathematics, Statistics, Computer Science or related field
At least 3 years' experience working in a similar role
A basic understanding of trading in financial markets
Experience working with a data analytics and visualisation platform such as Tableau, Cognos, QlikView, or Looker
Familiarity with using Google Analytics to understand customer behaviour
Solid knowledge of statistical and machine learning techniques
Familiarity with modern distributed data storage and processing systems such as Amazon Redshift, Big Query, Snowflake, Databricks and Apache Spark
You can gather and synthesise facts, theories, trends, patterns, inferences, and key issues in complex and variable situations
Ability to diagnose problems using formal problem-solving tools and techniques from multiple angles to generate multiple possible solutions
A sense of anticipating long-term problem areas and associated risk levels with objective rationale
Remote Life at Luno

If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
You'll be able to continuously upskill yourself with access to free online learning via MyAcademy, an international teaching marketplace with over 100000 courses from Harvard and other leading providers + share knowledge with your peers.
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity and paternity leave, and you can even take paw-ternity leave for your furry friend.
Annual Inspiration Day! Make time for that pottery course or spa day you've always wanted to do.
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"EY is a global leader in
assurance, tax, transaction and advisory services. Technology is at the heart
of what we do and deliver at EY. Technology solutions are integrated in the
client services we deliver and are key to our innovation as an organization.

Fueled by
strategic investment in technology and innovation, Client Technology seeks to
drive growth opportunities and solve complex business problems for our clients
through building a robust platform for business and powerful product engine
that are vital to innovation at scale. As part of Client Technology, you’ll
work with technologists and business experts, blending EY’s deep industry
knowledge and innovative ideas with our platforms, capabilities, and technical
expertise. As a catalyst for change and growth, you’ll be at the forefront of
integrating emerging technologies from AI to Data Analytics into every corner
of what we do at EY. That means more growth for you, exciting learning
opportunities, career choices, and the chance to make a real impact.

The selected
candidate
Develops
large and complex data architecture, composed of models, policies, rules or
standards that govern which data is collected and how it is stored, arranged,
integrated and put to use in data systems, including the design, build and
management of data infrastructure to address business requirements
Creates
sound use case driven roadmaps, depicting data architecture as-is and to-be
capabilities with the business by engaging with multidisciplinary teams, and by
identifying, managing and mitigating risk
Develops
relationships across the business to understand data requirements, applies deep
technical knowledge of data management to solve business problems in areas
where solutions may not currently exist, necessitating new solutions/ways of
working/technologies and proactively articulating these to the business
Review,
identify the latest emerging technologies, augmenting by services from the
leading cloud providers to solution and recommend the best next generation data
platform value driven approach for our clients
Your Key Responsibilities Include
Create
and maintain conceptual, logical and physical database models
Document
functional requirements and system specifications into the data architecture
and detailed design specifications for current and proposed designs
Document
and adhere to development standards and best practices in database designs
Maintain
highly effective and consistent communication within the team, peers, and the
leadership team
Reverse
engineer SQL code and modify it to solve problems/issues
Contribute
to the definition and implementation of data governance practices
Design
both data structures and data integration practices
Work
closely with the infrastructure teams to create a physical environment to
support data services
Evaluate
new and existing (internal and external) technologies and services in support
of data services and data analytics objectives
Skills And Attributes For Success
Understanding
of business process reengineering and business modeling concepts, business
systems development and analysis
Hands-on
experience in designing and implementing hybrid cloud and on-prem solutions
Experience
working with the latest versions of SQL Server
Experience
applying SAFe/Scrum/Kanban methodologies
Ability
to exercise judgment in solving technical, operational, and organizational
challenges
Expert
programming, performance tuning and troubleshooting skills, using the latest
popular programming languages for example python
Demonstrate
proactive approach to identifying issues and presenting solutions and options,
and where appropriate, leading to resolution
Minimum Qualifications
5+ years
demonstratable work experience as a Data Architect using data modeling tools
2-3 years
SQL coding experience on large projects
Must
possess expert SQL programming, performance tuning and troubleshooting skills
Create
database objects and SQL scripts
Understand
and developed data pipelines
Know how
to deformalize data for data science models
Experience
in python, spark and notebooks
Experience
designing data warehousing solutions
Experience
designing next generation data platforms utilising cloud services
In-depth
understanding of database structure principles
Seamlessly
able to translate business requirements to technology requirements
What We Look For
Strong
analytical skills and problem-solving ability
A
self-starter, independent-thinker, curious and creative person with ambition
and passion
Excellent
inter-personal, communication, collaboration, and presentation skills
Customer
focused
Excellent
time management skills
Positive
and constructive minded
Takes
responsibility for continuous self-learning
Takes the
lead and makes decisions in critical times and tough circumstances
Attention
to detail
High
levels of integrity and honesty
Curious
about new emerging technology
About EY
As a global leader in assurance, tax, transaction and consulting
services, we’re using the finance products, expertise and systems we’ve
developed to build a better working world. That starts with a culture that
believes in giving you the training, opportunities and creative freedom to make
things better. Whenever you join, however long you stay, the exceptional EY
experience lasts a lifetime.",3.8,"EY
3.8",Johannesburg,-1,10000+ Employees,1989,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Architect - Principal,-1,"We are looking for Principle Data Architect to join our Engineering team in Cape Town.

The world is changing.
We all want something different.
At Luno, we see you as individuals.

Together, we are upgrading the world of work to unleash the potential within and empower you to become the best possible version of yourself.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the financial landscape, and to do so, well we need the best team on board for our mission. In short, to achieve our goals, we need rockstars. As simple as that.

A little about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 5 million customers across 40 countries.
We're part of the Digital Currency Group, a group of companies driving progress in the cryptocurrency and blockchain space that includes Grayscale, Genesis, Coindesk and Foundry Services
Our platform has processed over $8 billion to date
We're proud to be one of the world's most international cryptocurrency teams from 43 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
How we work


Our engineering team (currently ~100 engineers) is split into organisations which we call Fleets. Each Fleet focuses on a core customer journey (onboarding, security, payments, support, new business, growth and marketing etc.). Each of these fleets contains multiple smaller teams called Pods, each of which focuses on a specific aspect of the product.

Pods will include a product owner, product designer, back-end engineers, Android, iOS and Web developers, who each bring a unique perspective to the problem you are all contributing towards.

We're agile, use scrum, continuous integration and continuous delivery, deploying to production every single day.

We're building teams to help us succeed in our mission to upgrade the world to a better financial system. You'll be joining a group of highly motivated software engineers who you'll work collaboratively with across our pods.

As a fast-growing company with offices around the world, you'll immediately see how your contributions directly impact both our internal users and client experience. Many of the problems we are solving result in trail blazing solutions which can't be found on Stack Overflow; so we're looking for engineers who flourish working in a complex domain.

In your first six months, you will:


...start at Luno by learning our processes, meeting the wider team and starting our engineering on-boarding program. After getting comfortable with the basics, you'll start learning our idiomatic patterns in a safe, easy-to-follow way - by building your own toy micro services. You'll get to practice how we do design docs, code reviews, deployments, events, logging and monitoring.

You'll meet the Pod(s) you'll be working with and quickly align on the teams' current OKRs and product roadmap. We succeed as a team, so we will provide you with regular feedback from your manager and peers and will encourage you to do the same.

What you'll do:
Work closely with our data science and platform teams on projects introducing new streams of data into our data lake
You will get to bring new ideas on how to further develop and innovate our data solutions and how to expose that data to the business
Accountable and Responsible for the design and architecture of Data systems that are robust and scalable.
Work in an Agile/Scrum framework or Agile mindset
Data backup/recovery and storage
Pick-up and learn new concepts, in both engineering and product, and be able to apply that knowledge quickly.
The ideal candidate for this role will have:
7+ years' experience in maintaining scalable data solutions and/or you are passionate about it
Ability to understand, communicate and advocate between build vs buy
Proven track record of setting up, restructuring and maintenance of databases
You know your way around ETL and you have experience with SQL
Experience in the AWS Data stack (RedShift,DynamoDB, Amazon RDS)
Familiarity with integrating data stores with BI platforms such as Looker, Tableau, or Power BI
You have experience with the concepts of CI/CD
Coding skills in e.g. Go, Python
Bachelor's degree in a related field preferred
AWS Certified DataOps Administrator
Be friendly, transparent, articulate and driven to succeed
Basic knowledge of and passion for digital currencies like Bitcoin
A work permit for South Africa if you are not a South African citizen
Don't be put off if you don't tick all of the boxes – they're a guide based on what we'd love to see but we appreciate that excellent software engineers have diverse backgrounds.

Remote Life at Luno


If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity / paternity and even (yes, you are reading it correctly) paw-ternity for your furry friend..
Annual Inspiration Day.. like that pottery course you've always been meaning to do!
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. You'll need to hold the legal right to work in South Africa already as we cannot provide visa sponsorship.

Be part of the change!",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer - EC2 Capacity Data Analytics,-1,"EC2 Capacity Data Analytics (CDA) team is looking for a Data Engineer to join our team.

Our team is part of the EC2 Capacity Engineering organization, which is responsible for providing the elasticity EC2 customers need to scale up/down compute resources in a cost-efficient manner. We predict customer usage across thousands of configuration combinations to deliver exactly what our customers require in just the right amount of time with just the right amount of capacity.

As a Data Engineer, you will build the ETL and analytics solutions for our internal customers to answer questions with data and drive critical improvements for the business. You will use best practices in software engineering, data management, data storage, data compute, and distributed systems. On any given day, we use Python, Scala, Java, SQL, Lambda, CloudFormation, Redshift and Glue as well as other public AWS services and a host of Amazon internal tools. We dont expect you to be an expert in, or necessarily even be familiar with all of the technologies listed above, but we do expect you to be excited to learn about them.

This position involves on-call responsibilities, typically for one week every two months. Our team is dedicated to supporting new team members. We care about your career growth, we try to assign projects and tasks based on what will help each team member develop into a more well-rounded engineer and enable them to take on more complex tasks in the future.

Our team values work-life balance and we are flexible when people occasionally need to work from home.

Job Duties
Develop and maintain automated ETL pipelines for big data using languages such as Scala, Spark, SQL and AWS services such as S3, Glue, Lambda, SNS, SQS, KMS. Example: ETL jobs that process a continuous flow of JSON source files and output the data in a business-friendly Parquet format that can be efficiently queried via Redshift Spectrum using SQL to answer business question.

Develop and maintain automated ETL monitoring and alarming solutions using Java/Python/Scala, Spark, SQL, and AWS services such as CloudWatch and Lambda.

Implement and support reporting and analytics infrastructure for internal business customers using AWS, services such Athena, Redshift, Spectrum, EMR, and QuickSight.

Develop and maintain data security and permissions solutions for enterprise scale data warehouse and data lake implementations including data encryption and database user access controls and logging.

Develop and maintain data warehouse and data lake metadata, data catalog, and user documentation for internal business customers.

Develop, test, and deploy code using internal software development toolsets. This includes the code for deploying infrastructure and solutions for secure data storage, ETL pipelines, data catalog, and data query.


Basic Qualifications

· Bachelors degree in Computer Science or related technical field, or equivalent work experience.
· 4+ years of overall work experience including Software Engineering, Data Engineering, Database Engineering, Business Intelligence.
· Experience with AWS technologies stack including Lambda, Glue, Redshift, RDS, S3, EMR or similar big data solutions stack

Preferred Qualifications

· Demonstrate efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data.
· Demonstrable proficiency in distributed systems and data architecture; design and implementation of batch and stream data processing pipelines; knows how to optimize the distribution, partitioning, and MPP of high-level data structures.

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer,-1,"Our client based in Johannesburg is urgently looking for a Data Engineer to be on a 3 months contract
Build data pipelines, experience in new tech like nifi, kafka, python

Joburg based, open to EE, 3 month contract with the option to extend, must be available at short notice",-1,EQplus,Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Overview
Job ID: 51456
Job Sector: Information Technology and Services
Country: South Africa
Region/State/Province/District: Gauteng
Location: Johannesburg

Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose

This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes

Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems

Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions

Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.
Research and best practices

Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development

Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.

Preferred Qualification and Experience

Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry

Knowledge/Technical Skills/Expertise

Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision

PLEASE NOTE: All our recruitment and selection processes comply with applicable local laws and regulations. We will never ask for money or any form of payment as part of our recruitment process. If you experience this, please contact our Fraudline on +27 800222050 or forward to TransactionFraudOpsSA@standardbank.co.za",4.1,"Standard Bank
4.1",Johannesburg,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"About us

At PBT Group we pride ourselves on being a Data Specialist organisation. With 20 years of experience in 27 countries over 3 continents, our team of 550 consultants have implemented more than 700 projects.",4.3,"PBT Group
4.3",Johannesburg,-1,Unknown,-1,Company - Private,Accounting,Accounting & Legal,Less than $1 million (USD),-1
Data Engineer,-1,"Kick-start your career in the online gaming world and experience the very latest in technology and innovation.

The Department:

Our mission is to provide our customers with the best online betting experience and share the thrill of gaming with them. Data is at the very heart of our business and is vital in everything we do.

Our cross-functional Data team has a big and exciting challenge ahead. We are in the process of re-platforming our traditional, on-premises RDBMS environment to a new microservice architecture in the cloud. We’re making use of the diverse set of data technologies in Microsoft Azure to offer new services, reporting structures and real-time data pipeline while serving the day-to-day requirements of a rapidly growing, data-hungry organisation.

Purpose of the Role:

This is an excellent opportunity for an individual who is looking to gain new skills. We are committed to creating a culture of learning and regularly run proof of concepts, provide internal demos, manage workshops and attend external conferences. Our data team has a wide range of skills including development for highly transactional RDBMS systems, data warehousing, data science and cloud technologies and we are always working to raise everyone’s game.

Duties include, but not limited to:

Work as part of an agile Data Engineering Team
Development of greenfield projects in Azure
Develop and maintain on-premises RDBMS/DW systems
Create robust ETL services and real-time data pipelines
Build and maintain Continuous Integration and DevOps pipelines
Test-driven development and pair programming with colleagues

Essential Criteria:

C#, .Net, Visual Studio
Git, Azure DevOps
NoSQL development (CosmosDB)
Demonstrable understanding of MS SQL Server in a highly transactional environment
Demonstrable understanding of development in Microsoft Azure
Able to understand query plans and identify performance bottlenecks
Test/Business-Driven Development
Building Continuous Integration/Deployment pipelines
Communicate effectively with both technical and non-technical stakeholders

Desirable Criteria:

Implementing Data Storage and Processing solutions in Azure (ARM Templates, Storage Accounts, Data Lake Storage, SQL DB, Cosmos DB, EventHubs, Function Apps, Log Analytics, Data Factory, Databricks, Polybase)
Implementing Security, Disaster Recovery, High Availability, Auditing, Monitoring and Alerting solutions in Azure
Automating tasks in Azure using Powershell / CLI
Predicting costs and optimizing spending in Azure
Message Queues (RabbitMQ, Kafka)
Python

Person Specifications:

Resilience
Teamwork
Technical Knowledge
Communication skills
Stress Tolerance
Please note we will apply relevance to our Talent Management and Talent Development Programme as part of our recruitment process.
Shortlisted candidates may need to complete an assessment.
This position requires trust and honesty it has access to customers financial details - therefore a credit and criminal record check will be conducted. The qualifications identified herein are an inherent job requirement; therefore, a qualification verification check will be done. By applying for this role, and supplying the necessary details, you hereby grant us permission to apply for these checks. This will be done in a confidential manner, and solely for the purposes of verification.

To view all current vacancies, please visit our website, www.digioutsource.com

Should you not hear from us within 2 weeks, please deem your application as unsuccessful.

The perfect place to work, play and grow!",3.9,"Digital Outsource Services
3.9",Cape Town,-1,1001 to 5000 Employees,1997,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
Data Engineer,-1,"At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes

Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.

Key Responsibilities

Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.

Key Traits

Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern

Position Requirements

2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.

Where will you work? This role will be based out of Durbanville, South Africa.",3.1,"Aculocity, LLC
3.1",Durbanville,-1,1 to 50 Employees,2006,Company - Private,IT Services,Information Technology,$1 to $5 million (USD),-1
Data Engineer,-1,"ENVIRONMENT:

A rapidly growing E-Commerce Platform seeks a highly talented Data Engineer to make an invaluable contribution to data democratisation and literacy vision by making accessible and easy-to-use data products and tools. You will require a Comp-Sci Degree or 3 years’ relevant industry experience, MySQL, PostgreSQL, Java, Python, in-depth understanding of OLAP, Data Marts, Star Scheme, Snowflake, be familiar with Jenkins, Travis, Circle CI, Docker, Kubernetes, experience with Kafka, Pub/Sub, Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks & significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing & Data Lake design and implementation and Lambda/Kappa architectures.

DUTIES:

Design, develop, test and maintain data architecture.

Prepare data for descriptive, predictive and prescriptive modelling.

Automate repetitive tasks and manual processes related with the data usage.

Optimize data delivery.

Design, develop and test large stream data pipelines to ingest, aggregate, clean, and distribute data models ready for analysis.

Ensure the highest standard in data integrity.

Leverage best practices in continuous integration and delivery.

Collaborate with other engineers, ML experts, analysts, and stakeholders to produce the most efficient and valuable solutions.

Implement features, technology, and processes that move us towards industry best practices, improving on scalability, efficiency, reliability, and security.

Operations and ownership of systems in production, responding to incidents.

REQUIREMENTS:

Qualifications –

Comp-Sci Degree or 3 years relevant industry experience.

Experience/Skills –

Open source relational database systems e.g. MySQL, PostgreSQL, etc.

Significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing, and Data Lake design and implementation and Lambda/Kappa architectures.

A thorough understanding of database and data warehousing principles e.g. OLAP, Data Marts, Star Schema, Snowflake, etc.

Java and Python.

Familiar with CI/CD tools such as Jenkins, Travis, Circle CI, etc.

Experience with Kafka, Pub/Sub, or other event-based systems.

Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks, etc.

Working in cloud environments and with containerisation frameworks, tools and platforms e.g. Docker, Kubernetes, GKE, etc.

A deep understanding of data pipelining, streaming, and Big Data technologies, methods, patterns, and techniques.

Troubleshooting complex database operations and performance issues.

Automating tasks using Shell Scripting or writing small applications.

ATTRIBUTES:

Works well with people and is passionate about helping people be their best.

A team player, an active listener, mentor, and able to communicate well.

Shows solid reasoning and decision making, with the ability to work under pressure.

Is passionate about technology, systems and data.

Is curious, always learning, and keeping up to date with the industry.

While we would really like to respond to every application, should you not be contacted for this position within 10 working days please consider your application unsuccessful.

COMMENTS:

When applying for jobs, ensure that you have the minimum job requirements. Only SA Citizens will be considered for this role. If you are not in the mentioned location of any of the jobs, please note your relocation plans in all applications for jobs and correspondence.",-1,Datafin IT Recruitment,Cape Town,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Cartrack is looking for passionate data science and engineering candidates that can join a growing team that is responsible for the intelligence and efficiency solution provision to over a million subscribers, many of whom are large fleets. We are in the midst of creating revolutionary platforms that will change the way that people interact with their vehicles.

You will have the opportunity to work with the very brightest global subject matter experts that are transforming the automotive industry across Fleet Management, Asset Management and Insurance Telematics solutions.

Get to know the role:

The role of a data engineer is a supporting one, but it is also an extremely vital one. As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements. We want to see candidates with mechanical tendencies and a desire to know how things work and to improve them.

The day-to-day activities:

Design, construct, install, test and maintain data management systems.
Build high-performance algorithms, predictive models, and prototypes.
Ensure that all systems meet the business/company requirements as well as industry practices.
Integrate up-and-coming data management and software engineering technologies into existing data structures.
Develop set processes for data mining, data modeling, and data production.
Create custom software components and analytics applications.
Research new uses for existing data.
Employ an array of technological languages and tools to connect systems together.
Install/update disaster recovery procedures.
Recommend different ways to constantly improve data reliability and quality.
Work on and maintain Data pipelines.

Requirements Essential:

At least 5 years’ proven experience as a Data Engineer, DevOps Engineer, Software Developer, or similar.
Proficient in Linux/Unix and shell scripting as well as in functional programming languages.
Expertise in setting up and explored with technologies such as Hadoop and Spark.
Bachelor’s degree in computer science, software/computer engineering, applied mathematics, or physics.",3.3,"Cartrack
3.3",Johannesburg,-1,501 to 1000 Employees,2004,Company - Private,Security Services,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Data Engineer,-1,"Data Engineers build and support data pipelines and datamarts built off those pipelines. Both must be scalable, repeatable and secure. The Data Engineer helps to facilitate gathering data from a variety of different sources, in the correct format, assuring that it conforms to data quality standards and assuring that downstream users can get to that data timeously. This role functions as a core member of an agile team. These professionals are responsible for the infrastructure that provides insights from raw data, handling and integrating diverse sources of data seamlessly. They enable solutions, by handling large volumes of data in batch and real-time by leveraging emerging technologies from both the big data and cloud spaces. Additional responsibilities include developing proof of concepts and implements complex big data solutions with a focus on collecting, parsing, managing, analysing and visualising large datasets. They know how to apply technologies to solve the problems of working with large volumes of data in diverse formats to deliver innovative solutions. Data Engineering is a technical job that requires substantial expertise in a broad range of software development and programming fields. These professionals have a knowledge of data analysis, end user requirements and business requirements analysis to develop a clear understanding of the business need and to incorporate these needs into a technical solution. They have a solid understanding of physical database design and the systems development lifecycle. This role must work well in a team environment.

Job Objectives

Work Complexity: * Architects Data analytics framework. * Translates complex functional and technical requirements into detailed architecture, design, and high performing software. * Leads Data and batch/real-time analytical solutions leveraging transformational technologies. * Works on multiple projects as a technical lead driving user story analysis and elaboration, design and development of software applications, testing, and builds automation tools.

Main Job Objectives: 1. Development and Operations 2. Database Development and Operations 3. Policies, Standards and Procedures 4. Communications 5. Business Continuity & Disaster Recovery 6. Research and Evaluation 7. Coaching/ Mentoring

Qualifications

Essential: 4 years Bachelors degree in computer science, computer engineering, or equivalent work experience AWS Certification at least to associate level

Experience

Essential:

5+ years Data engineering or software engineering

3-5 years demonstrated experience leading teams of engineers

2+ years Big Data experience

5+ years experience with Extract Transform and Load (ETL) processes

2+ years Could AWS experience

At least 2 years demonstrated experience with agile or other rapid application development methods - Agile exposure, Kanban or Scrum

5 years demonstrated experience with object oriented design, coding and testing patterns as well as experience in engineering (commercial or open source) software platforms and large scale data infrastructures.

Desirable:

5+ years Retail Operations experience

Knowledge and Skills

Essential: *Creating data feeds from on-premise to AWS Cloud (2 years) *Support data feeds in production on break fix basis (2 years) *Creating data marts using Talend or similar ETL development tool (4 years) *Manipulating data using python and pyspark (2 years) *Processing data using the Hadoop paradigm particularly using EMR, AWSs distribution of Hadoop (2 years) *Devop for Big Data and Business Intelligence including automated testing and deployment (2 years) * Extensive knowledge in different programming or scripting languages * Expert knowledge of data modeling and understanding of different data structures and their benefits and limitations under particular use cases.

Further technical skills required: * Capability to architect highly scalable distributed systems, using different open source tools. * Big Data batch and streaming tools * Talend (1 year) * AWS: EMR, EC2, S3 (1 year) * Python (1 year) * PySpark or Spark (1 year) - Desirable * Business Intelligence Data modelling (3 years) * SQL (3 years)",-1,Datonomy Solutions,Brackenfell,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We are assisting one of our clients that is based in Pretoria to fill a role of a Data Engineer

This is a 12 month contract role

Objective of this Scope of Work

The Data Engineer will drive improvement of the data management maturity levels and provide the necessary technical support within the company to support reliable and effective decision-making, appropriate usage and protection thereof.

Scope of Services Definition

The scope will include but will not be limited to:

ï†· To develop, construct, test and maintain architectures.

ï†· To ensure architectures will support the requirements of business.

ï†· To discover opportunities for data acquisition and sharing.

ï†· To develop data set processes for data modelling, mining and production.

ï†· To employ a variety of languages and tools to marry systems together.

ï†· To recommend way to improve data reliability, efficiency and quality.

ï†· To prepare data for use in predictive and prescriptive modelling.

ï†· To conduct research to answer industry and business questions.

ï†· To leverage volumes of data from internal and external to answer business questions.

ï†· To develop and manage stakeholder relations effectively to promote data management across the organisation and support reliable decision making and appropriate data usage.

ï†· To participate and provide technical support in cross organisational activities relating to any of the above mentioned data management activities.

ï†· To provide regular progress reports as per stakeholder requirements and present data management updates in various forums as required.

Minimum qualification Required:

ï†· A minimum of a Bachelors degree in Computer Science or Information Management OR equivalent;

ï†· A minimum of five to eight years experience in a data management environment",-1,HR Genie,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Our client based in the Northern Suburbs, is currently looking for a Data Engineer to join their team.

Responsibilities
Our client is a dynamic IT company that delivers value-driven IT solutions to the group. Our work lives revolve around our DNA. We take pride in our work, treat our colleagues, partners and our country with respect. We exercise collaborative decision-making and believe in having a balance in life. We do this all while having fun and enjoying what we do.

The primary focus of this position is to use technical skills to put software, systems and data together in a way that extracts meaningful insights from raw data. You will need to be helpful and supportive to your team and fellow developers. You join an energetic, focused and dynamic team.

Interact with clients to understand requirements and business problems/needs

Identify, analyse, visualise and understand supporting data to propose solid solutions

Create technical documentation for reference and reporting

Support existing solutions within GCP and Oracle

Doing standby on a rotating basis

Key Competencies and Qualifications

Matric

Tertiary qualification in IT

Preferred cloud experience in AWS/AZURE/GCP

At least 3 years of data warehouse ETL experience

Dimensional Modelling

Data analyses

Experience with data visualization and visualization tool(s)

Knowledge of the retail industry will be beneficial

Understanding and experience with version control SVN/GIT

Preferred – Korn shell scripting, Python/Java, SQL

Google Cloud Platform experience would be looked upon favourably

Having a broad understanding of different SDLC’s

Preferred agile experience

Strengths

The natural tendency to take ownership and responsibility

Strong problem solving, critical thinking, effective planning and organisational skills

Detail-oriented with excellent communication skills

You have a can-do attitude and positive outlook on life

Can cope under pressure

Curious and interested in analysing problems and possible solutions

Strong team player

Self-driven learner, passionate about new technology

Above all, be passionate about what you do

Should you wish to apply for the position, please apply directly via this job board, please ensure that you quote reference number 201620 subject heading or email body.

Please note that due to the high volume of CV's received; only shortlisted applicants will be contacted. Should you not receive communication from our offices within two weeks of submission please note that your application will not be considered for this position.

We will keep your CV on file and re-establish contact with you should opportunities in line with your expertise become available again.

Should you require any additional information give us a call on 021 012 5566.",-1,Surgo HR & Training,Cape Town,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We believe that our employees fuel our organization, essential to enable us to help our customers overcome their business challenges and achieve sustainable growth. As a result, we are committed to growing each individual and providing them with the challenges, feedback and support needed to achieve success in their career

If this sounds appealing, and like us, you get excited about data: its collection, storage, transformation or display, see if you’ve got what it takes to join our sought after DATA team.

Key Responsibilities And/or Outputs

You will represent IQbusiness at our customers, sometimes alone, and sometimes as part of an IQ team.

Providing a superior customer experience by building and maintaining relationships, working at customer offices, keeping data confidential
Design and develop – databases, SQL queries, stored procedures, reports, dashboards or integration solutions
Produce solutions for both real-time and batch environments
Test your work to ensure compliance
Solve problems, and do root cause analysis
Prioritize your workload
Assist in other areas relating to your true data function, such as data modeling, data and business analysts
Interact with a variety of individuals: senior, junior, technical and from business
Provide guidance to fellow colleagues, or even manage a team
Uphold the IQ values, which are to care, learn & share; innovate; deliver as well as to build, enhance and maintain relationships

Education

Matric pass
A tertiary qualification, preferably in an ICT relevant field
Appropriate Microsoft certifications are beneficial but not required

Requirements

3 - 6 years experience in the Data Engineering environments and technologies
Great communication skills
A passion for SQL, databases or reports
Can you write stored procedures, design complex queries and create views and triggers?
Are you able to work out the relationships in a data warehouse or the aggregation of a cube?
Do you extract and display useful information when you see patterns and trends in data?
Strong knowledge of the financial services industry, ideally in a consulting role
The use of data related software: databases, ETL and BI tools; report writing and analytical tools
We use a lot of Microsoft products. You may often be expected to use MS SQL Server, SSIS, SSRS, SSAS and Power BI to develop solutions
What other relevant software have you’ve used?
Ability to work in different project methodologies: Waterfall and/or Agile
Knowledge of full SDLC
Exposure to logical and physical data modeling

Equal Employment Opportunity

IQbusiness is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, citizenship, marital, domestic or civil partnership status, sexual orientation, or gender identity",3.7,"IQbusiness South Africa
3.7",Johannesburg,-1,1 to 50 Employees,-1,Company - Private,Consulting,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"We value a data engineer as someone who works behind the scenes to obtain, process and supply data via various methodologies and technologies, to various consumers, in ways and forms that makes sense and add value. This definition is very broad, as the field of data engineering is just as broad.

You may be the type of data engineer that develops API endpoints for the consumption of data by end users or even another data pipeline, or you may be the type of data engineer that develops highly distributed, high availability data processing pipelines in an effort to satisfy the need of the ever questioning data analysts and/or data scientists.

You have awesome knowledge about the following concepts
Data modelling
Relational data modelling in traditional relational database management systems. (Microsoft SQL Server, MySQL, PostgreSQL, etc)
Coercing unstructured and semi-structured data into a structured form.
Data pipelining knowledge - data extraction and transformation.
Data transformation knowledge for reporting and analytics purposes.
Knowledge of the MapReduce and related data processing paradigms would be a boon.
You have the following technical competencies
Writing SQL queries, that can relate, transform and aggregate data from many differing sources where natural keys may or may not exist.
Experience with writing data pipelines that move and transform data, for various uses.
Working knowledge of a general purpose programming language like Python would be a boost.
Working knowledge of columnar databases such as Google BigQuery, and SAP HANA would be a boost.
Working knowledge of highly distributed technologies such as Apache Hadoop or Apache Spark would be a boost.
Working knowledge of NoSQL technologies, such as Apache Solr would be a boost.
You have the following personal competencies
The ability to solve problems.
The ability to rotate around a problem, to see if solutions can be gained in different ways.
The ability to work in an ever changing, unstructured environment.
The ability to work as part of a team, with vastly differing skill sets and opinions.
The ability to contribute ideas to the quorum.
The ability to mentor and provide guidance for other team members.
A systems approach to thinking, as opposed to a siloed approach. The candidate needs to understand how their work affects the greater system.
The ability to work without supervision, and take accountability for the work they deliver.
The ability to liaise with a client, sifting through the fluff and extracting the actual requirements.
If this is you - apply now and we'll get in touch",-1,DotModus,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Data Engineer

Our client in the contact centre space is currently seeking a DATA ENGINEER that will work on the collecting, storing, processing, and analyzing of large datasets. The primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them. You will also be responsible for integrating them with the architecture used across the company.

Key Performance Areas:

Data reporting.
Implementing ETL processes.
Defining data retention policies.
Management of Customer Lead data.
Provision of data for advanced analytics.
Maintenance of internal client scorecards.
Assist team in resolving data-related support queries.
Optimize existing data processes through automation.
Assist with all data-related reporting and documentation.
Maintenance and optimisation of the Analytics database.
Provide technical support to and supervision of junior data administrators.
Continuous upskilling on new technologies, frameworks and market trends.
Monitoring performance and advising any necessary infrastructure changes.
Identifying, selecting and integrating any Big Data tools and frameworks required to provide real-time analytics.

Educational Requirements

IT related Degree or Diploma is a pre-requisite

Required Skills/Experience

ETL tools: Advanced SSIS
BI/Reporting : Qlikview/Power BI/ SSRS or SSAS
Programming languages: JAVA, C# , Python, SAS or R
Experience with NoSQL databases and/or campaign management tools will be advantageous.
Minimum 3 years’ applicable work experience in SQL, relational databases and data manipulation.
Experience in big data platforms (eg. Hadoop) or processing frameworks (eg. MapReduce/Spark) and querying tools (eg. Pig, Hive and Impala) will be highly beneficial.

Preferred Skills

Organizational skills
Experience in Attentional to detail.
Accountability is critical for this role.
Ability to work under pressure and meet deadlines.
Solid understanding of database design principles.
Should you not receive a response in 2 weeks please consider your application unsuccessful",-1,Rubik's Cubed Consulting,Durban,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"This well known company is looking for a Data Engineer. will be based in Rivonia
The ideal candidate will have strong experience in the following:
Data cleaning
SQL Export
Big data Sets

BSc Degree in Maths and Stats will be required
a min of 3 years experience.
Stable track record is required.

Send your Cv to marinda@prrrecruitment.co.za",-1,PRR Recruitment Services,Johannesburg,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Description

Position at Aculocity, LLC

At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes
Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.
Key Responsibilities
Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.
Key Traits
Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern
Position Requirements
2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.
Where will you work? This role will be based out of Durbanville, South Africa.",-1,GVW,Durbanville,-1,Unknown,-1,Unknown,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Information Technology, Gauteng JHB - Northern Suburbs

Market related - Market related Annually

An IT Consultancy Business based in Johannesburg is currently looking for a Business Intelligence Consultant / Data Engineering Consultant.

Requirements:

Extensive experience in data engineering
Experience in Business Intelligence, data and Power BI
Extensive experience in data governance and the Popi act
Ability to assess and make recommendations on data within the Popi act
Good understanding of T-SQL and query optimization, developing ETL strategies.
Good understanding with SQL Server 2008/2012, SSIS, SSRS and SSAS
Use SSIS to create ETL packages to validate, extract, transform, and load data into the data warehouse and data marts.
Deploy and configured the reports in the Report Server (SSRS).
Excellent experience in Tabular Modelling , PowerView, Qlikvie,w, and Power BI
Maintain ETL
Qlikview model
Create Drill-through, Drill-down, and Cross Tab Reports and Sub-Report using Report Definition Language (RDL).
Generate periodic reports based on the statistical analysis of the data using SQL Server Reporting Services (SSRS)
Advise and provide written technical documentation and recommendations

The information displayed above is not limited to advertisements. Please contact Thato for further information.

Please consider your application as unsuccessful if you have not received a response within 14 days of submitting your application. However, please keep a lookout on our website, www.bedifferent.co.za, for available positions that you may be suited for

Ad Visible Until: 29 October 2020
Ref: JHB005346/NL

Vacancy Type: Permanent",2.9,"Be Different Recruitment
2.9",Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Cloud Support Engineer (Big Data),-1,"ABOUT US

Amazon Web Services is the market leader and technology forerunner in the Cloud business. As a member of the AWS Support team you will be at the forefront of this transformational technology, assisting a global list of companies and developers that are taking advantage of a growing set of services and features to run their mission-critical applications. As a Cloud Support Engineer, you will act as the Cloud Ambassador across all the cloud products, arming our customers with required tools & tactics to get the most out of their Product and Support investment.

Would you like to use the latest cloud computing technologies? Do you have an interest in helping customers understand application architectures and integration approaches? Are you familiar with best practices for applications, servers and networks? Do you want to be part of a customer facing technology team helping to ensure the success of Amazon Web Services (AWS) as a leading technology organization?

If you fit the description, you might be the person we are looking for! We are a group of smart people, passionate about cloud computing, and believe that world class support is critical to customer success.

WHAT CAN YOU EXPECT FROM A LIFE AT AWS?

Every day will bring new and exciting challenges on the job while you:

· Learn and use groundbreaking technologies.
· Apply advanced troubleshooting techniques to provide unique solutions to our customers' individual needs.
· Interact with leading engineers around the world.
· Partner with Amazon Web Services teams to help reproduce and resolve customer issues.
· Leverage your extensive customer support experience to provide feedback to internal AWS teams on how to improve our services.
· Drive customer communication during critical events.
· Drive projects that improve support-related processes and our customers technical support experience.
· Write tutorials, how-to videos, and other technical articles for the developer community.
· Work on critical, highly complex customer problems that may span multiple AWS services.

WHY AWS SUPPORT?

· First and foremost this is a customer support role in The Cloud.
· On a typical day, a Support Engineer will be primarily responsible for solving customers cases through a variety of customer contact channels which include telephone, email, and web/live chat. You will apply advanced troubleshooting techniques to provide tailored solutions for our customers and drive customer interactions by thoughtfully working with customers to dive deep into the root cause of an issue.
· Apart from working on a broad spectrum of technical issues, an AWS Support Engineer may also coach/mentor new hires, develop & present training, partner with development teams on complex issues or contact deflection initiatives, participate in new hiring, write tools/script to help the team, or work with leadership on process improvement and strategic initiatives.
· Career development: We promote advancement opportunities across the organization to help you meet your career goals.
· Training: We have training programs to help you develop the skills required to be successful in your role.
· We hire smart people who are keen to build a career with AWS, so we are more interested in the areas that you do know instead of those you havent been exposed to yet.
· Support engineers interested in travel have presented training or participated in focused summits across our sites or at specific AWS events.
· As we operate on a follow-the-sun model, with Premium Support sites located globally, there is no after hours on-call or mandated overtime in this role.
· https://www.youtube.com/watch?v=GC3bWcFFZTo&t=24s



Basic Qualifications

The Big Data role supports our services that leverage data and produce business insights, which may include using Machine Learning/Artificial Intelligence (ML/AI). Helping our customers use and integrate Big Data services in what is arguably our industrys most exciting space. The portfolio of services covers EMR (Hadoop), DynamoDB (NoSQL), MangoDB, and Apache Cassandra.

· Advanced experience in Apache Hadoop, Apache Spark, Apache Hive, and Presto
· Advanced experience in DynamoDB or NoSQL technologies like MongoDB or Cassandra
· Advanced experience with System Administration with Linux (RHEL/CentOS) including Microsoft Active Directory, and LDAP integration.
· Experience with troubleshooting Kerberos Authentication problems.
· Experience with Network troubleshooting.
· Basic understanding of Machine Learning and statistics
· Experience with Java and Python and shell scripting
· Bachelors degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position



Preferred Qualifications

· Expert experience in the Hadoop Ecosystem including Apache Spark and Presto
· Expert experience in NoSQL
· Expert experience with blockchain technologies like Etherium Expert experience in data Data Lake architecture and administration
· Experience managing full application stacks from the OS up through custom applications
· Prior work experience with AWS - any or all of EC2, VPC, S3, RDS, EMR, Glue, SageMaker
· Excellent knowledge of Hadoop architecture, administration and support
· Expert understanding of distributed computing principles and their application in the cloud
· Good understanding of distributed computing environments Lead technical discussions on big data systems architecture and design
· Strong analysis and troubleshooting skills and experience
· AWS Certified Solutions Architect
· AWS certified Big Data Specialty
· Masters degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity and Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Response Center Engineer,-1,"Job Title
Response Center Engineer
Job Description


Philips is a world leading health technology company with a vision to make life better for people worldwide through meaningful innovation. Making good on this promise depends on our passionate, inspirational, collaborative and diverse team. We have over 80,000+ brilliant people around the world but are always looking for more. Like-minded, motivated, focused minds to join us in creating a healthier, more connected society while transforming themselves personally and professionally.

As a CCC Coordinator - Response Center Engineer you will have the opportunity to process customer calls and be responsible for screening and diagnosing professionally Healthcare equipment to support customers and colleagues remotely with solving technical issues and ensuring maximum customer satisfaction

You are responsible for:
Diagnose healthcare equipment to the quality standards set by Philips Healthcare (PH) remotely by interviewing customers or colleagues by telephone or by remotely logging in to the system
Advise Customer Care Center Coordinators and District Operations Managers and / or Team Leads about the best follow-up w.r.t. technical state of the diagnosed healthcare equipment
Advise the Customer Care Center Coordinators or Field Services Engineers about required spare parts and resources
Responsible for planning engineers related to Modality responsibility.
Responsible for coordination between CCC, CUSTOMER, Spare parts AND Engineer.
Responsible to drive Remote and FTR KPI’s to targets respectively 40% and 85%.
Will require minimal field work to keep abreast of technical capabilities.
Take calls from customers and make sure they are processed in the CCC ERP on timely manner including all relevant data
Support Field Services Engineers in the field with technical knowledge
Escalate technical issues to the Technical Support Specialist
Escalate technical issues to Business Unit support after consultation of the Technical Support Specialist
Monitor critical functions of the equipment’s in the IB and environmental conditions including RSN and True reachability.
Lead the planning and implementation of FSN’s and FCO’s accelerating remote implementation where applicable.
Submit timely and accurate service data, job sheets, reports, expense claims, radiation film badges, field problem reports and other paperwork as assigned
Keep abreast of new technologies likely to affect PH range of products
Use company property with care to ensure optimal results with minimal operational costs
Be a professional representative for PH with respect to customer problems, ensuring personal acceptability by the customer in behavior in accordance with PH policy and targets
Conform to PH safety standards including health and safety regulations and in the event of hazards or accidents to take immediate control of the situation and involve the Operations Manager and / or the responsible person to handle properly confidential issues according Philips standards and to act according General Business Principals
Follow all quality standards within the frame of valid PH business policies
Follow the company quality regulations (ISO 9001; PQA; TQM) and internal directives and procedures
You are a part of the dynamic South Africa Customer Care Centre Team .You will be reporting to the Customer Care Center Manager.

Requires a pleasant, assertive individual you can work very well in a team setting, a dynamic environment that requires flexibility and creativeness to achieve goals.

To succeed in this role, you should have the following skills and experience:
Degree level education or equivalent
Experience in maintenance and troubleshooting of technical complex systems
Fluent in English, verbal and written in addition to local language
In return, we offer you the unique combination of a critical and challenging role and a creative and empowering office environment. You will be actively encouraged to make improvements, establish best in class service and have a direct impact on the success of Philips on a daily basis.

Employment Equity

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply. Only apply for this role if you are a South African Citizen by birth or Naturalization prior to the 27 April 1994.

Why should you join Philips?

Working at Philips is more than a job. It’s a calling to create a healthier society through meaningful work, focused on improving 3 billion lives a year by delivering innovative solutions across the health continuum. Our people experience a variety of unexpected moments when their lives and careers come together in meaningful ways. Learn more by watching this video.

To find out more about what it’s like working for Philips at a personal level, visit the Working at Philips page on our career website, where you can read stories from our employee blog. Once there, you can also learn about our recruitment process, or find answers to some of the frequently asked questions.

Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.9,"Philips
3.9",Johannesburg,-1,10000+ Employees,1891,Company - Public,Health Care Services & Hospitals,Health Care,$10 to $25 million (USD),-1
Software Development Engineer - EC2 Placement,-1,"Build the systems that optimize how EC2 matches requests for Instances with the underlying compute capacity. EC2 Placement is seeking talented engineers to build the online and offline optimization systems for compute workload scheduling, and the customer capabilities to better manage those workloads. Amazon EC2 provides on-demand scalable compute capacity, and powers some of the largest services in the world. You will collaborate with a top-tier community of engineers to build systems to improve how customers are able to access EC2 compute resources.

The successful candidate will have strong software engineering experience, with a passion for thinking about, building and testing distributed systems. You have an interest in how Machine Learning and other optimization techniques can be applied to large-scale problems. You have demonstrated experience working with a team to design, build and operate large-scale systems. With strong engineering fundamentals, an analytical and data-driven approach to your work, and strong communication skills, you have the ability to collaborate well to deliver results. We move fast and work together on small teams to solve big problems.

If this opportunity sounds interesting, we would love to talk to you more about our work and the vibrant culture at AWS in Cape Town.

Basic Qualifications

· Degree in Computer Science or related field, or equivalent working experience
· 3+ years of industry experience in a software development environment
· Strong Computer Science fundamentals, including data structures, object-oriented design, algorithm design, problem solving, and complexity analysis.
· Proficiency in at least one modern programming language, such as Java, C#, Python, Scala, Kotlin

Preferred Qualifications

One or more of the following help you stand out:
· Demonstrated results designing, building and operating high-performance distributed systems in large-scale Linux environments
· Role model in writing high-quality, maintainable and secure code, mentoring others, and helping teams sharpen their development processes
· Ability to work effectively across teams to deliver results, with strong verbal and written communication skills
· Experience working with machine learning systems

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer - PBB IT,-1,"Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose


This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes
Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems
Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions
Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.

Research and best practices
Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development
Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.
Preferred Qualification and Experience
Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Aws Data Platform Engineer,-1,"Aws Data Platform Engineer

Posting Country:

South Africa

Date Posted:

15-Oct-2020

Full Time / Part Time:

Full Time

Contract Type:

Permanent

Joining Vodacom is more than a job, what we do matters. We don’t just carry minutes, texts and data – we carry people’s lives. And that’s a huge responsibility. If you think for a minute about the people you rely on…the likelihood is they rely on us.

Customers are at the heart of everything we do and we want to make a difference to the lives of our customers, and the communities in which we live and work. We support our people to give something back to the causes that mean the most to them through helping them give time and money to the charities they love.

And what’s it like to work here? We have created an environment where you can look forward to coming to work and are empowered to be at your best. We offer flexibility in how you work that helps you do your job in a way that suits you, opportunities to help you grow and progress throughout your career and a choice of benefits to suit your lifestyle.

Role Purpose
The H Band AWS Data Platform Engineer position is based within the Technology Business Unit.

The AWS Data Platform Engineer will be responsible for all Database services such as RDS, DynamoDB, etc. Should be able to migrate any databases from anywhere to AWS using any third-party tools or AWS database migration tool. Should also have understanding or expertise in creating data warehouses and data lake solutions on AWS.
Your responsibilities will include:
Apply practical knowledge of relational database design and usage with customers
Perform workload analysis and undertake performance tuning, as well as performance benchmarking in customer environments.
To develop state of the art solutions which are technically sound.
To provide a high-quality service to the Enterprise Cloud Services clients i.t.o. consultancy, solutions and delivery.
Commitment to team success and positive team dynamics including mentoring of other team members.
Passion for growing and applying technical skills in service to customers.
Be a trusted infrastructure advisor by providing objective, practical and relevant ideas, insights and advice.
Work collaboratively with consulting partners and technology teams to ensure high quality of solution delivery.
Encourage best practice and knowledge sharing with partners and cross-functional groups
Manage the overall database design and delivery of solutions.
Ability to make recommendations as they pertain to improvements in support/development initiatives and facilitate implementation with partners and cross-functional groups within the Business.
Participate in high level database solution definition and design during the implementation phase with the goal of providing reliable, stable and operationally sound applications that meet the Business requirements.
Ability to understand and translate business requirements into technical specifications
The ideal candidate will have:
A minimum of 3 years of industry related experience of which 1 year must be within a complex hosting environment.
Certifications in Database design, system architecture or cloud technologies.
Demonstrate knowledge of database systems internals including storage layouts and distributed databases/MPP architectures
Advanced SQL coding, tuning and query optimization.
Experience designing and leading database performance benchmarks.
Good knowledge of the different AWS services
Knowledge of cloud networking architecture, cloud operations, security, automation and orchestration.
Knowledge of database internals as it relates to query and system performance and tuning.
Understanding of overall system architecture, scalability, reliability, and performance in a database environment.
Excellent teamwork, time-management and organizational skills.
Perform other duties as deemed necessary and assigned by the customer and management
Strong interpersonal skills and problem-solving abilities.
Excellent documentation, communication and interpersonal skills.
Excellent analytical and problem-solving abilities.
Closing date for applications: Monday, 13 April 2020

The base location for this role is Vodacom World, Midrand

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply.
Vodacom is committed to an organisational culture that recognises, appreciates and values diversity & inclusion.

Commitment from Vodacom

Vodacom is committed to attracting, developing and retaining the very best people by offering a flexible, motivating and inclusive workplace in which talent is truly recognized, developed and rewarded. We believe that diversity plays an important role in the success of our business and we are committed to creating an inclusive work environment which respects, values, celebrates and makes the most of people’s individual differences - we are not only multinational but multicultural too. At Vodacom you will have access to our excellent flexible benefits programme that you would expect from any global company.",3.9,"Vodafone
3.9",Midrand,-1,10000+ Employees,1982,Company - Public,"Cable, Internet & Telephone Providers",Telecommunications,$10+ billion (USD),-1
Data Engineer Azure Data Factory,-1,"Enthuzex is looking for a motivated Lead Data Engineer to contribute towards the success of our Data and Analytics Technology initiatives. This is a hands-on technical role and this person will be responsible for the development and build of scalable solutions as it relates to the architecture strategies, data standards, digital data management, data integration, tools, and technology. The right candidate will play a deep dive hands-on critical development role in the digital transformation and in shaping how we acquire, ingest, transform and deliver data through the digital consumer channels.

Responsibilities:

Architect, design, develop and engineering end-to-end data pipelines across multiple data sources and systems of record.
Ensure data quality, integrity, security and completeness throughout the data lifecycle
Develop, design data models, data structures and ETL jobs for data acquisition and manipulation purposes
Develop deep understanding of the data sources, implement data standards, maintain data quality and master data management
Developing data services and API
Work closely with the cloud service providers to ensure completeness and alignment with the service offerings
Manage and maintain cloud based data and analytics platform
Deep understanding of the cloud offerings and engage in quick proof of concepts and proof of value in prototyping data and analytics solutions and derive viability
Ability to interact with the business stakeholders to understand requirements and translating into technology solutions

Expirience:

Experience in Cloud platform AWS or Azure eco-system. (Azure preferred)
Data Engineering/Development experience with SQL (Oracle, SQL Server, MySQL)
Strong development background creating pipelines and complex data transformations and manipulations using one of the languages Python, Java, R, or Scala with Databricks/Spark
Experience in NoSQL Databases and Big data technologies including Hadoop
Experience with API / RESTful data services
Worked on real-time data capture, processing and storing using technologies like Azure Event Hubs and Analytics
Experience working with different data storage options including AWS S3, Azure BLOB storage etc.
Understanding of different data formats including Parquet, Avro, CSV, ORC etc.
Prior experience with MPP databases and maintain large amount of data processing
Experience with Azure Data Factory and Azure Data Catalog is a big plus and mandatory
Experience with Microsoft/Azure ETL solutions and business Intelligence technologies is a big and mandatory
Past working experience on a fast paced and agile environment
Perform ongoing monitoring, automation and refinement of data engineering solutions
Experience in leading high visibility transformation projects that interacts with multiple business lines
Build and meet project timelines and manage delivery commitments with proper communication to management

Qualifications

Bachelor’s degree with 4+ years of relevant experience
Willingness to learn new technologies and thrive in an extremely fast paced environment
Team player and easy to work with.

Applicants must demonstrate their ability to master new enterprise level technologies. Successful applicants will exemplify Enthuzex ethical principles of uncompromising integrity, respect for others, and accountability for decisions

send cv's info@enthuzex.co.za",-1,Enthuzex,Leslie,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Scientist,-1,"The world is changing.

We all want something different.

At Luno, we see you as an individual.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the world, and to do so, we need the best team on board for our mission.

A bit about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 3 million customers across 40 countries.
We are Series B funded, backed by Balderton Capital and the Naspers Group.
Our platform has processed over 8 billion dollars since we've launched
We're proud to be one of the world's most international cryptocurrency teams from 26 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
The role in a nutshell:

Identifying opportunities in the business that could benefit most from cognitive applications, as well as building and enhancing organisational capabilities for deriving value from multiple data sources using data science.

What we'd like you to have:
Bachelor's degree or higher in the natural sciences or technical fields such as Mathematics, Statistics, Computer Science, Engineering or Economics
Enthusiasm to work in the cryptocurrencies space
Advanced SQL skills
Solid understanding of exploratory data analysis, predictive analytics, and optimisation using Python, R, Matlab, RapidMiner, KNIME or other data science-oriented platforms
Proficiency in the use of data science and machine learning domain-specific languages such as ""Caret"" and the ""Tidyverse"" suite of tools in R, or ""Pandas"" in Python
Strong interpersonal and communication skills
Communicating data insights using storytelling narratives
Ability to work independently, as well as within and across teams
Ability to successfully complete projects with large and/or incomplete data sets
More about what you'll be doing:
Optimising product performance by tracking and analysing customer behaviour on web and app, in collaboration with software engineers and product designers
Providing the business with reports and dashboards, on key performance metrics
Developing metrics to accurately assess the health of our Exchange platform
Comparative data-driven analysis of our Exchange against alternative platforms
Formulating business requirements into analytical objectives
Designing and running experiments to test hypotheses
Hacking through complex business problems using advanced data analysis to provide insights and recommendations
Building, maintaining, and optimising decisioning systems using advanced statistical and predictive modelling techniques
What will set you apart:
An advanced degree in Mathematics, Statistics, Computer Science or related field
At least 3 years' experience working in a similar role
A basic understanding of trading in financial markets
Experience working with a data analytics and visualisation platform such as Tableau, Cognos, QlikView, or Looker
Familiarity with using Google Analytics to understand customer behaviour
Solid knowledge of statistical and machine learning techniques
Familiarity with modern distributed data storage and processing systems such as Amazon Redshift, Big Query, Snowflake, Databricks and Apache Spark
You can gather and synthesise facts, theories, trends, patterns, inferences, and key issues in complex and variable situations
Ability to diagnose problems using formal problem-solving tools and techniques from multiple angles to generate multiple possible solutions
A sense of anticipating long-term problem areas and associated risk levels with objective rationale
Remote Life at Luno

If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
You'll be able to continuously upskill yourself with access to free online learning via MyAcademy, an international teaching marketplace with over 100000 courses from Harvard and other leading providers + share knowledge with your peers.
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity and paternity leave, and you can even take paw-ternity leave for your furry friend.
Annual Inspiration Day! Make time for that pottery course or spa day you've always wanted to do.
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"EY is a global leader in
assurance, tax, transaction and advisory services. Technology is at the heart
of what we do and deliver at EY. Technology solutions are integrated in the
client services we deliver and are key to our innovation as an organization.

Fueled by
strategic investment in technology and innovation, Client Technology seeks to
drive growth opportunities and solve complex business problems for our clients
through building a robust platform for business and powerful product engine
that are vital to innovation at scale. As part of Client Technology, you’ll
work with technologists and business experts, blending EY’s deep industry
knowledge and innovative ideas with our platforms, capabilities, and technical
expertise. As a catalyst for change and growth, you’ll be at the forefront of
integrating emerging technologies from AI to Data Analytics into every corner
of what we do at EY. That means more growth for you, exciting learning
opportunities, career choices, and the chance to make a real impact.

The selected
candidate
Develops
large and complex data architecture, composed of models, policies, rules or
standards that govern which data is collected and how it is stored, arranged,
integrated and put to use in data systems, including the design, build and
management of data infrastructure to address business requirements
Creates
sound use case driven roadmaps, depicting data architecture as-is and to-be
capabilities with the business by engaging with multidisciplinary teams, and by
identifying, managing and mitigating risk
Develops
relationships across the business to understand data requirements, applies deep
technical knowledge of data management to solve business problems in areas
where solutions may not currently exist, necessitating new solutions/ways of
working/technologies and proactively articulating these to the business
Review,
identify the latest emerging technologies, augmenting by services from the
leading cloud providers to solution and recommend the best next generation data
platform value driven approach for our clients
Your Key Responsibilities Include
Create
and maintain conceptual, logical and physical database models
Document
functional requirements and system specifications into the data architecture
and detailed design specifications for current and proposed designs
Document
and adhere to development standards and best practices in database designs
Maintain
highly effective and consistent communication within the team, peers, and the
leadership team
Reverse
engineer SQL code and modify it to solve problems/issues
Contribute
to the definition and implementation of data governance practices
Design
both data structures and data integration practices
Work
closely with the infrastructure teams to create a physical environment to
support data services
Evaluate
new and existing (internal and external) technologies and services in support
of data services and data analytics objectives
Skills And Attributes For Success
Understanding
of business process reengineering and business modeling concepts, business
systems development and analysis
Hands-on
experience in designing and implementing hybrid cloud and on-prem solutions
Experience
working with the latest versions of SQL Server
Experience
applying SAFe/Scrum/Kanban methodologies
Ability
to exercise judgment in solving technical, operational, and organizational
challenges
Expert
programming, performance tuning and troubleshooting skills, using the latest
popular programming languages for example python
Demonstrate
proactive approach to identifying issues and presenting solutions and options,
and where appropriate, leading to resolution
Minimum Qualifications
5+ years
demonstratable work experience as a Data Architect using data modeling tools
2-3 years
SQL coding experience on large projects
Must
possess expert SQL programming, performance tuning and troubleshooting skills
Create
database objects and SQL scripts
Understand
and developed data pipelines
Know how
to deformalize data for data science models
Experience
in python, spark and notebooks
Experience
designing data warehousing solutions
Experience
designing next generation data platforms utilising cloud services
In-depth
understanding of database structure principles
Seamlessly
able to translate business requirements to technology requirements
What We Look For
Strong
analytical skills and problem-solving ability
A
self-starter, independent-thinker, curious and creative person with ambition
and passion
Excellent
inter-personal, communication, collaboration, and presentation skills
Customer
focused
Excellent
time management skills
Positive
and constructive minded
Takes
responsibility for continuous self-learning
Takes the
lead and makes decisions in critical times and tough circumstances
Attention
to detail
High
levels of integrity and honesty
Curious
about new emerging technology
About EY
As a global leader in assurance, tax, transaction and consulting
services, we’re using the finance products, expertise and systems we’ve
developed to build a better working world. That starts with a culture that
believes in giving you the training, opportunities and creative freedom to make
things better. Whenever you join, however long you stay, the exceptional EY
experience lasts a lifetime.",3.8,"EY
3.8",Johannesburg,-1,10000+ Employees,1989,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Architect - Principal,-1,"We are looking for Principle Data Architect to join our Engineering team in Cape Town.

The world is changing.
We all want something different.
At Luno, we see you as individuals.

Together, we are upgrading the world of work to unleash the potential within and empower you to become the best possible version of yourself.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the financial landscape, and to do so, well we need the best team on board for our mission. In short, to achieve our goals, we need rockstars. As simple as that.

A little about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 5 million customers across 40 countries.
We're part of the Digital Currency Group, a group of companies driving progress in the cryptocurrency and blockchain space that includes Grayscale, Genesis, Coindesk and Foundry Services
Our platform has processed over $8 billion to date
We're proud to be one of the world's most international cryptocurrency teams from 43 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
How we work


Our engineering team (currently ~100 engineers) is split into organisations which we call Fleets. Each Fleet focuses on a core customer journey (onboarding, security, payments, support, new business, growth and marketing etc.). Each of these fleets contains multiple smaller teams called Pods, each of which focuses on a specific aspect of the product.

Pods will include a product owner, product designer, back-end engineers, Android, iOS and Web developers, who each bring a unique perspective to the problem you are all contributing towards.

We're agile, use scrum, continuous integration and continuous delivery, deploying to production every single day.

We're building teams to help us succeed in our mission to upgrade the world to a better financial system. You'll be joining a group of highly motivated software engineers who you'll work collaboratively with across our pods.

As a fast-growing company with offices around the world, you'll immediately see how your contributions directly impact both our internal users and client experience. Many of the problems we are solving result in trail blazing solutions which can't be found on Stack Overflow; so we're looking for engineers who flourish working in a complex domain.

In your first six months, you will:


...start at Luno by learning our processes, meeting the wider team and starting our engineering on-boarding program. After getting comfortable with the basics, you'll start learning our idiomatic patterns in a safe, easy-to-follow way - by building your own toy micro services. You'll get to practice how we do design docs, code reviews, deployments, events, logging and monitoring.

You'll meet the Pod(s) you'll be working with and quickly align on the teams' current OKRs and product roadmap. We succeed as a team, so we will provide you with regular feedback from your manager and peers and will encourage you to do the same.

What you'll do:
Work closely with our data science and platform teams on projects introducing new streams of data into our data lake
You will get to bring new ideas on how to further develop and innovate our data solutions and how to expose that data to the business
Accountable and Responsible for the design and architecture of Data systems that are robust and scalable.
Work in an Agile/Scrum framework or Agile mindset
Data backup/recovery and storage
Pick-up and learn new concepts, in both engineering and product, and be able to apply that knowledge quickly.
The ideal candidate for this role will have:
7+ years' experience in maintaining scalable data solutions and/or you are passionate about it
Ability to understand, communicate and advocate between build vs buy
Proven track record of setting up, restructuring and maintenance of databases
You know your way around ETL and you have experience with SQL
Experience in the AWS Data stack (RedShift,DynamoDB, Amazon RDS)
Familiarity with integrating data stores with BI platforms such as Looker, Tableau, or Power BI
You have experience with the concepts of CI/CD
Coding skills in e.g. Go, Python
Bachelor's degree in a related field preferred
AWS Certified DataOps Administrator
Be friendly, transparent, articulate and driven to succeed
Basic knowledge of and passion for digital currencies like Bitcoin
A work permit for South Africa if you are not a South African citizen
Don't be put off if you don't tick all of the boxes – they're a guide based on what we'd love to see but we appreciate that excellent software engineers have diverse backgrounds.

Remote Life at Luno


If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity / paternity and even (yes, you are reading it correctly) paw-ternity for your furry friend..
Annual Inspiration Day.. like that pottery course you've always been meaning to do!
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. You'll need to hold the legal right to work in South Africa already as we cannot provide visa sponsorship.

Be part of the change!",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer - EC2 Capacity Data Analytics,-1,"EC2 Capacity Data Analytics (CDA) team is looking for a Data Engineer to join our team.

Our team is part of the EC2 Capacity Engineering organization, which is responsible for providing the elasticity EC2 customers need to scale up/down compute resources in a cost-efficient manner. We predict customer usage across thousands of configuration combinations to deliver exactly what our customers require in just the right amount of time with just the right amount of capacity.

As a Data Engineer, you will build the ETL and analytics solutions for our internal customers to answer questions with data and drive critical improvements for the business. You will use best practices in software engineering, data management, data storage, data compute, and distributed systems. On any given day, we use Python, Scala, Java, SQL, Lambda, CloudFormation, Redshift and Glue as well as other public AWS services and a host of Amazon internal tools. We dont expect you to be an expert in, or necessarily even be familiar with all of the technologies listed above, but we do expect you to be excited to learn about them.

This position involves on-call responsibilities, typically for one week every two months. Our team is dedicated to supporting new team members. We care about your career growth, we try to assign projects and tasks based on what will help each team member develop into a more well-rounded engineer and enable them to take on more complex tasks in the future.

Our team values work-life balance and we are flexible when people occasionally need to work from home.

Job Duties
Develop and maintain automated ETL pipelines for big data using languages such as Scala, Spark, SQL and AWS services such as S3, Glue, Lambda, SNS, SQS, KMS. Example: ETL jobs that process a continuous flow of JSON source files and output the data in a business-friendly Parquet format that can be efficiently queried via Redshift Spectrum using SQL to answer business question.

Develop and maintain automated ETL monitoring and alarming solutions using Java/Python/Scala, Spark, SQL, and AWS services such as CloudWatch and Lambda.

Implement and support reporting and analytics infrastructure for internal business customers using AWS, services such Athena, Redshift, Spectrum, EMR, and QuickSight.

Develop and maintain data security and permissions solutions for enterprise scale data warehouse and data lake implementations including data encryption and database user access controls and logging.

Develop and maintain data warehouse and data lake metadata, data catalog, and user documentation for internal business customers.

Develop, test, and deploy code using internal software development toolsets. This includes the code for deploying infrastructure and solutions for secure data storage, ETL pipelines, data catalog, and data query.


Basic Qualifications

· Bachelors degree in Computer Science or related technical field, or equivalent work experience.
· 4+ years of overall work experience including Software Engineering, Data Engineering, Database Engineering, Business Intelligence.
· Experience with AWS technologies stack including Lambda, Glue, Redshift, RDS, S3, EMR or similar big data solutions stack

Preferred Qualifications

· Demonstrate efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data.
· Demonstrable proficiency in distributed systems and data architecture; design and implementation of batch and stream data processing pipelines; knows how to optimize the distribution, partitioning, and MPP of high-level data structures.

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer,-1,"Our client based in Johannesburg is urgently looking for a Data Engineer to be on a 3 months contract
Build data pipelines, experience in new tech like nifi, kafka, python

Joburg based, open to EE, 3 month contract with the option to extend, must be available at short notice",-1,EQplus,Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Overview
Job ID: 51456
Job Sector: Information Technology and Services
Country: South Africa
Region/State/Province/District: Gauteng
Location: Johannesburg

Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose

This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes

Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems

Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions

Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.
Research and best practices

Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development

Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.

Preferred Qualification and Experience

Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry

Knowledge/Technical Skills/Expertise

Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision

PLEASE NOTE: All our recruitment and selection processes comply with applicable local laws and regulations. We will never ask for money or any form of payment as part of our recruitment process. If you experience this, please contact our Fraudline on +27 800222050 or forward to TransactionFraudOpsSA@standardbank.co.za",4.1,"Standard Bank
4.1",Johannesburg,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"About us

At PBT Group we pride ourselves on being a Data Specialist organisation. With 20 years of experience in 27 countries over 3 continents, our team of 550 consultants have implemented more than 700 projects.",4.3,"PBT Group
4.3",Johannesburg,-1,Unknown,-1,Company - Private,Accounting,Accounting & Legal,Less than $1 million (USD),-1
Data Engineer,-1,"Kick-start your career in the online gaming world and experience the very latest in technology and innovation.

The Department:

Our mission is to provide our customers with the best online betting experience and share the thrill of gaming with them. Data is at the very heart of our business and is vital in everything we do.

Our cross-functional Data team has a big and exciting challenge ahead. We are in the process of re-platforming our traditional, on-premises RDBMS environment to a new microservice architecture in the cloud. We’re making use of the diverse set of data technologies in Microsoft Azure to offer new services, reporting structures and real-time data pipeline while serving the day-to-day requirements of a rapidly growing, data-hungry organisation.

Purpose of the Role:

This is an excellent opportunity for an individual who is looking to gain new skills. We are committed to creating a culture of learning and regularly run proof of concepts, provide internal demos, manage workshops and attend external conferences. Our data team has a wide range of skills including development for highly transactional RDBMS systems, data warehousing, data science and cloud technologies and we are always working to raise everyone’s game.

Duties include, but not limited to:

Work as part of an agile Data Engineering Team
Development of greenfield projects in Azure
Develop and maintain on-premises RDBMS/DW systems
Create robust ETL services and real-time data pipelines
Build and maintain Continuous Integration and DevOps pipelines
Test-driven development and pair programming with colleagues

Essential Criteria:

C#, .Net, Visual Studio
Git, Azure DevOps
NoSQL development (CosmosDB)
Demonstrable understanding of MS SQL Server in a highly transactional environment
Demonstrable understanding of development in Microsoft Azure
Able to understand query plans and identify performance bottlenecks
Test/Business-Driven Development
Building Continuous Integration/Deployment pipelines
Communicate effectively with both technical and non-technical stakeholders

Desirable Criteria:

Implementing Data Storage and Processing solutions in Azure (ARM Templates, Storage Accounts, Data Lake Storage, SQL DB, Cosmos DB, EventHubs, Function Apps, Log Analytics, Data Factory, Databricks, Polybase)
Implementing Security, Disaster Recovery, High Availability, Auditing, Monitoring and Alerting solutions in Azure
Automating tasks in Azure using Powershell / CLI
Predicting costs and optimizing spending in Azure
Message Queues (RabbitMQ, Kafka)
Python

Person Specifications:

Resilience
Teamwork
Technical Knowledge
Communication skills
Stress Tolerance
Please note we will apply relevance to our Talent Management and Talent Development Programme as part of our recruitment process.
Shortlisted candidates may need to complete an assessment.
This position requires trust and honesty it has access to customers financial details - therefore a credit and criminal record check will be conducted. The qualifications identified herein are an inherent job requirement; therefore, a qualification verification check will be done. By applying for this role, and supplying the necessary details, you hereby grant us permission to apply for these checks. This will be done in a confidential manner, and solely for the purposes of verification.

To view all current vacancies, please visit our website, www.digioutsource.com

Should you not hear from us within 2 weeks, please deem your application as unsuccessful.

The perfect place to work, play and grow!",3.9,"Digital Outsource Services
3.9",Cape Town,-1,1001 to 5000 Employees,1997,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
Data Engineer,-1,"At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes

Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.

Key Responsibilities

Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.

Key Traits

Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern

Position Requirements

2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.

Where will you work? This role will be based out of Durbanville, South Africa.",3.1,"Aculocity, LLC
3.1",Durbanville,-1,1 to 50 Employees,2006,Company - Private,IT Services,Information Technology,$1 to $5 million (USD),-1
Data Engineer,-1,"ENVIRONMENT:

A rapidly growing E-Commerce Platform seeks a highly talented Data Engineer to make an invaluable contribution to data democratisation and literacy vision by making accessible and easy-to-use data products and tools. You will require a Comp-Sci Degree or 3 years’ relevant industry experience, MySQL, PostgreSQL, Java, Python, in-depth understanding of OLAP, Data Marts, Star Scheme, Snowflake, be familiar with Jenkins, Travis, Circle CI, Docker, Kubernetes, experience with Kafka, Pub/Sub, Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks & significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing & Data Lake design and implementation and Lambda/Kappa architectures.

DUTIES:

Design, develop, test and maintain data architecture.

Prepare data for descriptive, predictive and prescriptive modelling.

Automate repetitive tasks and manual processes related with the data usage.

Optimize data delivery.

Design, develop and test large stream data pipelines to ingest, aggregate, clean, and distribute data models ready for analysis.

Ensure the highest standard in data integrity.

Leverage best practices in continuous integration and delivery.

Collaborate with other engineers, ML experts, analysts, and stakeholders to produce the most efficient and valuable solutions.

Implement features, technology, and processes that move us towards industry best practices, improving on scalability, efficiency, reliability, and security.

Operations and ownership of systems in production, responding to incidents.

REQUIREMENTS:

Qualifications –

Comp-Sci Degree or 3 years relevant industry experience.

Experience/Skills –

Open source relational database systems e.g. MySQL, PostgreSQL, etc.

Significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing, and Data Lake design and implementation and Lambda/Kappa architectures.

A thorough understanding of database and data warehousing principles e.g. OLAP, Data Marts, Star Schema, Snowflake, etc.

Java and Python.

Familiar with CI/CD tools such as Jenkins, Travis, Circle CI, etc.

Experience with Kafka, Pub/Sub, or other event-based systems.

Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks, etc.

Working in cloud environments and with containerisation frameworks, tools and platforms e.g. Docker, Kubernetes, GKE, etc.

A deep understanding of data pipelining, streaming, and Big Data technologies, methods, patterns, and techniques.

Troubleshooting complex database operations and performance issues.

Automating tasks using Shell Scripting or writing small applications.

ATTRIBUTES:

Works well with people and is passionate about helping people be their best.

A team player, an active listener, mentor, and able to communicate well.

Shows solid reasoning and decision making, with the ability to work under pressure.

Is passionate about technology, systems and data.

Is curious, always learning, and keeping up to date with the industry.

While we would really like to respond to every application, should you not be contacted for this position within 10 working days please consider your application unsuccessful.

COMMENTS:

When applying for jobs, ensure that you have the minimum job requirements. Only SA Citizens will be considered for this role. If you are not in the mentioned location of any of the jobs, please note your relocation plans in all applications for jobs and correspondence.",-1,Datafin IT Recruitment,Cape Town,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Cartrack is looking for passionate data science and engineering candidates that can join a growing team that is responsible for the intelligence and efficiency solution provision to over a million subscribers, many of whom are large fleets. We are in the midst of creating revolutionary platforms that will change the way that people interact with their vehicles.

You will have the opportunity to work with the very brightest global subject matter experts that are transforming the automotive industry across Fleet Management, Asset Management and Insurance Telematics solutions.

Get to know the role:

The role of a data engineer is a supporting one, but it is also an extremely vital one. As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements. We want to see candidates with mechanical tendencies and a desire to know how things work and to improve them.

The day-to-day activities:

Design, construct, install, test and maintain data management systems.
Build high-performance algorithms, predictive models, and prototypes.
Ensure that all systems meet the business/company requirements as well as industry practices.
Integrate up-and-coming data management and software engineering technologies into existing data structures.
Develop set processes for data mining, data modeling, and data production.
Create custom software components and analytics applications.
Research new uses for existing data.
Employ an array of technological languages and tools to connect systems together.
Install/update disaster recovery procedures.
Recommend different ways to constantly improve data reliability and quality.
Work on and maintain Data pipelines.

Requirements Essential:

At least 5 years’ proven experience as a Data Engineer, DevOps Engineer, Software Developer, or similar.
Proficient in Linux/Unix and shell scripting as well as in functional programming languages.
Expertise in setting up and explored with technologies such as Hadoop and Spark.
Bachelor’s degree in computer science, software/computer engineering, applied mathematics, or physics.",3.3,"Cartrack
3.3",Johannesburg,-1,501 to 1000 Employees,2004,Company - Private,Security Services,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Data Engineer,-1,"Data Engineers build and support data pipelines and datamarts built off those pipelines. Both must be scalable, repeatable and secure. The Data Engineer helps to facilitate gathering data from a variety of different sources, in the correct format, assuring that it conforms to data quality standards and assuring that downstream users can get to that data timeously. This role functions as a core member of an agile team. These professionals are responsible for the infrastructure that provides insights from raw data, handling and integrating diverse sources of data seamlessly. They enable solutions, by handling large volumes of data in batch and real-time by leveraging emerging technologies from both the big data and cloud spaces. Additional responsibilities include developing proof of concepts and implements complex big data solutions with a focus on collecting, parsing, managing, analysing and visualising large datasets. They know how to apply technologies to solve the problems of working with large volumes of data in diverse formats to deliver innovative solutions. Data Engineering is a technical job that requires substantial expertise in a broad range of software development and programming fields. These professionals have a knowledge of data analysis, end user requirements and business requirements analysis to develop a clear understanding of the business need and to incorporate these needs into a technical solution. They have a solid understanding of physical database design and the systems development lifecycle. This role must work well in a team environment.

Job Objectives

Work Complexity: * Architects Data analytics framework. * Translates complex functional and technical requirements into detailed architecture, design, and high performing software. * Leads Data and batch/real-time analytical solutions leveraging transformational technologies. * Works on multiple projects as a technical lead driving user story analysis and elaboration, design and development of software applications, testing, and builds automation tools.

Main Job Objectives: 1. Development and Operations 2. Database Development and Operations 3. Policies, Standards and Procedures 4. Communications 5. Business Continuity & Disaster Recovery 6. Research and Evaluation 7. Coaching/ Mentoring

Qualifications

Essential: 4 years Bachelors degree in computer science, computer engineering, or equivalent work experience AWS Certification at least to associate level

Experience

Essential:

5+ years Data engineering or software engineering

3-5 years demonstrated experience leading teams of engineers

2+ years Big Data experience

5+ years experience with Extract Transform and Load (ETL) processes

2+ years Could AWS experience

At least 2 years demonstrated experience with agile or other rapid application development methods - Agile exposure, Kanban or Scrum

5 years demonstrated experience with object oriented design, coding and testing patterns as well as experience in engineering (commercial or open source) software platforms and large scale data infrastructures.

Desirable:

5+ years Retail Operations experience

Knowledge and Skills

Essential: *Creating data feeds from on-premise to AWS Cloud (2 years) *Support data feeds in production on break fix basis (2 years) *Creating data marts using Talend or similar ETL development tool (4 years) *Manipulating data using python and pyspark (2 years) *Processing data using the Hadoop paradigm particularly using EMR, AWSs distribution of Hadoop (2 years) *Devop for Big Data and Business Intelligence including automated testing and deployment (2 years) * Extensive knowledge in different programming or scripting languages * Expert knowledge of data modeling and understanding of different data structures and their benefits and limitations under particular use cases.

Further technical skills required: * Capability to architect highly scalable distributed systems, using different open source tools. * Big Data batch and streaming tools * Talend (1 year) * AWS: EMR, EC2, S3 (1 year) * Python (1 year) * PySpark or Spark (1 year) - Desirable * Business Intelligence Data modelling (3 years) * SQL (3 years)",-1,Datonomy Solutions,Brackenfell,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We are assisting one of our clients that is based in Pretoria to fill a role of a Data Engineer

This is a 12 month contract role

Objective of this Scope of Work

The Data Engineer will drive improvement of the data management maturity levels and provide the necessary technical support within the company to support reliable and effective decision-making, appropriate usage and protection thereof.

Scope of Services Definition

The scope will include but will not be limited to:

ï†· To develop, construct, test and maintain architectures.

ï†· To ensure architectures will support the requirements of business.

ï†· To discover opportunities for data acquisition and sharing.

ï†· To develop data set processes for data modelling, mining and production.

ï†· To employ a variety of languages and tools to marry systems together.

ï†· To recommend way to improve data reliability, efficiency and quality.

ï†· To prepare data for use in predictive and prescriptive modelling.

ï†· To conduct research to answer industry and business questions.

ï†· To leverage volumes of data from internal and external to answer business questions.

ï†· To develop and manage stakeholder relations effectively to promote data management across the organisation and support reliable decision making and appropriate data usage.

ï†· To participate and provide technical support in cross organisational activities relating to any of the above mentioned data management activities.

ï†· To provide regular progress reports as per stakeholder requirements and present data management updates in various forums as required.

Minimum qualification Required:

ï†· A minimum of a Bachelors degree in Computer Science or Information Management OR equivalent;

ï†· A minimum of five to eight years experience in a data management environment",-1,HR Genie,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Our client based in the Northern Suburbs, is currently looking for a Data Engineer to join their team.

Responsibilities
Our client is a dynamic IT company that delivers value-driven IT solutions to the group. Our work lives revolve around our DNA. We take pride in our work, treat our colleagues, partners and our country with respect. We exercise collaborative decision-making and believe in having a balance in life. We do this all while having fun and enjoying what we do.

The primary focus of this position is to use technical skills to put software, systems and data together in a way that extracts meaningful insights from raw data. You will need to be helpful and supportive to your team and fellow developers. You join an energetic, focused and dynamic team.

Interact with clients to understand requirements and business problems/needs

Identify, analyse, visualise and understand supporting data to propose solid solutions

Create technical documentation for reference and reporting

Support existing solutions within GCP and Oracle

Doing standby on a rotating basis

Key Competencies and Qualifications

Matric

Tertiary qualification in IT

Preferred cloud experience in AWS/AZURE/GCP

At least 3 years of data warehouse ETL experience

Dimensional Modelling

Data analyses

Experience with data visualization and visualization tool(s)

Knowledge of the retail industry will be beneficial

Understanding and experience with version control SVN/GIT

Preferred – Korn shell scripting, Python/Java, SQL

Google Cloud Platform experience would be looked upon favourably

Having a broad understanding of different SDLC’s

Preferred agile experience

Strengths

The natural tendency to take ownership and responsibility

Strong problem solving, critical thinking, effective planning and organisational skills

Detail-oriented with excellent communication skills

You have a can-do attitude and positive outlook on life

Can cope under pressure

Curious and interested in analysing problems and possible solutions

Strong team player

Self-driven learner, passionate about new technology

Above all, be passionate about what you do

Should you wish to apply for the position, please apply directly via this job board, please ensure that you quote reference number 201620 subject heading or email body.

Please note that due to the high volume of CV's received; only shortlisted applicants will be contacted. Should you not receive communication from our offices within two weeks of submission please note that your application will not be considered for this position.

We will keep your CV on file and re-establish contact with you should opportunities in line with your expertise become available again.

Should you require any additional information give us a call on 021 012 5566.",-1,Surgo HR & Training,Cape Town,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We believe that our employees fuel our organization, essential to enable us to help our customers overcome their business challenges and achieve sustainable growth. As a result, we are committed to growing each individual and providing them with the challenges, feedback and support needed to achieve success in their career

If this sounds appealing, and like us, you get excited about data: its collection, storage, transformation or display, see if you’ve got what it takes to join our sought after DATA team.

Key Responsibilities And/or Outputs

You will represent IQbusiness at our customers, sometimes alone, and sometimes as part of an IQ team.

Providing a superior customer experience by building and maintaining relationships, working at customer offices, keeping data confidential
Design and develop – databases, SQL queries, stored procedures, reports, dashboards or integration solutions
Produce solutions for both real-time and batch environments
Test your work to ensure compliance
Solve problems, and do root cause analysis
Prioritize your workload
Assist in other areas relating to your true data function, such as data modeling, data and business analysts
Interact with a variety of individuals: senior, junior, technical and from business
Provide guidance to fellow colleagues, or even manage a team
Uphold the IQ values, which are to care, learn & share; innovate; deliver as well as to build, enhance and maintain relationships

Education

Matric pass
A tertiary qualification, preferably in an ICT relevant field
Appropriate Microsoft certifications are beneficial but not required

Requirements

3 - 6 years experience in the Data Engineering environments and technologies
Great communication skills
A passion for SQL, databases or reports
Can you write stored procedures, design complex queries and create views and triggers?
Are you able to work out the relationships in a data warehouse or the aggregation of a cube?
Do you extract and display useful information when you see patterns and trends in data?
Strong knowledge of the financial services industry, ideally in a consulting role
The use of data related software: databases, ETL and BI tools; report writing and analytical tools
We use a lot of Microsoft products. You may often be expected to use MS SQL Server, SSIS, SSRS, SSAS and Power BI to develop solutions
What other relevant software have you’ve used?
Ability to work in different project methodologies: Waterfall and/or Agile
Knowledge of full SDLC
Exposure to logical and physical data modeling

Equal Employment Opportunity

IQbusiness is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, citizenship, marital, domestic or civil partnership status, sexual orientation, or gender identity",3.7,"IQbusiness South Africa
3.7",Johannesburg,-1,1 to 50 Employees,-1,Company - Private,Consulting,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"We value a data engineer as someone who works behind the scenes to obtain, process and supply data via various methodologies and technologies, to various consumers, in ways and forms that makes sense and add value. This definition is very broad, as the field of data engineering is just as broad.

You may be the type of data engineer that develops API endpoints for the consumption of data by end users or even another data pipeline, or you may be the type of data engineer that develops highly distributed, high availability data processing pipelines in an effort to satisfy the need of the ever questioning data analysts and/or data scientists.

You have awesome knowledge about the following concepts
Data modelling
Relational data modelling in traditional relational database management systems. (Microsoft SQL Server, MySQL, PostgreSQL, etc)
Coercing unstructured and semi-structured data into a structured form.
Data pipelining knowledge - data extraction and transformation.
Data transformation knowledge for reporting and analytics purposes.
Knowledge of the MapReduce and related data processing paradigms would be a boon.
You have the following technical competencies
Writing SQL queries, that can relate, transform and aggregate data from many differing sources where natural keys may or may not exist.
Experience with writing data pipelines that move and transform data, for various uses.
Working knowledge of a general purpose programming language like Python would be a boost.
Working knowledge of columnar databases such as Google BigQuery, and SAP HANA would be a boost.
Working knowledge of highly distributed technologies such as Apache Hadoop or Apache Spark would be a boost.
Working knowledge of NoSQL technologies, such as Apache Solr would be a boost.
You have the following personal competencies
The ability to solve problems.
The ability to rotate around a problem, to see if solutions can be gained in different ways.
The ability to work in an ever changing, unstructured environment.
The ability to work as part of a team, with vastly differing skill sets and opinions.
The ability to contribute ideas to the quorum.
The ability to mentor and provide guidance for other team members.
A systems approach to thinking, as opposed to a siloed approach. The candidate needs to understand how their work affects the greater system.
The ability to work without supervision, and take accountability for the work they deliver.
The ability to liaise with a client, sifting through the fluff and extracting the actual requirements.
If this is you - apply now and we'll get in touch",-1,DotModus,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Data Engineer

Our client in the contact centre space is currently seeking a DATA ENGINEER that will work on the collecting, storing, processing, and analyzing of large datasets. The primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them. You will also be responsible for integrating them with the architecture used across the company.

Key Performance Areas:

Data reporting.
Implementing ETL processes.
Defining data retention policies.
Management of Customer Lead data.
Provision of data for advanced analytics.
Maintenance of internal client scorecards.
Assist team in resolving data-related support queries.
Optimize existing data processes through automation.
Assist with all data-related reporting and documentation.
Maintenance and optimisation of the Analytics database.
Provide technical support to and supervision of junior data administrators.
Continuous upskilling on new technologies, frameworks and market trends.
Monitoring performance and advising any necessary infrastructure changes.
Identifying, selecting and integrating any Big Data tools and frameworks required to provide real-time analytics.

Educational Requirements

IT related Degree or Diploma is a pre-requisite

Required Skills/Experience

ETL tools: Advanced SSIS
BI/Reporting : Qlikview/Power BI/ SSRS or SSAS
Programming languages: JAVA, C# , Python, SAS or R
Experience with NoSQL databases and/or campaign management tools will be advantageous.
Minimum 3 years’ applicable work experience in SQL, relational databases and data manipulation.
Experience in big data platforms (eg. Hadoop) or processing frameworks (eg. MapReduce/Spark) and querying tools (eg. Pig, Hive and Impala) will be highly beneficial.

Preferred Skills

Organizational skills
Experience in Attentional to detail.
Accountability is critical for this role.
Ability to work under pressure and meet deadlines.
Solid understanding of database design principles.
Should you not receive a response in 2 weeks please consider your application unsuccessful",-1,Rubik's Cubed Consulting,Durban,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"This well known company is looking for a Data Engineer. will be based in Rivonia
The ideal candidate will have strong experience in the following:
Data cleaning
SQL Export
Big data Sets

BSc Degree in Maths and Stats will be required
a min of 3 years experience.
Stable track record is required.

Send your Cv to marinda@prrrecruitment.co.za",-1,PRR Recruitment Services,Johannesburg,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Description

Position at Aculocity, LLC

At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes
Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.
Key Responsibilities
Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.
Key Traits
Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern
Position Requirements
2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.
Where will you work? This role will be based out of Durbanville, South Africa.",-1,GVW,Durbanville,-1,Unknown,-1,Unknown,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Information Technology, Gauteng JHB - Northern Suburbs

Market related - Market related Annually

An IT Consultancy Business based in Johannesburg is currently looking for a Business Intelligence Consultant / Data Engineering Consultant.

Requirements:

Extensive experience in data engineering
Experience in Business Intelligence, data and Power BI
Extensive experience in data governance and the Popi act
Ability to assess and make recommendations on data within the Popi act
Good understanding of T-SQL and query optimization, developing ETL strategies.
Good understanding with SQL Server 2008/2012, SSIS, SSRS and SSAS
Use SSIS to create ETL packages to validate, extract, transform, and load data into the data warehouse and data marts.
Deploy and configured the reports in the Report Server (SSRS).
Excellent experience in Tabular Modelling , PowerView, Qlikvie,w, and Power BI
Maintain ETL
Qlikview model
Create Drill-through, Drill-down, and Cross Tab Reports and Sub-Report using Report Definition Language (RDL).
Generate periodic reports based on the statistical analysis of the data using SQL Server Reporting Services (SSRS)
Advise and provide written technical documentation and recommendations

The information displayed above is not limited to advertisements. Please contact Thato for further information.

Please consider your application as unsuccessful if you have not received a response within 14 days of submitting your application. However, please keep a lookout on our website, www.bedifferent.co.za, for available positions that you may be suited for

Ad Visible Until: 29 October 2020
Ref: JHB005346/NL

Vacancy Type: Permanent",2.9,"Be Different Recruitment
2.9",Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Cloud Support Engineer (Big Data),-1,"ABOUT US

Amazon Web Services is the market leader and technology forerunner in the Cloud business. As a member of the AWS Support team you will be at the forefront of this transformational technology, assisting a global list of companies and developers that are taking advantage of a growing set of services and features to run their mission-critical applications. As a Cloud Support Engineer, you will act as the Cloud Ambassador across all the cloud products, arming our customers with required tools & tactics to get the most out of their Product and Support investment.

Would you like to use the latest cloud computing technologies? Do you have an interest in helping customers understand application architectures and integration approaches? Are you familiar with best practices for applications, servers and networks? Do you want to be part of a customer facing technology team helping to ensure the success of Amazon Web Services (AWS) as a leading technology organization?

If you fit the description, you might be the person we are looking for! We are a group of smart people, passionate about cloud computing, and believe that world class support is critical to customer success.

WHAT CAN YOU EXPECT FROM A LIFE AT AWS?

Every day will bring new and exciting challenges on the job while you:

· Learn and use groundbreaking technologies.
· Apply advanced troubleshooting techniques to provide unique solutions to our customers' individual needs.
· Interact with leading engineers around the world.
· Partner with Amazon Web Services teams to help reproduce and resolve customer issues.
· Leverage your extensive customer support experience to provide feedback to internal AWS teams on how to improve our services.
· Drive customer communication during critical events.
· Drive projects that improve support-related processes and our customers technical support experience.
· Write tutorials, how-to videos, and other technical articles for the developer community.
· Work on critical, highly complex customer problems that may span multiple AWS services.

WHY AWS SUPPORT?

· First and foremost this is a customer support role in The Cloud.
· On a typical day, a Support Engineer will be primarily responsible for solving customers cases through a variety of customer contact channels which include telephone, email, and web/live chat. You will apply advanced troubleshooting techniques to provide tailored solutions for our customers and drive customer interactions by thoughtfully working with customers to dive deep into the root cause of an issue.
· Apart from working on a broad spectrum of technical issues, an AWS Support Engineer may also coach/mentor new hires, develop & present training, partner with development teams on complex issues or contact deflection initiatives, participate in new hiring, write tools/script to help the team, or work with leadership on process improvement and strategic initiatives.
· Career development: We promote advancement opportunities across the organization to help you meet your career goals.
· Training: We have training programs to help you develop the skills required to be successful in your role.
· We hire smart people who are keen to build a career with AWS, so we are more interested in the areas that you do know instead of those you havent been exposed to yet.
· Support engineers interested in travel have presented training or participated in focused summits across our sites or at specific AWS events.
· As we operate on a follow-the-sun model, with Premium Support sites located globally, there is no after hours on-call or mandated overtime in this role.
· https://www.youtube.com/watch?v=GC3bWcFFZTo&t=24s



Basic Qualifications

The Big Data role supports our services that leverage data and produce business insights, which may include using Machine Learning/Artificial Intelligence (ML/AI). Helping our customers use and integrate Big Data services in what is arguably our industrys most exciting space. The portfolio of services covers EMR (Hadoop), DynamoDB (NoSQL), MangoDB, and Apache Cassandra.

· Advanced experience in Apache Hadoop, Apache Spark, Apache Hive, and Presto
· Advanced experience in DynamoDB or NoSQL technologies like MongoDB or Cassandra
· Advanced experience with System Administration with Linux (RHEL/CentOS) including Microsoft Active Directory, and LDAP integration.
· Experience with troubleshooting Kerberos Authentication problems.
· Experience with Network troubleshooting.
· Basic understanding of Machine Learning and statistics
· Experience with Java and Python and shell scripting
· Bachelors degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position



Preferred Qualifications

· Expert experience in the Hadoop Ecosystem including Apache Spark and Presto
· Expert experience in NoSQL
· Expert experience with blockchain technologies like Etherium Expert experience in data Data Lake architecture and administration
· Experience managing full application stacks from the OS up through custom applications
· Prior work experience with AWS - any or all of EC2, VPC, S3, RDS, EMR, Glue, SageMaker
· Excellent knowledge of Hadoop architecture, administration and support
· Expert understanding of distributed computing principles and their application in the cloud
· Good understanding of distributed computing environments Lead technical discussions on big data systems architecture and design
· Strong analysis and troubleshooting skills and experience
· AWS Certified Solutions Architect
· AWS certified Big Data Specialty
· Masters degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity and Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Response Center Engineer,-1,"Job Title
Response Center Engineer
Job Description


Philips is a world leading health technology company with a vision to make life better for people worldwide through meaningful innovation. Making good on this promise depends on our passionate, inspirational, collaborative and diverse team. We have over 80,000+ brilliant people around the world but are always looking for more. Like-minded, motivated, focused minds to join us in creating a healthier, more connected society while transforming themselves personally and professionally.

As a CCC Coordinator - Response Center Engineer you will have the opportunity to process customer calls and be responsible for screening and diagnosing professionally Healthcare equipment to support customers and colleagues remotely with solving technical issues and ensuring maximum customer satisfaction

You are responsible for:
Diagnose healthcare equipment to the quality standards set by Philips Healthcare (PH) remotely by interviewing customers or colleagues by telephone or by remotely logging in to the system
Advise Customer Care Center Coordinators and District Operations Managers and / or Team Leads about the best follow-up w.r.t. technical state of the diagnosed healthcare equipment
Advise the Customer Care Center Coordinators or Field Services Engineers about required spare parts and resources
Responsible for planning engineers related to Modality responsibility.
Responsible for coordination between CCC, CUSTOMER, Spare parts AND Engineer.
Responsible to drive Remote and FTR KPI’s to targets respectively 40% and 85%.
Will require minimal field work to keep abreast of technical capabilities.
Take calls from customers and make sure they are processed in the CCC ERP on timely manner including all relevant data
Support Field Services Engineers in the field with technical knowledge
Escalate technical issues to the Technical Support Specialist
Escalate technical issues to Business Unit support after consultation of the Technical Support Specialist
Monitor critical functions of the equipment’s in the IB and environmental conditions including RSN and True reachability.
Lead the planning and implementation of FSN’s and FCO’s accelerating remote implementation where applicable.
Submit timely and accurate service data, job sheets, reports, expense claims, radiation film badges, field problem reports and other paperwork as assigned
Keep abreast of new technologies likely to affect PH range of products
Use company property with care to ensure optimal results with minimal operational costs
Be a professional representative for PH with respect to customer problems, ensuring personal acceptability by the customer in behavior in accordance with PH policy and targets
Conform to PH safety standards including health and safety regulations and in the event of hazards or accidents to take immediate control of the situation and involve the Operations Manager and / or the responsible person to handle properly confidential issues according Philips standards and to act according General Business Principals
Follow all quality standards within the frame of valid PH business policies
Follow the company quality regulations (ISO 9001; PQA; TQM) and internal directives and procedures
You are a part of the dynamic South Africa Customer Care Centre Team .You will be reporting to the Customer Care Center Manager.

Requires a pleasant, assertive individual you can work very well in a team setting, a dynamic environment that requires flexibility and creativeness to achieve goals.

To succeed in this role, you should have the following skills and experience:
Degree level education or equivalent
Experience in maintenance and troubleshooting of technical complex systems
Fluent in English, verbal and written in addition to local language
In return, we offer you the unique combination of a critical and challenging role and a creative and empowering office environment. You will be actively encouraged to make improvements, establish best in class service and have a direct impact on the success of Philips on a daily basis.

Employment Equity

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply. Only apply for this role if you are a South African Citizen by birth or Naturalization prior to the 27 April 1994.

Why should you join Philips?

Working at Philips is more than a job. It’s a calling to create a healthier society through meaningful work, focused on improving 3 billion lives a year by delivering innovative solutions across the health continuum. Our people experience a variety of unexpected moments when their lives and careers come together in meaningful ways. Learn more by watching this video.

To find out more about what it’s like working for Philips at a personal level, visit the Working at Philips page on our career website, where you can read stories from our employee blog. Once there, you can also learn about our recruitment process, or find answers to some of the frequently asked questions.

Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.9,"Philips
3.9",Johannesburg,-1,10000+ Employees,1891,Company - Public,Health Care Services & Hospitals,Health Care,$10 to $25 million (USD),-1
Software Development Engineer - EC2 Placement,-1,"Build the systems that optimize how EC2 matches requests for Instances with the underlying compute capacity. EC2 Placement is seeking talented engineers to build the online and offline optimization systems for compute workload scheduling, and the customer capabilities to better manage those workloads. Amazon EC2 provides on-demand scalable compute capacity, and powers some of the largest services in the world. You will collaborate with a top-tier community of engineers to build systems to improve how customers are able to access EC2 compute resources.

The successful candidate will have strong software engineering experience, with a passion for thinking about, building and testing distributed systems. You have an interest in how Machine Learning and other optimization techniques can be applied to large-scale problems. You have demonstrated experience working with a team to design, build and operate large-scale systems. With strong engineering fundamentals, an analytical and data-driven approach to your work, and strong communication skills, you have the ability to collaborate well to deliver results. We move fast and work together on small teams to solve big problems.

If this opportunity sounds interesting, we would love to talk to you more about our work and the vibrant culture at AWS in Cape Town.

Basic Qualifications

· Degree in Computer Science or related field, or equivalent working experience
· 3+ years of industry experience in a software development environment
· Strong Computer Science fundamentals, including data structures, object-oriented design, algorithm design, problem solving, and complexity analysis.
· Proficiency in at least one modern programming language, such as Java, C#, Python, Scala, Kotlin

Preferred Qualifications

One or more of the following help you stand out:
· Demonstrated results designing, building and operating high-performance distributed systems in large-scale Linux environments
· Role model in writing high-quality, maintainable and secure code, mentoring others, and helping teams sharpen their development processes
· Ability to work effectively across teams to deliver results, with strong verbal and written communication skills
· Experience working with machine learning systems

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer - PBB IT,-1,"Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose


This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes
Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems
Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions
Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.

Research and best practices
Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development
Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.
Preferred Qualification and Experience
Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Aws Data Platform Engineer,-1,"Aws Data Platform Engineer

Posting Country:

South Africa

Date Posted:

15-Oct-2020

Full Time / Part Time:

Full Time

Contract Type:

Permanent

Joining Vodacom is more than a job, what we do matters. We don’t just carry minutes, texts and data – we carry people’s lives. And that’s a huge responsibility. If you think for a minute about the people you rely on…the likelihood is they rely on us.

Customers are at the heart of everything we do and we want to make a difference to the lives of our customers, and the communities in which we live and work. We support our people to give something back to the causes that mean the most to them through helping them give time and money to the charities they love.

And what’s it like to work here? We have created an environment where you can look forward to coming to work and are empowered to be at your best. We offer flexibility in how you work that helps you do your job in a way that suits you, opportunities to help you grow and progress throughout your career and a choice of benefits to suit your lifestyle.

Role Purpose
The H Band AWS Data Platform Engineer position is based within the Technology Business Unit.

The AWS Data Platform Engineer will be responsible for all Database services such as RDS, DynamoDB, etc. Should be able to migrate any databases from anywhere to AWS using any third-party tools or AWS database migration tool. Should also have understanding or expertise in creating data warehouses and data lake solutions on AWS.
Your responsibilities will include:
Apply practical knowledge of relational database design and usage with customers
Perform workload analysis and undertake performance tuning, as well as performance benchmarking in customer environments.
To develop state of the art solutions which are technically sound.
To provide a high-quality service to the Enterprise Cloud Services clients i.t.o. consultancy, solutions and delivery.
Commitment to team success and positive team dynamics including mentoring of other team members.
Passion for growing and applying technical skills in service to customers.
Be a trusted infrastructure advisor by providing objective, practical and relevant ideas, insights and advice.
Work collaboratively with consulting partners and technology teams to ensure high quality of solution delivery.
Encourage best practice and knowledge sharing with partners and cross-functional groups
Manage the overall database design and delivery of solutions.
Ability to make recommendations as they pertain to improvements in support/development initiatives and facilitate implementation with partners and cross-functional groups within the Business.
Participate in high level database solution definition and design during the implementation phase with the goal of providing reliable, stable and operationally sound applications that meet the Business requirements.
Ability to understand and translate business requirements into technical specifications
The ideal candidate will have:
A minimum of 3 years of industry related experience of which 1 year must be within a complex hosting environment.
Certifications in Database design, system architecture or cloud technologies.
Demonstrate knowledge of database systems internals including storage layouts and distributed databases/MPP architectures
Advanced SQL coding, tuning and query optimization.
Experience designing and leading database performance benchmarks.
Good knowledge of the different AWS services
Knowledge of cloud networking architecture, cloud operations, security, automation and orchestration.
Knowledge of database internals as it relates to query and system performance and tuning.
Understanding of overall system architecture, scalability, reliability, and performance in a database environment.
Excellent teamwork, time-management and organizational skills.
Perform other duties as deemed necessary and assigned by the customer and management
Strong interpersonal skills and problem-solving abilities.
Excellent documentation, communication and interpersonal skills.
Excellent analytical and problem-solving abilities.
Closing date for applications: Monday, 13 April 2020

The base location for this role is Vodacom World, Midrand

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply.
Vodacom is committed to an organisational culture that recognises, appreciates and values diversity & inclusion.

Commitment from Vodacom

Vodacom is committed to attracting, developing and retaining the very best people by offering a flexible, motivating and inclusive workplace in which talent is truly recognized, developed and rewarded. We believe that diversity plays an important role in the success of our business and we are committed to creating an inclusive work environment which respects, values, celebrates and makes the most of people’s individual differences - we are not only multinational but multicultural too. At Vodacom you will have access to our excellent flexible benefits programme that you would expect from any global company.",3.9,"Vodafone
3.9",Midrand,-1,10000+ Employees,1982,Company - Public,"Cable, Internet & Telephone Providers",Telecommunications,$10+ billion (USD),-1
Data Engineer Azure Data Factory,-1,"Enthuzex is looking for a motivated Lead Data Engineer to contribute towards the success of our Data and Analytics Technology initiatives. This is a hands-on technical role and this person will be responsible for the development and build of scalable solutions as it relates to the architecture strategies, data standards, digital data management, data integration, tools, and technology. The right candidate will play a deep dive hands-on critical development role in the digital transformation and in shaping how we acquire, ingest, transform and deliver data through the digital consumer channels.

Responsibilities:

Architect, design, develop and engineering end-to-end data pipelines across multiple data sources and systems of record.
Ensure data quality, integrity, security and completeness throughout the data lifecycle
Develop, design data models, data structures and ETL jobs for data acquisition and manipulation purposes
Develop deep understanding of the data sources, implement data standards, maintain data quality and master data management
Developing data services and API
Work closely with the cloud service providers to ensure completeness and alignment with the service offerings
Manage and maintain cloud based data and analytics platform
Deep understanding of the cloud offerings and engage in quick proof of concepts and proof of value in prototyping data and analytics solutions and derive viability
Ability to interact with the business stakeholders to understand requirements and translating into technology solutions

Expirience:

Experience in Cloud platform AWS or Azure eco-system. (Azure preferred)
Data Engineering/Development experience with SQL (Oracle, SQL Server, MySQL)
Strong development background creating pipelines and complex data transformations and manipulations using one of the languages Python, Java, R, or Scala with Databricks/Spark
Experience in NoSQL Databases and Big data technologies including Hadoop
Experience with API / RESTful data services
Worked on real-time data capture, processing and storing using technologies like Azure Event Hubs and Analytics
Experience working with different data storage options including AWS S3, Azure BLOB storage etc.
Understanding of different data formats including Parquet, Avro, CSV, ORC etc.
Prior experience with MPP databases and maintain large amount of data processing
Experience with Azure Data Factory and Azure Data Catalog is a big plus and mandatory
Experience with Microsoft/Azure ETL solutions and business Intelligence technologies is a big and mandatory
Past working experience on a fast paced and agile environment
Perform ongoing monitoring, automation and refinement of data engineering solutions
Experience in leading high visibility transformation projects that interacts with multiple business lines
Build and meet project timelines and manage delivery commitments with proper communication to management

Qualifications

Bachelor’s degree with 4+ years of relevant experience
Willingness to learn new technologies and thrive in an extremely fast paced environment
Team player and easy to work with.

Applicants must demonstrate their ability to master new enterprise level technologies. Successful applicants will exemplify Enthuzex ethical principles of uncompromising integrity, respect for others, and accountability for decisions

send cv's info@enthuzex.co.za",-1,Enthuzex,Leslie,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Scientist,-1,"The world is changing.

We all want something different.

At Luno, we see you as an individual.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the world, and to do so, we need the best team on board for our mission.

A bit about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 3 million customers across 40 countries.
We are Series B funded, backed by Balderton Capital and the Naspers Group.
Our platform has processed over 8 billion dollars since we've launched
We're proud to be one of the world's most international cryptocurrency teams from 26 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
The role in a nutshell:

Identifying opportunities in the business that could benefit most from cognitive applications, as well as building and enhancing organisational capabilities for deriving value from multiple data sources using data science.

What we'd like you to have:
Bachelor's degree or higher in the natural sciences or technical fields such as Mathematics, Statistics, Computer Science, Engineering or Economics
Enthusiasm to work in the cryptocurrencies space
Advanced SQL skills
Solid understanding of exploratory data analysis, predictive analytics, and optimisation using Python, R, Matlab, RapidMiner, KNIME or other data science-oriented platforms
Proficiency in the use of data science and machine learning domain-specific languages such as ""Caret"" and the ""Tidyverse"" suite of tools in R, or ""Pandas"" in Python
Strong interpersonal and communication skills
Communicating data insights using storytelling narratives
Ability to work independently, as well as within and across teams
Ability to successfully complete projects with large and/or incomplete data sets
More about what you'll be doing:
Optimising product performance by tracking and analysing customer behaviour on web and app, in collaboration with software engineers and product designers
Providing the business with reports and dashboards, on key performance metrics
Developing metrics to accurately assess the health of our Exchange platform
Comparative data-driven analysis of our Exchange against alternative platforms
Formulating business requirements into analytical objectives
Designing and running experiments to test hypotheses
Hacking through complex business problems using advanced data analysis to provide insights and recommendations
Building, maintaining, and optimising decisioning systems using advanced statistical and predictive modelling techniques
What will set you apart:
An advanced degree in Mathematics, Statistics, Computer Science or related field
At least 3 years' experience working in a similar role
A basic understanding of trading in financial markets
Experience working with a data analytics and visualisation platform such as Tableau, Cognos, QlikView, or Looker
Familiarity with using Google Analytics to understand customer behaviour
Solid knowledge of statistical and machine learning techniques
Familiarity with modern distributed data storage and processing systems such as Amazon Redshift, Big Query, Snowflake, Databricks and Apache Spark
You can gather and synthesise facts, theories, trends, patterns, inferences, and key issues in complex and variable situations
Ability to diagnose problems using formal problem-solving tools and techniques from multiple angles to generate multiple possible solutions
A sense of anticipating long-term problem areas and associated risk levels with objective rationale
Remote Life at Luno

If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
You'll be able to continuously upskill yourself with access to free online learning via MyAcademy, an international teaching marketplace with over 100000 courses from Harvard and other leading providers + share knowledge with your peers.
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity and paternity leave, and you can even take paw-ternity leave for your furry friend.
Annual Inspiration Day! Make time for that pottery course or spa day you've always wanted to do.
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"EY is a global leader in
assurance, tax, transaction and advisory services. Technology is at the heart
of what we do and deliver at EY. Technology solutions are integrated in the
client services we deliver and are key to our innovation as an organization.

Fueled by
strategic investment in technology and innovation, Client Technology seeks to
drive growth opportunities and solve complex business problems for our clients
through building a robust platform for business and powerful product engine
that are vital to innovation at scale. As part of Client Technology, you’ll
work with technologists and business experts, blending EY’s deep industry
knowledge and innovative ideas with our platforms, capabilities, and technical
expertise. As a catalyst for change and growth, you’ll be at the forefront of
integrating emerging technologies from AI to Data Analytics into every corner
of what we do at EY. That means more growth for you, exciting learning
opportunities, career choices, and the chance to make a real impact.

The selected
candidate
Develops
large and complex data architecture, composed of models, policies, rules or
standards that govern which data is collected and how it is stored, arranged,
integrated and put to use in data systems, including the design, build and
management of data infrastructure to address business requirements
Creates
sound use case driven roadmaps, depicting data architecture as-is and to-be
capabilities with the business by engaging with multidisciplinary teams, and by
identifying, managing and mitigating risk
Develops
relationships across the business to understand data requirements, applies deep
technical knowledge of data management to solve business problems in areas
where solutions may not currently exist, necessitating new solutions/ways of
working/technologies and proactively articulating these to the business
Review,
identify the latest emerging technologies, augmenting by services from the
leading cloud providers to solution and recommend the best next generation data
platform value driven approach for our clients
Your Key Responsibilities Include
Create
and maintain conceptual, logical and physical database models
Document
functional requirements and system specifications into the data architecture
and detailed design specifications for current and proposed designs
Document
and adhere to development standards and best practices in database designs
Maintain
highly effective and consistent communication within the team, peers, and the
leadership team
Reverse
engineer SQL code and modify it to solve problems/issues
Contribute
to the definition and implementation of data governance practices
Design
both data structures and data integration practices
Work
closely with the infrastructure teams to create a physical environment to
support data services
Evaluate
new and existing (internal and external) technologies and services in support
of data services and data analytics objectives
Skills And Attributes For Success
Understanding
of business process reengineering and business modeling concepts, business
systems development and analysis
Hands-on
experience in designing and implementing hybrid cloud and on-prem solutions
Experience
working with the latest versions of SQL Server
Experience
applying SAFe/Scrum/Kanban methodologies
Ability
to exercise judgment in solving technical, operational, and organizational
challenges
Expert
programming, performance tuning and troubleshooting skills, using the latest
popular programming languages for example python
Demonstrate
proactive approach to identifying issues and presenting solutions and options,
and where appropriate, leading to resolution
Minimum Qualifications
5+ years
demonstratable work experience as a Data Architect using data modeling tools
2-3 years
SQL coding experience on large projects
Must
possess expert SQL programming, performance tuning and troubleshooting skills
Create
database objects and SQL scripts
Understand
and developed data pipelines
Know how
to deformalize data for data science models
Experience
in python, spark and notebooks
Experience
designing data warehousing solutions
Experience
designing next generation data platforms utilising cloud services
In-depth
understanding of database structure principles
Seamlessly
able to translate business requirements to technology requirements
What We Look For
Strong
analytical skills and problem-solving ability
A
self-starter, independent-thinker, curious and creative person with ambition
and passion
Excellent
inter-personal, communication, collaboration, and presentation skills
Customer
focused
Excellent
time management skills
Positive
and constructive minded
Takes
responsibility for continuous self-learning
Takes the
lead and makes decisions in critical times and tough circumstances
Attention
to detail
High
levels of integrity and honesty
Curious
about new emerging technology
About EY
As a global leader in assurance, tax, transaction and consulting
services, we’re using the finance products, expertise and systems we’ve
developed to build a better working world. That starts with a culture that
believes in giving you the training, opportunities and creative freedom to make
things better. Whenever you join, however long you stay, the exceptional EY
experience lasts a lifetime.",3.8,"EY
3.8",Johannesburg,-1,10000+ Employees,1989,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Architect - Principal,-1,"We are looking for Principle Data Architect to join our Engineering team in Cape Town.

The world is changing.
We all want something different.
At Luno, we see you as individuals.

Together, we are upgrading the world of work to unleash the potential within and empower you to become the best possible version of yourself.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the financial landscape, and to do so, well we need the best team on board for our mission. In short, to achieve our goals, we need rockstars. As simple as that.

A little about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 5 million customers across 40 countries.
We're part of the Digital Currency Group, a group of companies driving progress in the cryptocurrency and blockchain space that includes Grayscale, Genesis, Coindesk and Foundry Services
Our platform has processed over $8 billion to date
We're proud to be one of the world's most international cryptocurrency teams from 43 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
How we work


Our engineering team (currently ~100 engineers) is split into organisations which we call Fleets. Each Fleet focuses on a core customer journey (onboarding, security, payments, support, new business, growth and marketing etc.). Each of these fleets contains multiple smaller teams called Pods, each of which focuses on a specific aspect of the product.

Pods will include a product owner, product designer, back-end engineers, Android, iOS and Web developers, who each bring a unique perspective to the problem you are all contributing towards.

We're agile, use scrum, continuous integration and continuous delivery, deploying to production every single day.

We're building teams to help us succeed in our mission to upgrade the world to a better financial system. You'll be joining a group of highly motivated software engineers who you'll work collaboratively with across our pods.

As a fast-growing company with offices around the world, you'll immediately see how your contributions directly impact both our internal users and client experience. Many of the problems we are solving result in trail blazing solutions which can't be found on Stack Overflow; so we're looking for engineers who flourish working in a complex domain.

In your first six months, you will:


...start at Luno by learning our processes, meeting the wider team and starting our engineering on-boarding program. After getting comfortable with the basics, you'll start learning our idiomatic patterns in a safe, easy-to-follow way - by building your own toy micro services. You'll get to practice how we do design docs, code reviews, deployments, events, logging and monitoring.

You'll meet the Pod(s) you'll be working with and quickly align on the teams' current OKRs and product roadmap. We succeed as a team, so we will provide you with regular feedback from your manager and peers and will encourage you to do the same.

What you'll do:
Work closely with our data science and platform teams on projects introducing new streams of data into our data lake
You will get to bring new ideas on how to further develop and innovate our data solutions and how to expose that data to the business
Accountable and Responsible for the design and architecture of Data systems that are robust and scalable.
Work in an Agile/Scrum framework or Agile mindset
Data backup/recovery and storage
Pick-up and learn new concepts, in both engineering and product, and be able to apply that knowledge quickly.
The ideal candidate for this role will have:
7+ years' experience in maintaining scalable data solutions and/or you are passionate about it
Ability to understand, communicate and advocate between build vs buy
Proven track record of setting up, restructuring and maintenance of databases
You know your way around ETL and you have experience with SQL
Experience in the AWS Data stack (RedShift,DynamoDB, Amazon RDS)
Familiarity with integrating data stores with BI platforms such as Looker, Tableau, or Power BI
You have experience with the concepts of CI/CD
Coding skills in e.g. Go, Python
Bachelor's degree in a related field preferred
AWS Certified DataOps Administrator
Be friendly, transparent, articulate and driven to succeed
Basic knowledge of and passion for digital currencies like Bitcoin
A work permit for South Africa if you are not a South African citizen
Don't be put off if you don't tick all of the boxes – they're a guide based on what we'd love to see but we appreciate that excellent software engineers have diverse backgrounds.

Remote Life at Luno


If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity / paternity and even (yes, you are reading it correctly) paw-ternity for your furry friend..
Annual Inspiration Day.. like that pottery course you've always been meaning to do!
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. You'll need to hold the legal right to work in South Africa already as we cannot provide visa sponsorship.

Be part of the change!",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer - EC2 Capacity Data Analytics,-1,"EC2 Capacity Data Analytics (CDA) team is looking for a Data Engineer to join our team.

Our team is part of the EC2 Capacity Engineering organization, which is responsible for providing the elasticity EC2 customers need to scale up/down compute resources in a cost-efficient manner. We predict customer usage across thousands of configuration combinations to deliver exactly what our customers require in just the right amount of time with just the right amount of capacity.

As a Data Engineer, you will build the ETL and analytics solutions for our internal customers to answer questions with data and drive critical improvements for the business. You will use best practices in software engineering, data management, data storage, data compute, and distributed systems. On any given day, we use Python, Scala, Java, SQL, Lambda, CloudFormation, Redshift and Glue as well as other public AWS services and a host of Amazon internal tools. We dont expect you to be an expert in, or necessarily even be familiar with all of the technologies listed above, but we do expect you to be excited to learn about them.

This position involves on-call responsibilities, typically for one week every two months. Our team is dedicated to supporting new team members. We care about your career growth, we try to assign projects and tasks based on what will help each team member develop into a more well-rounded engineer and enable them to take on more complex tasks in the future.

Our team values work-life balance and we are flexible when people occasionally need to work from home.

Job Duties
Develop and maintain automated ETL pipelines for big data using languages such as Scala, Spark, SQL and AWS services such as S3, Glue, Lambda, SNS, SQS, KMS. Example: ETL jobs that process a continuous flow of JSON source files and output the data in a business-friendly Parquet format that can be efficiently queried via Redshift Spectrum using SQL to answer business question.

Develop and maintain automated ETL monitoring and alarming solutions using Java/Python/Scala, Spark, SQL, and AWS services such as CloudWatch and Lambda.

Implement and support reporting and analytics infrastructure for internal business customers using AWS, services such Athena, Redshift, Spectrum, EMR, and QuickSight.

Develop and maintain data security and permissions solutions for enterprise scale data warehouse and data lake implementations including data encryption and database user access controls and logging.

Develop and maintain data warehouse and data lake metadata, data catalog, and user documentation for internal business customers.

Develop, test, and deploy code using internal software development toolsets. This includes the code for deploying infrastructure and solutions for secure data storage, ETL pipelines, data catalog, and data query.


Basic Qualifications

· Bachelors degree in Computer Science or related technical field, or equivalent work experience.
· 4+ years of overall work experience including Software Engineering, Data Engineering, Database Engineering, Business Intelligence.
· Experience with AWS technologies stack including Lambda, Glue, Redshift, RDS, S3, EMR or similar big data solutions stack

Preferred Qualifications

· Demonstrate efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data.
· Demonstrable proficiency in distributed systems and data architecture; design and implementation of batch and stream data processing pipelines; knows how to optimize the distribution, partitioning, and MPP of high-level data structures.

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer,-1,"Our client based in Johannesburg is urgently looking for a Data Engineer to be on a 3 months contract
Build data pipelines, experience in new tech like nifi, kafka, python

Joburg based, open to EE, 3 month contract with the option to extend, must be available at short notice",-1,EQplus,Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Overview
Job ID: 51456
Job Sector: Information Technology and Services
Country: South Africa
Region/State/Province/District: Gauteng
Location: Johannesburg

Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose

This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes

Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems

Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions

Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.
Research and best practices

Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development

Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.

Preferred Qualification and Experience

Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry

Knowledge/Technical Skills/Expertise

Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision

PLEASE NOTE: All our recruitment and selection processes comply with applicable local laws and regulations. We will never ask for money or any form of payment as part of our recruitment process. If you experience this, please contact our Fraudline on +27 800222050 or forward to TransactionFraudOpsSA@standardbank.co.za",4.1,"Standard Bank
4.1",Johannesburg,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"About us

At PBT Group we pride ourselves on being a Data Specialist organisation. With 20 years of experience in 27 countries over 3 continents, our team of 550 consultants have implemented more than 700 projects.",4.3,"PBT Group
4.3",Johannesburg,-1,Unknown,-1,Company - Private,Accounting,Accounting & Legal,Less than $1 million (USD),-1
Data Engineer,-1,"Kick-start your career in the online gaming world and experience the very latest in technology and innovation.

The Department:

Our mission is to provide our customers with the best online betting experience and share the thrill of gaming with them. Data is at the very heart of our business and is vital in everything we do.

Our cross-functional Data team has a big and exciting challenge ahead. We are in the process of re-platforming our traditional, on-premises RDBMS environment to a new microservice architecture in the cloud. We’re making use of the diverse set of data technologies in Microsoft Azure to offer new services, reporting structures and real-time data pipeline while serving the day-to-day requirements of a rapidly growing, data-hungry organisation.

Purpose of the Role:

This is an excellent opportunity for an individual who is looking to gain new skills. We are committed to creating a culture of learning and regularly run proof of concepts, provide internal demos, manage workshops and attend external conferences. Our data team has a wide range of skills including development for highly transactional RDBMS systems, data warehousing, data science and cloud technologies and we are always working to raise everyone’s game.

Duties include, but not limited to:

Work as part of an agile Data Engineering Team
Development of greenfield projects in Azure
Develop and maintain on-premises RDBMS/DW systems
Create robust ETL services and real-time data pipelines
Build and maintain Continuous Integration and DevOps pipelines
Test-driven development and pair programming with colleagues

Essential Criteria:

C#, .Net, Visual Studio
Git, Azure DevOps
NoSQL development (CosmosDB)
Demonstrable understanding of MS SQL Server in a highly transactional environment
Demonstrable understanding of development in Microsoft Azure
Able to understand query plans and identify performance bottlenecks
Test/Business-Driven Development
Building Continuous Integration/Deployment pipelines
Communicate effectively with both technical and non-technical stakeholders

Desirable Criteria:

Implementing Data Storage and Processing solutions in Azure (ARM Templates, Storage Accounts, Data Lake Storage, SQL DB, Cosmos DB, EventHubs, Function Apps, Log Analytics, Data Factory, Databricks, Polybase)
Implementing Security, Disaster Recovery, High Availability, Auditing, Monitoring and Alerting solutions in Azure
Automating tasks in Azure using Powershell / CLI
Predicting costs and optimizing spending in Azure
Message Queues (RabbitMQ, Kafka)
Python

Person Specifications:

Resilience
Teamwork
Technical Knowledge
Communication skills
Stress Tolerance
Please note we will apply relevance to our Talent Management and Talent Development Programme as part of our recruitment process.
Shortlisted candidates may need to complete an assessment.
This position requires trust and honesty it has access to customers financial details - therefore a credit and criminal record check will be conducted. The qualifications identified herein are an inherent job requirement; therefore, a qualification verification check will be done. By applying for this role, and supplying the necessary details, you hereby grant us permission to apply for these checks. This will be done in a confidential manner, and solely for the purposes of verification.

To view all current vacancies, please visit our website, www.digioutsource.com

Should you not hear from us within 2 weeks, please deem your application as unsuccessful.

The perfect place to work, play and grow!",3.9,"Digital Outsource Services
3.9",Cape Town,-1,1001 to 5000 Employees,1997,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
Data Engineer,-1,"At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes

Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.

Key Responsibilities

Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.

Key Traits

Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern

Position Requirements

2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.

Where will you work? This role will be based out of Durbanville, South Africa.",3.1,"Aculocity, LLC
3.1",Durbanville,-1,1 to 50 Employees,2006,Company - Private,IT Services,Information Technology,$1 to $5 million (USD),-1
Data Engineer,-1,"ENVIRONMENT:

A rapidly growing E-Commerce Platform seeks a highly talented Data Engineer to make an invaluable contribution to data democratisation and literacy vision by making accessible and easy-to-use data products and tools. You will require a Comp-Sci Degree or 3 years’ relevant industry experience, MySQL, PostgreSQL, Java, Python, in-depth understanding of OLAP, Data Marts, Star Scheme, Snowflake, be familiar with Jenkins, Travis, Circle CI, Docker, Kubernetes, experience with Kafka, Pub/Sub, Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks & significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing & Data Lake design and implementation and Lambda/Kappa architectures.

DUTIES:

Design, develop, test and maintain data architecture.

Prepare data for descriptive, predictive and prescriptive modelling.

Automate repetitive tasks and manual processes related with the data usage.

Optimize data delivery.

Design, develop and test large stream data pipelines to ingest, aggregate, clean, and distribute data models ready for analysis.

Ensure the highest standard in data integrity.

Leverage best practices in continuous integration and delivery.

Collaborate with other engineers, ML experts, analysts, and stakeholders to produce the most efficient and valuable solutions.

Implement features, technology, and processes that move us towards industry best practices, improving on scalability, efficiency, reliability, and security.

Operations and ownership of systems in production, responding to incidents.

REQUIREMENTS:

Qualifications –

Comp-Sci Degree or 3 years relevant industry experience.

Experience/Skills –

Open source relational database systems e.g. MySQL, PostgreSQL, etc.

Significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing, and Data Lake design and implementation and Lambda/Kappa architectures.

A thorough understanding of database and data warehousing principles e.g. OLAP, Data Marts, Star Schema, Snowflake, etc.

Java and Python.

Familiar with CI/CD tools such as Jenkins, Travis, Circle CI, etc.

Experience with Kafka, Pub/Sub, or other event-based systems.

Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks, etc.

Working in cloud environments and with containerisation frameworks, tools and platforms e.g. Docker, Kubernetes, GKE, etc.

A deep understanding of data pipelining, streaming, and Big Data technologies, methods, patterns, and techniques.

Troubleshooting complex database operations and performance issues.

Automating tasks using Shell Scripting or writing small applications.

ATTRIBUTES:

Works well with people and is passionate about helping people be their best.

A team player, an active listener, mentor, and able to communicate well.

Shows solid reasoning and decision making, with the ability to work under pressure.

Is passionate about technology, systems and data.

Is curious, always learning, and keeping up to date with the industry.

While we would really like to respond to every application, should you not be contacted for this position within 10 working days please consider your application unsuccessful.

COMMENTS:

When applying for jobs, ensure that you have the minimum job requirements. Only SA Citizens will be considered for this role. If you are not in the mentioned location of any of the jobs, please note your relocation plans in all applications for jobs and correspondence.",-1,Datafin IT Recruitment,Cape Town,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Cartrack is looking for passionate data science and engineering candidates that can join a growing team that is responsible for the intelligence and efficiency solution provision to over a million subscribers, many of whom are large fleets. We are in the midst of creating revolutionary platforms that will change the way that people interact with their vehicles.

You will have the opportunity to work with the very brightest global subject matter experts that are transforming the automotive industry across Fleet Management, Asset Management and Insurance Telematics solutions.

Get to know the role:

The role of a data engineer is a supporting one, but it is also an extremely vital one. As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements. We want to see candidates with mechanical tendencies and a desire to know how things work and to improve them.

The day-to-day activities:

Design, construct, install, test and maintain data management systems.
Build high-performance algorithms, predictive models, and prototypes.
Ensure that all systems meet the business/company requirements as well as industry practices.
Integrate up-and-coming data management and software engineering technologies into existing data structures.
Develop set processes for data mining, data modeling, and data production.
Create custom software components and analytics applications.
Research new uses for existing data.
Employ an array of technological languages and tools to connect systems together.
Install/update disaster recovery procedures.
Recommend different ways to constantly improve data reliability and quality.
Work on and maintain Data pipelines.

Requirements Essential:

At least 5 years’ proven experience as a Data Engineer, DevOps Engineer, Software Developer, or similar.
Proficient in Linux/Unix and shell scripting as well as in functional programming languages.
Expertise in setting up and explored with technologies such as Hadoop and Spark.
Bachelor’s degree in computer science, software/computer engineering, applied mathematics, or physics.",3.3,"Cartrack
3.3",Johannesburg,-1,501 to 1000 Employees,2004,Company - Private,Security Services,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Data Engineer,-1,"Data Engineers build and support data pipelines and datamarts built off those pipelines. Both must be scalable, repeatable and secure. The Data Engineer helps to facilitate gathering data from a variety of different sources, in the correct format, assuring that it conforms to data quality standards and assuring that downstream users can get to that data timeously. This role functions as a core member of an agile team. These professionals are responsible for the infrastructure that provides insights from raw data, handling and integrating diverse sources of data seamlessly. They enable solutions, by handling large volumes of data in batch and real-time by leveraging emerging technologies from both the big data and cloud spaces. Additional responsibilities include developing proof of concepts and implements complex big data solutions with a focus on collecting, parsing, managing, analysing and visualising large datasets. They know how to apply technologies to solve the problems of working with large volumes of data in diverse formats to deliver innovative solutions. Data Engineering is a technical job that requires substantial expertise in a broad range of software development and programming fields. These professionals have a knowledge of data analysis, end user requirements and business requirements analysis to develop a clear understanding of the business need and to incorporate these needs into a technical solution. They have a solid understanding of physical database design and the systems development lifecycle. This role must work well in a team environment.

Job Objectives

Work Complexity: * Architects Data analytics framework. * Translates complex functional and technical requirements into detailed architecture, design, and high performing software. * Leads Data and batch/real-time analytical solutions leveraging transformational technologies. * Works on multiple projects as a technical lead driving user story analysis and elaboration, design and development of software applications, testing, and builds automation tools.

Main Job Objectives: 1. Development and Operations 2. Database Development and Operations 3. Policies, Standards and Procedures 4. Communications 5. Business Continuity & Disaster Recovery 6. Research and Evaluation 7. Coaching/ Mentoring

Qualifications

Essential: 4 years Bachelors degree in computer science, computer engineering, or equivalent work experience AWS Certification at least to associate level

Experience

Essential:

5+ years Data engineering or software engineering

3-5 years demonstrated experience leading teams of engineers

2+ years Big Data experience

5+ years experience with Extract Transform and Load (ETL) processes

2+ years Could AWS experience

At least 2 years demonstrated experience with agile or other rapid application development methods - Agile exposure, Kanban or Scrum

5 years demonstrated experience with object oriented design, coding and testing patterns as well as experience in engineering (commercial or open source) software platforms and large scale data infrastructures.

Desirable:

5+ years Retail Operations experience

Knowledge and Skills

Essential: *Creating data feeds from on-premise to AWS Cloud (2 years) *Support data feeds in production on break fix basis (2 years) *Creating data marts using Talend or similar ETL development tool (4 years) *Manipulating data using python and pyspark (2 years) *Processing data using the Hadoop paradigm particularly using EMR, AWSs distribution of Hadoop (2 years) *Devop for Big Data and Business Intelligence including automated testing and deployment (2 years) * Extensive knowledge in different programming or scripting languages * Expert knowledge of data modeling and understanding of different data structures and their benefits and limitations under particular use cases.

Further technical skills required: * Capability to architect highly scalable distributed systems, using different open source tools. * Big Data batch and streaming tools * Talend (1 year) * AWS: EMR, EC2, S3 (1 year) * Python (1 year) * PySpark or Spark (1 year) - Desirable * Business Intelligence Data modelling (3 years) * SQL (3 years)",-1,Datonomy Solutions,Brackenfell,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We are assisting one of our clients that is based in Pretoria to fill a role of a Data Engineer

This is a 12 month contract role

Objective of this Scope of Work

The Data Engineer will drive improvement of the data management maturity levels and provide the necessary technical support within the company to support reliable and effective decision-making, appropriate usage and protection thereof.

Scope of Services Definition

The scope will include but will not be limited to:

ï†· To develop, construct, test and maintain architectures.

ï†· To ensure architectures will support the requirements of business.

ï†· To discover opportunities for data acquisition and sharing.

ï†· To develop data set processes for data modelling, mining and production.

ï†· To employ a variety of languages and tools to marry systems together.

ï†· To recommend way to improve data reliability, efficiency and quality.

ï†· To prepare data for use in predictive and prescriptive modelling.

ï†· To conduct research to answer industry and business questions.

ï†· To leverage volumes of data from internal and external to answer business questions.

ï†· To develop and manage stakeholder relations effectively to promote data management across the organisation and support reliable decision making and appropriate data usage.

ï†· To participate and provide technical support in cross organisational activities relating to any of the above mentioned data management activities.

ï†· To provide regular progress reports as per stakeholder requirements and present data management updates in various forums as required.

Minimum qualification Required:

ï†· A minimum of a Bachelors degree in Computer Science or Information Management OR equivalent;

ï†· A minimum of five to eight years experience in a data management environment",-1,HR Genie,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Our client based in the Northern Suburbs, is currently looking for a Data Engineer to join their team.

Responsibilities
Our client is a dynamic IT company that delivers value-driven IT solutions to the group. Our work lives revolve around our DNA. We take pride in our work, treat our colleagues, partners and our country with respect. We exercise collaborative decision-making and believe in having a balance in life. We do this all while having fun and enjoying what we do.

The primary focus of this position is to use technical skills to put software, systems and data together in a way that extracts meaningful insights from raw data. You will need to be helpful and supportive to your team and fellow developers. You join an energetic, focused and dynamic team.

Interact with clients to understand requirements and business problems/needs

Identify, analyse, visualise and understand supporting data to propose solid solutions

Create technical documentation for reference and reporting

Support existing solutions within GCP and Oracle

Doing standby on a rotating basis

Key Competencies and Qualifications

Matric

Tertiary qualification in IT

Preferred cloud experience in AWS/AZURE/GCP

At least 3 years of data warehouse ETL experience

Dimensional Modelling

Data analyses

Experience with data visualization and visualization tool(s)

Knowledge of the retail industry will be beneficial

Understanding and experience with version control SVN/GIT

Preferred – Korn shell scripting, Python/Java, SQL

Google Cloud Platform experience would be looked upon favourably

Having a broad understanding of different SDLC’s

Preferred agile experience

Strengths

The natural tendency to take ownership and responsibility

Strong problem solving, critical thinking, effective planning and organisational skills

Detail-oriented with excellent communication skills

You have a can-do attitude and positive outlook on life

Can cope under pressure

Curious and interested in analysing problems and possible solutions

Strong team player

Self-driven learner, passionate about new technology

Above all, be passionate about what you do

Should you wish to apply for the position, please apply directly via this job board, please ensure that you quote reference number 201620 subject heading or email body.

Please note that due to the high volume of CV's received; only shortlisted applicants will be contacted. Should you not receive communication from our offices within two weeks of submission please note that your application will not be considered for this position.

We will keep your CV on file and re-establish contact with you should opportunities in line with your expertise become available again.

Should you require any additional information give us a call on 021 012 5566.",-1,Surgo HR & Training,Cape Town,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We believe that our employees fuel our organization, essential to enable us to help our customers overcome their business challenges and achieve sustainable growth. As a result, we are committed to growing each individual and providing them with the challenges, feedback and support needed to achieve success in their career

If this sounds appealing, and like us, you get excited about data: its collection, storage, transformation or display, see if you’ve got what it takes to join our sought after DATA team.

Key Responsibilities And/or Outputs

You will represent IQbusiness at our customers, sometimes alone, and sometimes as part of an IQ team.

Providing a superior customer experience by building and maintaining relationships, working at customer offices, keeping data confidential
Design and develop – databases, SQL queries, stored procedures, reports, dashboards or integration solutions
Produce solutions for both real-time and batch environments
Test your work to ensure compliance
Solve problems, and do root cause analysis
Prioritize your workload
Assist in other areas relating to your true data function, such as data modeling, data and business analysts
Interact with a variety of individuals: senior, junior, technical and from business
Provide guidance to fellow colleagues, or even manage a team
Uphold the IQ values, which are to care, learn & share; innovate; deliver as well as to build, enhance and maintain relationships

Education

Matric pass
A tertiary qualification, preferably in an ICT relevant field
Appropriate Microsoft certifications are beneficial but not required

Requirements

3 - 6 years experience in the Data Engineering environments and technologies
Great communication skills
A passion for SQL, databases or reports
Can you write stored procedures, design complex queries and create views and triggers?
Are you able to work out the relationships in a data warehouse or the aggregation of a cube?
Do you extract and display useful information when you see patterns and trends in data?
Strong knowledge of the financial services industry, ideally in a consulting role
The use of data related software: databases, ETL and BI tools; report writing and analytical tools
We use a lot of Microsoft products. You may often be expected to use MS SQL Server, SSIS, SSRS, SSAS and Power BI to develop solutions
What other relevant software have you’ve used?
Ability to work in different project methodologies: Waterfall and/or Agile
Knowledge of full SDLC
Exposure to logical and physical data modeling

Equal Employment Opportunity

IQbusiness is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, citizenship, marital, domestic or civil partnership status, sexual orientation, or gender identity",3.7,"IQbusiness South Africa
3.7",Johannesburg,-1,1 to 50 Employees,-1,Company - Private,Consulting,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"We value a data engineer as someone who works behind the scenes to obtain, process and supply data via various methodologies and technologies, to various consumers, in ways and forms that makes sense and add value. This definition is very broad, as the field of data engineering is just as broad.

You may be the type of data engineer that develops API endpoints for the consumption of data by end users or even another data pipeline, or you may be the type of data engineer that develops highly distributed, high availability data processing pipelines in an effort to satisfy the need of the ever questioning data analysts and/or data scientists.

You have awesome knowledge about the following concepts
Data modelling
Relational data modelling in traditional relational database management systems. (Microsoft SQL Server, MySQL, PostgreSQL, etc)
Coercing unstructured and semi-structured data into a structured form.
Data pipelining knowledge - data extraction and transformation.
Data transformation knowledge for reporting and analytics purposes.
Knowledge of the MapReduce and related data processing paradigms would be a boon.
You have the following technical competencies
Writing SQL queries, that can relate, transform and aggregate data from many differing sources where natural keys may or may not exist.
Experience with writing data pipelines that move and transform data, for various uses.
Working knowledge of a general purpose programming language like Python would be a boost.
Working knowledge of columnar databases such as Google BigQuery, and SAP HANA would be a boost.
Working knowledge of highly distributed technologies such as Apache Hadoop or Apache Spark would be a boost.
Working knowledge of NoSQL technologies, such as Apache Solr would be a boost.
You have the following personal competencies
The ability to solve problems.
The ability to rotate around a problem, to see if solutions can be gained in different ways.
The ability to work in an ever changing, unstructured environment.
The ability to work as part of a team, with vastly differing skill sets and opinions.
The ability to contribute ideas to the quorum.
The ability to mentor and provide guidance for other team members.
A systems approach to thinking, as opposed to a siloed approach. The candidate needs to understand how their work affects the greater system.
The ability to work without supervision, and take accountability for the work they deliver.
The ability to liaise with a client, sifting through the fluff and extracting the actual requirements.
If this is you - apply now and we'll get in touch",-1,DotModus,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Data Engineer

Our client in the contact centre space is currently seeking a DATA ENGINEER that will work on the collecting, storing, processing, and analyzing of large datasets. The primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them. You will also be responsible for integrating them with the architecture used across the company.

Key Performance Areas:

Data reporting.
Implementing ETL processes.
Defining data retention policies.
Management of Customer Lead data.
Provision of data for advanced analytics.
Maintenance of internal client scorecards.
Assist team in resolving data-related support queries.
Optimize existing data processes through automation.
Assist with all data-related reporting and documentation.
Maintenance and optimisation of the Analytics database.
Provide technical support to and supervision of junior data administrators.
Continuous upskilling on new technologies, frameworks and market trends.
Monitoring performance and advising any necessary infrastructure changes.
Identifying, selecting and integrating any Big Data tools and frameworks required to provide real-time analytics.

Educational Requirements

IT related Degree or Diploma is a pre-requisite

Required Skills/Experience

ETL tools: Advanced SSIS
BI/Reporting : Qlikview/Power BI/ SSRS or SSAS
Programming languages: JAVA, C# , Python, SAS or R
Experience with NoSQL databases and/or campaign management tools will be advantageous.
Minimum 3 years’ applicable work experience in SQL, relational databases and data manipulation.
Experience in big data platforms (eg. Hadoop) or processing frameworks (eg. MapReduce/Spark) and querying tools (eg. Pig, Hive and Impala) will be highly beneficial.

Preferred Skills

Organizational skills
Experience in Attentional to detail.
Accountability is critical for this role.
Ability to work under pressure and meet deadlines.
Solid understanding of database design principles.
Should you not receive a response in 2 weeks please consider your application unsuccessful",-1,Rubik's Cubed Consulting,Durban,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"This well known company is looking for a Data Engineer. will be based in Rivonia
The ideal candidate will have strong experience in the following:
Data cleaning
SQL Export
Big data Sets

BSc Degree in Maths and Stats will be required
a min of 3 years experience.
Stable track record is required.

Send your Cv to marinda@prrrecruitment.co.za",-1,PRR Recruitment Services,Johannesburg,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Description

Position at Aculocity, LLC

At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes
Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.
Key Responsibilities
Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.
Key Traits
Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern
Position Requirements
2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.
Where will you work? This role will be based out of Durbanville, South Africa.",-1,GVW,Durbanville,-1,Unknown,-1,Unknown,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Information Technology, Gauteng JHB - Northern Suburbs

Market related - Market related Annually

An IT Consultancy Business based in Johannesburg is currently looking for a Business Intelligence Consultant / Data Engineering Consultant.

Requirements:

Extensive experience in data engineering
Experience in Business Intelligence, data and Power BI
Extensive experience in data governance and the Popi act
Ability to assess and make recommendations on data within the Popi act
Good understanding of T-SQL and query optimization, developing ETL strategies.
Good understanding with SQL Server 2008/2012, SSIS, SSRS and SSAS
Use SSIS to create ETL packages to validate, extract, transform, and load data into the data warehouse and data marts.
Deploy and configured the reports in the Report Server (SSRS).
Excellent experience in Tabular Modelling , PowerView, Qlikvie,w, and Power BI
Maintain ETL
Qlikview model
Create Drill-through, Drill-down, and Cross Tab Reports and Sub-Report using Report Definition Language (RDL).
Generate periodic reports based on the statistical analysis of the data using SQL Server Reporting Services (SSRS)
Advise and provide written technical documentation and recommendations

The information displayed above is not limited to advertisements. Please contact Thato for further information.

Please consider your application as unsuccessful if you have not received a response within 14 days of submitting your application. However, please keep a lookout on our website, www.bedifferent.co.za, for available positions that you may be suited for

Ad Visible Until: 29 October 2020
Ref: JHB005346/NL

Vacancy Type: Permanent",2.9,"Be Different Recruitment
2.9",Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Cloud Support Engineer (Big Data),-1,"ABOUT US

Amazon Web Services is the market leader and technology forerunner in the Cloud business. As a member of the AWS Support team you will be at the forefront of this transformational technology, assisting a global list of companies and developers that are taking advantage of a growing set of services and features to run their mission-critical applications. As a Cloud Support Engineer, you will act as the Cloud Ambassador across all the cloud products, arming our customers with required tools & tactics to get the most out of their Product and Support investment.

Would you like to use the latest cloud computing technologies? Do you have an interest in helping customers understand application architectures and integration approaches? Are you familiar with best practices for applications, servers and networks? Do you want to be part of a customer facing technology team helping to ensure the success of Amazon Web Services (AWS) as a leading technology organization?

If you fit the description, you might be the person we are looking for! We are a group of smart people, passionate about cloud computing, and believe that world class support is critical to customer success.

WHAT CAN YOU EXPECT FROM A LIFE AT AWS?

Every day will bring new and exciting challenges on the job while you:

· Learn and use groundbreaking technologies.
· Apply advanced troubleshooting techniques to provide unique solutions to our customers' individual needs.
· Interact with leading engineers around the world.
· Partner with Amazon Web Services teams to help reproduce and resolve customer issues.
· Leverage your extensive customer support experience to provide feedback to internal AWS teams on how to improve our services.
· Drive customer communication during critical events.
· Drive projects that improve support-related processes and our customers technical support experience.
· Write tutorials, how-to videos, and other technical articles for the developer community.
· Work on critical, highly complex customer problems that may span multiple AWS services.

WHY AWS SUPPORT?

· First and foremost this is a customer support role in The Cloud.
· On a typical day, a Support Engineer will be primarily responsible for solving customers cases through a variety of customer contact channels which include telephone, email, and web/live chat. You will apply advanced troubleshooting techniques to provide tailored solutions for our customers and drive customer interactions by thoughtfully working with customers to dive deep into the root cause of an issue.
· Apart from working on a broad spectrum of technical issues, an AWS Support Engineer may also coach/mentor new hires, develop & present training, partner with development teams on complex issues or contact deflection initiatives, participate in new hiring, write tools/script to help the team, or work with leadership on process improvement and strategic initiatives.
· Career development: We promote advancement opportunities across the organization to help you meet your career goals.
· Training: We have training programs to help you develop the skills required to be successful in your role.
· We hire smart people who are keen to build a career with AWS, so we are more interested in the areas that you do know instead of those you havent been exposed to yet.
· Support engineers interested in travel have presented training or participated in focused summits across our sites or at specific AWS events.
· As we operate on a follow-the-sun model, with Premium Support sites located globally, there is no after hours on-call or mandated overtime in this role.
· https://www.youtube.com/watch?v=GC3bWcFFZTo&t=24s



Basic Qualifications

The Big Data role supports our services that leverage data and produce business insights, which may include using Machine Learning/Artificial Intelligence (ML/AI). Helping our customers use and integrate Big Data services in what is arguably our industrys most exciting space. The portfolio of services covers EMR (Hadoop), DynamoDB (NoSQL), MangoDB, and Apache Cassandra.

· Advanced experience in Apache Hadoop, Apache Spark, Apache Hive, and Presto
· Advanced experience in DynamoDB or NoSQL technologies like MongoDB or Cassandra
· Advanced experience with System Administration with Linux (RHEL/CentOS) including Microsoft Active Directory, and LDAP integration.
· Experience with troubleshooting Kerberos Authentication problems.
· Experience with Network troubleshooting.
· Basic understanding of Machine Learning and statistics
· Experience with Java and Python and shell scripting
· Bachelors degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position



Preferred Qualifications

· Expert experience in the Hadoop Ecosystem including Apache Spark and Presto
· Expert experience in NoSQL
· Expert experience with blockchain technologies like Etherium Expert experience in data Data Lake architecture and administration
· Experience managing full application stacks from the OS up through custom applications
· Prior work experience with AWS - any or all of EC2, VPC, S3, RDS, EMR, Glue, SageMaker
· Excellent knowledge of Hadoop architecture, administration and support
· Expert understanding of distributed computing principles and their application in the cloud
· Good understanding of distributed computing environments Lead technical discussions on big data systems architecture and design
· Strong analysis and troubleshooting skills and experience
· AWS Certified Solutions Architect
· AWS certified Big Data Specialty
· Masters degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity and Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Response Center Engineer,-1,"Job Title
Response Center Engineer
Job Description


Philips is a world leading health technology company with a vision to make life better for people worldwide through meaningful innovation. Making good on this promise depends on our passionate, inspirational, collaborative and diverse team. We have over 80,000+ brilliant people around the world but are always looking for more. Like-minded, motivated, focused minds to join us in creating a healthier, more connected society while transforming themselves personally and professionally.

As a CCC Coordinator - Response Center Engineer you will have the opportunity to process customer calls and be responsible for screening and diagnosing professionally Healthcare equipment to support customers and colleagues remotely with solving technical issues and ensuring maximum customer satisfaction

You are responsible for:
Diagnose healthcare equipment to the quality standards set by Philips Healthcare (PH) remotely by interviewing customers or colleagues by telephone or by remotely logging in to the system
Advise Customer Care Center Coordinators and District Operations Managers and / or Team Leads about the best follow-up w.r.t. technical state of the diagnosed healthcare equipment
Advise the Customer Care Center Coordinators or Field Services Engineers about required spare parts and resources
Responsible for planning engineers related to Modality responsibility.
Responsible for coordination between CCC, CUSTOMER, Spare parts AND Engineer.
Responsible to drive Remote and FTR KPI’s to targets respectively 40% and 85%.
Will require minimal field work to keep abreast of technical capabilities.
Take calls from customers and make sure they are processed in the CCC ERP on timely manner including all relevant data
Support Field Services Engineers in the field with technical knowledge
Escalate technical issues to the Technical Support Specialist
Escalate technical issues to Business Unit support after consultation of the Technical Support Specialist
Monitor critical functions of the equipment’s in the IB and environmental conditions including RSN and True reachability.
Lead the planning and implementation of FSN’s and FCO’s accelerating remote implementation where applicable.
Submit timely and accurate service data, job sheets, reports, expense claims, radiation film badges, field problem reports and other paperwork as assigned
Keep abreast of new technologies likely to affect PH range of products
Use company property with care to ensure optimal results with minimal operational costs
Be a professional representative for PH with respect to customer problems, ensuring personal acceptability by the customer in behavior in accordance with PH policy and targets
Conform to PH safety standards including health and safety regulations and in the event of hazards or accidents to take immediate control of the situation and involve the Operations Manager and / or the responsible person to handle properly confidential issues according Philips standards and to act according General Business Principals
Follow all quality standards within the frame of valid PH business policies
Follow the company quality regulations (ISO 9001; PQA; TQM) and internal directives and procedures
You are a part of the dynamic South Africa Customer Care Centre Team .You will be reporting to the Customer Care Center Manager.

Requires a pleasant, assertive individual you can work very well in a team setting, a dynamic environment that requires flexibility and creativeness to achieve goals.

To succeed in this role, you should have the following skills and experience:
Degree level education or equivalent
Experience in maintenance and troubleshooting of technical complex systems
Fluent in English, verbal and written in addition to local language
In return, we offer you the unique combination of a critical and challenging role and a creative and empowering office environment. You will be actively encouraged to make improvements, establish best in class service and have a direct impact on the success of Philips on a daily basis.

Employment Equity

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply. Only apply for this role if you are a South African Citizen by birth or Naturalization prior to the 27 April 1994.

Why should you join Philips?

Working at Philips is more than a job. It’s a calling to create a healthier society through meaningful work, focused on improving 3 billion lives a year by delivering innovative solutions across the health continuum. Our people experience a variety of unexpected moments when their lives and careers come together in meaningful ways. Learn more by watching this video.

To find out more about what it’s like working for Philips at a personal level, visit the Working at Philips page on our career website, where you can read stories from our employee blog. Once there, you can also learn about our recruitment process, or find answers to some of the frequently asked questions.

Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.9,"Philips
3.9",Johannesburg,-1,10000+ Employees,1891,Company - Public,Health Care Services & Hospitals,Health Care,$10 to $25 million (USD),-1
Software Development Engineer - EC2 Placement,-1,"Build the systems that optimize how EC2 matches requests for Instances with the underlying compute capacity. EC2 Placement is seeking talented engineers to build the online and offline optimization systems for compute workload scheduling, and the customer capabilities to better manage those workloads. Amazon EC2 provides on-demand scalable compute capacity, and powers some of the largest services in the world. You will collaborate with a top-tier community of engineers to build systems to improve how customers are able to access EC2 compute resources.

The successful candidate will have strong software engineering experience, with a passion for thinking about, building and testing distributed systems. You have an interest in how Machine Learning and other optimization techniques can be applied to large-scale problems. You have demonstrated experience working with a team to design, build and operate large-scale systems. With strong engineering fundamentals, an analytical and data-driven approach to your work, and strong communication skills, you have the ability to collaborate well to deliver results. We move fast and work together on small teams to solve big problems.

If this opportunity sounds interesting, we would love to talk to you more about our work and the vibrant culture at AWS in Cape Town.

Basic Qualifications

· Degree in Computer Science or related field, or equivalent working experience
· 3+ years of industry experience in a software development environment
· Strong Computer Science fundamentals, including data structures, object-oriented design, algorithm design, problem solving, and complexity analysis.
· Proficiency in at least one modern programming language, such as Java, C#, Python, Scala, Kotlin

Preferred Qualifications

One or more of the following help you stand out:
· Demonstrated results designing, building and operating high-performance distributed systems in large-scale Linux environments
· Role model in writing high-quality, maintainable and secure code, mentoring others, and helping teams sharpen their development processes
· Ability to work effectively across teams to deliver results, with strong verbal and written communication skills
· Experience working with machine learning systems

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer - PBB IT,-1,"Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose


This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes
Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems
Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions
Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.

Research and best practices
Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development
Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.
Preferred Qualification and Experience
Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Aws Data Platform Engineer,-1,"Aws Data Platform Engineer

Posting Country:

South Africa

Date Posted:

15-Oct-2020

Full Time / Part Time:

Full Time

Contract Type:

Permanent

Joining Vodacom is more than a job, what we do matters. We don’t just carry minutes, texts and data – we carry people’s lives. And that’s a huge responsibility. If you think for a minute about the people you rely on…the likelihood is they rely on us.

Customers are at the heart of everything we do and we want to make a difference to the lives of our customers, and the communities in which we live and work. We support our people to give something back to the causes that mean the most to them through helping them give time and money to the charities they love.

And what’s it like to work here? We have created an environment where you can look forward to coming to work and are empowered to be at your best. We offer flexibility in how you work that helps you do your job in a way that suits you, opportunities to help you grow and progress throughout your career and a choice of benefits to suit your lifestyle.

Role Purpose
The H Band AWS Data Platform Engineer position is based within the Technology Business Unit.

The AWS Data Platform Engineer will be responsible for all Database services such as RDS, DynamoDB, etc. Should be able to migrate any databases from anywhere to AWS using any third-party tools or AWS database migration tool. Should also have understanding or expertise in creating data warehouses and data lake solutions on AWS.
Your responsibilities will include:
Apply practical knowledge of relational database design and usage with customers
Perform workload analysis and undertake performance tuning, as well as performance benchmarking in customer environments.
To develop state of the art solutions which are technically sound.
To provide a high-quality service to the Enterprise Cloud Services clients i.t.o. consultancy, solutions and delivery.
Commitment to team success and positive team dynamics including mentoring of other team members.
Passion for growing and applying technical skills in service to customers.
Be a trusted infrastructure advisor by providing objective, practical and relevant ideas, insights and advice.
Work collaboratively with consulting partners and technology teams to ensure high quality of solution delivery.
Encourage best practice and knowledge sharing with partners and cross-functional groups
Manage the overall database design and delivery of solutions.
Ability to make recommendations as they pertain to improvements in support/development initiatives and facilitate implementation with partners and cross-functional groups within the Business.
Participate in high level database solution definition and design during the implementation phase with the goal of providing reliable, stable and operationally sound applications that meet the Business requirements.
Ability to understand and translate business requirements into technical specifications
The ideal candidate will have:
A minimum of 3 years of industry related experience of which 1 year must be within a complex hosting environment.
Certifications in Database design, system architecture or cloud technologies.
Demonstrate knowledge of database systems internals including storage layouts and distributed databases/MPP architectures
Advanced SQL coding, tuning and query optimization.
Experience designing and leading database performance benchmarks.
Good knowledge of the different AWS services
Knowledge of cloud networking architecture, cloud operations, security, automation and orchestration.
Knowledge of database internals as it relates to query and system performance and tuning.
Understanding of overall system architecture, scalability, reliability, and performance in a database environment.
Excellent teamwork, time-management and organizational skills.
Perform other duties as deemed necessary and assigned by the customer and management
Strong interpersonal skills and problem-solving abilities.
Excellent documentation, communication and interpersonal skills.
Excellent analytical and problem-solving abilities.
Closing date for applications: Monday, 13 April 2020

The base location for this role is Vodacom World, Midrand

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply.
Vodacom is committed to an organisational culture that recognises, appreciates and values diversity & inclusion.

Commitment from Vodacom

Vodacom is committed to attracting, developing and retaining the very best people by offering a flexible, motivating and inclusive workplace in which talent is truly recognized, developed and rewarded. We believe that diversity plays an important role in the success of our business and we are committed to creating an inclusive work environment which respects, values, celebrates and makes the most of people’s individual differences - we are not only multinational but multicultural too. At Vodacom you will have access to our excellent flexible benefits programme that you would expect from any global company.",3.9,"Vodafone
3.9",Midrand,-1,10000+ Employees,1982,Company - Public,"Cable, Internet & Telephone Providers",Telecommunications,$10+ billion (USD),-1
Data Engineer Azure Data Factory,-1,"Enthuzex is looking for a motivated Lead Data Engineer to contribute towards the success of our Data and Analytics Technology initiatives. This is a hands-on technical role and this person will be responsible for the development and build of scalable solutions as it relates to the architecture strategies, data standards, digital data management, data integration, tools, and technology. The right candidate will play a deep dive hands-on critical development role in the digital transformation and in shaping how we acquire, ingest, transform and deliver data through the digital consumer channels.

Responsibilities:

Architect, design, develop and engineering end-to-end data pipelines across multiple data sources and systems of record.
Ensure data quality, integrity, security and completeness throughout the data lifecycle
Develop, design data models, data structures and ETL jobs for data acquisition and manipulation purposes
Develop deep understanding of the data sources, implement data standards, maintain data quality and master data management
Developing data services and API
Work closely with the cloud service providers to ensure completeness and alignment with the service offerings
Manage and maintain cloud based data and analytics platform
Deep understanding of the cloud offerings and engage in quick proof of concepts and proof of value in prototyping data and analytics solutions and derive viability
Ability to interact with the business stakeholders to understand requirements and translating into technology solutions

Expirience:

Experience in Cloud platform AWS or Azure eco-system. (Azure preferred)
Data Engineering/Development experience with SQL (Oracle, SQL Server, MySQL)
Strong development background creating pipelines and complex data transformations and manipulations using one of the languages Python, Java, R, or Scala with Databricks/Spark
Experience in NoSQL Databases and Big data technologies including Hadoop
Experience with API / RESTful data services
Worked on real-time data capture, processing and storing using technologies like Azure Event Hubs and Analytics
Experience working with different data storage options including AWS S3, Azure BLOB storage etc.
Understanding of different data formats including Parquet, Avro, CSV, ORC etc.
Prior experience with MPP databases and maintain large amount of data processing
Experience with Azure Data Factory and Azure Data Catalog is a big plus and mandatory
Experience with Microsoft/Azure ETL solutions and business Intelligence technologies is a big and mandatory
Past working experience on a fast paced and agile environment
Perform ongoing monitoring, automation and refinement of data engineering solutions
Experience in leading high visibility transformation projects that interacts with multiple business lines
Build and meet project timelines and manage delivery commitments with proper communication to management

Qualifications

Bachelor’s degree with 4+ years of relevant experience
Willingness to learn new technologies and thrive in an extremely fast paced environment
Team player and easy to work with.

Applicants must demonstrate their ability to master new enterprise level technologies. Successful applicants will exemplify Enthuzex ethical principles of uncompromising integrity, respect for others, and accountability for decisions

send cv's info@enthuzex.co.za",-1,Enthuzex,Leslie,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Scientist,-1,"The world is changing.

We all want something different.

At Luno, we see you as an individual.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the world, and to do so, we need the best team on board for our mission.

A bit about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 3 million customers across 40 countries.
We are Series B funded, backed by Balderton Capital and the Naspers Group.
Our platform has processed over 8 billion dollars since we've launched
We're proud to be one of the world's most international cryptocurrency teams from 26 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
The role in a nutshell:

Identifying opportunities in the business that could benefit most from cognitive applications, as well as building and enhancing organisational capabilities for deriving value from multiple data sources using data science.

What we'd like you to have:
Bachelor's degree or higher in the natural sciences or technical fields such as Mathematics, Statistics, Computer Science, Engineering or Economics
Enthusiasm to work in the cryptocurrencies space
Advanced SQL skills
Solid understanding of exploratory data analysis, predictive analytics, and optimisation using Python, R, Matlab, RapidMiner, KNIME or other data science-oriented platforms
Proficiency in the use of data science and machine learning domain-specific languages such as ""Caret"" and the ""Tidyverse"" suite of tools in R, or ""Pandas"" in Python
Strong interpersonal and communication skills
Communicating data insights using storytelling narratives
Ability to work independently, as well as within and across teams
Ability to successfully complete projects with large and/or incomplete data sets
More about what you'll be doing:
Optimising product performance by tracking and analysing customer behaviour on web and app, in collaboration with software engineers and product designers
Providing the business with reports and dashboards, on key performance metrics
Developing metrics to accurately assess the health of our Exchange platform
Comparative data-driven analysis of our Exchange against alternative platforms
Formulating business requirements into analytical objectives
Designing and running experiments to test hypotheses
Hacking through complex business problems using advanced data analysis to provide insights and recommendations
Building, maintaining, and optimising decisioning systems using advanced statistical and predictive modelling techniques
What will set you apart:
An advanced degree in Mathematics, Statistics, Computer Science or related field
At least 3 years' experience working in a similar role
A basic understanding of trading in financial markets
Experience working with a data analytics and visualisation platform such as Tableau, Cognos, QlikView, or Looker
Familiarity with using Google Analytics to understand customer behaviour
Solid knowledge of statistical and machine learning techniques
Familiarity with modern distributed data storage and processing systems such as Amazon Redshift, Big Query, Snowflake, Databricks and Apache Spark
You can gather and synthesise facts, theories, trends, patterns, inferences, and key issues in complex and variable situations
Ability to diagnose problems using formal problem-solving tools and techniques from multiple angles to generate multiple possible solutions
A sense of anticipating long-term problem areas and associated risk levels with objective rationale
Remote Life at Luno

If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
You'll be able to continuously upskill yourself with access to free online learning via MyAcademy, an international teaching marketplace with over 100000 courses from Harvard and other leading providers + share knowledge with your peers.
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity and paternity leave, and you can even take paw-ternity leave for your furry friend.
Annual Inspiration Day! Make time for that pottery course or spa day you've always wanted to do.
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"EY is a global leader in
assurance, tax, transaction and advisory services. Technology is at the heart
of what we do and deliver at EY. Technology solutions are integrated in the
client services we deliver and are key to our innovation as an organization.

Fueled by
strategic investment in technology and innovation, Client Technology seeks to
drive growth opportunities and solve complex business problems for our clients
through building a robust platform for business and powerful product engine
that are vital to innovation at scale. As part of Client Technology, you’ll
work with technologists and business experts, blending EY’s deep industry
knowledge and innovative ideas with our platforms, capabilities, and technical
expertise. As a catalyst for change and growth, you’ll be at the forefront of
integrating emerging technologies from AI to Data Analytics into every corner
of what we do at EY. That means more growth for you, exciting learning
opportunities, career choices, and the chance to make a real impact.

The selected
candidate
Develops
large and complex data architecture, composed of models, policies, rules or
standards that govern which data is collected and how it is stored, arranged,
integrated and put to use in data systems, including the design, build and
management of data infrastructure to address business requirements
Creates
sound use case driven roadmaps, depicting data architecture as-is and to-be
capabilities with the business by engaging with multidisciplinary teams, and by
identifying, managing and mitigating risk
Develops
relationships across the business to understand data requirements, applies deep
technical knowledge of data management to solve business problems in areas
where solutions may not currently exist, necessitating new solutions/ways of
working/technologies and proactively articulating these to the business
Review,
identify the latest emerging technologies, augmenting by services from the
leading cloud providers to solution and recommend the best next generation data
platform value driven approach for our clients
Your Key Responsibilities Include
Create
and maintain conceptual, logical and physical database models
Document
functional requirements and system specifications into the data architecture
and detailed design specifications for current and proposed designs
Document
and adhere to development standards and best practices in database designs
Maintain
highly effective and consistent communication within the team, peers, and the
leadership team
Reverse
engineer SQL code and modify it to solve problems/issues
Contribute
to the definition and implementation of data governance practices
Design
both data structures and data integration practices
Work
closely with the infrastructure teams to create a physical environment to
support data services
Evaluate
new and existing (internal and external) technologies and services in support
of data services and data analytics objectives
Skills And Attributes For Success
Understanding
of business process reengineering and business modeling concepts, business
systems development and analysis
Hands-on
experience in designing and implementing hybrid cloud and on-prem solutions
Experience
working with the latest versions of SQL Server
Experience
applying SAFe/Scrum/Kanban methodologies
Ability
to exercise judgment in solving technical, operational, and organizational
challenges
Expert
programming, performance tuning and troubleshooting skills, using the latest
popular programming languages for example python
Demonstrate
proactive approach to identifying issues and presenting solutions and options,
and where appropriate, leading to resolution
Minimum Qualifications
5+ years
demonstratable work experience as a Data Architect using data modeling tools
2-3 years
SQL coding experience on large projects
Must
possess expert SQL programming, performance tuning and troubleshooting skills
Create
database objects and SQL scripts
Understand
and developed data pipelines
Know how
to deformalize data for data science models
Experience
in python, spark and notebooks
Experience
designing data warehousing solutions
Experience
designing next generation data platforms utilising cloud services
In-depth
understanding of database structure principles
Seamlessly
able to translate business requirements to technology requirements
What We Look For
Strong
analytical skills and problem-solving ability
A
self-starter, independent-thinker, curious and creative person with ambition
and passion
Excellent
inter-personal, communication, collaboration, and presentation skills
Customer
focused
Excellent
time management skills
Positive
and constructive minded
Takes
responsibility for continuous self-learning
Takes the
lead and makes decisions in critical times and tough circumstances
Attention
to detail
High
levels of integrity and honesty
Curious
about new emerging technology
About EY
As a global leader in assurance, tax, transaction and consulting
services, we’re using the finance products, expertise and systems we’ve
developed to build a better working world. That starts with a culture that
believes in giving you the training, opportunities and creative freedom to make
things better. Whenever you join, however long you stay, the exceptional EY
experience lasts a lifetime.",3.8,"EY
3.8",Johannesburg,-1,10000+ Employees,1989,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Architect - Principal,-1,"We are looking for Principle Data Architect to join our Engineering team in Cape Town.

The world is changing.
We all want something different.
At Luno, we see you as individuals.

Together, we are upgrading the world of work to unleash the potential within and empower you to become the best possible version of yourself.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the financial landscape, and to do so, well we need the best team on board for our mission. In short, to achieve our goals, we need rockstars. As simple as that.

A little about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 5 million customers across 40 countries.
We're part of the Digital Currency Group, a group of companies driving progress in the cryptocurrency and blockchain space that includes Grayscale, Genesis, Coindesk and Foundry Services
Our platform has processed over $8 billion to date
We're proud to be one of the world's most international cryptocurrency teams from 43 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
How we work


Our engineering team (currently ~100 engineers) is split into organisations which we call Fleets. Each Fleet focuses on a core customer journey (onboarding, security, payments, support, new business, growth and marketing etc.). Each of these fleets contains multiple smaller teams called Pods, each of which focuses on a specific aspect of the product.

Pods will include a product owner, product designer, back-end engineers, Android, iOS and Web developers, who each bring a unique perspective to the problem you are all contributing towards.

We're agile, use scrum, continuous integration and continuous delivery, deploying to production every single day.

We're building teams to help us succeed in our mission to upgrade the world to a better financial system. You'll be joining a group of highly motivated software engineers who you'll work collaboratively with across our pods.

As a fast-growing company with offices around the world, you'll immediately see how your contributions directly impact both our internal users and client experience. Many of the problems we are solving result in trail blazing solutions which can't be found on Stack Overflow; so we're looking for engineers who flourish working in a complex domain.

In your first six months, you will:


...start at Luno by learning our processes, meeting the wider team and starting our engineering on-boarding program. After getting comfortable with the basics, you'll start learning our idiomatic patterns in a safe, easy-to-follow way - by building your own toy micro services. You'll get to practice how we do design docs, code reviews, deployments, events, logging and monitoring.

You'll meet the Pod(s) you'll be working with and quickly align on the teams' current OKRs and product roadmap. We succeed as a team, so we will provide you with regular feedback from your manager and peers and will encourage you to do the same.

What you'll do:
Work closely with our data science and platform teams on projects introducing new streams of data into our data lake
You will get to bring new ideas on how to further develop and innovate our data solutions and how to expose that data to the business
Accountable and Responsible for the design and architecture of Data systems that are robust and scalable.
Work in an Agile/Scrum framework or Agile mindset
Data backup/recovery and storage
Pick-up and learn new concepts, in both engineering and product, and be able to apply that knowledge quickly.
The ideal candidate for this role will have:
7+ years' experience in maintaining scalable data solutions and/or you are passionate about it
Ability to understand, communicate and advocate between build vs buy
Proven track record of setting up, restructuring and maintenance of databases
You know your way around ETL and you have experience with SQL
Experience in the AWS Data stack (RedShift,DynamoDB, Amazon RDS)
Familiarity with integrating data stores with BI platforms such as Looker, Tableau, or Power BI
You have experience with the concepts of CI/CD
Coding skills in e.g. Go, Python
Bachelor's degree in a related field preferred
AWS Certified DataOps Administrator
Be friendly, transparent, articulate and driven to succeed
Basic knowledge of and passion for digital currencies like Bitcoin
A work permit for South Africa if you are not a South African citizen
Don't be put off if you don't tick all of the boxes – they're a guide based on what we'd love to see but we appreciate that excellent software engineers have diverse backgrounds.

Remote Life at Luno


If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity / paternity and even (yes, you are reading it correctly) paw-ternity for your furry friend..
Annual Inspiration Day.. like that pottery course you've always been meaning to do!
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. You'll need to hold the legal right to work in South Africa already as we cannot provide visa sponsorship.

Be part of the change!",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer - EC2 Capacity Data Analytics,-1,"EC2 Capacity Data Analytics (CDA) team is looking for a Data Engineer to join our team.

Our team is part of the EC2 Capacity Engineering organization, which is responsible for providing the elasticity EC2 customers need to scale up/down compute resources in a cost-efficient manner. We predict customer usage across thousands of configuration combinations to deliver exactly what our customers require in just the right amount of time with just the right amount of capacity.

As a Data Engineer, you will build the ETL and analytics solutions for our internal customers to answer questions with data and drive critical improvements for the business. You will use best practices in software engineering, data management, data storage, data compute, and distributed systems. On any given day, we use Python, Scala, Java, SQL, Lambda, CloudFormation, Redshift and Glue as well as other public AWS services and a host of Amazon internal tools. We dont expect you to be an expert in, or necessarily even be familiar with all of the technologies listed above, but we do expect you to be excited to learn about them.

This position involves on-call responsibilities, typically for one week every two months. Our team is dedicated to supporting new team members. We care about your career growth, we try to assign projects and tasks based on what will help each team member develop into a more well-rounded engineer and enable them to take on more complex tasks in the future.

Our team values work-life balance and we are flexible when people occasionally need to work from home.

Job Duties
Develop and maintain automated ETL pipelines for big data using languages such as Scala, Spark, SQL and AWS services such as S3, Glue, Lambda, SNS, SQS, KMS. Example: ETL jobs that process a continuous flow of JSON source files and output the data in a business-friendly Parquet format that can be efficiently queried via Redshift Spectrum using SQL to answer business question.

Develop and maintain automated ETL monitoring and alarming solutions using Java/Python/Scala, Spark, SQL, and AWS services such as CloudWatch and Lambda.

Implement and support reporting and analytics infrastructure for internal business customers using AWS, services such Athena, Redshift, Spectrum, EMR, and QuickSight.

Develop and maintain data security and permissions solutions for enterprise scale data warehouse and data lake implementations including data encryption and database user access controls and logging.

Develop and maintain data warehouse and data lake metadata, data catalog, and user documentation for internal business customers.

Develop, test, and deploy code using internal software development toolsets. This includes the code for deploying infrastructure and solutions for secure data storage, ETL pipelines, data catalog, and data query.


Basic Qualifications

· Bachelors degree in Computer Science or related technical field, or equivalent work experience.
· 4+ years of overall work experience including Software Engineering, Data Engineering, Database Engineering, Business Intelligence.
· Experience with AWS technologies stack including Lambda, Glue, Redshift, RDS, S3, EMR or similar big data solutions stack

Preferred Qualifications

· Demonstrate efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data.
· Demonstrable proficiency in distributed systems and data architecture; design and implementation of batch and stream data processing pipelines; knows how to optimize the distribution, partitioning, and MPP of high-level data structures.

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer,-1,"Our client based in Johannesburg is urgently looking for a Data Engineer to be on a 3 months contract
Build data pipelines, experience in new tech like nifi, kafka, python

Joburg based, open to EE, 3 month contract with the option to extend, must be available at short notice",-1,EQplus,Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Overview
Job ID: 51456
Job Sector: Information Technology and Services
Country: South Africa
Region/State/Province/District: Gauteng
Location: Johannesburg

Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose

This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes

Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems

Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions

Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.
Research and best practices

Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development

Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.

Preferred Qualification and Experience

Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry

Knowledge/Technical Skills/Expertise

Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision

PLEASE NOTE: All our recruitment and selection processes comply with applicable local laws and regulations. We will never ask for money or any form of payment as part of our recruitment process. If you experience this, please contact our Fraudline on +27 800222050 or forward to TransactionFraudOpsSA@standardbank.co.za",4.1,"Standard Bank
4.1",Johannesburg,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"About us

At PBT Group we pride ourselves on being a Data Specialist organisation. With 20 years of experience in 27 countries over 3 continents, our team of 550 consultants have implemented more than 700 projects.",4.3,"PBT Group
4.3",Johannesburg,-1,Unknown,-1,Company - Private,Accounting,Accounting & Legal,Less than $1 million (USD),-1
Data Engineer,-1,"Kick-start your career in the online gaming world and experience the very latest in technology and innovation.

The Department:

Our mission is to provide our customers with the best online betting experience and share the thrill of gaming with them. Data is at the very heart of our business and is vital in everything we do.

Our cross-functional Data team has a big and exciting challenge ahead. We are in the process of re-platforming our traditional, on-premises RDBMS environment to a new microservice architecture in the cloud. We’re making use of the diverse set of data technologies in Microsoft Azure to offer new services, reporting structures and real-time data pipeline while serving the day-to-day requirements of a rapidly growing, data-hungry organisation.

Purpose of the Role:

This is an excellent opportunity for an individual who is looking to gain new skills. We are committed to creating a culture of learning and regularly run proof of concepts, provide internal demos, manage workshops and attend external conferences. Our data team has a wide range of skills including development for highly transactional RDBMS systems, data warehousing, data science and cloud technologies and we are always working to raise everyone’s game.

Duties include, but not limited to:

Work as part of an agile Data Engineering Team
Development of greenfield projects in Azure
Develop and maintain on-premises RDBMS/DW systems
Create robust ETL services and real-time data pipelines
Build and maintain Continuous Integration and DevOps pipelines
Test-driven development and pair programming with colleagues

Essential Criteria:

C#, .Net, Visual Studio
Git, Azure DevOps
NoSQL development (CosmosDB)
Demonstrable understanding of MS SQL Server in a highly transactional environment
Demonstrable understanding of development in Microsoft Azure
Able to understand query plans and identify performance bottlenecks
Test/Business-Driven Development
Building Continuous Integration/Deployment pipelines
Communicate effectively with both technical and non-technical stakeholders

Desirable Criteria:

Implementing Data Storage and Processing solutions in Azure (ARM Templates, Storage Accounts, Data Lake Storage, SQL DB, Cosmos DB, EventHubs, Function Apps, Log Analytics, Data Factory, Databricks, Polybase)
Implementing Security, Disaster Recovery, High Availability, Auditing, Monitoring and Alerting solutions in Azure
Automating tasks in Azure using Powershell / CLI
Predicting costs and optimizing spending in Azure
Message Queues (RabbitMQ, Kafka)
Python

Person Specifications:

Resilience
Teamwork
Technical Knowledge
Communication skills
Stress Tolerance
Please note we will apply relevance to our Talent Management and Talent Development Programme as part of our recruitment process.
Shortlisted candidates may need to complete an assessment.
This position requires trust and honesty it has access to customers financial details - therefore a credit and criminal record check will be conducted. The qualifications identified herein are an inherent job requirement; therefore, a qualification verification check will be done. By applying for this role, and supplying the necessary details, you hereby grant us permission to apply for these checks. This will be done in a confidential manner, and solely for the purposes of verification.

To view all current vacancies, please visit our website, www.digioutsource.com

Should you not hear from us within 2 weeks, please deem your application as unsuccessful.

The perfect place to work, play and grow!",3.9,"Digital Outsource Services
3.9",Cape Town,-1,1001 to 5000 Employees,1997,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
Data Engineer,-1,"At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes

Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.

Key Responsibilities

Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.

Key Traits

Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern

Position Requirements

2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.

Where will you work? This role will be based out of Durbanville, South Africa.",3.1,"Aculocity, LLC
3.1",Durbanville,-1,1 to 50 Employees,2006,Company - Private,IT Services,Information Technology,$1 to $5 million (USD),-1
Data Engineer,-1,"ENVIRONMENT:

A rapidly growing E-Commerce Platform seeks a highly talented Data Engineer to make an invaluable contribution to data democratisation and literacy vision by making accessible and easy-to-use data products and tools. You will require a Comp-Sci Degree or 3 years’ relevant industry experience, MySQL, PostgreSQL, Java, Python, in-depth understanding of OLAP, Data Marts, Star Scheme, Snowflake, be familiar with Jenkins, Travis, Circle CI, Docker, Kubernetes, experience with Kafka, Pub/Sub, Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks & significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing & Data Lake design and implementation and Lambda/Kappa architectures.

DUTIES:

Design, develop, test and maintain data architecture.

Prepare data for descriptive, predictive and prescriptive modelling.

Automate repetitive tasks and manual processes related with the data usage.

Optimize data delivery.

Design, develop and test large stream data pipelines to ingest, aggregate, clean, and distribute data models ready for analysis.

Ensure the highest standard in data integrity.

Leverage best practices in continuous integration and delivery.

Collaborate with other engineers, ML experts, analysts, and stakeholders to produce the most efficient and valuable solutions.

Implement features, technology, and processes that move us towards industry best practices, improving on scalability, efficiency, reliability, and security.

Operations and ownership of systems in production, responding to incidents.

REQUIREMENTS:

Qualifications –

Comp-Sci Degree or 3 years relevant industry experience.

Experience/Skills –

Open source relational database systems e.g. MySQL, PostgreSQL, etc.

Significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing, and Data Lake design and implementation and Lambda/Kappa architectures.

A thorough understanding of database and data warehousing principles e.g. OLAP, Data Marts, Star Schema, Snowflake, etc.

Java and Python.

Familiar with CI/CD tools such as Jenkins, Travis, Circle CI, etc.

Experience with Kafka, Pub/Sub, or other event-based systems.

Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks, etc.

Working in cloud environments and with containerisation frameworks, tools and platforms e.g. Docker, Kubernetes, GKE, etc.

A deep understanding of data pipelining, streaming, and Big Data technologies, methods, patterns, and techniques.

Troubleshooting complex database operations and performance issues.

Automating tasks using Shell Scripting or writing small applications.

ATTRIBUTES:

Works well with people and is passionate about helping people be their best.

A team player, an active listener, mentor, and able to communicate well.

Shows solid reasoning and decision making, with the ability to work under pressure.

Is passionate about technology, systems and data.

Is curious, always learning, and keeping up to date with the industry.

While we would really like to respond to every application, should you not be contacted for this position within 10 working days please consider your application unsuccessful.

COMMENTS:

When applying for jobs, ensure that you have the minimum job requirements. Only SA Citizens will be considered for this role. If you are not in the mentioned location of any of the jobs, please note your relocation plans in all applications for jobs and correspondence.",-1,Datafin IT Recruitment,Cape Town,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Cartrack is looking for passionate data science and engineering candidates that can join a growing team that is responsible for the intelligence and efficiency solution provision to over a million subscribers, many of whom are large fleets. We are in the midst of creating revolutionary platforms that will change the way that people interact with their vehicles.

You will have the opportunity to work with the very brightest global subject matter experts that are transforming the automotive industry across Fleet Management, Asset Management and Insurance Telematics solutions.

Get to know the role:

The role of a data engineer is a supporting one, but it is also an extremely vital one. As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements. We want to see candidates with mechanical tendencies and a desire to know how things work and to improve them.

The day-to-day activities:

Design, construct, install, test and maintain data management systems.
Build high-performance algorithms, predictive models, and prototypes.
Ensure that all systems meet the business/company requirements as well as industry practices.
Integrate up-and-coming data management and software engineering technologies into existing data structures.
Develop set processes for data mining, data modeling, and data production.
Create custom software components and analytics applications.
Research new uses for existing data.
Employ an array of technological languages and tools to connect systems together.
Install/update disaster recovery procedures.
Recommend different ways to constantly improve data reliability and quality.
Work on and maintain Data pipelines.

Requirements Essential:

At least 5 years’ proven experience as a Data Engineer, DevOps Engineer, Software Developer, or similar.
Proficient in Linux/Unix and shell scripting as well as in functional programming languages.
Expertise in setting up and explored with technologies such as Hadoop and Spark.
Bachelor’s degree in computer science, software/computer engineering, applied mathematics, or physics.",3.3,"Cartrack
3.3",Johannesburg,-1,501 to 1000 Employees,2004,Company - Private,Security Services,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Data Engineer,-1,"Data Engineers build and support data pipelines and datamarts built off those pipelines. Both must be scalable, repeatable and secure. The Data Engineer helps to facilitate gathering data from a variety of different sources, in the correct format, assuring that it conforms to data quality standards and assuring that downstream users can get to that data timeously. This role functions as a core member of an agile team. These professionals are responsible for the infrastructure that provides insights from raw data, handling and integrating diverse sources of data seamlessly. They enable solutions, by handling large volumes of data in batch and real-time by leveraging emerging technologies from both the big data and cloud spaces. Additional responsibilities include developing proof of concepts and implements complex big data solutions with a focus on collecting, parsing, managing, analysing and visualising large datasets. They know how to apply technologies to solve the problems of working with large volumes of data in diverse formats to deliver innovative solutions. Data Engineering is a technical job that requires substantial expertise in a broad range of software development and programming fields. These professionals have a knowledge of data analysis, end user requirements and business requirements analysis to develop a clear understanding of the business need and to incorporate these needs into a technical solution. They have a solid understanding of physical database design and the systems development lifecycle. This role must work well in a team environment.

Job Objectives

Work Complexity: * Architects Data analytics framework. * Translates complex functional and technical requirements into detailed architecture, design, and high performing software. * Leads Data and batch/real-time analytical solutions leveraging transformational technologies. * Works on multiple projects as a technical lead driving user story analysis and elaboration, design and development of software applications, testing, and builds automation tools.

Main Job Objectives: 1. Development and Operations 2. Database Development and Operations 3. Policies, Standards and Procedures 4. Communications 5. Business Continuity & Disaster Recovery 6. Research and Evaluation 7. Coaching/ Mentoring

Qualifications

Essential: 4 years Bachelors degree in computer science, computer engineering, or equivalent work experience AWS Certification at least to associate level

Experience

Essential:

5+ years Data engineering or software engineering

3-5 years demonstrated experience leading teams of engineers

2+ years Big Data experience

5+ years experience with Extract Transform and Load (ETL) processes

2+ years Could AWS experience

At least 2 years demonstrated experience with agile or other rapid application development methods - Agile exposure, Kanban or Scrum

5 years demonstrated experience with object oriented design, coding and testing patterns as well as experience in engineering (commercial or open source) software platforms and large scale data infrastructures.

Desirable:

5+ years Retail Operations experience

Knowledge and Skills

Essential: *Creating data feeds from on-premise to AWS Cloud (2 years) *Support data feeds in production on break fix basis (2 years) *Creating data marts using Talend or similar ETL development tool (4 years) *Manipulating data using python and pyspark (2 years) *Processing data using the Hadoop paradigm particularly using EMR, AWSs distribution of Hadoop (2 years) *Devop for Big Data and Business Intelligence including automated testing and deployment (2 years) * Extensive knowledge in different programming or scripting languages * Expert knowledge of data modeling and understanding of different data structures and their benefits and limitations under particular use cases.

Further technical skills required: * Capability to architect highly scalable distributed systems, using different open source tools. * Big Data batch and streaming tools * Talend (1 year) * AWS: EMR, EC2, S3 (1 year) * Python (1 year) * PySpark or Spark (1 year) - Desirable * Business Intelligence Data modelling (3 years) * SQL (3 years)",-1,Datonomy Solutions,Brackenfell,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We are assisting one of our clients that is based in Pretoria to fill a role of a Data Engineer

This is a 12 month contract role

Objective of this Scope of Work

The Data Engineer will drive improvement of the data management maturity levels and provide the necessary technical support within the company to support reliable and effective decision-making, appropriate usage and protection thereof.

Scope of Services Definition

The scope will include but will not be limited to:

ï†· To develop, construct, test and maintain architectures.

ï†· To ensure architectures will support the requirements of business.

ï†· To discover opportunities for data acquisition and sharing.

ï†· To develop data set processes for data modelling, mining and production.

ï†· To employ a variety of languages and tools to marry systems together.

ï†· To recommend way to improve data reliability, efficiency and quality.

ï†· To prepare data for use in predictive and prescriptive modelling.

ï†· To conduct research to answer industry and business questions.

ï†· To leverage volumes of data from internal and external to answer business questions.

ï†· To develop and manage stakeholder relations effectively to promote data management across the organisation and support reliable decision making and appropriate data usage.

ï†· To participate and provide technical support in cross organisational activities relating to any of the above mentioned data management activities.

ï†· To provide regular progress reports as per stakeholder requirements and present data management updates in various forums as required.

Minimum qualification Required:

ï†· A minimum of a Bachelors degree in Computer Science or Information Management OR equivalent;

ï†· A minimum of five to eight years experience in a data management environment",-1,HR Genie,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Our client based in the Northern Suburbs, is currently looking for a Data Engineer to join their team.

Responsibilities
Our client is a dynamic IT company that delivers value-driven IT solutions to the group. Our work lives revolve around our DNA. We take pride in our work, treat our colleagues, partners and our country with respect. We exercise collaborative decision-making and believe in having a balance in life. We do this all while having fun and enjoying what we do.

The primary focus of this position is to use technical skills to put software, systems and data together in a way that extracts meaningful insights from raw data. You will need to be helpful and supportive to your team and fellow developers. You join an energetic, focused and dynamic team.

Interact with clients to understand requirements and business problems/needs

Identify, analyse, visualise and understand supporting data to propose solid solutions

Create technical documentation for reference and reporting

Support existing solutions within GCP and Oracle

Doing standby on a rotating basis

Key Competencies and Qualifications

Matric

Tertiary qualification in IT

Preferred cloud experience in AWS/AZURE/GCP

At least 3 years of data warehouse ETL experience

Dimensional Modelling

Data analyses

Experience with data visualization and visualization tool(s)

Knowledge of the retail industry will be beneficial

Understanding and experience with version control SVN/GIT

Preferred – Korn shell scripting, Python/Java, SQL

Google Cloud Platform experience would be looked upon favourably

Having a broad understanding of different SDLC’s

Preferred agile experience

Strengths

The natural tendency to take ownership and responsibility

Strong problem solving, critical thinking, effective planning and organisational skills

Detail-oriented with excellent communication skills

You have a can-do attitude and positive outlook on life

Can cope under pressure

Curious and interested in analysing problems and possible solutions

Strong team player

Self-driven learner, passionate about new technology

Above all, be passionate about what you do

Should you wish to apply for the position, please apply directly via this job board, please ensure that you quote reference number 201620 subject heading or email body.

Please note that due to the high volume of CV's received; only shortlisted applicants will be contacted. Should you not receive communication from our offices within two weeks of submission please note that your application will not be considered for this position.

We will keep your CV on file and re-establish contact with you should opportunities in line with your expertise become available again.

Should you require any additional information give us a call on 021 012 5566.",-1,Surgo HR & Training,Cape Town,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We believe that our employees fuel our organization, essential to enable us to help our customers overcome their business challenges and achieve sustainable growth. As a result, we are committed to growing each individual and providing them with the challenges, feedback and support needed to achieve success in their career

If this sounds appealing, and like us, you get excited about data: its collection, storage, transformation or display, see if you’ve got what it takes to join our sought after DATA team.

Key Responsibilities And/or Outputs

You will represent IQbusiness at our customers, sometimes alone, and sometimes as part of an IQ team.

Providing a superior customer experience by building and maintaining relationships, working at customer offices, keeping data confidential
Design and develop – databases, SQL queries, stored procedures, reports, dashboards or integration solutions
Produce solutions for both real-time and batch environments
Test your work to ensure compliance
Solve problems, and do root cause analysis
Prioritize your workload
Assist in other areas relating to your true data function, such as data modeling, data and business analysts
Interact with a variety of individuals: senior, junior, technical and from business
Provide guidance to fellow colleagues, or even manage a team
Uphold the IQ values, which are to care, learn & share; innovate; deliver as well as to build, enhance and maintain relationships

Education

Matric pass
A tertiary qualification, preferably in an ICT relevant field
Appropriate Microsoft certifications are beneficial but not required

Requirements

3 - 6 years experience in the Data Engineering environments and technologies
Great communication skills
A passion for SQL, databases or reports
Can you write stored procedures, design complex queries and create views and triggers?
Are you able to work out the relationships in a data warehouse or the aggregation of a cube?
Do you extract and display useful information when you see patterns and trends in data?
Strong knowledge of the financial services industry, ideally in a consulting role
The use of data related software: databases, ETL and BI tools; report writing and analytical tools
We use a lot of Microsoft products. You may often be expected to use MS SQL Server, SSIS, SSRS, SSAS and Power BI to develop solutions
What other relevant software have you’ve used?
Ability to work in different project methodologies: Waterfall and/or Agile
Knowledge of full SDLC
Exposure to logical and physical data modeling

Equal Employment Opportunity

IQbusiness is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, citizenship, marital, domestic or civil partnership status, sexual orientation, or gender identity",3.7,"IQbusiness South Africa
3.7",Johannesburg,-1,1 to 50 Employees,-1,Company - Private,Consulting,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"We value a data engineer as someone who works behind the scenes to obtain, process and supply data via various methodologies and technologies, to various consumers, in ways and forms that makes sense and add value. This definition is very broad, as the field of data engineering is just as broad.

You may be the type of data engineer that develops API endpoints for the consumption of data by end users or even another data pipeline, or you may be the type of data engineer that develops highly distributed, high availability data processing pipelines in an effort to satisfy the need of the ever questioning data analysts and/or data scientists.

You have awesome knowledge about the following concepts
Data modelling
Relational data modelling in traditional relational database management systems. (Microsoft SQL Server, MySQL, PostgreSQL, etc)
Coercing unstructured and semi-structured data into a structured form.
Data pipelining knowledge - data extraction and transformation.
Data transformation knowledge for reporting and analytics purposes.
Knowledge of the MapReduce and related data processing paradigms would be a boon.
You have the following technical competencies
Writing SQL queries, that can relate, transform and aggregate data from many differing sources where natural keys may or may not exist.
Experience with writing data pipelines that move and transform data, for various uses.
Working knowledge of a general purpose programming language like Python would be a boost.
Working knowledge of columnar databases such as Google BigQuery, and SAP HANA would be a boost.
Working knowledge of highly distributed technologies such as Apache Hadoop or Apache Spark would be a boost.
Working knowledge of NoSQL technologies, such as Apache Solr would be a boost.
You have the following personal competencies
The ability to solve problems.
The ability to rotate around a problem, to see if solutions can be gained in different ways.
The ability to work in an ever changing, unstructured environment.
The ability to work as part of a team, with vastly differing skill sets and opinions.
The ability to contribute ideas to the quorum.
The ability to mentor and provide guidance for other team members.
A systems approach to thinking, as opposed to a siloed approach. The candidate needs to understand how their work affects the greater system.
The ability to work without supervision, and take accountability for the work they deliver.
The ability to liaise with a client, sifting through the fluff and extracting the actual requirements.
If this is you - apply now and we'll get in touch",-1,DotModus,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Data Engineer

Our client in the contact centre space is currently seeking a DATA ENGINEER that will work on the collecting, storing, processing, and analyzing of large datasets. The primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them. You will also be responsible for integrating them with the architecture used across the company.

Key Performance Areas:

Data reporting.
Implementing ETL processes.
Defining data retention policies.
Management of Customer Lead data.
Provision of data for advanced analytics.
Maintenance of internal client scorecards.
Assist team in resolving data-related support queries.
Optimize existing data processes through automation.
Assist with all data-related reporting and documentation.
Maintenance and optimisation of the Analytics database.
Provide technical support to and supervision of junior data administrators.
Continuous upskilling on new technologies, frameworks and market trends.
Monitoring performance and advising any necessary infrastructure changes.
Identifying, selecting and integrating any Big Data tools and frameworks required to provide real-time analytics.

Educational Requirements

IT related Degree or Diploma is a pre-requisite

Required Skills/Experience

ETL tools: Advanced SSIS
BI/Reporting : Qlikview/Power BI/ SSRS or SSAS
Programming languages: JAVA, C# , Python, SAS or R
Experience with NoSQL databases and/or campaign management tools will be advantageous.
Minimum 3 years’ applicable work experience in SQL, relational databases and data manipulation.
Experience in big data platforms (eg. Hadoop) or processing frameworks (eg. MapReduce/Spark) and querying tools (eg. Pig, Hive and Impala) will be highly beneficial.

Preferred Skills

Organizational skills
Experience in Attentional to detail.
Accountability is critical for this role.
Ability to work under pressure and meet deadlines.
Solid understanding of database design principles.
Should you not receive a response in 2 weeks please consider your application unsuccessful",-1,Rubik's Cubed Consulting,Durban,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"This well known company is looking for a Data Engineer. will be based in Rivonia
The ideal candidate will have strong experience in the following:
Data cleaning
SQL Export
Big data Sets

BSc Degree in Maths and Stats will be required
a min of 3 years experience.
Stable track record is required.

Send your Cv to marinda@prrrecruitment.co.za",-1,PRR Recruitment Services,Johannesburg,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Description

Position at Aculocity, LLC

At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes
Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.
Key Responsibilities
Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.
Key Traits
Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern
Position Requirements
2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.
Where will you work? This role will be based out of Durbanville, South Africa.",-1,GVW,Durbanville,-1,Unknown,-1,Unknown,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Information Technology, Gauteng JHB - Northern Suburbs

Market related - Market related Annually

An IT Consultancy Business based in Johannesburg is currently looking for a Business Intelligence Consultant / Data Engineering Consultant.

Requirements:

Extensive experience in data engineering
Experience in Business Intelligence, data and Power BI
Extensive experience in data governance and the Popi act
Ability to assess and make recommendations on data within the Popi act
Good understanding of T-SQL and query optimization, developing ETL strategies.
Good understanding with SQL Server 2008/2012, SSIS, SSRS and SSAS
Use SSIS to create ETL packages to validate, extract, transform, and load data into the data warehouse and data marts.
Deploy and configured the reports in the Report Server (SSRS).
Excellent experience in Tabular Modelling , PowerView, Qlikvie,w, and Power BI
Maintain ETL
Qlikview model
Create Drill-through, Drill-down, and Cross Tab Reports and Sub-Report using Report Definition Language (RDL).
Generate periodic reports based on the statistical analysis of the data using SQL Server Reporting Services (SSRS)
Advise and provide written technical documentation and recommendations

The information displayed above is not limited to advertisements. Please contact Thato for further information.

Please consider your application as unsuccessful if you have not received a response within 14 days of submitting your application. However, please keep a lookout on our website, www.bedifferent.co.za, for available positions that you may be suited for

Ad Visible Until: 29 October 2020
Ref: JHB005346/NL

Vacancy Type: Permanent",2.9,"Be Different Recruitment
2.9",Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Cloud Support Engineer (Big Data),-1,"ABOUT US

Amazon Web Services is the market leader and technology forerunner in the Cloud business. As a member of the AWS Support team you will be at the forefront of this transformational technology, assisting a global list of companies and developers that are taking advantage of a growing set of services and features to run their mission-critical applications. As a Cloud Support Engineer, you will act as the Cloud Ambassador across all the cloud products, arming our customers with required tools & tactics to get the most out of their Product and Support investment.

Would you like to use the latest cloud computing technologies? Do you have an interest in helping customers understand application architectures and integration approaches? Are you familiar with best practices for applications, servers and networks? Do you want to be part of a customer facing technology team helping to ensure the success of Amazon Web Services (AWS) as a leading technology organization?

If you fit the description, you might be the person we are looking for! We are a group of smart people, passionate about cloud computing, and believe that world class support is critical to customer success.

WHAT CAN YOU EXPECT FROM A LIFE AT AWS?

Every day will bring new and exciting challenges on the job while you:

· Learn and use groundbreaking technologies.
· Apply advanced troubleshooting techniques to provide unique solutions to our customers' individual needs.
· Interact with leading engineers around the world.
· Partner with Amazon Web Services teams to help reproduce and resolve customer issues.
· Leverage your extensive customer support experience to provide feedback to internal AWS teams on how to improve our services.
· Drive customer communication during critical events.
· Drive projects that improve support-related processes and our customers technical support experience.
· Write tutorials, how-to videos, and other technical articles for the developer community.
· Work on critical, highly complex customer problems that may span multiple AWS services.

WHY AWS SUPPORT?

· First and foremost this is a customer support role in The Cloud.
· On a typical day, a Support Engineer will be primarily responsible for solving customers cases through a variety of customer contact channels which include telephone, email, and web/live chat. You will apply advanced troubleshooting techniques to provide tailored solutions for our customers and drive customer interactions by thoughtfully working with customers to dive deep into the root cause of an issue.
· Apart from working on a broad spectrum of technical issues, an AWS Support Engineer may also coach/mentor new hires, develop & present training, partner with development teams on complex issues or contact deflection initiatives, participate in new hiring, write tools/script to help the team, or work with leadership on process improvement and strategic initiatives.
· Career development: We promote advancement opportunities across the organization to help you meet your career goals.
· Training: We have training programs to help you develop the skills required to be successful in your role.
· We hire smart people who are keen to build a career with AWS, so we are more interested in the areas that you do know instead of those you havent been exposed to yet.
· Support engineers interested in travel have presented training or participated in focused summits across our sites or at specific AWS events.
· As we operate on a follow-the-sun model, with Premium Support sites located globally, there is no after hours on-call or mandated overtime in this role.
· https://www.youtube.com/watch?v=GC3bWcFFZTo&t=24s



Basic Qualifications

The Big Data role supports our services that leverage data and produce business insights, which may include using Machine Learning/Artificial Intelligence (ML/AI). Helping our customers use and integrate Big Data services in what is arguably our industrys most exciting space. The portfolio of services covers EMR (Hadoop), DynamoDB (NoSQL), MangoDB, and Apache Cassandra.

· Advanced experience in Apache Hadoop, Apache Spark, Apache Hive, and Presto
· Advanced experience in DynamoDB or NoSQL technologies like MongoDB or Cassandra
· Advanced experience with System Administration with Linux (RHEL/CentOS) including Microsoft Active Directory, and LDAP integration.
· Experience with troubleshooting Kerberos Authentication problems.
· Experience with Network troubleshooting.
· Basic understanding of Machine Learning and statistics
· Experience with Java and Python and shell scripting
· Bachelors degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position



Preferred Qualifications

· Expert experience in the Hadoop Ecosystem including Apache Spark and Presto
· Expert experience in NoSQL
· Expert experience with blockchain technologies like Etherium Expert experience in data Data Lake architecture and administration
· Experience managing full application stacks from the OS up through custom applications
· Prior work experience with AWS - any or all of EC2, VPC, S3, RDS, EMR, Glue, SageMaker
· Excellent knowledge of Hadoop architecture, administration and support
· Expert understanding of distributed computing principles and their application in the cloud
· Good understanding of distributed computing environments Lead technical discussions on big data systems architecture and design
· Strong analysis and troubleshooting skills and experience
· AWS Certified Solutions Architect
· AWS certified Big Data Specialty
· Masters degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity and Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Response Center Engineer,-1,"Job Title
Response Center Engineer
Job Description


Philips is a world leading health technology company with a vision to make life better for people worldwide through meaningful innovation. Making good on this promise depends on our passionate, inspirational, collaborative and diverse team. We have over 80,000+ brilliant people around the world but are always looking for more. Like-minded, motivated, focused minds to join us in creating a healthier, more connected society while transforming themselves personally and professionally.

As a CCC Coordinator - Response Center Engineer you will have the opportunity to process customer calls and be responsible for screening and diagnosing professionally Healthcare equipment to support customers and colleagues remotely with solving technical issues and ensuring maximum customer satisfaction

You are responsible for:
Diagnose healthcare equipment to the quality standards set by Philips Healthcare (PH) remotely by interviewing customers or colleagues by telephone or by remotely logging in to the system
Advise Customer Care Center Coordinators and District Operations Managers and / or Team Leads about the best follow-up w.r.t. technical state of the diagnosed healthcare equipment
Advise the Customer Care Center Coordinators or Field Services Engineers about required spare parts and resources
Responsible for planning engineers related to Modality responsibility.
Responsible for coordination between CCC, CUSTOMER, Spare parts AND Engineer.
Responsible to drive Remote and FTR KPI’s to targets respectively 40% and 85%.
Will require minimal field work to keep abreast of technical capabilities.
Take calls from customers and make sure they are processed in the CCC ERP on timely manner including all relevant data
Support Field Services Engineers in the field with technical knowledge
Escalate technical issues to the Technical Support Specialist
Escalate technical issues to Business Unit support after consultation of the Technical Support Specialist
Monitor critical functions of the equipment’s in the IB and environmental conditions including RSN and True reachability.
Lead the planning and implementation of FSN’s and FCO’s accelerating remote implementation where applicable.
Submit timely and accurate service data, job sheets, reports, expense claims, radiation film badges, field problem reports and other paperwork as assigned
Keep abreast of new technologies likely to affect PH range of products
Use company property with care to ensure optimal results with minimal operational costs
Be a professional representative for PH with respect to customer problems, ensuring personal acceptability by the customer in behavior in accordance with PH policy and targets
Conform to PH safety standards including health and safety regulations and in the event of hazards or accidents to take immediate control of the situation and involve the Operations Manager and / or the responsible person to handle properly confidential issues according Philips standards and to act according General Business Principals
Follow all quality standards within the frame of valid PH business policies
Follow the company quality regulations (ISO 9001; PQA; TQM) and internal directives and procedures
You are a part of the dynamic South Africa Customer Care Centre Team .You will be reporting to the Customer Care Center Manager.

Requires a pleasant, assertive individual you can work very well in a team setting, a dynamic environment that requires flexibility and creativeness to achieve goals.

To succeed in this role, you should have the following skills and experience:
Degree level education or equivalent
Experience in maintenance and troubleshooting of technical complex systems
Fluent in English, verbal and written in addition to local language
In return, we offer you the unique combination of a critical and challenging role and a creative and empowering office environment. You will be actively encouraged to make improvements, establish best in class service and have a direct impact on the success of Philips on a daily basis.

Employment Equity

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply. Only apply for this role if you are a South African Citizen by birth or Naturalization prior to the 27 April 1994.

Why should you join Philips?

Working at Philips is more than a job. It’s a calling to create a healthier society through meaningful work, focused on improving 3 billion lives a year by delivering innovative solutions across the health continuum. Our people experience a variety of unexpected moments when their lives and careers come together in meaningful ways. Learn more by watching this video.

To find out more about what it’s like working for Philips at a personal level, visit the Working at Philips page on our career website, where you can read stories from our employee blog. Once there, you can also learn about our recruitment process, or find answers to some of the frequently asked questions.

Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.9,"Philips
3.9",Johannesburg,-1,10000+ Employees,1891,Company - Public,Health Care Services & Hospitals,Health Care,$10 to $25 million (USD),-1
Software Development Engineer - EC2 Placement,-1,"Build the systems that optimize how EC2 matches requests for Instances with the underlying compute capacity. EC2 Placement is seeking talented engineers to build the online and offline optimization systems for compute workload scheduling, and the customer capabilities to better manage those workloads. Amazon EC2 provides on-demand scalable compute capacity, and powers some of the largest services in the world. You will collaborate with a top-tier community of engineers to build systems to improve how customers are able to access EC2 compute resources.

The successful candidate will have strong software engineering experience, with a passion for thinking about, building and testing distributed systems. You have an interest in how Machine Learning and other optimization techniques can be applied to large-scale problems. You have demonstrated experience working with a team to design, build and operate large-scale systems. With strong engineering fundamentals, an analytical and data-driven approach to your work, and strong communication skills, you have the ability to collaborate well to deliver results. We move fast and work together on small teams to solve big problems.

If this opportunity sounds interesting, we would love to talk to you more about our work and the vibrant culture at AWS in Cape Town.

Basic Qualifications

· Degree in Computer Science or related field, or equivalent working experience
· 3+ years of industry experience in a software development environment
· Strong Computer Science fundamentals, including data structures, object-oriented design, algorithm design, problem solving, and complexity analysis.
· Proficiency in at least one modern programming language, such as Java, C#, Python, Scala, Kotlin

Preferred Qualifications

One or more of the following help you stand out:
· Demonstrated results designing, building and operating high-performance distributed systems in large-scale Linux environments
· Role model in writing high-quality, maintainable and secure code, mentoring others, and helping teams sharpen their development processes
· Ability to work effectively across teams to deliver results, with strong verbal and written communication skills
· Experience working with machine learning systems

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer - PBB IT,-1,"Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose


This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes
Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems
Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions
Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.

Research and best practices
Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development
Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.
Preferred Qualification and Experience
Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Aws Data Platform Engineer,-1,"Aws Data Platform Engineer

Posting Country:

South Africa

Date Posted:

15-Oct-2020

Full Time / Part Time:

Full Time

Contract Type:

Permanent

Joining Vodacom is more than a job, what we do matters. We don’t just carry minutes, texts and data – we carry people’s lives. And that’s a huge responsibility. If you think for a minute about the people you rely on…the likelihood is they rely on us.

Customers are at the heart of everything we do and we want to make a difference to the lives of our customers, and the communities in which we live and work. We support our people to give something back to the causes that mean the most to them through helping them give time and money to the charities they love.

And what’s it like to work here? We have created an environment where you can look forward to coming to work and are empowered to be at your best. We offer flexibility in how you work that helps you do your job in a way that suits you, opportunities to help you grow and progress throughout your career and a choice of benefits to suit your lifestyle.

Role Purpose
The H Band AWS Data Platform Engineer position is based within the Technology Business Unit.

The AWS Data Platform Engineer will be responsible for all Database services such as RDS, DynamoDB, etc. Should be able to migrate any databases from anywhere to AWS using any third-party tools or AWS database migration tool. Should also have understanding or expertise in creating data warehouses and data lake solutions on AWS.
Your responsibilities will include:
Apply practical knowledge of relational database design and usage with customers
Perform workload analysis and undertake performance tuning, as well as performance benchmarking in customer environments.
To develop state of the art solutions which are technically sound.
To provide a high-quality service to the Enterprise Cloud Services clients i.t.o. consultancy, solutions and delivery.
Commitment to team success and positive team dynamics including mentoring of other team members.
Passion for growing and applying technical skills in service to customers.
Be a trusted infrastructure advisor by providing objective, practical and relevant ideas, insights and advice.
Work collaboratively with consulting partners and technology teams to ensure high quality of solution delivery.
Encourage best practice and knowledge sharing with partners and cross-functional groups
Manage the overall database design and delivery of solutions.
Ability to make recommendations as they pertain to improvements in support/development initiatives and facilitate implementation with partners and cross-functional groups within the Business.
Participate in high level database solution definition and design during the implementation phase with the goal of providing reliable, stable and operationally sound applications that meet the Business requirements.
Ability to understand and translate business requirements into technical specifications
The ideal candidate will have:
A minimum of 3 years of industry related experience of which 1 year must be within a complex hosting environment.
Certifications in Database design, system architecture or cloud technologies.
Demonstrate knowledge of database systems internals including storage layouts and distributed databases/MPP architectures
Advanced SQL coding, tuning and query optimization.
Experience designing and leading database performance benchmarks.
Good knowledge of the different AWS services
Knowledge of cloud networking architecture, cloud operations, security, automation and orchestration.
Knowledge of database internals as it relates to query and system performance and tuning.
Understanding of overall system architecture, scalability, reliability, and performance in a database environment.
Excellent teamwork, time-management and organizational skills.
Perform other duties as deemed necessary and assigned by the customer and management
Strong interpersonal skills and problem-solving abilities.
Excellent documentation, communication and interpersonal skills.
Excellent analytical and problem-solving abilities.
Closing date for applications: Monday, 13 April 2020

The base location for this role is Vodacom World, Midrand

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply.
Vodacom is committed to an organisational culture that recognises, appreciates and values diversity & inclusion.

Commitment from Vodacom

Vodacom is committed to attracting, developing and retaining the very best people by offering a flexible, motivating and inclusive workplace in which talent is truly recognized, developed and rewarded. We believe that diversity plays an important role in the success of our business and we are committed to creating an inclusive work environment which respects, values, celebrates and makes the most of people’s individual differences - we are not only multinational but multicultural too. At Vodacom you will have access to our excellent flexible benefits programme that you would expect from any global company.",3.9,"Vodafone
3.9",Midrand,-1,10000+ Employees,1982,Company - Public,"Cable, Internet & Telephone Providers",Telecommunications,$10+ billion (USD),-1
Data Engineer Azure Data Factory,-1,"Enthuzex is looking for a motivated Lead Data Engineer to contribute towards the success of our Data and Analytics Technology initiatives. This is a hands-on technical role and this person will be responsible for the development and build of scalable solutions as it relates to the architecture strategies, data standards, digital data management, data integration, tools, and technology. The right candidate will play a deep dive hands-on critical development role in the digital transformation and in shaping how we acquire, ingest, transform and deliver data through the digital consumer channels.

Responsibilities:

Architect, design, develop and engineering end-to-end data pipelines across multiple data sources and systems of record.
Ensure data quality, integrity, security and completeness throughout the data lifecycle
Develop, design data models, data structures and ETL jobs for data acquisition and manipulation purposes
Develop deep understanding of the data sources, implement data standards, maintain data quality and master data management
Developing data services and API
Work closely with the cloud service providers to ensure completeness and alignment with the service offerings
Manage and maintain cloud based data and analytics platform
Deep understanding of the cloud offerings and engage in quick proof of concepts and proof of value in prototyping data and analytics solutions and derive viability
Ability to interact with the business stakeholders to understand requirements and translating into technology solutions

Expirience:

Experience in Cloud platform AWS or Azure eco-system. (Azure preferred)
Data Engineering/Development experience with SQL (Oracle, SQL Server, MySQL)
Strong development background creating pipelines and complex data transformations and manipulations using one of the languages Python, Java, R, or Scala with Databricks/Spark
Experience in NoSQL Databases and Big data technologies including Hadoop
Experience with API / RESTful data services
Worked on real-time data capture, processing and storing using technologies like Azure Event Hubs and Analytics
Experience working with different data storage options including AWS S3, Azure BLOB storage etc.
Understanding of different data formats including Parquet, Avro, CSV, ORC etc.
Prior experience with MPP databases and maintain large amount of data processing
Experience with Azure Data Factory and Azure Data Catalog is a big plus and mandatory
Experience with Microsoft/Azure ETL solutions and business Intelligence technologies is a big and mandatory
Past working experience on a fast paced and agile environment
Perform ongoing monitoring, automation and refinement of data engineering solutions
Experience in leading high visibility transformation projects that interacts with multiple business lines
Build and meet project timelines and manage delivery commitments with proper communication to management

Qualifications

Bachelor’s degree with 4+ years of relevant experience
Willingness to learn new technologies and thrive in an extremely fast paced environment
Team player and easy to work with.

Applicants must demonstrate their ability to master new enterprise level technologies. Successful applicants will exemplify Enthuzex ethical principles of uncompromising integrity, respect for others, and accountability for decisions

send cv's info@enthuzex.co.za",-1,Enthuzex,Leslie,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Scientist,-1,"The world is changing.

We all want something different.

At Luno, we see you as an individual.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the world, and to do so, we need the best team on board for our mission.

A bit about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 3 million customers across 40 countries.
We are Series B funded, backed by Balderton Capital and the Naspers Group.
Our platform has processed over 8 billion dollars since we've launched
We're proud to be one of the world's most international cryptocurrency teams from 26 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
The role in a nutshell:

Identifying opportunities in the business that could benefit most from cognitive applications, as well as building and enhancing organisational capabilities for deriving value from multiple data sources using data science.

What we'd like you to have:
Bachelor's degree or higher in the natural sciences or technical fields such as Mathematics, Statistics, Computer Science, Engineering or Economics
Enthusiasm to work in the cryptocurrencies space
Advanced SQL skills
Solid understanding of exploratory data analysis, predictive analytics, and optimisation using Python, R, Matlab, RapidMiner, KNIME or other data science-oriented platforms
Proficiency in the use of data science and machine learning domain-specific languages such as ""Caret"" and the ""Tidyverse"" suite of tools in R, or ""Pandas"" in Python
Strong interpersonal and communication skills
Communicating data insights using storytelling narratives
Ability to work independently, as well as within and across teams
Ability to successfully complete projects with large and/or incomplete data sets
More about what you'll be doing:
Optimising product performance by tracking and analysing customer behaviour on web and app, in collaboration with software engineers and product designers
Providing the business with reports and dashboards, on key performance metrics
Developing metrics to accurately assess the health of our Exchange platform
Comparative data-driven analysis of our Exchange against alternative platforms
Formulating business requirements into analytical objectives
Designing and running experiments to test hypotheses
Hacking through complex business problems using advanced data analysis to provide insights and recommendations
Building, maintaining, and optimising decisioning systems using advanced statistical and predictive modelling techniques
What will set you apart:
An advanced degree in Mathematics, Statistics, Computer Science or related field
At least 3 years' experience working in a similar role
A basic understanding of trading in financial markets
Experience working with a data analytics and visualisation platform such as Tableau, Cognos, QlikView, or Looker
Familiarity with using Google Analytics to understand customer behaviour
Solid knowledge of statistical and machine learning techniques
Familiarity with modern distributed data storage and processing systems such as Amazon Redshift, Big Query, Snowflake, Databricks and Apache Spark
You can gather and synthesise facts, theories, trends, patterns, inferences, and key issues in complex and variable situations
Ability to diagnose problems using formal problem-solving tools and techniques from multiple angles to generate multiple possible solutions
A sense of anticipating long-term problem areas and associated risk levels with objective rationale
Remote Life at Luno

If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
You'll be able to continuously upskill yourself with access to free online learning via MyAcademy, an international teaching marketplace with over 100000 courses from Harvard and other leading providers + share knowledge with your peers.
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity and paternity leave, and you can even take paw-ternity leave for your furry friend.
Annual Inspiration Day! Make time for that pottery course or spa day you've always wanted to do.
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"EY is a global leader in
assurance, tax, transaction and advisory services. Technology is at the heart
of what we do and deliver at EY. Technology solutions are integrated in the
client services we deliver and are key to our innovation as an organization.

Fueled by
strategic investment in technology and innovation, Client Technology seeks to
drive growth opportunities and solve complex business problems for our clients
through building a robust platform for business and powerful product engine
that are vital to innovation at scale. As part of Client Technology, you’ll
work with technologists and business experts, blending EY’s deep industry
knowledge and innovative ideas with our platforms, capabilities, and technical
expertise. As a catalyst for change and growth, you’ll be at the forefront of
integrating emerging technologies from AI to Data Analytics into every corner
of what we do at EY. That means more growth for you, exciting learning
opportunities, career choices, and the chance to make a real impact.

The selected
candidate
Develops
large and complex data architecture, composed of models, policies, rules or
standards that govern which data is collected and how it is stored, arranged,
integrated and put to use in data systems, including the design, build and
management of data infrastructure to address business requirements
Creates
sound use case driven roadmaps, depicting data architecture as-is and to-be
capabilities with the business by engaging with multidisciplinary teams, and by
identifying, managing and mitigating risk
Develops
relationships across the business to understand data requirements, applies deep
technical knowledge of data management to solve business problems in areas
where solutions may not currently exist, necessitating new solutions/ways of
working/technologies and proactively articulating these to the business
Review,
identify the latest emerging technologies, augmenting by services from the
leading cloud providers to solution and recommend the best next generation data
platform value driven approach for our clients
Your Key Responsibilities Include
Create
and maintain conceptual, logical and physical database models
Document
functional requirements and system specifications into the data architecture
and detailed design specifications for current and proposed designs
Document
and adhere to development standards and best practices in database designs
Maintain
highly effective and consistent communication within the team, peers, and the
leadership team
Reverse
engineer SQL code and modify it to solve problems/issues
Contribute
to the definition and implementation of data governance practices
Design
both data structures and data integration practices
Work
closely with the infrastructure teams to create a physical environment to
support data services
Evaluate
new and existing (internal and external) technologies and services in support
of data services and data analytics objectives
Skills And Attributes For Success
Understanding
of business process reengineering and business modeling concepts, business
systems development and analysis
Hands-on
experience in designing and implementing hybrid cloud and on-prem solutions
Experience
working with the latest versions of SQL Server
Experience
applying SAFe/Scrum/Kanban methodologies
Ability
to exercise judgment in solving technical, operational, and organizational
challenges
Expert
programming, performance tuning and troubleshooting skills, using the latest
popular programming languages for example python
Demonstrate
proactive approach to identifying issues and presenting solutions and options,
and where appropriate, leading to resolution
Minimum Qualifications
5+ years
demonstratable work experience as a Data Architect using data modeling tools
2-3 years
SQL coding experience on large projects
Must
possess expert SQL programming, performance tuning and troubleshooting skills
Create
database objects and SQL scripts
Understand
and developed data pipelines
Know how
to deformalize data for data science models
Experience
in python, spark and notebooks
Experience
designing data warehousing solutions
Experience
designing next generation data platforms utilising cloud services
In-depth
understanding of database structure principles
Seamlessly
able to translate business requirements to technology requirements
What We Look For
Strong
analytical skills and problem-solving ability
A
self-starter, independent-thinker, curious and creative person with ambition
and passion
Excellent
inter-personal, communication, collaboration, and presentation skills
Customer
focused
Excellent
time management skills
Positive
and constructive minded
Takes
responsibility for continuous self-learning
Takes the
lead and makes decisions in critical times and tough circumstances
Attention
to detail
High
levels of integrity and honesty
Curious
about new emerging technology
About EY
As a global leader in assurance, tax, transaction and consulting
services, we’re using the finance products, expertise and systems we’ve
developed to build a better working world. That starts with a culture that
believes in giving you the training, opportunities and creative freedom to make
things better. Whenever you join, however long you stay, the exceptional EY
experience lasts a lifetime.",3.8,"EY
3.8",Johannesburg,-1,10000+ Employees,1989,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Architect - Principal,-1,"We are looking for Principle Data Architect to join our Engineering team in Cape Town.

The world is changing.
We all want something different.
At Luno, we see you as individuals.

Together, we are upgrading the world of work to unleash the potential within and empower you to become the best possible version of yourself.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the financial landscape, and to do so, well we need the best team on board for our mission. In short, to achieve our goals, we need rockstars. As simple as that.

A little about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 5 million customers across 40 countries.
We're part of the Digital Currency Group, a group of companies driving progress in the cryptocurrency and blockchain space that includes Grayscale, Genesis, Coindesk and Foundry Services
Our platform has processed over $8 billion to date
We're proud to be one of the world's most international cryptocurrency teams from 43 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
How we work


Our engineering team (currently ~100 engineers) is split into organisations which we call Fleets. Each Fleet focuses on a core customer journey (onboarding, security, payments, support, new business, growth and marketing etc.). Each of these fleets contains multiple smaller teams called Pods, each of which focuses on a specific aspect of the product.

Pods will include a product owner, product designer, back-end engineers, Android, iOS and Web developers, who each bring a unique perspective to the problem you are all contributing towards.

We're agile, use scrum, continuous integration and continuous delivery, deploying to production every single day.

We're building teams to help us succeed in our mission to upgrade the world to a better financial system. You'll be joining a group of highly motivated software engineers who you'll work collaboratively with across our pods.

As a fast-growing company with offices around the world, you'll immediately see how your contributions directly impact both our internal users and client experience. Many of the problems we are solving result in trail blazing solutions which can't be found on Stack Overflow; so we're looking for engineers who flourish working in a complex domain.

In your first six months, you will:


...start at Luno by learning our processes, meeting the wider team and starting our engineering on-boarding program. After getting comfortable with the basics, you'll start learning our idiomatic patterns in a safe, easy-to-follow way - by building your own toy micro services. You'll get to practice how we do design docs, code reviews, deployments, events, logging and monitoring.

You'll meet the Pod(s) you'll be working with and quickly align on the teams' current OKRs and product roadmap. We succeed as a team, so we will provide you with regular feedback from your manager and peers and will encourage you to do the same.

What you'll do:
Work closely with our data science and platform teams on projects introducing new streams of data into our data lake
You will get to bring new ideas on how to further develop and innovate our data solutions and how to expose that data to the business
Accountable and Responsible for the design and architecture of Data systems that are robust and scalable.
Work in an Agile/Scrum framework or Agile mindset
Data backup/recovery and storage
Pick-up and learn new concepts, in both engineering and product, and be able to apply that knowledge quickly.
The ideal candidate for this role will have:
7+ years' experience in maintaining scalable data solutions and/or you are passionate about it
Ability to understand, communicate and advocate between build vs buy
Proven track record of setting up, restructuring and maintenance of databases
You know your way around ETL and you have experience with SQL
Experience in the AWS Data stack (RedShift,DynamoDB, Amazon RDS)
Familiarity with integrating data stores with BI platforms such as Looker, Tableau, or Power BI
You have experience with the concepts of CI/CD
Coding skills in e.g. Go, Python
Bachelor's degree in a related field preferred
AWS Certified DataOps Administrator
Be friendly, transparent, articulate and driven to succeed
Basic knowledge of and passion for digital currencies like Bitcoin
A work permit for South Africa if you are not a South African citizen
Don't be put off if you don't tick all of the boxes – they're a guide based on what we'd love to see but we appreciate that excellent software engineers have diverse backgrounds.

Remote Life at Luno


If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity / paternity and even (yes, you are reading it correctly) paw-ternity for your furry friend..
Annual Inspiration Day.. like that pottery course you've always been meaning to do!
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. You'll need to hold the legal right to work in South Africa already as we cannot provide visa sponsorship.

Be part of the change!",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer - EC2 Capacity Data Analytics,-1,"EC2 Capacity Data Analytics (CDA) team is looking for a Data Engineer to join our team.

Our team is part of the EC2 Capacity Engineering organization, which is responsible for providing the elasticity EC2 customers need to scale up/down compute resources in a cost-efficient manner. We predict customer usage across thousands of configuration combinations to deliver exactly what our customers require in just the right amount of time with just the right amount of capacity.

As a Data Engineer, you will build the ETL and analytics solutions for our internal customers to answer questions with data and drive critical improvements for the business. You will use best practices in software engineering, data management, data storage, data compute, and distributed systems. On any given day, we use Python, Scala, Java, SQL, Lambda, CloudFormation, Redshift and Glue as well as other public AWS services and a host of Amazon internal tools. We dont expect you to be an expert in, or necessarily even be familiar with all of the technologies listed above, but we do expect you to be excited to learn about them.

This position involves on-call responsibilities, typically for one week every two months. Our team is dedicated to supporting new team members. We care about your career growth, we try to assign projects and tasks based on what will help each team member develop into a more well-rounded engineer and enable them to take on more complex tasks in the future.

Our team values work-life balance and we are flexible when people occasionally need to work from home.

Job Duties
Develop and maintain automated ETL pipelines for big data using languages such as Scala, Spark, SQL and AWS services such as S3, Glue, Lambda, SNS, SQS, KMS. Example: ETL jobs that process a continuous flow of JSON source files and output the data in a business-friendly Parquet format that can be efficiently queried via Redshift Spectrum using SQL to answer business question.

Develop and maintain automated ETL monitoring and alarming solutions using Java/Python/Scala, Spark, SQL, and AWS services such as CloudWatch and Lambda.

Implement and support reporting and analytics infrastructure for internal business customers using AWS, services such Athena, Redshift, Spectrum, EMR, and QuickSight.

Develop and maintain data security and permissions solutions for enterprise scale data warehouse and data lake implementations including data encryption and database user access controls and logging.

Develop and maintain data warehouse and data lake metadata, data catalog, and user documentation for internal business customers.

Develop, test, and deploy code using internal software development toolsets. This includes the code for deploying infrastructure and solutions for secure data storage, ETL pipelines, data catalog, and data query.


Basic Qualifications

· Bachelors degree in Computer Science or related technical field, or equivalent work experience.
· 4+ years of overall work experience including Software Engineering, Data Engineering, Database Engineering, Business Intelligence.
· Experience with AWS technologies stack including Lambda, Glue, Redshift, RDS, S3, EMR or similar big data solutions stack

Preferred Qualifications

· Demonstrate efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data.
· Demonstrable proficiency in distributed systems and data architecture; design and implementation of batch and stream data processing pipelines; knows how to optimize the distribution, partitioning, and MPP of high-level data structures.

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer,-1,"Our client based in Johannesburg is urgently looking for a Data Engineer to be on a 3 months contract
Build data pipelines, experience in new tech like nifi, kafka, python

Joburg based, open to EE, 3 month contract with the option to extend, must be available at short notice",-1,EQplus,Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Overview
Job ID: 51456
Job Sector: Information Technology and Services
Country: South Africa
Region/State/Province/District: Gauteng
Location: Johannesburg

Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose

This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes

Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems

Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions

Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.
Research and best practices

Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development

Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.

Preferred Qualification and Experience

Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry

Knowledge/Technical Skills/Expertise

Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision

PLEASE NOTE: All our recruitment and selection processes comply with applicable local laws and regulations. We will never ask for money or any form of payment as part of our recruitment process. If you experience this, please contact our Fraudline on +27 800222050 or forward to TransactionFraudOpsSA@standardbank.co.za",4.1,"Standard Bank
4.1",Johannesburg,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"About us

At PBT Group we pride ourselves on being a Data Specialist organisation. With 20 years of experience in 27 countries over 3 continents, our team of 550 consultants have implemented more than 700 projects.",4.3,"PBT Group
4.3",Johannesburg,-1,Unknown,-1,Company - Private,Accounting,Accounting & Legal,Less than $1 million (USD),-1
Data Engineer,-1,"Kick-start your career in the online gaming world and experience the very latest in technology and innovation.

The Department:

Our mission is to provide our customers with the best online betting experience and share the thrill of gaming with them. Data is at the very heart of our business and is vital in everything we do.

Our cross-functional Data team has a big and exciting challenge ahead. We are in the process of re-platforming our traditional, on-premises RDBMS environment to a new microservice architecture in the cloud. We’re making use of the diverse set of data technologies in Microsoft Azure to offer new services, reporting structures and real-time data pipeline while serving the day-to-day requirements of a rapidly growing, data-hungry organisation.

Purpose of the Role:

This is an excellent opportunity for an individual who is looking to gain new skills. We are committed to creating a culture of learning and regularly run proof of concepts, provide internal demos, manage workshops and attend external conferences. Our data team has a wide range of skills including development for highly transactional RDBMS systems, data warehousing, data science and cloud technologies and we are always working to raise everyone’s game.

Duties include, but not limited to:

Work as part of an agile Data Engineering Team
Development of greenfield projects in Azure
Develop and maintain on-premises RDBMS/DW systems
Create robust ETL services and real-time data pipelines
Build and maintain Continuous Integration and DevOps pipelines
Test-driven development and pair programming with colleagues

Essential Criteria:

C#, .Net, Visual Studio
Git, Azure DevOps
NoSQL development (CosmosDB)
Demonstrable understanding of MS SQL Server in a highly transactional environment
Demonstrable understanding of development in Microsoft Azure
Able to understand query plans and identify performance bottlenecks
Test/Business-Driven Development
Building Continuous Integration/Deployment pipelines
Communicate effectively with both technical and non-technical stakeholders

Desirable Criteria:

Implementing Data Storage and Processing solutions in Azure (ARM Templates, Storage Accounts, Data Lake Storage, SQL DB, Cosmos DB, EventHubs, Function Apps, Log Analytics, Data Factory, Databricks, Polybase)
Implementing Security, Disaster Recovery, High Availability, Auditing, Monitoring and Alerting solutions in Azure
Automating tasks in Azure using Powershell / CLI
Predicting costs and optimizing spending in Azure
Message Queues (RabbitMQ, Kafka)
Python

Person Specifications:

Resilience
Teamwork
Technical Knowledge
Communication skills
Stress Tolerance
Please note we will apply relevance to our Talent Management and Talent Development Programme as part of our recruitment process.
Shortlisted candidates may need to complete an assessment.
This position requires trust and honesty it has access to customers financial details - therefore a credit and criminal record check will be conducted. The qualifications identified herein are an inherent job requirement; therefore, a qualification verification check will be done. By applying for this role, and supplying the necessary details, you hereby grant us permission to apply for these checks. This will be done in a confidential manner, and solely for the purposes of verification.

To view all current vacancies, please visit our website, www.digioutsource.com

Should you not hear from us within 2 weeks, please deem your application as unsuccessful.

The perfect place to work, play and grow!",3.9,"Digital Outsource Services
3.9",Cape Town,-1,1001 to 5000 Employees,1997,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
Data Engineer,-1,"At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes

Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.

Key Responsibilities

Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.

Key Traits

Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern

Position Requirements

2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.

Where will you work? This role will be based out of Durbanville, South Africa.",3.1,"Aculocity, LLC
3.1",Durbanville,-1,1 to 50 Employees,2006,Company - Private,IT Services,Information Technology,$1 to $5 million (USD),-1
Data Engineer,-1,"ENVIRONMENT:

A rapidly growing E-Commerce Platform seeks a highly talented Data Engineer to make an invaluable contribution to data democratisation and literacy vision by making accessible and easy-to-use data products and tools. You will require a Comp-Sci Degree or 3 years’ relevant industry experience, MySQL, PostgreSQL, Java, Python, in-depth understanding of OLAP, Data Marts, Star Scheme, Snowflake, be familiar with Jenkins, Travis, Circle CI, Docker, Kubernetes, experience with Kafka, Pub/Sub, Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks & significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing & Data Lake design and implementation and Lambda/Kappa architectures.

DUTIES:

Design, develop, test and maintain data architecture.

Prepare data for descriptive, predictive and prescriptive modelling.

Automate repetitive tasks and manual processes related with the data usage.

Optimize data delivery.

Design, develop and test large stream data pipelines to ingest, aggregate, clean, and distribute data models ready for analysis.

Ensure the highest standard in data integrity.

Leverage best practices in continuous integration and delivery.

Collaborate with other engineers, ML experts, analysts, and stakeholders to produce the most efficient and valuable solutions.

Implement features, technology, and processes that move us towards industry best practices, improving on scalability, efficiency, reliability, and security.

Operations and ownership of systems in production, responding to incidents.

REQUIREMENTS:

Qualifications –

Comp-Sci Degree or 3 years relevant industry experience.

Experience/Skills –

Open source relational database systems e.g. MySQL, PostgreSQL, etc.

Significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing, and Data Lake design and implementation and Lambda/Kappa architectures.

A thorough understanding of database and data warehousing principles e.g. OLAP, Data Marts, Star Schema, Snowflake, etc.

Java and Python.

Familiar with CI/CD tools such as Jenkins, Travis, Circle CI, etc.

Experience with Kafka, Pub/Sub, or other event-based systems.

Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks, etc.

Working in cloud environments and with containerisation frameworks, tools and platforms e.g. Docker, Kubernetes, GKE, etc.

A deep understanding of data pipelining, streaming, and Big Data technologies, methods, patterns, and techniques.

Troubleshooting complex database operations and performance issues.

Automating tasks using Shell Scripting or writing small applications.

ATTRIBUTES:

Works well with people and is passionate about helping people be their best.

A team player, an active listener, mentor, and able to communicate well.

Shows solid reasoning and decision making, with the ability to work under pressure.

Is passionate about technology, systems and data.

Is curious, always learning, and keeping up to date with the industry.

While we would really like to respond to every application, should you not be contacted for this position within 10 working days please consider your application unsuccessful.

COMMENTS:

When applying for jobs, ensure that you have the minimum job requirements. Only SA Citizens will be considered for this role. If you are not in the mentioned location of any of the jobs, please note your relocation plans in all applications for jobs and correspondence.",-1,Datafin IT Recruitment,Cape Town,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Cartrack is looking for passionate data science and engineering candidates that can join a growing team that is responsible for the intelligence and efficiency solution provision to over a million subscribers, many of whom are large fleets. We are in the midst of creating revolutionary platforms that will change the way that people interact with their vehicles.

You will have the opportunity to work with the very brightest global subject matter experts that are transforming the automotive industry across Fleet Management, Asset Management and Insurance Telematics solutions.

Get to know the role:

The role of a data engineer is a supporting one, but it is also an extremely vital one. As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements. We want to see candidates with mechanical tendencies and a desire to know how things work and to improve them.

The day-to-day activities:

Design, construct, install, test and maintain data management systems.
Build high-performance algorithms, predictive models, and prototypes.
Ensure that all systems meet the business/company requirements as well as industry practices.
Integrate up-and-coming data management and software engineering technologies into existing data structures.
Develop set processes for data mining, data modeling, and data production.
Create custom software components and analytics applications.
Research new uses for existing data.
Employ an array of technological languages and tools to connect systems together.
Install/update disaster recovery procedures.
Recommend different ways to constantly improve data reliability and quality.
Work on and maintain Data pipelines.

Requirements Essential:

At least 5 years’ proven experience as a Data Engineer, DevOps Engineer, Software Developer, or similar.
Proficient in Linux/Unix and shell scripting as well as in functional programming languages.
Expertise in setting up and explored with technologies such as Hadoop and Spark.
Bachelor’s degree in computer science, software/computer engineering, applied mathematics, or physics.",3.3,"Cartrack
3.3",Johannesburg,-1,501 to 1000 Employees,2004,Company - Private,Security Services,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Data Engineer,-1,"Data Engineers build and support data pipelines and datamarts built off those pipelines. Both must be scalable, repeatable and secure. The Data Engineer helps to facilitate gathering data from a variety of different sources, in the correct format, assuring that it conforms to data quality standards and assuring that downstream users can get to that data timeously. This role functions as a core member of an agile team. These professionals are responsible for the infrastructure that provides insights from raw data, handling and integrating diverse sources of data seamlessly. They enable solutions, by handling large volumes of data in batch and real-time by leveraging emerging technologies from both the big data and cloud spaces. Additional responsibilities include developing proof of concepts and implements complex big data solutions with a focus on collecting, parsing, managing, analysing and visualising large datasets. They know how to apply technologies to solve the problems of working with large volumes of data in diverse formats to deliver innovative solutions. Data Engineering is a technical job that requires substantial expertise in a broad range of software development and programming fields. These professionals have a knowledge of data analysis, end user requirements and business requirements analysis to develop a clear understanding of the business need and to incorporate these needs into a technical solution. They have a solid understanding of physical database design and the systems development lifecycle. This role must work well in a team environment.

Job Objectives

Work Complexity: * Architects Data analytics framework. * Translates complex functional and technical requirements into detailed architecture, design, and high performing software. * Leads Data and batch/real-time analytical solutions leveraging transformational technologies. * Works on multiple projects as a technical lead driving user story analysis and elaboration, design and development of software applications, testing, and builds automation tools.

Main Job Objectives: 1. Development and Operations 2. Database Development and Operations 3. Policies, Standards and Procedures 4. Communications 5. Business Continuity & Disaster Recovery 6. Research and Evaluation 7. Coaching/ Mentoring

Qualifications

Essential: 4 years Bachelors degree in computer science, computer engineering, or equivalent work experience AWS Certification at least to associate level

Experience

Essential:

5+ years Data engineering or software engineering

3-5 years demonstrated experience leading teams of engineers

2+ years Big Data experience

5+ years experience with Extract Transform and Load (ETL) processes

2+ years Could AWS experience

At least 2 years demonstrated experience with agile or other rapid application development methods - Agile exposure, Kanban or Scrum

5 years demonstrated experience with object oriented design, coding and testing patterns as well as experience in engineering (commercial or open source) software platforms and large scale data infrastructures.

Desirable:

5+ years Retail Operations experience

Knowledge and Skills

Essential: *Creating data feeds from on-premise to AWS Cloud (2 years) *Support data feeds in production on break fix basis (2 years) *Creating data marts using Talend or similar ETL development tool (4 years) *Manipulating data using python and pyspark (2 years) *Processing data using the Hadoop paradigm particularly using EMR, AWSs distribution of Hadoop (2 years) *Devop for Big Data and Business Intelligence including automated testing and deployment (2 years) * Extensive knowledge in different programming or scripting languages * Expert knowledge of data modeling and understanding of different data structures and their benefits and limitations under particular use cases.

Further technical skills required: * Capability to architect highly scalable distributed systems, using different open source tools. * Big Data batch and streaming tools * Talend (1 year) * AWS: EMR, EC2, S3 (1 year) * Python (1 year) * PySpark or Spark (1 year) - Desirable * Business Intelligence Data modelling (3 years) * SQL (3 years)",-1,Datonomy Solutions,Brackenfell,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We are assisting one of our clients that is based in Pretoria to fill a role of a Data Engineer

This is a 12 month contract role

Objective of this Scope of Work

The Data Engineer will drive improvement of the data management maturity levels and provide the necessary technical support within the company to support reliable and effective decision-making, appropriate usage and protection thereof.

Scope of Services Definition

The scope will include but will not be limited to:

ï†· To develop, construct, test and maintain architectures.

ï†· To ensure architectures will support the requirements of business.

ï†· To discover opportunities for data acquisition and sharing.

ï†· To develop data set processes for data modelling, mining and production.

ï†· To employ a variety of languages and tools to marry systems together.

ï†· To recommend way to improve data reliability, efficiency and quality.

ï†· To prepare data for use in predictive and prescriptive modelling.

ï†· To conduct research to answer industry and business questions.

ï†· To leverage volumes of data from internal and external to answer business questions.

ï†· To develop and manage stakeholder relations effectively to promote data management across the organisation and support reliable decision making and appropriate data usage.

ï†· To participate and provide technical support in cross organisational activities relating to any of the above mentioned data management activities.

ï†· To provide regular progress reports as per stakeholder requirements and present data management updates in various forums as required.

Minimum qualification Required:

ï†· A minimum of a Bachelors degree in Computer Science or Information Management OR equivalent;

ï†· A minimum of five to eight years experience in a data management environment",-1,HR Genie,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Our client based in the Northern Suburbs, is currently looking for a Data Engineer to join their team.

Responsibilities
Our client is a dynamic IT company that delivers value-driven IT solutions to the group. Our work lives revolve around our DNA. We take pride in our work, treat our colleagues, partners and our country with respect. We exercise collaborative decision-making and believe in having a balance in life. We do this all while having fun and enjoying what we do.

The primary focus of this position is to use technical skills to put software, systems and data together in a way that extracts meaningful insights from raw data. You will need to be helpful and supportive to your team and fellow developers. You join an energetic, focused and dynamic team.

Interact with clients to understand requirements and business problems/needs

Identify, analyse, visualise and understand supporting data to propose solid solutions

Create technical documentation for reference and reporting

Support existing solutions within GCP and Oracle

Doing standby on a rotating basis

Key Competencies and Qualifications

Matric

Tertiary qualification in IT

Preferred cloud experience in AWS/AZURE/GCP

At least 3 years of data warehouse ETL experience

Dimensional Modelling

Data analyses

Experience with data visualization and visualization tool(s)

Knowledge of the retail industry will be beneficial

Understanding and experience with version control SVN/GIT

Preferred – Korn shell scripting, Python/Java, SQL

Google Cloud Platform experience would be looked upon favourably

Having a broad understanding of different SDLC’s

Preferred agile experience

Strengths

The natural tendency to take ownership and responsibility

Strong problem solving, critical thinking, effective planning and organisational skills

Detail-oriented with excellent communication skills

You have a can-do attitude and positive outlook on life

Can cope under pressure

Curious and interested in analysing problems and possible solutions

Strong team player

Self-driven learner, passionate about new technology

Above all, be passionate about what you do

Should you wish to apply for the position, please apply directly via this job board, please ensure that you quote reference number 201620 subject heading or email body.

Please note that due to the high volume of CV's received; only shortlisted applicants will be contacted. Should you not receive communication from our offices within two weeks of submission please note that your application will not be considered for this position.

We will keep your CV on file and re-establish contact with you should opportunities in line with your expertise become available again.

Should you require any additional information give us a call on 021 012 5566.",-1,Surgo HR & Training,Cape Town,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We believe that our employees fuel our organization, essential to enable us to help our customers overcome their business challenges and achieve sustainable growth. As a result, we are committed to growing each individual and providing them with the challenges, feedback and support needed to achieve success in their career

If this sounds appealing, and like us, you get excited about data: its collection, storage, transformation or display, see if you’ve got what it takes to join our sought after DATA team.

Key Responsibilities And/or Outputs

You will represent IQbusiness at our customers, sometimes alone, and sometimes as part of an IQ team.

Providing a superior customer experience by building and maintaining relationships, working at customer offices, keeping data confidential
Design and develop – databases, SQL queries, stored procedures, reports, dashboards or integration solutions
Produce solutions for both real-time and batch environments
Test your work to ensure compliance
Solve problems, and do root cause analysis
Prioritize your workload
Assist in other areas relating to your true data function, such as data modeling, data and business analysts
Interact with a variety of individuals: senior, junior, technical and from business
Provide guidance to fellow colleagues, or even manage a team
Uphold the IQ values, which are to care, learn & share; innovate; deliver as well as to build, enhance and maintain relationships

Education

Matric pass
A tertiary qualification, preferably in an ICT relevant field
Appropriate Microsoft certifications are beneficial but not required

Requirements

3 - 6 years experience in the Data Engineering environments and technologies
Great communication skills
A passion for SQL, databases or reports
Can you write stored procedures, design complex queries and create views and triggers?
Are you able to work out the relationships in a data warehouse or the aggregation of a cube?
Do you extract and display useful information when you see patterns and trends in data?
Strong knowledge of the financial services industry, ideally in a consulting role
The use of data related software: databases, ETL and BI tools; report writing and analytical tools
We use a lot of Microsoft products. You may often be expected to use MS SQL Server, SSIS, SSRS, SSAS and Power BI to develop solutions
What other relevant software have you’ve used?
Ability to work in different project methodologies: Waterfall and/or Agile
Knowledge of full SDLC
Exposure to logical and physical data modeling

Equal Employment Opportunity

IQbusiness is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, citizenship, marital, domestic or civil partnership status, sexual orientation, or gender identity",3.7,"IQbusiness South Africa
3.7",Johannesburg,-1,1 to 50 Employees,-1,Company - Private,Consulting,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"We value a data engineer as someone who works behind the scenes to obtain, process and supply data via various methodologies and technologies, to various consumers, in ways and forms that makes sense and add value. This definition is very broad, as the field of data engineering is just as broad.

You may be the type of data engineer that develops API endpoints for the consumption of data by end users or even another data pipeline, or you may be the type of data engineer that develops highly distributed, high availability data processing pipelines in an effort to satisfy the need of the ever questioning data analysts and/or data scientists.

You have awesome knowledge about the following concepts
Data modelling
Relational data modelling in traditional relational database management systems. (Microsoft SQL Server, MySQL, PostgreSQL, etc)
Coercing unstructured and semi-structured data into a structured form.
Data pipelining knowledge - data extraction and transformation.
Data transformation knowledge for reporting and analytics purposes.
Knowledge of the MapReduce and related data processing paradigms would be a boon.
You have the following technical competencies
Writing SQL queries, that can relate, transform and aggregate data from many differing sources where natural keys may or may not exist.
Experience with writing data pipelines that move and transform data, for various uses.
Working knowledge of a general purpose programming language like Python would be a boost.
Working knowledge of columnar databases such as Google BigQuery, and SAP HANA would be a boost.
Working knowledge of highly distributed technologies such as Apache Hadoop or Apache Spark would be a boost.
Working knowledge of NoSQL technologies, such as Apache Solr would be a boost.
You have the following personal competencies
The ability to solve problems.
The ability to rotate around a problem, to see if solutions can be gained in different ways.
The ability to work in an ever changing, unstructured environment.
The ability to work as part of a team, with vastly differing skill sets and opinions.
The ability to contribute ideas to the quorum.
The ability to mentor and provide guidance for other team members.
A systems approach to thinking, as opposed to a siloed approach. The candidate needs to understand how their work affects the greater system.
The ability to work without supervision, and take accountability for the work they deliver.
The ability to liaise with a client, sifting through the fluff and extracting the actual requirements.
If this is you - apply now and we'll get in touch",-1,DotModus,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Data Engineer

Our client in the contact centre space is currently seeking a DATA ENGINEER that will work on the collecting, storing, processing, and analyzing of large datasets. The primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them. You will also be responsible for integrating them with the architecture used across the company.

Key Performance Areas:

Data reporting.
Implementing ETL processes.
Defining data retention policies.
Management of Customer Lead data.
Provision of data for advanced analytics.
Maintenance of internal client scorecards.
Assist team in resolving data-related support queries.
Optimize existing data processes through automation.
Assist with all data-related reporting and documentation.
Maintenance and optimisation of the Analytics database.
Provide technical support to and supervision of junior data administrators.
Continuous upskilling on new technologies, frameworks and market trends.
Monitoring performance and advising any necessary infrastructure changes.
Identifying, selecting and integrating any Big Data tools and frameworks required to provide real-time analytics.

Educational Requirements

IT related Degree or Diploma is a pre-requisite

Required Skills/Experience

ETL tools: Advanced SSIS
BI/Reporting : Qlikview/Power BI/ SSRS or SSAS
Programming languages: JAVA, C# , Python, SAS or R
Experience with NoSQL databases and/or campaign management tools will be advantageous.
Minimum 3 years’ applicable work experience in SQL, relational databases and data manipulation.
Experience in big data platforms (eg. Hadoop) or processing frameworks (eg. MapReduce/Spark) and querying tools (eg. Pig, Hive and Impala) will be highly beneficial.

Preferred Skills

Organizational skills
Experience in Attentional to detail.
Accountability is critical for this role.
Ability to work under pressure and meet deadlines.
Solid understanding of database design principles.
Should you not receive a response in 2 weeks please consider your application unsuccessful",-1,Rubik's Cubed Consulting,Durban,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"This well known company is looking for a Data Engineer. will be based in Rivonia
The ideal candidate will have strong experience in the following:
Data cleaning
SQL Export
Big data Sets

BSc Degree in Maths and Stats will be required
a min of 3 years experience.
Stable track record is required.

Send your Cv to marinda@prrrecruitment.co.za",-1,PRR Recruitment Services,Johannesburg,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Description

Position at Aculocity, LLC

At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes
Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.
Key Responsibilities
Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.
Key Traits
Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern
Position Requirements
2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.
Where will you work? This role will be based out of Durbanville, South Africa.",-1,GVW,Durbanville,-1,Unknown,-1,Unknown,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Information Technology, Gauteng JHB - Northern Suburbs

Market related - Market related Annually

An IT Consultancy Business based in Johannesburg is currently looking for a Business Intelligence Consultant / Data Engineering Consultant.

Requirements:

Extensive experience in data engineering
Experience in Business Intelligence, data and Power BI
Extensive experience in data governance and the Popi act
Ability to assess and make recommendations on data within the Popi act
Good understanding of T-SQL and query optimization, developing ETL strategies.
Good understanding with SQL Server 2008/2012, SSIS, SSRS and SSAS
Use SSIS to create ETL packages to validate, extract, transform, and load data into the data warehouse and data marts.
Deploy and configured the reports in the Report Server (SSRS).
Excellent experience in Tabular Modelling , PowerView, Qlikvie,w, and Power BI
Maintain ETL
Qlikview model
Create Drill-through, Drill-down, and Cross Tab Reports and Sub-Report using Report Definition Language (RDL).
Generate periodic reports based on the statistical analysis of the data using SQL Server Reporting Services (SSRS)
Advise and provide written technical documentation and recommendations

The information displayed above is not limited to advertisements. Please contact Thato for further information.

Please consider your application as unsuccessful if you have not received a response within 14 days of submitting your application. However, please keep a lookout on our website, www.bedifferent.co.za, for available positions that you may be suited for

Ad Visible Until: 29 October 2020
Ref: JHB005346/NL

Vacancy Type: Permanent",2.9,"Be Different Recruitment
2.9",Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Cloud Support Engineer (Big Data),-1,"ABOUT US

Amazon Web Services is the market leader and technology forerunner in the Cloud business. As a member of the AWS Support team you will be at the forefront of this transformational technology, assisting a global list of companies and developers that are taking advantage of a growing set of services and features to run their mission-critical applications. As a Cloud Support Engineer, you will act as the Cloud Ambassador across all the cloud products, arming our customers with required tools & tactics to get the most out of their Product and Support investment.

Would you like to use the latest cloud computing technologies? Do you have an interest in helping customers understand application architectures and integration approaches? Are you familiar with best practices for applications, servers and networks? Do you want to be part of a customer facing technology team helping to ensure the success of Amazon Web Services (AWS) as a leading technology organization?

If you fit the description, you might be the person we are looking for! We are a group of smart people, passionate about cloud computing, and believe that world class support is critical to customer success.

WHAT CAN YOU EXPECT FROM A LIFE AT AWS?

Every day will bring new and exciting challenges on the job while you:

· Learn and use groundbreaking technologies.
· Apply advanced troubleshooting techniques to provide unique solutions to our customers' individual needs.
· Interact with leading engineers around the world.
· Partner with Amazon Web Services teams to help reproduce and resolve customer issues.
· Leverage your extensive customer support experience to provide feedback to internal AWS teams on how to improve our services.
· Drive customer communication during critical events.
· Drive projects that improve support-related processes and our customers technical support experience.
· Write tutorials, how-to videos, and other technical articles for the developer community.
· Work on critical, highly complex customer problems that may span multiple AWS services.

WHY AWS SUPPORT?

· First and foremost this is a customer support role in The Cloud.
· On a typical day, a Support Engineer will be primarily responsible for solving customers cases through a variety of customer contact channels which include telephone, email, and web/live chat. You will apply advanced troubleshooting techniques to provide tailored solutions for our customers and drive customer interactions by thoughtfully working with customers to dive deep into the root cause of an issue.
· Apart from working on a broad spectrum of technical issues, an AWS Support Engineer may also coach/mentor new hires, develop & present training, partner with development teams on complex issues or contact deflection initiatives, participate in new hiring, write tools/script to help the team, or work with leadership on process improvement and strategic initiatives.
· Career development: We promote advancement opportunities across the organization to help you meet your career goals.
· Training: We have training programs to help you develop the skills required to be successful in your role.
· We hire smart people who are keen to build a career with AWS, so we are more interested in the areas that you do know instead of those you havent been exposed to yet.
· Support engineers interested in travel have presented training or participated in focused summits across our sites or at specific AWS events.
· As we operate on a follow-the-sun model, with Premium Support sites located globally, there is no after hours on-call or mandated overtime in this role.
· https://www.youtube.com/watch?v=GC3bWcFFZTo&t=24s



Basic Qualifications

The Big Data role supports our services that leverage data and produce business insights, which may include using Machine Learning/Artificial Intelligence (ML/AI). Helping our customers use and integrate Big Data services in what is arguably our industrys most exciting space. The portfolio of services covers EMR (Hadoop), DynamoDB (NoSQL), MangoDB, and Apache Cassandra.

· Advanced experience in Apache Hadoop, Apache Spark, Apache Hive, and Presto
· Advanced experience in DynamoDB or NoSQL technologies like MongoDB or Cassandra
· Advanced experience with System Administration with Linux (RHEL/CentOS) including Microsoft Active Directory, and LDAP integration.
· Experience with troubleshooting Kerberos Authentication problems.
· Experience with Network troubleshooting.
· Basic understanding of Machine Learning and statistics
· Experience with Java and Python and shell scripting
· Bachelors degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position



Preferred Qualifications

· Expert experience in the Hadoop Ecosystem including Apache Spark and Presto
· Expert experience in NoSQL
· Expert experience with blockchain technologies like Etherium Expert experience in data Data Lake architecture and administration
· Experience managing full application stacks from the OS up through custom applications
· Prior work experience with AWS - any or all of EC2, VPC, S3, RDS, EMR, Glue, SageMaker
· Excellent knowledge of Hadoop architecture, administration and support
· Expert understanding of distributed computing principles and their application in the cloud
· Good understanding of distributed computing environments Lead technical discussions on big data systems architecture and design
· Strong analysis and troubleshooting skills and experience
· AWS Certified Solutions Architect
· AWS certified Big Data Specialty
· Masters degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity and Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Response Center Engineer,-1,"Job Title
Response Center Engineer
Job Description


Philips is a world leading health technology company with a vision to make life better for people worldwide through meaningful innovation. Making good on this promise depends on our passionate, inspirational, collaborative and diverse team. We have over 80,000+ brilliant people around the world but are always looking for more. Like-minded, motivated, focused minds to join us in creating a healthier, more connected society while transforming themselves personally and professionally.

As a CCC Coordinator - Response Center Engineer you will have the opportunity to process customer calls and be responsible for screening and diagnosing professionally Healthcare equipment to support customers and colleagues remotely with solving technical issues and ensuring maximum customer satisfaction

You are responsible for:
Diagnose healthcare equipment to the quality standards set by Philips Healthcare (PH) remotely by interviewing customers or colleagues by telephone or by remotely logging in to the system
Advise Customer Care Center Coordinators and District Operations Managers and / or Team Leads about the best follow-up w.r.t. technical state of the diagnosed healthcare equipment
Advise the Customer Care Center Coordinators or Field Services Engineers about required spare parts and resources
Responsible for planning engineers related to Modality responsibility.
Responsible for coordination between CCC, CUSTOMER, Spare parts AND Engineer.
Responsible to drive Remote and FTR KPI’s to targets respectively 40% and 85%.
Will require minimal field work to keep abreast of technical capabilities.
Take calls from customers and make sure they are processed in the CCC ERP on timely manner including all relevant data
Support Field Services Engineers in the field with technical knowledge
Escalate technical issues to the Technical Support Specialist
Escalate technical issues to Business Unit support after consultation of the Technical Support Specialist
Monitor critical functions of the equipment’s in the IB and environmental conditions including RSN and True reachability.
Lead the planning and implementation of FSN’s and FCO’s accelerating remote implementation where applicable.
Submit timely and accurate service data, job sheets, reports, expense claims, radiation film badges, field problem reports and other paperwork as assigned
Keep abreast of new technologies likely to affect PH range of products
Use company property with care to ensure optimal results with minimal operational costs
Be a professional representative for PH with respect to customer problems, ensuring personal acceptability by the customer in behavior in accordance with PH policy and targets
Conform to PH safety standards including health and safety regulations and in the event of hazards or accidents to take immediate control of the situation and involve the Operations Manager and / or the responsible person to handle properly confidential issues according Philips standards and to act according General Business Principals
Follow all quality standards within the frame of valid PH business policies
Follow the company quality regulations (ISO 9001; PQA; TQM) and internal directives and procedures
You are a part of the dynamic South Africa Customer Care Centre Team .You will be reporting to the Customer Care Center Manager.

Requires a pleasant, assertive individual you can work very well in a team setting, a dynamic environment that requires flexibility and creativeness to achieve goals.

To succeed in this role, you should have the following skills and experience:
Degree level education or equivalent
Experience in maintenance and troubleshooting of technical complex systems
Fluent in English, verbal and written in addition to local language
In return, we offer you the unique combination of a critical and challenging role and a creative and empowering office environment. You will be actively encouraged to make improvements, establish best in class service and have a direct impact on the success of Philips on a daily basis.

Employment Equity

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply. Only apply for this role if you are a South African Citizen by birth or Naturalization prior to the 27 April 1994.

Why should you join Philips?

Working at Philips is more than a job. It’s a calling to create a healthier society through meaningful work, focused on improving 3 billion lives a year by delivering innovative solutions across the health continuum. Our people experience a variety of unexpected moments when their lives and careers come together in meaningful ways. Learn more by watching this video.

To find out more about what it’s like working for Philips at a personal level, visit the Working at Philips page on our career website, where you can read stories from our employee blog. Once there, you can also learn about our recruitment process, or find answers to some of the frequently asked questions.

Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.9,"Philips
3.9",Johannesburg,-1,10000+ Employees,1891,Company - Public,Health Care Services & Hospitals,Health Care,$10 to $25 million (USD),-1
Software Development Engineer - EC2 Placement,-1,"Build the systems that optimize how EC2 matches requests for Instances with the underlying compute capacity. EC2 Placement is seeking talented engineers to build the online and offline optimization systems for compute workload scheduling, and the customer capabilities to better manage those workloads. Amazon EC2 provides on-demand scalable compute capacity, and powers some of the largest services in the world. You will collaborate with a top-tier community of engineers to build systems to improve how customers are able to access EC2 compute resources.

The successful candidate will have strong software engineering experience, with a passion for thinking about, building and testing distributed systems. You have an interest in how Machine Learning and other optimization techniques can be applied to large-scale problems. You have demonstrated experience working with a team to design, build and operate large-scale systems. With strong engineering fundamentals, an analytical and data-driven approach to your work, and strong communication skills, you have the ability to collaborate well to deliver results. We move fast and work together on small teams to solve big problems.

If this opportunity sounds interesting, we would love to talk to you more about our work and the vibrant culture at AWS in Cape Town.

Basic Qualifications

· Degree in Computer Science or related field, or equivalent working experience
· 3+ years of industry experience in a software development environment
· Strong Computer Science fundamentals, including data structures, object-oriented design, algorithm design, problem solving, and complexity analysis.
· Proficiency in at least one modern programming language, such as Java, C#, Python, Scala, Kotlin

Preferred Qualifications

One or more of the following help you stand out:
· Demonstrated results designing, building and operating high-performance distributed systems in large-scale Linux environments
· Role model in writing high-quality, maintainable and secure code, mentoring others, and helping teams sharpen their development processes
· Ability to work effectively across teams to deliver results, with strong verbal and written communication skills
· Experience working with machine learning systems

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer - PBB IT,-1,"Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose


This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes
Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems
Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions
Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.

Research and best practices
Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development
Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.
Preferred Qualification and Experience
Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Aws Data Platform Engineer,-1,"Aws Data Platform Engineer

Posting Country:

South Africa

Date Posted:

15-Oct-2020

Full Time / Part Time:

Full Time

Contract Type:

Permanent

Joining Vodacom is more than a job, what we do matters. We don’t just carry minutes, texts and data – we carry people’s lives. And that’s a huge responsibility. If you think for a minute about the people you rely on…the likelihood is they rely on us.

Customers are at the heart of everything we do and we want to make a difference to the lives of our customers, and the communities in which we live and work. We support our people to give something back to the causes that mean the most to them through helping them give time and money to the charities they love.

And what’s it like to work here? We have created an environment where you can look forward to coming to work and are empowered to be at your best. We offer flexibility in how you work that helps you do your job in a way that suits you, opportunities to help you grow and progress throughout your career and a choice of benefits to suit your lifestyle.

Role Purpose
The H Band AWS Data Platform Engineer position is based within the Technology Business Unit.

The AWS Data Platform Engineer will be responsible for all Database services such as RDS, DynamoDB, etc. Should be able to migrate any databases from anywhere to AWS using any third-party tools or AWS database migration tool. Should also have understanding or expertise in creating data warehouses and data lake solutions on AWS.
Your responsibilities will include:
Apply practical knowledge of relational database design and usage with customers
Perform workload analysis and undertake performance tuning, as well as performance benchmarking in customer environments.
To develop state of the art solutions which are technically sound.
To provide a high-quality service to the Enterprise Cloud Services clients i.t.o. consultancy, solutions and delivery.
Commitment to team success and positive team dynamics including mentoring of other team members.
Passion for growing and applying technical skills in service to customers.
Be a trusted infrastructure advisor by providing objective, practical and relevant ideas, insights and advice.
Work collaboratively with consulting partners and technology teams to ensure high quality of solution delivery.
Encourage best practice and knowledge sharing with partners and cross-functional groups
Manage the overall database design and delivery of solutions.
Ability to make recommendations as they pertain to improvements in support/development initiatives and facilitate implementation with partners and cross-functional groups within the Business.
Participate in high level database solution definition and design during the implementation phase with the goal of providing reliable, stable and operationally sound applications that meet the Business requirements.
Ability to understand and translate business requirements into technical specifications
The ideal candidate will have:
A minimum of 3 years of industry related experience of which 1 year must be within a complex hosting environment.
Certifications in Database design, system architecture or cloud technologies.
Demonstrate knowledge of database systems internals including storage layouts and distributed databases/MPP architectures
Advanced SQL coding, tuning and query optimization.
Experience designing and leading database performance benchmarks.
Good knowledge of the different AWS services
Knowledge of cloud networking architecture, cloud operations, security, automation and orchestration.
Knowledge of database internals as it relates to query and system performance and tuning.
Understanding of overall system architecture, scalability, reliability, and performance in a database environment.
Excellent teamwork, time-management and organizational skills.
Perform other duties as deemed necessary and assigned by the customer and management
Strong interpersonal skills and problem-solving abilities.
Excellent documentation, communication and interpersonal skills.
Excellent analytical and problem-solving abilities.
Closing date for applications: Monday, 13 April 2020

The base location for this role is Vodacom World, Midrand

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply.
Vodacom is committed to an organisational culture that recognises, appreciates and values diversity & inclusion.

Commitment from Vodacom

Vodacom is committed to attracting, developing and retaining the very best people by offering a flexible, motivating and inclusive workplace in which talent is truly recognized, developed and rewarded. We believe that diversity plays an important role in the success of our business and we are committed to creating an inclusive work environment which respects, values, celebrates and makes the most of people’s individual differences - we are not only multinational but multicultural too. At Vodacom you will have access to our excellent flexible benefits programme that you would expect from any global company.",3.9,"Vodafone
3.9",Midrand,-1,10000+ Employees,1982,Company - Public,"Cable, Internet & Telephone Providers",Telecommunications,$10+ billion (USD),-1
Data Engineer Azure Data Factory,-1,"Enthuzex is looking for a motivated Lead Data Engineer to contribute towards the success of our Data and Analytics Technology initiatives. This is a hands-on technical role and this person will be responsible for the development and build of scalable solutions as it relates to the architecture strategies, data standards, digital data management, data integration, tools, and technology. The right candidate will play a deep dive hands-on critical development role in the digital transformation and in shaping how we acquire, ingest, transform and deliver data through the digital consumer channels.

Responsibilities:

Architect, design, develop and engineering end-to-end data pipelines across multiple data sources and systems of record.
Ensure data quality, integrity, security and completeness throughout the data lifecycle
Develop, design data models, data structures and ETL jobs for data acquisition and manipulation purposes
Develop deep understanding of the data sources, implement data standards, maintain data quality and master data management
Developing data services and API
Work closely with the cloud service providers to ensure completeness and alignment with the service offerings
Manage and maintain cloud based data and analytics platform
Deep understanding of the cloud offerings and engage in quick proof of concepts and proof of value in prototyping data and analytics solutions and derive viability
Ability to interact with the business stakeholders to understand requirements and translating into technology solutions

Expirience:

Experience in Cloud platform AWS or Azure eco-system. (Azure preferred)
Data Engineering/Development experience with SQL (Oracle, SQL Server, MySQL)
Strong development background creating pipelines and complex data transformations and manipulations using one of the languages Python, Java, R, or Scala with Databricks/Spark
Experience in NoSQL Databases and Big data technologies including Hadoop
Experience with API / RESTful data services
Worked on real-time data capture, processing and storing using technologies like Azure Event Hubs and Analytics
Experience working with different data storage options including AWS S3, Azure BLOB storage etc.
Understanding of different data formats including Parquet, Avro, CSV, ORC etc.
Prior experience with MPP databases and maintain large amount of data processing
Experience with Azure Data Factory and Azure Data Catalog is a big plus and mandatory
Experience with Microsoft/Azure ETL solutions and business Intelligence technologies is a big and mandatory
Past working experience on a fast paced and agile environment
Perform ongoing monitoring, automation and refinement of data engineering solutions
Experience in leading high visibility transformation projects that interacts with multiple business lines
Build and meet project timelines and manage delivery commitments with proper communication to management

Qualifications

Bachelor’s degree with 4+ years of relevant experience
Willingness to learn new technologies and thrive in an extremely fast paced environment
Team player and easy to work with.

Applicants must demonstrate their ability to master new enterprise level technologies. Successful applicants will exemplify Enthuzex ethical principles of uncompromising integrity, respect for others, and accountability for decisions

send cv's info@enthuzex.co.za",-1,Enthuzex,Leslie,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Scientist,-1,"The world is changing.

We all want something different.

At Luno, we see you as an individual.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the world, and to do so, we need the best team on board for our mission.

A bit about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 3 million customers across 40 countries.
We are Series B funded, backed by Balderton Capital and the Naspers Group.
Our platform has processed over 8 billion dollars since we've launched
We're proud to be one of the world's most international cryptocurrency teams from 26 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
The role in a nutshell:

Identifying opportunities in the business that could benefit most from cognitive applications, as well as building and enhancing organisational capabilities for deriving value from multiple data sources using data science.

What we'd like you to have:
Bachelor's degree or higher in the natural sciences or technical fields such as Mathematics, Statistics, Computer Science, Engineering or Economics
Enthusiasm to work in the cryptocurrencies space
Advanced SQL skills
Solid understanding of exploratory data analysis, predictive analytics, and optimisation using Python, R, Matlab, RapidMiner, KNIME or other data science-oriented platforms
Proficiency in the use of data science and machine learning domain-specific languages such as ""Caret"" and the ""Tidyverse"" suite of tools in R, or ""Pandas"" in Python
Strong interpersonal and communication skills
Communicating data insights using storytelling narratives
Ability to work independently, as well as within and across teams
Ability to successfully complete projects with large and/or incomplete data sets
More about what you'll be doing:
Optimising product performance by tracking and analysing customer behaviour on web and app, in collaboration with software engineers and product designers
Providing the business with reports and dashboards, on key performance metrics
Developing metrics to accurately assess the health of our Exchange platform
Comparative data-driven analysis of our Exchange against alternative platforms
Formulating business requirements into analytical objectives
Designing and running experiments to test hypotheses
Hacking through complex business problems using advanced data analysis to provide insights and recommendations
Building, maintaining, and optimising decisioning systems using advanced statistical and predictive modelling techniques
What will set you apart:
An advanced degree in Mathematics, Statistics, Computer Science or related field
At least 3 years' experience working in a similar role
A basic understanding of trading in financial markets
Experience working with a data analytics and visualisation platform such as Tableau, Cognos, QlikView, or Looker
Familiarity with using Google Analytics to understand customer behaviour
Solid knowledge of statistical and machine learning techniques
Familiarity with modern distributed data storage and processing systems such as Amazon Redshift, Big Query, Snowflake, Databricks and Apache Spark
You can gather and synthesise facts, theories, trends, patterns, inferences, and key issues in complex and variable situations
Ability to diagnose problems using formal problem-solving tools and techniques from multiple angles to generate multiple possible solutions
A sense of anticipating long-term problem areas and associated risk levels with objective rationale
Remote Life at Luno

If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
You'll be able to continuously upskill yourself with access to free online learning via MyAcademy, an international teaching marketplace with over 100000 courses from Harvard and other leading providers + share knowledge with your peers.
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity and paternity leave, and you can even take paw-ternity leave for your furry friend.
Annual Inspiration Day! Make time for that pottery course or spa day you've always wanted to do.
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"EY is a global leader in
assurance, tax, transaction and advisory services. Technology is at the heart
of what we do and deliver at EY. Technology solutions are integrated in the
client services we deliver and are key to our innovation as an organization.

Fueled by
strategic investment in technology and innovation, Client Technology seeks to
drive growth opportunities and solve complex business problems for our clients
through building a robust platform for business and powerful product engine
that are vital to innovation at scale. As part of Client Technology, you’ll
work with technologists and business experts, blending EY’s deep industry
knowledge and innovative ideas with our platforms, capabilities, and technical
expertise. As a catalyst for change and growth, you’ll be at the forefront of
integrating emerging technologies from AI to Data Analytics into every corner
of what we do at EY. That means more growth for you, exciting learning
opportunities, career choices, and the chance to make a real impact.

The selected
candidate
Develops
large and complex data architecture, composed of models, policies, rules or
standards that govern which data is collected and how it is stored, arranged,
integrated and put to use in data systems, including the design, build and
management of data infrastructure to address business requirements
Creates
sound use case driven roadmaps, depicting data architecture as-is and to-be
capabilities with the business by engaging with multidisciplinary teams, and by
identifying, managing and mitigating risk
Develops
relationships across the business to understand data requirements, applies deep
technical knowledge of data management to solve business problems in areas
where solutions may not currently exist, necessitating new solutions/ways of
working/technologies and proactively articulating these to the business
Review,
identify the latest emerging technologies, augmenting by services from the
leading cloud providers to solution and recommend the best next generation data
platform value driven approach for our clients
Your Key Responsibilities Include
Create
and maintain conceptual, logical and physical database models
Document
functional requirements and system specifications into the data architecture
and detailed design specifications for current and proposed designs
Document
and adhere to development standards and best practices in database designs
Maintain
highly effective and consistent communication within the team, peers, and the
leadership team
Reverse
engineer SQL code and modify it to solve problems/issues
Contribute
to the definition and implementation of data governance practices
Design
both data structures and data integration practices
Work
closely with the infrastructure teams to create a physical environment to
support data services
Evaluate
new and existing (internal and external) technologies and services in support
of data services and data analytics objectives
Skills And Attributes For Success
Understanding
of business process reengineering and business modeling concepts, business
systems development and analysis
Hands-on
experience in designing and implementing hybrid cloud and on-prem solutions
Experience
working with the latest versions of SQL Server
Experience
applying SAFe/Scrum/Kanban methodologies
Ability
to exercise judgment in solving technical, operational, and organizational
challenges
Expert
programming, performance tuning and troubleshooting skills, using the latest
popular programming languages for example python
Demonstrate
proactive approach to identifying issues and presenting solutions and options,
and where appropriate, leading to resolution
Minimum Qualifications
5+ years
demonstratable work experience as a Data Architect using data modeling tools
2-3 years
SQL coding experience on large projects
Must
possess expert SQL programming, performance tuning and troubleshooting skills
Create
database objects and SQL scripts
Understand
and developed data pipelines
Know how
to deformalize data for data science models
Experience
in python, spark and notebooks
Experience
designing data warehousing solutions
Experience
designing next generation data platforms utilising cloud services
In-depth
understanding of database structure principles
Seamlessly
able to translate business requirements to technology requirements
What We Look For
Strong
analytical skills and problem-solving ability
A
self-starter, independent-thinker, curious and creative person with ambition
and passion
Excellent
inter-personal, communication, collaboration, and presentation skills
Customer
focused
Excellent
time management skills
Positive
and constructive minded
Takes
responsibility for continuous self-learning
Takes the
lead and makes decisions in critical times and tough circumstances
Attention
to detail
High
levels of integrity and honesty
Curious
about new emerging technology
About EY
As a global leader in assurance, tax, transaction and consulting
services, we’re using the finance products, expertise and systems we’ve
developed to build a better working world. That starts with a culture that
believes in giving you the training, opportunities and creative freedom to make
things better. Whenever you join, however long you stay, the exceptional EY
experience lasts a lifetime.",3.8,"EY
3.8",Johannesburg,-1,10000+ Employees,1989,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Architect - Principal,-1,"We are looking for Principle Data Architect to join our Engineering team in Cape Town.

The world is changing.
We all want something different.
At Luno, we see you as individuals.

Together, we are upgrading the world of work to unleash the potential within and empower you to become the best possible version of yourself.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the financial landscape, and to do so, well we need the best team on board for our mission. In short, to achieve our goals, we need rockstars. As simple as that.

A little about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 5 million customers across 40 countries.
We're part of the Digital Currency Group, a group of companies driving progress in the cryptocurrency and blockchain space that includes Grayscale, Genesis, Coindesk and Foundry Services
Our platform has processed over $8 billion to date
We're proud to be one of the world's most international cryptocurrency teams from 43 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
How we work


Our engineering team (currently ~100 engineers) is split into organisations which we call Fleets. Each Fleet focuses on a core customer journey (onboarding, security, payments, support, new business, growth and marketing etc.). Each of these fleets contains multiple smaller teams called Pods, each of which focuses on a specific aspect of the product.

Pods will include a product owner, product designer, back-end engineers, Android, iOS and Web developers, who each bring a unique perspective to the problem you are all contributing towards.

We're agile, use scrum, continuous integration and continuous delivery, deploying to production every single day.

We're building teams to help us succeed in our mission to upgrade the world to a better financial system. You'll be joining a group of highly motivated software engineers who you'll work collaboratively with across our pods.

As a fast-growing company with offices around the world, you'll immediately see how your contributions directly impact both our internal users and client experience. Many of the problems we are solving result in trail blazing solutions which can't be found on Stack Overflow; so we're looking for engineers who flourish working in a complex domain.

In your first six months, you will:


...start at Luno by learning our processes, meeting the wider team and starting our engineering on-boarding program. After getting comfortable with the basics, you'll start learning our idiomatic patterns in a safe, easy-to-follow way - by building your own toy micro services. You'll get to practice how we do design docs, code reviews, deployments, events, logging and monitoring.

You'll meet the Pod(s) you'll be working with and quickly align on the teams' current OKRs and product roadmap. We succeed as a team, so we will provide you with regular feedback from your manager and peers and will encourage you to do the same.

What you'll do:
Work closely with our data science and platform teams on projects introducing new streams of data into our data lake
You will get to bring new ideas on how to further develop and innovate our data solutions and how to expose that data to the business
Accountable and Responsible for the design and architecture of Data systems that are robust and scalable.
Work in an Agile/Scrum framework or Agile mindset
Data backup/recovery and storage
Pick-up and learn new concepts, in both engineering and product, and be able to apply that knowledge quickly.
The ideal candidate for this role will have:
7+ years' experience in maintaining scalable data solutions and/or you are passionate about it
Ability to understand, communicate and advocate between build vs buy
Proven track record of setting up, restructuring and maintenance of databases
You know your way around ETL and you have experience with SQL
Experience in the AWS Data stack (RedShift,DynamoDB, Amazon RDS)
Familiarity with integrating data stores with BI platforms such as Looker, Tableau, or Power BI
You have experience with the concepts of CI/CD
Coding skills in e.g. Go, Python
Bachelor's degree in a related field preferred
AWS Certified DataOps Administrator
Be friendly, transparent, articulate and driven to succeed
Basic knowledge of and passion for digital currencies like Bitcoin
A work permit for South Africa if you are not a South African citizen
Don't be put off if you don't tick all of the boxes – they're a guide based on what we'd love to see but we appreciate that excellent software engineers have diverse backgrounds.

Remote Life at Luno


If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity / paternity and even (yes, you are reading it correctly) paw-ternity for your furry friend..
Annual Inspiration Day.. like that pottery course you've always been meaning to do!
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. You'll need to hold the legal right to work in South Africa already as we cannot provide visa sponsorship.

Be part of the change!",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer - EC2 Capacity Data Analytics,-1,"EC2 Capacity Data Analytics (CDA) team is looking for a Data Engineer to join our team.

Our team is part of the EC2 Capacity Engineering organization, which is responsible for providing the elasticity EC2 customers need to scale up/down compute resources in a cost-efficient manner. We predict customer usage across thousands of configuration combinations to deliver exactly what our customers require in just the right amount of time with just the right amount of capacity.

As a Data Engineer, you will build the ETL and analytics solutions for our internal customers to answer questions with data and drive critical improvements for the business. You will use best practices in software engineering, data management, data storage, data compute, and distributed systems. On any given day, we use Python, Scala, Java, SQL, Lambda, CloudFormation, Redshift and Glue as well as other public AWS services and a host of Amazon internal tools. We dont expect you to be an expert in, or necessarily even be familiar with all of the technologies listed above, but we do expect you to be excited to learn about them.

This position involves on-call responsibilities, typically for one week every two months. Our team is dedicated to supporting new team members. We care about your career growth, we try to assign projects and tasks based on what will help each team member develop into a more well-rounded engineer and enable them to take on more complex tasks in the future.

Our team values work-life balance and we are flexible when people occasionally need to work from home.

Job Duties
Develop and maintain automated ETL pipelines for big data using languages such as Scala, Spark, SQL and AWS services such as S3, Glue, Lambda, SNS, SQS, KMS. Example: ETL jobs that process a continuous flow of JSON source files and output the data in a business-friendly Parquet format that can be efficiently queried via Redshift Spectrum using SQL to answer business question.

Develop and maintain automated ETL monitoring and alarming solutions using Java/Python/Scala, Spark, SQL, and AWS services such as CloudWatch and Lambda.

Implement and support reporting and analytics infrastructure for internal business customers using AWS, services such Athena, Redshift, Spectrum, EMR, and QuickSight.

Develop and maintain data security and permissions solutions for enterprise scale data warehouse and data lake implementations including data encryption and database user access controls and logging.

Develop and maintain data warehouse and data lake metadata, data catalog, and user documentation for internal business customers.

Develop, test, and deploy code using internal software development toolsets. This includes the code for deploying infrastructure and solutions for secure data storage, ETL pipelines, data catalog, and data query.


Basic Qualifications

· Bachelors degree in Computer Science or related technical field, or equivalent work experience.
· 4+ years of overall work experience including Software Engineering, Data Engineering, Database Engineering, Business Intelligence.
· Experience with AWS technologies stack including Lambda, Glue, Redshift, RDS, S3, EMR or similar big data solutions stack

Preferred Qualifications

· Demonstrate efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data.
· Demonstrable proficiency in distributed systems and data architecture; design and implementation of batch and stream data processing pipelines; knows how to optimize the distribution, partitioning, and MPP of high-level data structures.

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer,-1,"Our client based in Johannesburg is urgently looking for a Data Engineer to be on a 3 months contract
Build data pipelines, experience in new tech like nifi, kafka, python

Joburg based, open to EE, 3 month contract with the option to extend, must be available at short notice",-1,EQplus,Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Overview
Job ID: 51456
Job Sector: Information Technology and Services
Country: South Africa
Region/State/Province/District: Gauteng
Location: Johannesburg

Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose

This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes

Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems

Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions

Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.
Research and best practices

Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development

Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.

Preferred Qualification and Experience

Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry

Knowledge/Technical Skills/Expertise

Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision

PLEASE NOTE: All our recruitment and selection processes comply with applicable local laws and regulations. We will never ask for money or any form of payment as part of our recruitment process. If you experience this, please contact our Fraudline on +27 800222050 or forward to TransactionFraudOpsSA@standardbank.co.za",4.1,"Standard Bank
4.1",Johannesburg,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"About us

At PBT Group we pride ourselves on being a Data Specialist organisation. With 20 years of experience in 27 countries over 3 continents, our team of 550 consultants have implemented more than 700 projects.",4.3,"PBT Group
4.3",Johannesburg,-1,Unknown,-1,Company - Private,Accounting,Accounting & Legal,Less than $1 million (USD),-1
Data Engineer,-1,"Kick-start your career in the online gaming world and experience the very latest in technology and innovation.

The Department:

Our mission is to provide our customers with the best online betting experience and share the thrill of gaming with them. Data is at the very heart of our business and is vital in everything we do.

Our cross-functional Data team has a big and exciting challenge ahead. We are in the process of re-platforming our traditional, on-premises RDBMS environment to a new microservice architecture in the cloud. We’re making use of the diverse set of data technologies in Microsoft Azure to offer new services, reporting structures and real-time data pipeline while serving the day-to-day requirements of a rapidly growing, data-hungry organisation.

Purpose of the Role:

This is an excellent opportunity for an individual who is looking to gain new skills. We are committed to creating a culture of learning and regularly run proof of concepts, provide internal demos, manage workshops and attend external conferences. Our data team has a wide range of skills including development for highly transactional RDBMS systems, data warehousing, data science and cloud technologies and we are always working to raise everyone’s game.

Duties include, but not limited to:

Work as part of an agile Data Engineering Team
Development of greenfield projects in Azure
Develop and maintain on-premises RDBMS/DW systems
Create robust ETL services and real-time data pipelines
Build and maintain Continuous Integration and DevOps pipelines
Test-driven development and pair programming with colleagues

Essential Criteria:

C#, .Net, Visual Studio
Git, Azure DevOps
NoSQL development (CosmosDB)
Demonstrable understanding of MS SQL Server in a highly transactional environment
Demonstrable understanding of development in Microsoft Azure
Able to understand query plans and identify performance bottlenecks
Test/Business-Driven Development
Building Continuous Integration/Deployment pipelines
Communicate effectively with both technical and non-technical stakeholders

Desirable Criteria:

Implementing Data Storage and Processing solutions in Azure (ARM Templates, Storage Accounts, Data Lake Storage, SQL DB, Cosmos DB, EventHubs, Function Apps, Log Analytics, Data Factory, Databricks, Polybase)
Implementing Security, Disaster Recovery, High Availability, Auditing, Monitoring and Alerting solutions in Azure
Automating tasks in Azure using Powershell / CLI
Predicting costs and optimizing spending in Azure
Message Queues (RabbitMQ, Kafka)
Python

Person Specifications:

Resilience
Teamwork
Technical Knowledge
Communication skills
Stress Tolerance
Please note we will apply relevance to our Talent Management and Talent Development Programme as part of our recruitment process.
Shortlisted candidates may need to complete an assessment.
This position requires trust and honesty it has access to customers financial details - therefore a credit and criminal record check will be conducted. The qualifications identified herein are an inherent job requirement; therefore, a qualification verification check will be done. By applying for this role, and supplying the necessary details, you hereby grant us permission to apply for these checks. This will be done in a confidential manner, and solely for the purposes of verification.

To view all current vacancies, please visit our website, www.digioutsource.com

Should you not hear from us within 2 weeks, please deem your application as unsuccessful.

The perfect place to work, play and grow!",3.9,"Digital Outsource Services
3.9",Cape Town,-1,1001 to 5000 Employees,1997,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
Data Engineer,-1,"At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes

Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.

Key Responsibilities

Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.

Key Traits

Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern

Position Requirements

2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.

Where will you work? This role will be based out of Durbanville, South Africa.",3.1,"Aculocity, LLC
3.1",Durbanville,-1,1 to 50 Employees,2006,Company - Private,IT Services,Information Technology,$1 to $5 million (USD),-1
Data Engineer,-1,"ENVIRONMENT:

A rapidly growing E-Commerce Platform seeks a highly talented Data Engineer to make an invaluable contribution to data democratisation and literacy vision by making accessible and easy-to-use data products and tools. You will require a Comp-Sci Degree or 3 years’ relevant industry experience, MySQL, PostgreSQL, Java, Python, in-depth understanding of OLAP, Data Marts, Star Scheme, Snowflake, be familiar with Jenkins, Travis, Circle CI, Docker, Kubernetes, experience with Kafka, Pub/Sub, Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks & significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing & Data Lake design and implementation and Lambda/Kappa architectures.

DUTIES:

Design, develop, test and maintain data architecture.

Prepare data for descriptive, predictive and prescriptive modelling.

Automate repetitive tasks and manual processes related with the data usage.

Optimize data delivery.

Design, develop and test large stream data pipelines to ingest, aggregate, clean, and distribute data models ready for analysis.

Ensure the highest standard in data integrity.

Leverage best practices in continuous integration and delivery.

Collaborate with other engineers, ML experts, analysts, and stakeholders to produce the most efficient and valuable solutions.

Implement features, technology, and processes that move us towards industry best practices, improving on scalability, efficiency, reliability, and security.

Operations and ownership of systems in production, responding to incidents.

REQUIREMENTS:

Qualifications –

Comp-Sci Degree or 3 years relevant industry experience.

Experience/Skills –

Open source relational database systems e.g. MySQL, PostgreSQL, etc.

Significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing, and Data Lake design and implementation and Lambda/Kappa architectures.

A thorough understanding of database and data warehousing principles e.g. OLAP, Data Marts, Star Schema, Snowflake, etc.

Java and Python.

Familiar with CI/CD tools such as Jenkins, Travis, Circle CI, etc.

Experience with Kafka, Pub/Sub, or other event-based systems.

Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks, etc.

Working in cloud environments and with containerisation frameworks, tools and platforms e.g. Docker, Kubernetes, GKE, etc.

A deep understanding of data pipelining, streaming, and Big Data technologies, methods, patterns, and techniques.

Troubleshooting complex database operations and performance issues.

Automating tasks using Shell Scripting or writing small applications.

ATTRIBUTES:

Works well with people and is passionate about helping people be their best.

A team player, an active listener, mentor, and able to communicate well.

Shows solid reasoning and decision making, with the ability to work under pressure.

Is passionate about technology, systems and data.

Is curious, always learning, and keeping up to date with the industry.

While we would really like to respond to every application, should you not be contacted for this position within 10 working days please consider your application unsuccessful.

COMMENTS:

When applying for jobs, ensure that you have the minimum job requirements. Only SA Citizens will be considered for this role. If you are not in the mentioned location of any of the jobs, please note your relocation plans in all applications for jobs and correspondence.",-1,Datafin IT Recruitment,Cape Town,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Cartrack is looking for passionate data science and engineering candidates that can join a growing team that is responsible for the intelligence and efficiency solution provision to over a million subscribers, many of whom are large fleets. We are in the midst of creating revolutionary platforms that will change the way that people interact with their vehicles.

You will have the opportunity to work with the very brightest global subject matter experts that are transforming the automotive industry across Fleet Management, Asset Management and Insurance Telematics solutions.

Get to know the role:

The role of a data engineer is a supporting one, but it is also an extremely vital one. As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements. We want to see candidates with mechanical tendencies and a desire to know how things work and to improve them.

The day-to-day activities:

Design, construct, install, test and maintain data management systems.
Build high-performance algorithms, predictive models, and prototypes.
Ensure that all systems meet the business/company requirements as well as industry practices.
Integrate up-and-coming data management and software engineering technologies into existing data structures.
Develop set processes for data mining, data modeling, and data production.
Create custom software components and analytics applications.
Research new uses for existing data.
Employ an array of technological languages and tools to connect systems together.
Install/update disaster recovery procedures.
Recommend different ways to constantly improve data reliability and quality.
Work on and maintain Data pipelines.

Requirements Essential:

At least 5 years’ proven experience as a Data Engineer, DevOps Engineer, Software Developer, or similar.
Proficient in Linux/Unix and shell scripting as well as in functional programming languages.
Expertise in setting up and explored with technologies such as Hadoop and Spark.
Bachelor’s degree in computer science, software/computer engineering, applied mathematics, or physics.",3.3,"Cartrack
3.3",Johannesburg,-1,501 to 1000 Employees,2004,Company - Private,Security Services,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Data Engineer,-1,"Data Engineers build and support data pipelines and datamarts built off those pipelines. Both must be scalable, repeatable and secure. The Data Engineer helps to facilitate gathering data from a variety of different sources, in the correct format, assuring that it conforms to data quality standards and assuring that downstream users can get to that data timeously. This role functions as a core member of an agile team. These professionals are responsible for the infrastructure that provides insights from raw data, handling and integrating diverse sources of data seamlessly. They enable solutions, by handling large volumes of data in batch and real-time by leveraging emerging technologies from both the big data and cloud spaces. Additional responsibilities include developing proof of concepts and implements complex big data solutions with a focus on collecting, parsing, managing, analysing and visualising large datasets. They know how to apply technologies to solve the problems of working with large volumes of data in diverse formats to deliver innovative solutions. Data Engineering is a technical job that requires substantial expertise in a broad range of software development and programming fields. These professionals have a knowledge of data analysis, end user requirements and business requirements analysis to develop a clear understanding of the business need and to incorporate these needs into a technical solution. They have a solid understanding of physical database design and the systems development lifecycle. This role must work well in a team environment.

Job Objectives

Work Complexity: * Architects Data analytics framework. * Translates complex functional and technical requirements into detailed architecture, design, and high performing software. * Leads Data and batch/real-time analytical solutions leveraging transformational technologies. * Works on multiple projects as a technical lead driving user story analysis and elaboration, design and development of software applications, testing, and builds automation tools.

Main Job Objectives: 1. Development and Operations 2. Database Development and Operations 3. Policies, Standards and Procedures 4. Communications 5. Business Continuity & Disaster Recovery 6. Research and Evaluation 7. Coaching/ Mentoring

Qualifications

Essential: 4 years Bachelors degree in computer science, computer engineering, or equivalent work experience AWS Certification at least to associate level

Experience

Essential:

5+ years Data engineering or software engineering

3-5 years demonstrated experience leading teams of engineers

2+ years Big Data experience

5+ years experience with Extract Transform and Load (ETL) processes

2+ years Could AWS experience

At least 2 years demonstrated experience with agile or other rapid application development methods - Agile exposure, Kanban or Scrum

5 years demonstrated experience with object oriented design, coding and testing patterns as well as experience in engineering (commercial or open source) software platforms and large scale data infrastructures.

Desirable:

5+ years Retail Operations experience

Knowledge and Skills

Essential: *Creating data feeds from on-premise to AWS Cloud (2 years) *Support data feeds in production on break fix basis (2 years) *Creating data marts using Talend or similar ETL development tool (4 years) *Manipulating data using python and pyspark (2 years) *Processing data using the Hadoop paradigm particularly using EMR, AWSs distribution of Hadoop (2 years) *Devop for Big Data and Business Intelligence including automated testing and deployment (2 years) * Extensive knowledge in different programming or scripting languages * Expert knowledge of data modeling and understanding of different data structures and their benefits and limitations under particular use cases.

Further technical skills required: * Capability to architect highly scalable distributed systems, using different open source tools. * Big Data batch and streaming tools * Talend (1 year) * AWS: EMR, EC2, S3 (1 year) * Python (1 year) * PySpark or Spark (1 year) - Desirable * Business Intelligence Data modelling (3 years) * SQL (3 years)",-1,Datonomy Solutions,Brackenfell,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We are assisting one of our clients that is based in Pretoria to fill a role of a Data Engineer

This is a 12 month contract role

Objective of this Scope of Work

The Data Engineer will drive improvement of the data management maturity levels and provide the necessary technical support within the company to support reliable and effective decision-making, appropriate usage and protection thereof.

Scope of Services Definition

The scope will include but will not be limited to:

ï†· To develop, construct, test and maintain architectures.

ï†· To ensure architectures will support the requirements of business.

ï†· To discover opportunities for data acquisition and sharing.

ï†· To develop data set processes for data modelling, mining and production.

ï†· To employ a variety of languages and tools to marry systems together.

ï†· To recommend way to improve data reliability, efficiency and quality.

ï†· To prepare data for use in predictive and prescriptive modelling.

ï†· To conduct research to answer industry and business questions.

ï†· To leverage volumes of data from internal and external to answer business questions.

ï†· To develop and manage stakeholder relations effectively to promote data management across the organisation and support reliable decision making and appropriate data usage.

ï†· To participate and provide technical support in cross organisational activities relating to any of the above mentioned data management activities.

ï†· To provide regular progress reports as per stakeholder requirements and present data management updates in various forums as required.

Minimum qualification Required:

ï†· A minimum of a Bachelors degree in Computer Science or Information Management OR equivalent;

ï†· A minimum of five to eight years experience in a data management environment",-1,HR Genie,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Our client based in the Northern Suburbs, is currently looking for a Data Engineer to join their team.

Responsibilities
Our client is a dynamic IT company that delivers value-driven IT solutions to the group. Our work lives revolve around our DNA. We take pride in our work, treat our colleagues, partners and our country with respect. We exercise collaborative decision-making and believe in having a balance in life. We do this all while having fun and enjoying what we do.

The primary focus of this position is to use technical skills to put software, systems and data together in a way that extracts meaningful insights from raw data. You will need to be helpful and supportive to your team and fellow developers. You join an energetic, focused and dynamic team.

Interact with clients to understand requirements and business problems/needs

Identify, analyse, visualise and understand supporting data to propose solid solutions

Create technical documentation for reference and reporting

Support existing solutions within GCP and Oracle

Doing standby on a rotating basis

Key Competencies and Qualifications

Matric

Tertiary qualification in IT

Preferred cloud experience in AWS/AZURE/GCP

At least 3 years of data warehouse ETL experience

Dimensional Modelling

Data analyses

Experience with data visualization and visualization tool(s)

Knowledge of the retail industry will be beneficial

Understanding and experience with version control SVN/GIT

Preferred – Korn shell scripting, Python/Java, SQL

Google Cloud Platform experience would be looked upon favourably

Having a broad understanding of different SDLC’s

Preferred agile experience

Strengths

The natural tendency to take ownership and responsibility

Strong problem solving, critical thinking, effective planning and organisational skills

Detail-oriented with excellent communication skills

You have a can-do attitude and positive outlook on life

Can cope under pressure

Curious and interested in analysing problems and possible solutions

Strong team player

Self-driven learner, passionate about new technology

Above all, be passionate about what you do

Should you wish to apply for the position, please apply directly via this job board, please ensure that you quote reference number 201620 subject heading or email body.

Please note that due to the high volume of CV's received; only shortlisted applicants will be contacted. Should you not receive communication from our offices within two weeks of submission please note that your application will not be considered for this position.

We will keep your CV on file and re-establish contact with you should opportunities in line with your expertise become available again.

Should you require any additional information give us a call on 021 012 5566.",-1,Surgo HR & Training,Cape Town,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We believe that our employees fuel our organization, essential to enable us to help our customers overcome their business challenges and achieve sustainable growth. As a result, we are committed to growing each individual and providing them with the challenges, feedback and support needed to achieve success in their career

If this sounds appealing, and like us, you get excited about data: its collection, storage, transformation or display, see if you’ve got what it takes to join our sought after DATA team.

Key Responsibilities And/or Outputs

You will represent IQbusiness at our customers, sometimes alone, and sometimes as part of an IQ team.

Providing a superior customer experience by building and maintaining relationships, working at customer offices, keeping data confidential
Design and develop – databases, SQL queries, stored procedures, reports, dashboards or integration solutions
Produce solutions for both real-time and batch environments
Test your work to ensure compliance
Solve problems, and do root cause analysis
Prioritize your workload
Assist in other areas relating to your true data function, such as data modeling, data and business analysts
Interact with a variety of individuals: senior, junior, technical and from business
Provide guidance to fellow colleagues, or even manage a team
Uphold the IQ values, which are to care, learn & share; innovate; deliver as well as to build, enhance and maintain relationships

Education

Matric pass
A tertiary qualification, preferably in an ICT relevant field
Appropriate Microsoft certifications are beneficial but not required

Requirements

3 - 6 years experience in the Data Engineering environments and technologies
Great communication skills
A passion for SQL, databases or reports
Can you write stored procedures, design complex queries and create views and triggers?
Are you able to work out the relationships in a data warehouse or the aggregation of a cube?
Do you extract and display useful information when you see patterns and trends in data?
Strong knowledge of the financial services industry, ideally in a consulting role
The use of data related software: databases, ETL and BI tools; report writing and analytical tools
We use a lot of Microsoft products. You may often be expected to use MS SQL Server, SSIS, SSRS, SSAS and Power BI to develop solutions
What other relevant software have you’ve used?
Ability to work in different project methodologies: Waterfall and/or Agile
Knowledge of full SDLC
Exposure to logical and physical data modeling

Equal Employment Opportunity

IQbusiness is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, citizenship, marital, domestic or civil partnership status, sexual orientation, or gender identity",3.7,"IQbusiness South Africa
3.7",Johannesburg,-1,1 to 50 Employees,-1,Company - Private,Consulting,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"We value a data engineer as someone who works behind the scenes to obtain, process and supply data via various methodologies and technologies, to various consumers, in ways and forms that makes sense and add value. This definition is very broad, as the field of data engineering is just as broad.

You may be the type of data engineer that develops API endpoints for the consumption of data by end users or even another data pipeline, or you may be the type of data engineer that develops highly distributed, high availability data processing pipelines in an effort to satisfy the need of the ever questioning data analysts and/or data scientists.

You have awesome knowledge about the following concepts
Data modelling
Relational data modelling in traditional relational database management systems. (Microsoft SQL Server, MySQL, PostgreSQL, etc)
Coercing unstructured and semi-structured data into a structured form.
Data pipelining knowledge - data extraction and transformation.
Data transformation knowledge for reporting and analytics purposes.
Knowledge of the MapReduce and related data processing paradigms would be a boon.
You have the following technical competencies
Writing SQL queries, that can relate, transform and aggregate data from many differing sources where natural keys may or may not exist.
Experience with writing data pipelines that move and transform data, for various uses.
Working knowledge of a general purpose programming language like Python would be a boost.
Working knowledge of columnar databases such as Google BigQuery, and SAP HANA would be a boost.
Working knowledge of highly distributed technologies such as Apache Hadoop or Apache Spark would be a boost.
Working knowledge of NoSQL technologies, such as Apache Solr would be a boost.
You have the following personal competencies
The ability to solve problems.
The ability to rotate around a problem, to see if solutions can be gained in different ways.
The ability to work in an ever changing, unstructured environment.
The ability to work as part of a team, with vastly differing skill sets and opinions.
The ability to contribute ideas to the quorum.
The ability to mentor and provide guidance for other team members.
A systems approach to thinking, as opposed to a siloed approach. The candidate needs to understand how their work affects the greater system.
The ability to work without supervision, and take accountability for the work they deliver.
The ability to liaise with a client, sifting through the fluff and extracting the actual requirements.
If this is you - apply now and we'll get in touch",-1,DotModus,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Data Engineer

Our client in the contact centre space is currently seeking a DATA ENGINEER that will work on the collecting, storing, processing, and analyzing of large datasets. The primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them. You will also be responsible for integrating them with the architecture used across the company.

Key Performance Areas:

Data reporting.
Implementing ETL processes.
Defining data retention policies.
Management of Customer Lead data.
Provision of data for advanced analytics.
Maintenance of internal client scorecards.
Assist team in resolving data-related support queries.
Optimize existing data processes through automation.
Assist with all data-related reporting and documentation.
Maintenance and optimisation of the Analytics database.
Provide technical support to and supervision of junior data administrators.
Continuous upskilling on new technologies, frameworks and market trends.
Monitoring performance and advising any necessary infrastructure changes.
Identifying, selecting and integrating any Big Data tools and frameworks required to provide real-time analytics.

Educational Requirements

IT related Degree or Diploma is a pre-requisite

Required Skills/Experience

ETL tools: Advanced SSIS
BI/Reporting : Qlikview/Power BI/ SSRS or SSAS
Programming languages: JAVA, C# , Python, SAS or R
Experience with NoSQL databases and/or campaign management tools will be advantageous.
Minimum 3 years’ applicable work experience in SQL, relational databases and data manipulation.
Experience in big data platforms (eg. Hadoop) or processing frameworks (eg. MapReduce/Spark) and querying tools (eg. Pig, Hive and Impala) will be highly beneficial.

Preferred Skills

Organizational skills
Experience in Attentional to detail.
Accountability is critical for this role.
Ability to work under pressure and meet deadlines.
Solid understanding of database design principles.
Should you not receive a response in 2 weeks please consider your application unsuccessful",-1,Rubik's Cubed Consulting,Durban,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"This well known company is looking for a Data Engineer. will be based in Rivonia
The ideal candidate will have strong experience in the following:
Data cleaning
SQL Export
Big data Sets

BSc Degree in Maths and Stats will be required
a min of 3 years experience.
Stable track record is required.

Send your Cv to marinda@prrrecruitment.co.za",-1,PRR Recruitment Services,Johannesburg,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Description

Position at Aculocity, LLC

At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes
Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.
Key Responsibilities
Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.
Key Traits
Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern
Position Requirements
2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.
Where will you work? This role will be based out of Durbanville, South Africa.",-1,GVW,Durbanville,-1,Unknown,-1,Unknown,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Information Technology, Gauteng JHB - Northern Suburbs

Market related - Market related Annually

An IT Consultancy Business based in Johannesburg is currently looking for a Business Intelligence Consultant / Data Engineering Consultant.

Requirements:

Extensive experience in data engineering
Experience in Business Intelligence, data and Power BI
Extensive experience in data governance and the Popi act
Ability to assess and make recommendations on data within the Popi act
Good understanding of T-SQL and query optimization, developing ETL strategies.
Good understanding with SQL Server 2008/2012, SSIS, SSRS and SSAS
Use SSIS to create ETL packages to validate, extract, transform, and load data into the data warehouse and data marts.
Deploy and configured the reports in the Report Server (SSRS).
Excellent experience in Tabular Modelling , PowerView, Qlikvie,w, and Power BI
Maintain ETL
Qlikview model
Create Drill-through, Drill-down, and Cross Tab Reports and Sub-Report using Report Definition Language (RDL).
Generate periodic reports based on the statistical analysis of the data using SQL Server Reporting Services (SSRS)
Advise and provide written technical documentation and recommendations

The information displayed above is not limited to advertisements. Please contact Thato for further information.

Please consider your application as unsuccessful if you have not received a response within 14 days of submitting your application. However, please keep a lookout on our website, www.bedifferent.co.za, for available positions that you may be suited for

Ad Visible Until: 29 October 2020
Ref: JHB005346/NL

Vacancy Type: Permanent",2.9,"Be Different Recruitment
2.9",Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Cloud Support Engineer (Big Data),-1,"ABOUT US

Amazon Web Services is the market leader and technology forerunner in the Cloud business. As a member of the AWS Support team you will be at the forefront of this transformational technology, assisting a global list of companies and developers that are taking advantage of a growing set of services and features to run their mission-critical applications. As a Cloud Support Engineer, you will act as the Cloud Ambassador across all the cloud products, arming our customers with required tools & tactics to get the most out of their Product and Support investment.

Would you like to use the latest cloud computing technologies? Do you have an interest in helping customers understand application architectures and integration approaches? Are you familiar with best practices for applications, servers and networks? Do you want to be part of a customer facing technology team helping to ensure the success of Amazon Web Services (AWS) as a leading technology organization?

If you fit the description, you might be the person we are looking for! We are a group of smart people, passionate about cloud computing, and believe that world class support is critical to customer success.

WHAT CAN YOU EXPECT FROM A LIFE AT AWS?

Every day will bring new and exciting challenges on the job while you:

· Learn and use groundbreaking technologies.
· Apply advanced troubleshooting techniques to provide unique solutions to our customers' individual needs.
· Interact with leading engineers around the world.
· Partner with Amazon Web Services teams to help reproduce and resolve customer issues.
· Leverage your extensive customer support experience to provide feedback to internal AWS teams on how to improve our services.
· Drive customer communication during critical events.
· Drive projects that improve support-related processes and our customers technical support experience.
· Write tutorials, how-to videos, and other technical articles for the developer community.
· Work on critical, highly complex customer problems that may span multiple AWS services.

WHY AWS SUPPORT?

· First and foremost this is a customer support role in The Cloud.
· On a typical day, a Support Engineer will be primarily responsible for solving customers cases through a variety of customer contact channels which include telephone, email, and web/live chat. You will apply advanced troubleshooting techniques to provide tailored solutions for our customers and drive customer interactions by thoughtfully working with customers to dive deep into the root cause of an issue.
· Apart from working on a broad spectrum of technical issues, an AWS Support Engineer may also coach/mentor new hires, develop & present training, partner with development teams on complex issues or contact deflection initiatives, participate in new hiring, write tools/script to help the team, or work with leadership on process improvement and strategic initiatives.
· Career development: We promote advancement opportunities across the organization to help you meet your career goals.
· Training: We have training programs to help you develop the skills required to be successful in your role.
· We hire smart people who are keen to build a career with AWS, so we are more interested in the areas that you do know instead of those you havent been exposed to yet.
· Support engineers interested in travel have presented training or participated in focused summits across our sites or at specific AWS events.
· As we operate on a follow-the-sun model, with Premium Support sites located globally, there is no after hours on-call or mandated overtime in this role.
· https://www.youtube.com/watch?v=GC3bWcFFZTo&t=24s



Basic Qualifications

The Big Data role supports our services that leverage data and produce business insights, which may include using Machine Learning/Artificial Intelligence (ML/AI). Helping our customers use and integrate Big Data services in what is arguably our industrys most exciting space. The portfolio of services covers EMR (Hadoop), DynamoDB (NoSQL), MangoDB, and Apache Cassandra.

· Advanced experience in Apache Hadoop, Apache Spark, Apache Hive, and Presto
· Advanced experience in DynamoDB or NoSQL technologies like MongoDB or Cassandra
· Advanced experience with System Administration with Linux (RHEL/CentOS) including Microsoft Active Directory, and LDAP integration.
· Experience with troubleshooting Kerberos Authentication problems.
· Experience with Network troubleshooting.
· Basic understanding of Machine Learning and statistics
· Experience with Java and Python and shell scripting
· Bachelors degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position



Preferred Qualifications

· Expert experience in the Hadoop Ecosystem including Apache Spark and Presto
· Expert experience in NoSQL
· Expert experience with blockchain technologies like Etherium Expert experience in data Data Lake architecture and administration
· Experience managing full application stacks from the OS up through custom applications
· Prior work experience with AWS - any or all of EC2, VPC, S3, RDS, EMR, Glue, SageMaker
· Excellent knowledge of Hadoop architecture, administration and support
· Expert understanding of distributed computing principles and their application in the cloud
· Good understanding of distributed computing environments Lead technical discussions on big data systems architecture and design
· Strong analysis and troubleshooting skills and experience
· AWS Certified Solutions Architect
· AWS certified Big Data Specialty
· Masters degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity and Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Response Center Engineer,-1,"Job Title
Response Center Engineer
Job Description


Philips is a world leading health technology company with a vision to make life better for people worldwide through meaningful innovation. Making good on this promise depends on our passionate, inspirational, collaborative and diverse team. We have over 80,000+ brilliant people around the world but are always looking for more. Like-minded, motivated, focused minds to join us in creating a healthier, more connected society while transforming themselves personally and professionally.

As a CCC Coordinator - Response Center Engineer you will have the opportunity to process customer calls and be responsible for screening and diagnosing professionally Healthcare equipment to support customers and colleagues remotely with solving technical issues and ensuring maximum customer satisfaction

You are responsible for:
Diagnose healthcare equipment to the quality standards set by Philips Healthcare (PH) remotely by interviewing customers or colleagues by telephone or by remotely logging in to the system
Advise Customer Care Center Coordinators and District Operations Managers and / or Team Leads about the best follow-up w.r.t. technical state of the diagnosed healthcare equipment
Advise the Customer Care Center Coordinators or Field Services Engineers about required spare parts and resources
Responsible for planning engineers related to Modality responsibility.
Responsible for coordination between CCC, CUSTOMER, Spare parts AND Engineer.
Responsible to drive Remote and FTR KPI’s to targets respectively 40% and 85%.
Will require minimal field work to keep abreast of technical capabilities.
Take calls from customers and make sure they are processed in the CCC ERP on timely manner including all relevant data
Support Field Services Engineers in the field with technical knowledge
Escalate technical issues to the Technical Support Specialist
Escalate technical issues to Business Unit support after consultation of the Technical Support Specialist
Monitor critical functions of the equipment’s in the IB and environmental conditions including RSN and True reachability.
Lead the planning and implementation of FSN’s and FCO’s accelerating remote implementation where applicable.
Submit timely and accurate service data, job sheets, reports, expense claims, radiation film badges, field problem reports and other paperwork as assigned
Keep abreast of new technologies likely to affect PH range of products
Use company property with care to ensure optimal results with minimal operational costs
Be a professional representative for PH with respect to customer problems, ensuring personal acceptability by the customer in behavior in accordance with PH policy and targets
Conform to PH safety standards including health and safety regulations and in the event of hazards or accidents to take immediate control of the situation and involve the Operations Manager and / or the responsible person to handle properly confidential issues according Philips standards and to act according General Business Principals
Follow all quality standards within the frame of valid PH business policies
Follow the company quality regulations (ISO 9001; PQA; TQM) and internal directives and procedures
You are a part of the dynamic South Africa Customer Care Centre Team .You will be reporting to the Customer Care Center Manager.

Requires a pleasant, assertive individual you can work very well in a team setting, a dynamic environment that requires flexibility and creativeness to achieve goals.

To succeed in this role, you should have the following skills and experience:
Degree level education or equivalent
Experience in maintenance and troubleshooting of technical complex systems
Fluent in English, verbal and written in addition to local language
In return, we offer you the unique combination of a critical and challenging role and a creative and empowering office environment. You will be actively encouraged to make improvements, establish best in class service and have a direct impact on the success of Philips on a daily basis.

Employment Equity

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply. Only apply for this role if you are a South African Citizen by birth or Naturalization prior to the 27 April 1994.

Why should you join Philips?

Working at Philips is more than a job. It’s a calling to create a healthier society through meaningful work, focused on improving 3 billion lives a year by delivering innovative solutions across the health continuum. Our people experience a variety of unexpected moments when their lives and careers come together in meaningful ways. Learn more by watching this video.

To find out more about what it’s like working for Philips at a personal level, visit the Working at Philips page on our career website, where you can read stories from our employee blog. Once there, you can also learn about our recruitment process, or find answers to some of the frequently asked questions.

Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.9,"Philips
3.9",Johannesburg,-1,10000+ Employees,1891,Company - Public,Health Care Services & Hospitals,Health Care,$10 to $25 million (USD),-1
Software Development Engineer - EC2 Placement,-1,"Build the systems that optimize how EC2 matches requests for Instances with the underlying compute capacity. EC2 Placement is seeking talented engineers to build the online and offline optimization systems for compute workload scheduling, and the customer capabilities to better manage those workloads. Amazon EC2 provides on-demand scalable compute capacity, and powers some of the largest services in the world. You will collaborate with a top-tier community of engineers to build systems to improve how customers are able to access EC2 compute resources.

The successful candidate will have strong software engineering experience, with a passion for thinking about, building and testing distributed systems. You have an interest in how Machine Learning and other optimization techniques can be applied to large-scale problems. You have demonstrated experience working with a team to design, build and operate large-scale systems. With strong engineering fundamentals, an analytical and data-driven approach to your work, and strong communication skills, you have the ability to collaborate well to deliver results. We move fast and work together on small teams to solve big problems.

If this opportunity sounds interesting, we would love to talk to you more about our work and the vibrant culture at AWS in Cape Town.

Basic Qualifications

· Degree in Computer Science or related field, or equivalent working experience
· 3+ years of industry experience in a software development environment
· Strong Computer Science fundamentals, including data structures, object-oriented design, algorithm design, problem solving, and complexity analysis.
· Proficiency in at least one modern programming language, such as Java, C#, Python, Scala, Kotlin

Preferred Qualifications

One or more of the following help you stand out:
· Demonstrated results designing, building and operating high-performance distributed systems in large-scale Linux environments
· Role model in writing high-quality, maintainable and secure code, mentoring others, and helping teams sharpen their development processes
· Ability to work effectively across teams to deliver results, with strong verbal and written communication skills
· Experience working with machine learning systems

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer - PBB IT,-1,"Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose


This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes
Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems
Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions
Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.

Research and best practices
Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development
Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.
Preferred Qualification and Experience
Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Aws Data Platform Engineer,-1,"Aws Data Platform Engineer

Posting Country:

South Africa

Date Posted:

15-Oct-2020

Full Time / Part Time:

Full Time

Contract Type:

Permanent

Joining Vodacom is more than a job, what we do matters. We don’t just carry minutes, texts and data – we carry people’s lives. And that’s a huge responsibility. If you think for a minute about the people you rely on…the likelihood is they rely on us.

Customers are at the heart of everything we do and we want to make a difference to the lives of our customers, and the communities in which we live and work. We support our people to give something back to the causes that mean the most to them through helping them give time and money to the charities they love.

And what’s it like to work here? We have created an environment where you can look forward to coming to work and are empowered to be at your best. We offer flexibility in how you work that helps you do your job in a way that suits you, opportunities to help you grow and progress throughout your career and a choice of benefits to suit your lifestyle.

Role Purpose
The H Band AWS Data Platform Engineer position is based within the Technology Business Unit.

The AWS Data Platform Engineer will be responsible for all Database services such as RDS, DynamoDB, etc. Should be able to migrate any databases from anywhere to AWS using any third-party tools or AWS database migration tool. Should also have understanding or expertise in creating data warehouses and data lake solutions on AWS.
Your responsibilities will include:
Apply practical knowledge of relational database design and usage with customers
Perform workload analysis and undertake performance tuning, as well as performance benchmarking in customer environments.
To develop state of the art solutions which are technically sound.
To provide a high-quality service to the Enterprise Cloud Services clients i.t.o. consultancy, solutions and delivery.
Commitment to team success and positive team dynamics including mentoring of other team members.
Passion for growing and applying technical skills in service to customers.
Be a trusted infrastructure advisor by providing objective, practical and relevant ideas, insights and advice.
Work collaboratively with consulting partners and technology teams to ensure high quality of solution delivery.
Encourage best practice and knowledge sharing with partners and cross-functional groups
Manage the overall database design and delivery of solutions.
Ability to make recommendations as they pertain to improvements in support/development initiatives and facilitate implementation with partners and cross-functional groups within the Business.
Participate in high level database solution definition and design during the implementation phase with the goal of providing reliable, stable and operationally sound applications that meet the Business requirements.
Ability to understand and translate business requirements into technical specifications
The ideal candidate will have:
A minimum of 3 years of industry related experience of which 1 year must be within a complex hosting environment.
Certifications in Database design, system architecture or cloud technologies.
Demonstrate knowledge of database systems internals including storage layouts and distributed databases/MPP architectures
Advanced SQL coding, tuning and query optimization.
Experience designing and leading database performance benchmarks.
Good knowledge of the different AWS services
Knowledge of cloud networking architecture, cloud operations, security, automation and orchestration.
Knowledge of database internals as it relates to query and system performance and tuning.
Understanding of overall system architecture, scalability, reliability, and performance in a database environment.
Excellent teamwork, time-management and organizational skills.
Perform other duties as deemed necessary and assigned by the customer and management
Strong interpersonal skills and problem-solving abilities.
Excellent documentation, communication and interpersonal skills.
Excellent analytical and problem-solving abilities.
Closing date for applications: Monday, 13 April 2020

The base location for this role is Vodacom World, Midrand

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply.
Vodacom is committed to an organisational culture that recognises, appreciates and values diversity & inclusion.

Commitment from Vodacom

Vodacom is committed to attracting, developing and retaining the very best people by offering a flexible, motivating and inclusive workplace in which talent is truly recognized, developed and rewarded. We believe that diversity plays an important role in the success of our business and we are committed to creating an inclusive work environment which respects, values, celebrates and makes the most of people’s individual differences - we are not only multinational but multicultural too. At Vodacom you will have access to our excellent flexible benefits programme that you would expect from any global company.",3.9,"Vodafone
3.9",Midrand,-1,10000+ Employees,1982,Company - Public,"Cable, Internet & Telephone Providers",Telecommunications,$10+ billion (USD),-1
Data Engineer Azure Data Factory,-1,"Enthuzex is looking for a motivated Lead Data Engineer to contribute towards the success of our Data and Analytics Technology initiatives. This is a hands-on technical role and this person will be responsible for the development and build of scalable solutions as it relates to the architecture strategies, data standards, digital data management, data integration, tools, and technology. The right candidate will play a deep dive hands-on critical development role in the digital transformation and in shaping how we acquire, ingest, transform and deliver data through the digital consumer channels.

Responsibilities:

Architect, design, develop and engineering end-to-end data pipelines across multiple data sources and systems of record.
Ensure data quality, integrity, security and completeness throughout the data lifecycle
Develop, design data models, data structures and ETL jobs for data acquisition and manipulation purposes
Develop deep understanding of the data sources, implement data standards, maintain data quality and master data management
Developing data services and API
Work closely with the cloud service providers to ensure completeness and alignment with the service offerings
Manage and maintain cloud based data and analytics platform
Deep understanding of the cloud offerings and engage in quick proof of concepts and proof of value in prototyping data and analytics solutions and derive viability
Ability to interact with the business stakeholders to understand requirements and translating into technology solutions

Expirience:

Experience in Cloud platform AWS or Azure eco-system. (Azure preferred)
Data Engineering/Development experience with SQL (Oracle, SQL Server, MySQL)
Strong development background creating pipelines and complex data transformations and manipulations using one of the languages Python, Java, R, or Scala with Databricks/Spark
Experience in NoSQL Databases and Big data technologies including Hadoop
Experience with API / RESTful data services
Worked on real-time data capture, processing and storing using technologies like Azure Event Hubs and Analytics
Experience working with different data storage options including AWS S3, Azure BLOB storage etc.
Understanding of different data formats including Parquet, Avro, CSV, ORC etc.
Prior experience with MPP databases and maintain large amount of data processing
Experience with Azure Data Factory and Azure Data Catalog is a big plus and mandatory
Experience with Microsoft/Azure ETL solutions and business Intelligence technologies is a big and mandatory
Past working experience on a fast paced and agile environment
Perform ongoing monitoring, automation and refinement of data engineering solutions
Experience in leading high visibility transformation projects that interacts with multiple business lines
Build and meet project timelines and manage delivery commitments with proper communication to management

Qualifications

Bachelor’s degree with 4+ years of relevant experience
Willingness to learn new technologies and thrive in an extremely fast paced environment
Team player and easy to work with.

Applicants must demonstrate their ability to master new enterprise level technologies. Successful applicants will exemplify Enthuzex ethical principles of uncompromising integrity, respect for others, and accountability for decisions

send cv's info@enthuzex.co.za",-1,Enthuzex,Leslie,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Scientist,-1,"The world is changing.

We all want something different.

At Luno, we see you as an individual.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the world, and to do so, we need the best team on board for our mission.

A bit about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 3 million customers across 40 countries.
We are Series B funded, backed by Balderton Capital and the Naspers Group.
Our platform has processed over 8 billion dollars since we've launched
We're proud to be one of the world's most international cryptocurrency teams from 26 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
The role in a nutshell:

Identifying opportunities in the business that could benefit most from cognitive applications, as well as building and enhancing organisational capabilities for deriving value from multiple data sources using data science.

What we'd like you to have:
Bachelor's degree or higher in the natural sciences or technical fields such as Mathematics, Statistics, Computer Science, Engineering or Economics
Enthusiasm to work in the cryptocurrencies space
Advanced SQL skills
Solid understanding of exploratory data analysis, predictive analytics, and optimisation using Python, R, Matlab, RapidMiner, KNIME or other data science-oriented platforms
Proficiency in the use of data science and machine learning domain-specific languages such as ""Caret"" and the ""Tidyverse"" suite of tools in R, or ""Pandas"" in Python
Strong interpersonal and communication skills
Communicating data insights using storytelling narratives
Ability to work independently, as well as within and across teams
Ability to successfully complete projects with large and/or incomplete data sets
More about what you'll be doing:
Optimising product performance by tracking and analysing customer behaviour on web and app, in collaboration with software engineers and product designers
Providing the business with reports and dashboards, on key performance metrics
Developing metrics to accurately assess the health of our Exchange platform
Comparative data-driven analysis of our Exchange against alternative platforms
Formulating business requirements into analytical objectives
Designing and running experiments to test hypotheses
Hacking through complex business problems using advanced data analysis to provide insights and recommendations
Building, maintaining, and optimising decisioning systems using advanced statistical and predictive modelling techniques
What will set you apart:
An advanced degree in Mathematics, Statistics, Computer Science or related field
At least 3 years' experience working in a similar role
A basic understanding of trading in financial markets
Experience working with a data analytics and visualisation platform such as Tableau, Cognos, QlikView, or Looker
Familiarity with using Google Analytics to understand customer behaviour
Solid knowledge of statistical and machine learning techniques
Familiarity with modern distributed data storage and processing systems such as Amazon Redshift, Big Query, Snowflake, Databricks and Apache Spark
You can gather and synthesise facts, theories, trends, patterns, inferences, and key issues in complex and variable situations
Ability to diagnose problems using formal problem-solving tools and techniques from multiple angles to generate multiple possible solutions
A sense of anticipating long-term problem areas and associated risk levels with objective rationale
Remote Life at Luno

If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
You'll be able to continuously upskill yourself with access to free online learning via MyAcademy, an international teaching marketplace with over 100000 courses from Harvard and other leading providers + share knowledge with your peers.
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity and paternity leave, and you can even take paw-ternity leave for your furry friend.
Annual Inspiration Day! Make time for that pottery course or spa day you've always wanted to do.
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"EY is a global leader in
assurance, tax, transaction and advisory services. Technology is at the heart
of what we do and deliver at EY. Technology solutions are integrated in the
client services we deliver and are key to our innovation as an organization.

Fueled by
strategic investment in technology and innovation, Client Technology seeks to
drive growth opportunities and solve complex business problems for our clients
through building a robust platform for business and powerful product engine
that are vital to innovation at scale. As part of Client Technology, you’ll
work with technologists and business experts, blending EY’s deep industry
knowledge and innovative ideas with our platforms, capabilities, and technical
expertise. As a catalyst for change and growth, you’ll be at the forefront of
integrating emerging technologies from AI to Data Analytics into every corner
of what we do at EY. That means more growth for you, exciting learning
opportunities, career choices, and the chance to make a real impact.

The selected
candidate
Develops
large and complex data architecture, composed of models, policies, rules or
standards that govern which data is collected and how it is stored, arranged,
integrated and put to use in data systems, including the design, build and
management of data infrastructure to address business requirements
Creates
sound use case driven roadmaps, depicting data architecture as-is and to-be
capabilities with the business by engaging with multidisciplinary teams, and by
identifying, managing and mitigating risk
Develops
relationships across the business to understand data requirements, applies deep
technical knowledge of data management to solve business problems in areas
where solutions may not currently exist, necessitating new solutions/ways of
working/technologies and proactively articulating these to the business
Review,
identify the latest emerging technologies, augmenting by services from the
leading cloud providers to solution and recommend the best next generation data
platform value driven approach for our clients
Your Key Responsibilities Include
Create
and maintain conceptual, logical and physical database models
Document
functional requirements and system specifications into the data architecture
and detailed design specifications for current and proposed designs
Document
and adhere to development standards and best practices in database designs
Maintain
highly effective and consistent communication within the team, peers, and the
leadership team
Reverse
engineer SQL code and modify it to solve problems/issues
Contribute
to the definition and implementation of data governance practices
Design
both data structures and data integration practices
Work
closely with the infrastructure teams to create a physical environment to
support data services
Evaluate
new and existing (internal and external) technologies and services in support
of data services and data analytics objectives
Skills And Attributes For Success
Understanding
of business process reengineering and business modeling concepts, business
systems development and analysis
Hands-on
experience in designing and implementing hybrid cloud and on-prem solutions
Experience
working with the latest versions of SQL Server
Experience
applying SAFe/Scrum/Kanban methodologies
Ability
to exercise judgment in solving technical, operational, and organizational
challenges
Expert
programming, performance tuning and troubleshooting skills, using the latest
popular programming languages for example python
Demonstrate
proactive approach to identifying issues and presenting solutions and options,
and where appropriate, leading to resolution
Minimum Qualifications
5+ years
demonstratable work experience as a Data Architect using data modeling tools
2-3 years
SQL coding experience on large projects
Must
possess expert SQL programming, performance tuning and troubleshooting skills
Create
database objects and SQL scripts
Understand
and developed data pipelines
Know how
to deformalize data for data science models
Experience
in python, spark and notebooks
Experience
designing data warehousing solutions
Experience
designing next generation data platforms utilising cloud services
In-depth
understanding of database structure principles
Seamlessly
able to translate business requirements to technology requirements
What We Look For
Strong
analytical skills and problem-solving ability
A
self-starter, independent-thinker, curious and creative person with ambition
and passion
Excellent
inter-personal, communication, collaboration, and presentation skills
Customer
focused
Excellent
time management skills
Positive
and constructive minded
Takes
responsibility for continuous self-learning
Takes the
lead and makes decisions in critical times and tough circumstances
Attention
to detail
High
levels of integrity and honesty
Curious
about new emerging technology
About EY
As a global leader in assurance, tax, transaction and consulting
services, we’re using the finance products, expertise and systems we’ve
developed to build a better working world. That starts with a culture that
believes in giving you the training, opportunities and creative freedom to make
things better. Whenever you join, however long you stay, the exceptional EY
experience lasts a lifetime.",3.8,"EY
3.8",Johannesburg,-1,10000+ Employees,1989,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Architect - Principal,-1,"We are looking for Principle Data Architect to join our Engineering team in Cape Town.

The world is changing.
We all want something different.
At Luno, we see you as individuals.

Together, we are upgrading the world of work to unleash the potential within and empower you to become the best possible version of yourself.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the financial landscape, and to do so, well we need the best team on board for our mission. In short, to achieve our goals, we need rockstars. As simple as that.

A little about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 5 million customers across 40 countries.
We're part of the Digital Currency Group, a group of companies driving progress in the cryptocurrency and blockchain space that includes Grayscale, Genesis, Coindesk and Foundry Services
Our platform has processed over $8 billion to date
We're proud to be one of the world's most international cryptocurrency teams from 43 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
How we work


Our engineering team (currently ~100 engineers) is split into organisations which we call Fleets. Each Fleet focuses on a core customer journey (onboarding, security, payments, support, new business, growth and marketing etc.). Each of these fleets contains multiple smaller teams called Pods, each of which focuses on a specific aspect of the product.

Pods will include a product owner, product designer, back-end engineers, Android, iOS and Web developers, who each bring a unique perspective to the problem you are all contributing towards.

We're agile, use scrum, continuous integration and continuous delivery, deploying to production every single day.

We're building teams to help us succeed in our mission to upgrade the world to a better financial system. You'll be joining a group of highly motivated software engineers who you'll work collaboratively with across our pods.

As a fast-growing company with offices around the world, you'll immediately see how your contributions directly impact both our internal users and client experience. Many of the problems we are solving result in trail blazing solutions which can't be found on Stack Overflow; so we're looking for engineers who flourish working in a complex domain.

In your first six months, you will:


...start at Luno by learning our processes, meeting the wider team and starting our engineering on-boarding program. After getting comfortable with the basics, you'll start learning our idiomatic patterns in a safe, easy-to-follow way - by building your own toy micro services. You'll get to practice how we do design docs, code reviews, deployments, events, logging and monitoring.

You'll meet the Pod(s) you'll be working with and quickly align on the teams' current OKRs and product roadmap. We succeed as a team, so we will provide you with regular feedback from your manager and peers and will encourage you to do the same.

What you'll do:
Work closely with our data science and platform teams on projects introducing new streams of data into our data lake
You will get to bring new ideas on how to further develop and innovate our data solutions and how to expose that data to the business
Accountable and Responsible for the design and architecture of Data systems that are robust and scalable.
Work in an Agile/Scrum framework or Agile mindset
Data backup/recovery and storage
Pick-up and learn new concepts, in both engineering and product, and be able to apply that knowledge quickly.
The ideal candidate for this role will have:
7+ years' experience in maintaining scalable data solutions and/or you are passionate about it
Ability to understand, communicate and advocate between build vs buy
Proven track record of setting up, restructuring and maintenance of databases
You know your way around ETL and you have experience with SQL
Experience in the AWS Data stack (RedShift,DynamoDB, Amazon RDS)
Familiarity with integrating data stores with BI platforms such as Looker, Tableau, or Power BI
You have experience with the concepts of CI/CD
Coding skills in e.g. Go, Python
Bachelor's degree in a related field preferred
AWS Certified DataOps Administrator
Be friendly, transparent, articulate and driven to succeed
Basic knowledge of and passion for digital currencies like Bitcoin
A work permit for South Africa if you are not a South African citizen
Don't be put off if you don't tick all of the boxes – they're a guide based on what we'd love to see but we appreciate that excellent software engineers have diverse backgrounds.

Remote Life at Luno


If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity / paternity and even (yes, you are reading it correctly) paw-ternity for your furry friend..
Annual Inspiration Day.. like that pottery course you've always been meaning to do!
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. You'll need to hold the legal right to work in South Africa already as we cannot provide visa sponsorship.

Be part of the change!",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer - EC2 Capacity Data Analytics,-1,"EC2 Capacity Data Analytics (CDA) team is looking for a Data Engineer to join our team.

Our team is part of the EC2 Capacity Engineering organization, which is responsible for providing the elasticity EC2 customers need to scale up/down compute resources in a cost-efficient manner. We predict customer usage across thousands of configuration combinations to deliver exactly what our customers require in just the right amount of time with just the right amount of capacity.

As a Data Engineer, you will build the ETL and analytics solutions for our internal customers to answer questions with data and drive critical improvements for the business. You will use best practices in software engineering, data management, data storage, data compute, and distributed systems. On any given day, we use Python, Scala, Java, SQL, Lambda, CloudFormation, Redshift and Glue as well as other public AWS services and a host of Amazon internal tools. We dont expect you to be an expert in, or necessarily even be familiar with all of the technologies listed above, but we do expect you to be excited to learn about them.

This position involves on-call responsibilities, typically for one week every two months. Our team is dedicated to supporting new team members. We care about your career growth, we try to assign projects and tasks based on what will help each team member develop into a more well-rounded engineer and enable them to take on more complex tasks in the future.

Our team values work-life balance and we are flexible when people occasionally need to work from home.

Job Duties
Develop and maintain automated ETL pipelines for big data using languages such as Scala, Spark, SQL and AWS services such as S3, Glue, Lambda, SNS, SQS, KMS. Example: ETL jobs that process a continuous flow of JSON source files and output the data in a business-friendly Parquet format that can be efficiently queried via Redshift Spectrum using SQL to answer business question.

Develop and maintain automated ETL monitoring and alarming solutions using Java/Python/Scala, Spark, SQL, and AWS services such as CloudWatch and Lambda.

Implement and support reporting and analytics infrastructure for internal business customers using AWS, services such Athena, Redshift, Spectrum, EMR, and QuickSight.

Develop and maintain data security and permissions solutions for enterprise scale data warehouse and data lake implementations including data encryption and database user access controls and logging.

Develop and maintain data warehouse and data lake metadata, data catalog, and user documentation for internal business customers.

Develop, test, and deploy code using internal software development toolsets. This includes the code for deploying infrastructure and solutions for secure data storage, ETL pipelines, data catalog, and data query.


Basic Qualifications

· Bachelors degree in Computer Science or related technical field, or equivalent work experience.
· 4+ years of overall work experience including Software Engineering, Data Engineering, Database Engineering, Business Intelligence.
· Experience with AWS technologies stack including Lambda, Glue, Redshift, RDS, S3, EMR or similar big data solutions stack

Preferred Qualifications

· Demonstrate efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data.
· Demonstrable proficiency in distributed systems and data architecture; design and implementation of batch and stream data processing pipelines; knows how to optimize the distribution, partitioning, and MPP of high-level data structures.

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer,-1,"Our client based in Johannesburg is urgently looking for a Data Engineer to be on a 3 months contract
Build data pipelines, experience in new tech like nifi, kafka, python

Joburg based, open to EE, 3 month contract with the option to extend, must be available at short notice",-1,EQplus,Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Overview
Job ID: 51456
Job Sector: Information Technology and Services
Country: South Africa
Region/State/Province/District: Gauteng
Location: Johannesburg

Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose

This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes

Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems

Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions

Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.
Research and best practices

Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development

Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.

Preferred Qualification and Experience

Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry

Knowledge/Technical Skills/Expertise

Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision

PLEASE NOTE: All our recruitment and selection processes comply with applicable local laws and regulations. We will never ask for money or any form of payment as part of our recruitment process. If you experience this, please contact our Fraudline on +27 800222050 or forward to TransactionFraudOpsSA@standardbank.co.za",4.1,"Standard Bank
4.1",Johannesburg,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"About us

At PBT Group we pride ourselves on being a Data Specialist organisation. With 20 years of experience in 27 countries over 3 continents, our team of 550 consultants have implemented more than 700 projects.",4.3,"PBT Group
4.3",Johannesburg,-1,Unknown,-1,Company - Private,Accounting,Accounting & Legal,Less than $1 million (USD),-1
Data Engineer,-1,"Kick-start your career in the online gaming world and experience the very latest in technology and innovation.

The Department:

Our mission is to provide our customers with the best online betting experience and share the thrill of gaming with them. Data is at the very heart of our business and is vital in everything we do.

Our cross-functional Data team has a big and exciting challenge ahead. We are in the process of re-platforming our traditional, on-premises RDBMS environment to a new microservice architecture in the cloud. We’re making use of the diverse set of data technologies in Microsoft Azure to offer new services, reporting structures and real-time data pipeline while serving the day-to-day requirements of a rapidly growing, data-hungry organisation.

Purpose of the Role:

This is an excellent opportunity for an individual who is looking to gain new skills. We are committed to creating a culture of learning and regularly run proof of concepts, provide internal demos, manage workshops and attend external conferences. Our data team has a wide range of skills including development for highly transactional RDBMS systems, data warehousing, data science and cloud technologies and we are always working to raise everyone’s game.

Duties include, but not limited to:

Work as part of an agile Data Engineering Team
Development of greenfield projects in Azure
Develop and maintain on-premises RDBMS/DW systems
Create robust ETL services and real-time data pipelines
Build and maintain Continuous Integration and DevOps pipelines
Test-driven development and pair programming with colleagues

Essential Criteria:

C#, .Net, Visual Studio
Git, Azure DevOps
NoSQL development (CosmosDB)
Demonstrable understanding of MS SQL Server in a highly transactional environment
Demonstrable understanding of development in Microsoft Azure
Able to understand query plans and identify performance bottlenecks
Test/Business-Driven Development
Building Continuous Integration/Deployment pipelines
Communicate effectively with both technical and non-technical stakeholders

Desirable Criteria:

Implementing Data Storage and Processing solutions in Azure (ARM Templates, Storage Accounts, Data Lake Storage, SQL DB, Cosmos DB, EventHubs, Function Apps, Log Analytics, Data Factory, Databricks, Polybase)
Implementing Security, Disaster Recovery, High Availability, Auditing, Monitoring and Alerting solutions in Azure
Automating tasks in Azure using Powershell / CLI
Predicting costs and optimizing spending in Azure
Message Queues (RabbitMQ, Kafka)
Python

Person Specifications:

Resilience
Teamwork
Technical Knowledge
Communication skills
Stress Tolerance
Please note we will apply relevance to our Talent Management and Talent Development Programme as part of our recruitment process.
Shortlisted candidates may need to complete an assessment.
This position requires trust and honesty it has access to customers financial details - therefore a credit and criminal record check will be conducted. The qualifications identified herein are an inherent job requirement; therefore, a qualification verification check will be done. By applying for this role, and supplying the necessary details, you hereby grant us permission to apply for these checks. This will be done in a confidential manner, and solely for the purposes of verification.

To view all current vacancies, please visit our website, www.digioutsource.com

Should you not hear from us within 2 weeks, please deem your application as unsuccessful.

The perfect place to work, play and grow!",3.9,"Digital Outsource Services
3.9",Cape Town,-1,1001 to 5000 Employees,1997,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
Data Engineer,-1,"At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes

Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.

Key Responsibilities

Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.

Key Traits

Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern

Position Requirements

2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.

Where will you work? This role will be based out of Durbanville, South Africa.",3.1,"Aculocity, LLC
3.1",Durbanville,-1,1 to 50 Employees,2006,Company - Private,IT Services,Information Technology,$1 to $5 million (USD),-1
Data Engineer,-1,"ENVIRONMENT:

A rapidly growing E-Commerce Platform seeks a highly talented Data Engineer to make an invaluable contribution to data democratisation and literacy vision by making accessible and easy-to-use data products and tools. You will require a Comp-Sci Degree or 3 years’ relevant industry experience, MySQL, PostgreSQL, Java, Python, in-depth understanding of OLAP, Data Marts, Star Scheme, Snowflake, be familiar with Jenkins, Travis, Circle CI, Docker, Kubernetes, experience with Kafka, Pub/Sub, Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks & significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing & Data Lake design and implementation and Lambda/Kappa architectures.

DUTIES:

Design, develop, test and maintain data architecture.

Prepare data for descriptive, predictive and prescriptive modelling.

Automate repetitive tasks and manual processes related with the data usage.

Optimize data delivery.

Design, develop and test large stream data pipelines to ingest, aggregate, clean, and distribute data models ready for analysis.

Ensure the highest standard in data integrity.

Leverage best practices in continuous integration and delivery.

Collaborate with other engineers, ML experts, analysts, and stakeholders to produce the most efficient and valuable solutions.

Implement features, technology, and processes that move us towards industry best practices, improving on scalability, efficiency, reliability, and security.

Operations and ownership of systems in production, responding to incidents.

REQUIREMENTS:

Qualifications –

Comp-Sci Degree or 3 years relevant industry experience.

Experience/Skills –

Open source relational database systems e.g. MySQL, PostgreSQL, etc.

Significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing, and Data Lake design and implementation and Lambda/Kappa architectures.

A thorough understanding of database and data warehousing principles e.g. OLAP, Data Marts, Star Schema, Snowflake, etc.

Java and Python.

Familiar with CI/CD tools such as Jenkins, Travis, Circle CI, etc.

Experience with Kafka, Pub/Sub, or other event-based systems.

Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks, etc.

Working in cloud environments and with containerisation frameworks, tools and platforms e.g. Docker, Kubernetes, GKE, etc.

A deep understanding of data pipelining, streaming, and Big Data technologies, methods, patterns, and techniques.

Troubleshooting complex database operations and performance issues.

Automating tasks using Shell Scripting or writing small applications.

ATTRIBUTES:

Works well with people and is passionate about helping people be their best.

A team player, an active listener, mentor, and able to communicate well.

Shows solid reasoning and decision making, with the ability to work under pressure.

Is passionate about technology, systems and data.

Is curious, always learning, and keeping up to date with the industry.

While we would really like to respond to every application, should you not be contacted for this position within 10 working days please consider your application unsuccessful.

COMMENTS:

When applying for jobs, ensure that you have the minimum job requirements. Only SA Citizens will be considered for this role. If you are not in the mentioned location of any of the jobs, please note your relocation plans in all applications for jobs and correspondence.",-1,Datafin IT Recruitment,Cape Town,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Cartrack is looking for passionate data science and engineering candidates that can join a growing team that is responsible for the intelligence and efficiency solution provision to over a million subscribers, many of whom are large fleets. We are in the midst of creating revolutionary platforms that will change the way that people interact with their vehicles.

You will have the opportunity to work with the very brightest global subject matter experts that are transforming the automotive industry across Fleet Management, Asset Management and Insurance Telematics solutions.

Get to know the role:

The role of a data engineer is a supporting one, but it is also an extremely vital one. As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements. We want to see candidates with mechanical tendencies and a desire to know how things work and to improve them.

The day-to-day activities:

Design, construct, install, test and maintain data management systems.
Build high-performance algorithms, predictive models, and prototypes.
Ensure that all systems meet the business/company requirements as well as industry practices.
Integrate up-and-coming data management and software engineering technologies into existing data structures.
Develop set processes for data mining, data modeling, and data production.
Create custom software components and analytics applications.
Research new uses for existing data.
Employ an array of technological languages and tools to connect systems together.
Install/update disaster recovery procedures.
Recommend different ways to constantly improve data reliability and quality.
Work on and maintain Data pipelines.

Requirements Essential:

At least 5 years’ proven experience as a Data Engineer, DevOps Engineer, Software Developer, or similar.
Proficient in Linux/Unix and shell scripting as well as in functional programming languages.
Expertise in setting up and explored with technologies such as Hadoop and Spark.
Bachelor’s degree in computer science, software/computer engineering, applied mathematics, or physics.",3.3,"Cartrack
3.3",Johannesburg,-1,501 to 1000 Employees,2004,Company - Private,Security Services,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Data Engineer,-1,"Data Engineers build and support data pipelines and datamarts built off those pipelines. Both must be scalable, repeatable and secure. The Data Engineer helps to facilitate gathering data from a variety of different sources, in the correct format, assuring that it conforms to data quality standards and assuring that downstream users can get to that data timeously. This role functions as a core member of an agile team. These professionals are responsible for the infrastructure that provides insights from raw data, handling and integrating diverse sources of data seamlessly. They enable solutions, by handling large volumes of data in batch and real-time by leveraging emerging technologies from both the big data and cloud spaces. Additional responsibilities include developing proof of concepts and implements complex big data solutions with a focus on collecting, parsing, managing, analysing and visualising large datasets. They know how to apply technologies to solve the problems of working with large volumes of data in diverse formats to deliver innovative solutions. Data Engineering is a technical job that requires substantial expertise in a broad range of software development and programming fields. These professionals have a knowledge of data analysis, end user requirements and business requirements analysis to develop a clear understanding of the business need and to incorporate these needs into a technical solution. They have a solid understanding of physical database design and the systems development lifecycle. This role must work well in a team environment.

Job Objectives

Work Complexity: * Architects Data analytics framework. * Translates complex functional and technical requirements into detailed architecture, design, and high performing software. * Leads Data and batch/real-time analytical solutions leveraging transformational technologies. * Works on multiple projects as a technical lead driving user story analysis and elaboration, design and development of software applications, testing, and builds automation tools.

Main Job Objectives: 1. Development and Operations 2. Database Development and Operations 3. Policies, Standards and Procedures 4. Communications 5. Business Continuity & Disaster Recovery 6. Research and Evaluation 7. Coaching/ Mentoring

Qualifications

Essential: 4 years Bachelors degree in computer science, computer engineering, or equivalent work experience AWS Certification at least to associate level

Experience

Essential:

5+ years Data engineering or software engineering

3-5 years demonstrated experience leading teams of engineers

2+ years Big Data experience

5+ years experience with Extract Transform and Load (ETL) processes

2+ years Could AWS experience

At least 2 years demonstrated experience with agile or other rapid application development methods - Agile exposure, Kanban or Scrum

5 years demonstrated experience with object oriented design, coding and testing patterns as well as experience in engineering (commercial or open source) software platforms and large scale data infrastructures.

Desirable:

5+ years Retail Operations experience

Knowledge and Skills

Essential: *Creating data feeds from on-premise to AWS Cloud (2 years) *Support data feeds in production on break fix basis (2 years) *Creating data marts using Talend or similar ETL development tool (4 years) *Manipulating data using python and pyspark (2 years) *Processing data using the Hadoop paradigm particularly using EMR, AWSs distribution of Hadoop (2 years) *Devop for Big Data and Business Intelligence including automated testing and deployment (2 years) * Extensive knowledge in different programming or scripting languages * Expert knowledge of data modeling and understanding of different data structures and their benefits and limitations under particular use cases.

Further technical skills required: * Capability to architect highly scalable distributed systems, using different open source tools. * Big Data batch and streaming tools * Talend (1 year) * AWS: EMR, EC2, S3 (1 year) * Python (1 year) * PySpark or Spark (1 year) - Desirable * Business Intelligence Data modelling (3 years) * SQL (3 years)",-1,Datonomy Solutions,Brackenfell,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We are assisting one of our clients that is based in Pretoria to fill a role of a Data Engineer

This is a 12 month contract role

Objective of this Scope of Work

The Data Engineer will drive improvement of the data management maturity levels and provide the necessary technical support within the company to support reliable and effective decision-making, appropriate usage and protection thereof.

Scope of Services Definition

The scope will include but will not be limited to:

ï†· To develop, construct, test and maintain architectures.

ï†· To ensure architectures will support the requirements of business.

ï†· To discover opportunities for data acquisition and sharing.

ï†· To develop data set processes for data modelling, mining and production.

ï†· To employ a variety of languages and tools to marry systems together.

ï†· To recommend way to improve data reliability, efficiency and quality.

ï†· To prepare data for use in predictive and prescriptive modelling.

ï†· To conduct research to answer industry and business questions.

ï†· To leverage volumes of data from internal and external to answer business questions.

ï†· To develop and manage stakeholder relations effectively to promote data management across the organisation and support reliable decision making and appropriate data usage.

ï†· To participate and provide technical support in cross organisational activities relating to any of the above mentioned data management activities.

ï†· To provide regular progress reports as per stakeholder requirements and present data management updates in various forums as required.

Minimum qualification Required:

ï†· A minimum of a Bachelors degree in Computer Science or Information Management OR equivalent;

ï†· A minimum of five to eight years experience in a data management environment",-1,HR Genie,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Our client based in the Northern Suburbs, is currently looking for a Data Engineer to join their team.

Responsibilities
Our client is a dynamic IT company that delivers value-driven IT solutions to the group. Our work lives revolve around our DNA. We take pride in our work, treat our colleagues, partners and our country with respect. We exercise collaborative decision-making and believe in having a balance in life. We do this all while having fun and enjoying what we do.

The primary focus of this position is to use technical skills to put software, systems and data together in a way that extracts meaningful insights from raw data. You will need to be helpful and supportive to your team and fellow developers. You join an energetic, focused and dynamic team.

Interact with clients to understand requirements and business problems/needs

Identify, analyse, visualise and understand supporting data to propose solid solutions

Create technical documentation for reference and reporting

Support existing solutions within GCP and Oracle

Doing standby on a rotating basis

Key Competencies and Qualifications

Matric

Tertiary qualification in IT

Preferred cloud experience in AWS/AZURE/GCP

At least 3 years of data warehouse ETL experience

Dimensional Modelling

Data analyses

Experience with data visualization and visualization tool(s)

Knowledge of the retail industry will be beneficial

Understanding and experience with version control SVN/GIT

Preferred – Korn shell scripting, Python/Java, SQL

Google Cloud Platform experience would be looked upon favourably

Having a broad understanding of different SDLC’s

Preferred agile experience

Strengths

The natural tendency to take ownership and responsibility

Strong problem solving, critical thinking, effective planning and organisational skills

Detail-oriented with excellent communication skills

You have a can-do attitude and positive outlook on life

Can cope under pressure

Curious and interested in analysing problems and possible solutions

Strong team player

Self-driven learner, passionate about new technology

Above all, be passionate about what you do

Should you wish to apply for the position, please apply directly via this job board, please ensure that you quote reference number 201620 subject heading or email body.

Please note that due to the high volume of CV's received; only shortlisted applicants will be contacted. Should you not receive communication from our offices within two weeks of submission please note that your application will not be considered for this position.

We will keep your CV on file and re-establish contact with you should opportunities in line with your expertise become available again.

Should you require any additional information give us a call on 021 012 5566.",-1,Surgo HR & Training,Cape Town,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We believe that our employees fuel our organization, essential to enable us to help our customers overcome their business challenges and achieve sustainable growth. As a result, we are committed to growing each individual and providing them with the challenges, feedback and support needed to achieve success in their career

If this sounds appealing, and like us, you get excited about data: its collection, storage, transformation or display, see if you’ve got what it takes to join our sought after DATA team.

Key Responsibilities And/or Outputs

You will represent IQbusiness at our customers, sometimes alone, and sometimes as part of an IQ team.

Providing a superior customer experience by building and maintaining relationships, working at customer offices, keeping data confidential
Design and develop – databases, SQL queries, stored procedures, reports, dashboards or integration solutions
Produce solutions for both real-time and batch environments
Test your work to ensure compliance
Solve problems, and do root cause analysis
Prioritize your workload
Assist in other areas relating to your true data function, such as data modeling, data and business analysts
Interact with a variety of individuals: senior, junior, technical and from business
Provide guidance to fellow colleagues, or even manage a team
Uphold the IQ values, which are to care, learn & share; innovate; deliver as well as to build, enhance and maintain relationships

Education

Matric pass
A tertiary qualification, preferably in an ICT relevant field
Appropriate Microsoft certifications are beneficial but not required

Requirements

3 - 6 years experience in the Data Engineering environments and technologies
Great communication skills
A passion for SQL, databases or reports
Can you write stored procedures, design complex queries and create views and triggers?
Are you able to work out the relationships in a data warehouse or the aggregation of a cube?
Do you extract and display useful information when you see patterns and trends in data?
Strong knowledge of the financial services industry, ideally in a consulting role
The use of data related software: databases, ETL and BI tools; report writing and analytical tools
We use a lot of Microsoft products. You may often be expected to use MS SQL Server, SSIS, SSRS, SSAS and Power BI to develop solutions
What other relevant software have you’ve used?
Ability to work in different project methodologies: Waterfall and/or Agile
Knowledge of full SDLC
Exposure to logical and physical data modeling

Equal Employment Opportunity

IQbusiness is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, citizenship, marital, domestic or civil partnership status, sexual orientation, or gender identity",3.7,"IQbusiness South Africa
3.7",Johannesburg,-1,1 to 50 Employees,-1,Company - Private,Consulting,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"We value a data engineer as someone who works behind the scenes to obtain, process and supply data via various methodologies and technologies, to various consumers, in ways and forms that makes sense and add value. This definition is very broad, as the field of data engineering is just as broad.

You may be the type of data engineer that develops API endpoints for the consumption of data by end users or even another data pipeline, or you may be the type of data engineer that develops highly distributed, high availability data processing pipelines in an effort to satisfy the need of the ever questioning data analysts and/or data scientists.

You have awesome knowledge about the following concepts
Data modelling
Relational data modelling in traditional relational database management systems. (Microsoft SQL Server, MySQL, PostgreSQL, etc)
Coercing unstructured and semi-structured data into a structured form.
Data pipelining knowledge - data extraction and transformation.
Data transformation knowledge for reporting and analytics purposes.
Knowledge of the MapReduce and related data processing paradigms would be a boon.
You have the following technical competencies
Writing SQL queries, that can relate, transform and aggregate data from many differing sources where natural keys may or may not exist.
Experience with writing data pipelines that move and transform data, for various uses.
Working knowledge of a general purpose programming language like Python would be a boost.
Working knowledge of columnar databases such as Google BigQuery, and SAP HANA would be a boost.
Working knowledge of highly distributed technologies such as Apache Hadoop or Apache Spark would be a boost.
Working knowledge of NoSQL technologies, such as Apache Solr would be a boost.
You have the following personal competencies
The ability to solve problems.
The ability to rotate around a problem, to see if solutions can be gained in different ways.
The ability to work in an ever changing, unstructured environment.
The ability to work as part of a team, with vastly differing skill sets and opinions.
The ability to contribute ideas to the quorum.
The ability to mentor and provide guidance for other team members.
A systems approach to thinking, as opposed to a siloed approach. The candidate needs to understand how their work affects the greater system.
The ability to work without supervision, and take accountability for the work they deliver.
The ability to liaise with a client, sifting through the fluff and extracting the actual requirements.
If this is you - apply now and we'll get in touch",-1,DotModus,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Data Engineer

Our client in the contact centre space is currently seeking a DATA ENGINEER that will work on the collecting, storing, processing, and analyzing of large datasets. The primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them. You will also be responsible for integrating them with the architecture used across the company.

Key Performance Areas:

Data reporting.
Implementing ETL processes.
Defining data retention policies.
Management of Customer Lead data.
Provision of data for advanced analytics.
Maintenance of internal client scorecards.
Assist team in resolving data-related support queries.
Optimize existing data processes through automation.
Assist with all data-related reporting and documentation.
Maintenance and optimisation of the Analytics database.
Provide technical support to and supervision of junior data administrators.
Continuous upskilling on new technologies, frameworks and market trends.
Monitoring performance and advising any necessary infrastructure changes.
Identifying, selecting and integrating any Big Data tools and frameworks required to provide real-time analytics.

Educational Requirements

IT related Degree or Diploma is a pre-requisite

Required Skills/Experience

ETL tools: Advanced SSIS
BI/Reporting : Qlikview/Power BI/ SSRS or SSAS
Programming languages: JAVA, C# , Python, SAS or R
Experience with NoSQL databases and/or campaign management tools will be advantageous.
Minimum 3 years’ applicable work experience in SQL, relational databases and data manipulation.
Experience in big data platforms (eg. Hadoop) or processing frameworks (eg. MapReduce/Spark) and querying tools (eg. Pig, Hive and Impala) will be highly beneficial.

Preferred Skills

Organizational skills
Experience in Attentional to detail.
Accountability is critical for this role.
Ability to work under pressure and meet deadlines.
Solid understanding of database design principles.
Should you not receive a response in 2 weeks please consider your application unsuccessful",-1,Rubik's Cubed Consulting,Durban,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"This well known company is looking for a Data Engineer. will be based in Rivonia
The ideal candidate will have strong experience in the following:
Data cleaning
SQL Export
Big data Sets

BSc Degree in Maths and Stats will be required
a min of 3 years experience.
Stable track record is required.

Send your Cv to marinda@prrrecruitment.co.za",-1,PRR Recruitment Services,Johannesburg,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Description

Position at Aculocity, LLC

At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes
Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.
Key Responsibilities
Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.
Key Traits
Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern
Position Requirements
2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.
Where will you work? This role will be based out of Durbanville, South Africa.",-1,GVW,Durbanville,-1,Unknown,-1,Unknown,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Information Technology, Gauteng JHB - Northern Suburbs

Market related - Market related Annually

An IT Consultancy Business based in Johannesburg is currently looking for a Business Intelligence Consultant / Data Engineering Consultant.

Requirements:

Extensive experience in data engineering
Experience in Business Intelligence, data and Power BI
Extensive experience in data governance and the Popi act
Ability to assess and make recommendations on data within the Popi act
Good understanding of T-SQL and query optimization, developing ETL strategies.
Good understanding with SQL Server 2008/2012, SSIS, SSRS and SSAS
Use SSIS to create ETL packages to validate, extract, transform, and load data into the data warehouse and data marts.
Deploy and configured the reports in the Report Server (SSRS).
Excellent experience in Tabular Modelling , PowerView, Qlikvie,w, and Power BI
Maintain ETL
Qlikview model
Create Drill-through, Drill-down, and Cross Tab Reports and Sub-Report using Report Definition Language (RDL).
Generate periodic reports based on the statistical analysis of the data using SQL Server Reporting Services (SSRS)
Advise and provide written technical documentation and recommendations

The information displayed above is not limited to advertisements. Please contact Thato for further information.

Please consider your application as unsuccessful if you have not received a response within 14 days of submitting your application. However, please keep a lookout on our website, www.bedifferent.co.za, for available positions that you may be suited for

Ad Visible Until: 29 October 2020
Ref: JHB005346/NL

Vacancy Type: Permanent",2.9,"Be Different Recruitment
2.9",Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Cloud Support Engineer (Big Data),-1,"ABOUT US

Amazon Web Services is the market leader and technology forerunner in the Cloud business. As a member of the AWS Support team you will be at the forefront of this transformational technology, assisting a global list of companies and developers that are taking advantage of a growing set of services and features to run their mission-critical applications. As a Cloud Support Engineer, you will act as the Cloud Ambassador across all the cloud products, arming our customers with required tools & tactics to get the most out of their Product and Support investment.

Would you like to use the latest cloud computing technologies? Do you have an interest in helping customers understand application architectures and integration approaches? Are you familiar with best practices for applications, servers and networks? Do you want to be part of a customer facing technology team helping to ensure the success of Amazon Web Services (AWS) as a leading technology organization?

If you fit the description, you might be the person we are looking for! We are a group of smart people, passionate about cloud computing, and believe that world class support is critical to customer success.

WHAT CAN YOU EXPECT FROM A LIFE AT AWS?

Every day will bring new and exciting challenges on the job while you:

· Learn and use groundbreaking technologies.
· Apply advanced troubleshooting techniques to provide unique solutions to our customers' individual needs.
· Interact with leading engineers around the world.
· Partner with Amazon Web Services teams to help reproduce and resolve customer issues.
· Leverage your extensive customer support experience to provide feedback to internal AWS teams on how to improve our services.
· Drive customer communication during critical events.
· Drive projects that improve support-related processes and our customers technical support experience.
· Write tutorials, how-to videos, and other technical articles for the developer community.
· Work on critical, highly complex customer problems that may span multiple AWS services.

WHY AWS SUPPORT?

· First and foremost this is a customer support role in The Cloud.
· On a typical day, a Support Engineer will be primarily responsible for solving customers cases through a variety of customer contact channels which include telephone, email, and web/live chat. You will apply advanced troubleshooting techniques to provide tailored solutions for our customers and drive customer interactions by thoughtfully working with customers to dive deep into the root cause of an issue.
· Apart from working on a broad spectrum of technical issues, an AWS Support Engineer may also coach/mentor new hires, develop & present training, partner with development teams on complex issues or contact deflection initiatives, participate in new hiring, write tools/script to help the team, or work with leadership on process improvement and strategic initiatives.
· Career development: We promote advancement opportunities across the organization to help you meet your career goals.
· Training: We have training programs to help you develop the skills required to be successful in your role.
· We hire smart people who are keen to build a career with AWS, so we are more interested in the areas that you do know instead of those you havent been exposed to yet.
· Support engineers interested in travel have presented training or participated in focused summits across our sites or at specific AWS events.
· As we operate on a follow-the-sun model, with Premium Support sites located globally, there is no after hours on-call or mandated overtime in this role.
· https://www.youtube.com/watch?v=GC3bWcFFZTo&t=24s



Basic Qualifications

The Big Data role supports our services that leverage data and produce business insights, which may include using Machine Learning/Artificial Intelligence (ML/AI). Helping our customers use and integrate Big Data services in what is arguably our industrys most exciting space. The portfolio of services covers EMR (Hadoop), DynamoDB (NoSQL), MangoDB, and Apache Cassandra.

· Advanced experience in Apache Hadoop, Apache Spark, Apache Hive, and Presto
· Advanced experience in DynamoDB or NoSQL technologies like MongoDB or Cassandra
· Advanced experience with System Administration with Linux (RHEL/CentOS) including Microsoft Active Directory, and LDAP integration.
· Experience with troubleshooting Kerberos Authentication problems.
· Experience with Network troubleshooting.
· Basic understanding of Machine Learning and statistics
· Experience with Java and Python and shell scripting
· Bachelors degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position



Preferred Qualifications

· Expert experience in the Hadoop Ecosystem including Apache Spark and Presto
· Expert experience in NoSQL
· Expert experience with blockchain technologies like Etherium Expert experience in data Data Lake architecture and administration
· Experience managing full application stacks from the OS up through custom applications
· Prior work experience with AWS - any or all of EC2, VPC, S3, RDS, EMR, Glue, SageMaker
· Excellent knowledge of Hadoop architecture, administration and support
· Expert understanding of distributed computing principles and their application in the cloud
· Good understanding of distributed computing environments Lead technical discussions on big data systems architecture and design
· Strong analysis and troubleshooting skills and experience
· AWS Certified Solutions Architect
· AWS certified Big Data Specialty
· Masters degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity and Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Response Center Engineer,-1,"Job Title
Response Center Engineer
Job Description


Philips is a world leading health technology company with a vision to make life better for people worldwide through meaningful innovation. Making good on this promise depends on our passionate, inspirational, collaborative and diverse team. We have over 80,000+ brilliant people around the world but are always looking for more. Like-minded, motivated, focused minds to join us in creating a healthier, more connected society while transforming themselves personally and professionally.

As a CCC Coordinator - Response Center Engineer you will have the opportunity to process customer calls and be responsible for screening and diagnosing professionally Healthcare equipment to support customers and colleagues remotely with solving technical issues and ensuring maximum customer satisfaction

You are responsible for:
Diagnose healthcare equipment to the quality standards set by Philips Healthcare (PH) remotely by interviewing customers or colleagues by telephone or by remotely logging in to the system
Advise Customer Care Center Coordinators and District Operations Managers and / or Team Leads about the best follow-up w.r.t. technical state of the diagnosed healthcare equipment
Advise the Customer Care Center Coordinators or Field Services Engineers about required spare parts and resources
Responsible for planning engineers related to Modality responsibility.
Responsible for coordination between CCC, CUSTOMER, Spare parts AND Engineer.
Responsible to drive Remote and FTR KPI’s to targets respectively 40% and 85%.
Will require minimal field work to keep abreast of technical capabilities.
Take calls from customers and make sure they are processed in the CCC ERP on timely manner including all relevant data
Support Field Services Engineers in the field with technical knowledge
Escalate technical issues to the Technical Support Specialist
Escalate technical issues to Business Unit support after consultation of the Technical Support Specialist
Monitor critical functions of the equipment’s in the IB and environmental conditions including RSN and True reachability.
Lead the planning and implementation of FSN’s and FCO’s accelerating remote implementation where applicable.
Submit timely and accurate service data, job sheets, reports, expense claims, radiation film badges, field problem reports and other paperwork as assigned
Keep abreast of new technologies likely to affect PH range of products
Use company property with care to ensure optimal results with minimal operational costs
Be a professional representative for PH with respect to customer problems, ensuring personal acceptability by the customer in behavior in accordance with PH policy and targets
Conform to PH safety standards including health and safety regulations and in the event of hazards or accidents to take immediate control of the situation and involve the Operations Manager and / or the responsible person to handle properly confidential issues according Philips standards and to act according General Business Principals
Follow all quality standards within the frame of valid PH business policies
Follow the company quality regulations (ISO 9001; PQA; TQM) and internal directives and procedures
You are a part of the dynamic South Africa Customer Care Centre Team .You will be reporting to the Customer Care Center Manager.

Requires a pleasant, assertive individual you can work very well in a team setting, a dynamic environment that requires flexibility and creativeness to achieve goals.

To succeed in this role, you should have the following skills and experience:
Degree level education or equivalent
Experience in maintenance and troubleshooting of technical complex systems
Fluent in English, verbal and written in addition to local language
In return, we offer you the unique combination of a critical and challenging role and a creative and empowering office environment. You will be actively encouraged to make improvements, establish best in class service and have a direct impact on the success of Philips on a daily basis.

Employment Equity

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply. Only apply for this role if you are a South African Citizen by birth or Naturalization prior to the 27 April 1994.

Why should you join Philips?

Working at Philips is more than a job. It’s a calling to create a healthier society through meaningful work, focused on improving 3 billion lives a year by delivering innovative solutions across the health continuum. Our people experience a variety of unexpected moments when their lives and careers come together in meaningful ways. Learn more by watching this video.

To find out more about what it’s like working for Philips at a personal level, visit the Working at Philips page on our career website, where you can read stories from our employee blog. Once there, you can also learn about our recruitment process, or find answers to some of the frequently asked questions.

Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.9,"Philips
3.9",Johannesburg,-1,10000+ Employees,1891,Company - Public,Health Care Services & Hospitals,Health Care,$10 to $25 million (USD),-1
Software Development Engineer - EC2 Placement,-1,"Build the systems that optimize how EC2 matches requests for Instances with the underlying compute capacity. EC2 Placement is seeking talented engineers to build the online and offline optimization systems for compute workload scheduling, and the customer capabilities to better manage those workloads. Amazon EC2 provides on-demand scalable compute capacity, and powers some of the largest services in the world. You will collaborate with a top-tier community of engineers to build systems to improve how customers are able to access EC2 compute resources.

The successful candidate will have strong software engineering experience, with a passion for thinking about, building and testing distributed systems. You have an interest in how Machine Learning and other optimization techniques can be applied to large-scale problems. You have demonstrated experience working with a team to design, build and operate large-scale systems. With strong engineering fundamentals, an analytical and data-driven approach to your work, and strong communication skills, you have the ability to collaborate well to deliver results. We move fast and work together on small teams to solve big problems.

If this opportunity sounds interesting, we would love to talk to you more about our work and the vibrant culture at AWS in Cape Town.

Basic Qualifications

· Degree in Computer Science or related field, or equivalent working experience
· 3+ years of industry experience in a software development environment
· Strong Computer Science fundamentals, including data structures, object-oriented design, algorithm design, problem solving, and complexity analysis.
· Proficiency in at least one modern programming language, such as Java, C#, Python, Scala, Kotlin

Preferred Qualifications

One or more of the following help you stand out:
· Demonstrated results designing, building and operating high-performance distributed systems in large-scale Linux environments
· Role model in writing high-quality, maintainable and secure code, mentoring others, and helping teams sharpen their development processes
· Ability to work effectively across teams to deliver results, with strong verbal and written communication skills
· Experience working with machine learning systems

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer - PBB IT,-1,"Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose


This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes
Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems
Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions
Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.

Research and best practices
Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development
Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.
Preferred Qualification and Experience
Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Aws Data Platform Engineer,-1,"Aws Data Platform Engineer

Posting Country:

South Africa

Date Posted:

15-Oct-2020

Full Time / Part Time:

Full Time

Contract Type:

Permanent

Joining Vodacom is more than a job, what we do matters. We don’t just carry minutes, texts and data – we carry people’s lives. And that’s a huge responsibility. If you think for a minute about the people you rely on…the likelihood is they rely on us.

Customers are at the heart of everything we do and we want to make a difference to the lives of our customers, and the communities in which we live and work. We support our people to give something back to the causes that mean the most to them through helping them give time and money to the charities they love.

And what’s it like to work here? We have created an environment where you can look forward to coming to work and are empowered to be at your best. We offer flexibility in how you work that helps you do your job in a way that suits you, opportunities to help you grow and progress throughout your career and a choice of benefits to suit your lifestyle.

Role Purpose
The H Band AWS Data Platform Engineer position is based within the Technology Business Unit.

The AWS Data Platform Engineer will be responsible for all Database services such as RDS, DynamoDB, etc. Should be able to migrate any databases from anywhere to AWS using any third-party tools or AWS database migration tool. Should also have understanding or expertise in creating data warehouses and data lake solutions on AWS.
Your responsibilities will include:
Apply practical knowledge of relational database design and usage with customers
Perform workload analysis and undertake performance tuning, as well as performance benchmarking in customer environments.
To develop state of the art solutions which are technically sound.
To provide a high-quality service to the Enterprise Cloud Services clients i.t.o. consultancy, solutions and delivery.
Commitment to team success and positive team dynamics including mentoring of other team members.
Passion for growing and applying technical skills in service to customers.
Be a trusted infrastructure advisor by providing objective, practical and relevant ideas, insights and advice.
Work collaboratively with consulting partners and technology teams to ensure high quality of solution delivery.
Encourage best practice and knowledge sharing with partners and cross-functional groups
Manage the overall database design and delivery of solutions.
Ability to make recommendations as they pertain to improvements in support/development initiatives and facilitate implementation with partners and cross-functional groups within the Business.
Participate in high level database solution definition and design during the implementation phase with the goal of providing reliable, stable and operationally sound applications that meet the Business requirements.
Ability to understand and translate business requirements into technical specifications
The ideal candidate will have:
A minimum of 3 years of industry related experience of which 1 year must be within a complex hosting environment.
Certifications in Database design, system architecture or cloud technologies.
Demonstrate knowledge of database systems internals including storage layouts and distributed databases/MPP architectures
Advanced SQL coding, tuning and query optimization.
Experience designing and leading database performance benchmarks.
Good knowledge of the different AWS services
Knowledge of cloud networking architecture, cloud operations, security, automation and orchestration.
Knowledge of database internals as it relates to query and system performance and tuning.
Understanding of overall system architecture, scalability, reliability, and performance in a database environment.
Excellent teamwork, time-management and organizational skills.
Perform other duties as deemed necessary and assigned by the customer and management
Strong interpersonal skills and problem-solving abilities.
Excellent documentation, communication and interpersonal skills.
Excellent analytical and problem-solving abilities.
Closing date for applications: Monday, 13 April 2020

The base location for this role is Vodacom World, Midrand

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply.
Vodacom is committed to an organisational culture that recognises, appreciates and values diversity & inclusion.

Commitment from Vodacom

Vodacom is committed to attracting, developing and retaining the very best people by offering a flexible, motivating and inclusive workplace in which talent is truly recognized, developed and rewarded. We believe that diversity plays an important role in the success of our business and we are committed to creating an inclusive work environment which respects, values, celebrates and makes the most of people’s individual differences - we are not only multinational but multicultural too. At Vodacom you will have access to our excellent flexible benefits programme that you would expect from any global company.",3.9,"Vodafone
3.9",Midrand,-1,10000+ Employees,1982,Company - Public,"Cable, Internet & Telephone Providers",Telecommunications,$10+ billion (USD),-1
Data Engineer Azure Data Factory,-1,"Enthuzex is looking for a motivated Lead Data Engineer to contribute towards the success of our Data and Analytics Technology initiatives. This is a hands-on technical role and this person will be responsible for the development and build of scalable solutions as it relates to the architecture strategies, data standards, digital data management, data integration, tools, and technology. The right candidate will play a deep dive hands-on critical development role in the digital transformation and in shaping how we acquire, ingest, transform and deliver data through the digital consumer channels.

Responsibilities:

Architect, design, develop and engineering end-to-end data pipelines across multiple data sources and systems of record.
Ensure data quality, integrity, security and completeness throughout the data lifecycle
Develop, design data models, data structures and ETL jobs for data acquisition and manipulation purposes
Develop deep understanding of the data sources, implement data standards, maintain data quality and master data management
Developing data services and API
Work closely with the cloud service providers to ensure completeness and alignment with the service offerings
Manage and maintain cloud based data and analytics platform
Deep understanding of the cloud offerings and engage in quick proof of concepts and proof of value in prototyping data and analytics solutions and derive viability
Ability to interact with the business stakeholders to understand requirements and translating into technology solutions

Expirience:

Experience in Cloud platform AWS or Azure eco-system. (Azure preferred)
Data Engineering/Development experience with SQL (Oracle, SQL Server, MySQL)
Strong development background creating pipelines and complex data transformations and manipulations using one of the languages Python, Java, R, or Scala with Databricks/Spark
Experience in NoSQL Databases and Big data technologies including Hadoop
Experience with API / RESTful data services
Worked on real-time data capture, processing and storing using technologies like Azure Event Hubs and Analytics
Experience working with different data storage options including AWS S3, Azure BLOB storage etc.
Understanding of different data formats including Parquet, Avro, CSV, ORC etc.
Prior experience with MPP databases and maintain large amount of data processing
Experience with Azure Data Factory and Azure Data Catalog is a big plus and mandatory
Experience with Microsoft/Azure ETL solutions and business Intelligence technologies is a big and mandatory
Past working experience on a fast paced and agile environment
Perform ongoing monitoring, automation and refinement of data engineering solutions
Experience in leading high visibility transformation projects that interacts with multiple business lines
Build and meet project timelines and manage delivery commitments with proper communication to management

Qualifications

Bachelor’s degree with 4+ years of relevant experience
Willingness to learn new technologies and thrive in an extremely fast paced environment
Team player and easy to work with.

Applicants must demonstrate their ability to master new enterprise level technologies. Successful applicants will exemplify Enthuzex ethical principles of uncompromising integrity, respect for others, and accountability for decisions

send cv's info@enthuzex.co.za",-1,Enthuzex,Leslie,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Scientist,-1,"The world is changing.

We all want something different.

At Luno, we see you as an individual.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the world, and to do so, we need the best team on board for our mission.

A bit about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 3 million customers across 40 countries.
We are Series B funded, backed by Balderton Capital and the Naspers Group.
Our platform has processed over 8 billion dollars since we've launched
We're proud to be one of the world's most international cryptocurrency teams from 26 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
The role in a nutshell:

Identifying opportunities in the business that could benefit most from cognitive applications, as well as building and enhancing organisational capabilities for deriving value from multiple data sources using data science.

What we'd like you to have:
Bachelor's degree or higher in the natural sciences or technical fields such as Mathematics, Statistics, Computer Science, Engineering or Economics
Enthusiasm to work in the cryptocurrencies space
Advanced SQL skills
Solid understanding of exploratory data analysis, predictive analytics, and optimisation using Python, R, Matlab, RapidMiner, KNIME or other data science-oriented platforms
Proficiency in the use of data science and machine learning domain-specific languages such as ""Caret"" and the ""Tidyverse"" suite of tools in R, or ""Pandas"" in Python
Strong interpersonal and communication skills
Communicating data insights using storytelling narratives
Ability to work independently, as well as within and across teams
Ability to successfully complete projects with large and/or incomplete data sets
More about what you'll be doing:
Optimising product performance by tracking and analysing customer behaviour on web and app, in collaboration with software engineers and product designers
Providing the business with reports and dashboards, on key performance metrics
Developing metrics to accurately assess the health of our Exchange platform
Comparative data-driven analysis of our Exchange against alternative platforms
Formulating business requirements into analytical objectives
Designing and running experiments to test hypotheses
Hacking through complex business problems using advanced data analysis to provide insights and recommendations
Building, maintaining, and optimising decisioning systems using advanced statistical and predictive modelling techniques
What will set you apart:
An advanced degree in Mathematics, Statistics, Computer Science or related field
At least 3 years' experience working in a similar role
A basic understanding of trading in financial markets
Experience working with a data analytics and visualisation platform such as Tableau, Cognos, QlikView, or Looker
Familiarity with using Google Analytics to understand customer behaviour
Solid knowledge of statistical and machine learning techniques
Familiarity with modern distributed data storage and processing systems such as Amazon Redshift, Big Query, Snowflake, Databricks and Apache Spark
You can gather and synthesise facts, theories, trends, patterns, inferences, and key issues in complex and variable situations
Ability to diagnose problems using formal problem-solving tools and techniques from multiple angles to generate multiple possible solutions
A sense of anticipating long-term problem areas and associated risk levels with objective rationale
Remote Life at Luno

If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
You'll be able to continuously upskill yourself with access to free online learning via MyAcademy, an international teaching marketplace with over 100000 courses from Harvard and other leading providers + share knowledge with your peers.
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity and paternity leave, and you can even take paw-ternity leave for your furry friend.
Annual Inspiration Day! Make time for that pottery course or spa day you've always wanted to do.
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"EY is a global leader in
assurance, tax, transaction and advisory services. Technology is at the heart
of what we do and deliver at EY. Technology solutions are integrated in the
client services we deliver and are key to our innovation as an organization.

Fueled by
strategic investment in technology and innovation, Client Technology seeks to
drive growth opportunities and solve complex business problems for our clients
through building a robust platform for business and powerful product engine
that are vital to innovation at scale. As part of Client Technology, you’ll
work with technologists and business experts, blending EY’s deep industry
knowledge and innovative ideas with our platforms, capabilities, and technical
expertise. As a catalyst for change and growth, you’ll be at the forefront of
integrating emerging technologies from AI to Data Analytics into every corner
of what we do at EY. That means more growth for you, exciting learning
opportunities, career choices, and the chance to make a real impact.

The selected
candidate
Develops
large and complex data architecture, composed of models, policies, rules or
standards that govern which data is collected and how it is stored, arranged,
integrated and put to use in data systems, including the design, build and
management of data infrastructure to address business requirements
Creates
sound use case driven roadmaps, depicting data architecture as-is and to-be
capabilities with the business by engaging with multidisciplinary teams, and by
identifying, managing and mitigating risk
Develops
relationships across the business to understand data requirements, applies deep
technical knowledge of data management to solve business problems in areas
where solutions may not currently exist, necessitating new solutions/ways of
working/technologies and proactively articulating these to the business
Review,
identify the latest emerging technologies, augmenting by services from the
leading cloud providers to solution and recommend the best next generation data
platform value driven approach for our clients
Your Key Responsibilities Include
Create
and maintain conceptual, logical and physical database models
Document
functional requirements and system specifications into the data architecture
and detailed design specifications for current and proposed designs
Document
and adhere to development standards and best practices in database designs
Maintain
highly effective and consistent communication within the team, peers, and the
leadership team
Reverse
engineer SQL code and modify it to solve problems/issues
Contribute
to the definition and implementation of data governance practices
Design
both data structures and data integration practices
Work
closely with the infrastructure teams to create a physical environment to
support data services
Evaluate
new and existing (internal and external) technologies and services in support
of data services and data analytics objectives
Skills And Attributes For Success
Understanding
of business process reengineering and business modeling concepts, business
systems development and analysis
Hands-on
experience in designing and implementing hybrid cloud and on-prem solutions
Experience
working with the latest versions of SQL Server
Experience
applying SAFe/Scrum/Kanban methodologies
Ability
to exercise judgment in solving technical, operational, and organizational
challenges
Expert
programming, performance tuning and troubleshooting skills, using the latest
popular programming languages for example python
Demonstrate
proactive approach to identifying issues and presenting solutions and options,
and where appropriate, leading to resolution
Minimum Qualifications
5+ years
demonstratable work experience as a Data Architect using data modeling tools
2-3 years
SQL coding experience on large projects
Must
possess expert SQL programming, performance tuning and troubleshooting skills
Create
database objects and SQL scripts
Understand
and developed data pipelines
Know how
to deformalize data for data science models
Experience
in python, spark and notebooks
Experience
designing data warehousing solutions
Experience
designing next generation data platforms utilising cloud services
In-depth
understanding of database structure principles
Seamlessly
able to translate business requirements to technology requirements
What We Look For
Strong
analytical skills and problem-solving ability
A
self-starter, independent-thinker, curious and creative person with ambition
and passion
Excellent
inter-personal, communication, collaboration, and presentation skills
Customer
focused
Excellent
time management skills
Positive
and constructive minded
Takes
responsibility for continuous self-learning
Takes the
lead and makes decisions in critical times and tough circumstances
Attention
to detail
High
levels of integrity and honesty
Curious
about new emerging technology
About EY
As a global leader in assurance, tax, transaction and consulting
services, we’re using the finance products, expertise and systems we’ve
developed to build a better working world. That starts with a culture that
believes in giving you the training, opportunities and creative freedom to make
things better. Whenever you join, however long you stay, the exceptional EY
experience lasts a lifetime.",3.8,"EY
3.8",Johannesburg,-1,10000+ Employees,1989,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Architect - Principal,-1,"We are looking for Principle Data Architect to join our Engineering team in Cape Town.

The world is changing.
We all want something different.
At Luno, we see you as individuals.

Together, we are upgrading the world of work to unleash the potential within and empower you to become the best possible version of yourself.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the financial landscape, and to do so, well we need the best team on board for our mission. In short, to achieve our goals, we need rockstars. As simple as that.

A little about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 5 million customers across 40 countries.
We're part of the Digital Currency Group, a group of companies driving progress in the cryptocurrency and blockchain space that includes Grayscale, Genesis, Coindesk and Foundry Services
Our platform has processed over $8 billion to date
We're proud to be one of the world's most international cryptocurrency teams from 43 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
How we work


Our engineering team (currently ~100 engineers) is split into organisations which we call Fleets. Each Fleet focuses on a core customer journey (onboarding, security, payments, support, new business, growth and marketing etc.). Each of these fleets contains multiple smaller teams called Pods, each of which focuses on a specific aspect of the product.

Pods will include a product owner, product designer, back-end engineers, Android, iOS and Web developers, who each bring a unique perspective to the problem you are all contributing towards.

We're agile, use scrum, continuous integration and continuous delivery, deploying to production every single day.

We're building teams to help us succeed in our mission to upgrade the world to a better financial system. You'll be joining a group of highly motivated software engineers who you'll work collaboratively with across our pods.

As a fast-growing company with offices around the world, you'll immediately see how your contributions directly impact both our internal users and client experience. Many of the problems we are solving result in trail blazing solutions which can't be found on Stack Overflow; so we're looking for engineers who flourish working in a complex domain.

In your first six months, you will:


...start at Luno by learning our processes, meeting the wider team and starting our engineering on-boarding program. After getting comfortable with the basics, you'll start learning our idiomatic patterns in a safe, easy-to-follow way - by building your own toy micro services. You'll get to practice how we do design docs, code reviews, deployments, events, logging and monitoring.

You'll meet the Pod(s) you'll be working with and quickly align on the teams' current OKRs and product roadmap. We succeed as a team, so we will provide you with regular feedback from your manager and peers and will encourage you to do the same.

What you'll do:
Work closely with our data science and platform teams on projects introducing new streams of data into our data lake
You will get to bring new ideas on how to further develop and innovate our data solutions and how to expose that data to the business
Accountable and Responsible for the design and architecture of Data systems that are robust and scalable.
Work in an Agile/Scrum framework or Agile mindset
Data backup/recovery and storage
Pick-up and learn new concepts, in both engineering and product, and be able to apply that knowledge quickly.
The ideal candidate for this role will have:
7+ years' experience in maintaining scalable data solutions and/or you are passionate about it
Ability to understand, communicate and advocate between build vs buy
Proven track record of setting up, restructuring and maintenance of databases
You know your way around ETL and you have experience with SQL
Experience in the AWS Data stack (RedShift,DynamoDB, Amazon RDS)
Familiarity with integrating data stores with BI platforms such as Looker, Tableau, or Power BI
You have experience with the concepts of CI/CD
Coding skills in e.g. Go, Python
Bachelor's degree in a related field preferred
AWS Certified DataOps Administrator
Be friendly, transparent, articulate and driven to succeed
Basic knowledge of and passion for digital currencies like Bitcoin
A work permit for South Africa if you are not a South African citizen
Don't be put off if you don't tick all of the boxes – they're a guide based on what we'd love to see but we appreciate that excellent software engineers have diverse backgrounds.

Remote Life at Luno


If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity / paternity and even (yes, you are reading it correctly) paw-ternity for your furry friend..
Annual Inspiration Day.. like that pottery course you've always been meaning to do!
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. You'll need to hold the legal right to work in South Africa already as we cannot provide visa sponsorship.

Be part of the change!",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer - EC2 Capacity Data Analytics,-1,"EC2 Capacity Data Analytics (CDA) team is looking for a Data Engineer to join our team.

Our team is part of the EC2 Capacity Engineering organization, which is responsible for providing the elasticity EC2 customers need to scale up/down compute resources in a cost-efficient manner. We predict customer usage across thousands of configuration combinations to deliver exactly what our customers require in just the right amount of time with just the right amount of capacity.

As a Data Engineer, you will build the ETL and analytics solutions for our internal customers to answer questions with data and drive critical improvements for the business. You will use best practices in software engineering, data management, data storage, data compute, and distributed systems. On any given day, we use Python, Scala, Java, SQL, Lambda, CloudFormation, Redshift and Glue as well as other public AWS services and a host of Amazon internal tools. We dont expect you to be an expert in, or necessarily even be familiar with all of the technologies listed above, but we do expect you to be excited to learn about them.

This position involves on-call responsibilities, typically for one week every two months. Our team is dedicated to supporting new team members. We care about your career growth, we try to assign projects and tasks based on what will help each team member develop into a more well-rounded engineer and enable them to take on more complex tasks in the future.

Our team values work-life balance and we are flexible when people occasionally need to work from home.

Job Duties
Develop and maintain automated ETL pipelines for big data using languages such as Scala, Spark, SQL and AWS services such as S3, Glue, Lambda, SNS, SQS, KMS. Example: ETL jobs that process a continuous flow of JSON source files and output the data in a business-friendly Parquet format that can be efficiently queried via Redshift Spectrum using SQL to answer business question.

Develop and maintain automated ETL monitoring and alarming solutions using Java/Python/Scala, Spark, SQL, and AWS services such as CloudWatch and Lambda.

Implement and support reporting and analytics infrastructure for internal business customers using AWS, services such Athena, Redshift, Spectrum, EMR, and QuickSight.

Develop and maintain data security and permissions solutions for enterprise scale data warehouse and data lake implementations including data encryption and database user access controls and logging.

Develop and maintain data warehouse and data lake metadata, data catalog, and user documentation for internal business customers.

Develop, test, and deploy code using internal software development toolsets. This includes the code for deploying infrastructure and solutions for secure data storage, ETL pipelines, data catalog, and data query.


Basic Qualifications

· Bachelors degree in Computer Science or related technical field, or equivalent work experience.
· 4+ years of overall work experience including Software Engineering, Data Engineering, Database Engineering, Business Intelligence.
· Experience with AWS technologies stack including Lambda, Glue, Redshift, RDS, S3, EMR or similar big data solutions stack

Preferred Qualifications

· Demonstrate efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data.
· Demonstrable proficiency in distributed systems and data architecture; design and implementation of batch and stream data processing pipelines; knows how to optimize the distribution, partitioning, and MPP of high-level data structures.

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer,-1,"Our client based in Johannesburg is urgently looking for a Data Engineer to be on a 3 months contract
Build data pipelines, experience in new tech like nifi, kafka, python

Joburg based, open to EE, 3 month contract with the option to extend, must be available at short notice",-1,EQplus,Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Overview
Job ID: 51456
Job Sector: Information Technology and Services
Country: South Africa
Region/State/Province/District: Gauteng
Location: Johannesburg

Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose

This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes

Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems

Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions

Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.
Research and best practices

Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development

Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.

Preferred Qualification and Experience

Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry

Knowledge/Technical Skills/Expertise

Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision

PLEASE NOTE: All our recruitment and selection processes comply with applicable local laws and regulations. We will never ask for money or any form of payment as part of our recruitment process. If you experience this, please contact our Fraudline on +27 800222050 or forward to TransactionFraudOpsSA@standardbank.co.za",4.1,"Standard Bank
4.1",Johannesburg,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"About us

At PBT Group we pride ourselves on being a Data Specialist organisation. With 20 years of experience in 27 countries over 3 continents, our team of 550 consultants have implemented more than 700 projects.",4.3,"PBT Group
4.3",Johannesburg,-1,Unknown,-1,Company - Private,Accounting,Accounting & Legal,Less than $1 million (USD),-1
Data Engineer,-1,"Kick-start your career in the online gaming world and experience the very latest in technology and innovation.

The Department:

Our mission is to provide our customers with the best online betting experience and share the thrill of gaming with them. Data is at the very heart of our business and is vital in everything we do.

Our cross-functional Data team has a big and exciting challenge ahead. We are in the process of re-platforming our traditional, on-premises RDBMS environment to a new microservice architecture in the cloud. We’re making use of the diverse set of data technologies in Microsoft Azure to offer new services, reporting structures and real-time data pipeline while serving the day-to-day requirements of a rapidly growing, data-hungry organisation.

Purpose of the Role:

This is an excellent opportunity for an individual who is looking to gain new skills. We are committed to creating a culture of learning and regularly run proof of concepts, provide internal demos, manage workshops and attend external conferences. Our data team has a wide range of skills including development for highly transactional RDBMS systems, data warehousing, data science and cloud technologies and we are always working to raise everyone’s game.

Duties include, but not limited to:

Work as part of an agile Data Engineering Team
Development of greenfield projects in Azure
Develop and maintain on-premises RDBMS/DW systems
Create robust ETL services and real-time data pipelines
Build and maintain Continuous Integration and DevOps pipelines
Test-driven development and pair programming with colleagues

Essential Criteria:

C#, .Net, Visual Studio
Git, Azure DevOps
NoSQL development (CosmosDB)
Demonstrable understanding of MS SQL Server in a highly transactional environment
Demonstrable understanding of development in Microsoft Azure
Able to understand query plans and identify performance bottlenecks
Test/Business-Driven Development
Building Continuous Integration/Deployment pipelines
Communicate effectively with both technical and non-technical stakeholders

Desirable Criteria:

Implementing Data Storage and Processing solutions in Azure (ARM Templates, Storage Accounts, Data Lake Storage, SQL DB, Cosmos DB, EventHubs, Function Apps, Log Analytics, Data Factory, Databricks, Polybase)
Implementing Security, Disaster Recovery, High Availability, Auditing, Monitoring and Alerting solutions in Azure
Automating tasks in Azure using Powershell / CLI
Predicting costs and optimizing spending in Azure
Message Queues (RabbitMQ, Kafka)
Python

Person Specifications:

Resilience
Teamwork
Technical Knowledge
Communication skills
Stress Tolerance
Please note we will apply relevance to our Talent Management and Talent Development Programme as part of our recruitment process.
Shortlisted candidates may need to complete an assessment.
This position requires trust and honesty it has access to customers financial details - therefore a credit and criminal record check will be conducted. The qualifications identified herein are an inherent job requirement; therefore, a qualification verification check will be done. By applying for this role, and supplying the necessary details, you hereby grant us permission to apply for these checks. This will be done in a confidential manner, and solely for the purposes of verification.

To view all current vacancies, please visit our website, www.digioutsource.com

Should you not hear from us within 2 weeks, please deem your application as unsuccessful.

The perfect place to work, play and grow!",3.9,"Digital Outsource Services
3.9",Cape Town,-1,1001 to 5000 Employees,1997,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
Data Engineer,-1,"At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes

Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.

Key Responsibilities

Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.

Key Traits

Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern

Position Requirements

2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.

Where will you work? This role will be based out of Durbanville, South Africa.",3.1,"Aculocity, LLC
3.1",Durbanville,-1,1 to 50 Employees,2006,Company - Private,IT Services,Information Technology,$1 to $5 million (USD),-1
Data Engineer,-1,"ENVIRONMENT:

A rapidly growing E-Commerce Platform seeks a highly talented Data Engineer to make an invaluable contribution to data democratisation and literacy vision by making accessible and easy-to-use data products and tools. You will require a Comp-Sci Degree or 3 years’ relevant industry experience, MySQL, PostgreSQL, Java, Python, in-depth understanding of OLAP, Data Marts, Star Scheme, Snowflake, be familiar with Jenkins, Travis, Circle CI, Docker, Kubernetes, experience with Kafka, Pub/Sub, Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks & significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing & Data Lake design and implementation and Lambda/Kappa architectures.

DUTIES:

Design, develop, test and maintain data architecture.

Prepare data for descriptive, predictive and prescriptive modelling.

Automate repetitive tasks and manual processes related with the data usage.

Optimize data delivery.

Design, develop and test large stream data pipelines to ingest, aggregate, clean, and distribute data models ready for analysis.

Ensure the highest standard in data integrity.

Leverage best practices in continuous integration and delivery.

Collaborate with other engineers, ML experts, analysts, and stakeholders to produce the most efficient and valuable solutions.

Implement features, technology, and processes that move us towards industry best practices, improving on scalability, efficiency, reliability, and security.

Operations and ownership of systems in production, responding to incidents.

REQUIREMENTS:

Qualifications –

Comp-Sci Degree or 3 years relevant industry experience.

Experience/Skills –

Open source relational database systems e.g. MySQL, PostgreSQL, etc.

Significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing, and Data Lake design and implementation and Lambda/Kappa architectures.

A thorough understanding of database and data warehousing principles e.g. OLAP, Data Marts, Star Schema, Snowflake, etc.

Java and Python.

Familiar with CI/CD tools such as Jenkins, Travis, Circle CI, etc.

Experience with Kafka, Pub/Sub, or other event-based systems.

Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks, etc.

Working in cloud environments and with containerisation frameworks, tools and platforms e.g. Docker, Kubernetes, GKE, etc.

A deep understanding of data pipelining, streaming, and Big Data technologies, methods, patterns, and techniques.

Troubleshooting complex database operations and performance issues.

Automating tasks using Shell Scripting or writing small applications.

ATTRIBUTES:

Works well with people and is passionate about helping people be their best.

A team player, an active listener, mentor, and able to communicate well.

Shows solid reasoning and decision making, with the ability to work under pressure.

Is passionate about technology, systems and data.

Is curious, always learning, and keeping up to date with the industry.

While we would really like to respond to every application, should you not be contacted for this position within 10 working days please consider your application unsuccessful.

COMMENTS:

When applying for jobs, ensure that you have the minimum job requirements. Only SA Citizens will be considered for this role. If you are not in the mentioned location of any of the jobs, please note your relocation plans in all applications for jobs and correspondence.",-1,Datafin IT Recruitment,Cape Town,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Cartrack is looking for passionate data science and engineering candidates that can join a growing team that is responsible for the intelligence and efficiency solution provision to over a million subscribers, many of whom are large fleets. We are in the midst of creating revolutionary platforms that will change the way that people interact with their vehicles.

You will have the opportunity to work with the very brightest global subject matter experts that are transforming the automotive industry across Fleet Management, Asset Management and Insurance Telematics solutions.

Get to know the role:

The role of a data engineer is a supporting one, but it is also an extremely vital one. As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements. We want to see candidates with mechanical tendencies and a desire to know how things work and to improve them.

The day-to-day activities:

Design, construct, install, test and maintain data management systems.
Build high-performance algorithms, predictive models, and prototypes.
Ensure that all systems meet the business/company requirements as well as industry practices.
Integrate up-and-coming data management and software engineering technologies into existing data structures.
Develop set processes for data mining, data modeling, and data production.
Create custom software components and analytics applications.
Research new uses for existing data.
Employ an array of technological languages and tools to connect systems together.
Install/update disaster recovery procedures.
Recommend different ways to constantly improve data reliability and quality.
Work on and maintain Data pipelines.

Requirements Essential:

At least 5 years’ proven experience as a Data Engineer, DevOps Engineer, Software Developer, or similar.
Proficient in Linux/Unix and shell scripting as well as in functional programming languages.
Expertise in setting up and explored with technologies such as Hadoop and Spark.
Bachelor’s degree in computer science, software/computer engineering, applied mathematics, or physics.",3.3,"Cartrack
3.3",Johannesburg,-1,501 to 1000 Employees,2004,Company - Private,Security Services,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Data Engineer,-1,"Data Engineers build and support data pipelines and datamarts built off those pipelines. Both must be scalable, repeatable and secure. The Data Engineer helps to facilitate gathering data from a variety of different sources, in the correct format, assuring that it conforms to data quality standards and assuring that downstream users can get to that data timeously. This role functions as a core member of an agile team. These professionals are responsible for the infrastructure that provides insights from raw data, handling and integrating diverse sources of data seamlessly. They enable solutions, by handling large volumes of data in batch and real-time by leveraging emerging technologies from both the big data and cloud spaces. Additional responsibilities include developing proof of concepts and implements complex big data solutions with a focus on collecting, parsing, managing, analysing and visualising large datasets. They know how to apply technologies to solve the problems of working with large volumes of data in diverse formats to deliver innovative solutions. Data Engineering is a technical job that requires substantial expertise in a broad range of software development and programming fields. These professionals have a knowledge of data analysis, end user requirements and business requirements analysis to develop a clear understanding of the business need and to incorporate these needs into a technical solution. They have a solid understanding of physical database design and the systems development lifecycle. This role must work well in a team environment.

Job Objectives

Work Complexity: * Architects Data analytics framework. * Translates complex functional and technical requirements into detailed architecture, design, and high performing software. * Leads Data and batch/real-time analytical solutions leveraging transformational technologies. * Works on multiple projects as a technical lead driving user story analysis and elaboration, design and development of software applications, testing, and builds automation tools.

Main Job Objectives: 1. Development and Operations 2. Database Development and Operations 3. Policies, Standards and Procedures 4. Communications 5. Business Continuity & Disaster Recovery 6. Research and Evaluation 7. Coaching/ Mentoring

Qualifications

Essential: 4 years Bachelors degree in computer science, computer engineering, or equivalent work experience AWS Certification at least to associate level

Experience

Essential:

5+ years Data engineering or software engineering

3-5 years demonstrated experience leading teams of engineers

2+ years Big Data experience

5+ years experience with Extract Transform and Load (ETL) processes

2+ years Could AWS experience

At least 2 years demonstrated experience with agile or other rapid application development methods - Agile exposure, Kanban or Scrum

5 years demonstrated experience with object oriented design, coding and testing patterns as well as experience in engineering (commercial or open source) software platforms and large scale data infrastructures.

Desirable:

5+ years Retail Operations experience

Knowledge and Skills

Essential: *Creating data feeds from on-premise to AWS Cloud (2 years) *Support data feeds in production on break fix basis (2 years) *Creating data marts using Talend or similar ETL development tool (4 years) *Manipulating data using python and pyspark (2 years) *Processing data using the Hadoop paradigm particularly using EMR, AWSs distribution of Hadoop (2 years) *Devop for Big Data and Business Intelligence including automated testing and deployment (2 years) * Extensive knowledge in different programming or scripting languages * Expert knowledge of data modeling and understanding of different data structures and their benefits and limitations under particular use cases.

Further technical skills required: * Capability to architect highly scalable distributed systems, using different open source tools. * Big Data batch and streaming tools * Talend (1 year) * AWS: EMR, EC2, S3 (1 year) * Python (1 year) * PySpark or Spark (1 year) - Desirable * Business Intelligence Data modelling (3 years) * SQL (3 years)",-1,Datonomy Solutions,Brackenfell,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We are assisting one of our clients that is based in Pretoria to fill a role of a Data Engineer

This is a 12 month contract role

Objective of this Scope of Work

The Data Engineer will drive improvement of the data management maturity levels and provide the necessary technical support within the company to support reliable and effective decision-making, appropriate usage and protection thereof.

Scope of Services Definition

The scope will include but will not be limited to:

ï†· To develop, construct, test and maintain architectures.

ï†· To ensure architectures will support the requirements of business.

ï†· To discover opportunities for data acquisition and sharing.

ï†· To develop data set processes for data modelling, mining and production.

ï†· To employ a variety of languages and tools to marry systems together.

ï†· To recommend way to improve data reliability, efficiency and quality.

ï†· To prepare data for use in predictive and prescriptive modelling.

ï†· To conduct research to answer industry and business questions.

ï†· To leverage volumes of data from internal and external to answer business questions.

ï†· To develop and manage stakeholder relations effectively to promote data management across the organisation and support reliable decision making and appropriate data usage.

ï†· To participate and provide technical support in cross organisational activities relating to any of the above mentioned data management activities.

ï†· To provide regular progress reports as per stakeholder requirements and present data management updates in various forums as required.

Minimum qualification Required:

ï†· A minimum of a Bachelors degree in Computer Science or Information Management OR equivalent;

ï†· A minimum of five to eight years experience in a data management environment",-1,HR Genie,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Our client based in the Northern Suburbs, is currently looking for a Data Engineer to join their team.

Responsibilities
Our client is a dynamic IT company that delivers value-driven IT solutions to the group. Our work lives revolve around our DNA. We take pride in our work, treat our colleagues, partners and our country with respect. We exercise collaborative decision-making and believe in having a balance in life. We do this all while having fun and enjoying what we do.

The primary focus of this position is to use technical skills to put software, systems and data together in a way that extracts meaningful insights from raw data. You will need to be helpful and supportive to your team and fellow developers. You join an energetic, focused and dynamic team.

Interact with clients to understand requirements and business problems/needs

Identify, analyse, visualise and understand supporting data to propose solid solutions

Create technical documentation for reference and reporting

Support existing solutions within GCP and Oracle

Doing standby on a rotating basis

Key Competencies and Qualifications

Matric

Tertiary qualification in IT

Preferred cloud experience in AWS/AZURE/GCP

At least 3 years of data warehouse ETL experience

Dimensional Modelling

Data analyses

Experience with data visualization and visualization tool(s)

Knowledge of the retail industry will be beneficial

Understanding and experience with version control SVN/GIT

Preferred – Korn shell scripting, Python/Java, SQL

Google Cloud Platform experience would be looked upon favourably

Having a broad understanding of different SDLC’s

Preferred agile experience

Strengths

The natural tendency to take ownership and responsibility

Strong problem solving, critical thinking, effective planning and organisational skills

Detail-oriented with excellent communication skills

You have a can-do attitude and positive outlook on life

Can cope under pressure

Curious and interested in analysing problems and possible solutions

Strong team player

Self-driven learner, passionate about new technology

Above all, be passionate about what you do

Should you wish to apply for the position, please apply directly via this job board, please ensure that you quote reference number 201620 subject heading or email body.

Please note that due to the high volume of CV's received; only shortlisted applicants will be contacted. Should you not receive communication from our offices within two weeks of submission please note that your application will not be considered for this position.

We will keep your CV on file and re-establish contact with you should opportunities in line with your expertise become available again.

Should you require any additional information give us a call on 021 012 5566.",-1,Surgo HR & Training,Cape Town,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We believe that our employees fuel our organization, essential to enable us to help our customers overcome their business challenges and achieve sustainable growth. As a result, we are committed to growing each individual and providing them with the challenges, feedback and support needed to achieve success in their career

If this sounds appealing, and like us, you get excited about data: its collection, storage, transformation or display, see if you’ve got what it takes to join our sought after DATA team.

Key Responsibilities And/or Outputs

You will represent IQbusiness at our customers, sometimes alone, and sometimes as part of an IQ team.

Providing a superior customer experience by building and maintaining relationships, working at customer offices, keeping data confidential
Design and develop – databases, SQL queries, stored procedures, reports, dashboards or integration solutions
Produce solutions for both real-time and batch environments
Test your work to ensure compliance
Solve problems, and do root cause analysis
Prioritize your workload
Assist in other areas relating to your true data function, such as data modeling, data and business analysts
Interact with a variety of individuals: senior, junior, technical and from business
Provide guidance to fellow colleagues, or even manage a team
Uphold the IQ values, which are to care, learn & share; innovate; deliver as well as to build, enhance and maintain relationships

Education

Matric pass
A tertiary qualification, preferably in an ICT relevant field
Appropriate Microsoft certifications are beneficial but not required

Requirements

3 - 6 years experience in the Data Engineering environments and technologies
Great communication skills
A passion for SQL, databases or reports
Can you write stored procedures, design complex queries and create views and triggers?
Are you able to work out the relationships in a data warehouse or the aggregation of a cube?
Do you extract and display useful information when you see patterns and trends in data?
Strong knowledge of the financial services industry, ideally in a consulting role
The use of data related software: databases, ETL and BI tools; report writing and analytical tools
We use a lot of Microsoft products. You may often be expected to use MS SQL Server, SSIS, SSRS, SSAS and Power BI to develop solutions
What other relevant software have you’ve used?
Ability to work in different project methodologies: Waterfall and/or Agile
Knowledge of full SDLC
Exposure to logical and physical data modeling

Equal Employment Opportunity

IQbusiness is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, citizenship, marital, domestic or civil partnership status, sexual orientation, or gender identity",3.7,"IQbusiness South Africa
3.7",Johannesburg,-1,1 to 50 Employees,-1,Company - Private,Consulting,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"We value a data engineer as someone who works behind the scenes to obtain, process and supply data via various methodologies and technologies, to various consumers, in ways and forms that makes sense and add value. This definition is very broad, as the field of data engineering is just as broad.

You may be the type of data engineer that develops API endpoints for the consumption of data by end users or even another data pipeline, or you may be the type of data engineer that develops highly distributed, high availability data processing pipelines in an effort to satisfy the need of the ever questioning data analysts and/or data scientists.

You have awesome knowledge about the following concepts
Data modelling
Relational data modelling in traditional relational database management systems. (Microsoft SQL Server, MySQL, PostgreSQL, etc)
Coercing unstructured and semi-structured data into a structured form.
Data pipelining knowledge - data extraction and transformation.
Data transformation knowledge for reporting and analytics purposes.
Knowledge of the MapReduce and related data processing paradigms would be a boon.
You have the following technical competencies
Writing SQL queries, that can relate, transform and aggregate data from many differing sources where natural keys may or may not exist.
Experience with writing data pipelines that move and transform data, for various uses.
Working knowledge of a general purpose programming language like Python would be a boost.
Working knowledge of columnar databases such as Google BigQuery, and SAP HANA would be a boost.
Working knowledge of highly distributed technologies such as Apache Hadoop or Apache Spark would be a boost.
Working knowledge of NoSQL technologies, such as Apache Solr would be a boost.
You have the following personal competencies
The ability to solve problems.
The ability to rotate around a problem, to see if solutions can be gained in different ways.
The ability to work in an ever changing, unstructured environment.
The ability to work as part of a team, with vastly differing skill sets and opinions.
The ability to contribute ideas to the quorum.
The ability to mentor and provide guidance for other team members.
A systems approach to thinking, as opposed to a siloed approach. The candidate needs to understand how their work affects the greater system.
The ability to work without supervision, and take accountability for the work they deliver.
The ability to liaise with a client, sifting through the fluff and extracting the actual requirements.
If this is you - apply now and we'll get in touch",-1,DotModus,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Data Engineer

Our client in the contact centre space is currently seeking a DATA ENGINEER that will work on the collecting, storing, processing, and analyzing of large datasets. The primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them. You will also be responsible for integrating them with the architecture used across the company.

Key Performance Areas:

Data reporting.
Implementing ETL processes.
Defining data retention policies.
Management of Customer Lead data.
Provision of data for advanced analytics.
Maintenance of internal client scorecards.
Assist team in resolving data-related support queries.
Optimize existing data processes through automation.
Assist with all data-related reporting and documentation.
Maintenance and optimisation of the Analytics database.
Provide technical support to and supervision of junior data administrators.
Continuous upskilling on new technologies, frameworks and market trends.
Monitoring performance and advising any necessary infrastructure changes.
Identifying, selecting and integrating any Big Data tools and frameworks required to provide real-time analytics.

Educational Requirements

IT related Degree or Diploma is a pre-requisite

Required Skills/Experience

ETL tools: Advanced SSIS
BI/Reporting : Qlikview/Power BI/ SSRS or SSAS
Programming languages: JAVA, C# , Python, SAS or R
Experience with NoSQL databases and/or campaign management tools will be advantageous.
Minimum 3 years’ applicable work experience in SQL, relational databases and data manipulation.
Experience in big data platforms (eg. Hadoop) or processing frameworks (eg. MapReduce/Spark) and querying tools (eg. Pig, Hive and Impala) will be highly beneficial.

Preferred Skills

Organizational skills
Experience in Attentional to detail.
Accountability is critical for this role.
Ability to work under pressure and meet deadlines.
Solid understanding of database design principles.
Should you not receive a response in 2 weeks please consider your application unsuccessful",-1,Rubik's Cubed Consulting,Durban,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"This well known company is looking for a Data Engineer. will be based in Rivonia
The ideal candidate will have strong experience in the following:
Data cleaning
SQL Export
Big data Sets

BSc Degree in Maths and Stats will be required
a min of 3 years experience.
Stable track record is required.

Send your Cv to marinda@prrrecruitment.co.za",-1,PRR Recruitment Services,Johannesburg,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Description

Position at Aculocity, LLC

At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes
Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.
Key Responsibilities
Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.
Key Traits
Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern
Position Requirements
2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.
Where will you work? This role will be based out of Durbanville, South Africa.",-1,GVW,Durbanville,-1,Unknown,-1,Unknown,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Information Technology, Gauteng JHB - Northern Suburbs

Market related - Market related Annually

An IT Consultancy Business based in Johannesburg is currently looking for a Business Intelligence Consultant / Data Engineering Consultant.

Requirements:

Extensive experience in data engineering
Experience in Business Intelligence, data and Power BI
Extensive experience in data governance and the Popi act
Ability to assess and make recommendations on data within the Popi act
Good understanding of T-SQL and query optimization, developing ETL strategies.
Good understanding with SQL Server 2008/2012, SSIS, SSRS and SSAS
Use SSIS to create ETL packages to validate, extract, transform, and load data into the data warehouse and data marts.
Deploy and configured the reports in the Report Server (SSRS).
Excellent experience in Tabular Modelling , PowerView, Qlikvie,w, and Power BI
Maintain ETL
Qlikview model
Create Drill-through, Drill-down, and Cross Tab Reports and Sub-Report using Report Definition Language (RDL).
Generate periodic reports based on the statistical analysis of the data using SQL Server Reporting Services (SSRS)
Advise and provide written technical documentation and recommendations

The information displayed above is not limited to advertisements. Please contact Thato for further information.

Please consider your application as unsuccessful if you have not received a response within 14 days of submitting your application. However, please keep a lookout on our website, www.bedifferent.co.za, for available positions that you may be suited for

Ad Visible Until: 29 October 2020
Ref: JHB005346/NL

Vacancy Type: Permanent",2.9,"Be Different Recruitment
2.9",Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Cloud Support Engineer (Big Data),-1,"ABOUT US

Amazon Web Services is the market leader and technology forerunner in the Cloud business. As a member of the AWS Support team you will be at the forefront of this transformational technology, assisting a global list of companies and developers that are taking advantage of a growing set of services and features to run their mission-critical applications. As a Cloud Support Engineer, you will act as the Cloud Ambassador across all the cloud products, arming our customers with required tools & tactics to get the most out of their Product and Support investment.

Would you like to use the latest cloud computing technologies? Do you have an interest in helping customers understand application architectures and integration approaches? Are you familiar with best practices for applications, servers and networks? Do you want to be part of a customer facing technology team helping to ensure the success of Amazon Web Services (AWS) as a leading technology organization?

If you fit the description, you might be the person we are looking for! We are a group of smart people, passionate about cloud computing, and believe that world class support is critical to customer success.

WHAT CAN YOU EXPECT FROM A LIFE AT AWS?

Every day will bring new and exciting challenges on the job while you:

· Learn and use groundbreaking technologies.
· Apply advanced troubleshooting techniques to provide unique solutions to our customers' individual needs.
· Interact with leading engineers around the world.
· Partner with Amazon Web Services teams to help reproduce and resolve customer issues.
· Leverage your extensive customer support experience to provide feedback to internal AWS teams on how to improve our services.
· Drive customer communication during critical events.
· Drive projects that improve support-related processes and our customers technical support experience.
· Write tutorials, how-to videos, and other technical articles for the developer community.
· Work on critical, highly complex customer problems that may span multiple AWS services.

WHY AWS SUPPORT?

· First and foremost this is a customer support role in The Cloud.
· On a typical day, a Support Engineer will be primarily responsible for solving customers cases through a variety of customer contact channels which include telephone, email, and web/live chat. You will apply advanced troubleshooting techniques to provide tailored solutions for our customers and drive customer interactions by thoughtfully working with customers to dive deep into the root cause of an issue.
· Apart from working on a broad spectrum of technical issues, an AWS Support Engineer may also coach/mentor new hires, develop & present training, partner with development teams on complex issues or contact deflection initiatives, participate in new hiring, write tools/script to help the team, or work with leadership on process improvement and strategic initiatives.
· Career development: We promote advancement opportunities across the organization to help you meet your career goals.
· Training: We have training programs to help you develop the skills required to be successful in your role.
· We hire smart people who are keen to build a career with AWS, so we are more interested in the areas that you do know instead of those you havent been exposed to yet.
· Support engineers interested in travel have presented training or participated in focused summits across our sites or at specific AWS events.
· As we operate on a follow-the-sun model, with Premium Support sites located globally, there is no after hours on-call or mandated overtime in this role.
· https://www.youtube.com/watch?v=GC3bWcFFZTo&t=24s



Basic Qualifications

The Big Data role supports our services that leverage data and produce business insights, which may include using Machine Learning/Artificial Intelligence (ML/AI). Helping our customers use and integrate Big Data services in what is arguably our industrys most exciting space. The portfolio of services covers EMR (Hadoop), DynamoDB (NoSQL), MangoDB, and Apache Cassandra.

· Advanced experience in Apache Hadoop, Apache Spark, Apache Hive, and Presto
· Advanced experience in DynamoDB or NoSQL technologies like MongoDB or Cassandra
· Advanced experience with System Administration with Linux (RHEL/CentOS) including Microsoft Active Directory, and LDAP integration.
· Experience with troubleshooting Kerberos Authentication problems.
· Experience with Network troubleshooting.
· Basic understanding of Machine Learning and statistics
· Experience with Java and Python and shell scripting
· Bachelors degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position



Preferred Qualifications

· Expert experience in the Hadoop Ecosystem including Apache Spark and Presto
· Expert experience in NoSQL
· Expert experience with blockchain technologies like Etherium Expert experience in data Data Lake architecture and administration
· Experience managing full application stacks from the OS up through custom applications
· Prior work experience with AWS - any or all of EC2, VPC, S3, RDS, EMR, Glue, SageMaker
· Excellent knowledge of Hadoop architecture, administration and support
· Expert understanding of distributed computing principles and their application in the cloud
· Good understanding of distributed computing environments Lead technical discussions on big data systems architecture and design
· Strong analysis and troubleshooting skills and experience
· AWS Certified Solutions Architect
· AWS certified Big Data Specialty
· Masters degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity and Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Response Center Engineer,-1,"Job Title
Response Center Engineer
Job Description


Philips is a world leading health technology company with a vision to make life better for people worldwide through meaningful innovation. Making good on this promise depends on our passionate, inspirational, collaborative and diverse team. We have over 80,000+ brilliant people around the world but are always looking for more. Like-minded, motivated, focused minds to join us in creating a healthier, more connected society while transforming themselves personally and professionally.

As a CCC Coordinator - Response Center Engineer you will have the opportunity to process customer calls and be responsible for screening and diagnosing professionally Healthcare equipment to support customers and colleagues remotely with solving technical issues and ensuring maximum customer satisfaction

You are responsible for:
Diagnose healthcare equipment to the quality standards set by Philips Healthcare (PH) remotely by interviewing customers or colleagues by telephone or by remotely logging in to the system
Advise Customer Care Center Coordinators and District Operations Managers and / or Team Leads about the best follow-up w.r.t. technical state of the diagnosed healthcare equipment
Advise the Customer Care Center Coordinators or Field Services Engineers about required spare parts and resources
Responsible for planning engineers related to Modality responsibility.
Responsible for coordination between CCC, CUSTOMER, Spare parts AND Engineer.
Responsible to drive Remote and FTR KPI’s to targets respectively 40% and 85%.
Will require minimal field work to keep abreast of technical capabilities.
Take calls from customers and make sure they are processed in the CCC ERP on timely manner including all relevant data
Support Field Services Engineers in the field with technical knowledge
Escalate technical issues to the Technical Support Specialist
Escalate technical issues to Business Unit support after consultation of the Technical Support Specialist
Monitor critical functions of the equipment’s in the IB and environmental conditions including RSN and True reachability.
Lead the planning and implementation of FSN’s and FCO’s accelerating remote implementation where applicable.
Submit timely and accurate service data, job sheets, reports, expense claims, radiation film badges, field problem reports and other paperwork as assigned
Keep abreast of new technologies likely to affect PH range of products
Use company property with care to ensure optimal results with minimal operational costs
Be a professional representative for PH with respect to customer problems, ensuring personal acceptability by the customer in behavior in accordance with PH policy and targets
Conform to PH safety standards including health and safety regulations and in the event of hazards or accidents to take immediate control of the situation and involve the Operations Manager and / or the responsible person to handle properly confidential issues according Philips standards and to act according General Business Principals
Follow all quality standards within the frame of valid PH business policies
Follow the company quality regulations (ISO 9001; PQA; TQM) and internal directives and procedures
You are a part of the dynamic South Africa Customer Care Centre Team .You will be reporting to the Customer Care Center Manager.

Requires a pleasant, assertive individual you can work very well in a team setting, a dynamic environment that requires flexibility and creativeness to achieve goals.

To succeed in this role, you should have the following skills and experience:
Degree level education or equivalent
Experience in maintenance and troubleshooting of technical complex systems
Fluent in English, verbal and written in addition to local language
In return, we offer you the unique combination of a critical and challenging role and a creative and empowering office environment. You will be actively encouraged to make improvements, establish best in class service and have a direct impact on the success of Philips on a daily basis.

Employment Equity

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply. Only apply for this role if you are a South African Citizen by birth or Naturalization prior to the 27 April 1994.

Why should you join Philips?

Working at Philips is more than a job. It’s a calling to create a healthier society through meaningful work, focused on improving 3 billion lives a year by delivering innovative solutions across the health continuum. Our people experience a variety of unexpected moments when their lives and careers come together in meaningful ways. Learn more by watching this video.

To find out more about what it’s like working for Philips at a personal level, visit the Working at Philips page on our career website, where you can read stories from our employee blog. Once there, you can also learn about our recruitment process, or find answers to some of the frequently asked questions.

Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.9,"Philips
3.9",Johannesburg,-1,10000+ Employees,1891,Company - Public,Health Care Services & Hospitals,Health Care,$10 to $25 million (USD),-1
Software Development Engineer - EC2 Placement,-1,"Build the systems that optimize how EC2 matches requests for Instances with the underlying compute capacity. EC2 Placement is seeking talented engineers to build the online and offline optimization systems for compute workload scheduling, and the customer capabilities to better manage those workloads. Amazon EC2 provides on-demand scalable compute capacity, and powers some of the largest services in the world. You will collaborate with a top-tier community of engineers to build systems to improve how customers are able to access EC2 compute resources.

The successful candidate will have strong software engineering experience, with a passion for thinking about, building and testing distributed systems. You have an interest in how Machine Learning and other optimization techniques can be applied to large-scale problems. You have demonstrated experience working with a team to design, build and operate large-scale systems. With strong engineering fundamentals, an analytical and data-driven approach to your work, and strong communication skills, you have the ability to collaborate well to deliver results. We move fast and work together on small teams to solve big problems.

If this opportunity sounds interesting, we would love to talk to you more about our work and the vibrant culture at AWS in Cape Town.

Basic Qualifications

· Degree in Computer Science or related field, or equivalent working experience
· 3+ years of industry experience in a software development environment
· Strong Computer Science fundamentals, including data structures, object-oriented design, algorithm design, problem solving, and complexity analysis.
· Proficiency in at least one modern programming language, such as Java, C#, Python, Scala, Kotlin

Preferred Qualifications

One or more of the following help you stand out:
· Demonstrated results designing, building and operating high-performance distributed systems in large-scale Linux environments
· Role model in writing high-quality, maintainable and secure code, mentoring others, and helping teams sharpen their development processes
· Ability to work effectively across teams to deliver results, with strong verbal and written communication skills
· Experience working with machine learning systems

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer - PBB IT,-1,"Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose


This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes
Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems
Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions
Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.

Research and best practices
Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development
Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.
Preferred Qualification and Experience
Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Aws Data Platform Engineer,-1,"Aws Data Platform Engineer

Posting Country:

South Africa

Date Posted:

15-Oct-2020

Full Time / Part Time:

Full Time

Contract Type:

Permanent

Joining Vodacom is more than a job, what we do matters. We don’t just carry minutes, texts and data – we carry people’s lives. And that’s a huge responsibility. If you think for a minute about the people you rely on…the likelihood is they rely on us.

Customers are at the heart of everything we do and we want to make a difference to the lives of our customers, and the communities in which we live and work. We support our people to give something back to the causes that mean the most to them through helping them give time and money to the charities they love.

And what’s it like to work here? We have created an environment where you can look forward to coming to work and are empowered to be at your best. We offer flexibility in how you work that helps you do your job in a way that suits you, opportunities to help you grow and progress throughout your career and a choice of benefits to suit your lifestyle.

Role Purpose
The H Band AWS Data Platform Engineer position is based within the Technology Business Unit.

The AWS Data Platform Engineer will be responsible for all Database services such as RDS, DynamoDB, etc. Should be able to migrate any databases from anywhere to AWS using any third-party tools or AWS database migration tool. Should also have understanding or expertise in creating data warehouses and data lake solutions on AWS.
Your responsibilities will include:
Apply practical knowledge of relational database design and usage with customers
Perform workload analysis and undertake performance tuning, as well as performance benchmarking in customer environments.
To develop state of the art solutions which are technically sound.
To provide a high-quality service to the Enterprise Cloud Services clients i.t.o. consultancy, solutions and delivery.
Commitment to team success and positive team dynamics including mentoring of other team members.
Passion for growing and applying technical skills in service to customers.
Be a trusted infrastructure advisor by providing objective, practical and relevant ideas, insights and advice.
Work collaboratively with consulting partners and technology teams to ensure high quality of solution delivery.
Encourage best practice and knowledge sharing with partners and cross-functional groups
Manage the overall database design and delivery of solutions.
Ability to make recommendations as they pertain to improvements in support/development initiatives and facilitate implementation with partners and cross-functional groups within the Business.
Participate in high level database solution definition and design during the implementation phase with the goal of providing reliable, stable and operationally sound applications that meet the Business requirements.
Ability to understand and translate business requirements into technical specifications
The ideal candidate will have:
A minimum of 3 years of industry related experience of which 1 year must be within a complex hosting environment.
Certifications in Database design, system architecture or cloud technologies.
Demonstrate knowledge of database systems internals including storage layouts and distributed databases/MPP architectures
Advanced SQL coding, tuning and query optimization.
Experience designing and leading database performance benchmarks.
Good knowledge of the different AWS services
Knowledge of cloud networking architecture, cloud operations, security, automation and orchestration.
Knowledge of database internals as it relates to query and system performance and tuning.
Understanding of overall system architecture, scalability, reliability, and performance in a database environment.
Excellent teamwork, time-management and organizational skills.
Perform other duties as deemed necessary and assigned by the customer and management
Strong interpersonal skills and problem-solving abilities.
Excellent documentation, communication and interpersonal skills.
Excellent analytical and problem-solving abilities.
Closing date for applications: Monday, 13 April 2020

The base location for this role is Vodacom World, Midrand

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply.
Vodacom is committed to an organisational culture that recognises, appreciates and values diversity & inclusion.

Commitment from Vodacom

Vodacom is committed to attracting, developing and retaining the very best people by offering a flexible, motivating and inclusive workplace in which talent is truly recognized, developed and rewarded. We believe that diversity plays an important role in the success of our business and we are committed to creating an inclusive work environment which respects, values, celebrates and makes the most of people’s individual differences - we are not only multinational but multicultural too. At Vodacom you will have access to our excellent flexible benefits programme that you would expect from any global company.",3.9,"Vodafone
3.9",Midrand,-1,10000+ Employees,1982,Company - Public,"Cable, Internet & Telephone Providers",Telecommunications,$10+ billion (USD),-1
Data Engineer Azure Data Factory,-1,"Enthuzex is looking for a motivated Lead Data Engineer to contribute towards the success of our Data and Analytics Technology initiatives. This is a hands-on technical role and this person will be responsible for the development and build of scalable solutions as it relates to the architecture strategies, data standards, digital data management, data integration, tools, and technology. The right candidate will play a deep dive hands-on critical development role in the digital transformation and in shaping how we acquire, ingest, transform and deliver data through the digital consumer channels.

Responsibilities:

Architect, design, develop and engineering end-to-end data pipelines across multiple data sources and systems of record.
Ensure data quality, integrity, security and completeness throughout the data lifecycle
Develop, design data models, data structures and ETL jobs for data acquisition and manipulation purposes
Develop deep understanding of the data sources, implement data standards, maintain data quality and master data management
Developing data services and API
Work closely with the cloud service providers to ensure completeness and alignment with the service offerings
Manage and maintain cloud based data and analytics platform
Deep understanding of the cloud offerings and engage in quick proof of concepts and proof of value in prototyping data and analytics solutions and derive viability
Ability to interact with the business stakeholders to understand requirements and translating into technology solutions

Expirience:

Experience in Cloud platform AWS or Azure eco-system. (Azure preferred)
Data Engineering/Development experience with SQL (Oracle, SQL Server, MySQL)
Strong development background creating pipelines and complex data transformations and manipulations using one of the languages Python, Java, R, or Scala with Databricks/Spark
Experience in NoSQL Databases and Big data technologies including Hadoop
Experience with API / RESTful data services
Worked on real-time data capture, processing and storing using technologies like Azure Event Hubs and Analytics
Experience working with different data storage options including AWS S3, Azure BLOB storage etc.
Understanding of different data formats including Parquet, Avro, CSV, ORC etc.
Prior experience with MPP databases and maintain large amount of data processing
Experience with Azure Data Factory and Azure Data Catalog is a big plus and mandatory
Experience with Microsoft/Azure ETL solutions and business Intelligence technologies is a big and mandatory
Past working experience on a fast paced and agile environment
Perform ongoing monitoring, automation and refinement of data engineering solutions
Experience in leading high visibility transformation projects that interacts with multiple business lines
Build and meet project timelines and manage delivery commitments with proper communication to management

Qualifications

Bachelor’s degree with 4+ years of relevant experience
Willingness to learn new technologies and thrive in an extremely fast paced environment
Team player and easy to work with.

Applicants must demonstrate their ability to master new enterprise level technologies. Successful applicants will exemplify Enthuzex ethical principles of uncompromising integrity, respect for others, and accountability for decisions

send cv's info@enthuzex.co.za",-1,Enthuzex,Leslie,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Scientist,-1,"The world is changing.

We all want something different.

At Luno, we see you as an individual.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the world, and to do so, we need the best team on board for our mission.

A bit about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 3 million customers across 40 countries.
We are Series B funded, backed by Balderton Capital and the Naspers Group.
Our platform has processed over 8 billion dollars since we've launched
We're proud to be one of the world's most international cryptocurrency teams from 26 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
The role in a nutshell:

Identifying opportunities in the business that could benefit most from cognitive applications, as well as building and enhancing organisational capabilities for deriving value from multiple data sources using data science.

What we'd like you to have:
Bachelor's degree or higher in the natural sciences or technical fields such as Mathematics, Statistics, Computer Science, Engineering or Economics
Enthusiasm to work in the cryptocurrencies space
Advanced SQL skills
Solid understanding of exploratory data analysis, predictive analytics, and optimisation using Python, R, Matlab, RapidMiner, KNIME or other data science-oriented platforms
Proficiency in the use of data science and machine learning domain-specific languages such as ""Caret"" and the ""Tidyverse"" suite of tools in R, or ""Pandas"" in Python
Strong interpersonal and communication skills
Communicating data insights using storytelling narratives
Ability to work independently, as well as within and across teams
Ability to successfully complete projects with large and/or incomplete data sets
More about what you'll be doing:
Optimising product performance by tracking and analysing customer behaviour on web and app, in collaboration with software engineers and product designers
Providing the business with reports and dashboards, on key performance metrics
Developing metrics to accurately assess the health of our Exchange platform
Comparative data-driven analysis of our Exchange against alternative platforms
Formulating business requirements into analytical objectives
Designing and running experiments to test hypotheses
Hacking through complex business problems using advanced data analysis to provide insights and recommendations
Building, maintaining, and optimising decisioning systems using advanced statistical and predictive modelling techniques
What will set you apart:
An advanced degree in Mathematics, Statistics, Computer Science or related field
At least 3 years' experience working in a similar role
A basic understanding of trading in financial markets
Experience working with a data analytics and visualisation platform such as Tableau, Cognos, QlikView, or Looker
Familiarity with using Google Analytics to understand customer behaviour
Solid knowledge of statistical and machine learning techniques
Familiarity with modern distributed data storage and processing systems such as Amazon Redshift, Big Query, Snowflake, Databricks and Apache Spark
You can gather and synthesise facts, theories, trends, patterns, inferences, and key issues in complex and variable situations
Ability to diagnose problems using formal problem-solving tools and techniques from multiple angles to generate multiple possible solutions
A sense of anticipating long-term problem areas and associated risk levels with objective rationale
Remote Life at Luno

If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
You'll be able to continuously upskill yourself with access to free online learning via MyAcademy, an international teaching marketplace with over 100000 courses from Harvard and other leading providers + share knowledge with your peers.
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity and paternity leave, and you can even take paw-ternity leave for your furry friend.
Annual Inspiration Day! Make time for that pottery course or spa day you've always wanted to do.
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"EY is a global leader in
assurance, tax, transaction and advisory services. Technology is at the heart
of what we do and deliver at EY. Technology solutions are integrated in the
client services we deliver and are key to our innovation as an organization.

Fueled by
strategic investment in technology and innovation, Client Technology seeks to
drive growth opportunities and solve complex business problems for our clients
through building a robust platform for business and powerful product engine
that are vital to innovation at scale. As part of Client Technology, you’ll
work with technologists and business experts, blending EY’s deep industry
knowledge and innovative ideas with our platforms, capabilities, and technical
expertise. As a catalyst for change and growth, you’ll be at the forefront of
integrating emerging technologies from AI to Data Analytics into every corner
of what we do at EY. That means more growth for you, exciting learning
opportunities, career choices, and the chance to make a real impact.

The selected
candidate
Develops
large and complex data architecture, composed of models, policies, rules or
standards that govern which data is collected and how it is stored, arranged,
integrated and put to use in data systems, including the design, build and
management of data infrastructure to address business requirements
Creates
sound use case driven roadmaps, depicting data architecture as-is and to-be
capabilities with the business by engaging with multidisciplinary teams, and by
identifying, managing and mitigating risk
Develops
relationships across the business to understand data requirements, applies deep
technical knowledge of data management to solve business problems in areas
where solutions may not currently exist, necessitating new solutions/ways of
working/technologies and proactively articulating these to the business
Review,
identify the latest emerging technologies, augmenting by services from the
leading cloud providers to solution and recommend the best next generation data
platform value driven approach for our clients
Your Key Responsibilities Include
Create
and maintain conceptual, logical and physical database models
Document
functional requirements and system specifications into the data architecture
and detailed design specifications for current and proposed designs
Document
and adhere to development standards and best practices in database designs
Maintain
highly effective and consistent communication within the team, peers, and the
leadership team
Reverse
engineer SQL code and modify it to solve problems/issues
Contribute
to the definition and implementation of data governance practices
Design
both data structures and data integration practices
Work
closely with the infrastructure teams to create a physical environment to
support data services
Evaluate
new and existing (internal and external) technologies and services in support
of data services and data analytics objectives
Skills And Attributes For Success
Understanding
of business process reengineering and business modeling concepts, business
systems development and analysis
Hands-on
experience in designing and implementing hybrid cloud and on-prem solutions
Experience
working with the latest versions of SQL Server
Experience
applying SAFe/Scrum/Kanban methodologies
Ability
to exercise judgment in solving technical, operational, and organizational
challenges
Expert
programming, performance tuning and troubleshooting skills, using the latest
popular programming languages for example python
Demonstrate
proactive approach to identifying issues and presenting solutions and options,
and where appropriate, leading to resolution
Minimum Qualifications
5+ years
demonstratable work experience as a Data Architect using data modeling tools
2-3 years
SQL coding experience on large projects
Must
possess expert SQL programming, performance tuning and troubleshooting skills
Create
database objects and SQL scripts
Understand
and developed data pipelines
Know how
to deformalize data for data science models
Experience
in python, spark and notebooks
Experience
designing data warehousing solutions
Experience
designing next generation data platforms utilising cloud services
In-depth
understanding of database structure principles
Seamlessly
able to translate business requirements to technology requirements
What We Look For
Strong
analytical skills and problem-solving ability
A
self-starter, independent-thinker, curious and creative person with ambition
and passion
Excellent
inter-personal, communication, collaboration, and presentation skills
Customer
focused
Excellent
time management skills
Positive
and constructive minded
Takes
responsibility for continuous self-learning
Takes the
lead and makes decisions in critical times and tough circumstances
Attention
to detail
High
levels of integrity and honesty
Curious
about new emerging technology
About EY
As a global leader in assurance, tax, transaction and consulting
services, we’re using the finance products, expertise and systems we’ve
developed to build a better working world. That starts with a culture that
believes in giving you the training, opportunities and creative freedom to make
things better. Whenever you join, however long you stay, the exceptional EY
experience lasts a lifetime.",3.8,"EY
3.8",Johannesburg,-1,10000+ Employees,1989,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Architect - Principal,-1,"We are looking for Principle Data Architect to join our Engineering team in Cape Town.

The world is changing.
We all want something different.
At Luno, we see you as individuals.

Together, we are upgrading the world of work to unleash the potential within and empower you to become the best possible version of yourself.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the financial landscape, and to do so, well we need the best team on board for our mission. In short, to achieve our goals, we need rockstars. As simple as that.

A little about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 5 million customers across 40 countries.
We're part of the Digital Currency Group, a group of companies driving progress in the cryptocurrency and blockchain space that includes Grayscale, Genesis, Coindesk and Foundry Services
Our platform has processed over $8 billion to date
We're proud to be one of the world's most international cryptocurrency teams from 43 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
How we work


Our engineering team (currently ~100 engineers) is split into organisations which we call Fleets. Each Fleet focuses on a core customer journey (onboarding, security, payments, support, new business, growth and marketing etc.). Each of these fleets contains multiple smaller teams called Pods, each of which focuses on a specific aspect of the product.

Pods will include a product owner, product designer, back-end engineers, Android, iOS and Web developers, who each bring a unique perspective to the problem you are all contributing towards.

We're agile, use scrum, continuous integration and continuous delivery, deploying to production every single day.

We're building teams to help us succeed in our mission to upgrade the world to a better financial system. You'll be joining a group of highly motivated software engineers who you'll work collaboratively with across our pods.

As a fast-growing company with offices around the world, you'll immediately see how your contributions directly impact both our internal users and client experience. Many of the problems we are solving result in trail blazing solutions which can't be found on Stack Overflow; so we're looking for engineers who flourish working in a complex domain.

In your first six months, you will:


...start at Luno by learning our processes, meeting the wider team and starting our engineering on-boarding program. After getting comfortable with the basics, you'll start learning our idiomatic patterns in a safe, easy-to-follow way - by building your own toy micro services. You'll get to practice how we do design docs, code reviews, deployments, events, logging and monitoring.

You'll meet the Pod(s) you'll be working with and quickly align on the teams' current OKRs and product roadmap. We succeed as a team, so we will provide you with regular feedback from your manager and peers and will encourage you to do the same.

What you'll do:
Work closely with our data science and platform teams on projects introducing new streams of data into our data lake
You will get to bring new ideas on how to further develop and innovate our data solutions and how to expose that data to the business
Accountable and Responsible for the design and architecture of Data systems that are robust and scalable.
Work in an Agile/Scrum framework or Agile mindset
Data backup/recovery and storage
Pick-up and learn new concepts, in both engineering and product, and be able to apply that knowledge quickly.
The ideal candidate for this role will have:
7+ years' experience in maintaining scalable data solutions and/or you are passionate about it
Ability to understand, communicate and advocate between build vs buy
Proven track record of setting up, restructuring and maintenance of databases
You know your way around ETL and you have experience with SQL
Experience in the AWS Data stack (RedShift,DynamoDB, Amazon RDS)
Familiarity with integrating data stores with BI platforms such as Looker, Tableau, or Power BI
You have experience with the concepts of CI/CD
Coding skills in e.g. Go, Python
Bachelor's degree in a related field preferred
AWS Certified DataOps Administrator
Be friendly, transparent, articulate and driven to succeed
Basic knowledge of and passion for digital currencies like Bitcoin
A work permit for South Africa if you are not a South African citizen
Don't be put off if you don't tick all of the boxes – they're a guide based on what we'd love to see but we appreciate that excellent software engineers have diverse backgrounds.

Remote Life at Luno


If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity / paternity and even (yes, you are reading it correctly) paw-ternity for your furry friend..
Annual Inspiration Day.. like that pottery course you've always been meaning to do!
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. You'll need to hold the legal right to work in South Africa already as we cannot provide visa sponsorship.

Be part of the change!",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer - EC2 Capacity Data Analytics,-1,"EC2 Capacity Data Analytics (CDA) team is looking for a Data Engineer to join our team.

Our team is part of the EC2 Capacity Engineering organization, which is responsible for providing the elasticity EC2 customers need to scale up/down compute resources in a cost-efficient manner. We predict customer usage across thousands of configuration combinations to deliver exactly what our customers require in just the right amount of time with just the right amount of capacity.

As a Data Engineer, you will build the ETL and analytics solutions for our internal customers to answer questions with data and drive critical improvements for the business. You will use best practices in software engineering, data management, data storage, data compute, and distributed systems. On any given day, we use Python, Scala, Java, SQL, Lambda, CloudFormation, Redshift and Glue as well as other public AWS services and a host of Amazon internal tools. We dont expect you to be an expert in, or necessarily even be familiar with all of the technologies listed above, but we do expect you to be excited to learn about them.

This position involves on-call responsibilities, typically for one week every two months. Our team is dedicated to supporting new team members. We care about your career growth, we try to assign projects and tasks based on what will help each team member develop into a more well-rounded engineer and enable them to take on more complex tasks in the future.

Our team values work-life balance and we are flexible when people occasionally need to work from home.

Job Duties
Develop and maintain automated ETL pipelines for big data using languages such as Scala, Spark, SQL and AWS services such as S3, Glue, Lambda, SNS, SQS, KMS. Example: ETL jobs that process a continuous flow of JSON source files and output the data in a business-friendly Parquet format that can be efficiently queried via Redshift Spectrum using SQL to answer business question.

Develop and maintain automated ETL monitoring and alarming solutions using Java/Python/Scala, Spark, SQL, and AWS services such as CloudWatch and Lambda.

Implement and support reporting and analytics infrastructure for internal business customers using AWS, services such Athena, Redshift, Spectrum, EMR, and QuickSight.

Develop and maintain data security and permissions solutions for enterprise scale data warehouse and data lake implementations including data encryption and database user access controls and logging.

Develop and maintain data warehouse and data lake metadata, data catalog, and user documentation for internal business customers.

Develop, test, and deploy code using internal software development toolsets. This includes the code for deploying infrastructure and solutions for secure data storage, ETL pipelines, data catalog, and data query.


Basic Qualifications

· Bachelors degree in Computer Science or related technical field, or equivalent work experience.
· 4+ years of overall work experience including Software Engineering, Data Engineering, Database Engineering, Business Intelligence.
· Experience with AWS technologies stack including Lambda, Glue, Redshift, RDS, S3, EMR or similar big data solutions stack

Preferred Qualifications

· Demonstrate efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data.
· Demonstrable proficiency in distributed systems and data architecture; design and implementation of batch and stream data processing pipelines; knows how to optimize the distribution, partitioning, and MPP of high-level data structures.

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer,-1,"Our client based in Johannesburg is urgently looking for a Data Engineer to be on a 3 months contract
Build data pipelines, experience in new tech like nifi, kafka, python

Joburg based, open to EE, 3 month contract with the option to extend, must be available at short notice",-1,EQplus,Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Overview
Job ID: 51456
Job Sector: Information Technology and Services
Country: South Africa
Region/State/Province/District: Gauteng
Location: Johannesburg

Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose

This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes

Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems

Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions

Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.
Research and best practices

Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development

Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.

Preferred Qualification and Experience

Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry

Knowledge/Technical Skills/Expertise

Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision

PLEASE NOTE: All our recruitment and selection processes comply with applicable local laws and regulations. We will never ask for money or any form of payment as part of our recruitment process. If you experience this, please contact our Fraudline on +27 800222050 or forward to TransactionFraudOpsSA@standardbank.co.za",4.1,"Standard Bank
4.1",Johannesburg,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"About us

At PBT Group we pride ourselves on being a Data Specialist organisation. With 20 years of experience in 27 countries over 3 continents, our team of 550 consultants have implemented more than 700 projects.",4.3,"PBT Group
4.3",Johannesburg,-1,Unknown,-1,Company - Private,Accounting,Accounting & Legal,Less than $1 million (USD),-1
Data Engineer,-1,"Kick-start your career in the online gaming world and experience the very latest in technology and innovation.

The Department:

Our mission is to provide our customers with the best online betting experience and share the thrill of gaming with them. Data is at the very heart of our business and is vital in everything we do.

Our cross-functional Data team has a big and exciting challenge ahead. We are in the process of re-platforming our traditional, on-premises RDBMS environment to a new microservice architecture in the cloud. We’re making use of the diverse set of data technologies in Microsoft Azure to offer new services, reporting structures and real-time data pipeline while serving the day-to-day requirements of a rapidly growing, data-hungry organisation.

Purpose of the Role:

This is an excellent opportunity for an individual who is looking to gain new skills. We are committed to creating a culture of learning and regularly run proof of concepts, provide internal demos, manage workshops and attend external conferences. Our data team has a wide range of skills including development for highly transactional RDBMS systems, data warehousing, data science and cloud technologies and we are always working to raise everyone’s game.

Duties include, but not limited to:

Work as part of an agile Data Engineering Team
Development of greenfield projects in Azure
Develop and maintain on-premises RDBMS/DW systems
Create robust ETL services and real-time data pipelines
Build and maintain Continuous Integration and DevOps pipelines
Test-driven development and pair programming with colleagues

Essential Criteria:

C#, .Net, Visual Studio
Git, Azure DevOps
NoSQL development (CosmosDB)
Demonstrable understanding of MS SQL Server in a highly transactional environment
Demonstrable understanding of development in Microsoft Azure
Able to understand query plans and identify performance bottlenecks
Test/Business-Driven Development
Building Continuous Integration/Deployment pipelines
Communicate effectively with both technical and non-technical stakeholders

Desirable Criteria:

Implementing Data Storage and Processing solutions in Azure (ARM Templates, Storage Accounts, Data Lake Storage, SQL DB, Cosmos DB, EventHubs, Function Apps, Log Analytics, Data Factory, Databricks, Polybase)
Implementing Security, Disaster Recovery, High Availability, Auditing, Monitoring and Alerting solutions in Azure
Automating tasks in Azure using Powershell / CLI
Predicting costs and optimizing spending in Azure
Message Queues (RabbitMQ, Kafka)
Python

Person Specifications:

Resilience
Teamwork
Technical Knowledge
Communication skills
Stress Tolerance
Please note we will apply relevance to our Talent Management and Talent Development Programme as part of our recruitment process.
Shortlisted candidates may need to complete an assessment.
This position requires trust and honesty it has access to customers financial details - therefore a credit and criminal record check will be conducted. The qualifications identified herein are an inherent job requirement; therefore, a qualification verification check will be done. By applying for this role, and supplying the necessary details, you hereby grant us permission to apply for these checks. This will be done in a confidential manner, and solely for the purposes of verification.

To view all current vacancies, please visit our website, www.digioutsource.com

Should you not hear from us within 2 weeks, please deem your application as unsuccessful.

The perfect place to work, play and grow!",3.9,"Digital Outsource Services
3.9",Cape Town,-1,1001 to 5000 Employees,1997,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
Data Engineer,-1,"At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes

Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.

Key Responsibilities

Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.

Key Traits

Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern

Position Requirements

2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.

Where will you work? This role will be based out of Durbanville, South Africa.",3.1,"Aculocity, LLC
3.1",Durbanville,-1,1 to 50 Employees,2006,Company - Private,IT Services,Information Technology,$1 to $5 million (USD),-1
Data Engineer,-1,"ENVIRONMENT:

A rapidly growing E-Commerce Platform seeks a highly talented Data Engineer to make an invaluable contribution to data democratisation and literacy vision by making accessible and easy-to-use data products and tools. You will require a Comp-Sci Degree or 3 years’ relevant industry experience, MySQL, PostgreSQL, Java, Python, in-depth understanding of OLAP, Data Marts, Star Scheme, Snowflake, be familiar with Jenkins, Travis, Circle CI, Docker, Kubernetes, experience with Kafka, Pub/Sub, Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks & significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing & Data Lake design and implementation and Lambda/Kappa architectures.

DUTIES:

Design, develop, test and maintain data architecture.

Prepare data for descriptive, predictive and prescriptive modelling.

Automate repetitive tasks and manual processes related with the data usage.

Optimize data delivery.

Design, develop and test large stream data pipelines to ingest, aggregate, clean, and distribute data models ready for analysis.

Ensure the highest standard in data integrity.

Leverage best practices in continuous integration and delivery.

Collaborate with other engineers, ML experts, analysts, and stakeholders to produce the most efficient and valuable solutions.

Implement features, technology, and processes that move us towards industry best practices, improving on scalability, efficiency, reliability, and security.

Operations and ownership of systems in production, responding to incidents.

REQUIREMENTS:

Qualifications –

Comp-Sci Degree or 3 years relevant industry experience.

Experience/Skills –

Open source relational database systems e.g. MySQL, PostgreSQL, etc.

Significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing, and Data Lake design and implementation and Lambda/Kappa architectures.

A thorough understanding of database and data warehousing principles e.g. OLAP, Data Marts, Star Schema, Snowflake, etc.

Java and Python.

Familiar with CI/CD tools such as Jenkins, Travis, Circle CI, etc.

Experience with Kafka, Pub/Sub, or other event-based systems.

Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks, etc.

Working in cloud environments and with containerisation frameworks, tools and platforms e.g. Docker, Kubernetes, GKE, etc.

A deep understanding of data pipelining, streaming, and Big Data technologies, methods, patterns, and techniques.

Troubleshooting complex database operations and performance issues.

Automating tasks using Shell Scripting or writing small applications.

ATTRIBUTES:

Works well with people and is passionate about helping people be their best.

A team player, an active listener, mentor, and able to communicate well.

Shows solid reasoning and decision making, with the ability to work under pressure.

Is passionate about technology, systems and data.

Is curious, always learning, and keeping up to date with the industry.

While we would really like to respond to every application, should you not be contacted for this position within 10 working days please consider your application unsuccessful.

COMMENTS:

When applying for jobs, ensure that you have the minimum job requirements. Only SA Citizens will be considered for this role. If you are not in the mentioned location of any of the jobs, please note your relocation plans in all applications for jobs and correspondence.",-1,Datafin IT Recruitment,Cape Town,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Cartrack is looking for passionate data science and engineering candidates that can join a growing team that is responsible for the intelligence and efficiency solution provision to over a million subscribers, many of whom are large fleets. We are in the midst of creating revolutionary platforms that will change the way that people interact with their vehicles.

You will have the opportunity to work with the very brightest global subject matter experts that are transforming the automotive industry across Fleet Management, Asset Management and Insurance Telematics solutions.

Get to know the role:

The role of a data engineer is a supporting one, but it is also an extremely vital one. As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements. We want to see candidates with mechanical tendencies and a desire to know how things work and to improve them.

The day-to-day activities:

Design, construct, install, test and maintain data management systems.
Build high-performance algorithms, predictive models, and prototypes.
Ensure that all systems meet the business/company requirements as well as industry practices.
Integrate up-and-coming data management and software engineering technologies into existing data structures.
Develop set processes for data mining, data modeling, and data production.
Create custom software components and analytics applications.
Research new uses for existing data.
Employ an array of technological languages and tools to connect systems together.
Install/update disaster recovery procedures.
Recommend different ways to constantly improve data reliability and quality.
Work on and maintain Data pipelines.

Requirements Essential:

At least 5 years’ proven experience as a Data Engineer, DevOps Engineer, Software Developer, or similar.
Proficient in Linux/Unix and shell scripting as well as in functional programming languages.
Expertise in setting up and explored with technologies such as Hadoop and Spark.
Bachelor’s degree in computer science, software/computer engineering, applied mathematics, or physics.",3.3,"Cartrack
3.3",Johannesburg,-1,501 to 1000 Employees,2004,Company - Private,Security Services,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Data Engineer,-1,"Data Engineers build and support data pipelines and datamarts built off those pipelines. Both must be scalable, repeatable and secure. The Data Engineer helps to facilitate gathering data from a variety of different sources, in the correct format, assuring that it conforms to data quality standards and assuring that downstream users can get to that data timeously. This role functions as a core member of an agile team. These professionals are responsible for the infrastructure that provides insights from raw data, handling and integrating diverse sources of data seamlessly. They enable solutions, by handling large volumes of data in batch and real-time by leveraging emerging technologies from both the big data and cloud spaces. Additional responsibilities include developing proof of concepts and implements complex big data solutions with a focus on collecting, parsing, managing, analysing and visualising large datasets. They know how to apply technologies to solve the problems of working with large volumes of data in diverse formats to deliver innovative solutions. Data Engineering is a technical job that requires substantial expertise in a broad range of software development and programming fields. These professionals have a knowledge of data analysis, end user requirements and business requirements analysis to develop a clear understanding of the business need and to incorporate these needs into a technical solution. They have a solid understanding of physical database design and the systems development lifecycle. This role must work well in a team environment.

Job Objectives

Work Complexity: * Architects Data analytics framework. * Translates complex functional and technical requirements into detailed architecture, design, and high performing software. * Leads Data and batch/real-time analytical solutions leveraging transformational technologies. * Works on multiple projects as a technical lead driving user story analysis and elaboration, design and development of software applications, testing, and builds automation tools.

Main Job Objectives: 1. Development and Operations 2. Database Development and Operations 3. Policies, Standards and Procedures 4. Communications 5. Business Continuity & Disaster Recovery 6. Research and Evaluation 7. Coaching/ Mentoring

Qualifications

Essential: 4 years Bachelors degree in computer science, computer engineering, or equivalent work experience AWS Certification at least to associate level

Experience

Essential:

5+ years Data engineering or software engineering

3-5 years demonstrated experience leading teams of engineers

2+ years Big Data experience

5+ years experience with Extract Transform and Load (ETL) processes

2+ years Could AWS experience

At least 2 years demonstrated experience with agile or other rapid application development methods - Agile exposure, Kanban or Scrum

5 years demonstrated experience with object oriented design, coding and testing patterns as well as experience in engineering (commercial or open source) software platforms and large scale data infrastructures.

Desirable:

5+ years Retail Operations experience

Knowledge and Skills

Essential: *Creating data feeds from on-premise to AWS Cloud (2 years) *Support data feeds in production on break fix basis (2 years) *Creating data marts using Talend or similar ETL development tool (4 years) *Manipulating data using python and pyspark (2 years) *Processing data using the Hadoop paradigm particularly using EMR, AWSs distribution of Hadoop (2 years) *Devop for Big Data and Business Intelligence including automated testing and deployment (2 years) * Extensive knowledge in different programming or scripting languages * Expert knowledge of data modeling and understanding of different data structures and their benefits and limitations under particular use cases.

Further technical skills required: * Capability to architect highly scalable distributed systems, using different open source tools. * Big Data batch and streaming tools * Talend (1 year) * AWS: EMR, EC2, S3 (1 year) * Python (1 year) * PySpark or Spark (1 year) - Desirable * Business Intelligence Data modelling (3 years) * SQL (3 years)",-1,Datonomy Solutions,Brackenfell,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We are assisting one of our clients that is based in Pretoria to fill a role of a Data Engineer

This is a 12 month contract role

Objective of this Scope of Work

The Data Engineer will drive improvement of the data management maturity levels and provide the necessary technical support within the company to support reliable and effective decision-making, appropriate usage and protection thereof.

Scope of Services Definition

The scope will include but will not be limited to:

ï†· To develop, construct, test and maintain architectures.

ï†· To ensure architectures will support the requirements of business.

ï†· To discover opportunities for data acquisition and sharing.

ï†· To develop data set processes for data modelling, mining and production.

ï†· To employ a variety of languages and tools to marry systems together.

ï†· To recommend way to improve data reliability, efficiency and quality.

ï†· To prepare data for use in predictive and prescriptive modelling.

ï†· To conduct research to answer industry and business questions.

ï†· To leverage volumes of data from internal and external to answer business questions.

ï†· To develop and manage stakeholder relations effectively to promote data management across the organisation and support reliable decision making and appropriate data usage.

ï†· To participate and provide technical support in cross organisational activities relating to any of the above mentioned data management activities.

ï†· To provide regular progress reports as per stakeholder requirements and present data management updates in various forums as required.

Minimum qualification Required:

ï†· A minimum of a Bachelors degree in Computer Science or Information Management OR equivalent;

ï†· A minimum of five to eight years experience in a data management environment",-1,HR Genie,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Our client based in the Northern Suburbs, is currently looking for a Data Engineer to join their team.

Responsibilities
Our client is a dynamic IT company that delivers value-driven IT solutions to the group. Our work lives revolve around our DNA. We take pride in our work, treat our colleagues, partners and our country with respect. We exercise collaborative decision-making and believe in having a balance in life. We do this all while having fun and enjoying what we do.

The primary focus of this position is to use technical skills to put software, systems and data together in a way that extracts meaningful insights from raw data. You will need to be helpful and supportive to your team and fellow developers. You join an energetic, focused and dynamic team.

Interact with clients to understand requirements and business problems/needs

Identify, analyse, visualise and understand supporting data to propose solid solutions

Create technical documentation for reference and reporting

Support existing solutions within GCP and Oracle

Doing standby on a rotating basis

Key Competencies and Qualifications

Matric

Tertiary qualification in IT

Preferred cloud experience in AWS/AZURE/GCP

At least 3 years of data warehouse ETL experience

Dimensional Modelling

Data analyses

Experience with data visualization and visualization tool(s)

Knowledge of the retail industry will be beneficial

Understanding and experience with version control SVN/GIT

Preferred – Korn shell scripting, Python/Java, SQL

Google Cloud Platform experience would be looked upon favourably

Having a broad understanding of different SDLC’s

Preferred agile experience

Strengths

The natural tendency to take ownership and responsibility

Strong problem solving, critical thinking, effective planning and organisational skills

Detail-oriented with excellent communication skills

You have a can-do attitude and positive outlook on life

Can cope under pressure

Curious and interested in analysing problems and possible solutions

Strong team player

Self-driven learner, passionate about new technology

Above all, be passionate about what you do

Should you wish to apply for the position, please apply directly via this job board, please ensure that you quote reference number 201620 subject heading or email body.

Please note that due to the high volume of CV's received; only shortlisted applicants will be contacted. Should you not receive communication from our offices within two weeks of submission please note that your application will not be considered for this position.

We will keep your CV on file and re-establish contact with you should opportunities in line with your expertise become available again.

Should you require any additional information give us a call on 021 012 5566.",-1,Surgo HR & Training,Cape Town,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We believe that our employees fuel our organization, essential to enable us to help our customers overcome their business challenges and achieve sustainable growth. As a result, we are committed to growing each individual and providing them with the challenges, feedback and support needed to achieve success in their career

If this sounds appealing, and like us, you get excited about data: its collection, storage, transformation or display, see if you’ve got what it takes to join our sought after DATA team.

Key Responsibilities And/or Outputs

You will represent IQbusiness at our customers, sometimes alone, and sometimes as part of an IQ team.

Providing a superior customer experience by building and maintaining relationships, working at customer offices, keeping data confidential
Design and develop – databases, SQL queries, stored procedures, reports, dashboards or integration solutions
Produce solutions for both real-time and batch environments
Test your work to ensure compliance
Solve problems, and do root cause analysis
Prioritize your workload
Assist in other areas relating to your true data function, such as data modeling, data and business analysts
Interact with a variety of individuals: senior, junior, technical and from business
Provide guidance to fellow colleagues, or even manage a team
Uphold the IQ values, which are to care, learn & share; innovate; deliver as well as to build, enhance and maintain relationships

Education

Matric pass
A tertiary qualification, preferably in an ICT relevant field
Appropriate Microsoft certifications are beneficial but not required

Requirements

3 - 6 years experience in the Data Engineering environments and technologies
Great communication skills
A passion for SQL, databases or reports
Can you write stored procedures, design complex queries and create views and triggers?
Are you able to work out the relationships in a data warehouse or the aggregation of a cube?
Do you extract and display useful information when you see patterns and trends in data?
Strong knowledge of the financial services industry, ideally in a consulting role
The use of data related software: databases, ETL and BI tools; report writing and analytical tools
We use a lot of Microsoft products. You may often be expected to use MS SQL Server, SSIS, SSRS, SSAS and Power BI to develop solutions
What other relevant software have you’ve used?
Ability to work in different project methodologies: Waterfall and/or Agile
Knowledge of full SDLC
Exposure to logical and physical data modeling

Equal Employment Opportunity

IQbusiness is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, citizenship, marital, domestic or civil partnership status, sexual orientation, or gender identity",3.7,"IQbusiness South Africa
3.7",Johannesburg,-1,1 to 50 Employees,-1,Company - Private,Consulting,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"We value a data engineer as someone who works behind the scenes to obtain, process and supply data via various methodologies and technologies, to various consumers, in ways and forms that makes sense and add value. This definition is very broad, as the field of data engineering is just as broad.

You may be the type of data engineer that develops API endpoints for the consumption of data by end users or even another data pipeline, or you may be the type of data engineer that develops highly distributed, high availability data processing pipelines in an effort to satisfy the need of the ever questioning data analysts and/or data scientists.

You have awesome knowledge about the following concepts
Data modelling
Relational data modelling in traditional relational database management systems. (Microsoft SQL Server, MySQL, PostgreSQL, etc)
Coercing unstructured and semi-structured data into a structured form.
Data pipelining knowledge - data extraction and transformation.
Data transformation knowledge for reporting and analytics purposes.
Knowledge of the MapReduce and related data processing paradigms would be a boon.
You have the following technical competencies
Writing SQL queries, that can relate, transform and aggregate data from many differing sources where natural keys may or may not exist.
Experience with writing data pipelines that move and transform data, for various uses.
Working knowledge of a general purpose programming language like Python would be a boost.
Working knowledge of columnar databases such as Google BigQuery, and SAP HANA would be a boost.
Working knowledge of highly distributed technologies such as Apache Hadoop or Apache Spark would be a boost.
Working knowledge of NoSQL technologies, such as Apache Solr would be a boost.
You have the following personal competencies
The ability to solve problems.
The ability to rotate around a problem, to see if solutions can be gained in different ways.
The ability to work in an ever changing, unstructured environment.
The ability to work as part of a team, with vastly differing skill sets and opinions.
The ability to contribute ideas to the quorum.
The ability to mentor and provide guidance for other team members.
A systems approach to thinking, as opposed to a siloed approach. The candidate needs to understand how their work affects the greater system.
The ability to work without supervision, and take accountability for the work they deliver.
The ability to liaise with a client, sifting through the fluff and extracting the actual requirements.
If this is you - apply now and we'll get in touch",-1,DotModus,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Data Engineer

Our client in the contact centre space is currently seeking a DATA ENGINEER that will work on the collecting, storing, processing, and analyzing of large datasets. The primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them. You will also be responsible for integrating them with the architecture used across the company.

Key Performance Areas:

Data reporting.
Implementing ETL processes.
Defining data retention policies.
Management of Customer Lead data.
Provision of data for advanced analytics.
Maintenance of internal client scorecards.
Assist team in resolving data-related support queries.
Optimize existing data processes through automation.
Assist with all data-related reporting and documentation.
Maintenance and optimisation of the Analytics database.
Provide technical support to and supervision of junior data administrators.
Continuous upskilling on new technologies, frameworks and market trends.
Monitoring performance and advising any necessary infrastructure changes.
Identifying, selecting and integrating any Big Data tools and frameworks required to provide real-time analytics.

Educational Requirements

IT related Degree or Diploma is a pre-requisite

Required Skills/Experience

ETL tools: Advanced SSIS
BI/Reporting : Qlikview/Power BI/ SSRS or SSAS
Programming languages: JAVA, C# , Python, SAS or R
Experience with NoSQL databases and/or campaign management tools will be advantageous.
Minimum 3 years’ applicable work experience in SQL, relational databases and data manipulation.
Experience in big data platforms (eg. Hadoop) or processing frameworks (eg. MapReduce/Spark) and querying tools (eg. Pig, Hive and Impala) will be highly beneficial.

Preferred Skills

Organizational skills
Experience in Attentional to detail.
Accountability is critical for this role.
Ability to work under pressure and meet deadlines.
Solid understanding of database design principles.
Should you not receive a response in 2 weeks please consider your application unsuccessful",-1,Rubik's Cubed Consulting,Durban,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"This well known company is looking for a Data Engineer. will be based in Rivonia
The ideal candidate will have strong experience in the following:
Data cleaning
SQL Export
Big data Sets

BSc Degree in Maths and Stats will be required
a min of 3 years experience.
Stable track record is required.

Send your Cv to marinda@prrrecruitment.co.za",-1,PRR Recruitment Services,Johannesburg,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Description

Position at Aculocity, LLC

At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes
Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.
Key Responsibilities
Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.
Key Traits
Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern
Position Requirements
2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.
Where will you work? This role will be based out of Durbanville, South Africa.",-1,GVW,Durbanville,-1,Unknown,-1,Unknown,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Information Technology, Gauteng JHB - Northern Suburbs

Market related - Market related Annually

An IT Consultancy Business based in Johannesburg is currently looking for a Business Intelligence Consultant / Data Engineering Consultant.

Requirements:

Extensive experience in data engineering
Experience in Business Intelligence, data and Power BI
Extensive experience in data governance and the Popi act
Ability to assess and make recommendations on data within the Popi act
Good understanding of T-SQL and query optimization, developing ETL strategies.
Good understanding with SQL Server 2008/2012, SSIS, SSRS and SSAS
Use SSIS to create ETL packages to validate, extract, transform, and load data into the data warehouse and data marts.
Deploy and configured the reports in the Report Server (SSRS).
Excellent experience in Tabular Modelling , PowerView, Qlikvie,w, and Power BI
Maintain ETL
Qlikview model
Create Drill-through, Drill-down, and Cross Tab Reports and Sub-Report using Report Definition Language (RDL).
Generate periodic reports based on the statistical analysis of the data using SQL Server Reporting Services (SSRS)
Advise and provide written technical documentation and recommendations

The information displayed above is not limited to advertisements. Please contact Thato for further information.

Please consider your application as unsuccessful if you have not received a response within 14 days of submitting your application. However, please keep a lookout on our website, www.bedifferent.co.za, for available positions that you may be suited for

Ad Visible Until: 29 October 2020
Ref: JHB005346/NL

Vacancy Type: Permanent",2.9,"Be Different Recruitment
2.9",Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Cloud Support Engineer (Big Data),-1,"ABOUT US

Amazon Web Services is the market leader and technology forerunner in the Cloud business. As a member of the AWS Support team you will be at the forefront of this transformational technology, assisting a global list of companies and developers that are taking advantage of a growing set of services and features to run their mission-critical applications. As a Cloud Support Engineer, you will act as the Cloud Ambassador across all the cloud products, arming our customers with required tools & tactics to get the most out of their Product and Support investment.

Would you like to use the latest cloud computing technologies? Do you have an interest in helping customers understand application architectures and integration approaches? Are you familiar with best practices for applications, servers and networks? Do you want to be part of a customer facing technology team helping to ensure the success of Amazon Web Services (AWS) as a leading technology organization?

If you fit the description, you might be the person we are looking for! We are a group of smart people, passionate about cloud computing, and believe that world class support is critical to customer success.

WHAT CAN YOU EXPECT FROM A LIFE AT AWS?

Every day will bring new and exciting challenges on the job while you:

· Learn and use groundbreaking technologies.
· Apply advanced troubleshooting techniques to provide unique solutions to our customers' individual needs.
· Interact with leading engineers around the world.
· Partner with Amazon Web Services teams to help reproduce and resolve customer issues.
· Leverage your extensive customer support experience to provide feedback to internal AWS teams on how to improve our services.
· Drive customer communication during critical events.
· Drive projects that improve support-related processes and our customers technical support experience.
· Write tutorials, how-to videos, and other technical articles for the developer community.
· Work on critical, highly complex customer problems that may span multiple AWS services.

WHY AWS SUPPORT?

· First and foremost this is a customer support role in The Cloud.
· On a typical day, a Support Engineer will be primarily responsible for solving customers cases through a variety of customer contact channels which include telephone, email, and web/live chat. You will apply advanced troubleshooting techniques to provide tailored solutions for our customers and drive customer interactions by thoughtfully working with customers to dive deep into the root cause of an issue.
· Apart from working on a broad spectrum of technical issues, an AWS Support Engineer may also coach/mentor new hires, develop & present training, partner with development teams on complex issues or contact deflection initiatives, participate in new hiring, write tools/script to help the team, or work with leadership on process improvement and strategic initiatives.
· Career development: We promote advancement opportunities across the organization to help you meet your career goals.
· Training: We have training programs to help you develop the skills required to be successful in your role.
· We hire smart people who are keen to build a career with AWS, so we are more interested in the areas that you do know instead of those you havent been exposed to yet.
· Support engineers interested in travel have presented training or participated in focused summits across our sites or at specific AWS events.
· As we operate on a follow-the-sun model, with Premium Support sites located globally, there is no after hours on-call or mandated overtime in this role.
· https://www.youtube.com/watch?v=GC3bWcFFZTo&t=24s



Basic Qualifications

The Big Data role supports our services that leverage data and produce business insights, which may include using Machine Learning/Artificial Intelligence (ML/AI). Helping our customers use and integrate Big Data services in what is arguably our industrys most exciting space. The portfolio of services covers EMR (Hadoop), DynamoDB (NoSQL), MangoDB, and Apache Cassandra.

· Advanced experience in Apache Hadoop, Apache Spark, Apache Hive, and Presto
· Advanced experience in DynamoDB or NoSQL technologies like MongoDB or Cassandra
· Advanced experience with System Administration with Linux (RHEL/CentOS) including Microsoft Active Directory, and LDAP integration.
· Experience with troubleshooting Kerberos Authentication problems.
· Experience with Network troubleshooting.
· Basic understanding of Machine Learning and statistics
· Experience with Java and Python and shell scripting
· Bachelors degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position



Preferred Qualifications

· Expert experience in the Hadoop Ecosystem including Apache Spark and Presto
· Expert experience in NoSQL
· Expert experience with blockchain technologies like Etherium Expert experience in data Data Lake architecture and administration
· Experience managing full application stacks from the OS up through custom applications
· Prior work experience with AWS - any or all of EC2, VPC, S3, RDS, EMR, Glue, SageMaker
· Excellent knowledge of Hadoop architecture, administration and support
· Expert understanding of distributed computing principles and their application in the cloud
· Good understanding of distributed computing environments Lead technical discussions on big data systems architecture and design
· Strong analysis and troubleshooting skills and experience
· AWS Certified Solutions Architect
· AWS certified Big Data Specialty
· Masters degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity and Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Response Center Engineer,-1,"Job Title
Response Center Engineer
Job Description


Philips is a world leading health technology company with a vision to make life better for people worldwide through meaningful innovation. Making good on this promise depends on our passionate, inspirational, collaborative and diverse team. We have over 80,000+ brilliant people around the world but are always looking for more. Like-minded, motivated, focused minds to join us in creating a healthier, more connected society while transforming themselves personally and professionally.

As a CCC Coordinator - Response Center Engineer you will have the opportunity to process customer calls and be responsible for screening and diagnosing professionally Healthcare equipment to support customers and colleagues remotely with solving technical issues and ensuring maximum customer satisfaction

You are responsible for:
Diagnose healthcare equipment to the quality standards set by Philips Healthcare (PH) remotely by interviewing customers or colleagues by telephone or by remotely logging in to the system
Advise Customer Care Center Coordinators and District Operations Managers and / or Team Leads about the best follow-up w.r.t. technical state of the diagnosed healthcare equipment
Advise the Customer Care Center Coordinators or Field Services Engineers about required spare parts and resources
Responsible for planning engineers related to Modality responsibility.
Responsible for coordination between CCC, CUSTOMER, Spare parts AND Engineer.
Responsible to drive Remote and FTR KPI’s to targets respectively 40% and 85%.
Will require minimal field work to keep abreast of technical capabilities.
Take calls from customers and make sure they are processed in the CCC ERP on timely manner including all relevant data
Support Field Services Engineers in the field with technical knowledge
Escalate technical issues to the Technical Support Specialist
Escalate technical issues to Business Unit support after consultation of the Technical Support Specialist
Monitor critical functions of the equipment’s in the IB and environmental conditions including RSN and True reachability.
Lead the planning and implementation of FSN’s and FCO’s accelerating remote implementation where applicable.
Submit timely and accurate service data, job sheets, reports, expense claims, radiation film badges, field problem reports and other paperwork as assigned
Keep abreast of new technologies likely to affect PH range of products
Use company property with care to ensure optimal results with minimal operational costs
Be a professional representative for PH with respect to customer problems, ensuring personal acceptability by the customer in behavior in accordance with PH policy and targets
Conform to PH safety standards including health and safety regulations and in the event of hazards or accidents to take immediate control of the situation and involve the Operations Manager and / or the responsible person to handle properly confidential issues according Philips standards and to act according General Business Principals
Follow all quality standards within the frame of valid PH business policies
Follow the company quality regulations (ISO 9001; PQA; TQM) and internal directives and procedures
You are a part of the dynamic South Africa Customer Care Centre Team .You will be reporting to the Customer Care Center Manager.

Requires a pleasant, assertive individual you can work very well in a team setting, a dynamic environment that requires flexibility and creativeness to achieve goals.

To succeed in this role, you should have the following skills and experience:
Degree level education or equivalent
Experience in maintenance and troubleshooting of technical complex systems
Fluent in English, verbal and written in addition to local language
In return, we offer you the unique combination of a critical and challenging role and a creative and empowering office environment. You will be actively encouraged to make improvements, establish best in class service and have a direct impact on the success of Philips on a daily basis.

Employment Equity

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply. Only apply for this role if you are a South African Citizen by birth or Naturalization prior to the 27 April 1994.

Why should you join Philips?

Working at Philips is more than a job. It’s a calling to create a healthier society through meaningful work, focused on improving 3 billion lives a year by delivering innovative solutions across the health continuum. Our people experience a variety of unexpected moments when their lives and careers come together in meaningful ways. Learn more by watching this video.

To find out more about what it’s like working for Philips at a personal level, visit the Working at Philips page on our career website, where you can read stories from our employee blog. Once there, you can also learn about our recruitment process, or find answers to some of the frequently asked questions.

Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.9,"Philips
3.9",Johannesburg,-1,10000+ Employees,1891,Company - Public,Health Care Services & Hospitals,Health Care,$10 to $25 million (USD),-1
Software Development Engineer - EC2 Placement,-1,"Build the systems that optimize how EC2 matches requests for Instances with the underlying compute capacity. EC2 Placement is seeking talented engineers to build the online and offline optimization systems for compute workload scheduling, and the customer capabilities to better manage those workloads. Amazon EC2 provides on-demand scalable compute capacity, and powers some of the largest services in the world. You will collaborate with a top-tier community of engineers to build systems to improve how customers are able to access EC2 compute resources.

The successful candidate will have strong software engineering experience, with a passion for thinking about, building and testing distributed systems. You have an interest in how Machine Learning and other optimization techniques can be applied to large-scale problems. You have demonstrated experience working with a team to design, build and operate large-scale systems. With strong engineering fundamentals, an analytical and data-driven approach to your work, and strong communication skills, you have the ability to collaborate well to deliver results. We move fast and work together on small teams to solve big problems.

If this opportunity sounds interesting, we would love to talk to you more about our work and the vibrant culture at AWS in Cape Town.

Basic Qualifications

· Degree in Computer Science or related field, or equivalent working experience
· 3+ years of industry experience in a software development environment
· Strong Computer Science fundamentals, including data structures, object-oriented design, algorithm design, problem solving, and complexity analysis.
· Proficiency in at least one modern programming language, such as Java, C#, Python, Scala, Kotlin

Preferred Qualifications

One or more of the following help you stand out:
· Demonstrated results designing, building and operating high-performance distributed systems in large-scale Linux environments
· Role model in writing high-quality, maintainable and secure code, mentoring others, and helping teams sharpen their development processes
· Ability to work effectively across teams to deliver results, with strong verbal and written communication skills
· Experience working with machine learning systems

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer - PBB IT,-1,"Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose


This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes
Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems
Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions
Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.

Research and best practices
Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development
Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.
Preferred Qualification and Experience
Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Aws Data Platform Engineer,-1,"Aws Data Platform Engineer

Posting Country:

South Africa

Date Posted:

15-Oct-2020

Full Time / Part Time:

Full Time

Contract Type:

Permanent

Joining Vodacom is more than a job, what we do matters. We don’t just carry minutes, texts and data – we carry people’s lives. And that’s a huge responsibility. If you think for a minute about the people you rely on…the likelihood is they rely on us.

Customers are at the heart of everything we do and we want to make a difference to the lives of our customers, and the communities in which we live and work. We support our people to give something back to the causes that mean the most to them through helping them give time and money to the charities they love.

And what’s it like to work here? We have created an environment where you can look forward to coming to work and are empowered to be at your best. We offer flexibility in how you work that helps you do your job in a way that suits you, opportunities to help you grow and progress throughout your career and a choice of benefits to suit your lifestyle.

Role Purpose
The H Band AWS Data Platform Engineer position is based within the Technology Business Unit.

The AWS Data Platform Engineer will be responsible for all Database services such as RDS, DynamoDB, etc. Should be able to migrate any databases from anywhere to AWS using any third-party tools or AWS database migration tool. Should also have understanding or expertise in creating data warehouses and data lake solutions on AWS.
Your responsibilities will include:
Apply practical knowledge of relational database design and usage with customers
Perform workload analysis and undertake performance tuning, as well as performance benchmarking in customer environments.
To develop state of the art solutions which are technically sound.
To provide a high-quality service to the Enterprise Cloud Services clients i.t.o. consultancy, solutions and delivery.
Commitment to team success and positive team dynamics including mentoring of other team members.
Passion for growing and applying technical skills in service to customers.
Be a trusted infrastructure advisor by providing objective, practical and relevant ideas, insights and advice.
Work collaboratively with consulting partners and technology teams to ensure high quality of solution delivery.
Encourage best practice and knowledge sharing with partners and cross-functional groups
Manage the overall database design and delivery of solutions.
Ability to make recommendations as they pertain to improvements in support/development initiatives and facilitate implementation with partners and cross-functional groups within the Business.
Participate in high level database solution definition and design during the implementation phase with the goal of providing reliable, stable and operationally sound applications that meet the Business requirements.
Ability to understand and translate business requirements into technical specifications
The ideal candidate will have:
A minimum of 3 years of industry related experience of which 1 year must be within a complex hosting environment.
Certifications in Database design, system architecture or cloud technologies.
Demonstrate knowledge of database systems internals including storage layouts and distributed databases/MPP architectures
Advanced SQL coding, tuning and query optimization.
Experience designing and leading database performance benchmarks.
Good knowledge of the different AWS services
Knowledge of cloud networking architecture, cloud operations, security, automation and orchestration.
Knowledge of database internals as it relates to query and system performance and tuning.
Understanding of overall system architecture, scalability, reliability, and performance in a database environment.
Excellent teamwork, time-management and organizational skills.
Perform other duties as deemed necessary and assigned by the customer and management
Strong interpersonal skills and problem-solving abilities.
Excellent documentation, communication and interpersonal skills.
Excellent analytical and problem-solving abilities.
Closing date for applications: Monday, 13 April 2020

The base location for this role is Vodacom World, Midrand

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply.
Vodacom is committed to an organisational culture that recognises, appreciates and values diversity & inclusion.

Commitment from Vodacom

Vodacom is committed to attracting, developing and retaining the very best people by offering a flexible, motivating and inclusive workplace in which talent is truly recognized, developed and rewarded. We believe that diversity plays an important role in the success of our business and we are committed to creating an inclusive work environment which respects, values, celebrates and makes the most of people’s individual differences - we are not only multinational but multicultural too. At Vodacom you will have access to our excellent flexible benefits programme that you would expect from any global company.",3.9,"Vodafone
3.9",Midrand,-1,10000+ Employees,1982,Company - Public,"Cable, Internet & Telephone Providers",Telecommunications,$10+ billion (USD),-1
Data Engineer Azure Data Factory,-1,"Enthuzex is looking for a motivated Lead Data Engineer to contribute towards the success of our Data and Analytics Technology initiatives. This is a hands-on technical role and this person will be responsible for the development and build of scalable solutions as it relates to the architecture strategies, data standards, digital data management, data integration, tools, and technology. The right candidate will play a deep dive hands-on critical development role in the digital transformation and in shaping how we acquire, ingest, transform and deliver data through the digital consumer channels.

Responsibilities:

Architect, design, develop and engineering end-to-end data pipelines across multiple data sources and systems of record.
Ensure data quality, integrity, security and completeness throughout the data lifecycle
Develop, design data models, data structures and ETL jobs for data acquisition and manipulation purposes
Develop deep understanding of the data sources, implement data standards, maintain data quality and master data management
Developing data services and API
Work closely with the cloud service providers to ensure completeness and alignment with the service offerings
Manage and maintain cloud based data and analytics platform
Deep understanding of the cloud offerings and engage in quick proof of concepts and proof of value in prototyping data and analytics solutions and derive viability
Ability to interact with the business stakeholders to understand requirements and translating into technology solutions

Expirience:

Experience in Cloud platform AWS or Azure eco-system. (Azure preferred)
Data Engineering/Development experience with SQL (Oracle, SQL Server, MySQL)
Strong development background creating pipelines and complex data transformations and manipulations using one of the languages Python, Java, R, or Scala with Databricks/Spark
Experience in NoSQL Databases and Big data technologies including Hadoop
Experience with API / RESTful data services
Worked on real-time data capture, processing and storing using technologies like Azure Event Hubs and Analytics
Experience working with different data storage options including AWS S3, Azure BLOB storage etc.
Understanding of different data formats including Parquet, Avro, CSV, ORC etc.
Prior experience with MPP databases and maintain large amount of data processing
Experience with Azure Data Factory and Azure Data Catalog is a big plus and mandatory
Experience with Microsoft/Azure ETL solutions and business Intelligence technologies is a big and mandatory
Past working experience on a fast paced and agile environment
Perform ongoing monitoring, automation and refinement of data engineering solutions
Experience in leading high visibility transformation projects that interacts with multiple business lines
Build and meet project timelines and manage delivery commitments with proper communication to management

Qualifications

Bachelor’s degree with 4+ years of relevant experience
Willingness to learn new technologies and thrive in an extremely fast paced environment
Team player and easy to work with.

Applicants must demonstrate their ability to master new enterprise level technologies. Successful applicants will exemplify Enthuzex ethical principles of uncompromising integrity, respect for others, and accountability for decisions

send cv's info@enthuzex.co.za",-1,Enthuzex,Leslie,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Scientist,-1,"The world is changing.

We all want something different.

At Luno, we see you as an individual.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the world, and to do so, we need the best team on board for our mission.

A bit about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 3 million customers across 40 countries.
We are Series B funded, backed by Balderton Capital and the Naspers Group.
Our platform has processed over 8 billion dollars since we've launched
We're proud to be one of the world's most international cryptocurrency teams from 26 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
The role in a nutshell:

Identifying opportunities in the business that could benefit most from cognitive applications, as well as building and enhancing organisational capabilities for deriving value from multiple data sources using data science.

What we'd like you to have:
Bachelor's degree or higher in the natural sciences or technical fields such as Mathematics, Statistics, Computer Science, Engineering or Economics
Enthusiasm to work in the cryptocurrencies space
Advanced SQL skills
Solid understanding of exploratory data analysis, predictive analytics, and optimisation using Python, R, Matlab, RapidMiner, KNIME or other data science-oriented platforms
Proficiency in the use of data science and machine learning domain-specific languages such as ""Caret"" and the ""Tidyverse"" suite of tools in R, or ""Pandas"" in Python
Strong interpersonal and communication skills
Communicating data insights using storytelling narratives
Ability to work independently, as well as within and across teams
Ability to successfully complete projects with large and/or incomplete data sets
More about what you'll be doing:
Optimising product performance by tracking and analysing customer behaviour on web and app, in collaboration with software engineers and product designers
Providing the business with reports and dashboards, on key performance metrics
Developing metrics to accurately assess the health of our Exchange platform
Comparative data-driven analysis of our Exchange against alternative platforms
Formulating business requirements into analytical objectives
Designing and running experiments to test hypotheses
Hacking through complex business problems using advanced data analysis to provide insights and recommendations
Building, maintaining, and optimising decisioning systems using advanced statistical and predictive modelling techniques
What will set you apart:
An advanced degree in Mathematics, Statistics, Computer Science or related field
At least 3 years' experience working in a similar role
A basic understanding of trading in financial markets
Experience working with a data analytics and visualisation platform such as Tableau, Cognos, QlikView, or Looker
Familiarity with using Google Analytics to understand customer behaviour
Solid knowledge of statistical and machine learning techniques
Familiarity with modern distributed data storage and processing systems such as Amazon Redshift, Big Query, Snowflake, Databricks and Apache Spark
You can gather and synthesise facts, theories, trends, patterns, inferences, and key issues in complex and variable situations
Ability to diagnose problems using formal problem-solving tools and techniques from multiple angles to generate multiple possible solutions
A sense of anticipating long-term problem areas and associated risk levels with objective rationale
Remote Life at Luno

If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
You'll be able to continuously upskill yourself with access to free online learning via MyAcademy, an international teaching marketplace with over 100000 courses from Harvard and other leading providers + share knowledge with your peers.
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity and paternity leave, and you can even take paw-ternity leave for your furry friend.
Annual Inspiration Day! Make time for that pottery course or spa day you've always wanted to do.
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"EY is a global leader in
assurance, tax, transaction and advisory services. Technology is at the heart
of what we do and deliver at EY. Technology solutions are integrated in the
client services we deliver and are key to our innovation as an organization.

Fueled by
strategic investment in technology and innovation, Client Technology seeks to
drive growth opportunities and solve complex business problems for our clients
through building a robust platform for business and powerful product engine
that are vital to innovation at scale. As part of Client Technology, you’ll
work with technologists and business experts, blending EY’s deep industry
knowledge and innovative ideas with our platforms, capabilities, and technical
expertise. As a catalyst for change and growth, you’ll be at the forefront of
integrating emerging technologies from AI to Data Analytics into every corner
of what we do at EY. That means more growth for you, exciting learning
opportunities, career choices, and the chance to make a real impact.

The selected
candidate
Develops
large and complex data architecture, composed of models, policies, rules or
standards that govern which data is collected and how it is stored, arranged,
integrated and put to use in data systems, including the design, build and
management of data infrastructure to address business requirements
Creates
sound use case driven roadmaps, depicting data architecture as-is and to-be
capabilities with the business by engaging with multidisciplinary teams, and by
identifying, managing and mitigating risk
Develops
relationships across the business to understand data requirements, applies deep
technical knowledge of data management to solve business problems in areas
where solutions may not currently exist, necessitating new solutions/ways of
working/technologies and proactively articulating these to the business
Review,
identify the latest emerging technologies, augmenting by services from the
leading cloud providers to solution and recommend the best next generation data
platform value driven approach for our clients
Your Key Responsibilities Include
Create
and maintain conceptual, logical and physical database models
Document
functional requirements and system specifications into the data architecture
and detailed design specifications for current and proposed designs
Document
and adhere to development standards and best practices in database designs
Maintain
highly effective and consistent communication within the team, peers, and the
leadership team
Reverse
engineer SQL code and modify it to solve problems/issues
Contribute
to the definition and implementation of data governance practices
Design
both data structures and data integration practices
Work
closely with the infrastructure teams to create a physical environment to
support data services
Evaluate
new and existing (internal and external) technologies and services in support
of data services and data analytics objectives
Skills And Attributes For Success
Understanding
of business process reengineering and business modeling concepts, business
systems development and analysis
Hands-on
experience in designing and implementing hybrid cloud and on-prem solutions
Experience
working with the latest versions of SQL Server
Experience
applying SAFe/Scrum/Kanban methodologies
Ability
to exercise judgment in solving technical, operational, and organizational
challenges
Expert
programming, performance tuning and troubleshooting skills, using the latest
popular programming languages for example python
Demonstrate
proactive approach to identifying issues and presenting solutions and options,
and where appropriate, leading to resolution
Minimum Qualifications
5+ years
demonstratable work experience as a Data Architect using data modeling tools
2-3 years
SQL coding experience on large projects
Must
possess expert SQL programming, performance tuning and troubleshooting skills
Create
database objects and SQL scripts
Understand
and developed data pipelines
Know how
to deformalize data for data science models
Experience
in python, spark and notebooks
Experience
designing data warehousing solutions
Experience
designing next generation data platforms utilising cloud services
In-depth
understanding of database structure principles
Seamlessly
able to translate business requirements to technology requirements
What We Look For
Strong
analytical skills and problem-solving ability
A
self-starter, independent-thinker, curious and creative person with ambition
and passion
Excellent
inter-personal, communication, collaboration, and presentation skills
Customer
focused
Excellent
time management skills
Positive
and constructive minded
Takes
responsibility for continuous self-learning
Takes the
lead and makes decisions in critical times and tough circumstances
Attention
to detail
High
levels of integrity and honesty
Curious
about new emerging technology
About EY
As a global leader in assurance, tax, transaction and consulting
services, we’re using the finance products, expertise and systems we’ve
developed to build a better working world. That starts with a culture that
believes in giving you the training, opportunities and creative freedom to make
things better. Whenever you join, however long you stay, the exceptional EY
experience lasts a lifetime.",3.8,"EY
3.8",Johannesburg,-1,10000+ Employees,1989,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Architect - Principal,-1,"We are looking for Principle Data Architect to join our Engineering team in Cape Town.

The world is changing.
We all want something different.
At Luno, we see you as individuals.

Together, we are upgrading the world of work to unleash the potential within and empower you to become the best possible version of yourself.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the financial landscape, and to do so, well we need the best team on board for our mission. In short, to achieve our goals, we need rockstars. As simple as that.

A little about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 5 million customers across 40 countries.
We're part of the Digital Currency Group, a group of companies driving progress in the cryptocurrency and blockchain space that includes Grayscale, Genesis, Coindesk and Foundry Services
Our platform has processed over $8 billion to date
We're proud to be one of the world's most international cryptocurrency teams from 43 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
How we work


Our engineering team (currently ~100 engineers) is split into organisations which we call Fleets. Each Fleet focuses on a core customer journey (onboarding, security, payments, support, new business, growth and marketing etc.). Each of these fleets contains multiple smaller teams called Pods, each of which focuses on a specific aspect of the product.

Pods will include a product owner, product designer, back-end engineers, Android, iOS and Web developers, who each bring a unique perspective to the problem you are all contributing towards.

We're agile, use scrum, continuous integration and continuous delivery, deploying to production every single day.

We're building teams to help us succeed in our mission to upgrade the world to a better financial system. You'll be joining a group of highly motivated software engineers who you'll work collaboratively with across our pods.

As a fast-growing company with offices around the world, you'll immediately see how your contributions directly impact both our internal users and client experience. Many of the problems we are solving result in trail blazing solutions which can't be found on Stack Overflow; so we're looking for engineers who flourish working in a complex domain.

In your first six months, you will:


...start at Luno by learning our processes, meeting the wider team and starting our engineering on-boarding program. After getting comfortable with the basics, you'll start learning our idiomatic patterns in a safe, easy-to-follow way - by building your own toy micro services. You'll get to practice how we do design docs, code reviews, deployments, events, logging and monitoring.

You'll meet the Pod(s) you'll be working with and quickly align on the teams' current OKRs and product roadmap. We succeed as a team, so we will provide you with regular feedback from your manager and peers and will encourage you to do the same.

What you'll do:
Work closely with our data science and platform teams on projects introducing new streams of data into our data lake
You will get to bring new ideas on how to further develop and innovate our data solutions and how to expose that data to the business
Accountable and Responsible for the design and architecture of Data systems that are robust and scalable.
Work in an Agile/Scrum framework or Agile mindset
Data backup/recovery and storage
Pick-up and learn new concepts, in both engineering and product, and be able to apply that knowledge quickly.
The ideal candidate for this role will have:
7+ years' experience in maintaining scalable data solutions and/or you are passionate about it
Ability to understand, communicate and advocate between build vs buy
Proven track record of setting up, restructuring and maintenance of databases
You know your way around ETL and you have experience with SQL
Experience in the AWS Data stack (RedShift,DynamoDB, Amazon RDS)
Familiarity with integrating data stores with BI platforms such as Looker, Tableau, or Power BI
You have experience with the concepts of CI/CD
Coding skills in e.g. Go, Python
Bachelor's degree in a related field preferred
AWS Certified DataOps Administrator
Be friendly, transparent, articulate and driven to succeed
Basic knowledge of and passion for digital currencies like Bitcoin
A work permit for South Africa if you are not a South African citizen
Don't be put off if you don't tick all of the boxes – they're a guide based on what we'd love to see but we appreciate that excellent software engineers have diverse backgrounds.

Remote Life at Luno


If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity / paternity and even (yes, you are reading it correctly) paw-ternity for your furry friend..
Annual Inspiration Day.. like that pottery course you've always been meaning to do!
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. You'll need to hold the legal right to work in South Africa already as we cannot provide visa sponsorship.

Be part of the change!",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer - EC2 Capacity Data Analytics,-1,"EC2 Capacity Data Analytics (CDA) team is looking for a Data Engineer to join our team.

Our team is part of the EC2 Capacity Engineering organization, which is responsible for providing the elasticity EC2 customers need to scale up/down compute resources in a cost-efficient manner. We predict customer usage across thousands of configuration combinations to deliver exactly what our customers require in just the right amount of time with just the right amount of capacity.

As a Data Engineer, you will build the ETL and analytics solutions for our internal customers to answer questions with data and drive critical improvements for the business. You will use best practices in software engineering, data management, data storage, data compute, and distributed systems. On any given day, we use Python, Scala, Java, SQL, Lambda, CloudFormation, Redshift and Glue as well as other public AWS services and a host of Amazon internal tools. We dont expect you to be an expert in, or necessarily even be familiar with all of the technologies listed above, but we do expect you to be excited to learn about them.

This position involves on-call responsibilities, typically for one week every two months. Our team is dedicated to supporting new team members. We care about your career growth, we try to assign projects and tasks based on what will help each team member develop into a more well-rounded engineer and enable them to take on more complex tasks in the future.

Our team values work-life balance and we are flexible when people occasionally need to work from home.

Job Duties
Develop and maintain automated ETL pipelines for big data using languages such as Scala, Spark, SQL and AWS services such as S3, Glue, Lambda, SNS, SQS, KMS. Example: ETL jobs that process a continuous flow of JSON source files and output the data in a business-friendly Parquet format that can be efficiently queried via Redshift Spectrum using SQL to answer business question.

Develop and maintain automated ETL monitoring and alarming solutions using Java/Python/Scala, Spark, SQL, and AWS services such as CloudWatch and Lambda.

Implement and support reporting and analytics infrastructure for internal business customers using AWS, services such Athena, Redshift, Spectrum, EMR, and QuickSight.

Develop and maintain data security and permissions solutions for enterprise scale data warehouse and data lake implementations including data encryption and database user access controls and logging.

Develop and maintain data warehouse and data lake metadata, data catalog, and user documentation for internal business customers.

Develop, test, and deploy code using internal software development toolsets. This includes the code for deploying infrastructure and solutions for secure data storage, ETL pipelines, data catalog, and data query.


Basic Qualifications

· Bachelors degree in Computer Science or related technical field, or equivalent work experience.
· 4+ years of overall work experience including Software Engineering, Data Engineering, Database Engineering, Business Intelligence.
· Experience with AWS technologies stack including Lambda, Glue, Redshift, RDS, S3, EMR or similar big data solutions stack

Preferred Qualifications

· Demonstrate efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data.
· Demonstrable proficiency in distributed systems and data architecture; design and implementation of batch and stream data processing pipelines; knows how to optimize the distribution, partitioning, and MPP of high-level data structures.

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer,-1,"Our client based in Johannesburg is urgently looking for a Data Engineer to be on a 3 months contract
Build data pipelines, experience in new tech like nifi, kafka, python

Joburg based, open to EE, 3 month contract with the option to extend, must be available at short notice",-1,EQplus,Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Overview
Job ID: 51456
Job Sector: Information Technology and Services
Country: South Africa
Region/State/Province/District: Gauteng
Location: Johannesburg

Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose

This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes

Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems

Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions

Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.
Research and best practices

Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development

Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.

Preferred Qualification and Experience

Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry

Knowledge/Technical Skills/Expertise

Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision

PLEASE NOTE: All our recruitment and selection processes comply with applicable local laws and regulations. We will never ask for money or any form of payment as part of our recruitment process. If you experience this, please contact our Fraudline on +27 800222050 or forward to TransactionFraudOpsSA@standardbank.co.za",4.1,"Standard Bank
4.1",Johannesburg,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"About us

At PBT Group we pride ourselves on being a Data Specialist organisation. With 20 years of experience in 27 countries over 3 continents, our team of 550 consultants have implemented more than 700 projects.",4.3,"PBT Group
4.3",Johannesburg,-1,Unknown,-1,Company - Private,Accounting,Accounting & Legal,Less than $1 million (USD),-1
Data Engineer,-1,"Kick-start your career in the online gaming world and experience the very latest in technology and innovation.

The Department:

Our mission is to provide our customers with the best online betting experience and share the thrill of gaming with them. Data is at the very heart of our business and is vital in everything we do.

Our cross-functional Data team has a big and exciting challenge ahead. We are in the process of re-platforming our traditional, on-premises RDBMS environment to a new microservice architecture in the cloud. We’re making use of the diverse set of data technologies in Microsoft Azure to offer new services, reporting structures and real-time data pipeline while serving the day-to-day requirements of a rapidly growing, data-hungry organisation.

Purpose of the Role:

This is an excellent opportunity for an individual who is looking to gain new skills. We are committed to creating a culture of learning and regularly run proof of concepts, provide internal demos, manage workshops and attend external conferences. Our data team has a wide range of skills including development for highly transactional RDBMS systems, data warehousing, data science and cloud technologies and we are always working to raise everyone’s game.

Duties include, but not limited to:

Work as part of an agile Data Engineering Team
Development of greenfield projects in Azure
Develop and maintain on-premises RDBMS/DW systems
Create robust ETL services and real-time data pipelines
Build and maintain Continuous Integration and DevOps pipelines
Test-driven development and pair programming with colleagues

Essential Criteria:

C#, .Net, Visual Studio
Git, Azure DevOps
NoSQL development (CosmosDB)
Demonstrable understanding of MS SQL Server in a highly transactional environment
Demonstrable understanding of development in Microsoft Azure
Able to understand query plans and identify performance bottlenecks
Test/Business-Driven Development
Building Continuous Integration/Deployment pipelines
Communicate effectively with both technical and non-technical stakeholders

Desirable Criteria:

Implementing Data Storage and Processing solutions in Azure (ARM Templates, Storage Accounts, Data Lake Storage, SQL DB, Cosmos DB, EventHubs, Function Apps, Log Analytics, Data Factory, Databricks, Polybase)
Implementing Security, Disaster Recovery, High Availability, Auditing, Monitoring and Alerting solutions in Azure
Automating tasks in Azure using Powershell / CLI
Predicting costs and optimizing spending in Azure
Message Queues (RabbitMQ, Kafka)
Python

Person Specifications:

Resilience
Teamwork
Technical Knowledge
Communication skills
Stress Tolerance
Please note we will apply relevance to our Talent Management and Talent Development Programme as part of our recruitment process.
Shortlisted candidates may need to complete an assessment.
This position requires trust and honesty it has access to customers financial details - therefore a credit and criminal record check will be conducted. The qualifications identified herein are an inherent job requirement; therefore, a qualification verification check will be done. By applying for this role, and supplying the necessary details, you hereby grant us permission to apply for these checks. This will be done in a confidential manner, and solely for the purposes of verification.

To view all current vacancies, please visit our website, www.digioutsource.com

Should you not hear from us within 2 weeks, please deem your application as unsuccessful.

The perfect place to work, play and grow!",3.9,"Digital Outsource Services
3.9",Cape Town,-1,1001 to 5000 Employees,1997,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
Data Engineer,-1,"At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes

Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.

Key Responsibilities

Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.

Key Traits

Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern

Position Requirements

2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.

Where will you work? This role will be based out of Durbanville, South Africa.",3.1,"Aculocity, LLC
3.1",Durbanville,-1,1 to 50 Employees,2006,Company - Private,IT Services,Information Technology,$1 to $5 million (USD),-1
Data Engineer,-1,"ENVIRONMENT:

A rapidly growing E-Commerce Platform seeks a highly talented Data Engineer to make an invaluable contribution to data democratisation and literacy vision by making accessible and easy-to-use data products and tools. You will require a Comp-Sci Degree or 3 years’ relevant industry experience, MySQL, PostgreSQL, Java, Python, in-depth understanding of OLAP, Data Marts, Star Scheme, Snowflake, be familiar with Jenkins, Travis, Circle CI, Docker, Kubernetes, experience with Kafka, Pub/Sub, Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks & significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing & Data Lake design and implementation and Lambda/Kappa architectures.

DUTIES:

Design, develop, test and maintain data architecture.

Prepare data for descriptive, predictive and prescriptive modelling.

Automate repetitive tasks and manual processes related with the data usage.

Optimize data delivery.

Design, develop and test large stream data pipelines to ingest, aggregate, clean, and distribute data models ready for analysis.

Ensure the highest standard in data integrity.

Leverage best practices in continuous integration and delivery.

Collaborate with other engineers, ML experts, analysts, and stakeholders to produce the most efficient and valuable solutions.

Implement features, technology, and processes that move us towards industry best practices, improving on scalability, efficiency, reliability, and security.

Operations and ownership of systems in production, responding to incidents.

REQUIREMENTS:

Qualifications –

Comp-Sci Degree or 3 years relevant industry experience.

Experience/Skills –

Open source relational database systems e.g. MySQL, PostgreSQL, etc.

Significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing, and Data Lake design and implementation and Lambda/Kappa architectures.

A thorough understanding of database and data warehousing principles e.g. OLAP, Data Marts, Star Schema, Snowflake, etc.

Java and Python.

Familiar with CI/CD tools such as Jenkins, Travis, Circle CI, etc.

Experience with Kafka, Pub/Sub, or other event-based systems.

Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks, etc.

Working in cloud environments and with containerisation frameworks, tools and platforms e.g. Docker, Kubernetes, GKE, etc.

A deep understanding of data pipelining, streaming, and Big Data technologies, methods, patterns, and techniques.

Troubleshooting complex database operations and performance issues.

Automating tasks using Shell Scripting or writing small applications.

ATTRIBUTES:

Works well with people and is passionate about helping people be their best.

A team player, an active listener, mentor, and able to communicate well.

Shows solid reasoning and decision making, with the ability to work under pressure.

Is passionate about technology, systems and data.

Is curious, always learning, and keeping up to date with the industry.

While we would really like to respond to every application, should you not be contacted for this position within 10 working days please consider your application unsuccessful.

COMMENTS:

When applying for jobs, ensure that you have the minimum job requirements. Only SA Citizens will be considered for this role. If you are not in the mentioned location of any of the jobs, please note your relocation plans in all applications for jobs and correspondence.",-1,Datafin IT Recruitment,Cape Town,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Cartrack is looking for passionate data science and engineering candidates that can join a growing team that is responsible for the intelligence and efficiency solution provision to over a million subscribers, many of whom are large fleets. We are in the midst of creating revolutionary platforms that will change the way that people interact with their vehicles.

You will have the opportunity to work with the very brightest global subject matter experts that are transforming the automotive industry across Fleet Management, Asset Management and Insurance Telematics solutions.

Get to know the role:

The role of a data engineer is a supporting one, but it is also an extremely vital one. As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements. We want to see candidates with mechanical tendencies and a desire to know how things work and to improve them.

The day-to-day activities:

Design, construct, install, test and maintain data management systems.
Build high-performance algorithms, predictive models, and prototypes.
Ensure that all systems meet the business/company requirements as well as industry practices.
Integrate up-and-coming data management and software engineering technologies into existing data structures.
Develop set processes for data mining, data modeling, and data production.
Create custom software components and analytics applications.
Research new uses for existing data.
Employ an array of technological languages and tools to connect systems together.
Install/update disaster recovery procedures.
Recommend different ways to constantly improve data reliability and quality.
Work on and maintain Data pipelines.

Requirements Essential:

At least 5 years’ proven experience as a Data Engineer, DevOps Engineer, Software Developer, or similar.
Proficient in Linux/Unix and shell scripting as well as in functional programming languages.
Expertise in setting up and explored with technologies such as Hadoop and Spark.
Bachelor’s degree in computer science, software/computer engineering, applied mathematics, or physics.",3.3,"Cartrack
3.3",Johannesburg,-1,501 to 1000 Employees,2004,Company - Private,Security Services,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Data Engineer,-1,"Data Engineers build and support data pipelines and datamarts built off those pipelines. Both must be scalable, repeatable and secure. The Data Engineer helps to facilitate gathering data from a variety of different sources, in the correct format, assuring that it conforms to data quality standards and assuring that downstream users can get to that data timeously. This role functions as a core member of an agile team. These professionals are responsible for the infrastructure that provides insights from raw data, handling and integrating diverse sources of data seamlessly. They enable solutions, by handling large volumes of data in batch and real-time by leveraging emerging technologies from both the big data and cloud spaces. Additional responsibilities include developing proof of concepts and implements complex big data solutions with a focus on collecting, parsing, managing, analysing and visualising large datasets. They know how to apply technologies to solve the problems of working with large volumes of data in diverse formats to deliver innovative solutions. Data Engineering is a technical job that requires substantial expertise in a broad range of software development and programming fields. These professionals have a knowledge of data analysis, end user requirements and business requirements analysis to develop a clear understanding of the business need and to incorporate these needs into a technical solution. They have a solid understanding of physical database design and the systems development lifecycle. This role must work well in a team environment.

Job Objectives

Work Complexity: * Architects Data analytics framework. * Translates complex functional and technical requirements into detailed architecture, design, and high performing software. * Leads Data and batch/real-time analytical solutions leveraging transformational technologies. * Works on multiple projects as a technical lead driving user story analysis and elaboration, design and development of software applications, testing, and builds automation tools.

Main Job Objectives: 1. Development and Operations 2. Database Development and Operations 3. Policies, Standards and Procedures 4. Communications 5. Business Continuity & Disaster Recovery 6. Research and Evaluation 7. Coaching/ Mentoring

Qualifications

Essential: 4 years Bachelors degree in computer science, computer engineering, or equivalent work experience AWS Certification at least to associate level

Experience

Essential:

5+ years Data engineering or software engineering

3-5 years demonstrated experience leading teams of engineers

2+ years Big Data experience

5+ years experience with Extract Transform and Load (ETL) processes

2+ years Could AWS experience

At least 2 years demonstrated experience with agile or other rapid application development methods - Agile exposure, Kanban or Scrum

5 years demonstrated experience with object oriented design, coding and testing patterns as well as experience in engineering (commercial or open source) software platforms and large scale data infrastructures.

Desirable:

5+ years Retail Operations experience

Knowledge and Skills

Essential: *Creating data feeds from on-premise to AWS Cloud (2 years) *Support data feeds in production on break fix basis (2 years) *Creating data marts using Talend or similar ETL development tool (4 years) *Manipulating data using python and pyspark (2 years) *Processing data using the Hadoop paradigm particularly using EMR, AWSs distribution of Hadoop (2 years) *Devop for Big Data and Business Intelligence including automated testing and deployment (2 years) * Extensive knowledge in different programming or scripting languages * Expert knowledge of data modeling and understanding of different data structures and their benefits and limitations under particular use cases.

Further technical skills required: * Capability to architect highly scalable distributed systems, using different open source tools. * Big Data batch and streaming tools * Talend (1 year) * AWS: EMR, EC2, S3 (1 year) * Python (1 year) * PySpark or Spark (1 year) - Desirable * Business Intelligence Data modelling (3 years) * SQL (3 years)",-1,Datonomy Solutions,Brackenfell,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We are assisting one of our clients that is based in Pretoria to fill a role of a Data Engineer

This is a 12 month contract role

Objective of this Scope of Work

The Data Engineer will drive improvement of the data management maturity levels and provide the necessary technical support within the company to support reliable and effective decision-making, appropriate usage and protection thereof.

Scope of Services Definition

The scope will include but will not be limited to:

ï†· To develop, construct, test and maintain architectures.

ï†· To ensure architectures will support the requirements of business.

ï†· To discover opportunities for data acquisition and sharing.

ï†· To develop data set processes for data modelling, mining and production.

ï†· To employ a variety of languages and tools to marry systems together.

ï†· To recommend way to improve data reliability, efficiency and quality.

ï†· To prepare data for use in predictive and prescriptive modelling.

ï†· To conduct research to answer industry and business questions.

ï†· To leverage volumes of data from internal and external to answer business questions.

ï†· To develop and manage stakeholder relations effectively to promote data management across the organisation and support reliable decision making and appropriate data usage.

ï†· To participate and provide technical support in cross organisational activities relating to any of the above mentioned data management activities.

ï†· To provide regular progress reports as per stakeholder requirements and present data management updates in various forums as required.

Minimum qualification Required:

ï†· A minimum of a Bachelors degree in Computer Science or Information Management OR equivalent;

ï†· A minimum of five to eight years experience in a data management environment",-1,HR Genie,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Our client based in the Northern Suburbs, is currently looking for a Data Engineer to join their team.

Responsibilities
Our client is a dynamic IT company that delivers value-driven IT solutions to the group. Our work lives revolve around our DNA. We take pride in our work, treat our colleagues, partners and our country with respect. We exercise collaborative decision-making and believe in having a balance in life. We do this all while having fun and enjoying what we do.

The primary focus of this position is to use technical skills to put software, systems and data together in a way that extracts meaningful insights from raw data. You will need to be helpful and supportive to your team and fellow developers. You join an energetic, focused and dynamic team.

Interact with clients to understand requirements and business problems/needs

Identify, analyse, visualise and understand supporting data to propose solid solutions

Create technical documentation for reference and reporting

Support existing solutions within GCP and Oracle

Doing standby on a rotating basis

Key Competencies and Qualifications

Matric

Tertiary qualification in IT

Preferred cloud experience in AWS/AZURE/GCP

At least 3 years of data warehouse ETL experience

Dimensional Modelling

Data analyses

Experience with data visualization and visualization tool(s)

Knowledge of the retail industry will be beneficial

Understanding and experience with version control SVN/GIT

Preferred – Korn shell scripting, Python/Java, SQL

Google Cloud Platform experience would be looked upon favourably

Having a broad understanding of different SDLC’s

Preferred agile experience

Strengths

The natural tendency to take ownership and responsibility

Strong problem solving, critical thinking, effective planning and organisational skills

Detail-oriented with excellent communication skills

You have a can-do attitude and positive outlook on life

Can cope under pressure

Curious and interested in analysing problems and possible solutions

Strong team player

Self-driven learner, passionate about new technology

Above all, be passionate about what you do

Should you wish to apply for the position, please apply directly via this job board, please ensure that you quote reference number 201620 subject heading or email body.

Please note that due to the high volume of CV's received; only shortlisted applicants will be contacted. Should you not receive communication from our offices within two weeks of submission please note that your application will not be considered for this position.

We will keep your CV on file and re-establish contact with you should opportunities in line with your expertise become available again.

Should you require any additional information give us a call on 021 012 5566.",-1,Surgo HR & Training,Cape Town,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We believe that our employees fuel our organization, essential to enable us to help our customers overcome their business challenges and achieve sustainable growth. As a result, we are committed to growing each individual and providing them with the challenges, feedback and support needed to achieve success in their career

If this sounds appealing, and like us, you get excited about data: its collection, storage, transformation or display, see if you’ve got what it takes to join our sought after DATA team.

Key Responsibilities And/or Outputs

You will represent IQbusiness at our customers, sometimes alone, and sometimes as part of an IQ team.

Providing a superior customer experience by building and maintaining relationships, working at customer offices, keeping data confidential
Design and develop – databases, SQL queries, stored procedures, reports, dashboards or integration solutions
Produce solutions for both real-time and batch environments
Test your work to ensure compliance
Solve problems, and do root cause analysis
Prioritize your workload
Assist in other areas relating to your true data function, such as data modeling, data and business analysts
Interact with a variety of individuals: senior, junior, technical and from business
Provide guidance to fellow colleagues, or even manage a team
Uphold the IQ values, which are to care, learn & share; innovate; deliver as well as to build, enhance and maintain relationships

Education

Matric pass
A tertiary qualification, preferably in an ICT relevant field
Appropriate Microsoft certifications are beneficial but not required

Requirements

3 - 6 years experience in the Data Engineering environments and technologies
Great communication skills
A passion for SQL, databases or reports
Can you write stored procedures, design complex queries and create views and triggers?
Are you able to work out the relationships in a data warehouse or the aggregation of a cube?
Do you extract and display useful information when you see patterns and trends in data?
Strong knowledge of the financial services industry, ideally in a consulting role
The use of data related software: databases, ETL and BI tools; report writing and analytical tools
We use a lot of Microsoft products. You may often be expected to use MS SQL Server, SSIS, SSRS, SSAS and Power BI to develop solutions
What other relevant software have you’ve used?
Ability to work in different project methodologies: Waterfall and/or Agile
Knowledge of full SDLC
Exposure to logical and physical data modeling

Equal Employment Opportunity

IQbusiness is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, citizenship, marital, domestic or civil partnership status, sexual orientation, or gender identity",3.7,"IQbusiness South Africa
3.7",Johannesburg,-1,1 to 50 Employees,-1,Company - Private,Consulting,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"We value a data engineer as someone who works behind the scenes to obtain, process and supply data via various methodologies and technologies, to various consumers, in ways and forms that makes sense and add value. This definition is very broad, as the field of data engineering is just as broad.

You may be the type of data engineer that develops API endpoints for the consumption of data by end users or even another data pipeline, or you may be the type of data engineer that develops highly distributed, high availability data processing pipelines in an effort to satisfy the need of the ever questioning data analysts and/or data scientists.

You have awesome knowledge about the following concepts
Data modelling
Relational data modelling in traditional relational database management systems. (Microsoft SQL Server, MySQL, PostgreSQL, etc)
Coercing unstructured and semi-structured data into a structured form.
Data pipelining knowledge - data extraction and transformation.
Data transformation knowledge for reporting and analytics purposes.
Knowledge of the MapReduce and related data processing paradigms would be a boon.
You have the following technical competencies
Writing SQL queries, that can relate, transform and aggregate data from many differing sources where natural keys may or may not exist.
Experience with writing data pipelines that move and transform data, for various uses.
Working knowledge of a general purpose programming language like Python would be a boost.
Working knowledge of columnar databases such as Google BigQuery, and SAP HANA would be a boost.
Working knowledge of highly distributed technologies such as Apache Hadoop or Apache Spark would be a boost.
Working knowledge of NoSQL technologies, such as Apache Solr would be a boost.
You have the following personal competencies
The ability to solve problems.
The ability to rotate around a problem, to see if solutions can be gained in different ways.
The ability to work in an ever changing, unstructured environment.
The ability to work as part of a team, with vastly differing skill sets and opinions.
The ability to contribute ideas to the quorum.
The ability to mentor and provide guidance for other team members.
A systems approach to thinking, as opposed to a siloed approach. The candidate needs to understand how their work affects the greater system.
The ability to work without supervision, and take accountability for the work they deliver.
The ability to liaise with a client, sifting through the fluff and extracting the actual requirements.
If this is you - apply now and we'll get in touch",-1,DotModus,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Data Engineer

Our client in the contact centre space is currently seeking a DATA ENGINEER that will work on the collecting, storing, processing, and analyzing of large datasets. The primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them. You will also be responsible for integrating them with the architecture used across the company.

Key Performance Areas:

Data reporting.
Implementing ETL processes.
Defining data retention policies.
Management of Customer Lead data.
Provision of data for advanced analytics.
Maintenance of internal client scorecards.
Assist team in resolving data-related support queries.
Optimize existing data processes through automation.
Assist with all data-related reporting and documentation.
Maintenance and optimisation of the Analytics database.
Provide technical support to and supervision of junior data administrators.
Continuous upskilling on new technologies, frameworks and market trends.
Monitoring performance and advising any necessary infrastructure changes.
Identifying, selecting and integrating any Big Data tools and frameworks required to provide real-time analytics.

Educational Requirements

IT related Degree or Diploma is a pre-requisite

Required Skills/Experience

ETL tools: Advanced SSIS
BI/Reporting : Qlikview/Power BI/ SSRS or SSAS
Programming languages: JAVA, C# , Python, SAS or R
Experience with NoSQL databases and/or campaign management tools will be advantageous.
Minimum 3 years’ applicable work experience in SQL, relational databases and data manipulation.
Experience in big data platforms (eg. Hadoop) or processing frameworks (eg. MapReduce/Spark) and querying tools (eg. Pig, Hive and Impala) will be highly beneficial.

Preferred Skills

Organizational skills
Experience in Attentional to detail.
Accountability is critical for this role.
Ability to work under pressure and meet deadlines.
Solid understanding of database design principles.
Should you not receive a response in 2 weeks please consider your application unsuccessful",-1,Rubik's Cubed Consulting,Durban,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"This well known company is looking for a Data Engineer. will be based in Rivonia
The ideal candidate will have strong experience in the following:
Data cleaning
SQL Export
Big data Sets

BSc Degree in Maths and Stats will be required
a min of 3 years experience.
Stable track record is required.

Send your Cv to marinda@prrrecruitment.co.za",-1,PRR Recruitment Services,Johannesburg,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Description

Position at Aculocity, LLC

At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes
Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.
Key Responsibilities
Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.
Key Traits
Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern
Position Requirements
2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.
Where will you work? This role will be based out of Durbanville, South Africa.",-1,GVW,Durbanville,-1,Unknown,-1,Unknown,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Information Technology, Gauteng JHB - Northern Suburbs

Market related - Market related Annually

An IT Consultancy Business based in Johannesburg is currently looking for a Business Intelligence Consultant / Data Engineering Consultant.

Requirements:

Extensive experience in data engineering
Experience in Business Intelligence, data and Power BI
Extensive experience in data governance and the Popi act
Ability to assess and make recommendations on data within the Popi act
Good understanding of T-SQL and query optimization, developing ETL strategies.
Good understanding with SQL Server 2008/2012, SSIS, SSRS and SSAS
Use SSIS to create ETL packages to validate, extract, transform, and load data into the data warehouse and data marts.
Deploy and configured the reports in the Report Server (SSRS).
Excellent experience in Tabular Modelling , PowerView, Qlikvie,w, and Power BI
Maintain ETL
Qlikview model
Create Drill-through, Drill-down, and Cross Tab Reports and Sub-Report using Report Definition Language (RDL).
Generate periodic reports based on the statistical analysis of the data using SQL Server Reporting Services (SSRS)
Advise and provide written technical documentation and recommendations

The information displayed above is not limited to advertisements. Please contact Thato for further information.

Please consider your application as unsuccessful if you have not received a response within 14 days of submitting your application. However, please keep a lookout on our website, www.bedifferent.co.za, for available positions that you may be suited for

Ad Visible Until: 29 October 2020
Ref: JHB005346/NL

Vacancy Type: Permanent",2.9,"Be Different Recruitment
2.9",Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Cloud Support Engineer (Big Data),-1,"ABOUT US

Amazon Web Services is the market leader and technology forerunner in the Cloud business. As a member of the AWS Support team you will be at the forefront of this transformational technology, assisting a global list of companies and developers that are taking advantage of a growing set of services and features to run their mission-critical applications. As a Cloud Support Engineer, you will act as the Cloud Ambassador across all the cloud products, arming our customers with required tools & tactics to get the most out of their Product and Support investment.

Would you like to use the latest cloud computing technologies? Do you have an interest in helping customers understand application architectures and integration approaches? Are you familiar with best practices for applications, servers and networks? Do you want to be part of a customer facing technology team helping to ensure the success of Amazon Web Services (AWS) as a leading technology organization?

If you fit the description, you might be the person we are looking for! We are a group of smart people, passionate about cloud computing, and believe that world class support is critical to customer success.

WHAT CAN YOU EXPECT FROM A LIFE AT AWS?

Every day will bring new and exciting challenges on the job while you:

· Learn and use groundbreaking technologies.
· Apply advanced troubleshooting techniques to provide unique solutions to our customers' individual needs.
· Interact with leading engineers around the world.
· Partner with Amazon Web Services teams to help reproduce and resolve customer issues.
· Leverage your extensive customer support experience to provide feedback to internal AWS teams on how to improve our services.
· Drive customer communication during critical events.
· Drive projects that improve support-related processes and our customers technical support experience.
· Write tutorials, how-to videos, and other technical articles for the developer community.
· Work on critical, highly complex customer problems that may span multiple AWS services.

WHY AWS SUPPORT?

· First and foremost this is a customer support role in The Cloud.
· On a typical day, a Support Engineer will be primarily responsible for solving customers cases through a variety of customer contact channels which include telephone, email, and web/live chat. You will apply advanced troubleshooting techniques to provide tailored solutions for our customers and drive customer interactions by thoughtfully working with customers to dive deep into the root cause of an issue.
· Apart from working on a broad spectrum of technical issues, an AWS Support Engineer may also coach/mentor new hires, develop & present training, partner with development teams on complex issues or contact deflection initiatives, participate in new hiring, write tools/script to help the team, or work with leadership on process improvement and strategic initiatives.
· Career development: We promote advancement opportunities across the organization to help you meet your career goals.
· Training: We have training programs to help you develop the skills required to be successful in your role.
· We hire smart people who are keen to build a career with AWS, so we are more interested in the areas that you do know instead of those you havent been exposed to yet.
· Support engineers interested in travel have presented training or participated in focused summits across our sites or at specific AWS events.
· As we operate on a follow-the-sun model, with Premium Support sites located globally, there is no after hours on-call or mandated overtime in this role.
· https://www.youtube.com/watch?v=GC3bWcFFZTo&t=24s



Basic Qualifications

The Big Data role supports our services that leverage data and produce business insights, which may include using Machine Learning/Artificial Intelligence (ML/AI). Helping our customers use and integrate Big Data services in what is arguably our industrys most exciting space. The portfolio of services covers EMR (Hadoop), DynamoDB (NoSQL), MangoDB, and Apache Cassandra.

· Advanced experience in Apache Hadoop, Apache Spark, Apache Hive, and Presto
· Advanced experience in DynamoDB or NoSQL technologies like MongoDB or Cassandra
· Advanced experience with System Administration with Linux (RHEL/CentOS) including Microsoft Active Directory, and LDAP integration.
· Experience with troubleshooting Kerberos Authentication problems.
· Experience with Network troubleshooting.
· Basic understanding of Machine Learning and statistics
· Experience with Java and Python and shell scripting
· Bachelors degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position



Preferred Qualifications

· Expert experience in the Hadoop Ecosystem including Apache Spark and Presto
· Expert experience in NoSQL
· Expert experience with blockchain technologies like Etherium Expert experience in data Data Lake architecture and administration
· Experience managing full application stacks from the OS up through custom applications
· Prior work experience with AWS - any or all of EC2, VPC, S3, RDS, EMR, Glue, SageMaker
· Excellent knowledge of Hadoop architecture, administration and support
· Expert understanding of distributed computing principles and their application in the cloud
· Good understanding of distributed computing environments Lead technical discussions on big data systems architecture and design
· Strong analysis and troubleshooting skills and experience
· AWS Certified Solutions Architect
· AWS certified Big Data Specialty
· Masters degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity and Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Response Center Engineer,-1,"Job Title
Response Center Engineer
Job Description


Philips is a world leading health technology company with a vision to make life better for people worldwide through meaningful innovation. Making good on this promise depends on our passionate, inspirational, collaborative and diverse team. We have over 80,000+ brilliant people around the world but are always looking for more. Like-minded, motivated, focused minds to join us in creating a healthier, more connected society while transforming themselves personally and professionally.

As a CCC Coordinator - Response Center Engineer you will have the opportunity to process customer calls and be responsible for screening and diagnosing professionally Healthcare equipment to support customers and colleagues remotely with solving technical issues and ensuring maximum customer satisfaction

You are responsible for:
Diagnose healthcare equipment to the quality standards set by Philips Healthcare (PH) remotely by interviewing customers or colleagues by telephone or by remotely logging in to the system
Advise Customer Care Center Coordinators and District Operations Managers and / or Team Leads about the best follow-up w.r.t. technical state of the diagnosed healthcare equipment
Advise the Customer Care Center Coordinators or Field Services Engineers about required spare parts and resources
Responsible for planning engineers related to Modality responsibility.
Responsible for coordination between CCC, CUSTOMER, Spare parts AND Engineer.
Responsible to drive Remote and FTR KPI’s to targets respectively 40% and 85%.
Will require minimal field work to keep abreast of technical capabilities.
Take calls from customers and make sure they are processed in the CCC ERP on timely manner including all relevant data
Support Field Services Engineers in the field with technical knowledge
Escalate technical issues to the Technical Support Specialist
Escalate technical issues to Business Unit support after consultation of the Technical Support Specialist
Monitor critical functions of the equipment’s in the IB and environmental conditions including RSN and True reachability.
Lead the planning and implementation of FSN’s and FCO’s accelerating remote implementation where applicable.
Submit timely and accurate service data, job sheets, reports, expense claims, radiation film badges, field problem reports and other paperwork as assigned
Keep abreast of new technologies likely to affect PH range of products
Use company property with care to ensure optimal results with minimal operational costs
Be a professional representative for PH with respect to customer problems, ensuring personal acceptability by the customer in behavior in accordance with PH policy and targets
Conform to PH safety standards including health and safety regulations and in the event of hazards or accidents to take immediate control of the situation and involve the Operations Manager and / or the responsible person to handle properly confidential issues according Philips standards and to act according General Business Principals
Follow all quality standards within the frame of valid PH business policies
Follow the company quality regulations (ISO 9001; PQA; TQM) and internal directives and procedures
You are a part of the dynamic South Africa Customer Care Centre Team .You will be reporting to the Customer Care Center Manager.

Requires a pleasant, assertive individual you can work very well in a team setting, a dynamic environment that requires flexibility and creativeness to achieve goals.

To succeed in this role, you should have the following skills and experience:
Degree level education or equivalent
Experience in maintenance and troubleshooting of technical complex systems
Fluent in English, verbal and written in addition to local language
In return, we offer you the unique combination of a critical and challenging role and a creative and empowering office environment. You will be actively encouraged to make improvements, establish best in class service and have a direct impact on the success of Philips on a daily basis.

Employment Equity

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply. Only apply for this role if you are a South African Citizen by birth or Naturalization prior to the 27 April 1994.

Why should you join Philips?

Working at Philips is more than a job. It’s a calling to create a healthier society through meaningful work, focused on improving 3 billion lives a year by delivering innovative solutions across the health continuum. Our people experience a variety of unexpected moments when their lives and careers come together in meaningful ways. Learn more by watching this video.

To find out more about what it’s like working for Philips at a personal level, visit the Working at Philips page on our career website, where you can read stories from our employee blog. Once there, you can also learn about our recruitment process, or find answers to some of the frequently asked questions.

Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.9,"Philips
3.9",Johannesburg,-1,10000+ Employees,1891,Company - Public,Health Care Services & Hospitals,Health Care,$10 to $25 million (USD),-1
Software Development Engineer - EC2 Placement,-1,"Build the systems that optimize how EC2 matches requests for Instances with the underlying compute capacity. EC2 Placement is seeking talented engineers to build the online and offline optimization systems for compute workload scheduling, and the customer capabilities to better manage those workloads. Amazon EC2 provides on-demand scalable compute capacity, and powers some of the largest services in the world. You will collaborate with a top-tier community of engineers to build systems to improve how customers are able to access EC2 compute resources.

The successful candidate will have strong software engineering experience, with a passion for thinking about, building and testing distributed systems. You have an interest in how Machine Learning and other optimization techniques can be applied to large-scale problems. You have demonstrated experience working with a team to design, build and operate large-scale systems. With strong engineering fundamentals, an analytical and data-driven approach to your work, and strong communication skills, you have the ability to collaborate well to deliver results. We move fast and work together on small teams to solve big problems.

If this opportunity sounds interesting, we would love to talk to you more about our work and the vibrant culture at AWS in Cape Town.

Basic Qualifications

· Degree in Computer Science or related field, or equivalent working experience
· 3+ years of industry experience in a software development environment
· Strong Computer Science fundamentals, including data structures, object-oriented design, algorithm design, problem solving, and complexity analysis.
· Proficiency in at least one modern programming language, such as Java, C#, Python, Scala, Kotlin

Preferred Qualifications

One or more of the following help you stand out:
· Demonstrated results designing, building and operating high-performance distributed systems in large-scale Linux environments
· Role model in writing high-quality, maintainable and secure code, mentoring others, and helping teams sharpen their development processes
· Ability to work effectively across teams to deliver results, with strong verbal and written communication skills
· Experience working with machine learning systems

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer - PBB IT,-1,"Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose


This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes
Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems
Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions
Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.

Research and best practices
Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development
Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.
Preferred Qualification and Experience
Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Aws Data Platform Engineer,-1,"Aws Data Platform Engineer

Posting Country:

South Africa

Date Posted:

15-Oct-2020

Full Time / Part Time:

Full Time

Contract Type:

Permanent

Joining Vodacom is more than a job, what we do matters. We don’t just carry minutes, texts and data – we carry people’s lives. And that’s a huge responsibility. If you think for a minute about the people you rely on…the likelihood is they rely on us.

Customers are at the heart of everything we do and we want to make a difference to the lives of our customers, and the communities in which we live and work. We support our people to give something back to the causes that mean the most to them through helping them give time and money to the charities they love.

And what’s it like to work here? We have created an environment where you can look forward to coming to work and are empowered to be at your best. We offer flexibility in how you work that helps you do your job in a way that suits you, opportunities to help you grow and progress throughout your career and a choice of benefits to suit your lifestyle.

Role Purpose
The H Band AWS Data Platform Engineer position is based within the Technology Business Unit.

The AWS Data Platform Engineer will be responsible for all Database services such as RDS, DynamoDB, etc. Should be able to migrate any databases from anywhere to AWS using any third-party tools or AWS database migration tool. Should also have understanding or expertise in creating data warehouses and data lake solutions on AWS.
Your responsibilities will include:
Apply practical knowledge of relational database design and usage with customers
Perform workload analysis and undertake performance tuning, as well as performance benchmarking in customer environments.
To develop state of the art solutions which are technically sound.
To provide a high-quality service to the Enterprise Cloud Services clients i.t.o. consultancy, solutions and delivery.
Commitment to team success and positive team dynamics including mentoring of other team members.
Passion for growing and applying technical skills in service to customers.
Be a trusted infrastructure advisor by providing objective, practical and relevant ideas, insights and advice.
Work collaboratively with consulting partners and technology teams to ensure high quality of solution delivery.
Encourage best practice and knowledge sharing with partners and cross-functional groups
Manage the overall database design and delivery of solutions.
Ability to make recommendations as they pertain to improvements in support/development initiatives and facilitate implementation with partners and cross-functional groups within the Business.
Participate in high level database solution definition and design during the implementation phase with the goal of providing reliable, stable and operationally sound applications that meet the Business requirements.
Ability to understand and translate business requirements into technical specifications
The ideal candidate will have:
A minimum of 3 years of industry related experience of which 1 year must be within a complex hosting environment.
Certifications in Database design, system architecture or cloud technologies.
Demonstrate knowledge of database systems internals including storage layouts and distributed databases/MPP architectures
Advanced SQL coding, tuning and query optimization.
Experience designing and leading database performance benchmarks.
Good knowledge of the different AWS services
Knowledge of cloud networking architecture, cloud operations, security, automation and orchestration.
Knowledge of database internals as it relates to query and system performance and tuning.
Understanding of overall system architecture, scalability, reliability, and performance in a database environment.
Excellent teamwork, time-management and organizational skills.
Perform other duties as deemed necessary and assigned by the customer and management
Strong interpersonal skills and problem-solving abilities.
Excellent documentation, communication and interpersonal skills.
Excellent analytical and problem-solving abilities.
Closing date for applications: Monday, 13 April 2020

The base location for this role is Vodacom World, Midrand

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply.
Vodacom is committed to an organisational culture that recognises, appreciates and values diversity & inclusion.

Commitment from Vodacom

Vodacom is committed to attracting, developing and retaining the very best people by offering a flexible, motivating and inclusive workplace in which talent is truly recognized, developed and rewarded. We believe that diversity plays an important role in the success of our business and we are committed to creating an inclusive work environment which respects, values, celebrates and makes the most of people’s individual differences - we are not only multinational but multicultural too. At Vodacom you will have access to our excellent flexible benefits programme that you would expect from any global company.",3.9,"Vodafone
3.9",Midrand,-1,10000+ Employees,1982,Company - Public,"Cable, Internet & Telephone Providers",Telecommunications,$10+ billion (USD),-1
Data Engineer Azure Data Factory,-1,"Enthuzex is looking for a motivated Lead Data Engineer to contribute towards the success of our Data and Analytics Technology initiatives. This is a hands-on technical role and this person will be responsible for the development and build of scalable solutions as it relates to the architecture strategies, data standards, digital data management, data integration, tools, and technology. The right candidate will play a deep dive hands-on critical development role in the digital transformation and in shaping how we acquire, ingest, transform and deliver data through the digital consumer channels.

Responsibilities:

Architect, design, develop and engineering end-to-end data pipelines across multiple data sources and systems of record.
Ensure data quality, integrity, security and completeness throughout the data lifecycle
Develop, design data models, data structures and ETL jobs for data acquisition and manipulation purposes
Develop deep understanding of the data sources, implement data standards, maintain data quality and master data management
Developing data services and API
Work closely with the cloud service providers to ensure completeness and alignment with the service offerings
Manage and maintain cloud based data and analytics platform
Deep understanding of the cloud offerings and engage in quick proof of concepts and proof of value in prototyping data and analytics solutions and derive viability
Ability to interact with the business stakeholders to understand requirements and translating into technology solutions

Expirience:

Experience in Cloud platform AWS or Azure eco-system. (Azure preferred)
Data Engineering/Development experience with SQL (Oracle, SQL Server, MySQL)
Strong development background creating pipelines and complex data transformations and manipulations using one of the languages Python, Java, R, or Scala with Databricks/Spark
Experience in NoSQL Databases and Big data technologies including Hadoop
Experience with API / RESTful data services
Worked on real-time data capture, processing and storing using technologies like Azure Event Hubs and Analytics
Experience working with different data storage options including AWS S3, Azure BLOB storage etc.
Understanding of different data formats including Parquet, Avro, CSV, ORC etc.
Prior experience with MPP databases and maintain large amount of data processing
Experience with Azure Data Factory and Azure Data Catalog is a big plus and mandatory
Experience with Microsoft/Azure ETL solutions and business Intelligence technologies is a big and mandatory
Past working experience on a fast paced and agile environment
Perform ongoing monitoring, automation and refinement of data engineering solutions
Experience in leading high visibility transformation projects that interacts with multiple business lines
Build and meet project timelines and manage delivery commitments with proper communication to management

Qualifications

Bachelor’s degree with 4+ years of relevant experience
Willingness to learn new technologies and thrive in an extremely fast paced environment
Team player and easy to work with.

Applicants must demonstrate their ability to master new enterprise level technologies. Successful applicants will exemplify Enthuzex ethical principles of uncompromising integrity, respect for others, and accountability for decisions

send cv's info@enthuzex.co.za",-1,Enthuzex,Leslie,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Scientist,-1,"The world is changing.

We all want something different.

At Luno, we see you as an individual.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the world, and to do so, we need the best team on board for our mission.

A bit about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 3 million customers across 40 countries.
We are Series B funded, backed by Balderton Capital and the Naspers Group.
Our platform has processed over 8 billion dollars since we've launched
We're proud to be one of the world's most international cryptocurrency teams from 26 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
The role in a nutshell:

Identifying opportunities in the business that could benefit most from cognitive applications, as well as building and enhancing organisational capabilities for deriving value from multiple data sources using data science.

What we'd like you to have:
Bachelor's degree or higher in the natural sciences or technical fields such as Mathematics, Statistics, Computer Science, Engineering or Economics
Enthusiasm to work in the cryptocurrencies space
Advanced SQL skills
Solid understanding of exploratory data analysis, predictive analytics, and optimisation using Python, R, Matlab, RapidMiner, KNIME or other data science-oriented platforms
Proficiency in the use of data science and machine learning domain-specific languages such as ""Caret"" and the ""Tidyverse"" suite of tools in R, or ""Pandas"" in Python
Strong interpersonal and communication skills
Communicating data insights using storytelling narratives
Ability to work independently, as well as within and across teams
Ability to successfully complete projects with large and/or incomplete data sets
More about what you'll be doing:
Optimising product performance by tracking and analysing customer behaviour on web and app, in collaboration with software engineers and product designers
Providing the business with reports and dashboards, on key performance metrics
Developing metrics to accurately assess the health of our Exchange platform
Comparative data-driven analysis of our Exchange against alternative platforms
Formulating business requirements into analytical objectives
Designing and running experiments to test hypotheses
Hacking through complex business problems using advanced data analysis to provide insights and recommendations
Building, maintaining, and optimising decisioning systems using advanced statistical and predictive modelling techniques
What will set you apart:
An advanced degree in Mathematics, Statistics, Computer Science or related field
At least 3 years' experience working in a similar role
A basic understanding of trading in financial markets
Experience working with a data analytics and visualisation platform such as Tableau, Cognos, QlikView, or Looker
Familiarity with using Google Analytics to understand customer behaviour
Solid knowledge of statistical and machine learning techniques
Familiarity with modern distributed data storage and processing systems such as Amazon Redshift, Big Query, Snowflake, Databricks and Apache Spark
You can gather and synthesise facts, theories, trends, patterns, inferences, and key issues in complex and variable situations
Ability to diagnose problems using formal problem-solving tools and techniques from multiple angles to generate multiple possible solutions
A sense of anticipating long-term problem areas and associated risk levels with objective rationale
Remote Life at Luno

If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
You'll be able to continuously upskill yourself with access to free online learning via MyAcademy, an international teaching marketplace with over 100000 courses from Harvard and other leading providers + share knowledge with your peers.
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity and paternity leave, and you can even take paw-ternity leave for your furry friend.
Annual Inspiration Day! Make time for that pottery course or spa day you've always wanted to do.
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"EY is a global leader in
assurance, tax, transaction and advisory services. Technology is at the heart
of what we do and deliver at EY. Technology solutions are integrated in the
client services we deliver and are key to our innovation as an organization.

Fueled by
strategic investment in technology and innovation, Client Technology seeks to
drive growth opportunities and solve complex business problems for our clients
through building a robust platform for business and powerful product engine
that are vital to innovation at scale. As part of Client Technology, you’ll
work with technologists and business experts, blending EY’s deep industry
knowledge and innovative ideas with our platforms, capabilities, and technical
expertise. As a catalyst for change and growth, you’ll be at the forefront of
integrating emerging technologies from AI to Data Analytics into every corner
of what we do at EY. That means more growth for you, exciting learning
opportunities, career choices, and the chance to make a real impact.

The selected
candidate
Develops
large and complex data architecture, composed of models, policies, rules or
standards that govern which data is collected and how it is stored, arranged,
integrated and put to use in data systems, including the design, build and
management of data infrastructure to address business requirements
Creates
sound use case driven roadmaps, depicting data architecture as-is and to-be
capabilities with the business by engaging with multidisciplinary teams, and by
identifying, managing and mitigating risk
Develops
relationships across the business to understand data requirements, applies deep
technical knowledge of data management to solve business problems in areas
where solutions may not currently exist, necessitating new solutions/ways of
working/technologies and proactively articulating these to the business
Review,
identify the latest emerging technologies, augmenting by services from the
leading cloud providers to solution and recommend the best next generation data
platform value driven approach for our clients
Your Key Responsibilities Include
Create
and maintain conceptual, logical and physical database models
Document
functional requirements and system specifications into the data architecture
and detailed design specifications for current and proposed designs
Document
and adhere to development standards and best practices in database designs
Maintain
highly effective and consistent communication within the team, peers, and the
leadership team
Reverse
engineer SQL code and modify it to solve problems/issues
Contribute
to the definition and implementation of data governance practices
Design
both data structures and data integration practices
Work
closely with the infrastructure teams to create a physical environment to
support data services
Evaluate
new and existing (internal and external) technologies and services in support
of data services and data analytics objectives
Skills And Attributes For Success
Understanding
of business process reengineering and business modeling concepts, business
systems development and analysis
Hands-on
experience in designing and implementing hybrid cloud and on-prem solutions
Experience
working with the latest versions of SQL Server
Experience
applying SAFe/Scrum/Kanban methodologies
Ability
to exercise judgment in solving technical, operational, and organizational
challenges
Expert
programming, performance tuning and troubleshooting skills, using the latest
popular programming languages for example python
Demonstrate
proactive approach to identifying issues and presenting solutions and options,
and where appropriate, leading to resolution
Minimum Qualifications
5+ years
demonstratable work experience as a Data Architect using data modeling tools
2-3 years
SQL coding experience on large projects
Must
possess expert SQL programming, performance tuning and troubleshooting skills
Create
database objects and SQL scripts
Understand
and developed data pipelines
Know how
to deformalize data for data science models
Experience
in python, spark and notebooks
Experience
designing data warehousing solutions
Experience
designing next generation data platforms utilising cloud services
In-depth
understanding of database structure principles
Seamlessly
able to translate business requirements to technology requirements
What We Look For
Strong
analytical skills and problem-solving ability
A
self-starter, independent-thinker, curious and creative person with ambition
and passion
Excellent
inter-personal, communication, collaboration, and presentation skills
Customer
focused
Excellent
time management skills
Positive
and constructive minded
Takes
responsibility for continuous self-learning
Takes the
lead and makes decisions in critical times and tough circumstances
Attention
to detail
High
levels of integrity and honesty
Curious
about new emerging technology
About EY
As a global leader in assurance, tax, transaction and consulting
services, we’re using the finance products, expertise and systems we’ve
developed to build a better working world. That starts with a culture that
believes in giving you the training, opportunities and creative freedom to make
things better. Whenever you join, however long you stay, the exceptional EY
experience lasts a lifetime.",3.8,"EY
3.8",Johannesburg,-1,10000+ Employees,1989,Company - Private,Accounting,Accounting & Legal,$10+ billion (USD),-1
Data Architect - Principal,-1,"We are looking for Principle Data Architect to join our Engineering team in Cape Town.

The world is changing.
We all want something different.
At Luno, we see you as individuals.

Together, we are upgrading the world of work to unleash the potential within and empower you to become the best possible version of yourself.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the financial landscape, and to do so, well we need the best team on board for our mission. In short, to achieve our goals, we need rockstars. As simple as that.

A little about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 5 million customers across 40 countries.
We're part of the Digital Currency Group, a group of companies driving progress in the cryptocurrency and blockchain space that includes Grayscale, Genesis, Coindesk and Foundry Services
Our platform has processed over $8 billion to date
We're proud to be one of the world's most international cryptocurrency teams from 43 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.
How we work


Our engineering team (currently ~100 engineers) is split into organisations which we call Fleets. Each Fleet focuses on a core customer journey (onboarding, security, payments, support, new business, growth and marketing etc.). Each of these fleets contains multiple smaller teams called Pods, each of which focuses on a specific aspect of the product.

Pods will include a product owner, product designer, back-end engineers, Android, iOS and Web developers, who each bring a unique perspective to the problem you are all contributing towards.

We're agile, use scrum, continuous integration and continuous delivery, deploying to production every single day.

We're building teams to help us succeed in our mission to upgrade the world to a better financial system. You'll be joining a group of highly motivated software engineers who you'll work collaboratively with across our pods.

As a fast-growing company with offices around the world, you'll immediately see how your contributions directly impact both our internal users and client experience. Many of the problems we are solving result in trail blazing solutions which can't be found on Stack Overflow; so we're looking for engineers who flourish working in a complex domain.

In your first six months, you will:


...start at Luno by learning our processes, meeting the wider team and starting our engineering on-boarding program. After getting comfortable with the basics, you'll start learning our idiomatic patterns in a safe, easy-to-follow way - by building your own toy micro services. You'll get to practice how we do design docs, code reviews, deployments, events, logging and monitoring.

You'll meet the Pod(s) you'll be working with and quickly align on the teams' current OKRs and product roadmap. We succeed as a team, so we will provide you with regular feedback from your manager and peers and will encourage you to do the same.

What you'll do:
Work closely with our data science and platform teams on projects introducing new streams of data into our data lake
You will get to bring new ideas on how to further develop and innovate our data solutions and how to expose that data to the business
Accountable and Responsible for the design and architecture of Data systems that are robust and scalable.
Work in an Agile/Scrum framework or Agile mindset
Data backup/recovery and storage
Pick-up and learn new concepts, in both engineering and product, and be able to apply that knowledge quickly.
The ideal candidate for this role will have:
7+ years' experience in maintaining scalable data solutions and/or you are passionate about it
Ability to understand, communicate and advocate between build vs buy
Proven track record of setting up, restructuring and maintenance of databases
You know your way around ETL and you have experience with SQL
Experience in the AWS Data stack (RedShift,DynamoDB, Amazon RDS)
Familiarity with integrating data stores with BI platforms such as Looker, Tableau, or Power BI
You have experience with the concepts of CI/CD
Coding skills in e.g. Go, Python
Bachelor's degree in a related field preferred
AWS Certified DataOps Administrator
Be friendly, transparent, articulate and driven to succeed
Basic knowledge of and passion for digital currencies like Bitcoin
A work permit for South Africa if you are not a South African citizen
Don't be put off if you don't tick all of the boxes – they're a guide based on what we'd love to see but we appreciate that excellent software engineers have diverse backgrounds.

Remote Life at Luno


If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity / paternity and even (yes, you are reading it correctly) paw-ternity for your furry friend..
Annual Inspiration Day.. like that pottery course you've always been meaning to do!
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. You'll need to hold the legal right to work in South Africa already as we cannot provide visa sponsorship.

Be part of the change!",4.6,"Luno
4.6",Cape Town,-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer - EC2 Capacity Data Analytics,-1,"EC2 Capacity Data Analytics (CDA) team is looking for a Data Engineer to join our team.

Our team is part of the EC2 Capacity Engineering organization, which is responsible for providing the elasticity EC2 customers need to scale up/down compute resources in a cost-efficient manner. We predict customer usage across thousands of configuration combinations to deliver exactly what our customers require in just the right amount of time with just the right amount of capacity.

As a Data Engineer, you will build the ETL and analytics solutions for our internal customers to answer questions with data and drive critical improvements for the business. You will use best practices in software engineering, data management, data storage, data compute, and distributed systems. On any given day, we use Python, Scala, Java, SQL, Lambda, CloudFormation, Redshift and Glue as well as other public AWS services and a host of Amazon internal tools. We dont expect you to be an expert in, or necessarily even be familiar with all of the technologies listed above, but we do expect you to be excited to learn about them.

This position involves on-call responsibilities, typically for one week every two months. Our team is dedicated to supporting new team members. We care about your career growth, we try to assign projects and tasks based on what will help each team member develop into a more well-rounded engineer and enable them to take on more complex tasks in the future.

Our team values work-life balance and we are flexible when people occasionally need to work from home.

Job Duties
Develop and maintain automated ETL pipelines for big data using languages such as Scala, Spark, SQL and AWS services such as S3, Glue, Lambda, SNS, SQS, KMS. Example: ETL jobs that process a continuous flow of JSON source files and output the data in a business-friendly Parquet format that can be efficiently queried via Redshift Spectrum using SQL to answer business question.

Develop and maintain automated ETL monitoring and alarming solutions using Java/Python/Scala, Spark, SQL, and AWS services such as CloudWatch and Lambda.

Implement and support reporting and analytics infrastructure for internal business customers using AWS, services such Athena, Redshift, Spectrum, EMR, and QuickSight.

Develop and maintain data security and permissions solutions for enterprise scale data warehouse and data lake implementations including data encryption and database user access controls and logging.

Develop and maintain data warehouse and data lake metadata, data catalog, and user documentation for internal business customers.

Develop, test, and deploy code using internal software development toolsets. This includes the code for deploying infrastructure and solutions for secure data storage, ETL pipelines, data catalog, and data query.


Basic Qualifications

· Bachelors degree in Computer Science or related technical field, or equivalent work experience.
· 4+ years of overall work experience including Software Engineering, Data Engineering, Database Engineering, Business Intelligence.
· Experience with AWS technologies stack including Lambda, Glue, Redshift, RDS, S3, EMR or similar big data solutions stack

Preferred Qualifications

· Demonstrate efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data.
· Demonstrable proficiency in distributed systems and data architecture; design and implementation of batch and stream data processing pipelines; knows how to optimize the distribution, partitioning, and MPP of high-level data structures.

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer,-1,"Our client based in Johannesburg is urgently looking for a Data Engineer to be on a 3 months contract
Build data pipelines, experience in new tech like nifi, kafka, python

Joburg based, open to EE, 3 month contract with the option to extend, must be available at short notice",-1,EQplus,Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Overview
Job ID: 51456
Job Sector: Information Technology and Services
Country: South Africa
Region/State/Province/District: Gauteng
Location: Johannesburg

Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose

This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes

Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems

Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions

Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.
Research and best practices

Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development

Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.

Preferred Qualification and Experience

Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry

Knowledge/Technical Skills/Expertise

Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision

PLEASE NOTE: All our recruitment and selection processes comply with applicable local laws and regulations. We will never ask for money or any form of payment as part of our recruitment process. If you experience this, please contact our Fraudline on +27 800222050 or forward to TransactionFraudOpsSA@standardbank.co.za",4.1,"Standard Bank
4.1",Johannesburg,-1,201 to 500 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"About us

At PBT Group we pride ourselves on being a Data Specialist organisation. With 20 years of experience in 27 countries over 3 continents, our team of 550 consultants have implemented more than 700 projects.",4.3,"PBT Group
4.3",Johannesburg,-1,Unknown,-1,Company - Private,Accounting,Accounting & Legal,Less than $1 million (USD),-1
Data Engineer,-1,"Kick-start your career in the online gaming world and experience the very latest in technology and innovation.

The Department:

Our mission is to provide our customers with the best online betting experience and share the thrill of gaming with them. Data is at the very heart of our business and is vital in everything we do.

Our cross-functional Data team has a big and exciting challenge ahead. We are in the process of re-platforming our traditional, on-premises RDBMS environment to a new microservice architecture in the cloud. We’re making use of the diverse set of data technologies in Microsoft Azure to offer new services, reporting structures and real-time data pipeline while serving the day-to-day requirements of a rapidly growing, data-hungry organisation.

Purpose of the Role:

This is an excellent opportunity for an individual who is looking to gain new skills. We are committed to creating a culture of learning and regularly run proof of concepts, provide internal demos, manage workshops and attend external conferences. Our data team has a wide range of skills including development for highly transactional RDBMS systems, data warehousing, data science and cloud technologies and we are always working to raise everyone’s game.

Duties include, but not limited to:

Work as part of an agile Data Engineering Team
Development of greenfield projects in Azure
Develop and maintain on-premises RDBMS/DW systems
Create robust ETL services and real-time data pipelines
Build and maintain Continuous Integration and DevOps pipelines
Test-driven development and pair programming with colleagues

Essential Criteria:

C#, .Net, Visual Studio
Git, Azure DevOps
NoSQL development (CosmosDB)
Demonstrable understanding of MS SQL Server in a highly transactional environment
Demonstrable understanding of development in Microsoft Azure
Able to understand query plans and identify performance bottlenecks
Test/Business-Driven Development
Building Continuous Integration/Deployment pipelines
Communicate effectively with both technical and non-technical stakeholders

Desirable Criteria:

Implementing Data Storage and Processing solutions in Azure (ARM Templates, Storage Accounts, Data Lake Storage, SQL DB, Cosmos DB, EventHubs, Function Apps, Log Analytics, Data Factory, Databricks, Polybase)
Implementing Security, Disaster Recovery, High Availability, Auditing, Monitoring and Alerting solutions in Azure
Automating tasks in Azure using Powershell / CLI
Predicting costs and optimizing spending in Azure
Message Queues (RabbitMQ, Kafka)
Python

Person Specifications:

Resilience
Teamwork
Technical Knowledge
Communication skills
Stress Tolerance
Please note we will apply relevance to our Talent Management and Talent Development Programme as part of our recruitment process.
Shortlisted candidates may need to complete an assessment.
This position requires trust and honesty it has access to customers financial details - therefore a credit and criminal record check will be conducted. The qualifications identified herein are an inherent job requirement; therefore, a qualification verification check will be done. By applying for this role, and supplying the necessary details, you hereby grant us permission to apply for these checks. This will be done in a confidential manner, and solely for the purposes of verification.

To view all current vacancies, please visit our website, www.digioutsource.com

Should you not hear from us within 2 weeks, please deem your application as unsuccessful.

The perfect place to work, play and grow!",3.9,"Digital Outsource Services
3.9",Cape Town,-1,1001 to 5000 Employees,1997,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
Data Engineer,-1,"At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes

Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.

Key Responsibilities

Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.

Key Traits

Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern

Position Requirements

2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.

Where will you work? This role will be based out of Durbanville, South Africa.",3.1,"Aculocity, LLC
3.1",Durbanville,-1,1 to 50 Employees,2006,Company - Private,IT Services,Information Technology,$1 to $5 million (USD),-1
Data Engineer,-1,"ENVIRONMENT:

A rapidly growing E-Commerce Platform seeks a highly talented Data Engineer to make an invaluable contribution to data democratisation and literacy vision by making accessible and easy-to-use data products and tools. You will require a Comp-Sci Degree or 3 years’ relevant industry experience, MySQL, PostgreSQL, Java, Python, in-depth understanding of OLAP, Data Marts, Star Scheme, Snowflake, be familiar with Jenkins, Travis, Circle CI, Docker, Kubernetes, experience with Kafka, Pub/Sub, Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks & significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing & Data Lake design and implementation and Lambda/Kappa architectures.

DUTIES:

Design, develop, test and maintain data architecture.

Prepare data for descriptive, predictive and prescriptive modelling.

Automate repetitive tasks and manual processes related with the data usage.

Optimize data delivery.

Design, develop and test large stream data pipelines to ingest, aggregate, clean, and distribute data models ready for analysis.

Ensure the highest standard in data integrity.

Leverage best practices in continuous integration and delivery.

Collaborate with other engineers, ML experts, analysts, and stakeholders to produce the most efficient and valuable solutions.

Implement features, technology, and processes that move us towards industry best practices, improving on scalability, efficiency, reliability, and security.

Operations and ownership of systems in production, responding to incidents.

REQUIREMENTS:

Qualifications –

Comp-Sci Degree or 3 years relevant industry experience.

Experience/Skills –

Open source relational database systems e.g. MySQL, PostgreSQL, etc.

Significant technical experience and a proven track record of Data Modelling, Schema Design, Data Warehousing, and Data Lake design and implementation and Lambda/Kappa architectures.

A thorough understanding of database and data warehousing principles e.g. OLAP, Data Marts, Star Schema, Snowflake, etc.

Java and Python.

Familiar with CI/CD tools such as Jenkins, Travis, Circle CI, etc.

Experience with Kafka, Pub/Sub, or other event-based systems.

Stream data pipeline frameworks or solutions such as Apache Flink, Apache Beam, Storm, Databricks, etc.

Working in cloud environments and with containerisation frameworks, tools and platforms e.g. Docker, Kubernetes, GKE, etc.

A deep understanding of data pipelining, streaming, and Big Data technologies, methods, patterns, and techniques.

Troubleshooting complex database operations and performance issues.

Automating tasks using Shell Scripting or writing small applications.

ATTRIBUTES:

Works well with people and is passionate about helping people be their best.

A team player, an active listener, mentor, and able to communicate well.

Shows solid reasoning and decision making, with the ability to work under pressure.

Is passionate about technology, systems and data.

Is curious, always learning, and keeping up to date with the industry.

While we would really like to respond to every application, should you not be contacted for this position within 10 working days please consider your application unsuccessful.

COMMENTS:

When applying for jobs, ensure that you have the minimum job requirements. Only SA Citizens will be considered for this role. If you are not in the mentioned location of any of the jobs, please note your relocation plans in all applications for jobs and correspondence.",-1,Datafin IT Recruitment,Cape Town,-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Cartrack is looking for passionate data science and engineering candidates that can join a growing team that is responsible for the intelligence and efficiency solution provision to over a million subscribers, many of whom are large fleets. We are in the midst of creating revolutionary platforms that will change the way that people interact with their vehicles.

You will have the opportunity to work with the very brightest global subject matter experts that are transforming the automotive industry across Fleet Management, Asset Management and Insurance Telematics solutions.

Get to know the role:

The role of a data engineer is a supporting one, but it is also an extremely vital one. As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements. We want to see candidates with mechanical tendencies and a desire to know how things work and to improve them.

The day-to-day activities:

Design, construct, install, test and maintain data management systems.
Build high-performance algorithms, predictive models, and prototypes.
Ensure that all systems meet the business/company requirements as well as industry practices.
Integrate up-and-coming data management and software engineering technologies into existing data structures.
Develop set processes for data mining, data modeling, and data production.
Create custom software components and analytics applications.
Research new uses for existing data.
Employ an array of technological languages and tools to connect systems together.
Install/update disaster recovery procedures.
Recommend different ways to constantly improve data reliability and quality.
Work on and maintain Data pipelines.

Requirements Essential:

At least 5 years’ proven experience as a Data Engineer, DevOps Engineer, Software Developer, or similar.
Proficient in Linux/Unix and shell scripting as well as in functional programming languages.
Expertise in setting up and explored with technologies such as Hadoop and Spark.
Bachelor’s degree in computer science, software/computer engineering, applied mathematics, or physics.",3.3,"Cartrack
3.3",Johannesburg,-1,501 to 1000 Employees,2004,Company - Private,Security Services,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Data Engineer,-1,"Data Engineers build and support data pipelines and datamarts built off those pipelines. Both must be scalable, repeatable and secure. The Data Engineer helps to facilitate gathering data from a variety of different sources, in the correct format, assuring that it conforms to data quality standards and assuring that downstream users can get to that data timeously. This role functions as a core member of an agile team. These professionals are responsible for the infrastructure that provides insights from raw data, handling and integrating diverse sources of data seamlessly. They enable solutions, by handling large volumes of data in batch and real-time by leveraging emerging technologies from both the big data and cloud spaces. Additional responsibilities include developing proof of concepts and implements complex big data solutions with a focus on collecting, parsing, managing, analysing and visualising large datasets. They know how to apply technologies to solve the problems of working with large volumes of data in diverse formats to deliver innovative solutions. Data Engineering is a technical job that requires substantial expertise in a broad range of software development and programming fields. These professionals have a knowledge of data analysis, end user requirements and business requirements analysis to develop a clear understanding of the business need and to incorporate these needs into a technical solution. They have a solid understanding of physical database design and the systems development lifecycle. This role must work well in a team environment.

Job Objectives

Work Complexity: * Architects Data analytics framework. * Translates complex functional and technical requirements into detailed architecture, design, and high performing software. * Leads Data and batch/real-time analytical solutions leveraging transformational technologies. * Works on multiple projects as a technical lead driving user story analysis and elaboration, design and development of software applications, testing, and builds automation tools.

Main Job Objectives: 1. Development and Operations 2. Database Development and Operations 3. Policies, Standards and Procedures 4. Communications 5. Business Continuity & Disaster Recovery 6. Research and Evaluation 7. Coaching/ Mentoring

Qualifications

Essential: 4 years Bachelors degree in computer science, computer engineering, or equivalent work experience AWS Certification at least to associate level

Experience

Essential:

5+ years Data engineering or software engineering

3-5 years demonstrated experience leading teams of engineers

2+ years Big Data experience

5+ years experience with Extract Transform and Load (ETL) processes

2+ years Could AWS experience

At least 2 years demonstrated experience with agile or other rapid application development methods - Agile exposure, Kanban or Scrum

5 years demonstrated experience with object oriented design, coding and testing patterns as well as experience in engineering (commercial or open source) software platforms and large scale data infrastructures.

Desirable:

5+ years Retail Operations experience

Knowledge and Skills

Essential: *Creating data feeds from on-premise to AWS Cloud (2 years) *Support data feeds in production on break fix basis (2 years) *Creating data marts using Talend or similar ETL development tool (4 years) *Manipulating data using python and pyspark (2 years) *Processing data using the Hadoop paradigm particularly using EMR, AWSs distribution of Hadoop (2 years) *Devop for Big Data and Business Intelligence including automated testing and deployment (2 years) * Extensive knowledge in different programming or scripting languages * Expert knowledge of data modeling and understanding of different data structures and their benefits and limitations under particular use cases.

Further technical skills required: * Capability to architect highly scalable distributed systems, using different open source tools. * Big Data batch and streaming tools * Talend (1 year) * AWS: EMR, EC2, S3 (1 year) * Python (1 year) * PySpark or Spark (1 year) - Desirable * Business Intelligence Data modelling (3 years) * SQL (3 years)",-1,Datonomy Solutions,Brackenfell,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We are assisting one of our clients that is based in Pretoria to fill a role of a Data Engineer

This is a 12 month contract role

Objective of this Scope of Work

The Data Engineer will drive improvement of the data management maturity levels and provide the necessary technical support within the company to support reliable and effective decision-making, appropriate usage and protection thereof.

Scope of Services Definition

The scope will include but will not be limited to:

ï†· To develop, construct, test and maintain architectures.

ï†· To ensure architectures will support the requirements of business.

ï†· To discover opportunities for data acquisition and sharing.

ï†· To develop data set processes for data modelling, mining and production.

ï†· To employ a variety of languages and tools to marry systems together.

ï†· To recommend way to improve data reliability, efficiency and quality.

ï†· To prepare data for use in predictive and prescriptive modelling.

ï†· To conduct research to answer industry and business questions.

ï†· To leverage volumes of data from internal and external to answer business questions.

ï†· To develop and manage stakeholder relations effectively to promote data management across the organisation and support reliable decision making and appropriate data usage.

ï†· To participate and provide technical support in cross organisational activities relating to any of the above mentioned data management activities.

ï†· To provide regular progress reports as per stakeholder requirements and present data management updates in various forums as required.

Minimum qualification Required:

ï†· A minimum of a Bachelors degree in Computer Science or Information Management OR equivalent;

ï†· A minimum of five to eight years experience in a data management environment",-1,HR Genie,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Our client based in the Northern Suburbs, is currently looking for a Data Engineer to join their team.

Responsibilities
Our client is a dynamic IT company that delivers value-driven IT solutions to the group. Our work lives revolve around our DNA. We take pride in our work, treat our colleagues, partners and our country with respect. We exercise collaborative decision-making and believe in having a balance in life. We do this all while having fun and enjoying what we do.

The primary focus of this position is to use technical skills to put software, systems and data together in a way that extracts meaningful insights from raw data. You will need to be helpful and supportive to your team and fellow developers. You join an energetic, focused and dynamic team.

Interact with clients to understand requirements and business problems/needs

Identify, analyse, visualise and understand supporting data to propose solid solutions

Create technical documentation for reference and reporting

Support existing solutions within GCP and Oracle

Doing standby on a rotating basis

Key Competencies and Qualifications

Matric

Tertiary qualification in IT

Preferred cloud experience in AWS/AZURE/GCP

At least 3 years of data warehouse ETL experience

Dimensional Modelling

Data analyses

Experience with data visualization and visualization tool(s)

Knowledge of the retail industry will be beneficial

Understanding and experience with version control SVN/GIT

Preferred – Korn shell scripting, Python/Java, SQL

Google Cloud Platform experience would be looked upon favourably

Having a broad understanding of different SDLC’s

Preferred agile experience

Strengths

The natural tendency to take ownership and responsibility

Strong problem solving, critical thinking, effective planning and organisational skills

Detail-oriented with excellent communication skills

You have a can-do attitude and positive outlook on life

Can cope under pressure

Curious and interested in analysing problems and possible solutions

Strong team player

Self-driven learner, passionate about new technology

Above all, be passionate about what you do

Should you wish to apply for the position, please apply directly via this job board, please ensure that you quote reference number 201620 subject heading or email body.

Please note that due to the high volume of CV's received; only shortlisted applicants will be contacted. Should you not receive communication from our offices within two weeks of submission please note that your application will not be considered for this position.

We will keep your CV on file and re-establish contact with you should opportunities in line with your expertise become available again.

Should you require any additional information give us a call on 021 012 5566.",-1,Surgo HR & Training,Cape Town,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We believe that our employees fuel our organization, essential to enable us to help our customers overcome their business challenges and achieve sustainable growth. As a result, we are committed to growing each individual and providing them with the challenges, feedback and support needed to achieve success in their career

If this sounds appealing, and like us, you get excited about data: its collection, storage, transformation or display, see if you’ve got what it takes to join our sought after DATA team.

Key Responsibilities And/or Outputs

You will represent IQbusiness at our customers, sometimes alone, and sometimes as part of an IQ team.

Providing a superior customer experience by building and maintaining relationships, working at customer offices, keeping data confidential
Design and develop – databases, SQL queries, stored procedures, reports, dashboards or integration solutions
Produce solutions for both real-time and batch environments
Test your work to ensure compliance
Solve problems, and do root cause analysis
Prioritize your workload
Assist in other areas relating to your true data function, such as data modeling, data and business analysts
Interact with a variety of individuals: senior, junior, technical and from business
Provide guidance to fellow colleagues, or even manage a team
Uphold the IQ values, which are to care, learn & share; innovate; deliver as well as to build, enhance and maintain relationships

Education

Matric pass
A tertiary qualification, preferably in an ICT relevant field
Appropriate Microsoft certifications are beneficial but not required

Requirements

3 - 6 years experience in the Data Engineering environments and technologies
Great communication skills
A passion for SQL, databases or reports
Can you write stored procedures, design complex queries and create views and triggers?
Are you able to work out the relationships in a data warehouse or the aggregation of a cube?
Do you extract and display useful information when you see patterns and trends in data?
Strong knowledge of the financial services industry, ideally in a consulting role
The use of data related software: databases, ETL and BI tools; report writing and analytical tools
We use a lot of Microsoft products. You may often be expected to use MS SQL Server, SSIS, SSRS, SSAS and Power BI to develop solutions
What other relevant software have you’ve used?
Ability to work in different project methodologies: Waterfall and/or Agile
Knowledge of full SDLC
Exposure to logical and physical data modeling

Equal Employment Opportunity

IQbusiness is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, citizenship, marital, domestic or civil partnership status, sexual orientation, or gender identity",3.7,"IQbusiness South Africa
3.7",Johannesburg,-1,1 to 50 Employees,-1,Company - Private,Consulting,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"We value a data engineer as someone who works behind the scenes to obtain, process and supply data via various methodologies and technologies, to various consumers, in ways and forms that makes sense and add value. This definition is very broad, as the field of data engineering is just as broad.

You may be the type of data engineer that develops API endpoints for the consumption of data by end users or even another data pipeline, or you may be the type of data engineer that develops highly distributed, high availability data processing pipelines in an effort to satisfy the need of the ever questioning data analysts and/or data scientists.

You have awesome knowledge about the following concepts
Data modelling
Relational data modelling in traditional relational database management systems. (Microsoft SQL Server, MySQL, PostgreSQL, etc)
Coercing unstructured and semi-structured data into a structured form.
Data pipelining knowledge - data extraction and transformation.
Data transformation knowledge for reporting and analytics purposes.
Knowledge of the MapReduce and related data processing paradigms would be a boon.
You have the following technical competencies
Writing SQL queries, that can relate, transform and aggregate data from many differing sources where natural keys may or may not exist.
Experience with writing data pipelines that move and transform data, for various uses.
Working knowledge of a general purpose programming language like Python would be a boost.
Working knowledge of columnar databases such as Google BigQuery, and SAP HANA would be a boost.
Working knowledge of highly distributed technologies such as Apache Hadoop or Apache Spark would be a boost.
Working knowledge of NoSQL technologies, such as Apache Solr would be a boost.
You have the following personal competencies
The ability to solve problems.
The ability to rotate around a problem, to see if solutions can be gained in different ways.
The ability to work in an ever changing, unstructured environment.
The ability to work as part of a team, with vastly differing skill sets and opinions.
The ability to contribute ideas to the quorum.
The ability to mentor and provide guidance for other team members.
A systems approach to thinking, as opposed to a siloed approach. The candidate needs to understand how their work affects the greater system.
The ability to work without supervision, and take accountability for the work they deliver.
The ability to liaise with a client, sifting through the fluff and extracting the actual requirements.
If this is you - apply now and we'll get in touch",-1,DotModus,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Data Engineer

Our client in the contact centre space is currently seeking a DATA ENGINEER that will work on the collecting, storing, processing, and analyzing of large datasets. The primary focus will be on choosing optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them. You will also be responsible for integrating them with the architecture used across the company.

Key Performance Areas:

Data reporting.
Implementing ETL processes.
Defining data retention policies.
Management of Customer Lead data.
Provision of data for advanced analytics.
Maintenance of internal client scorecards.
Assist team in resolving data-related support queries.
Optimize existing data processes through automation.
Assist with all data-related reporting and documentation.
Maintenance and optimisation of the Analytics database.
Provide technical support to and supervision of junior data administrators.
Continuous upskilling on new technologies, frameworks and market trends.
Monitoring performance and advising any necessary infrastructure changes.
Identifying, selecting and integrating any Big Data tools and frameworks required to provide real-time analytics.

Educational Requirements

IT related Degree or Diploma is a pre-requisite

Required Skills/Experience

ETL tools: Advanced SSIS
BI/Reporting : Qlikview/Power BI/ SSRS or SSAS
Programming languages: JAVA, C# , Python, SAS or R
Experience with NoSQL databases and/or campaign management tools will be advantageous.
Minimum 3 years’ applicable work experience in SQL, relational databases and data manipulation.
Experience in big data platforms (eg. Hadoop) or processing frameworks (eg. MapReduce/Spark) and querying tools (eg. Pig, Hive and Impala) will be highly beneficial.

Preferred Skills

Organizational skills
Experience in Attentional to detail.
Accountability is critical for this role.
Ability to work under pressure and meet deadlines.
Solid understanding of database design principles.
Should you not receive a response in 2 weeks please consider your application unsuccessful",-1,Rubik's Cubed Consulting,Durban,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Job Details

Risk Management: understanding all risks – from the economic to the political – that could affect our global business, and offering guidance to all parts of the bank

Job Purpose


Responsible for building the organisations data collection systems and processing pipelines. Oversee infrastructure, tools and frameworks used to support the delivery of end-to-end solutions to business problems through high performing data infrastructure.
Responsible for expanding and optimising the organisations data and data pipeline architecture, whilst optimising data flow and collection to ultimately support data initiatives.

Key Responsibilities/Accountabilities


Data:
• Owns and extends the business’s data pipeline through the collection, storage, processing, and transformation of large data-sets and oversee the process for creating and maintaining optimal data pipeline architecture and creating databases optimized for performance, implementing schema changes, and maintaining data architecture standards across the required Standard Bank databases.
• Oversee the assembly of large, complex data sets that meet functional / non-functional business requirements and align data architecture with business requirements.
• Responsible overseeing the process for enabling and running data migrations across different databases and different servers and defines and implements data stores based on system requirements and consumer requirements.
• Oversee, design, and develop algorithms for real-time data processing within the business and to create the frameworks that enable quick and

Product:
• Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Create data tools for analytics and data scientist team members that assist them in building and optimising Standard Bank into an innovative industry leader.
• Monitor the existing metrics, analyse data, and lead partnership with other Data and Analytics teams in an effort to identify and implement system and process improvements. Utilise data to discover tasks that can be automated and identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
• Developing ETL processes that convert data into formats for consumption.

Risk, Regulatory, Prudential and Compliance:
• Responsible for executing testing and validation in line with data governance and quality business requirements.

People:
• Liaise with and collaborate with data analysts, data warehousing engineers, and data scientists in finding and applying best practices within the Data and Analytics department as well as defining the business’s data requirements, which will ensure that the collected data is of a high quality and optimal for use across the department and the business at large.
• Acts as a subject matter expert from a data perspective and provides input into all decisions relating to data engineering and the use thereof. Provide guidance in terms of setting governance standards.

Strategy:
• Responsibility for contributing to the continual improvement of the business’s data platforms through thorough observations and well-researched knowledge. Keeps track of industry best practices and trends and through acquired knowledge, takes advantage of process and system improvement opportunities.
• Provide oversights and expertise to the Data Insights and Analytics that is responsible for the design, deployment, and maintenance of the business’s data requirements.

Preferred Qualification and Experience


Minimum qualification 1
Post Graduate Degree: Information Technology

Minimum qualification 2
Post Graduate Degree: Information Studies

Preferred qualification 1
Masters Degree: Information Technology

Preferred qualification 2
Masters Degree: Information Studies

Knowledge/Technical Skills/Expertise


IT Architecture:
• Architectural methodologies used in the design and development of IT systems.

Data Integrity:
• The ability to ensure the accuracy and consistency of data for the duration that the data is stored as well as preventing unintentional alterations or loss of data.

IT Applications:
• Knowledge and understanding of IT applications and architecture.

Data Analysis:
• Ability to analyse statistics and other data, interpret and evaluate results, and create reports and presentations for use by others.

Knowledge Classification:
• The ability to apply metadata to information to make it easy for other people to find.",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"This well known company is looking for a Data Engineer. will be based in Rivonia
The ideal candidate will have strong experience in the following:
Data cleaning
SQL Export
Big data Sets

BSc Degree in Maths and Stats will be required
a min of 3 years experience.
Stable track record is required.

Send your Cv to marinda@prrrecruitment.co.za",-1,PRR Recruitment Services,Johannesburg,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Description

Position at Aculocity, LLC

At Aculocity, we fight for the customer’s needs. We are disrupting the data industry by putting the customers’ needs first. We custom-build software designed to deliver competitive advantage for customers, and integrate with existing systems and data to give the customer operational excellence.

It takes a special kind of person to be a part of this business in transformation. We are privately owned and expect our team members to act with an owner mindset: Relentless about creating value for the customer. Dogged about finding efficiencies and eliminating waste. Standing arm and arm with the rest of the team until the job is done—and ready to do it again the next day, with a smile.

It is not easy do things differently. But we do it—because we are passionate about improving our business and the lives of the people who use our tools.

Key Outcomes
Plan, direct and coordinate integration activities on a daily basis between various in-house and third party software subsystems, ensuring they all work smoothly as a unit with a 100% uptime.
Continually define and enforce technical integration standards.
Key Responsibilities
Develop and maintaining system integrations and components, including but not limited to; application-to-application integrations, services, internal and external APIs, file transfer and real time sync.
Bridge the gaps between software development and data management to streamline business intelligence and maximize the value of data.
Lead in systems analysis and design for complex adaptive systems and leverage experience with enterprise architecture frameworks to design effective solutions that span multiple systems and platforms.
Supervise various activities for all integration of software applications for systems and ensure adherence to a technical architecture.
Work closely with development teams to architect, design, build, and implement application integrations.
Advise team on performance, scalability, reliability, monitoring and other operational concerns of integration solutions.
Leverage automation and Microsoft business intelligence stack to derive and display actionable outcomes from business processes.
Write technical integration requirements as needed.
Evaluate existing integration solutions and provide input for performance evaluations.
Clearly understand client short and long-term goals and recommend solutions.
Help trouble shoot critical production issues.
Industrialize solutions with DEVOPS.
Key Traits
Good communication skills.
Ability to work with an international team with international customers in different time zones.
Detailed, accurate, responsive, and inquisitive personality.
Demonstrable ability to learn new concepts quickly.
Be able to self-motivate and govern
Position Requirements
2+ years’ experience in developing and delivering integration and data projects using database, middleware and API methods.
Experience with microservices architecture and API development.
Experience using coding languages to expand base integration software.
Experience using Microsoft SaaS beneficial.
Experience integrating with Cloud/SaaS/PaaS solutions, APIs, and integration with legacy applications.
Experience in relational database management systems like Microsoft SQL Server/PostgreSQL, including data modeling and creating relational databases using SQL.
Solid understanding of the software development lifecycle including continuous integration & delivery using DevOps tools.
Experience in working in Agile teams.
Experience using cloud technologies like Amazon Web Services (AWS) beneficial.
Where will you work? This role will be based out of Durbanville, South Africa.",-1,GVW,Durbanville,-1,Unknown,-1,Unknown,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Information Technology, Gauteng JHB - Northern Suburbs

Market related - Market related Annually

An IT Consultancy Business based in Johannesburg is currently looking for a Business Intelligence Consultant / Data Engineering Consultant.

Requirements:

Extensive experience in data engineering
Experience in Business Intelligence, data and Power BI
Extensive experience in data governance and the Popi act
Ability to assess and make recommendations on data within the Popi act
Good understanding of T-SQL and query optimization, developing ETL strategies.
Good understanding with SQL Server 2008/2012, SSIS, SSRS and SSAS
Use SSIS to create ETL packages to validate, extract, transform, and load data into the data warehouse and data marts.
Deploy and configured the reports in the Report Server (SSRS).
Excellent experience in Tabular Modelling , PowerView, Qlikvie,w, and Power BI
Maintain ETL
Qlikview model
Create Drill-through, Drill-down, and Cross Tab Reports and Sub-Report using Report Definition Language (RDL).
Generate periodic reports based on the statistical analysis of the data using SQL Server Reporting Services (SSRS)
Advise and provide written technical documentation and recommendations

The information displayed above is not limited to advertisements. Please contact Thato for further information.

Please consider your application as unsuccessful if you have not received a response within 14 days of submitting your application. However, please keep a lookout on our website, www.bedifferent.co.za, for available positions that you may be suited for

Ad Visible Until: 29 October 2020
Ref: JHB005346/NL

Vacancy Type: Permanent",2.9,"Be Different Recruitment
2.9",Johannesburg,-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Quality Engineer (Data) – PBB IT,-1,"Job Details

Information Technology: systems development, business analysis, architecture, project management, data warehousing, infrastructure, maintenance and production

Job Purpose
An Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners. They wAn Agile QA Engineer is responsible to participate in feature teams to assist in delivering quality products to the Product Owners.
They will participate and give feedback on any activities where QA practices and risks are to be considered from the writing of user stories, pre-development testing notes, execute QA testing activities in accordance to processes and quality guidelines so as to identify defects / quality concerns in projects
Key Responsibilities/Accountabilities


QA Planning and Preparation:
Where applicable and agreed with the feature team, the correct planning of test scenarios and acceptance tests and test criteria using the available artefacts (FSS/TSS/Change notes/User Stories/Epics) and this is created in collaboration with Product Owner, Feature Analyst and Developer.
Participate in estimation of User Stories during iteration planning.
To identify complex, risky, negative and positive test scenarios.
Test data requirements are provided during grooming session and is prepared such that it should be ready in time for the developers/ testers.
Desk checks with BA’s, Developer’s, Infrastructure and UX’s team should be adhered too and should not hesitate to raise any issues.
Testing notes to be logged on file repository platform such as Confluence.
Visualization board Management (Kanban).

• Ensure all acceptance scenarios are scripted


QA Execution and Tracking:

Prepare Data requirements and ensure data availability for Test case execution. The focus on three types of data: test specific, test reference data to support scenario, application reference data which is needed for the application to start
Collaborate in Demo/Pilot to ensure that all the test scenarios have been catered and plan for exploratory testing which can be conducted over and above the automated unit and functional tests.
Ensure that Integration testing is conducted to ensure that the product works end-to-end. Use of additional testing such as exploratory testing should be conducted to facilitate this.
Ensure that the necessary test stubs and drivers are created with the assistance from the Developers to facilitate test execution where applicable.
All tests executed will contain associated evidence of testing. All test evidence will be attached in appropriate tool such as JIRA as and when required.
All defects associated with the test cases are raised timeously within the test environment, and should be investigated to the point where the impacted downstream system has been established and assigned to correct development resource. Defect SLA’s per priority must be set up and agreed.
JIRA / Management Tool should be utilized to keep a track of the tasks assigned to the QA and dashboards should be created to track the desired metrics for quality with the help of Iteration Manager.
Execution / Velocity targets / Lead time targets as determined by the Iteration Manager are achieved for each iteration/sprint. Any risks should be notified to the Iteration Manager and documented in Confluence for team’s reference.
Ensue scripts are executed.
Ensure regression testing is executed
Reporting:
Execution and reporting targets are met.
Attend other meetings (Inception, Iteration Planning Meeting, Grooming, retrofit session, Defect meetings, and Daily SCRUMS (Stand-ups).
Preferred Qualification and Experience


Qualifications:
National Diploma in IT / Computer Systems
BS/MS degree in Computer Science, Engineering or a related subject
Experience:
Proven working experience in software development Life Cycle - 1-2 Years
Proven working experience in software quality assurance - 1-2 Years
Banking industry experience, preferably in Retail / Business Banking - 3-4 Years
Hands-on experience with both white box and black box testing - 3-4 Years
Hands-on experience with automated testing tools such as QTP/Selenium - 3-4 Years
Hands-on experience with scripting language such as Java/Shell/Ruby - 3-4 Years
Experience working in an Agile/Scrum development process - 3-4 Years
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",-1,Standard Bank and Trust Co.,Johannesburg,-1,-1,-1,-1,-1,-1,-1,-1
Cloud Support Engineer (Big Data),-1,"ABOUT US

Amazon Web Services is the market leader and technology forerunner in the Cloud business. As a member of the AWS Support team you will be at the forefront of this transformational technology, assisting a global list of companies and developers that are taking advantage of a growing set of services and features to run their mission-critical applications. As a Cloud Support Engineer, you will act as the Cloud Ambassador across all the cloud products, arming our customers with required tools & tactics to get the most out of their Product and Support investment.

Would you like to use the latest cloud computing technologies? Do you have an interest in helping customers understand application architectures and integration approaches? Are you familiar with best practices for applications, servers and networks? Do you want to be part of a customer facing technology team helping to ensure the success of Amazon Web Services (AWS) as a leading technology organization?

If you fit the description, you might be the person we are looking for! We are a group of smart people, passionate about cloud computing, and believe that world class support is critical to customer success.

WHAT CAN YOU EXPECT FROM A LIFE AT AWS?

Every day will bring new and exciting challenges on the job while you:

· Learn and use groundbreaking technologies.
· Apply advanced troubleshooting techniques to provide unique solutions to our customers' individual needs.
· Interact with leading engineers around the world.
· Partner with Amazon Web Services teams to help reproduce and resolve customer issues.
· Leverage your extensive customer support experience to provide feedback to internal AWS teams on how to improve our services.
· Drive customer communication during critical events.
· Drive projects that improve support-related processes and our customers technical support experience.
· Write tutorials, how-to videos, and other technical articles for the developer community.
· Work on critical, highly complex customer problems that may span multiple AWS services.

WHY AWS SUPPORT?

· First and foremost this is a customer support role in The Cloud.
· On a typical day, a Support Engineer will be primarily responsible for solving customers cases through a variety of customer contact channels which include telephone, email, and web/live chat. You will apply advanced troubleshooting techniques to provide tailored solutions for our customers and drive customer interactions by thoughtfully working with customers to dive deep into the root cause of an issue.
· Apart from working on a broad spectrum of technical issues, an AWS Support Engineer may also coach/mentor new hires, develop & present training, partner with development teams on complex issues or contact deflection initiatives, participate in new hiring, write tools/script to help the team, or work with leadership on process improvement and strategic initiatives.
· Career development: We promote advancement opportunities across the organization to help you meet your career goals.
· Training: We have training programs to help you develop the skills required to be successful in your role.
· We hire smart people who are keen to build a career with AWS, so we are more interested in the areas that you do know instead of those you havent been exposed to yet.
· Support engineers interested in travel have presented training or participated in focused summits across our sites or at specific AWS events.
· As we operate on a follow-the-sun model, with Premium Support sites located globally, there is no after hours on-call or mandated overtime in this role.
· https://www.youtube.com/watch?v=GC3bWcFFZTo&t=24s



Basic Qualifications

The Big Data role supports our services that leverage data and produce business insights, which may include using Machine Learning/Artificial Intelligence (ML/AI). Helping our customers use and integrate Big Data services in what is arguably our industrys most exciting space. The portfolio of services covers EMR (Hadoop), DynamoDB (NoSQL), MangoDB, and Apache Cassandra.

· Advanced experience in Apache Hadoop, Apache Spark, Apache Hive, and Presto
· Advanced experience in DynamoDB or NoSQL technologies like MongoDB or Cassandra
· Advanced experience with System Administration with Linux (RHEL/CentOS) including Microsoft Active Directory, and LDAP integration.
· Experience with troubleshooting Kerberos Authentication problems.
· Experience with Network troubleshooting.
· Basic understanding of Machine Learning and statistics
· Experience with Java and Python and shell scripting
· Bachelors degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position



Preferred Qualifications

· Expert experience in the Hadoop Ecosystem including Apache Spark and Presto
· Expert experience in NoSQL
· Expert experience with blockchain technologies like Etherium Expert experience in data Data Lake architecture and administration
· Experience managing full application stacks from the OS up through custom applications
· Prior work experience with AWS - any or all of EC2, VPC, S3, RDS, EMR, Glue, SageMaker
· Excellent knowledge of Hadoop architecture, administration and support
· Expert understanding of distributed computing principles and their application in the cloud
· Good understanding of distributed computing environments Lead technical discussions on big data systems architecture and design
· Strong analysis and troubleshooting skills and experience
· AWS Certified Solutions Architect
· AWS certified Big Data Specialty
· Masters degree in Information Science / Information Technology, Data Science, Computer Science, Engineering, Mathematics, Physics, or a related field OR equivalent experience in a technical position

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity and Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Response Center Engineer,-1,"Job Title
Response Center Engineer
Job Description


Philips is a world leading health technology company with a vision to make life better for people worldwide through meaningful innovation. Making good on this promise depends on our passionate, inspirational, collaborative and diverse team. We have over 80,000+ brilliant people around the world but are always looking for more. Like-minded, motivated, focused minds to join us in creating a healthier, more connected society while transforming themselves personally and professionally.

As a CCC Coordinator - Response Center Engineer you will have the opportunity to process customer calls and be responsible for screening and diagnosing professionally Healthcare equipment to support customers and colleagues remotely with solving technical issues and ensuring maximum customer satisfaction

You are responsible for:
Diagnose healthcare equipment to the quality standards set by Philips Healthcare (PH) remotely by interviewing customers or colleagues by telephone or by remotely logging in to the system
Advise Customer Care Center Coordinators and District Operations Managers and / or Team Leads about the best follow-up w.r.t. technical state of the diagnosed healthcare equipment
Advise the Customer Care Center Coordinators or Field Services Engineers about required spare parts and resources
Responsible for planning engineers related to Modality responsibility.
Responsible for coordination between CCC, CUSTOMER, Spare parts AND Engineer.
Responsible to drive Remote and FTR KPI’s to targets respectively 40% and 85%.
Will require minimal field work to keep abreast of technical capabilities.
Take calls from customers and make sure they are processed in the CCC ERP on timely manner including all relevant data
Support Field Services Engineers in the field with technical knowledge
Escalate technical issues to the Technical Support Specialist
Escalate technical issues to Business Unit support after consultation of the Technical Support Specialist
Monitor critical functions of the equipment’s in the IB and environmental conditions including RSN and True reachability.
Lead the planning and implementation of FSN’s and FCO’s accelerating remote implementation where applicable.
Submit timely and accurate service data, job sheets, reports, expense claims, radiation film badges, field problem reports and other paperwork as assigned
Keep abreast of new technologies likely to affect PH range of products
Use company property with care to ensure optimal results with minimal operational costs
Be a professional representative for PH with respect to customer problems, ensuring personal acceptability by the customer in behavior in accordance with PH policy and targets
Conform to PH safety standards including health and safety regulations and in the event of hazards or accidents to take immediate control of the situation and involve the Operations Manager and / or the responsible person to handle properly confidential issues according Philips standards and to act according General Business Principals
Follow all quality standards within the frame of valid PH business policies
Follow the company quality regulations (ISO 9001; PQA; TQM) and internal directives and procedures
You are a part of the dynamic South Africa Customer Care Centre Team .You will be reporting to the Customer Care Center Manager.

Requires a pleasant, assertive individual you can work very well in a team setting, a dynamic environment that requires flexibility and creativeness to achieve goals.

To succeed in this role, you should have the following skills and experience:
Degree level education or equivalent
Experience in maintenance and troubleshooting of technical complex systems
Fluent in English, verbal and written in addition to local language
In return, we offer you the unique combination of a critical and challenging role and a creative and empowering office environment. You will be actively encouraged to make improvements, establish best in class service and have a direct impact on the success of Philips on a daily basis.

Employment Equity

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply. Only apply for this role if you are a South African Citizen by birth or Naturalization prior to the 27 April 1994.

Why should you join Philips?

Working at Philips is more than a job. It’s a calling to create a healthier society through meaningful work, focused on improving 3 billion lives a year by delivering innovative solutions across the health continuum. Our people experience a variety of unexpected moments when their lives and careers come together in meaningful ways. Learn more by watching this video.

To find out more about what it’s like working for Philips at a personal level, visit the Working at Philips page on our career website, where you can read stories from our employee blog. Once there, you can also learn about our recruitment process, or find answers to some of the frequently asked questions.

Contact


If you forgot your password, you can click the Forgot Password button on the Sign In screen to reset it.

If you have any other questions regarding the recruitment process please refer to our FAQs. In case of technical difficulties with the website, please send an email to careersite@philips.com.
(Note: To ensure fairness and legal compliance in our recruitment processes, only technical issues will be monitored through the above inbox. Please do not submit resumes or applications to this email, as they will not be reviewed. Only applications received through the online application process will be considered.)",3.9,"Philips
3.9",Johannesburg,-1,10000+ Employees,1891,Company - Public,Health Care Services & Hospitals,Health Care,$10 to $25 million (USD),-1
Software Development Engineer - EC2 Placement,-1,"Build the systems that optimize how EC2 matches requests for Instances with the underlying compute capacity. EC2 Placement is seeking talented engineers to build the online and offline optimization systems for compute workload scheduling, and the customer capabilities to better manage those workloads. Amazon EC2 provides on-demand scalable compute capacity, and powers some of the largest services in the world. You will collaborate with a top-tier community of engineers to build systems to improve how customers are able to access EC2 compute resources.

The successful candidate will have strong software engineering experience, with a passion for thinking about, building and testing distributed systems. You have an interest in how Machine Learning and other optimization techniques can be applied to large-scale problems. You have demonstrated experience working with a team to design, build and operate large-scale systems. With strong engineering fundamentals, an analytical and data-driven approach to your work, and strong communication skills, you have the ability to collaborate well to deliver results. We move fast and work together on small teams to solve big problems.

If this opportunity sounds interesting, we would love to talk to you more about our work and the vibrant culture at AWS in Cape Town.

Basic Qualifications

· Degree in Computer Science or related field, or equivalent working experience
· 3+ years of industry experience in a software development environment
· Strong Computer Science fundamentals, including data structures, object-oriented design, algorithm design, problem solving, and complexity analysis.
· Proficiency in at least one modern programming language, such as Java, C#, Python, Scala, Kotlin

Preferred Qualifications

One or more of the following help you stand out:
· Demonstrated results designing, building and operating high-performance distributed systems in large-scale Linux environments
· Role model in writing high-quality, maintainable and secure code, mentoring others, and helping teams sharpen their development processes
· Ability to work effectively across teams to deliver results, with strong verbal and written communication skills
· Experience working with machine learning systems

Amazon is an equal opportunities employer, and we value your passion to discover, invent, simplify and build. We welcome applications from all members of society irrespective of age, sex, disability, sexual orientation, race, religion or belief. Amazon is strongly committed to diversity within its community and especially welcomes applications from South African citizens who are members of designated groups who may contribute to Employment Equity within the workplace and the further diversification of ideas. In this regard, the relevant laws and principles associated with Employment Equity will be considered when appointing potential candidates. We are required by law to verify your ability to work lawfully in South Africa. Amazon requires that you submit a copy of either your identity document or your passport and any applicable work permit if you are a foreign national, along with an updated curriculum vitae.",3.9,"Amazon
3.9",Cape Town,-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer - PBB IT,-1,"Job Details

Standard Bank is a firm believer in technical innovation, to help us guarantee exceptional client service and leading edge financial solutions. Our growing global success reflects our commitment to the latest solutions, the best people, and a uniquely flexible and vibrant working culture. To help us drive our success into the future, we are looking for an experienced Data Engineer to join our team at our Johannesburg offices. Standard Bank is a leading African banking group focused on emerging markets globally. It has been a mainstay of South Africa's financial system for 150 years, and now spans 16 countries across the African continent.

Job Purpose


This position is essential in supporting our strategic priority for developing applications of machine learning, artificial intelligence and supporting other strategic priorities such as digitisation. We aim to grow our internal community of highly skilled and talented professionals.

Key Responsibilities/Accountabilities

Productise data science prototypes
Machine learning engineers sit at the intersection of software engineering and data science and are involved in research, design, experimentation, development, deployment, monitoring, and maintenance.
Design machine learning systems
Design machine learning systems and create intelligent data-driven products using both existing open source libraries & internally developed machine learning models.
Implement machine learning solutions
Develop machine learning applications (production-level code) according to requirements. Software architecture may include platforms such as cloud computing based data platforms or on-premise data platforms.

Research and best practices
Research and implement appropriate frameworks and tools. Contribute to popular open-source machine learning libraries and frameworks where possible.
Skills development
Keep up to date with current technologies and trends. Help grow our internal machine learning & artificial intelligence community.
Preferred Qualification and Experience
Relevant Tertiary Degree in Quantitative Science
Courses & certifications from reputable academic institutions in Machine Learning or Software Engineering.
IT and Computer Sciences Degree
Certification in MS SQL (including SSRS, SSAS and SSIS)
5-7 Years experience in Engineering - Building databases, warehouses and reporting solutions
5-7 Years experience in Engineering - Building data integration solutions
1- 2 Years experience in Engineering - Operating within an agile team
1- 2 Years experience in Engineering - Working with Risk Management data in Financial Services industry
Knowledge/Technical Skills/Expertise
Experience in data management, data integration and data quality verification
Understanding of Business Intelligence configuration management tools/processes
Background in data profiling
Familiarity with database design and implementation
Experience in troubleshooting, performance tuning, and optimization
Knowledge of CI/CD principles and best practices in data processing
Analytical and problem-solving skills coupled with initiative and accountability
Familiarity with different software development methodologies
Work in conjunction with BI and Data Engineers to ensure high quality Data Deliverable
Design and develop testing frameworks to test ETL jobs, BI reports and Dashboards and other data pipelines
Write SQL scripts to validate data in the data repositories against the data in the source systems
Write SQL scripts to validate data surfacing in BI assets against the data sources
Ensure data quality by checking against our ODS , Data Platforms and the front-end application
Track, monitor and document testing results
The development and maintenance of Extract Transform and Load (ETL) processes, database and performance administration, and dimensional design of the table structure. Work closely with Data Architect to understanding and operating data warehousing functionality, building the Unified Data Platform in Microsoft Azure cloud
Write high-quality, well-structured code that is maintainable and extensible
Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity
Perform tasks spanning the full lifecycle of data management activities with minimal supervision",4.0,"Standard Bank Group
4.0",Johannesburg,-1,10000+ Employees,1862,Company - Public,Banks & Credit Unions,Finance,$500 million to $1 billion (USD),-1
Aws Data Platform Engineer,-1,"Aws Data Platform Engineer

Posting Country:

South Africa

Date Posted:

15-Oct-2020

Full Time / Part Time:

Full Time

Contract Type:

Permanent

Joining Vodacom is more than a job, what we do matters. We don’t just carry minutes, texts and data – we carry people’s lives. And that’s a huge responsibility. If you think for a minute about the people you rely on…the likelihood is they rely on us.

Customers are at the heart of everything we do and we want to make a difference to the lives of our customers, and the communities in which we live and work. We support our people to give something back to the causes that mean the most to them through helping them give time and money to the charities they love.

And what’s it like to work here? We have created an environment where you can look forward to coming to work and are empowered to be at your best. We offer flexibility in how you work that helps you do your job in a way that suits you, opportunities to help you grow and progress throughout your career and a choice of benefits to suit your lifestyle.

Role Purpose
The H Band AWS Data Platform Engineer position is based within the Technology Business Unit.

The AWS Data Platform Engineer will be responsible for all Database services such as RDS, DynamoDB, etc. Should be able to migrate any databases from anywhere to AWS using any third-party tools or AWS database migration tool. Should also have understanding or expertise in creating data warehouses and data lake solutions on AWS.
Your responsibilities will include:
Apply practical knowledge of relational database design and usage with customers
Perform workload analysis and undertake performance tuning, as well as performance benchmarking in customer environments.
To develop state of the art solutions which are technically sound.
To provide a high-quality service to the Enterprise Cloud Services clients i.t.o. consultancy, solutions and delivery.
Commitment to team success and positive team dynamics including mentoring of other team members.
Passion for growing and applying technical skills in service to customers.
Be a trusted infrastructure advisor by providing objective, practical and relevant ideas, insights and advice.
Work collaboratively with consulting partners and technology teams to ensure high quality of solution delivery.
Encourage best practice and knowledge sharing with partners and cross-functional groups
Manage the overall database design and delivery of solutions.
Ability to make recommendations as they pertain to improvements in support/development initiatives and facilitate implementation with partners and cross-functional groups within the Business.
Participate in high level database solution definition and design during the implementation phase with the goal of providing reliable, stable and operationally sound applications that meet the Business requirements.
Ability to understand and translate business requirements into technical specifications
The ideal candidate will have:
A minimum of 3 years of industry related experience of which 1 year must be within a complex hosting environment.
Certifications in Database design, system architecture or cloud technologies.
Demonstrate knowledge of database systems internals including storage layouts and distributed databases/MPP architectures
Advanced SQL coding, tuning and query optimization.
Experience designing and leading database performance benchmarks.
Good knowledge of the different AWS services
Knowledge of cloud networking architecture, cloud operations, security, automation and orchestration.
Knowledge of database internals as it relates to query and system performance and tuning.
Understanding of overall system architecture, scalability, reliability, and performance in a database environment.
Excellent teamwork, time-management and organizational skills.
Perform other duties as deemed necessary and assigned by the customer and management
Strong interpersonal skills and problem-solving abilities.
Excellent documentation, communication and interpersonal skills.
Excellent analytical and problem-solving abilities.
Closing date for applications: Monday, 13 April 2020

The base location for this role is Vodacom World, Midrand

The Company’s approved Employment Equity Plan and Targets will be considered as part of the recruitment process. As an Equal Opportunities employer, we actively encourage and welcome people with various disabilities to apply.
Vodacom is committed to an organisational culture that recognises, appreciates and values diversity & inclusion.

Commitment from Vodacom

Vodacom is committed to attracting, developing and retaining the very best people by offering a flexible, motivating and inclusive workplace in which talent is truly recognized, developed and rewarded. We believe that diversity plays an important role in the success of our business and we are committed to creating an inclusive work environment which respects, values, celebrates and makes the most of people’s individual differences - we are not only multinational but multicultural too. At Vodacom you will have access to our excellent flexible benefits programme that you would expect from any global company.",3.9,"Vodafone
3.9",Midrand,-1,10000+ Employees,1982,Company - Public,"Cable, Internet & Telephone Providers",Telecommunications,$10+ billion (USD),-1
Data Engineer Azure Data Factory,-1,"Enthuzex is looking for a motivated Lead Data Engineer to contribute towards the success of our Data and Analytics Technology initiatives. This is a hands-on technical role and this person will be responsible for the development and build of scalable solutions as it relates to the architecture strategies, data standards, digital data management, data integration, tools, and technology. The right candidate will play a deep dive hands-on critical development role in the digital transformation and in shaping how we acquire, ingest, transform and deliver data through the digital consumer channels.

Responsibilities:

Architect, design, develop and engineering end-to-end data pipelines across multiple data sources and systems of record.
Ensure data quality, integrity, security and completeness throughout the data lifecycle
Develop, design data models, data structures and ETL jobs for data acquisition and manipulation purposes
Develop deep understanding of the data sources, implement data standards, maintain data quality and master data management
Developing data services and API
Work closely with the cloud service providers to ensure completeness and alignment with the service offerings
Manage and maintain cloud based data and analytics platform
Deep understanding of the cloud offerings and engage in quick proof of concepts and proof of value in prototyping data and analytics solutions and derive viability
Ability to interact with the business stakeholders to understand requirements and translating into technology solutions

Expirience:

Experience in Cloud platform AWS or Azure eco-system. (Azure preferred)
Data Engineering/Development experience with SQL (Oracle, SQL Server, MySQL)
Strong development background creating pipelines and complex data transformations and manipulations using one of the languages Python, Java, R, or Scala with Databricks/Spark
Experience in NoSQL Databases and Big data technologies including Hadoop
Experience with API / RESTful data services
Worked on real-time data capture, processing and storing using technologies like Azure Event Hubs and Analytics
Experience working with different data storage options including AWS S3, Azure BLOB storage etc.
Understanding of different data formats including Parquet, Avro, CSV, ORC etc.
Prior experience with MPP databases and maintain large amount of data processing
Experience with Azure Data Factory and Azure Data Catalog is a big plus and mandatory
Experience with Microsoft/Azure ETL solutions and business Intelligence technologies is a big and mandatory
Past working experience on a fast paced and agile environment
Perform ongoing monitoring, automation and refinement of data engineering solutions
Experience in leading high visibility transformation projects that interacts with multiple business lines
Build and meet project timelines and manage delivery commitments with proper communication to management

Qualifications

Bachelor’s degree with 4+ years of relevant experience
Willingness to learn new technologies and thrive in an extremely fast paced environment
Team player and easy to work with.

Applicants must demonstrate their ability to master new enterprise level technologies. Successful applicants will exemplify Enthuzex ethical principles of uncompromising integrity, respect for others, and accountability for decisions

send cv's info@enthuzex.co.za",-1,Enthuzex,Leslie,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
