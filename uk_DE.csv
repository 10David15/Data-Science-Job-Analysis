Job Title,Salary Estimate,Job Description,Rating,Company Name,Location,Headquarters,Size,Founded,Type of ownership,Industry,Sector,Revenue,Competitors
Data Engineer,-1,"Our purpose at Cookpad is to make everyday cooking fun. Not just because we like food but because we believe that cooking is key to a happier and healthier life for people, communities and the planet.

Cookpad started life in Japan and is now the largest recipe sharing community in the world with over 5 million recipes created by users active in more than 70 countries. Our global platform is used by more than 100 million people every month across the world, which brings very interesting reliability and scalability challenges to tackle.

We are building a team of diverse, exceptional problem-solvers from around the world. We only hire passionate, smart and innovative people who want to make a difference.

What’s it like to work at Cookpad? Visit www.cookpadteam.com to find out more.

The role is based in Bristol in the UK - one of the most exciting emerging tech hubs in Europe.

Requirements

A Data engineer in Cookpad is responsible for improving the value of employees' work by providing accurate and timely data and the ability to process it.

Data engineers' jobs start with planning (identifying issues and thinking out possible solutions) which may require discussion with other teams or detailed analysis of current systems. In this planning phase, a data engineer should be self-driven, a good communicator, and good at problem solving.

Design, development, and operation is carried out by the team or individual depending on scope of the system. Abilities to design scalable and reliable systems to process massive data, to implement with relevant programming languages, and to deploy/operate it on cloud platforms like AWS are required in this phase.

People from any gender, background and nationality are welcome and not discriminated against. We welcome engineers who can build better data platforms for Cookpad with us.
Plan, build, operate, optimize the company-wide data platform which can be used by employees and applications.
Provide a holistic view of users' on our service by ensuring consistent data collection in multiple touch points.
Provide one-stop service for all data by collecting and integrating data from multiple sources.
Help employees to locate and understand data of interest by preparing metadata and documentation.
Provide data and ability to process it to the people or applications at the right timing, by supporting both low latency streaming processing and high volume batch processing.
Help employees to find and share insights by providing tools for analytics (Business Intelligence tools).
Keep the quality of data consistent to ensure correct analysis results by data monitoring.
Ensure that personal and sensitive information is processed in accordance with the GDPR and other applicable regulations.
Must
Work experience with data modeling and SQL development on MPP RDBMS like Redshift, Teradata. We are using Redshift.
Work experience of installation and operation of event streaming data platforms like Apache Kafka.
Work experience of programming with any languages. You will at least use Java and Ruby since existing systems are written with those languages.
Should
Experience with designing, developing data processing systems which are scalable and reliable.
Experience with deploying and operating a system on AWS or other cloud platforms.
Experience with basic Linux commands, MySQL/PostgreSQL administration.
Preferred
Experience or knowledge with Git and code review with Github.
Experience or knowledge with Infra as Code and Infra task automation. We are using Terraform, Itamae (a Chef like tool), Docker on AWS ECS or k8s, Capistrano etc..
Experience with web application development with frameworks like RoR.
Experience with distributed data processing with Hadoop ecosystem.
Soft skills
Self-Driving attitude to identify issues on current data platform.
Problem solving skill backed by logical reasoning and task prioritization.
Good communication skill to work closely with other teams
Benefits

Why join Cookpad?

People join us because they share our vision to improve people’s lives. As a company Cookpad invests heavily in learning and development -we hire smart people who thrive in small, highly collaborative and energised teams, and who look at what we do and want to be part of it.

Valuing our team means we offer competitive salaries, an employee referral scheme and very generous benefits, including 7% employer pension contribution, income protection and life insurance. We are central to transport hubs and bike routes which helps with flexible working and all-important downtime with family and friends.

In our usual working environment breakfast is provided every day, we have a fully stocked and fully equipped team kitchen where we can cook together and there are weekly pilates/ yoga classes.

In this interim period due to the current global pandemic we are working to keep as many of our perks as possible available to our staff. This includes moving the pilates/ yoga classes online as well as company socials and attendance of meetups.

Equal Opportunity

The Cookpad team is made up of an incredible, diverse range of people. We are proud to be an equal opportunity employer. We do not discriminate based on race, ethnicity, colour, ancestry, national origin, religion, sex, sexual orientation, gender identity, age, disability, veteran status, genetic information, marital status or any other legally protected status.

Your Privacy

When applying for a job with Cookpad, we will collect personal information about you. We use that personal information predominantly for the purposes of processing your application and analysis of our recruitment activity. You can read more about how we use your personal information in our privacy policy. If you an applicant from Europe, you can read our privacy policy here . If you are an applicant from country other than Europe, you can read our privacy policy here.",3.9,"Cookpad Ltd
3.9","Bristol, England",-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"BRAND NEW OPPORTUNITY WITH A MARKET LEADING ECOMMERCE COMPANY IN MANCHESTER!!

Mid to senior level candidates to be considered
Central location, easily commutable on public transport
Python / R / SQL / ETL / CICD / Cloud / Data orchestration
Opportunity to work within a rapidly growing eCommerce company
To apply please call 01244567567 or email henry.turnbull@searchability.co.uk

Sourced by @TechCareers_NW – your 24/7 twitter feed of latest IT vacancies across the North West!

WHO ARE WE?

Rapidly expanding since our inception, we have been a market leader in providing exceptional travel experiences for our UK customer base. Starting as a small start-up with a few thousand users we are now dealing with millions of customers. With that comes a vast amount of data, spattered across our platform. We are now looking to leverage all of that data to make our customers lives and experience so much better and are on our way to becoming well and truly a data driven business. You, as our brand-new Data Engineer will be giving us the capability to do jus that.

WHAT WILL YOU BE DOING?

You will effectively have two hats in our company. Firstly you will help enable our data Scientists, software Engineers and Product Managers help give the very best service they can to our customers. Helping our ML recommendation models topped up with clean, accurate data through robust and automated pipelines. Secondly, as part of the wider Data team you will work across the wider business to ensure that our data platform and architecture is working as best it can. You will be instrumental in the way we approach data and may effect our overall strategy.

Due to the work you will be doing across the business with different teams, you must bring robust engineering practises including TDD and pair programming, along with hands-on experience of building scalable pipelines and re-usable infrastructure.

WE NEED YOU TO HAVE….

Python / R / SQL / ETL / CICD / Cloud / Data Orchestration
Experience in a TDD environment
Experience with Data Orchestration
Proven background Software Engineering
Experience with one of AWS, Azure, GCP
Experience with Big Data tools
Experience with DevOps principles
Experience working in an Agile Environment

TO BE CONSIDERED….

Please either apply by clicking online or emailing me directly to henry.turnbull@searchability.co.uk - For further information please call me on 01244567567 / 07841445427 . I can make myself available outside of normal working hours to suit from 7am until 10pm. If unavailable, please leave a message and either myself or one of my colleagues will respond. By applying for this role, you give express consent for us to process andamp; submit (subject to required skills) your application to our client in conjunction with this vacancy only. Also feel free to follow me on Twitter @SearchableHenry or connect with me on LinkedIn. I look forward to hearing from you.

KEY SKILLS:

Python / R / SQL / ETL / CICD / Cloud / Data Orchestration",4.7,"Searchability
4.7","Manchester, England",-1,1 to 50 Employees,2012,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Data Engineer,-1,"At Cabot, we pride ourselves on being the best at what we do and we recognise that it’s the people that make the difference to any organisation. So, are you ready for a new challenge?! As we are on the lookout for ­­a Data Engineer to join our Data Engineering departing in either our Kent or Worthing office.
Not heard of us? Here’s our story: *
Cabot Credit Management (CCM) is a market leader in credit management services. We are an award winning, Investors in People Gold accredited organisation and we are passionate about the ethical treatment of our customers and employees.
Things you should know: *
We require a developer in our Data Engineering team to help build new data processes and applications, manage data through the business, develop complex ETL routines, interpret and manipulate data to make it useful across the Cabot Group of businesses. The role will also entail the building and administration of new and existing reports (preferably in Power BI) & analytical datasets for use by key stakeholders in the business.

In the role, you will be using a combination of Power BI, Excel, SQL Server, SSRS and SSIS and Azure as your main tools. You will work with large, complex data sets and will be required to build up your knowledge of the data as well as gaining a good understanding of how the business areas function.

Some of the key responsibilities include:
Building & Maintaining the ETL processes in Azure & on premise.
Assisting the rest of the team with building their understanding of these new processes
Work with customers & project teams to define requirements for new analytical data stores and processes.
Identifying areas for improvement or gaps in existing processes and leading the development of new data capture and processes.
Validating data before use in reporting or analytics and ensuring the integrity of all data used within the reporting suite.
Troubleshoot and investigate anomalies.
Working with the other teams and businesses within the Cabot group to deliver objectives and ensure delivery on time and to a high standard.
Updating your sprint items to ensure the accurate documentation of progress on solutions.
The fun facts: *
Not only are we offering a competitive salary of £30-40k and a fantastic bonus scheme, you will also be entitled to loads of great benefits such as gym membership subsidy, discount and cash back on hundreds of high-street shops, healthcare cash back plan, travel insurance, pension, 23 days holiday, plus much, much more.
Things we need from you: *
The most important part for any applicant is that they have the technical skills and the mindset to look beyond the obvious, own their own work and work independently. Key needs are strong SQL, Power BI & Azure data processing, investigative skills, some level of design capability, the desire to understand what people need and the ability to deliver it. A can do attitude is a must.

Other key requirements include:
Demonstrable experience in using Azure Portal to build & manage resources such as Azure databases, Data Factories and Pipelines to move, transform and analyse data from on-premise data to the cloud.
Good knowledge of T-SQL, SQL Server, SSIS and SSRS
Power BI (preferable)
Working knowledge of object-oriented languages (preferable)
Experience of turning customer needs and concepts into automated MI processes or reports
Experience of automating reports, including data extraction, transformation/manipulation, summarisation and delivery.
Logical troubleshooting expertise
SQL Performance Tuning
What happens next?*
If this sounds like you and if you would like to join our rapidly expanding company that offers excellent career progression, then we would love to hear from you! We are looking for people to interview via video and join us asap.
_Diversity and inclusion_* _are very important to us at Cabot and we value a multitude of diverse talent within our business. We want everyone to be themselves at work and encourage a culture that includes everyone. Our policies ensure that every candidate and employee are treated fairly and with equal opportunities. _
Job Types: Full-time, Permanent

Salary: £30,000.00-£40,000.00 per year

Experience:
Azure tools and products: 1 year (Required)
Power BI: 1 year (Preferred)
T-SQL, SQL Server, SSIS and SSRS: 1 year (Required)
Education:
Bachelor's (Required)
Work remotely:
Temporarily due to COVID-19",-1,Cabot Financial,"Worthing, South East England, England",-1,-1,-1,-1,-1,-1,-1,-1
Software Engineer,-1,"This is your chance to join a truly iconic Midlands based financial services group. Given the ongoing increased demand for quality software solutions, the Software development team is once again expanding.

This is a hybrid role, the bulk of your time will be focussed on Software Development, but you will also have the opportunity to become involved in the configuration of SaaS solutions and also researching new technologies.

In order to qualify for this truly unique opportunity applicants MUST possess:
At least 2 years commercial development experience and extensive knowledge of professional software engineering practices and best practice (SDLC).
Significant knowledge of bespoke development in Microsoft software and platforms (C# .NET)
Strong knowledge of Operating Systems, Systems Architecture and Software Development Framework.
Knowledge and proven hands on experience working with algorithms, data structures, object orientation and similar development concepts.
Experience across any of the following is extremely desirable:
User-led design methodologies.
Agile Software Development and Project Delivery.
Design, acquisition and delivery of SaaS/PaaS solutions.
This is a truly outstanding opportunity that offers successful candidates unrivalled technical challenge, career progression and earnings potential – DO NOT MISS THIS!

_NB: It is expected the successful candidate will work from home for the rest of this year and return to the office full-time from Jan 2021._

Reference ID: PAS/3429

Application Deadline: 6/11/2020

Job Types: Full-time, Permanent

Salary: £30,000.00-£35,000.00 per year

Benefits:
Company pension
Flexible schedule
Sick pay
Work from home
Schedule:
Monday to Friday
Experience:
C# .NET hands on commercial: 2 years (Required)
commercial development experience and SDLC: 2 years (Required)
Education:
Bachelor's (Required)
Work remotely:
Temporarily due to COVID-19",-1,ProActive Search Ltd,"Birmingham, England",-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer & DBA,-1,"Audley Travel is one of the world's leading tailor-made travel businesses with operations in the UK and North America. Although like many industries travel faces much disruption, Audley is uniquely positioned to continue its stellar track record of growth when travel once again returns. We are undertaking a major business transformation, underpinned by significant investment in Technology, and the role represents an exciting opportunity to join the Technology team in either the Witney office in Oxfordshire or the Shepherd's Bush office in London. As a Data Engineer & DBA you will:
Create and maintain all data feeds that the Data Platform requires and that data sets are optimised, structured, partitioned, indexed and performant
Perform ad hoc data requests for the business where quick turnaround time is required for insight and critical decision making. This could be using a variety of technologies and working across Azure, Salesforce and Google platforms
Indexing, partitioning, scheduling loads and optimising all databases that are part of Data Platform as a key priority
Working with the BI Developer to ensure that all data feeds are optimised and available at the required times. This can include Change Capture, Change Data Control and other “delta loading” approaches
Assisting the wider Audley team with data optimisation, indexing and partitioning tasks. Review other developer’s SQL queries and interfaces to highlight performance issues and adherence to industry best practice
Optimising and reviewing all ETL and database processes to ensure that the platform is running efficiently and cost effectively
To succeed in this role, it is essential you can demonstrate you have:
Ability to effectively develop new data feeds as well as troubleshooting existing data queries
Strong technical documentation skills and the ability to be clear and precise with business users
Strong communication skills for all levels of the business, both technical and non-technical
Be detail oriented and have a good understanding of the data lifecycle and identify upstream issues
Ability to work interactively with the business through insight issues where users don’t have a clear view or understanding of the data they need and require a few iterations of data sourcing
What we are looking for:
Strong DBA and SQL coding experience
Extensive experience developing using T-SQL, relational databases, SSIS, KingswaySoft and other ETL technologies
Knowledge of SSRS, SSAS, Power BI, Power Query and DAX
Working knowledge of REST APIs
Experiencing using Cloud technologies and tooling for Azure and Google (GCP is less of a focus but confident to participate in data migration and connectivity to this platform)
Strong coding skills and the ability to write and debug ad hoc queries using various tools. Python and an understanding of Machine Learning is also a nice to have but an opportunity for future development
Embodies the Audley values of being positive, being the difference, being one team and being passionate about travel
Desirable to have working knowledge of SalesForce data structures
The package:
Salary is dependent on experience with great benefits on offer.

We believe it's our people that make the difference and who build Audley into the success it is today. We pride ourselves on enabling people to reach their full potential through promoting and celebrating a diverse and inclusive working environment.",3.5,"Audley Travel
3.5","Witney, England",-1,501 to 1000 Employees,1996,Company - Private,Travel Agencies,Travel & Tourism,Unknown / Non-Applicable,-1
Senior Test Engineer,-1,"Overview:

The Royal Society of Chemistry (RSC) is looking for a Senior Test Engineer to join us on a permanent full-time (35-hour week) basis. You will be based at our Science Park Cambridge office and initially work from home, within the UK, and in line with government guidance.

The Royal Society of Chemistry's Testing team are part of our Applications Development team which also includes Software Developers and an Agile Coach. Our testing team includes a Lead and Test Engineers. As a Senior Test Engineer for the Royal Society of Chemistry, you will develop and support a variety of test automation solutions and will be responsible for testing all of our software products.

Key responsibilities:

Working closely with the development team in all phases of development, ensuring that the appropriate testing tasks are done.
Developing and maintaining automated tests and test infrastructure.
Actively collaborating with developers and business stakeholders to clarify requirements, especially in terms of testability, consistency and completeness.
Providing guidance and subject matter expertise on testing methodologies and processes.
Helping to define Acceptance Criteria and the Definition of Done and participating proactively in daily stand-up meetings, story grooming sessions, team retrospectives, suggesting and implementing improvements for functional and non-functional testing.
Planning and defining the testing approach, providing advice on prioritisation of testing activity in support of identified risks in project schedules or test scenarios.
Executing test cases / scripts to ensure delivery of quality software applications, including systems integration, regression and performance testing.
Configuring, using and managing test environments, automation scripts, frameworks and test data.
Monitoring and tracking resolution of defects.
Understanding, implementing and updating the Agile Test Strategy.
Measuring and reporting test coverage and identifying opportunities to adopt innovative testing technologies and tools.
Looking beyond the obvious for continuous improvement opportunities.

Essential candidate requirements:

Experience of working in a fast-paced Agile environment and of building robust test automation solutions from scratch.
Well versed in best patterns and practices around automated testing, and able to define new automation processes and procedures.
Excellent exploratory testing experience.
Good scripting and troubleshooting experience with C#.
Experience of working in Agile / DevOps environments, familiar with Scrum / Kanban.
Experience of software management tools (e.g. Jira and Confluence).
Understanding of Continuous Integration and Continuous Delivery (CI/CD) pipelines.
Attention to detail, with a logical approach to problem solving and an investigative and inquisitive mind.
Understanding of user needs, user stories, and a business outcome approach to work.
A professional attitude, to build and maintain relationships with our customers and demonstrate a customer-focused behaviour at all times.
Strong team player with excellent communication skills and stakeholder management.

Desirable candidate requirements:

Experience of working in a cloud environment (e.g. AWS).
Knowledge of cross-browser testing tools (e.g. BrowserStack).
Load and performance testing.
Certified in Agile software testing (e.g. ISTQB Agile foundation).

To view and download the job description, please click here.

Competitive salary of £40,828 - £45,363 per annum plus benefits: https://www.rsc.org/about-us/work-for-us/#benefits.

Applications must be made by Monday 9 November 2020 via the Royal Society of Chemistry's careers website.",4.0,"The Royal Society of Chemistry
4.0","Cambridge, East of England, England",-1,501 to 1000 Employees,1841,Nonprofit Organization,Social Assistance,Non-Profit,$50 to $100 million (USD),-1
Data Cabling Engineer,-1,"We are looking for self-employed data cabling engineers (up to 4) to deliver a new Cat6a office fit-out project based in Norwich. Competent in structured cabling installation standards and best practices especially Cat6a is essential. Experienced in testing, tracing and fault-finding using Fluke testing equipment. Multi-mode fibre experience (installation, splicing and testing) beneficial.

A CSCS/ECS card will be required for this role.

If a limited company suitable PI insurance shall be required.

Salary: £125.00 to £175 per day depending on experience (Monday to Friday).

Length of project: up to 16 weeks (approx.), possibly breaks in between depending on main contractor programme changes. Project completion is estimated in early 2021.

Start date: immediately

Contract length: 16 weeks

Expected start date: Now

Job Types: Full-time, Temporary, Contract

Salary: Up to £175.00 per day

Schedule:
Day shift
Monday to Friday
Experience:
data cabling: 2 years (Preferred)
Work remotely:
No",-1,DHTS,"Norwich, England",-1,-1,-1,-1,-1,-1,-1,-1
Test Engineer,-1,"Test Engineer/Manfacturing

Job Type : Full Time

Career Level : Experienced (Non-Manager)

Education : Bachelor's Degree

Location : Llantrisant, Wales, UK

Job Description :

• Responsibilities Include:

• Calibrate highly complex equipment and see that test records are properly maintained.

• Develop test plans and conduct tests on current and new instruments.

Complete testing, capture test information, compile results and present test data to R&D and GVE management for approvals.

• Operate electrical and optical test equipment, including meters, scopes, and computer controlled testing.

• Troubleshoot, diagnose and repair test failures.

• Complete Manufacturing and R&D testing tasks under engineering direction. Perform initial functional testing of both in-process and completed products.

• Assemble multi-level electro-mechanical sub-assemblies into complex assemblies using a variety of hand tools.

• Safely use compressed gasses including cylinder setup and operation on a daily basis.

• Functional testing and analysis of newly developed products to ensure operation and reliability.

• Assembling and disassembling test configurations as necessary.

• Be willing to learn new technologies and procedures to remain current with industry standards and new products.

• Perform process training with employees.

• Help develop and maintain processes and methods that comply with all safety, regulatory, and company requirements/guidelines, in support of local, state and federal safety standards.

• Participate in Continuous Improvement Initiatives.

• Continuous Self Development.

• Other assignments as assigned.

Job Requirements :

o BSEE and exposure to mechanical engineering discipline a plus. Chemical Engineering knowledge would also be desired.

o 1-5 years laboratory or engineering experience.

o Prior experience in a GMP manufacturing environment is preferred.

o Understanding of quality systems. ISO experience preferred.

o Experience designing, building, and/or debugging Electrical & Electro-Mechanical assemblies desired, as well as knowledge of geometric dimensioning and tolerance.

o Excellent verbal and written communication skills; requires interaction with managers, supervisors, engineers, and other hourly associates in a fast pace environment.

o Ability to set-up and use basic hand tools and test fixtures. Ability to design fixtures a plus.

o Ability to assemble and align precision parts, requiring good manual dexterity.

o Familiar with set up and operation of digital meters and oscilloscopes.

o Understanding and ability to read and interpret Engineering drawings, schematics and technical documentation (mechanical, electrical, and gas flow).

o Strong analytical skills.

o Up to 10% domestic and international travel as needed.

o Knowledge of organizational principles, inventory control systems, and efficient manufacturing processes such as 5S, lean manufacturing, and six sigma desired.

o Proficient in the use of Microsoft office suite including excel, word, and PowerPoint.

o May require knowledge of computer systems and software (i.e. SAP, LabView, AutoCad, SolidWorks, C++ and/or modern engineering software applications).",3.2,"PerkinElmer
3.2",Wales,-1,10000+ Employees,1937,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$2 to $5 billion (USD),-1
Senior Data Engineer,-1,"About Us:

At Sensyne Health we combine technology and ethically sourced patient data to help people everywhere get better care. To do this, we have created a unique partnership with the NHS that delivers a return to our partner Trusts and unlocks the value of clinical data for research while safeguarding patient privacy. Alongside this, we develop clinically validated software applications that create clinician and patient benefit while providing highly curated data. Our products include vital-signs monitoring in hospitals and patient-to-clinician apps to support self-care and remote monitoring of gestational diabetes and chronic diseases such as COPD and heart failure.

We use our proprietary clinical AI technology to analyse ethically sourced, clinically curated, anonymised patient data to solve serious unmet medical needs across a wide range of therapeutic areas, enabling a new approach to clinical trial design, drug discovery, development and post-marketing surveillance.

The Role:

The Senior Data Engineer will provide best practice data engineering support across all Sensyne Health’s departments and customers.

Responsibilities:
Lead the way in defining architecture for all data engineering projects
Be hands-on, always developing, running and enhancing data pipelines
Define and maintain data models
Review and analyse data for data quality
Implement and maintain best practices for all software engineering
Liaise with other departments to meet their data engineering requirements
Provide technical leadership and mentor other data engineers
Requirements

Essential:
Two or more years’ experience designing, building and running data engineering projects in Azure (using, for example, Data Factory, Event Grid, Azure Storage)
Experience of building infrastructure with ARM templates or equivalent
Experience of full life-cycle software development
Experience operating and supporting complex software products
Data analytics skills (SQL, R, Python)
Two or more years’ experience developing software, ideally in Python
Desirable:
Experience running machine learning algorithms in the cloud (e.g. Azure AutoML)
Personal Qualities:
Communication: You are able to discuss technical issues at all levels of the business and provide clear presentations of technical work.
Technical: You will be a data geek! One who enjoys seeing value and insight derived from data; you will be a technology and cloud enthusiast, who embraces new ideas and processes, yet keeps a keen eye on delivery and providing value.
Skills and Qualifications:

Advanced IT Knowledge, Critical Thinking, Interpersonal Skills, Technological Analysis, Data Analytics, Big Data, Computational Skills, Excellent Written and Oral Communication Skills, Presentations

Benefits
Pension up to 10% employer contribution
Employee Assistance Programme with Cash back benefits and discounts
Group Life Assurance
Group Income Protection
Critical Illness Scheme
BUPA Health Insurance including partners and children
Electric Car Scheme
Health Cash Plan
Dental Insurance
Cycle to Work Scheme
Discounted Gym Membership
Eye care vouchers
Discounted dining",3.9,"Sensyne Health
3.9","Oxford, England",-1,51 to 200 Employees,2018,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$1 to $5 million (USD),-1
FPGA Engineer,-1,"JOB DESCRIPTION*: FPGA Engineer
Reports to: * Software Team Leader
Division: * hiSky UK
Location: * Harwell Campus - Oxfordshire
About hiSky*
hiSky brings innovative technology to the field of voice and data satellite communications, offering mobile connectivity that is affordable, portable and easy to use.

Overcoming the barriers that have, until now, kept people from using satellite communications for more than just a brief emergency call, hiSky uses patented technology, To leverage Ka-band High Throughput Satellites (HTS), enabling quick and easy connectivity, even in the most remote and extreme locations – on land, at sea or in the air.

We have created a solution that makes voice and data satellite communication services accessible and affordable to the masses.

This solution, the Smartellite™, is the culmination of a research and development process carried out by a multi-disciplinary team of highly skilled engineers, as well as business professionals, who have fused together their in-depth knowledge, vast expertise and shared a commitment to hiSky’s mission.

With offices in London and Harwell, Oxfordshire, and Tel Aviv, hiSky is expanding to meet market and customer requirements across the world.
Required experience *
· At least 3 years of experience in the FPGA design using Verilog/VHDL – Must
Experience with creating applications with C/C++ - Advantage
Experience with embedded C code development (preferably as Xilinx embedded processors such as Microblaze /ARM).
Experience or working understanding of creating embedded software that will interact with a real-time operating system.
Lab experience with oscilloscopes, logic analyzers, soldering iron, power supplies etc.
Experience with hardware trouble shooting.
Work with a multi-disciplinary engineering team to develop software and firmware and hardware
Experience with Xilinx Zynq/Xilinx Zynq Ultrascale FPGA family - Advantage
Experience with Xilinx UltraScale+ FPGA family - Advantage
Desired Knowledge and Skills: *
· Ability to multi-task

· Must work well under pressure, organized and a proactive team player

· Able to display skills to build collaborative relationships

· Experience of confidently and successfully working across all levels of an organization

· Makes well-founded decisions which take account of the individual and overall business

· Strong team-player with ability to foster a ‘think and work’ ethic within the team

· A doer, capable of completing tasks under their own initiative and to a high standard

• Experienced in the complete design flow from requirements to design acceptance
• Experienced in VERILOG simulation tools.
• Experienced in FPGA technologies and their tools including Xilinx.
• Experience in synthesis and STA tools from Synopsys is beneficial.
• Good analytical skills and methodical approach to problem resolution and investigations.
• Good communication skills and able to thrive in a team environment.
• Ability to present technical data in a clear and concise manner.
• Experience of the Linux operating system would be beneficial.
• Knowledge of scripting languages including TCL would be beneficial.
• Educated to degree level in Electronic Engineering or related discipline.

Job Type: Permanent

Benefits:
Casual dress
Company events
On-site parking
Schedule:
8 hour shift
Monday to Friday
Experience:
FPGA: 3 years (Required)
Education:
Bachelor's (Preferred)
Work remotely:
Temporarily due to COVID-19",-1,hiSkysat,United Kingdom,-1,-1,-1,-1,-1,-1,-1,-1
SDET/ QA Automation Engineer,-1,"Location: This is a remote based role with the option to work from one of our regional offices (London, Birmingham, Manchester, Leeds, Cardiff, Edinburgh, Liverpool)

What is Syft?

Founded in 2015, Syft is an on-demand marketplace helping Job Seekers and Employers have 100% control and choice over shifts worked in real time. We want to enable Job Seekers to control their schedule, choose their work and enable them to work as many or as few shifts as they want. The platform enables Employers to book reliable, rated and verified staff immediately. At Syft, we’re harnessing innovative technology to revolutionise the flexible staffing sector.

About Us

Our results speak for themselves, £8.75 million in VC funding between 2016 and 2018, ‘Recruitment Technology Innovation of the Year’ at the Recruiter Awards, ‘Hottest Platform Economy / Marketplace’ at the Europas and ranked 7th in the ‘Startups 100’ in 2018.

Syft has grown to over 200 employees across 9 offices around the UK and US. In 2019 Syft was acquired by Indeed.com, the world’s #1 job site, allowing us to match our synergies and skyrocket our journey.

Our mission is to help people get jobs by democratising work and giving jobseekers ownership, control, and choice. We are working hard to build a world where access to work and jobseekers are frictionless.

About You

You strive to make a positive impact on the world around you through your work. You’re flexible and focused on collaborative approaches to problem solving — and highly motivated to deliver those solutions with high quality and velocity. You’re also committed to learning and continual improvement.

We aim to fundamentally change how the world looks at work in a way that benefits both Job Seekers and Employers. We are looking for someone who is thrilled by all the possibilities.

Responsibilities & Duties

We are looking for an SDET to help us automate software quality throughout the Syft stack and to work as part of the team responsible for maintaining our quality standards.
We need an all-around contributor: While your main role will be automation, you’ll need to mentor and evangelize to empower the rest of the Quality and Engineering teams to contribute.
You’ll also need to be able to help with exploratory testing — ultimately, you will ensure that our products, applications, and systems work correctly.

Skills & Experience Required

Strong experience in Cucumber, Selenium, Cypress, or other related frameworks and the demonstrated ability to learn, incorporate, and apply new technologies as appropriate
Demonstrated successes implementing test automation across all areas of the stack: Web, iOS, Android, API layers, etc
Deep understanding of the SDLC in an agile environment, working with cross-functional teams to ensure quality throughout; understands business and quality requirements and can translate these into small pieces that can be delivered and validated incrementally
A collaborative team player: Strong experience with direct and indirect mentorship — able to transform development practices to enable and sustain automated approaches to quality, as well as strong partnership with Manual and Exploratory quality specializations
Ability to review and analyse system specifications/requirements, identify candidate areas for test automation, and provide risk estimates
Experience writing and executing automation scripts and analysing results across all test phases (smoke, system, integration, regression, UAT, etc)
Experience with defect management processes and systems: Demonstrated excellence in the ability to communicate bugs and errors, and the ability to quantify and justify further action
Excellent verbal and written communication

Desirable (nice to have)

Marketplace Experience or Hiring/ Recruitment Space Experience
MBA or degree in Computer Science or Engineering

You’ll fit right in at Syft if:

You’re Flexible- able to consider challenges from different perspectives.

You’re Entrepreneurial- see how a challenge could become an opportunity.

You take Accountability through thick and thin, inviting ideas for improvement.

You’re Data Driven- see the necessity of analysing metrics when devising solutions.

You’re Passionate about what you do and self motivated.

You can Adapt to your team’s challenges and Collaborate with other departments.

What you’ll get:

Flexible work arrangements, remote and working from home.
Employee Assistance programs, free eyecare vouchers, discounted gym memberships and more.
Unique bonus structure for every employee.
Social events and lunch and learns.

Syft is proud to be an equal opportunity employer that wants to build a welcoming and diverse working environment. All qualified applicants will be considered for employment without regard to ethnic background, race, religion, sex, gender identity or expression, sexual orientation, neuro-diversity, disability, age, or any other non-merit based or legally protected grounds.",-1,Syft Online LTD,"London, England",-1,-1,-1,-1,-1,-1,-1,-1
Machine Learning Engineer,-1,"We are looking for a Machine Learning Engineer to join our Machine Learning Research team to help take more of our research into production working in collaboration with our Machine Learning Infrastructure team to support the deployment of ML based features at scale.

The ideal candidate will be comfortable working with and understanding ML concepts and research and turning them into production ready services that scale to handle millions of users in collaboration with our ML Infrastructure team. This might involve tasks such as developing inference code from a well documented research repository - to building appropriate data ingestion pipelines for a variety of ML features and applications that stretch across our entire product.

Our heritage is unique: Cookpad was founded in Japan in 1997 and is a listed company in Tokyo. We set up our international HQ in the UK and here we’re a start-up, building the global platform and working with our colleagues around the world.

Cookpad is growing at speed and we’re looking for exceptional people who make things happen and create solutions on the scale we're looking for.

It feels like a start-up with global ambition. We work in small, collaborative teams and in a creative, fast-paced environment.

The role is based in Bristol in the UK - one of the most exciting emerging tech hubs in Europe, a city on National Geographic's cool list and regularly voted the best in the UK.

Responsibilities
Study and transform Machine Learning prototypes into production ready services
Design production scale machine learning systems
Research and implement appropriate ML algorithms and tools
Develop machine learning applications according to requirements
Run machine learning tests and experiments
Extend existing ML libraries and frameworks
Keep abreast of developments in the field
Requirements
2+ years of experience in Python as a Machine learning engineer or Software developer
BS, MS or PhD in Machine learning, Computer Science, Mathematics or similar field
Hands-on experience implementing production machine learning systems
Experience with PyTorch, Tensorflow or similar ML frameworks
Broad knowledge across production ML stack
Nice to have
Experience with data processing technologies: Apache Beam, Spark or similar
Experience with Docker, Kubernetes
Benefits

Why join Cookpad?

People join us because they share our vision to improve people’s lives. As a company Cookpad invests heavily in learning and development -we hire smart people who thrive in small, highly collaborative and energised teams, and who look at what we do and want to be part of it.

Valuing our team means we offer competitive salaries, an employee referral scheme and very generous benefits, including 7% employer pension contribution, income protection and life insurance, and an employee referral scheme. We are central to transport hubs and bike routes which helps with flexible working and all-important downtime with family and friends.

In our usual working environment breakfast is provided every day, we have a fully stocked and fully equipped team kitchen where we can cook together and there are weekly pilates/ yoga classes.

In this interim period due to the current global pandemic we are working to keep as many of our perks as possible available to our staff. This includes moving the pilates/ yoga classes online as well as company socials and attendance of meetups.

Equal Opportunity

The Cookpad team is made up of an incredible, diverse range of people. We are proud to be an equal opportunity employer. We do not discriminate based on race, ethnicity, colour, ancestry, national origin, religion, sex, sexual orientation, gender identity, age, disability, veteran status, genetic information, marital status or any other legally protected status.

Your Privacy

When applying for a job with Cookpad, we will collect personal information about you. We use that personal information predominantly for the purposes of processing your application and analysis of our recruitment activity. You can read more about how we use your personal information in our privacy policy. If you're an applicant from Europe, you can read our privacy policy here. If you are an applicant from a country outside Europe, you can read our privacy policy here.",3.9,"Cookpad Ltd
3.9","Bristol, England",-1,51 to 200 Employees,1997,Company - Public,Internet,Information Technology,Unknown / Non-Applicable,-1
Senior Data Engineer,-1,"Who are we?

We want to help small business win. That’s why we’re here.

We connect small business owners to investors – to create jobs, help families and power economies – because we believe that people are made to do more. And we want to help them.

So, we created the leading online marketplace for small business loans. Our investors have lent £9.8 billion in 130,000 loans to 90,000 small business owners. In a single year, we unlocked 115,000 jobs and contributed £6.5 billion to the global economy. There’s never been a better time to join!

Be part of the team that changes everything. Let’s build the place where small businesses can get the funding they need to win and leave a legacy behind, forever.

This role sits within the “Tech and Data” teams. The drivers behind our platform – brilliant people working together to create, code, and build the next game changers.

What will you be doing?

The data team makes sure that data at Funding Circle is reliable and easily accessible across the company. We leverage the latest technologies and a team of diverse backgrounds to build a data platform to address these challenges. We build tools to help us automate traditional data processing pipelines so that we can build data systems at scale. We also build tools to empower our analysts and data scientists in their day to day work.

Day to day you will be:

Building internal tools and libraries for our engineers and internal customers
Maintaining and monitoring our AWS data infrastructure
We love pairing! Whenever you wish for knowledge sharing or learning between the teammates. Driving design and problem solving sessions.
Researching and learning new tools and technologies in the data space
Synchronising with the teams in London, San Francisco, and Bangalore
Documenting the architecture and decisions made
Working with our stakeholders to iterate on our data products
Collaborating with the team to solve architectural challenges

Are You

A great communicator! A real people person that connects easily with people and brings a strong positive energy to the table.
Fired–up to achieve. Passionate about the power of data to drive better business outcomes for our customers.
Super organised. Someone who knows how to manage their workload, cope with multiple priorities and can organise their days and week effectively
Quick to learn. You get things quickly, can take on feedback and understand how to explain complex concepts and products to our customers simply
Good working knowledge of any of the following: SQL, Python, Clojure, Scala
Looking forward to working in an international team
We’re interested in meeting people from diverse education backgrounds and this role would suit someone who likes to help others
You will have worked on one or two of the following: AWS:Glue, Athena, Redshift, Apache Airflow, Kafka, Spark, Terraform.

Why should you join us?

We’re gearing up for our biggest chapter yet – and it’s being driven by tech.

That means full steam ahead working on our global platform and real challenges for you to noodle and solve – as we build new things, reimagine the stack and go after the greenfield.

We believe that great ideas come from everywhere. So, there are no pigeonholes here. We keep it agile and open. Think big remits and huge ownership in a continuous learning environment. Close knit teams, with mentorships and global career opportunities. Everyone working together to make a genuine difference to small business owners, to us and to you.

Join the team making it happen. Help us define long-term commitments and launch the next game changers – let’s build the incredible.

It’s in our differences that we find our strengths.

At Funding Circle, we celebrate and support the differences that make you, you. We’re proud to be an equal opportunity workplace and affirmative action employer. We truly believe that diversity makes us better. We particularly encourage applications from applicants from underrepresented backgrounds. We welcome applicants who may want to work flexibly.

Want to Build the Incredible? We’d love to hear from you.",3.8,"Funding Circle UK
3.8","London, England",-1,501 to 1000 Employees,2010,Company - Private,Lending,Finance,$50 to $100 million (USD),-1
Data Engineer,-1,"See yourself being part of a large, transformational change? This could be the role for you!


Iress is continuing to hire for roles during Covid-19 with all interviewing and on-boarding done virtually. Everyone new to the team, along with our current staff, will temporarily work from home until it is safe to return to our offices.


Passionate about data? Yes, so are we. And we’re looking for Data Engineers to join our team (you may call yourself a BI Developer, but let’s not fall out).

We’re just here to make sure people enjoy their job, get the opportunity to work on a bunch of cool stuff and get rewarded and noticed for doing so. Come and talk to us, we’re nice. What we need are talented people who really understand data.

You’ll have great attention to detail when it comes to designing, developing and maintaining SQL Data Extracts and ETL Packages. You're a methodical problem solver and working with SQL, C# and ideally Powershell, will come as second nature to you.

A self starter? You betcha. You’ll definitely be curious about Cloud technologies, actively seeking to broaden your understanding of these, as well as taking an interest in driving automation. It should excite you, as it does us.

Making sure our clients are as happy as we are is important too. You’ll be their go to for all things business intelligence and keep in touch with them regularly, as well as supporting your fellow, like minded colleagues on internal projects.

Sounds like you? Do you want to hear about us?

Iress is a technology company that began as a start-up. Now, around 500,000 people use our software to help them perform better and deliver more. We believe creating an inclusive workplace, where people feel supported to be their best both at work and at home, is how we'll achieve great things.

We support flexible working and offer employee benefits designed to support our people at every stage of life - some of the best in the industry.

Employment Type
Employee
Time Type
Full time",4.5,"IRESS
4.5","Cheltenham, England",-1,1001 to 5000 Employees,1993,Company - Public,Computer Hardware & Software,Information Technology,$100 to $500 million (USD),-1
Software Engineer,-1,"Job Description
Novastone builds next generation instant messaging solutions for businesses with high-value client relationships.

We believe the future of business communication is instant and context-rich conversations, wherever you may be. We empower organisations to manage client relationships on IM platforms like WhatsApp and WeChat, while remaining in control and compliant. Our secure instant messaging platform is designed to deliver high-touch, personalised client experiences through sales and account management teams, particularly suited for industries such as financial services, healthcare, and legal. Our clients include some of the best known global brands in these verticals.

We have mobile and web clients, along with a robust set of APIs for integration. We support white labelling of official IM accounts. We have made great strides towards becoming a cloud-native (AWS) company and now our clients benefit from scalability at ease through our managed multi-tenanted infrastructure, or private hosting.

We are headquartered in London and have an engineering team based in Belfast.

Team and role

As a Python engineer at Novastone, you’ll be working on the backend team. You’ll help us implement new features, integrate with other platforms, move to microservices and pay back technical debt. You’ll propose solutions that meet product and engineering requirements and design, build, and support them. You’ll work closely with colleagues in our Belfast and London offices and actively contribute to our product direction and roadmap. We follow a mature Kanban implementation, utilise Extreme Programming techniques, and our technology stack includes Python, AWS, Terraform, Serverless, Docker, Git and Jenkins.

You will

Work closely with the product, mobile, web and infrastructure teams to build RESTful APIs for new features and integrations with other collaboration platforms
Help us continue our move to microservices
Follow cloud-native patterns to deliver cost-effective, scalable and secure services
Be prepared to try new ways of working and solving problems, challenging yourself and fellow colleagues, and embracing failure and the opportunity to learn from it
Pair up across all teams to design, review, build and maintain new product features
Love discovering and learning new things through research and training, and sharing those learnings personally or presenting in sessions to colleagues
Write high-quality automated tests, preferably following TDD
Be passionate about improving the status quo but think iteratively about how to do so
Dig into existing solutions to understand how they work
Lead technical design reviews to elicit feedback from other engineers
You should have experience in

Python! Specifically, using it to build cloud-native and RESTful services that are scalable, secure and resilient
Writing all kinds of automated tests and TDD
Other extreme programming techniques like pair programming and trunk-based development
Integrating distributed services and considering how your decisions impact platform availability and data consistency
Building, improving and maintaining CI/CD pipelines
Leveraging services provided by AWS and others so that you don’t reinvent the wheel
Implementing serverless solutions
Iteratively improving the design of existing code
Contributing in design reviews and retros
We offer

A competitive salary with stock options
A modern laptop, a relaxed working environment with dedicated working hours and agreements, and management that are approachable and open
A remote working policy
Training budget & dedicated time to do it
A monthly lab day (hack-day), weekly demos, lightning talks, and regular knowledge-sharing sessions
An open and inclusive team environment
Our primary office locations are London and Belfast
Job Types: Full-time, Permanent
About The Role novastone are expanding the backend engineering team to build the next generation instant messaging platform for regulated industries.
Skills Needed Relationship, Technology
About The Company

Mobile messaging has revolutionised the way we communicate. It is fast replacing traditional email correspondence with real-time conversations. People now expect to be able to “chat” instantly, anytime and anywhere, via easy-to-use unobtrusive technology.

For businesses, whose value proposition is built upon a high-touch and highly personalised client experience, chat has opened up a new intimate engagement channel that implies and reinforces a closer relationship with clients in a more efficient way.

Company Culture Faced with increasing levels of fraud, there is also a growing recognition that email no longer meets the needs of organisations who rely on secure and verified communication with their clients. When instructions and the transfer of certain confidential information can no longer be made by email, the process becomes more inefficient. The resulting phone calls and use of other communication channels take up more time and compromise the client experience.

This is particularly acute among financial services providers, such as wealth managers. However, for chat to be a viable alternative to email, it needs to be secure and easy-to-use, as well as enabling efficient, confidential and compliant conversations.

novastone’s white label chat solutions, built by financial industry experts, deliver on all these requirements, seamlessly moving organisations’ most valuable relationships from the inbox into a chat conversation.

Required Criteria
Desired Criteria
3 Years Experience Software Development
Closing Date Monday 16th November, 2020",4.4,"Novastone Media
4.4","Belfast, Northern Ireland",-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
"Senior Developer (Java, AWS, Big Data)",-1,"REF_UK’

Want to get into the very interesting world of Regulatory Risk? The Risk specially World Check One Senior Software Engineer role builds real-time applications processing a hundred million updates to our customers daily and is growing at an astonishing rate.

Our high-performance software was recently migrated into AWS (Amazon Web Services) and this role will spend its time rearchitecting major aspects of the product to be cloud native, more resilient and much more performant. Developers play a key role throughout an iterative and dynamic delivery cycle by working with business analysts, quality assurance engineers, project managers, and operations staff.

Team members will rapidly come up to speed on the latest proprietary Refinitiv technology and domain specific languages to deliver projects while also growing their Java knowledge. The projects are technically challenging in an environment that is very engaging. The strongest employees are typically known as problem solvers; individuals that take full ownership of problems and drive them through to completion. Learning is also a meaningful aspect of every member of the team, and continued learning is strongly supported. AWS experience is a major plus but not required.

Responsibilities:

Work with business analysts to identify the best solution for meeting business requirements
Deliver high quality code and configuration
Ensure bug free software through automated regression testing, unit tests, and code reviews
Collaborate with QA and Operations to ensure successful integration into test and production environments
Embrace Agile in every way.

Essential, Required Skills

Excellent analytical skills and a real passion for solving problems.
Superb communication skills (written and oral)
Ability to collaborate in a team focused environment
Ability to thoroughly test and debug code using test driven development
Ability to suggest/research new technologies and quickly adapt to change
Ability to work with both Technical Architects and Product Owners in order to build to specification

Essential, Required Experience

Experience with the full life-cycle software development experience
Experience with Java
Experience developing on AWS or similar Cloud-based solutions
Experience of Big Data
Strong understanding of object oriented development
Object oriented design

Desired Skills

Exposure to Agile methodologies
Experience with automated testing
Knowledge of scripting languages Python, Unix or Powershell shell scripts desirable
Knowledge of other languages such as JavaScript, Node.js
Experience with Microservices or (SOA)
Adept at software design
Experience with debugging multi-threaded applications
Knowledge of/experience with design patterns
Real passion for continued learning and development

We care about benefits too.

We support our colleagues’ wellbeing with inclusive benefits. So that's support for physical, financial, mental and environmental health, paid time off to volunteer, consumer discounts & savings and so much more. All of which are tailored to your needs and may vary by location. For more details talk to your recruiter.

Our fast paced and supportive environment is only possible due to determined, autonomous problem solvers who love our high performance culture. And as a global business, Refinitiv relies on diversity of culture and thought to deliver on our goals. So we seek hardworking, qualified employees in all our operations around the world regardless of race, color, sex/gender, including pregnancy, gender identity and expression, national origin, religion, sexual orientation, disability, age, marital status, citizen status, veteran status, or any other protected classification under country or local law. Refinitiv is proud to be an Equal Employment Opportunity/Affirmative Action Employer providing a drug-free workplace.

Refinitiv makes reasonable accommodations for applicants and employees with disabilities. If an accommodation is needed to participate in the job application or interview process, to perform essential job functions, and/or to receive other benefits and privileges of employment, please contact us to request an accommodation.

Be the breakthrough, activate your future and shape ours.",3.6,"Refinitiv
3.6","Nottingham, England",-1,10000+ Employees,2018,Company - Private,Computer Hardware & Software,Information Technology,$5 to $10 billion (USD),-1
Financial Engineer,-1,"Derivatives professionals require accurate valuations to assess risk and move with confidence. We provide an integrated solution for every step of the derivatives workflow, across all asset classes. Our models are fed with high quality data giving you the context you need, so you can trade confidently and stay ahead of the markets.

What's the role?

You will be joining a specialised area of Bloomberg that concentrates on offering premium structuring, valuation and risk services to our clients including cross-asset flexible, customisable tools and models that illustrate valuation transparency.

Your familiarity with bespoke derivatives term sheets, and the industry standard valuation models and ""street practices"" used for security valuation and portfolio risk analysis will allow you to successfully contribute to the team. Valuation will rely heavily on the appropriate choice and use of pricing models (combined with appropriate adjustments when necessary). Your ability to assess if the model results are reasonable is essential.

You will be also responsible of maintaining and upgrading the (off-terminal) OTC pricing platform jointly with the IT department of the firm. Familiarity with Python and Javascript in a professional environment are essential.

As a member of the team you will be have regular contact with clients so you will need to have strong communication skills. Additionally, you will be working with various people from external clients (traders, sales, buy side, institutional investors), and internal sales specialists, to developers and quants.

You'll need to have:
Master's degree in a technical area (such as Math, Physics or Engineering), quantitative finance field required. PhD a plus.
Recent experience at a Dealer (or at other top financial institutions) in financial engineering, quantitative modelling, structuring of OTC Derivatives/Structured Notes. Experience as a trader is a plus.
A proven track-record in developing Python/Javascript libraries for financial applications in a professional environment. Hands-on knowledge of C++, C# is a plus.
Derivatives modelling experience (possibly, X-assets) including: vanilla& structured products, market conventions, and practices regarding bespoke exotics valuation and hedging.
Excellent written and verbal communication skills.
Ability to articulate clearly in group presentations and in interactions with clients, via phone or face-to-face.
Ability to work in a fast-paced, complex and cross-asset environment.
Ability to work with multiple groups across reporting lines.
We'd love to see:
Experience using Bloomberg, and other derivative pricing platforms
If this sounds like you:

Apply if you think we're a good match. We'll get in touch with you to let you know the next steps but in the meantime feel free to browse this:http://www.bloomberg.com/professional

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

Opening Date - 22nd June 2020

Closing Date - 22nd July 2020
Salary - Competitive & Expectations",3.9,"Bloomberg
3.9","London, England",-1,10000+ Employees,1981,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer (Mobility sector),-1,"_(Sorry, we can't sponsor a working visa at the moment, you must be eligible to work in the UK.)_

Nobody can predict how we will use vehicles in 10 years. Are all vehicles going to be self-driving? Is traffic going to be controlled using a central or distributed system? Are we going to own cars at all? Whatever the future of autonomous vehicles will be, one thing is certain: we will need roads, good, safe, and intelligent ones.

If you want to be part of a dynamic and award-winning start-up and help shape the future of mobility - join Valerann! We are developing a traffic management solution that is based on unique vehicle-level data fusion. We ingest streams of data in our cloud environment; we run machine learning algorithms to identify various traffic issues and feed them back in real-time to vehicles and traffic control centers. We have made huge progress, but we need your help to move to the next level.

Our London-based team is looking for a talented, experienced, and hard-working data engineer. Your primary focus will be developing data pipelines that ingest streams of data (IoT, camera feed, and connected vehicles data), run machine learning algorithms, in real-time and in batch, store the data in various databases, and transform it (ETL). Additionally, we are looking for someone who can participate in developing our APIs.

A proven experience that we are looking for someone with:
At least 3 years of experience in developing backend code and data pipelines using Python.
Experience in developing production-ready machine learning code, for example by training existing models.
Experience with implementing video pipelines or IoT pipelines, for example, streaming, processing data in real-time and in batch, storing data.
A high level of database proficiency, and experience at working with databases such as PostgreSQL, MySQL, Athena, and Redshift.
Experience at developing APIs, for example using Flask or Django.
Using common software development tools such as AWS, Docker, Terraform, Github, Jira, Airflow, Grafana.
You should be
A person who likes to work in a start-up environment: dealing with uncertainties, working in a small team, and taking initiatives.
Someone who enjoys engineering complex systems.
Someone who can identify MVP and develop the right product.
Someone who is eligible to work in the UK without sponsorship.
The interview process
Initial 30 minutes introduction where we will learn more about your professional background and experience. This will also let you understand the role and what we are looking for.
One hour technical interview.
One hour pair programming task. You and one of our team members will work together to solve/discuss a data engineer challenge.
Final interview with one of the company founders.
All interviews will be held remotely.
Location: London/Camden (flexible working is an option)

\*The company is an equal opportunity employer

Job Types: Full-time, Permanent

Salary: £50,000.00-£65,000.00 per year

Benefits:
Casual dress
Company pension
Flexible schedule
Profit sharing
Work from home
Schedule:
Monday to Friday
Experience:
AWS / Cloud: 2 years (Preferred)
Machine Learning: 2 years (Preferred)
Python: 3 years (Required)
Work remotely:
Temporarily due to COVID-19",-1,Valerann,"London, England",-1,-1,-1,-1,-1,-1,-1,-1
Software Engineer,-1,"Are you a starting a career as a Software Engineer and wants to join a leading cyber team within an evolving and dynamic organisation?

Due to the success of a number of strategic Gloucestershire based programmes, we are growing our Software Development team with creative and ambitious Software Engineers. With a primary focus on Java, your experience will cover different technologies within an agile environment

Different thinking for a Different world

Northrop Grumman is a leading global security company providing innovative systems, products and solutions to government and commercial customers worldwide. In Northrop Grumman’s rapidly growing UK Cyber and Intelligence business, we support our customers’ work to make the UK the safest place to live and do business, both physically and online.

Working with and alongside our customers, we use modern software engineering methods (Scaled Agile Development, DevSec Ops, Site Reliability Engineering, micro-service architectures) and cutting edge techniques (data science, Artificial Intelligence, Machine Learning) to tackle complex and challenging problems and deliver cost effective, reliable, supportable solutions.

Our solutions support complex analysis of substantial amounts of data, requiring state of the art ‘big data’, stream processing and cloud-based analytics, identifying and using ‘best of breed’ commercial and open source technologies and integrating them with our own software to meet customer needs quickly and efficiently.

At Northrop Grumman we pride ourselves on our ability to combine agile development with sound engineering and security practices to ensure that our solutions are robust and resilient; designed and built to start secure and stay secure against ever evolving cyber security threats. As well as designing for security, Information Assurance and legal / policy compliance, we actively assess products and services, identifying vulnerabilities and weaknesses that could be exploited by cyber attackers, and we create and run exercises to pit cyber security specialists against secure systems and each other.

We carry out research and innovation locally in the UK, with commercial and academic partners, and across our 85,000+ worldwide workforce.

How you will make a difference

600600For us, innovation is key and we have immediate opportunities for talented software engineers to join our team to help us develop and maintain a suite of applications. We are in a phase of rapid growth and there are opportunities to develop your career with us to meet your aspirations.

You will be helping us to solve our customer’s problems within an agile team. You will have opportunities throughout the Software Life cycle from requirements capture through to R&D(Research & Development), implementation, automation and test in a wide range of technologies.

You will work as a member of a Scrum Agile development team, with the opportunity to contribute to design,development, and deployment of software systems. You will gain experience in abroad range of technologies and tool sets.

Key criteria required...

Knowledge of the processes to design, develop, test and integrate quality software

Keen to learn a broad range of technologies on the Java stack

Also, we’d love it if you have experience of...

Agile/Scrum methodologies using tools such as Confluence and Jira

DevOps approaches and associated tools such as Ansible, Docker and Jenkins

Messaging and Routing Technologies such as NiFi and Kafka

Cloud-based architectures

Linux operating systems (Red Hat Enterprise Linux Server/CentOS)

Different programming languages, such as: Java, C, C++ and Python

Working with open source products

You will enjoy a growing career as we work collaboratively to innovate the world of cyber security.

Additional information for your consideration...

You must hold UK Government clearances

Opportunities exist across the UK to enhance your career progression

Being a part of Northrop Grumman gives you the opportunity to use your skills to make a difference in our mission of enabling global security. Our company grows because of our employees' dedication and commitment to achieving our mission, something we always remember. In return for working for us you will have access to a benefits package that provides you with flexibility to balance your professional career with your personal life, health & well-being benefits, discount schemes, pension benefits and investment in your future development.

We are committed to equality and diversity in our workplace. Northrop Grumman provides equal employment opportunities to all employees and applicants without regard to an individual’s protected status, including race, ethnic origin, colour, nationality, national origin, ancestry, sex/gender, gender identity/expression, gender reassignment, sexual orientation, marriage/civil partnership, pregnancy/maternity, religion or belief, creed, age, disability, genetic information, or any other protected status or characteristic.",3.8,"Northrop Grumman UK
3.8","Cheltenham, England",-1,10000+ Employees,1939,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
Setting Out Engineer,-1,"SETTING OUT ENGINEER*
_*Organisation Information: *_
\_*\_
_\*_\*Bouygues Travaux Publics (TP) and Laing O’Rourke, two of Europe’s most dynamic engineering and
construction specialists, are working together in a joint venture named BYLOR to deliver the main civil
engineering works at Hinkley Point C (HPC) worth over £2.8 billion.
Bylor is pushing the boundaries of innovation and modern technology while delivering high-quality
construction on a massive scale. Bylor has already broken the UK record for the largest continuous
concrete pour of 9,000m3 of concrete.
This is a great opportunity to be part of a dynamic organisation that is challenging the industry and making
history.

_*Purpose of the role: *_
\_*\_
_\*_\*Setting out engineers supports the engineering team through the use of sites plans, technology, and precision
instruments, to pinpoint and mark structural features above and below ground throughout the
nuclear construction activities.
Key responsibilities and specific accountabilities:
• Setting out, leveling and surveying on site
• Liaising between engineers and the construction team, to ensure plans and drawings are accurate
set out on site
• Supply reinforced concrete setting out support to the construction team
• Keeping a site diary
• Report site progress to engineering and survey department
• Site technical support

_*Essential skills & knowledge: *_

_*Technical Skills: *_
• 2 years experience in a similar role
• Knowledge in surveying and construction procedures
• Knowledge in use of survey equipment (EDM/Total Station)
• Structural setting out experience
• Knowledge of and experience in reinforced concrete is a must
\_*\_
_\*Interpersonal Skills: _\*
\_*\_
_\*_\*• Numeracy and the ability to make mathematical calculations
• The ability to understand and interpret data
• Lateral and logical thinking
• Problem solving and analysis
• Attention to detail
• Verbal and written communication skills
• Organisation and time management
• The ability to work independently and as part of a team
_Education & Qualifications: _*
\_*\_
_\*_\*• Must hold an Engineering or Survey qualification – Ideally at Degree level
_Additional Information: _*
\_*\_
_\*_\*All positions with Bylor are employed directly with either Laing O’Rourke or Bouygues Travaux Public and
include competitive salaries, private medical insurance, company pension schemes and annual holiday
allowance. Some grades will also include a company car allowance.
Unless stated otherwise all positions are based at Hinkley Point C in Somerset.
Somerset boasts beautiful English countryside, an attractive coastline, interesting towns and villages
along with easy access to the M5 and within proximity to the cities of Bristol and Exeter.
Bylor is committed to being an equal opportunities employer and promote greater equality, diversity and
inclusion in our workplace.

Job Type: Contract

Job Types: Full-time, Contract

Salary: £0.00 per day

Benefits:
Flexible schedule
Experience:
Section Engineering: 3 years (Required)
Education:
Certificate of Higher Education (Required)",4.0,"Bylor
4.0","Bridgwater, England",-1,201 to 500 Employees,-1,Other Organization,-1,-1,Less than $1 million (USD),-1
"Data Analyst, Data and Analytics",-1,"Snapshot

We're hiring for a passionate quantitative analyst to work at the intersection of insights and engineering, improving DeepMind's internal decision making!

About Us

DeepMind's mission is to ""Solve intelligence. Use it to make the world a better place.""

The Data & Analytics team builds on this with an objective to ""improve decision-making through relevant insights to achieve our mission"". We work closely with partners across the company to:

Deliver insights and improve decision-making
Cultivate DeepMind's analytics culture & community
Contribute to our analytics infrastructure

Success across these areas will have a material impact on the company's operations and management, offering exciting opportunities to dive deeply into a wide array of technical analysis, collaborate closely with talented partners throughout the organisation, and apply/grow your skill set.

Some examples of the types of work you might encounter on a day-to-day basis:

Mine large-scale datasets to understand patterns in compute demand and help plan future capacity
Analyse our recruitment process, conducting statistical tests to validate experimental changes to interview funnels
Present insights to senior management, translating analysis into the 'so what?' and identifying possible actions to take as a result
Partner with teams company-wide to understand key indicators of progress, develop and validate accompanying metrics, and visualise via dashboards / other reporting tools
Engineer tested, robust ETL pipelines to improve the availability of key data sources internally
Develop and deliver training on SQL, Python, data visualisation practices, and more
The role

We're looking for someone who is skilled at and motivated by helping to make and enable sound organisational decisions using quantitative data.

'Making' in the sense that you'll often be tasked to conduct rigorous analysis, using a variety of tools, to deliver meaningful insights. 'Enabling' in the manner that you're excited to help mentor and coach others in their own analytics efforts, and possess the skills to help bring greater consistency and robustness to our data sources and analytical workflows.

This role is technical in that it requires use of a diverse array of techniques and technologies to extract and prepare high-quality analysis. At the same time, there is a great deal of flexibility in your ability to focus on a subset of our team's broad mission and grow your skill set accordingly, whether that's in rigorous project management, deep statistical analysis, or robust pipeline engineering.

As a group we want to enhance the way DeepMind as a whole makes decisions and takes action, so there are many different ways team members can further this aim.

A core set of the responsibilities this role encompasses:

Work with partners to identify relevant high-level business questions and propose relevant data-focused analysis
Write queries and conduct rigorous, verifiable analysis (SQL, Python) to answer those questions
Communicate via presentations and written reports to a wide variety of stakeholders (with varying levels of seniority, technical and domain familiarity) – following through to ensure impact
Identify work appropriate for regular tracking, building appropriate reports and dashboards for consistency and ease of access
Manage several projects simultaneously, exhibiting good project management skills (timelines, expectations, progress, etc.)
Recommend changes to product/engineering roadmaps to improve data quality in source systems
Submit tested code into source control for review
Coach and mentor others in their own use of analytical tools and technique
About you

What we are looking for in the ideal candidate:

You excel at analytical problem solving with a 'nose for data', knowing which questions to ask of it, how to go about answering those questions, and how to ensure that your answer is correct.

You enjoy using a variety of technical tools to answer the question at hand. You recognise that there are lots of potential ways to approach a problem, and enjoy choosing the right tool for the job. You enjoy learning new technologies and techniques when appropriate.

You consider yourself 'business savvy'. You have proven experience working with various internal partners, and an intuition for which questions are most important to hone in on in service of our mission.

You are passionate about 'storytelling' with data. You're great at translating deeply technical analysis into insights and conclusions that everyone can grasp, independent of prior context or expertise. You know how to optimally express uncertainty in your conclusions, and key assumptions that have gone into the analytical process.

Qualities that are an asset

You are comfortable extracting and manipulating data via SQL (especially BigQuery and Google's StandardSQL implementation) and Python and the PyData stack (e.g. Pandas, Scikit-learn, Scipy, NumPy, Jupyter)
You might be familiar with some other aspects of ETL management (e.g. Apache Beam, Apache Spark, Airflow, Luigi), data modelling (e.g. DBT, Snowflake), and data visualisation (e.g. Tableau, Data Studio, d3.js, Matplotlib, Vega, Altair, etc.), or are at least excited to learn more
You like to 'work quantitatively', and have at least a basic solid understanding of statistical concepts that let you express ambiguity in your analysis and assumptions
You've previously taught yourself new tools/techniques to expand your skillset
You have experience partnering with senior decision-makers in a professional setting
You consistently strive to see 'beyond the data' and understand what your analysis represents in terms of actual reality/experience
You enjoy collaborating widely, and partnering with others to empower action and change

If you don't think you embody all of the above criteria, please still seriously consider applying! This role (and therefore the requirements) is broad, and we'd be excited to discuss how you see yourself contributing across it!

What we offer

You will join a diverse and vibrant environment where you can influence and have impact on groundbreaking research results. You will enjoy a creative and stimulating work environment and direct access to world-class researchers!

We constantly iterate on our work environment. It has been crafted to help you lead a balanced life. This goes from providing you excellent facilities (healthy food, music rooms, gym, faith rooms, terraces, spacious desks, etc) to enabling your manager to make special work arrangements if you need them. Our managers are being supported by our People and Culture team ensure we do our best to suit your needs. We also provide baby bonding leaves for both parents. Our list of arrangements is pretty extensive, so please do discuss this throughout the process.

Opening date: 2nd November 2020

Closing date: 3rd December 2020

DeepMind welcomes applications from all sections of society. We are committed to equal employment opportunity regardless of sex, race, religion or belief, ethnic or national origin, disability, age, citizenship, marital, domestic or civil partnership status, sexual orientation, gender identity, pregnancy, maternity or related condition (including breastfeeding) or any other basis as protected by applicable law. If you have a disability or additional need that requires accommodation, please do not hesitate to let us know.",4.9,"DeepMind
4.9","London, England",-1,501 to 1000 Employees,2010,Company - Public,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Gamesys Group is one of the world's leading gaming operators, with millions of players and over 1300 employees. We believe passionately in what we do. Quite simply, we craft entertainment with care, building trusted brands and creating great experiences that always put the player first.

Our award-winning brands – including Virgin, Jackpotjoy, Monopoly, Heart and Vera&John – are some of the best known in the industry. Join us and you'll be joining a big, international group with some great brands and an exciting future. You'll feel part of one global family, working with smart people, and delivering a great experience for our players. There's one thing we expect from you, over and above everything else. Be yourself. One of the values in our DNA is 'stay wonderfully weird' – and that applies to all of us.

The Role

The role will suit a hands-­on Data Engineer with a passion for data to work alongside other developers, architects and product owners in an agile environment. You will be working in a delivery team to deliver batch and streaming data pipelines between 3rd party gaming platforms, our strategic Google cloud-based data platform and various marketing and reporting platforms. You will work with data scrum team members, data architects, product owners and business analysts delivering elegant solutions and troubleshooting problems. You will get to work with large data sets and apply the latest data technologies on a range of cloud platforms and will get to see how we apply intelligence to the automation of an incredibly dynamic online gambling business.

Responsibilities
Designing and coding elegant strategic solutions which are reusable and easily maintainable
Peer reviewing other team member's code.
Cooperating with architects and other data engineers to develop technical designs and to propose solutions to key stakeholder requirements.
Attending stand-ups with key stakeholders, communicating the status of development and raising any potential risks as early as possible.
Producing clear and concise documentation where required.
Attending training as required related to Google Cloud Platform, and data pipelines and processing in general.
Building a solid understanding of the gaming industry, our games and our numerous intelligent marketing, compliance and player interaction processes.
Some 2nd line on-call support.
Competencies and experience required:

Minimum:
Strong SQL/Procedural SQL/Data Warehousing experience.
Python or Java experience
Unix shell scripting (or alternative) experience.
Has worked in a team that adhered to agile principles.
Has demonstrated self-motivation/pro-activeness on a previous role.
Good communication skills, and an ability to explain work well to other team members.
Can demonstrate how technical tasks translate into business value.
Someone who is not afraid to put forward ideas for improving team processes and new features.
Desirable
Public cloud experience, Google highly desirable.
Experience of data reporting or dashboarding platforms such as Tableau or Cognos.
Experience or demonstrable interest in analytics and/or machine learning.
Experience with streaming technologies such as Kafka, and REST APIs.",3.5,"Gamesys
3.5","London, England",-1,1001 to 5000 Employees,2001,Company - Public,Gambling,"Arts, Entertainment & Recreation",$100 to $500 million (USD),-1
Data Engineer,-1,"TrueLayer’s new Data Analytics team empowers our entire organisation to make strategic decisions based on a scalable data infrastructure, coupled with commercial insight and impeccable leadership skills.

As one of our first Data Engineers, you will join this team and help to shape the vision for our data infrastructure. By building entirely new services and maintaining/iterating on our existing infrastructure, you will be a key player in our engineering journey as we raise the bar for the whole financial ecosystem

We always aim to empower our engineers and this means using the best tools for the job. Technically this means using the best in class technologies such as Spark and Airflow for our data pipelines, Presto/Athena to enable easy access to our data lake across the business, Docker and Kubernetes to schedule and run our services, AWS for our infrastructure, ElasticSearch, PostgreSQL, Redis and more - the best tool for the job wins.

Our technology stack
Our go-to programming languages for backend services are C# and Python, but we use other technologies when the challenge we are working on calls for it (Golang and Rust);
Most of our data pipelines currently use Python, Spark and Hive, sometimes orchestrated with Airflow (but often glued together with BASH);
Docker containers orchestrated by Kubernetes, hosted in AWS;
Monitoring using a combination of the ELK stack, Jaeger, and Prometheus/Grafana.
Who we are:

At TrueLayer, we’re making finance work smarter for everyone by enabling secure, global access to the financial system. Headquartered in London with offices in Milan and Hong Kong, we’ve raised $72M to date and we’re trusted by some of the biggest names in fintech, including Revolut, Chip and Zopa.

Our people are what makes us great - at TrueLayer, you will work alongside some of the brightest minds in fintech and contribute to projects that have global impact. As we enter hyper-growth and expand our open banking platform across Europe and Asia, we’re looking for talented individuals who share our core principles to join us.

Our mission is to grow the open banking economy. We’re currently the leading open banking provider in the UK, and we’re just getting started…

As a Data Engineer, you will:
Help develop the vision for and architect our data infrastructure;
Design, build and launch new data pipelines in production, that can be used for analysis across all areas of the business including Product, Growth and Operations;
Maintain and enhance our core data infrastructure and ETL framework;
Help make our data platform globally scalable, reliable and available;
Ship rapidly and regularly to production - we don’t wait around - when it’s ready, we ship it;
Optimise our engineering processes and ultimately, our products;
Contribute to our culture, and help make sure TrueLayer remains an exceptional place to work;
Voluntary On-Call Duty

While being on call is a fantastic learning experience, we understand being on call out of hours is not for everyone, so at TrueLayer it’s voluntary. If interested, you can train with, and join, our on-call rota, which will involve compensated rotations of:
Being On-Call to respond to critical incidents affecting the availability of our platform;
Identifying, mitigating and resolving root causes of such incidents;
Coordinating our response to potentially major incidents, and being an active voice in postmortem/root cause analysis discussions to prevent future problems.
Requirements

What we need from you:
Data engineering experience, particularly in architecting and building end-to-end data solutions and pipelines;
Good understanding of data modelling, data access, data storage techniques, distributed systems and streaming data architectures;
Commitment to good engineering practices: clear documentation, thorough testing and helpful automation;
Knowledge and proficiency in at least one major programming language and SQL;
Effective communication skills- you can present insights to technical and non-technical audiences and you love proposing actionable solutions;
A methodical, analytical and organised approach to tackling large scale projects and data sets;
A desire to work in an engineering team that collaborates, shares knowledge and empowers each other to succeed.
Nice to haves:
Previous experience at a startup or high-growth company;
Experience in Big Data frameworks like Spark or Hadoop;
Experience with Python and data manipulation libraries like Pandas;
Exposure to Kubernetes/cloud-native patterns
Benefits

What you can expect from us:
Competitive salary and meaningful equity in the company ��
A lovely, spacious, natural light filled office in Clerkenwell ��
Team lunches on Friday ��
Flexible hours and remote working ⌛️
Flexible holiday policy ✈️
Generous parental leave ��‍��‍��‍��
Enhanced pension contribution at 4% & 4% plus Health Insurance ����
Learning & development allowance ��
Annual retreat & regular team socials ��������
Choice of Mac or Linux technology ��
(and yes we have both a ping pong table ��and pool table ��)
Be your True(Layer) self at work

As we go global, we want our team to reflect the diverse and multicultural world we live in.

So, we choose to talk about Inclusion and Diversity [in that specific order] because we believe Diversity won’t be successful without Inclusion first. We build teams, cultivate leaders and create a company that’s the right fit for every person in it.

We look forward to hearing from you!

Please note, we don't accept applications from recruitment agencies - thank you!",5.0,"TrueLayer
5.0","London, England",-1,51 to 200 Employees,2016,Company - Private,Financial Transaction Processing,Finance,Unknown / Non-Applicable,-1
Senior Data Engineer,-1,"Our Story
We’re empowering people to FeelGood about their money.
We’ve been on this journey since 2004, when we built the first ever peer-to-peer lending company to give people access to simpler, better-value loans and investments. When it comes to money, we think everyone deserves a fair deal, so since we launched, we’ve helped hundreds of thousands of customers to take the stress out of money by building our business on honesty, transparency and trust.
Our journey’s always evolving, and we’ve just launched a bank. But a different type of bank – one that empowers its customers to take control of their finances and FeelGood about their money.
If you embrace being challenged beyond the norm, aren’t afraid to think differently and are motivated by working somewhere you can really make an impact, you’ll love life here at Zopa.

Job Title: Senior Data Engineer
Salary: Competitive
Location: London Bridge
Advert Start Date: Tuesday 6th October 2020
Closing Date: Tuesday 3rd November 2020

The Role
As Data Engineers at Zopa, our goal is to democratise the data to empower individuals at all levels in the organisation to make right decisions to drive better customer experience.
We work with bigdata, by leveraging the latest tools and technologies in AWS cloud we are building the scalable, reliable and securable data platform at the enterprise level.
We are looking for a Senior Data Engineer to lead the data warehouse and data lakes related projects. This is a fast-paced and dynamic work environment with ever changing needs and tight deadlines. We work in agile ways where we ship the products and new features every week.
A day in the life
Liaise with data scientists, data analysts and decision-makers such as product owners and business analysts to gather and analyse the data requirements
Design, build, refractor and optimise various data pipelines required for the data lakes and data warehouse
Design and implement various data models to ensure the data integrity, ease of data access and for better query performance
Implement various data quality checks to ensure accuracy, completeness, consistency and reliability of the data
Provide guidance and mentorship to other members of the team
About you
You’ll have 4+ years demonstrable experience in data engineering or related domain
You'll have great interpersonal, relationship building and influencing skills
You'll have a true passion for project management, execution and getting things done
You’ll have robust understanding of Python data structures and algorithms
You’ll have experience with building custom data pipelines using Python and PySpark
You’ll have experience with Redshift or Postgres databases and proficient in writing complex SQL queries
You’ll have experience with different AWS services like Lambda, Glue, S3, Athena, DMS, etc.,
You’ll have experience with CI/CD pipelines
You’ll have an understanding of software development life cycle and practices such as coding standards, code reviews and version control using Git
You’ll have excellent analytical, problem-solving and communication skills
You'll be passionate about learning new and cutting-edge technologies!
Bonus points for...
AWS Certifications –Solution Architect, Developer, Data Analytics or equivalent
Knowledge about Streaming applications
Exposure to any BI tools


To thrive here, you’ll need to:
Champion our customers. Whatever your role, you’ll be close to our customers. We care passionately about doing the best for them.
Help us make fearless choices. Our environment is fast-paced, agile and open. You’ll solve interesting and challenging problems, and be trusted and empowered to bring your ideas to life.
Walk the talk. Like us, you’ll be honest, stick to your promises and face the tough moments head-on.
Win smarter. You’ll be always on the lookout for a better way of doing things, going beyond ‘good enough’ and welcoming different points of view.
Be in it together. You’ll join an ambitious, diverse and all-round approachable team with a mix of ideas and talents who inspire each other to be better every day.

Zopa is proud to offer a workplace free from discrimination. Diversity of experience, perspectives, and backgrounds leads to great products and unique company culture. We simply can’t expect to empower our customers to better manage their money without challenging the current status quo. Creating the best place for money is no easy task, which is why we need talent from all walks of life.",4.0,"Zopa
4.0","London, England",-1,201 to 500 Employees,2005,Company - Private,Lending,Finance,$10 to $25 million (USD),-1
Voice Engineer,-1,"Our customers are at the heart of everything we do, but we can’t achieve our customer focused strategy without the right people in our team. At TelXl, we know that people are our biggest investment, which is why a career with us is not just a job. It’s the chance to be part of something bigger, to add real value to help us constantly improve, in order to achieve our ambitions. We are looking for people who are enthusiastic, proactive and enjoy working in a fast-paced environment. *
This document is intended to give a detailed role requirement to fulfill a specific vacancy within the organisation. It will be used to define duties, responsibilities, key skills and person profile.*
_Job Purpose_*
_Key Responsibilities_*
· Will have with at least 3 years’ experience

· High level Linux and Linux CLI knowledge

· Understanding security implementations of Asterisk, Linux and general voip

· Strong working experience with GNU make files and GDB debugging processes/tools

· Packet level debug knowledge

· Working knowledge of SIP standards

· Understanding of audio codecs and common issues in media sessions

· Strong IP & Networking skills

· Experience with large VoIP production and cloud-based environments desired

· Working knowledge of ARI desired but if none must have knowledge of AGI and AMI
_Knowledge, experience, skills, other attributes_*
Making bespoke changes to core asterisk dial-plan to service our network/customer requirements.

General asterisk server maintenance and support.

Developing and maintaining applications that monitor and extract data from our asterisk servers

· Fault finding and Issue investigation

· Must have deployed a custom dial-plan application

· Telephony industry experience

·
Desirable Skills: *
· Experience with GNU make files and GDB debugging processes/tools

· Telephony industry experience
_Education & Qualifications_*
Degree level or higher in computer science/software engineering or equivalent achieved through working experience will be considered
_Competencies _*
· Highly self-organised and able to manage and prioritise a significant workload with competing demands.

· Ability to communicate with a wide range of stakeholders and tailor the communication style to be appropriate to the audience

· Must be able to think creatively to overcome issues and problem solve in a systematic way
_Benefit package _*
The successful candidate will be eligible for package and remuneration detailed below:

· Competitive Salary

· Holiday 25 days, + Bank Holidays

· Private Health cover

· Pension

INDE

If you feel you are suitable, please send an up to date CV outlining your experience.

Job Type: Full-time

Salary: £29,831.00-£71,720.00 per year

Schedule:
Monday to Friday
Experience:
Asterix: 3 years (Preferred)",4.3,"TelXL Ltd
4.3","Redditch, England",-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Variant Engineer (CAD/Electrical),-1,"Main Role: *
The Variants Engineers role is to provide technical and engineering support for the Newhaven Factory and Internal Sales Engineers as part of the Variants team. This involves the development of Variant products from concept through to production and requires knowledge of how products are designed for assembly and technical knowledge regarding the choice of components required.
Key Responsibilities: *
To provide technical support for the factory
To develop variant solutions that meet specific customer requests
To produce CAD drawings of new components / assemblies enabling new items to be sourced
To provide supporting documentation to the factory (drawings, wiring diagrams, build instruction sheets) to allow Variant products to be built
To liaise with internal customers to provide technical solutions
To build / develop prototypes and samples for lab approval and assist factory production
To provide engineering support for Variants being built through the factory
Liaise and communicate effectively with all associated departments.
To produce data sheets as required
Drive continuous improvement initiatives within the Variants team and the wider Manufacturing team
Person Specification: *
English mandatory; other languages beneficial.
Degree in Engineering, or by experience.
Previous experience within a technical products industry. Experience with LED technology highly desirable.
Proven CAD skills
Experience of a formal New Product Development / Introduction process.
Experience in operating and building effective relationships in a cross functional work environment,
Good numeracy and presentation skills.
Good commercial skills
Accurate with attention to detail.
Organisational Values: *
Progressive
Agile
Trusted
Simple
Approachable
Benefits: *
Contributory Pension scheme. Contributions are dependent on age with a min of 4% and a max of 8% Employee Assistance Programme
Death in service Insurance cover up to 3X annual salary
You @ work lifestyle benefits scheme
Employee Assistance Program & Health Support Scheme
Car Parking
Service Awards
Staff Discounts
Job Types: Full-time, Permanent

Salary: £26,000.00 per year

Schedule:
Monday to Friday
Experience:
CAD: 3 years (Required)
Electrical: 3 years (Required)
Education:
Bachelor's (Required)
Work remotely:
No",-1,Feilo Sylvania UK Limited,"Newhaven, England",-1,-1,-1,-1,-1,-1,-1,-1
Simulation Engineer,-1,"An exciting opportunity has become available to join Boeing Defence UK (BDUK) as a Simulation Engineer based in Fleet, UK or Bristol, UK.

Position overview:

We are looking for an experienced Simulation Engineer to join our team to oversee on-site development of simulation capabilities for the RAF’s Gladiator programme.

You will work as part of the Mission Systems engineering team to maintain and develop Boeing’s DCS&S (Defence Operational Training Capability (Air) Core System and Services) service, integrating with the RAF’s wider Gladiator team at RAF Waddington and across the Defence Industry.

You will be integrated into a faced-paced and dynamic customer focused environment and stretched to achieve your potential. Your wellbeing is also important to us and we strive to find a healthy life balance and with an ethical team culture and strong emphasis on openness, collaboration, innovation, safety and first time quality.

Please note that some business travel can be expected to other BDUK sites, as driven by business needs. This role also would require flexibility as off-hours support may occasionally be required to training service delivery.

Position responsibilities:

Definition of technical work packages that will integrate third party simulation systems and training devices to the core Gladiator system
Working with third parties to support their integration of DCS&S simulation components
Acting as technical liaison for third parties back into the core DCS&S development team
Providing support to integration, test and acceptance events
Providing technical support to initial training events, where needed

PLEASE NOTE: The successful candidate will be expected to undergo a UK SECURITY CHECK.

Employer will not sponsor applicants for employment visa status.

Preferred experience and qualifications:

Developing simulation systems for use in training
Usage of distributed simulation protocols such as Distributed Interactive Simulation (DIS) and High-level Architecture (HLA)
Application of systems engineering practices and principles
Experience developing air domain simulation systems
Experience integrating simulation systems for a military customer
Understanding /of modern air combat systems and tactics
Experience in developing and applying continuous improvement to process and productivity
Mission-orientated approach and familiarity with modern software development paradigms and processes
Approach with a focus on customers, quality and our people
A ""drive to action"" approach with the ability to be resilient and flexible in a fast-paced environment
Experience in or willingness to work collaboratively with other engineers, specialists and functional support team-members to achieve a sustainable outcome
Experience with the following systems:
VT MAK VR-Forces product line
3D geospatial tools and data formats such as OpenFlight, Shapefiles, ARCGIS, etc.
3D modelling formats and tools such as Presagis Creator, 3D Studio Max
HLAe based distributed simulation systems

Relocation:

This position does not offer relocation. Candidates must live in the immediate area or relocate at their own expense.

All information provided will be checked and may be verified.

Please apply for this role as soon as possible, as recruitment may commence before the end date.",3.7,"BOEING
3.7","Fleet, South East England, England",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
Data Engineer,-1,"Data Engineer

Experian

Grade D

Location: Remote, Midlands

In Experian Digital, we create powerful tools that allow our clients to gain insights into their customers and markets enabling safer and lower risk decisioning. We enable tooling around affordability and safe lending which ultimately helps end users. This section of the business is growing and we are in the unique position to collaborate directly with large clients in banking who are eager to consume our services, as well as combine Open Banking and other data with advanced class-leading data science products and classic bureau data.

The role

The role represents a rare opportunity to be an important part of connecting and delivering Experian’s Data Science capability where it is needed, collaboratively developing bespoke systems and pipelines for our teams and our clients for a variety of purposes such as enabling data scientists consuming models in client organisations, batch processing hundreds of thousands of customers for analytics purposes, and connecting our services to marketplaces for easy consumption.

You will be working with both Operations and Data science teams to connect services and products to data sources, with a focus on creating and automating the best data pipelines for users, and doing so in a safe way handling sensitive data in a regulated environment.

You will be participating in the development of cloud and code based solutions to move data through systems, debugging applications and configuring systems with client technical teams.

As a Data Engineer your key responsibilities will include
Discovering the most effective way of connecting data to services
Engineer effective pipelines pragmatically, automating to a high quality what can be re-used, and creating safe but disposable code where it cannot.
Leverage your knowledge of Data Science and Engineering tooling and Cloud vendor tooling to discover opportunities in how we use Data Science products.
Collaborate with and support colleagues to aid their continuous improvement and your own
Document services and operational procedures
Engage and collaborate with product owners and stakeholders within Experian, and technical staff at clients.
What makes this role special

Affordability is a key topic in this challenging environment and as a provider of data services primarily around banking, affordability, and finance to other businesses we’re positioned to leverage Experian’s strong partnership with banks to make a genuine difference to real people in the country, and eventually internationally. Experian Digital regards Data Science as strategically important and is in a position of strong growth, and as such a positions in this team can achieve a high profile for performing individuals.

Could this role be for you?

Skills and experience
Demonstrable experience with a scripting language, preferably Python, or equivalents (Ruby, Bash, Powershell or others)
Familiarity with Databricks or Spark
Some ability with cloud automation, such as AWS CloudFormation, Hashicorp Terraform, Azure ARM scripts etc.
Good communication skills and collaborative spirit
Desirable skills
Experience with development in, or operation of Python
Multi-cloud experience, AWS, Azure and GCP, we go where our clients are.
Interest in Docker, Kubernetes, or containers
A solid understanding of agile best practices, and testing processes


Why choose us?

Our colleagues’ health and wellbeing is a top priority for us, that’s why our reward, benefits and wellbeing programmes are designed so you can come to work feeling your very best self. Our benefits focus on health, money and lifestyle so you can tailor your benefits to your own personal needs. Whether it’s your physical and mental wellness, getting to work or planning for the future, we have a range of flexible options to have you covered!

Who are Experian?

We unlock the power of data to create opportunities for consumers, businesses and society. At life’s big moments – from buying a home or car, to sending a child to university, to growing a business exponentially by connecting it with new customers – we empower consumers and our clients to manage their data with confidence so they can maximize every opportunity.

For more than 125 years, we’ve helped consumers and clients prosper, and economies and communities flourish – and we’re not done.

Our 17,000 people in 37 countries believe the possibilities for you, and our world, are growing. We’re investing in new technologies, talented people and innovation so we can help create a better tomorrow.

#LI-AB1

*",4.1,"Experian
4.1","Nottingham, England",-1,10000+ Employees,1980,Company - Public,Financial Analytics & Research,Finance,$2 to $5 billion (USD),-1
Senior Data Analyst/SQL Developer / DevOPS Engineer,-1,"Great opportunity for an experienced Senior Data Analyst / SQL Developer / DevOPS Engineer to join a COVID-19 secure printing company onsite, on a temp to perm basis, immediately available.

This is initially a 3 month contract with the intention to move to a permanent role in 2021.

The primary objective of the role will be to support the Company in maintaining the efficient operation of the data processing and data transformation through the maintenance and development of SQL & Access Databases together with Microsoft Access Clients. The role will also encompass helping to develop and maintain new systems built with the .NET framework and to ensure high levels of Information Security within Stephen Austin in line with ISO 27001 standard.

Areas of Responsibility

Maintain and design Microsoft Access databases including VBA programming
Maintain and Design Microsoft SQL Server including SQL scripts, Views, Stored Procedures, Reports.
Working with stakeholders to accomplish new DevOPS projects both internal and external
Building new processes at every stage
Helping with testing and documentation

Relevant Skills and Qualifications

Experience of database-related software development (ideally using SQL Server)
Experience of Web and Desktop development (.NET, C# 6.0+, LINQ, MVC, Webforms, Winforms, HTML5, CSS, Javascript, JQuery, Bootstrap, ASync RESTful web services,
Advanced level Knowledge of Access
Advanced level of knowledge of Microsoft SQL Server including Views, Stored Procedures and other programmable features.
Knowledge of Agile development (SCRUM and KANBAN)
AJAX/CSS3
Microsoft VBA
Knowledge of building applications using VS
RDLC; XML

Scientific degree or equivalent, incorporating IT modules
Microsoft SQLServer
.NET, C# 6.0+, LINQ, MVC, ADO
OODM/ORM (Preferably Entity Framework)
OOP
Azure DevOps

Benefits

COVID-19 Secure
Permanent employment potential
26 days annual leave
Salary dependent on experience
Cycle to work scheme
Free secure car parking
EAP service and Mental Health First Aiders onsite
Central Hertford location with transport links nearby

The Company

Stephen Austin Printing Group (SAPG) is a well-established provider of security printing and data services to governments and authorities in the UK and worldwide. The group comprises two operating companies – Stephen Austin (www.stephenaustin.co.uk): security printing and distribution services for examination and electoral bodies and GradeMaker (www.grademaker.com): SAAS assessment software and data services for examination bodies.",3.5,"Stephen Austin
3.5","Hertford, England",-1,51 to 200 Employees,-1,Company - Private,-1,-1,$10 to $25 million (USD),-1
Simulation Engineer,-1,"An exciting opportunity has become available to join Boeing Defence UK (BDUK) as a Simulation Engineer based in Fleet, UK or Bristol, UK.

Position overview:

We are looking for an experienced Simulation Engineer to join our team to oversee on-site development of simulation capabilities for the RAF’s Gladiator programme.

You will work as part of the Mission Systems engineering team to maintain and develop Boeing’s DCS&S (Defence Operational Training Capability (Air) Core System and Services) service, integrating with the RAF’s wider Gladiator team at RAF Waddington and across the Defence Industry.

You will be integrated into a faced-paced and dynamic customer focused environment and stretched to achieve your potential. Your wellbeing is also important to us and we strive to find a healthy life balance and with an ethical team culture and strong emphasis on openness, collaboration, innovation, safety and first time quality.

Please note that some business travel can be expected to other BDUK sites, as driven by business needs. This role also would require flexibility as off-hours support may occasionally be required to training service delivery.

Position responsibilities:

Definition of technical work packages that will integrate third party simulation systems and training devices to the core Gladiator system
Working with third parties to support their integration of DCS&S simulation components
Acting as technical liaison for third parties back into the core DCS&S development team
Providing support to integration, test and acceptance events
Providing technical support to initial training events, where needed

PLEASE NOTE: The successful candidate will be expected to undergo a UK SECURITY CHECK.

Employer will not sponsor applicants for employment visa status.

Preferred experience and qualifications:

Developing simulation systems for use in training
Usage of distributed simulation protocols such as Distributed Interactive Simulation (DIS) and High-level Architecture (HLA)
Application of systems engineering practices and principles
Experience developing air domain simulation systems
Experience integrating simulation systems for a military customer
Understanding /of modern air combat systems and tactics
Experience in developing and applying continuous improvement to process and productivity
Mission-orientated approach and familiarity with modern software development paradigms and processes
Approach with a focus on customers, quality and our people
A ""drive to action"" approach with the ability to be resilient and flexible in a fast-paced environment
Experience in or willingness to work collaboratively with other engineers, specialists and functional support team-members to achieve a sustainable outcome
Experience with the following systems:
VT MAK VR-Forces product line
3D geospatial tools and data formats such as OpenFlight, Shapefiles, ARCGIS, etc.
3D modelling formats and tools such as Presagis Creator, 3D Studio Max
HLAe based distributed simulation systems

Relocation:

This position does not offer relocation. Candidates must live in the immediate area or relocate at their own expense.

All information provided will be checked and may be verified.

Please apply for this role as soon as possible, as recruitment may commence before the end date.",3.7,"BOEING
3.7","Fleet, South East England, England",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
Data Engineer,-1,"The details


Newton is a high growth and successful management consultancy, employing the brightest and most curious minds in the industry. We boast an impressive client base of household names and bluechips, delivering impressive tangible benefits in areas including process optimisation and cost reduction. We are small enough that every individual can make a huge impact, both internally and externally.

Newton’s rapidly growing Digital practice delivers digital transformation across our largest and most complex programmes, including data science and analytics, systems change, technology and data architecture. The team is fully embedded into our core consulting teams and enable solutions worth tens of millions of pounds to our clients. The Digital team is one of Newton’s specialist capabilities, along with Change Management; these teams work seamlessly with the core consulting body to enable delivery of exceptional results for our clients. All our work is delivered by a single, coherent team, aligned to the clear goals of the Programme. Together, these specialist capabilities form a critical part of Newton’s proposition.

We are seeking Data Engineers who consider themselves thought leaders, excellent technologists, and self-starters with extensive experience in SQL and NoSQL databases, Data Modelling, and ETL pipeline design. These roles will be focused on large improvement programmes, working alongside Newton’s Operational Consultants, Digital peers and clients. These are leadership roles which include improving, developing and embedding a data-driven decision-making capability within our clients. We passionately believe in the value and potential of this capability and we aim for it to represent more than 10% of our business by 2021.

The Role


Peers describe you as the go-to person for the most challenging data ingestion and modelling problems, and you have a track record of root-causing and solving challenging data problems. Detail-orientation and reliable, well-tested code are features of your work but you are also comfortable working with clients and colleagues who are less technical to achieve amazing outcomes.
Leading the gathering, manipulation and analysis of data on major transformation programmes within the client-facing consulting teams
Getting under the skin of client data and processes to understand where value can be added
Creating new opportunities to deliver value to clients through data and digital
Implementing data-driven actionable insights that drive change across an organisation
Building pipelines that are suitable for Data Scientists and analysts working in a Python environment
Building effective relationships with stakeholders in the client organisation, influencing and coaching to help them implement a data-driven capability within their organisation
Being held up as a role model amongst the wider business with a reputation as an inspirational leader; influencing and improving internal processes and delivering training
Changing the way Newton uses data and digital by guiding and mentoring colleagues on how to gather, manipulate and analyse data effectively
Managing and developing consultants within your team
The Candidate


Successful candidates will have will have 5 years plus experience and tangible results of projects that include:
Experience of designing, developing, delivering and maintaining large-scale data infrastructures
SQL Master - Extensive knowledge and Vast experience with SQL Queries
Extensive data modelling experience, especially with low-quality data – knowledge of common methods like third normal form and star schema
Strong shell scripting abilities
Proficiency in using Cloud services for data engineering, storage, and analytics
Expert Python developer with a working knowledge of data science
Proficient with software engineering best practices (monitoring, testing, documentation)
Work with data analysts and provide the data they need and guide them on the issues
Extensive ETL experience and Hadoop experience
Experience in Real time data ingestion (e.g. Kafka)
Able to troubleshoot the data issues in dashboarding tools (Power BI) and suggest solutions
A team player can achieve more on a team that the whole is greater than the sum of its parts and works effectively with less technical colleagues
A word from us


Everybody likes to say they’re different...

Newton was founded to buck the norm in management consultancy - to demand better for its clients. Because, for us, change doesn’t come from behind a laptop. It comes from getting under the skin of an organisation and learning first-hand how it ticks. It’s not about producing reports that gather dust on a boardroom’s top shelf; it’s about delivering results that actually work.We crack some of the biggest challenges that businesses and public sector organisations face.

We’re called upon to bring much-needed change, from redesigning social care to improving build efficiencies on aircraft carriers. The work’s varied and complex - just how we like it. And no one else does it quite like we do. Take our business model. We guarantee our fees against delivering results, and will only leave once our clients see those results stick. Bold - yes. Disruptive? Always.

Blindingly fast career progression means that if you show you’re ready to step up - you’ll be promoted. Because we recognise talent, not tenure. And with all the support, training, and development you need, there’s really no stopping you. No matter the role you join in, you’ll be surrounded by spirited, naturally curious people. People who want to learn from you, and who’ll also teach you a thing or two along the way. It’s how everyone goes further, faster.

Our Privacy Policy


We think that it is important to be transparent about how we collect and use your personal data and are committed to protecting the privacy and security of the information we hold about you. Our candidate privacy notice provides more information about how we do this and provides you with certain information that must be provided under the General Data Protection Regulation ((EU) 2016/679). It is available here. If you have any questions about our candidate privacy notice, please contact us at experienced.hire@newtoneurope.com.",3.8,"Newton Europe
3.8","Wideopen, England",-1,201 to 500 Employees,2001,Company - Private,Consulting,Business Services,$50 to $100 million (USD),-1
Senior Data Centre Engineer,-1,"Location: Roy Shaw Centre (3-5 Cressy Road) with some home working

Starting salary: £41,952

Contract Type: Permanent, 36 hours per week, Full time, 36 hours per week

Alternative flexible working options available/open
to discussion

Click
HERE
for information on Camden’s flexible working options

Camden is changing
on the inside to make life better for everyone. Because we’re not just home to
the UK’s fast-growing economy. We’re home to the most important conversations
happening today.

And we’re
making radical social change a reality, so that nobody gets left behind. As a Senior Data Centre Engineer, you’ll
provide a high-quality desktop support service for the whole council, which
will improve the future for all of us.

London Borough
of Camden requires an experienced Senior Data Centre Engineer with specific
Cloud and O365 Exchange Administration expertise. In this role you will lead on
the provision of day-to-day Data Centre operational services, along with
proactively analysing, designing, planning, and implementing infrastructure
solutions across the Technology team.

The right
individual will also have the ability to manage customer expectations and be
able to effectively communicate with internal and external stakeholders clearly
and concisely.

The successful
candidate will have a BSc in relevant discipline, or equivalent industry
experience. You will demonstrate strong knowledge of ITIL practices with
emphasis on Operating Systems/Firmware covering the following platforms:
Windows, Cisco, UNIX and Linux and Cloud.

You will also
have advanced knowledge of the Office 365 Exchange Online Administration Centre
as well as the Security and Compliance portal. Understanding the consequences
when applying/removing Office 365 settings and unified communications with MS
Lync 2013 Exchange integration knowledge is also required.

This role is
also subject to a DBS Enhanced Check.

We’re ready to
welcome your ideas, your views, and your rebellious spirit. Help us redefine how we provide IT support
at Camden, and we’ll redefine what a career can be. If that sounds good to
you, we’d love to talk.

About Camden

Working for Camden you’ll receive
a host of great benefits, Click HERE to see full details.

To discover more about Camden and
our commitment towards diversity, equality and safeguarding, please visit our recruitment website

How to
apply:

To apply for
this job please follow the ""Apply"" link. In the ‘Why you?’ section of
the application form you will be expected to explain how you meet the key
requirements for this role noted in the Job Profile. When explaining how you
meet each of the requirements, please give examples that clearly demonstrate
your skills, knowledge and experience. When writing your examples give a brief
description of the situation or task but focus on the actions you took and the
result of your actions.

Closing dates for applications: Sunday 22 November 2020, 23:59

Interviews to
be held: w/c 30 November 2020

Please quote
reference: 200000CC

To view the Job Profile please click HERE

Camden is committed to making our recruitment
practices barrier-free and as accessible as possible for everyone. This
includes making adjustments or changes for disabled people or people with
long-term health conditions. If you would like us to do anything differently
during the recruitment process, or provide any information in an alternative
format, please contact us on 020 7974 6655, at resourcing@camden.gov.uk, or
post to 5 Pancras Square, London N1C 4AG.

Some posts at Camden are politically restricted, which means individuals
holding these posts cannot have active political role. For a list of all
politically restricted roles at Camden
click
here.",3.6,"London Borough of Camden
3.6","Kings Cross, England",-1,5001 to 10000 Employees,-1,Government,Municipal Governments,Government,Unknown / Non-Applicable,-1
IT Data Engineer,-1,"At AstraZeneca, we believe in the potential of our people and well develop you beyond what you thought possible. We make the most of your skills and passion by actively supporting you to see what can be achieved no matter where you start with us. The IT Data Engineer plays a pivotal role in channelling our data and analytics capabilities to make a positive impact on changing patients lives!

Luton is home to our UK Marketing Company (UKMC), responsible for the marketing of our medicines in the UK. Here colleagues from AstraZenecas corporate functions and our European and International regions sales and marketing teams sit. As a member of the Association of the British Pharmaceutical Industry (ABPI), all of our sales, marketing and communications activities are subject to the ABPI Code of Practice. If youre encouraged by the possibilities of science to make a difference and ready to discover what can be done personally join us!

Role Summary


As an IT Data Engineer based in UKMC, you will be responsible for growing and optimising data and data pipeline architectures, as well as optimising data flow and collection for multi-functional teams. You'll be a capable data pipeline builder and data wrangler who enjoys optimising data systems and building them from the ground up. Supporting our architect, data teams and will ensure efficient data delivery architecture is consistent throughout ongoing projects. You will need to be self-sufficient and comfortable supporting the data needs of multiple stakeholders, systems and products.

Key Responsibilities
Build and maintain efficient data pipeline architecture
Build the infrastructure required for efficient extraction, transformation, and loading of data from a wide variety of data sources
Identify, design, and implement internal process improvements: automating manual processes, optimising data delivery, re-designing infrastructure for greater scalability, etc.
Work with stakeholders across UKMC to assist with data-related technical issues and support their data infrastructure needs.
Build data tools for data analysts and data scientists
Work with data and analytics experts to strive for greater functionality in our data systems.
Liaise with, and help manage the workload for, offshore data engineering resources
Essential Requirements
Bachelor's Degree or equivalent experience
3+ years of experience in a Data Engineer role
Sophisticated knowledge of data integration and management tools: Informatica / SnapLogic
Sophisticated proven understanding and experience working with relational databases, query authoring as well as working familiarity with a variety of databases, particularly Oracle.
Experience building and optimising big data data pipelines, architectures and data sets.
Experience with object-oriented/object function scripting languages: Python / Java
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Desirable Requirements
Experience with AWS cloud services: S3, EC2, EMR, RDS, Redshift, Athena, Glue
Experience with big data tools: Hadoop, Spark
Experience with Pharmaceutical industry data sets
Experience with Data Privacy and working in a regulated environment
Leveraging blended onshore and offshore delivery models
Agile delivery methodologies
Apply today to part of something outstanding....

AstraZeneca is an equal opportunity employer. AstraZeneca will consider all you for employment without discrimination on grounds of disability, sex or sexual orientation, pregnancy or maternity leave status, race or national or ethnic origin, age, religion or belief, gender identity or re-assignment, marital or civil partnership status, protected veteran status (if applicable) or any other characteristic protected by law.

We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform crucial job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.",4.1,"AstraZeneca
4.1",England,-1,10000+ Employees,1913,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$10+ billion (USD),-1
Data Engineer,-1,"THE ROLE
ATG exists to revolutionise the secondary market. We believe in a world where millions of objects can be traded online at the best possible value through our channel of green commerce that gives new life to all things timeless, sustainable or re-usable.
Our mission is to be the global marketplace connecting bidders, businesses, collectors, consigners, contractors, and consumers to an under-explored world curated by thousands of trusted auctioneer experts.
We recognise to achieve our mission we need passionate, bright, and talented people. We work in a dynamic and exciting environment where innovation is at the heart of everything we do.
Decades of data underpins our business. As a shared service function, the analytics department plays a crucial role ensuring our stakeholders needs are being met - be that for commercial divisions, finance, product, marketing or operations. The current main outputs are; enabling self-service reporting and analysis, creating new or ad hoc reports and dashboards, retrospective analysis and automation of it, as well as forecasting.
The team has successfully set up our data warehouse but there are many improvement-based projects to complete such as; refining existing reports, bringing in new data sources to the warehouse and extracting new insights.
Reporting to the Head of Engineering, we are looking for a savvy Data Engineer to join our Business Intelligence and Data team. The hire will be responsible for expanding and optimizing our data warehouse and data pipeline architecture, as well as optimizing data flow and collection. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing and expanding our company’s data architecture to the pave way for advanced analytics, such as the introduction of Data Lakes.
RESPONSIBILITIES
Create and maintain optimal data pipeline architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Work with data and analytics experts to strive for greater functionality in our data systems.
Support the engineering leadership team in defining the technology roadmap to underpin advanced analytics and data science.
KEY SKILLS/EXPERIENCES
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.
You should also have experience using the following software/tools:
Experience with Azure Data Factory, Azure Analysis Services, PowerBi, and DAX.
Experience with relational SQL and NoSQL databases.
Experience with MS SQL Server and Transact-SQL.
Experience with Google Analytics.
Experience with AWS/Azure cloud services.
Experience with Python, R and C# would be advantageous.
Knowledge and experience of architectures to support advanced analytics and data science would be advantageous.",4.0,"Auction Technology Group
4.0","London, England",-1,51 to 200 Employees,1971,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Cabling Engineer,-1,"We are looking for experienced data cabling engineers, with skills card. Ideally with IPAF and a current safety passport. Fibre optic skills/training is a bonus, but not essential. Installation of cable containment, conduits, tray, basket etc is preferred. We work mainly in the North West, but do also travel all over the country and sometimes into Europe. Please do not apply if this description doesn't match your skills or training.

Job Types: Full-time, Contract, Permanent

Benefits:
On-site parking
Schedule:
8 hour shift
Monday to Friday
Overtime
Licence:
Driving License (Preferred)",-1,DCE Datacoms,"Altrincham, England",-1,-1,-1,-1,-1,-1,-1,-1
Senior Network Engineer,-1,"Overview of role

Are you a proactive and driven individual who can take ownership of identifying and resolving issues to tight deadlines? Do you have extensive knowledge of supporting network and telecommunications services?

If you excel at working as part of an engaged team that provides exceptional support, then we are looking for you!

An exciting opportunity has arisen for a Senior Communications Specialist to join our IT team based in Sunderland. The successful candidate will take responsibility for the day to day management of Group Data LAN/WAN infrastructure, ensuring maximum availability of all voice and data networks throughout the business.

We're looking for someone who:

The successful applicant will have a minimum of 3 years’ experience supporting network / telecommunications services in a 2nd/3rd Line position and be experienced with the following essential skills:

• Administration - Firewalls/Routers/Switches (CCNA Equivalent or above, CCNP Level Preferable)
• LAN/WAN – Technologies – MPLS
• LAN/WAN – Order Management, Network Design, Provisioning, and Installation
• LAN/WAN - Management / Monitoring / Documentation (Visio)
• Knowledge of Enterprise Wireless Solutions – Aerohive Ideal
• Centralised / Hosted Telephony Knowledge – (Avaya Aura CM)
• Telephony and Contact Centre System Process / Configuration Experience
• Skilled in Call Routing Design, Configuration and Technical Support
• Network Routing / Proxy Servers / Proxy Scripts

Advantageous Skills:

• Fortinet Firewall & Switch Knowledge
• Powershell Scripting & CLI Configuration Scripting
• Knowledge of Audio/Visual Systems
• Knowledge of IP CCTV Systems – Axis / Mobotix / Adpro
• Windows Infrastructure Knowledge – Active Directory / Domain / DHCP / DNS
• Windows Server Technologies (inc 2008/2012)
• Mobile Device Management - Intune
• Mac OSx / iPad / iPhone

Interested in joining us?

As part of our mission to the best motor retailer as judged by you, we believe in offering a collaborative and innovative environment, removed of bias or stereotypes. We want everyone to feel comfortable to be themselves while at work, knowing they will be fully supported in their personal development to be the best they can. In creating an inclusive culture, we respect and celebrate the uniqueness of our colleagues through our #WeAreJMG diversification and inclusion strategy.

To find out more, visit the website here:
https://www.jardinemotors.co.uk/corporate/diversityandinclusion/
So, if you’re a Communication Specialist who’s looking for an empowering environment where you are recognised for your hard work and commitment, we would love to hear from you!

Here are just some of the extensive benefits you’ll receive with us:

• - 33 days of annual leave (including bank holidays)
• - An open environment to discussing flexible working patterns and arranging them wherever possible.
• - Enhanced parental leave options with up to 16 weeks of full pay.
• - Employee care helpline and access to digital GP (for repeat prescription orders and online doctor’s appointments).
• - Online discount portal including money off retail brands and cashback on purchases.
• - 3% contribution pension scheme and 2x annual salary life assurance.",4.1,"Jardine Motors Group
4.1","Sunderland, North East England, England",-1,1001 to 5000 Employees,1969,Company - Private,Vehicle Dealers,Retail,$1 to $2 billion (USD),-1
Data Engineer,-1,"Are you seeking the opportunity to utilise your data skills working with one of the largest customer databases in Europe?

Does holding a critical role within our Centralised Data Team, whos focus is to allow the business to enable data as a true strategic asset, sound like the next great step in your upward career trajectory?

Would you thrive working for a company is are committed to learning and development, giving you time to explore new ways of data usage that excite you?

Then a Data Engineer role with Moneysupermarket Group is for you!

Joining a highly skilled team, your role will be an integral part of the Group Data Function, whos focus is on the collection and provision of thousands of product and data points. Utilising your ETL and SQL skills, you will become part of collaborative team where knowledge sharing, best practice a personal growth is a priority for the business!

We have some huge projects in the pipeline, giving you the chance to work with teams across and building up a comprehensive skillset.

What we need from you?
Experience with SQL
Experience with one or more ETL tools (e.g.Talend/SSIS/Pentaho/Informatica)
Familiarity with either Python or Java
Understanding of computer programming languages and core programming concepts
A passion for Data, cloud based services, web stacks and customer experience
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

Please be aware that, if youre successful in securing this position, the offer will be subject to a range of colleague checks that may include: identity, right to work in the UK, credit, criminal record, references and, where relevant, professional qualifications.",4.1,"Moneysupermarket Group
4.1","Manchester, England",-1,501 to 1000 Employees,1999,Company - Public,Internet,Information Technology,$100 to $500 million (USD),-1
Senior Data & Analytics Engineer,-1,"Company


AstraZeneca is a global biopharmaceutical business that focuses on the discovery, development and commercialisation of prescription medicines for some of the world's most serious diseases. Our growth platforms are doing extremely well, and the impact of our older products decline is starting to reduce. And, with the potential of our pipeline and new medicines, we can be confident in our ability to sustain growth for years to come and make an even bigger difference to patients around the world.

At AstraZeneca, we're proud to have a workplace culture that encourages innovation and teamwork. Our vision of a phenomenal place to work is one in which all our employees are engaged and encouraged by a clear shared purpose and a compelling strategy; where they are encouraged to perform and develop to their full potential; and where they are supported by the right organisation design, culture, technology and processes.

Role


As a Data & Analytics engineer you will support solution development, provide technical leadership, and take ownership for delivery. You are a data professional with a broad range of knowledge and experience across data & analytics, with significant depth in at least one technical area. You will work almost exclusively with Cloud services. You will join a team that has delivered cloud solutions, such as the development of auto-scaling data integration and analytic platform.

You'll be part of a team of engineers who work closely with IT colleagues in UK, US, Sweden, India and Mexico. We have business partners and team members spread globally, so you would need a collaborative delivery approach to be successful. We prefer to use Agile, but choose the appropriate approach for the project. You will provide technical leadership throughout our software development lifecycle, from the initial development of a technical design based on agreed architecture, right through to service. Do you have a real passion for delivering well engineered solutions? Because this will make you stand out from other specialists.

If you would like to discuss flexible working or part-time working, we would be happy to hear from you.

Key responsibilities
Define effective ways of end-to-end deliver of our data and analytics platform, drive visualisation strategy to enable specific insights for better business decisions.
Manage a team of data and reporting engineers passionate about developing cutting edge visualisation and computational capabilities for our big data platform.
Be hands on within the scrum team on a day-to-day basis, continually inspecting and crafting the backlog in response to the changing business requirements or technical discoveries/POCs.
Lead technology processes from concept development to completion of project deliverables.
Desirable technical skills & experience
Experience of cloud techniques and tools (AWS services such as S3, SQS, SNS, Athena, Glue, Redshift, Postgres, Aurora, MySQL, EMR, HIVE, Spark),
Experience of ETL techniques and tools (Talend, Snaplogic),
Experience of visualisation technologies (Power BI, Spotfire),
Experience of low code technologies (Microsoft Power Platform),
Experience of building scalable high availability analytics solutions,
In depth knowledge in one or multiple programming languages (Python, Java),
Experience of building unit tests, integration tests, system tests and acceptance tests,
Experience in DevOps, using continuous integration and continuous development (we use Jenkins, Nexus, Git),
Experience of data analysis profiling, investigating, interpreting and documenting data structures,
Familiarity with data modelling techniques and hands on modelling experience (our relational databases are third normal form and star schema),
Agile practices, especially being a SCRUM Master.
AstraZeneca is an equal opportunity employer. AstraZeneca will consider all qualified applicants for employment without discrimination on grounds of disability, sex or sexual orientation, pregnancy or maternity leave status, race or national or ethnic origin, age, religion or belief, gender identity or re-assignment, marital or civil partnership status, protected veteran status (if applicable) or any other characteristic protected by law.",4.1,"AstraZeneca
4.1","Royston, East of England, England",-1,10000+ Employees,1913,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$10+ billion (USD),-1
Signal Processing Engineer,-1,"Employer Description: *
Guided Ultrasonics Ltd. (GUL) operates in the Non-destructive Testing (NDT) industry and is the world leader in the development and manufacture of guided wave testing (GWT) equipment for inspection of industrial structures. Our products are used across industries by many major clients ranging from BP, Chevron and Shell in the oil and gas industry to E-On Energy in the power generation industry. Every day, our equipment is helping to create a safer and more efficient environment in the industry.

Despite the potential effect of COVID to the global economy, GUL is continuing to invest substantially in our research and development programme – GUL has numerous projects targeting specific industrial needs. To help us moving forward in this fast-innovative engineering sector, we are continually looking for excellent self-motivated candidates to join us.
Overview of Vacancy: *
Data Scientist/ Signal Processing Engineer to join a successful company based in Brentford, Greater London. Exciting and challenging work with excellent long-term prospects for the right candidate. Candidates with a degree in any STEM subject and experience in signal processing are encouraged to apply.
Job Description: *
The candidate will work closely with the engineering staff to define, test and implement signal processing and machine learning algorithms into in-house software packages.

The main focus of their work will be on a software package which determines the current wall-thickness of a pipelines from traces collected by permanently installed guided wave sensors. The aim is to maintain and further develop the existing software. Besides this main project, the candidate is expected to also contribute to general programming tasks as required by the engineering team, and with time they may be involved in additional projects requiring a similar skill set, as well as experimental work conducted to test the software.

The ideal candidate will have a proven track record of developing algorithms for a variety of applications in Python, MATLAB or C-programming languages. In doing so it is essential that the algorithms are developed in close and constant interaction with the engineering team.

Reference ID: SignalEng13102020

Job Types: Full-time, Permanent

Salary: £30,000.00-£40,000.00 per year

Additional pay:
Bonus scheme
Benefits:
Casual dress
Company pension
Life insurance
On-site parking
Sick pay
Schedule:
8 hour shift
Day shift
Monday to Friday
No weekends
COVID-19 considerations:
Refer to our COVID policy: https://www.guided-ultrasonics.com/covid19-update/

Experience:
Python programming: 2 years (Required)
Education:
Master's (Required)
Work remotely:
Temporarily due to COVID-19",-1,Guided Ultrasonics Ltd,"Brentford, England",-1,-1,-1,-1,-1,-1,-1,-1
Cloud Data Engineer,-1,"Cloudreach is the leading multi-cloud services provider. Our mission is to help companies navigate their unique journeys to the cloud and build new foundations for future growth. We're a team of multi-cloud natives with certifications across AWS, GCP and Azure. Businesses that work with Cloudreach adopt cutting-edge technologies to solve challenges and create new opportunities. Working exclusively on public cloud, we deliver unrivaled value for more than 1000 enterprise clients globally.

Behind our services are our Cloudreachers.

We pride ourselves on being the go-to destination for curious, talented, and driven people looking for unique work experiences to maximize their potential. We are passionate about asking questions, finding solutions, playing with the latest tools & technology, doing our lives' work, and having fun along the way. You can learn more about our innovative culture, global workforce, and Cloudy Values on our website.

We're not content with the status quo. We're here to do things better, and then do better things.

What will your role be?

The purpose of a Cloud Data Engineer is to enable data scientists and analysts to gain insights into data by architecting and implementing data-driven cloud based solutions. At Cloudreach, they will be subject matter experts and will be responsible for the technical leadership for data ingestion and processing engagements.

What are we looking for?
Experience of building reporting solutions in Microsoft Power BI
Solid experience of working with databases and writing complex queries
Effective data analysis skills
Proficient in writing SQL Queries, DAX Scripts and Power Query
Working knowledge of how to troubleshoot problems within Power BI Workspaces
Has experience successfully implementing simple enterprise solutions using a vast range of data engineering technologies. Has experience deploying and using the services in a major cloud platform
Works on tasks independently with little support from senior engineers
Delivers - Significant code contributions to more complex components of ETL pipelines.
Writes test, test cases, and code documentation with a high level of detail. Skill mastery in a few areas.
Stakeholder Management - Has guided & influenced customer stakeholders. Manages customer expectations on project deliverables.
Aware of the customers political landscape beyond the technology. Clarifies and communicates internally customer objectives.
Coding - Pushes back bad code and employs ETL best practices.
Additional:
Experience of ETL Processes and Tools such as Microsoft SSIS
Experience of Database modelling
Familiarity with cloud technologies such as Microsoft Azure
What are our perks?
Meaningful and impactful work opportunities at a pioneering, cutting edge cloud services provider
People-first mentality. We know that you and your mental health & wellbeing are #1. That's why we give you an uncapped holiday allowance (+ your birthday off!), employee assistance programs, and resources to support your mental health & wellbeing.
We embrace technologies that unlock agile & flexible ways of working. We respect our people to do their work when and how they work best. Work-life blend is a priority!
Our dynamic work environment enables autonomy while also promoting a sense of belonging to a global community
Opportunity for growth & development. Not only will you work alongside and learn from industry thought leaders, you will also be reimbursed for function-based certifications. We're multi-cloud and proud!
An inclusive workplace where varying backgrounds, ideas, and points of view are celebrated and the individual is respected, included and empowered to bring their whole self to work
Transparency in business updates & communications. Whether you're on the senior leadership team or a brand new employee, you're an integral part of the team and we'll make sure you know what's up
Recognition-rich company culture where daily wins are celebrated and individuals living out our values are applauded
We strive to remove barriers, eliminate discrimination and ensure equal opportunity through our transparent recruitment process. We are open to all groups of people without regard to age, disability, marital status, gender identity, race, colour, sexual orientation, religion, military status, veteran status or any other legally-protected characteristic.",3.4,"Cloudreach
3.4","London, England",-1,501 to 1000 Employees,2009,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Principal Engineer /Contractors Responsible Engineer – Stations and Depot Structures,-1,"Description

We currently have the opportunity for a talented Principal Engineer and CRE – Station and Depot Structures to join the Rail team based in York. This is a fantastic opportunity to join a dynamic and successful team that is growing rapidly. Successful candidates will be rewarded with a rich diet of interesting and challenging rail projects and an opportunity to develop their careers with a successful global engineering consultancy.

About Arcadis:

At Arcadis, we never lose sight of what’s most important. Because look beyond our projects and programmes and you’ll see it’s about human stories. From remaking public spaces that bring people together, to making cities easier to navigate, we’re focused on making an impact where it matters most – and improving quality of life.

It’s a big challenge. And why we need people committed to bringing their best, who deliver on their promises. People who value different perspectives, build sustainable relationships and dare to shape the future. People who seize the experiences available to transform their world – and the world around them.

It’s a shared goal amongst 27,000 Arcadians. And one we can only achieve by working together and applying our skills and expertise across design, consultancy, engineering, project and management services. It’s how we’ll find solutions to our clients’ most complex challenges. And how we’ll deliver exceptional results, today and tomorrow.

The railway sector is one of our core markets, a position it has held throughout our history. We pride ourselves on delivering new and exciting resolutions for rail infrastructure design and construction schemes.

About The Team:

The Rail North East business based in York and covering Network Rail’s Eastern Region including Anglia is growing off the back of recent wins. We’re delivering a multitude of projects for clients including Network Rail, Nexus, Tier one Contractors and Local Authorities as well as supporting other parts of the UK business to deliver HS2, Crossrail and other Network Rail Frameworks.

Requirements:

Reporting to the Stations Team Leader as a Principal Engineer you will provide design delivery on a variety of Station, depot or general railway building structure led multi-disciplinary projects within the rail environment. As we operate in such a diverse marketplace, you will gain an experience of working on a wide and varied portfolio of projects which will enhance your skills and test your technical knowledge.

You will be a key technical team member in the York Rail Stations & Depots design team, responsible for and involved the delivery of project-related tasks to meet budget, time-frame and quality targets, meeting or exceeding client expectations, promoting and marketing all facets of Arcadis services during interfaces with clients and other sectors and disciplines, contributing towards the achievement of the divisional business plan and to build networks within the industry.

You will fulfil the role of Stations/Structures CRE for Network Rail projects or lead Station/Structural engineer on projects for other clients.

We will ensure that we offer personal development which will allow you to progress your career and offer you the opportunity to be mentored by industry recognised Technical Leaders in their field who will lend you their experience and ensure that the training you receive will give you the best possible chance of success.

Essential Experience

You will have a gained substantial civil / structural design experience with significant experience gained within the rail sector and in a consultancy environment.

Significant geotechnical design experience is also required

Have previous relevant experience including supervision of elements of large, complex projects (with a focus on railway building structural engineering)

Chartered Engineer status with ICE or IStructE

Previously fulfilled the role or stations or structures CRE for Network Rail or similar lead engineer roles for other clients.

Experience preparing design deliverables using structural engineering design software packages

Good working relationships developed with Clients

You will be an Innovative thinker, a team player, proactive and delivery focused

An aptitude for Building Information Modelling and the workflow associated with projects delivered in a Common Data Environment

You will possess the enthusiasm to tackle stretch tasks

You will be flexible to travel throughout the UK on occasion

You will be able to demonstrate strong team building and collaboration skills

Excellent written and verbal communication skills with proven planning and organisation skills

Manage engineering activities that contribute to sustainable development

Good IT skills including Microsoft Office applications

Duties & Responsibilities:

Responsibilities of this role include, but are not limited to:

Developing skills and knowledge base in both the technical and management streams

Leading and assisting with the preparation of documentation relating to projects

Designing in 3D modelling environments such as AECOSim, Revit and Civil 3D

Fulfilling CRE / Lead Engineer roles on projects

Preparing design calculations, drawings, specifications, reports and other project documentation as required in line with company and client requirements as well as national standards and codes of practice

Taking a lead role in the resolution of technical issues

Supervision and technical development of other engineering team members

Attending site and taking a lead role in the completion of surveys in a rail environment

Gaining experience and proficiency in Arcadis systems and procedures

Becoming familiar with, and compliant with, relevant Health, Safety and Welfare regulations and to promote a culture of awareness within the team

Building relationships with Clients on projects

Performing other duties and responsibilities as required from time to time by your manager or Arcadis

Line Management responsibilities

Why Arcadis?

At Arcadis, you’ll have the opportunity to build the career that’s right for you. Because each Arcadian has their own motivations, their own career goals. And, as a ‘people ﬁrst’ business, it’s why we’ll take the time to listen, to understand what you want from your time here, and provide the support you need to achieve your ambitions.

Wherever you join us, you can look forward to a competitive reward package that includes an attractive starting salary, opportunities for career development and being part of a sociable community. We have a performance-related bonus scheme and an employee recognition scheme. Other beneﬁts include membership fees to join your relevant professional body, employer contribution pension scheme, ﬂexible working and a flexible holiday scheme.

We believe that by working together diverse people with different experiences develop the most innovative ideas. Equality, diversity and inclusion is at the heart of how we improve quality of life and we work closely with our people across six ED&I Workstreams: Age, Disability, Faith, Gender, LGBT+ and Race. A diverse and skilled workforce is essential to our success.

Qualifications

Degree in civil/structural engineering (preferably a Masters’ Degree)

Chartered or Incorporated Engineer professional status, or equivalent",3.9,"Arcadis
3.9","York, England",-1,1001 to 5000 Employees,-1,Company - Public,Construction,"Construction, Repair & Maintenance",Unknown / Non-Applicable,-1
Data Engineer,-1,"Why the role exists

We are expanding our team and looking for talented Data Engineers to to support and coach agile delivery teams in developing and maintaining data solutions, in line with our data strategy, architectural vision and roadmap.

You'll get to work with an incredible bunch of people in a creative, energetic environment.

What you will be doing

You will play a vital role and will be an integral member of the delivery team. No two days are the same but typically some of things you will be doing will be:
Contributing towards data solutions in line with the data strategy, architectural vision and roadmap
Particpipating in chapter meetings and representing the Data chapter as an embedded resource in the delivery team
Working in alignment with the standards agreed in the Data chapter
Ownership of data engineering solutions ensuring quality and standards are met
Working with a team of talented people as part of an agile delivery team following Scrum Principles
Ensuring data engineers buy-into the data strategy and data engineering chapter standards
Providing technical coaching and mentoring to Data Engineers
Supporting the recruitment process for Data Engineers
You will be a technically proficient SQL developer, who is comfortable leading by example in coding best practices and standards and expect candidates to have proven experience in the following areas:

Core technical skills
Highly proficient in ETL Process Development
Highly proficient in Data Modelling
Highly proficient in Data Warehousing dimensional modelling techniques.
Experience in Data Warehousing Method Design Methodologies
Strong knowledge of data engineering technologies, such as SQL Server, Azure data lakes, Delta Lake, Azure data factory, Azure Databricks, Apache Spark, SSIS or other data platform/integration tool
Some experience in .NET, C#, PowerShell, Python, Scala or R.
Experience in the usage of a continuous delivery system and related concepts
Experience in the usage of data reporting platform, such as PowerBI
Strong understanding of application security concepts, including securing production applications and delivery pipelines
Strong understanding of systems required in delivering commercial finance products, and how they fit together (i.e. loan origination systems, loan management systems, collections systems)
Strong understanding of data governance concepts such as data ownership, data stewardship etc
Non-core technical skills
Collaborates well in a team environment
Passionate about continuous improvement / best practice
Passionate about Business Intelligence
Confidence to speak in front of people and produce useful and concise documentation as necessary
A desire to learn new techniques and trends and apply them within our business context
An ability to successfully balance technical requirements with pragmatic delivery
Must be able to demonstrate leadership, communication and influencing skills
This is an outstanding opportunity for an ambitious and talented Data Engineer to make a significant, long-lasting contribution to a high-profile business, at a key point in its development. For the right person theres a competitive salary and fantastic company benefits.

The Process

The selection process will consist of a short telephone interview and technical test followed by an online interview.

We are willing to consider remote working options with the successful candidate, however there will be occassions when you will be required to work in the Nottingham office. Remote working preferences will be discussed as part of the interview process.

Oakbrook is an Equal Opportunities Employer",4.5,"Oakbrook Finance
4.5","Nottingham, England",-1,51 to 200 Employees,2012,Company - Private,Lending,Finance,Unknown / Non-Applicable,-1
Data Engineer,-1,"At MarketFinance, we celebrate ambitious business leaders. They bring strength to our economy and are building the world we all want to live in. MarketFinance is one of the UK's leading Fintechs and we use smart technology, backed by help from great people, to deliver flexible business finance solutions, directly and quickly. Our online platform and proprietary risk model enable us to provide business loans and advance cash against outstanding invoices, in the form of working capital funding, so that businesses can get on with growing - instead of having to worry about cash flow. We believe in the endless possibilities that arise when entrepreneurs have more time to focus on what they love.

Our values matter and as part of the team, they’ll be yours too.

#MakeItHappen | #1Team1Dream | #AlwaysBeLearning

Requirements

Initially, the main focus of this role will be to help with the support and optimisation of the current data-platform. Going forward, this person will help with the design, implementation and deployment of new services on Azure, ensuring that they’re scalable and fit for purpose.
Hard skills
Strong Python and SQL skills
Processing of large data sets (ETL jobs) on distributed systems
At least 1 year experience with Azure cloud data products (for example: HD Insights, Data Lake Analytics, Data Factory)
Knows and applies testing best practices
Soft skills
Analytical skills
Problem solving
High level of autonomy (completes task end-to-end, proactively reaches out to stakeholders to gather inputs, etc
Nice to have:
C# experience
Serverless experience i.e. Azure functions, AWS Lambda etc.
Event-streaming architecture/technologies (Apache Kafka, etc)
Experience with AWS (Athena, S3, Lambda, StepFunctions, etc)
Benefits

We are a team of bright and talented people from different backgrounds and cultures, with different perspectives, skills and experiences, who work together to get things done. Positivity is key which means we support each other and have a lot of fun along the way. Our celebration of small businesses binds us together and keeps us focused on our ultimate purpose. Whether this celebration comes from working in small businesses previously, having founded a business or having experienced it through family we all have this unique appreciation and it drives us to be the best for our customers.

At MarketFinance, the opportunity for growth is as big as your ambition. Things move quickly in FinTech and that’s all part of the adventure. Our benefits include:
Competitive salary and best-in-class share options scheme
25 days annual leave, plus your birthday off
Mentoring from industry leaders and the opportunity to make an impact at one of Europe’s foremost Fintechs
Private health coverage and half-price Virgin Active gym membership
Enhanced maternity leave, Amazon Kindle and unlimited e-books
Excellent company culture and a great office in the heart of Shoreditch
This role will allow you to work 100% remotely with occasional travel to the London office (when safe to do so) for company meetings. This typically will be 1/2 days per quarter.

Applications for this role will close on 30/11/2020.",3.7,"MarketFinance
3.7","London, England",-1,51 to 200 Employees,2011,Company - Private,Financial Transaction Processing,Finance,$5 to $10 million (USD),-1
Senior Java Engineer,-1,"Senior Java Engineers *
Belfast, Northern Ireland *
We have an immediate need for Senior Java Engineers to join our expanding team.
WHAT YOU WILL DO: *
· Collaborate with Product, Engineering, and Data Science teams to design and develop the leading-edge Classify360 machine learning and related components

· Work within an Agile delivery / DevOps methodology to deliver proof-of-concept and production implementation in iterative sprints

· Continuously improve software components to perform at 10+ petabyte and 100+ billion DB record scale.

· Be exceptionally confident with communicating design ideas, development options, software components, configuration options, and other technical details to internal Congruity360 teams.

Please contact us immediately if you want to challenge yourself by working in a startup team within an established company.

Congruity360 is headquartered in the Boston metropolitan area with major offices in New York City, Los Angeles, and Belfast Northern Ireland. The recent EDM Consultancy acquisition is requiring rapid expansion of Congruity360’s Belfast team, which is our corporate Research & Development Center of Excellence.

The Congruity360 flagship product, Classify360, enables clients to reduce their financial and data risk by increasing their data understanding, classification, and security, allowing clients to meet all of the current, new, and changing laws, regulations, and business drivers. In other words, making intelligent business decisions.
Belfast and SURROUNDING area candidates ONLY**.*
OUR IDEAL CANDIDATE:

· 5-8+ years core Java

· 3+ years in Microservices

· 2-3+ years team leadership

· Agile development

· Data API & web services development
BONUS SKILLS: *
· Plus: AWS or Azure certifications

· Plus: CI/CD

· Plus: PostgreSQL

EDUCATIONAL and experience REQUIREMENTS:

· A University degree is required with a major in Computer Science, Mathematics, Physics, or any other related field

· 7-10+ years relevant software engineering and development experience

· Great communications skills, attention to detail, self-motivated, and the ability to work well with people are essential

· Some minor inter-office travel may be required.

Special notes:

We are an equal opportunities employer. Please visit our website to review our diversity and inclusion statement. All considerations will be made on merit. Applicants should note that Congruity360 will complete AccessNI background checks on all candidates offered a position.

Due to hiring velocity, Congruity360 requires a current and valid UK work permit. Visa sponsorships will NOT be considered. Congruity360 has an internal recruiting team and does not accept agency candidates. If you want to join our team, get in touch with us directly!

Job Types: Full-time, Permanent

Pay: £50,000.00-£80,000.00 per year

Benefits:
Work From Home
Schedule:
Monday to Friday
Weekends
Education:
Bachelor's (Required)
Work remotely:
Temporarily due to COVID-19",3.8,"Congruity360
3.8","Belfast, Northern Ireland",-1,51 to 200 Employees,2017,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Azure Data Engineer,-1,"What to expect
About the role
We are looking for a Microsoft Azure Data Engineer to be a key member of the Azure Data Team, working directly with various stakeholders from across the business, designing stable and reliable data warehousing technology that surfaces the data our business uses, proactively monitoring the company's data warehouse and participating in the design and implementation of the associated data pipeline technology that moves data from our operational systems to the data warehouse.
About Commify
We make business communication brilliant! We work with more than 45,000 companies, helping them to transform their mobile communication with their customers and employees. Our success is the result of hundreds of talented people pulling together to achieve a common goal. Join our team and be part of our success story.
You will thrive in an environment of passion, integrity, ownership and innovation, where development and progression is a real focus. We’d like to think we have everything you’d expect from a benefits package, from 27 days holiday and your birthday off work, to private medical cover, dental cover and bi-monthly social events! On top of this you can expect £350 of Christmas vouchers and added extras like beer o’clock and an amazing Christmas party.
What you’ll be doing
As Microsoft Azure Data Engineer you will be responsible for:
Developing the data warehouse platform, testing, improving and maintaining new and existing pipelines, and working closely with operational systems owners to ensure data consistency
Collaborating with operational systems owners to identify issues with existing pipelines, to develop changes to existing pipelines and to design and build new pipelines
Designing stable, reliable and effective data pipelines
Providing data design consultancy to operational systems owners to ensure the data they hold in their systems is optimised for use in the data warehouse
Providing expert data and domain advice to Management Information specialists, Analysts and Data Visualisers such that their understanding of the data within the data warehouse is suitable for their work
Contributing to data technology roadmaps including key items such as upgrades, technical refreshes and new versions
Schema design and data modelling
Ensuring the data warehouse technology complies with our operational and service management standards
Troubleshooting potentially inefficient pipelines and optimising them
Managing data technology across distributed Azure Regions and Technology
Maintaining all relevant documentation and knowledge bases
Escalating data problems to operational systems owners to assure the quality of the data within the data warehouse
Researching and suggesting new data products, services and technologies
Working in a 24x7, high-availability environment
Providing on call support including out-of-hours incident support
What we’re looking for
We’re interested in hearing from candidates with experience in the following areas:
Developing, building and deploying solutions based on Microsoft Azure SQL, Databricks, Data Factory and Blob Storage
Infrastructure as Code technologies such as Microsoft ARM templates or Terraform and the tools to automate their deployment
Producing production-quality code using git source control and completing with internal documentation
In-depth understanding of data management (e.g. permissions, recovery, security and monitoring)
Ability to quickly understand new schemas (including in technology other than Microsoft SQL Server i.e. MSSQL, NoSQL, API-Based)
Converting business requirements into data pipelines by working with operational systems owners to understand their data and extract it from their systems
Working with MI/BI Analysts/Visualisers to understand their requirements
Performance tuning of Azure Data Technology
It would be great if you also had:
High Availability in a Microsoft Azure Data Environment
Security in a Microsoft Azure Data Environment
Powershell for scripting automations
Azure SQL Data Warehouse/Azure Synapse
Azure Cosmos DB
Azure Stream Analytics
Tableau Report Design
Experience/knowledge of working in an agile environment and experience with agile methodologies such as TDD, Scrum, Kanban
What to do next
To apply please send your CV to recruitment@esendex.com by 25th October 2020.
Diversity
We’re committed to building a team with a variety of backgrounds, views and skills, embracing our key values. The more diverse and inclusive we are, the stronger we are as a team. We encourage applications from all candidates with the relevant skills and experience.
The legal stuff
Esendex is committed to protecting the privacy and security of your information. Personal information submitted as part of the recruitment and selection process will only be used for these purposes. We will retain information for up to 12 months, after which it will be deleted or destroyed. For full information about your rights in relation to your data, please see our full Recruitment Privacy Policy here.",4.6,"Esendex
4.6","Nottingham, England",-1,201 to 500 Employees,2001,Company - Private,"Cable, Internet & Telephone Providers",Telecommunications,Unknown / Non-Applicable,-1
Infrastructure Engineer/Specialist,-1,"Overview of role

An exciting, new opportunity has arisen for a for a knowledgeable and highly motivated Infrastructure Specialist to join our team. This role is ideal for a technically astute individual looking to join a business representing some of the most desirable automotive brands.

This is a 3rd line hands on role primarily responsible for the support of Jardine Motors Group network infrastructure, support applications and systems including the support and delivery of software and technology projects. You will be helping the drive of technology innovation across the group.

The successful candidate will have experience of working in a dedicated Infrastructure Team and can work on your own initiative within a team environment. Also, a proven track record in support within a ticket-based service desk function.

We are looking for someone who has:

Strong Background in Windows Server (2008r2, 2016) and Windows Server infrastructure including Group Policy, Active Directory, DFS, DFS-R, DNS, DHCP.
Experience in patch management of Client OS, Server OS, Applications and hardware, including monthly reporting.
Server and Desktop Application Support
MS SQL Server – 2008/2016 – Backup, maintenance and Recovery
Experience Supporting a Virtualised Environment including detailed knowledge of VMware vSphere 6.5 (knowledge of vSAN and/or Horizon advantageous)
Experience of managing Backup, Disaster Recovery and Business Continuity solutions and methods.
DNS domain management and expertise
Solid understanding of network technologies and of the Microsoft Suite of solutions and technologies such as Azure AD, Office 365 and MFA
Data Backup Applications
Change, Availability & Capacity Management
Firewall Management Knowledge / Experience

Desirable Skills / Experience :

Fortinet Security Product Experience
Antivirus (Fortinet experience advantageous)
Scripting and automation e.g. Powershell
Cloud Based Enterprise Wireless Solution Knowledge (Aerohive)
Project, document and time management
3rd party management and escalation
Autoline/Kerridge; Fortinet; Storage Systems (SAN/NAS) support and performance analysis and MDM knowledge/experience is also desirable, but not essential

Interested in joining us?

As part of our mission to the best motor retailer as judged by you, we believe in offering a collaborative and innovative environment, removed of bias or stereotypes. We want everyone to feel comfortable to be themselves while at work, knowing they will be fully supported in their personal development to be the best they can. In creating an inclusive culture, we respect and celebrate the uniqueness of our colleagues through our #WeAreJMG diversification and inclusion strategy.

To find out more, visit the website here: https://www.jardinemotors.co.uk/corporate/diversityandinclusion/

So, if you’re an Infrastructure Specialist who’s looking for an empowering environment where you are recognised for your hard work and commitment, we would love to hear from you!

Here are just some of the extensive benefits you’ll receive with us:

33 days of annual leave (including bank holidays)
An open environment to discussing flexible working patterns and arranging them wherever possible.
Enhanced parental leave options with up to 16 weeks of full pay.
Employee care helpline and access to digital GP (for repeat prescription orders and online doctor’s appointments).
Online discount portal including money off retail brands and cashback on purchases.
3% contribution pension scheme and 2x annual salary life assurance",4.1,"Jardine Motors Group
4.1","Sunderland, North East England, England",-1,1001 to 5000 Employees,1969,Company - Private,Vehicle Dealers,Retail,$1 to $2 billion (USD),-1
"Specialist, Data Engineer",-1,"Role Purpose

This position needs someone with energy and enthusiasm to complement our existing development team to look after our BAU processes and accelerate our delivery of our data lake solution.

In this role you must have a attention to detail and growth mind-set with a desire to deliver high quality output for yourself and the team.

The ability to hit the deck running and add value quickly will be crucial.

Key Accountabilities
Monitoring daily BAU data pipelines and ensure our data solution is refreshed up to date every day
Enhance the daily BAU process. Making it easier to monitor and less likely to fail
Hands on development on Data Lake build, change and defect fix
Responsible for the BAU release processes
Working with the team within an Agile framework using the industry best practice agile methodology tooling that controls our development and CI/CD release processes
Contributing to the new Data Lake technology across the organisation to address a broad set of use cases across data science and data warehousing
Skills and Experience

ESSENTIAL
Proficiency with traditional database SQL technologies (Oracle, SQL Server, DB2)
Experience with data solution BAU processes (ETL, table refresh etc.)
Experience with integration of data from multiple data sources
Experience in Big Data Data integration technologies such as Spark, Scala, Kafka
Experience in programming language such as Python or Scala.
Analytical and problem solving skills, applied to data solution
Experience of CI/CD best practice
Good aptitude in multi-threading and concurrency concepts
Familiarity with the fundamentals of Linux scripting language
DESIRABLE
Previous proficiency with ETL technologies (e.g. Talend, Informatica, Abinitio)
Previous exposure to Python
Previous exposure to own data solution BAU monitoring and enhancement
Exposure to building applications for a cloud environment
Personal Attributes
Attention to detail
Keen to learn and enhance the existing processes
Structured, organised, process driven and outcome oriented
Personable, credible, with good communication skills
Good interpersonal & written communication skills. Ability to present ideas in business-friendly language
Self-motivated, able to work in a high-pressure environment
Strong organizational, planning and time management skills
Ability to build strong and effective working relationships on an ongoing basis
Ability to embrace company culture and embed into day-to-day interactions
Passionate, keen and energetic with demonstrable enthusiasm and commitment.
Pragmatism in design decisions",3.1,"NewDay
3.1","London, England",-1,1001 to 5000 Employees,2011,Company - Private,Lending,Finance,Unknown / Non-Applicable,-1
DevOps Engineer Apprentice,-1,"This is an expanding technology Company that focusses on IT and Telephony Solutions. They are at the cutting edge of cloud technology and have grown year on year since they were founded in 2007. They are both a 3CX Solutions Provider and a Microsoft Partner.

They value every member of staff as they understand that they play a significant part in the development of the company. No one has ever left the company, which is testament to the opportunities and rewards that are on offer to everyone.
Overview: *
They have employed two previous apprentices, both of whom are excelling in their respective fields.

They are looking to invest in another apprentice to assist with their Dev Ops development.

The role is for a DevOps apprenticeship but an interest in Cloud Computing and experience in coding would be an added bonus.

As a DevOps Apprentice you will be focused on implementing and facilitating the use of DevOps practices within the business.
Main responsibilities: *
You will be involved with HTML, PHP, MySQL development
You will be involved in multiple stages of the software development life cycle.
Your role will focus on coding for business projects and deployment of code
You will be writing scripts and automation tasks
You will be working with and connecting databases
The role will not be restricted to development work. You will also be involved in the design and installation of cloud based phone systems, namely 3CX and MS Teams.
Desirable skills: *
Familiarity with Microsoft solutions and technologies
Keen interest and understanding of cloud computing
Code in multiple languages
Personal qualities: *
Passion for technology especially cloud computing
A can-do attitude
Able to interpret, record information and data accurately.
Excellent Problem solving skills.
Methodical approach to tasks
Self-motivated.
Ability to work alone without close supervision.
Excellent communication skills both verbal and written
Desired qualifications: *
As and Bs at GCSE or equivalent
Technical A-levels or equivalent
Ideally a L3 Apprenticeship in a technical standard
Future Prospects: *
Both of the companies former Level 3 apprentices are still within the business, working within fulltime positions and regular salary reviews and increases as well as constant training and career development.

A progressive career path will also be offered to you if you are successful in your DevOps apprenticeship
Important Information: *
QAs apprenticeships are funded by the Education & Skills Funding Agency (ESFA), an executive agency of the Department for Education.

To be eligible for a Government funded apprenticeship you must have lived in the UK or European Economic Area (EEA) for the last 3 consecutive years.

Job Types: Full-time, Apprenticeship

Salary: £12,000.00 per year

Schedule:
8 hour shift
Flexible Working Options Available:
Not offered
Work remotely:
No",3.1,"QA Ltd
3.1","Oldham, England",-1,1001 to 5000 Employees,1985,Company - Private,Education Training Services,Education,$100 to $500 million (USD),-1
Cloud/ Storage Infrastructure Engineer,-1,"*Cloud/ Infrastructure Storage Engineer*

*OUR REQUIREMENTS *

*RELEVANT EXPERIENCE*

· Minimum 5+ years in Infrastructure role

· Experience of current infrastructure trends e.g. soa, cloud, digital, rpa

· Experience in dealing with multiple suppliers

· Proven ability to work in a cloud based or hosting environment

· Experience working with NetBackup storage

· Experience in Microsoft System Centre Security, data, integration and applications layers

*TECHNICAL SKILLS *

· Knowledge of ITIL and industry best practices

· Strong virtualisation experience using VMWare, Citrix Xen App and NetScaler.

· Excellent understanding of server hardware

· Microsoft Technologies

· Cloud Technologies

· Proven track record with hosted desktop and published applications

*EDUCATION AND QUALIFICATIONS *

· VMware VCP Certified(Desirable)

· Microsoft MCSE Certified or equivalent

*SKILLS*

· Solid technical background in a hosted services environment including infrastructure networks,

· Experience with incident ticketing systems, workstation management systems and desktop imaging.

· Knowledge of Microsoft Active Directory, Exchange 2010 and SQL Server

· Good knowledge of security as it relates to cloud based infrastructure

· Experience using automated monitoring tools

Job Type: Full-time

Salary: £40,000.00-£62,000.00 per year

Schedule:
* Monday to Friday

Experience:
* Infrastructure: 5 years (Required)

Work remotely:
* Temporarily due to COVID-19",-1,N Consulting Limited,"London, England",-1,-1,-1,-1,-1,-1,-1,-1
Back End Developer / C# Software Engineer / ASP.NET MVC back end,-1,"Job Description*
Back End Developer – ASP.NET MVC (MUST HAVE FULL RIGHT TO WORK IN THE UK STATUS ALREADY IN PLACE). Driving license and own car would be preferable.*
This is an office based role and will require the successful candidate to work from the office in Salford, please only apply if you can commute*
Back End Developer / Software Developer / C# Software Engineer / ASP.NET MVC back end experience is essential for this role, experience within a mobile app environment and with Web API’s is desirable.
Responsibilities and Duties*
· Designing and building .Net MVC applications and CMS

· Integrating user-facing elements with server-side logic

· Building reusable code and libraries

· Optimising applications

· Implementing security and data protection
Qualifications and Skills*
· Essential Technical Skills:

· 2+ years’ experience using bootstrap framework

· Experience with the following: REST APIs, C# .NET 4.5 and above, MVC, visual studio developer tools, MSSQL

· Good experience of JavaScript, jQuery & Ajax

· Ability to adapt and be able to create solutions thinking outside of the box

· Able to transfer knowledge between different languages/frameworks when needed

· Basic knowledge at dealing with Stored Procedures

Work on several complex classic asp asp.net / C# software development projects

Manage legacy applications (classic asp) while updating them into newer technologies (asp.net)

Implementation of security and data protection

Well experienced with .NET frameworks

Experience writing SQL to query databases and stored procedures

Azure CI CD Pipeline deployment and configuration across multiple environments

Quickly debug and solve problems

Good understanding of the software development lifecycle
Beneficial Skills: *
· Experience of working within Azure DevOps for work allocation and tracking

· Previous experience in mobile / web app development

· Experience with the following: Android & iOS, Server Operating Systems, Amazon Web Services, CMS, CRM

Benefits:

· Flexible working hours

· Casual dress

Job Types: Full-time, Permanent

Expected Start Date: 14/10/2020

Job Types: Full-time, Contract, Permanent

Salary: £32,000.00-£36,000.00 per year

Work remotely:
No",-1,Desap Enterprises,"Manchester, England",-1,-1,-1,-1,-1,-1,-1,-1
Python Software Engineer - Search,-1,"As the world’s largest recipe-sharing community, Cookpad enables millions of people to find and share recipe ideas. It’s a global platform used by 100 million people, in over 30 languages, and in more than 70 countries.

Cookpad is looking for a Python Software Engineer to join our global headquarters in Bristol (remotely to start with). You will be part of our growing Search Team, whose focus is on delivering a world-leading joined-up search experience to solve real problems for our diverse community.

Our mission is to make everyday cooking fun. Because we believe that cooking is the key to a happier and healthier life for people, communities, and the planet.

As a Python Software Engineer joining us in this you will help build our next-generation search platform, using your skills to develop, test, and deploy sustainable and beautiful web APIs, machine learning inference services, and data processing pipelines. This is a unique opportunity to join a growing team at an exciting phase of development. You will work at the cutting edge of search engineering. Your expertise will be instrumental in building and scaling out a platform that combines vast quantities of real-time data with domain-leading machine learning to deliver real impact to more than 100 million users worldwide.

What are we looking for?

Our existing team covers a wide variety of different skills and we’re looking to broaden this yet further. Here are a few broad areas in which our team works. Can you picture yourself having an impact in one of these areas? Do you have an eagerness to advance your knowledge in one or more of these areas? Please highlight this when applying.
APIs and services: Building fast, flexible APIs and the data processing that underpins them. Designing APIs to be used by a variety of users – from cooks across the world, to internal users like engineers and community managers. Building libraries, services, and tooling that accelerate the pace of delivery.
Search at scale: Deep knowledge of the Elasticsearch query DSL and performance tuning for real-time applications at global scale. Skills in data exploration using Kibana.
Search science: The algorithms and methods that make search more relevant. Identifying opportunities to improve search quality – from relevance engineering to machine learning to natural language processing and beyond. Devising evaluation methodologies to measure search quality and developing experiments to validate them.
A typical day might include any of the following:
Implement and deploy a new experimental HTTP API endpoint to test an unproven feature concept against our existing baseline (and being prepared to fail fast, revert and rethink!).
Implement a change in system architecture to improve an onerous or error prone area of development, subsequently helping the team make the most of the change.
Explore API performance to further improve response times while still ensuring results are hyper-relevant for every user.
Refactor a section of code to fix the flaky test that seems to intermittently fail, especially when you want to release something new and exciting to production.
Review another team member’s PR, offering “must”, ”should”, “could”, and “would” guidance that finds the sweet spot between delivery and improvement.
Add a step to CI to automate an element of PR review, freeing team time to spend on other development work.
Requirements

Who you are:
You have substantial experience of working in a software team delivering features at pace.
You love writing software using Python. You deliver tested, reliable, and maintainable software.
You prefer working on backend engineering problems, including contributing to projects such as building web APIs, data processing pipelines, and project tooling. You leave beautiful clean code behind that other developers love to work with.
You’ll have experience of, or are excited to learn about, some of the other technologies we apply at Cookpad, such as Apache Spark (PySpark), Apache Kafka, Elasticsearch, AWS, Terraform, Docker, and Kubernetes (but don’t let not having any of these stop you applying if you have something else to bring!).
You are passionate about continuous integration and delivery, and apply these principles when building software, striving to ship your work quickly and often.
You’ll want to have a hand not only in deciding how our software is built, but in understanding who it’s being built for and why they need our help.
About Cookpad

Our heritage is unique: Cookpad was founded in Japan in 1997 and is a listed company in Tokyo. We set up our international HQ in the UK and here we’re a start-up, building the global platform and working with our colleagues around the world.

Cookpad is growing at speed and we’re looking for exceptional people who make things happen and create solutions on the scale we're looking for.

It feels like a start-up with global ambition. We work in small, collaborative teams and in a creative, fast-paced environment.

Benefits

Why join Cookpad?

People join us because they share our vision to improve people’s lives. As a company Cookpad invests heavily in learning and development - we hire smart people who thrive in small, highly collaborative and energised teams, and who look at what we do and want to be part of it.

Valuing our team means we offer competitive salaries, an employee referral scheme and very generous benefits, including 7% employer pension contribution, income protection and life insurance, and an employee referral scheme. We are central to transport hubs and bike routes which helps with flexible working and all-important downtime with family and friends.

In our usual working environment breakfast is provided every day, we have a fully stocked and fully equipped team kitchen where we can cook together and there are weekly pilates/ yoga classes.

In this interim period due to the current global pandemic we are working to keep as many of our perks as possible available to our staff. This includes moving the pilates/ yoga classes online as well as company socials and attendance of meetups.

Equal Opportunity

The Cookpad team is made up of an incredible, diverse range of people. We are proud to be an equal opportunity employer. We do not discriminate based on race, ethnicity, colour, ancestry, national origin, religion, sex, sexual orientation, gender identity, age, disability, veteran status, genetic information, marital status or any other legally protected status.

Your Privacy

When applying for a job with Cookpad, we will collect personal information about you. We use that personal information predominantly for the purposes of processing your application and analysis of our recruitment activity. You can read more about how we use your personal information in our privacy policy. If you're an applicant from Europe, you can read our privacy policy here. If you are an applicant from a country outside Europe, you can read our privacy policy here.",3.9,"Cookpad Ltd
3.9","Bristol, England",-1,51 to 200 Employees,1997,Company - Public,Internet,Information Technology,Unknown / Non-Applicable,-1
Splunk Engineer,-1,"QinetiQ comprises teams of dedicated people; experts in defence, aerospace, security and related markets. We draw on our extensive technical knowledge and intellectual property to provide the know-how and support to solve some of the world’s most challenging problems. Our people make the critical difference to customers by providing unique approaches to problem solving. Why don’t you join some of the world’s finest scientific and technical minds and help us make tomorrow work today?

Job description/Person specification
QinetiQ are currently in the process of modernising and automating the monitoring of service and machine data using Splunk IT Service Intelligence. We are looking for an individual to provide Splunk Systems Engineering and Administration expertise, supporting the monitoring of QinetiQ's information and business services.

Key Accountabilities

• Internal and external point of contact for the opportunity on all technical/engineering aspects and assurance for Splunk
• Devising of solution concepts which capture the problem to be solved and/or essential features of the outline solution
• Engaging with customers, other stakeholders, suppliers, and other technical disciplines to help develop an appropriate understanding of the problem and to form the basis of viable solutions
• To contribution to the wider QinetiQ digital transformation strategy in Analytics, Military Intelligence and AI
• Point of escalation from the tier 2 support function for Splunk related issues
• Sharing of knowledge and experience
• Supporting of DevOps processes and promotion of Agile ways of working
• Applying security measures as required

Key Capabilities/Knowledge

• Administration of an Enterprise Level distributed Splunk implementation. i.e. Search Head and Indexer Clustering.
• Onboarding a wide data sources. need to be able to write your own TA’s for custom data feeds and make them CIM compliant as well as be confident in tweaking Splunkbase TA's.
• Splunk IT Service Intelligence Administration. Design and Creation of services and their associated KPI, alerts and correlation searches.
• Linux Centos/Redhat for Splunk Administration.
• General IT systems engineering design and implementation. Need to have a decent overall understanding of Enterprise IT systems. Networks, Platforms, Infrastructure.
• Ability to manage and resolve complex issues relating to Splunk capability.
• Able to communicate effectively, think creatively and working collaboratively with the wider IT Team.
• Strong core splunk skills. Searching, Reporting, Alerting, making dashboards etc.

Experience & Qualifications
• Security Clearance at a minimum of SC.
• ITIL v3.0 Framework Certificate or equivalent experience of an ITIL Service Management Implementation.
• Knowledge of ISO 27001.
• Working with adaptive thresholds, correlation searches, metrics and metrics analysis, alerting and such.
• Splunk Enterprise Security operation and management
• Business Systems Services and Requirements. I.e. non IT Data, not all pie charts are about hard drives.
• Experience in working in agile teams, DevOps environments and processes
• Automation processes, systems and tools like Ansible.
• Modern documentation practises.",3.6,"QinetiQ
3.6","Farnborough, Hampshire, South East England, England",-1,5001 to 10000 Employees,2001,Company - Public,Aerospace & Defense,Aerospace & Defense,$2 to $5 billion (USD),-1
Data Engineer,-1,"Infinity Works is a leading software, IT and Digital engineering consultancy which helps our clients solve hard technical problems in a wide variety of domains using a diverse set of technology stacks.

We’ve got some phenomenal customers working with exciting technologies, for example:
Apache Spark
AWS/GCP/Azure
Kubernetes
Snowflake
NoSQL databases
Kafka
Kinesis
Elasticsearch
Hadoop
Prometheus
Python
Node.JS
Java 8
Scala
We don’t expect you to have such a broad experience in all cases, but we love investing in our employees to enable them to grow into highly skilled engineers across multiple platforms & languages. We would expect the following as a minimum:
Python
Spark
Some AWS/GCP/Azure/Snowflake experience
Willingness to learn other languages and technologies
As a result, you will regularly be working with the latest technologies and tools and deploying to popular cloud platforms.

Requirements

Do you have the soul of an engineer; someone who’ll roll up their sleeves and focus on delivering high quality, end to end systems?

If you have commercial software engineering experience and a real passion for data but maybe haven't had the chance to tackle data problems at scale then we want you.

This is an excellent opportunity for you to get hands-on exposure with systems that cover the entire data lifecycle - from ingestion to machine learning and analytics.

It would be good if you have some of these:
Proven experience in one or more languages employed in data systems - e.g. Python, Scala, Java.
Comfortable working on client sites alongside engineers and data scientists.
Exposure to cloud platforms such as AWS, Azure, GCP.
Familiarity with relational and non relational databases.
Data pipeline technologies, eg: Apache Spark
Multi functional team working in a DevOps culture surrounded by lean / agile delivery methodologies.
Source code management systems such as Git, CI tools such as CircleCI or Jenkins, various testing methodologies.
These would be great too, but aren’t essential:
Understanding of machine learning principles and libraries.
Hands-on delivery of software systems across several industries.
MSc or PhD in computer science, data science or similar.
Exposure to streaming technologies such as Kafka, Kinesis, Spark Streaming, Flink.
Log management and monitoring solutions such as Elasticsearch, Splunk, Prometheus or similar.
Languages such as Javascript, Go, Bash.
Web technologies and frameworks such as Spring Boot, React or AngularJS.
Benefits

You begin life at Infinity Works as an engineer with an interest in data. The aim is to broaden your skills and become a technology polyglot, excited to learn new technologies and techniques across the full data life cycle.

Don't worry if you've never solved a large scale data problem in production. You will be pairing up with expert fellow engineers in order to accelerate your transition to a data engineer.

In time, you will also contribute to the evolution of the data practice within Infinity Works.

We believe that our team should be rewarded for their efforts, so we offer a great salary along with a number of things that are designed to make life just a little easier for you.
Competitive Salary
Cycle to Work Scheme
Death in Service
Childcare Vouchers
Financial Advice Service
Hiring Bonuses
My Work/Life Solutions Voucher Scheme
Northern Rail Pass Discount Scheme
Company Pension Scheme
Private Health Care",4.6,"Infinity Works
4.6","Edinburgh, Scotland",-1,201 to 500 Employees,2014,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Principal Engineer - Civils – Rail,-1,"Description

Principal Engineer - Civils – Rail

We currently have opportunities for talented Principal Civil Engineer to join the Rail team based in Warrington. This is a fantastic opportunity to join a dynamic and successful team that is growing rapidly. Successful candidates will be rewarded with a rich diet of interesting and challenging rail projects and an opportunity to develop their careers with a successful global engineering consultancy.

About Arcadis:

At Arcadis, we never lose sight of what’s most important. Because look beyond our projects and programmes and you’ll see it’s about human stories. From remaking public spaces that bring people together, to making cities easier to navigate, we’re focused on making an impact where it matters most – and improving quality of life.

It’s a big challenge. And why we need people committed to bringing their best, who deliver on their promises. People who value different perspectives, build sustainable relationships and dare to shape the future. People who seize the experiences available to transform their world – and the world around them.

It’s a shared goal amongst 27,000 Arcadians. And one we can only achieve by working together and applying our skills and expertise across design, consultancy, engineering, project and management services. It’s how we’ll find solutions to our clients’ most complex challenges. And how we’ll deliver exceptional results, today and tomorrow.

About The Team:

Our UK Rail Team continues to add to their impressive list of project awards and recent successes have seen them secure some of the UK’s most high profile, complex and stimulating projects to complement their existing portfolio of works on programmes including Northern and Central Programmes, HS2, Crossrail and renewals and enhancement schemes across Network Rail Routes.

Representing approximately 16% of our global business, the railway sector is one of Arcadis core markets, a position it has held throughout our 150-year history. We have an enviable reputation for delivery of some of the UK’s, and indeed the World’s, most prestigious and challenging schemes.

We have been involved in all major rail programmes since the 1980s including the Jubilee Line Extension, West Coast Main Line, Thameslink, Crossrail, IEP, HS1, Northern Hub, HS2, and Euston Redevelopment.

Requirements:

Reporting to the Team Leader or Associate Director as a Principal Engineer you will provide design delivery on a variety of civils led multi-disciplinary projects within the rail environment. As we operate in such a diverse marketplace, you will gain an experience of working on a wide and varied portfolio of projects which will enhance your skills and test your technical knowledge.

You will be a key technical team member in the Warrington Rail Civils design team, responsible for and involved the delivery of project-related tasks to meet budget, time-frame and quality targets, meeting or exceeding client expectations, promoting and marketing all facets of Arcadis services during interfaces with clients and other sectors and disciplines, contributing towards the achievement of the divisional business plan and to build networks within the industry.

We will ensure that we offer personal development which will allow you to progress your career and offer you the opportunity to be mentored by industry recognised Technical Leaders in their field who will lend you their experience and ensure that the training you receive will give you the best possible chance of success.

Essential Experience:

You will have a gained substantial civil / structural design experience ideally including some within the rail sector and in a consultancy environment

Have previous relevant experience including supervision of elements of large, complex projects

Chartered Engineer status with ICE or IStructE (or close to achieving)

Experience preparing design deliverables using civil engineering design software packages

You will be an Innovative thinker, a team player, proactive and delivery focused

An aptitude for Building Information Modelling and the workflow associated with projects delivered in a Common Data Environment

You will possess the enthusiasm to tackle stretch tasks

You will be flexible to travel throughout the UK on occasion

Excellent written and verbal communication skills with proven planning and organisation skills

Manage engineering activities that contribute to sustainable development

Good IT skills including Microsoft Office applications

Duties & Responsibilities:

Responsibilities of this role include, but are not limited to:

Developing skills and knowledge base in both the technical and management streams

Leading and assisting with the preparation of documentation relating to projects

Designing in 3D modelling environments such as AECOSim, Revit and Civil 3D

Preparing design calculations, drawings, specifications, reports and other project documentation as required in line with company and client requirements as well as national standards and codes of practice

Taking a lead role in the resolution of technical issues

Supervision and technical development of junior engineering team members
Attending site and taking a lead role in the completion of surveys in a rail environment

Gaining experience and proficiency in Arcadis systems and procedures
Becoming familiar with, and compliant with, relevant Health, Safety and Welfare regulations and to promote a culture of awareness within the team
Building relationships with Clients on projects

Performing other duties and responsibilities as required from time to time by your manager or Arcadis

Opportunity to work under mentorship to develop and undertake CRE responsibilities on Rail projects

Why Arcadis?

At Arcadis, you’ll have the opportunity to build the career that’s right for you. Because each Arcadian has their own motivations, their own career goals. And, as a ‘people ﬁrst’ business, it’s why we’ll take the time to listen, to understand what you want from your time here, and provide the support you need to achieve your ambitions.

Wherever you join us, you can look forward to a competitive reward package that includes an attractive starting salary, opportunities for career development and being part of a sociable community. We have a performance-related bonus scheme and an employee recognition scheme. Other beneﬁts include membership fees to join your relevant professional body, employer contribution pension scheme, ﬂexible working and a flexible holiday scheme.

We believe that by working together diverse people with different experiences develop the most innovative ideas. Equality, diversity and inclusion is at the heart of how we improve quality of life and we work closely with our people across six ED&I Workstreams: Age, Disability, Faith, Gender, LGBT+ and Race. A diverse and skilled workforce is essential to our success.

Qualifications

Minimum Academic Qualifications:

Master’s degree in civil engineering

Achieved or very close to achieving Chartered or Incorporated Engineer professional status, or equivalent",3.9,"Arcadis
3.9","Warrington, North West England, England",-1,1001 to 5000 Employees,-1,Company - Public,Construction,"Construction, Repair & Maintenance",Unknown / Non-Applicable,-1
Software Engineer,-1,"Business Unit:
Cubic Transportation Systems
Company Details:
Cubic offers an opportunity to provide innovative technology for government and commercial customers around the globe, helping to solve their future problems today. We’re the leading integrator of payment and information technology and services for intelligent travel solutions worldwide, and the leading provider of realistic combat training systems, secure communications and networking and highly specialized support services for military and security forces of the U.S. and allied nations. If you have an entrepreneurial spirit and thrive in an innovative environment, we want to talk to you about your next role at Cubic! We are seeking employees inspired by technology, and motivated by the rewards of hard work, commitment, teamwork, quality, integrity, and respect. We invite you to explore opportunities with Cubic.
Job Details:


Job Summary:

Conceptualise, designs, codes, debugs and performs development activities in accordance with designated standards and procedures to meet specific project requirements.

Essential Job Duties and Responsibilities:
Using the current programming languages and technologies provide creative, thorough and practical solutions to a wide range of technical problems.
Analyse and contribute to system and subsystem requirements specifications and design definitions.
Design, develop and test applications and programs to support the company’s products.
Design, develop and test software programs following established quality standards and in accordance with internal engineering procedures including coding, unit testing, peer reviews and software configuration control.
Complete high and low level detailed software design specifications, storyboards and interface specifications.
Provide support of products through conception to product delivery including problem solving, defect maintenance and support to customer services (which may require out of hours support in certain circumstances).
Keeps abreast of improvements and developments within software engineering, supporting continuous improvement within engineering.
Comply with Cubic’s values and adherence to all company policies and procedures. In particular, comply with the code of conduct, quality, security and occupational health, safety and environmental policies and procedures.
In addition to the duties and responsibilities listed, the job holder is required to perform other duties assigned by their manager from time-to-time, as may be reasonably required of them.
Minimum Job Requirements:

Education and Qualifications

Essential:
Bachelor of Science degree in computer science, electrical engineering, or related field or equivalent professional experience or combination of both.
Desirable:
Master’s Degree in computer science or related discipline or equivalent qualification/experience.
Certification in a relevant programming language or framework.
Certified Scrum Master.
Skills, Knowledge and Experience

Essential:
Experience in Software Engineering with a proven track record of specification, design and development.
Demonstrable experience of defining test plans and test data requirements.
An effective problem solver with the ability to understand and resolve complex issues.
Experience in troubleshooting and debugging applications.
Experience of Object Oriented Design (e.g. UML) and implementation, along with Design patterns.
Ability to contribute to the development of the architecture for applications.
Able to build reusable code and libraries, ensuring thorough application documentation for future use.
Experience of software best practices such as Automated Testing (Google Test and VSTest), Continuous Integration, Test Driven Development, SOLID and Clean Code principles.
Scrum or Kanban experience.
GIT and Jenkins experience.
Experience working with test teams to optimise application performance.
Desirable:
Previous experience of CTSL products/industry or similar is desirable.
Desirable to have BitBucket and Conan experience.
Desirable to have DOORS, Test Rail and JIRA experience.
C++ Embedded development experience requirements:
C++ experience.
Delivered highly functional, performance-driven, user-friendly applications.
Client-side development experience.
Experience in developing multi-threaded applications.
Experience with REST, JSON & web services.
Experience using a crash reporting solution.
Experience of debugging on target hardware.
One of the following mandatory platform skills:
Win32/64 developers need
Skills in Visual Studio 2015 or greater.
Win32/64 specific UI / UX concepts should be understood.
An understanding of the nuances of the MS Windows platform.
Familiarity with using patching / installers.
Linux developers need
Skills in CLion or Eclipse.
Linux-specific UI / UX concepts should be understood.
An understanding of the nuances of the Linux (Ubuntu) platform.
Familiarity with using RPM / installers.
Desirable:
Experience in developing in other high-level languages, such as C#, Java, Python, JavaScript, PPP, and XML.
Experience with Valgrind.
Efficient memory management experience.
Efficient usage of disk IO experience.
Cryptography.
Low-level smart card comms/NFC interfacing.
Experience writing simulators and test harnesses.
The description provided above is not intended to be an exhaustive list of all job duties, responsibilities and requirements. Duties, responsibilities and requirements may change over time and according to business need.

Worker Type:
Employee",3.2,"Cubic
3.2","Stockton-on-Tees, England",-1,5001 to 10000 Employees,1951,Company - Public,Aerospace & Defense,Aerospace & Defense,$1 to $2 billion (USD),-1
Graduate Software Engineer - 2021 Intake,-1,"We are offering you the chance to be part of something amazing. We use innovation, partnerships, and our 60 years of experience to offer our clients exceptional advice, research and development. Every day, our people use their passion, skills and intelligence to make the world a safer place. Why not join us?

What will your role look like?
Roke develops and delivers all kinds of software systems to a broad range of customers. Software engineers at Roke have opportunities to work on everything from early research to mission-critical software. We develop, publish and contribute to open-source software and provide key commercial and sovereign capabilities for our clients.

Early career professionals at Roke get the opportunity to apply themselves across a broad range of projects. Roke’s teams carefully choose the most effective tools for each development and as such we are always learning new tools, frameworks, approaches and sometimes languages. We build teams that can adapt to solve our customers’ evolving challenges and rarely solve the same problem twice.

We write fast software, some low level, some massively scaled. We write software to assure and test and we build sophisticated DevOps setups to apply the rigor and regularity that we and our customers expect. We write smart mobile apps, polished web front-ends and visualise complex concepts and data simply. Sometimes we carefully and slowly develop our software, sometimes speed saves lives and customers want something to try tomorrow. Amongst these areas and Roke’s other expert fields there’s space to grow expertise and develop your passions.

A software engineer at Roke has a wide range of places to apply themselves and always new things to learn. We often work in teams and apply Agile methodologies. You can take opportunities to lead teams, customer engagements and own technical solutions. We work together to solve challenges and learn from the experience and insight of others. Some technologies we like at the moment…

Python, Java, C, C++, JavaScript, Go, Rust, C#, Kotlin, Swift…
Linux, Android, Docker, Ansible, Kubernetes, Vagrant, Terraform, GitLab, AWS, Vue, React, Node, Django, Flask, Spring...

What does our Graduate Development Programme look like?
At Roke we recruit some of the best talent the country has to offer. We provide the building blocks necessary for successful integration into the business, as well as the ongoing support to enable our graduate community to fulfil their undoubted potential. That’s why we’ve created a programme that will accelerate individual learning and development while delivering real business value by giving you the time, trust and freedom to take control of your career. This emphasis on experiential learning is supported through initiatives including:
A mixture of technical and soft skill training in order to provide you with the skills you need to thrive
Regular access to senior leaders
Opportunities to attend external exhibitions/conferences in order to broaden industry knowledge
We have a wide range of opportunities in this area so your role will vary depending on your existing experience, our customer needs and your aspirations.
What do we expect from you?
Roke is looking for staff enthusiastic about developing software. One way in part to evidence that is an honours degree in a relevant subject. A demonstrable passion for making good software
An ability to pick up new tools, frameworks and languages fast
An ability to analyse problems and communicate well thought through solutions
An ability to develop new solutions where no pre-existing solution fits
A willingness and capability to work as part of a team
What additional skills would be useful?
An awareness and experience of working with open-source software
A familiarity with Linux
Where will you be based?
Your work will typically be located at Roke's sites in either Romsey or Gloucester, with some travel to customer sites and the possibility for you to work on secondment with one of our prestigious customers.
The benefits of working for us include:
A highly competitive salary, pension and flexible benefits.
A substantial performance related bonus scheme.
25 days annual leave, which can be supplemented up to a further 8 days by Roke’s flexi-leave scheme.
A generous relocation allowance to help you settle into the local area and your new role.
Onsite tennis courts, gym (Romsey only) including showers & changing facilities, and fishing rights on the River Test.
Numerous company events throughout the year, including a summer music festival, bonfire night fireworks and Christmas party.
Employee led clubs covering numerous sports (including football, climbing, sailing, etc.), cyber security, data science, robotics, gaming, and more.
Diversity and Inclusion
Roke relies on strength that comes from the diverse backgrounds and perspectives of our staff. We all have a responsibility to create an environment where we have the freedom, support and trust to succeed– where we are encouraged to bring our whole self to work. Diversity and Inclusion makes life at Roke enjoyable, as you find yourself integrated in teams made up of a variety of people with ranging backgrounds and experiences. This enables you to interact and connect with individuals, and gather differing perspectives and knowledge that broadens your horizons as a graduate.

Security
Due to the nature of this position, we require you to be eligible to achieve SC and/or DV clearance. As a result, you should be a British Citizen and have resided in the UK for the last 5 years.
We are committed to a policy of Equal Opportunity, Diversity and Inclusion. Our working environment is friendly, creative and inclusive. We will consider flexible working arrangements, and support a diverse work-force and those with additional needs.",3.9,"Roke Manor
3.9","Gloucester, England",-1,201 to 500 Employees,1956,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"G-Research is Europe’s leading quantitative finance research firm. We hire the brightest minds in the world to tackle some of the biggest questions in finance. We pair this expertise with machine learning, big data, and some of the most advanced technology available to predict movements in financial markets.

The role

The Research Data team at G-Research is looking for a talented Data Engineer to join them. The team is responsible for processing and modelling vendor data and making this available in a standardised format for research and trading. The datasets range from simple CSV files to complex hierarchical formats, covering subjects as diverse as analyst tips and weather forecasts. We aim to provide the tools and services to access this data and ensure data quality and consistency.

This role involves collaborating closely with other teams across the business to deliver outstanding data resources and end-to-end design and implementation. Key technologies used in this role include: SQL Server, PostgreSQL, Cassandra, Spark, Kubernetes, Kotlin, Java, Scala, C#, .NET Core

The platform that the firm provides is used 24 hours a day, and all engineers in the group have a responsibility to support production issues encountered in the data processing. This will include a share of overnight calls from within the firm.

Key responsibilities of the role include:
Designing and implementing high-quality code to process and manipulate large datasets
Building cutting-edge tools and infrastructure supporting core facilities in the firm
Strong data management skills
Advising cross-team initiatives
Assessing frontier technologies
Occasional full stack engineering (despite the team being primarily backend focussed)
Optimising data storage and modelling
Responding to the ever-changing requirements of the business.
Who are we looking for?

The ideal candidate will have:
A demonstrable understanding of database design and use, or other data management techniques (both relational and non-relational)
A proven ability to engineer high-quality software
An appreciation of good software architecture, Comp Science fundamentals and data structures
Experience with micro-services and distributed systems
Experience of TDD and the ability to write clean code
Experience of agile methodologies and a familiarity with retrospectives and continuous improvement processes
A demonstrable desire to stay informed on the latest technologies and practices.
A keen interest in applying continuous delivery principles
Financial experience may be useful but is not required. Candidates from non-financial backgrounds are encouraged to apply.

Why should you apply?
Highly competitive compensation plus annual discretionary bonus
Informal dress code and excellent work/life balance
Comprehensive healthcare and life assurance
25 days holiday
9% company pension contributions
Cycle-to-work scheme
Subsidised gym membership
Monthly company events
Central London office close to 5 stations and 6 tube lines",4.8,"G-Research
4.8","London, England",-1,501 to 1000 Employees,2001,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Statistical Analysis Process Engineer,-1,"Life Changing**. Anything is Possible with the Right Approach…*
About Us*
Creo’s mission is to improve patient outcomes in the emerging field of surgical endoscopy, *a ground-breaking discovery* in minimally invasive surgery.

Our goal is to experience improved patient outcomes by applying advanced energy to surgical endoscopy. We started our journey in 2003 by the pioneer Professor Chris Hancock, initially to target the treatment of cancers through use of high frequency microwave energy and dynamic matching techniques.
Scalable Business Model*
Our pioneering CROMA Advanced Energy Platform is designed to be scaled via the ‘razorblade mode’ with a suite of single use devices that deliver superior outcomes for physicians and patients. Combined with our range of patented electrosurgical devices, CROMA is designed to provide clinicians with flexible, accurate and controlled clinical solutions, delivering a combination of bi-polar radiofrequency and microwave energy for a range of surgical effects through a single accessory port. This advanced energy, enables single use, surgical accessories to be optimised for the dissection, resection, haemostasis and ablation of tissue in multiple areas of therapy. Having received FDA clearance and CE marking for many of these, we are progressing in treating patients in many parts of the world already.

Our devices are designed to enhance existing techniques and provide effective new therapies in high-value segments of large and growing global markets.
Consistently Winning Innovation Awards and Rich in Product Pipeline & IP*
To recognise our achievements so far, we have been consistently winning Innovation and Angel Investment Awards and boast an extensive portfolio of patents - 188 granted and 599 pending. Since December 2016, we have been publicly trading on the AIM market of the London Stock Exchange. To learn more as well as understanding our history, check us out at www.creomedical.com.
Anything is possible with the right approach*
As a talented team with diverse backgrounds, we have a depth of expertise across all areas of the business. We succeed through applying our ‘can-do’ attitude to innovate so that we can satisfy our hunger for solutions!

Engagement and collaboration are key to our business success and to continually innovate and exchange ideas and knowledge in an open, encouraging and developmental environment whilst we challenge the status quo.
Being part of our team will mean making a real difference globally.*
Over recent times, the team at Creo has expanded significantly to introduce additional experience into the design, manufacture, production and commercialisation of electrosurgical medical devices. As such, we have developed an electrosurgical platform and are developing a pipeline of medical devices which we plan to launch commercially.
The Opportunity: *
We have many opportunities for those wanting to join our team. Opportunities to be part of this extraordinary journey as we continue our growth, innovation and commercialisation. Please visit our website for a full list of opportunities and feel free to spread the word!
Right now, we are looking for a Statistical Analysis Process Engineer to join our team.*
Key tasks for this role are:
*Excellent understanding of ISO 16269-6 2005 Statistical interpretation of data*
*Capability analysis and interpretation of supplier data*
*Statistical analysis (experienced with use of Minitab)*
*Analytical methods and how its applied to associated risk/reward*
*Understanding of IQ/OQ/PPQ of jigs and fixtures*
*Understanding of development of manufacturing jigs and fixtures, poke yoke design*
*Understanding of statistical process control (SPC)*
Test method qualification (TMQ)
Design of experiment (DOE)
Manufacturing of devices containing small parts and low volume manufacturing
Ensure the impact of design and process changes are fully assessed using engineering acumen and relevant change control procedures
Protocol generation
Report writing
Identify process problems and non-conformances in manufacturing processes and develop corrective actions
Implement GMP (Good Manufacturing Practice)
Coordinate the training of manufacturing operators at supplier if required
Support internal audits and work under ISO 13485
Review procedures for accuracy and make updates using a Document Change Order procedure to reflect process changes, and develop production procedures, standard operating procedures testing and inspection and drawings
Drive continuous and process improvements
Project management
Some of the aspects we look for in our team members includes:
*Degree qualified or equivalent skills from a mechanical, electronic, manufacturing, product engineering-based discipline*
*Highly experienced working within a Quality Management System ISO 13485 *
*Excellent process validation and verification expertise including IQ/OQ/PQ DOE and TMQs*
*Understanding of risk analysis documentation, DFMEA & Risk analysis*
First class engineering standards
Excellent engineering and root cause analysis problems solving skills (demonstrable use of the full range of problem-solving tools) with an ability to trouble shoot mechanical, electrical and electronics designs
An ability to multi-task and work under pressure to meet tight deadlines
Experience of working with external tooling companies
Experience with DFM
Ability to work under pressure
Can do attitude
We Can Offer: *
A flexible, *inspiring*, and fun work environment. We thrive as a ‘can-do’ and empowered culture
*Working at our Chepstow office, with flexibility for home working* (dependant on the task at hand!)
Our time and investment for your development, to *achieve your goals*
*Competitive salary and perks*
Opportunities to work with *exceptionally experienced* and advanced research institutions, companies and individuals
The opportunity to be part of, develop, explore, and discover *technology that aims to improve the lives of many *
Social events – whether pub lunches or team building activities. The social aspect of our *team culture* is high on our agenda
Supporting and helping everyone on their own journey as well as the journey we are collectively on is a very important part of our culture. Everyone, is *expected to muck-in* and do their best to help themselves and each other. This is expected regardless of experience, qualifications and especially seniority.

Now we’d like to know more about you. Please apply with a CV and also a covering letter that covers:
*Your values*
*Your contributions, and achievements (whether team or individually based), and; *
*How you see yourself working with our incredible team*
Job Types: Full-time, Permanent

Benefits:
Company Pension
Life Insurance
On-site Parking",-1,Creo Medical Ltd,"Chepstow, Wales",-1,-1,-1,-1,-1,-1,-1,-1
"Senior Specialist, Data Engineer",-1,"Role Purpose

This position needs someone with energy and enthusiasm to complement our existing development team to accelerate our delivery of our data lake solution.

In this role you must have a growth mind-set with a desire to deliver high quality output for yourself and the team and challenge the status quo.

The ability to hit the deck running and add value quickly will be crucial.

Will require development, OOH support and bug fixing on our new SAAS platform offering as part of the wider NewDay Data platform.

Key Accountabilities
Hands on development on Data Lake build and change
Responsible for the code quality and simplicity in the system and leading the enforcement of quality within the data landscape
Working with the team within an Agile framework using the industry best practice agile methodology tooling that controls our development and CI/CD release processes
Building knowledge of all data resources within ND and prototype new data sources internally and externally
Contributing to the new Data Lake technology across the organisation to address a broad set of use cases across data science and data warehousing
Skills and Experience

ESSENTIAL
Proficiency in Big Data data integration technologies such as Spark, Scala, Kafka
Excellent Scala/Java engineer with knowledge of and experience with container frameworks
Excellent API and library design skills
Proficiency with traditional database SQL technologies (Oracle, SQL Server, DB2)
Experience with integration of data from multiple data sources
Writing high-performance, reliable and maintainable code.
Analytical and problem solving skills, applied to Big Data domain
Experience of CI/CD best practice
Good aptitude in multi-threading and concurrency concepts
Experience with cloud deployment
Familiarity with the fundamentals of Linux scripting language
DESIRABLE
Previous proficiency with ETL technologies (e.g. Talend, Informatica, Abinitio)
Previous exposure to Python and Cython
Exposure to building applications for a cloud environment
Knowledge of workflow/schedulers like Yarn & Oozie.
Experience with NoSQL databases, such as HBase, Cassandra, MongoDB
Experience with various messaging systems, such as Kafka or RabbitMQ
Good knowledge in back-end programming, such as HTML, python, java, C, C++, JS, Node.js and OOA
Personal Attributes
Loves to code, and relentless about code quality.
Structured, organised, process driven and outcome oriented
Personable, credible, with good communication skills
Excellent interpersonal & written communication skills. Ability to present ideas in business-friendly language
Self-motivated, able to work in a high-pressure environment
Strong organizational, planning and time management skills
Ability to build strong and effective working relationships on an ongoing basis
Ability to embrace company culture and embed into day-to-day interactions
Passionate, keen and energetic with demonstrable enthusiasm and commitment.
Pragmatism in design decisions",3.1,"NewDay
3.1","London, England",-1,1001 to 5000 Employees,2011,Company - Private,Lending,Finance,Unknown / Non-Applicable,-1
Data Control Engineer,-1,"My client has an exciting opportunity for a Data Control Engineer to join their Regional team to work at the site Offices near Newcastle-under-Lyme, Staffordshire.

Role Purpose:To liaise daily with subcontractors and the site engineers recording all progress information on the appropriate trackers and providing site management with live information to enable progress to be captured accurately.

What you'll be doing:

As a Data Control Engineer you will:

Ensure a relentless focus on Zero Harm
Support the delivery of CSUKs Sustainability activities
Health Safety & Environmental- Carry out associated briefings
Carry out Safety Inspections
Hazard Identification and contribution to development of Safe System of Work
Engineering Control- Read and determine information from drawings, schedules and specification
Quality- Record as-built information
Maintain accurate records Daily Diary, records of site discussions.
Productivity- Collect data for Key Performance Indicators, including reasons for difference
Record outputs by subcontractors
Provide information to others, ie Planner.

Commercial:

Provide accurate daily diary of resources, including labour, plant, materials, subcontractors and outputs.

Who we're looking for:

Able to clearly communicate accurately with people at various levels
Capable of taking ownership of tasks and communicating outcomes
Strong work ethic with flexibility in the hours work
Able to work on own initiative and seek out opportunities in line with level of responsibility
Holds a current UK driving license
Must be a good team player, with strong communication and interpersonal skills.
CSCS card and Environmental awareness
Able to report issues with information provided
Able to capture data across their section in various trackers
Quality-Reads and understands drawings and schedules
Awareness and use of Specification and other Contract documents
Able to produce detailed documentation for handover of completed works
Maintain a good accurate daily diary
Able to accurately monitor production using excel-based trackers
Analyse and compare data quickly and produce a weekly report highlighting keep points
Knowledge of specification and contract documents
Understands what constitutes additional works

What you'll get:

Competitive basic salary and Car

Long-term career and support

Strong opportunity to grow your career

Click apply now!",4.5,"PSR Solutions
4.5",England,-1,51 to 200 Employees,2005,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer - Remote - £450-£500/Day Inside IR35,-1,"Data Engineer - Remote - £450-£500/Day Inside IR35

We are seeking a Data Engineer for our Government client. This is an initial contract running until March 2021, paying between £450 - £500/Day Inside IR35. This role is home based.

This role is inside IR35 - Due to the service of the role this will now be based on an Umbrella solution.

Please note, this role is shift based Working five days out of seven days covering various working patterns between 8am and 6pm. Shifts are 8am-4pm and 10am - 6pm.

Role Profile:

Experience of using SAS ViYA Products and Solutions including Data Interrogation Studio and SAS Enterprise Guide to deliver data solutions in accordance with agreed organizational standards that ensure services are resilient, scalable and future proof.
Experience of working on a large scale Programme to deliver data solutions. Understands core technical concepts related to their role and is able to apply them with guidance.
Designs, builds and tests data products based on feeds from multiple systems using a range of different storage technologies and/or access methods. Creates repeatable and reusable products
Delivers data solutions in accordance with agreed organisational standards that ensure services are resilient, scalable and future-proof
Understands the concepts and principles of data modelling and is able to produce, maintain and update relevant data models for specific business needs. Reverse engineers data models from a live system
Designs, codes, tests, corrects and documents simple programs or scripts under the direction of others
Experience of working in HMRC or another Government department in a Data Engineering role (Desirable)

Do not call - Click the ""Apply Now"" button now for immediate review

Data Engineer, Data Consultant, Data Lead, Data Manager, Data, Engineer, SAS, SAS ViYA, Data Interrogation Studio, Data Interrogation, Data, Government, Design, ViYA

Circle Recruitment is acting as an Employment Agency in relation to this vacancy. Earn yourself a referral bonus if you refer somebody else who fills the role! We also offer an iPad if you refer a new client to us and we recruit for them. Follow us on Facebook - Circle Recruitment , Twitter - @Circle_Rec and LinkedIn - Circle Recruitment.",5.0,"Circle Recruitment
5.0","London, England",-1,1 to 50 Employees,2003,Company - Private,-1,-1,Less than $1 million (USD),-1
Senior Data Engineer,-1,"Senior Data Engineer – Manchester*
SearchDATA Group have partnered with an Analytics Consultancy in their search for a Senior Data Engineer. Due to natural progressions within the business and the previous incumbent now holding the role of CTO, we’re now looking to add to the data engineering team with a SQL expert.

Our client has an excellent reputation for providing first class analytics services catering for the healthcare sector, allowing healthcare providers to solve complex challenges and deliver data driven software solutions.
The Role *
Due to the complex nature of the healthcare sector and the masses of data held in disparate systems, we’re looking for an expert to build data pipelines for Data Science teams as well as an internally developed analytics software solution.

Healthcare experience is a must, as the industry experience will be invaluable on client projects. Technical skills are flexible as our client are always keen to adopt new technologies, and as long as the fundamentals are there, the technical skills can be learned.
Responsibilities*
Work on database development, data integration and ingestion
Build accessible data for analysis
Clean-up, transform and normalise data so that it is trusted and easily used for analysis as well as consuming applications
Integrating data from different sources
Develop high quality, reusable data pipelines
Develop and maintain ETL processes in accordance with designs, standards and processes
Conduct data analysis to validate results of ETL and other batch processes that manipulate data
Essential Experience *
Development experience in ETL tools
Strong knowledge of SQL
Strong knowledge of a variety of database solutions
Confident in working with large data sets
Experience working within the Healthcare sector
Desirable Experience *
Creation and management of Cloud based data environments (AWS / Azure)
Knowledge of open source data solutions i.e. MySQL
Reference ID: SDG-BS-1408

Job Types: Full-time, Permanent

Salary: £50,000.00-£60,000.00 per year

Benefits:
Company pension
Flexible schedule
Work from home
Schedule:
Monday to Friday
Experience:
Healthcare Industry: 1 year (Preferred)
Work remotely:
Temporarily due to COVID-19",-1,SearchDATA Group,"Manchester, England",-1,-1,-1,-1,-1,-1,-1,-1
Analytics Data Engineer,-1,"ANALYTICS DATA ENGINEER

Curious about a position with MHR? You've come to the right place. MHR has been changing the industry for years, and now you can too.

MHR offers HR, Payroll and Analytical expertise to help our customers work smarter. Our strength is in the development of our own technology based upon the market and future trends to ensure our customers have solutions that fit their needs today and grow with them in the future.

Today we're powered by a world-class team of over 700 people working with us across four products, a multitude of services and three continents. We’re driven by organic growth, a significant achievement in our industry. We pride ourselves on being a financially independent family-owned company on a journey to completely transform the world of work for organisations of all shapes and sizes. We have over 1,000 customers, serving organisations across the public, private and non-profit sectors.

Our mission is to constantly strive to understand and improve the world of work, technology and people, enabling us to create market-leading platforms and services and we'll need creative individuals like you to help continue this success.

Our philosophy for the last 35 years and moving forward remains resolute - one vision, one strategy - one MHR.

Want to be part of something incredible? #OneMHR

Role Responsibilities

Due to continued growth, MHR Analytics are recruiting for an Analytics Data Engineer, who is experienced in data modelling principles; to plan, develop, implement and maintain Analytics solutions and services across the MHR customer base.

Core Skillset should be able to demonstrate:
Depth in data modelling and database design
Conversed in established and emerging data technologies
Core areas of BI development will consist of the following technology stack and disciplines;
Breadth in Enterprise Data warehousing and working with Data lakes in current technologies
Fully conversed in software project management approaches, requirements, design and test techniques
SQL Development, database administration
Columnar and NoSQL database expertise
Working with Structured/Unstructured big data sets
Experience in predictive modelling and AI technologies (e.g. SAP Predictive analytics/ Cognos Watson Analytics/ SAAS/ Azure ML/ R)
Experience in platform development and services (SAP Cloud Platform, Microsoft Azure)
Knowledge of SAP/ Microsoft BI and visualization technologies (SAP Business Objects, PowerBI)
Meta Data and Multi-Dimensional Design
SAP Business Objects Enterprise/Edge/Suite, including Crystal Reports, Dashboards (Xcelcius), Design Studio
Microsoft BI stack, including PowerBI, SSIS, SSAS
Experience in Apache Airflow and other modern pipeline/Orchestration tools advantageous
Experience in working with MS Azure Beneficial
Multiple Sector Experience (Particularly HR/Payroll)
Key Skills

Database Architecture
SQL
SSIS
SAP Data Services
SAP Business Objects
Open Source ETL (e.g. Airflow)
Data Warehousing Methodology
Microsoft Azure
Python
Microsoft Analytics (PowerBI, SAAS)
Capturing and defining business requirements
Stakeholder management
Change management & version control
Take design concepts to Commercial propositions
Internal and External customer presentations
Our Rewards
Market competitive salaries.
We contribute to a full company pension scheme to help you plan for your future.
We offer life assurance (x4 salary, with option to increase up to x8 salary).
An employee assistance programme is included.
Our sites all come with a subsidised restaurant and cafe on-site, with delicious new meals on offer from our chefs each day.
We offer Vodafone discounts, making it cheaper and easier to catch up with your favourite people.
Personal development plays a big part in helping our people to reach their potential, this is why we offer over 60 internal training courses and support our people with external qualifications.
Why us?
What makes MHR a great place to work, isn’t novelties or gimmicky job titles, it’s our down to earth approach working with people who want to do a job they’re proud of.
We invest for the long term, providing fantastic careers for our people and the best software and services to meet the needs of our customers now and in the future.
With over 35 years’ experience in the industry, our ethos has been to keep investing and moving forward with the changing world of work, and we can only do that by supporting our people. We’ve invested £20 million in a huge building expansion project to provide the best environment for our people, to give them the space they need to excel and grow. And by investing 20% of our turnover into our own research and development, our people shape the future of our products and services to support changing requirements on both a local and global scale.
We’re flexible, we embrace change and as we’re still owned by the original founders. We’re incredibly proud of what we we’ve built, evolving from a small business into one of the biggest and best in the industry.
Be part of something special, become part of the MHR family.

Apply here!",3.7,"MHR
3.7",Remote,-1,501 to 1000 Employees,1984,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Software Engineer (Python),-1,"Novastone builds next generation instant messaging solutions for businesses with high-value client relationships.*
We believe the future of business communication is instant and context-rich conversations, wherever you may be. We empower organisations to manage client relationships on IM platforms like WhatsApp and WeChat, while remaining in control and compliant. Our secure instant messaging platform is designed to deliver high-touch, personalised client experiences through sales and account management teams, particularly suited for industries such as financial services, healthcare, and legal. Our clients include some of the best known global brands in these verticals.

We have mobile and web clients, along with a robust set of APIs for integration. We support white labelling of official IM accounts. We have made great strides towards becoming a cloud-native (AWS) company and now our clients benefit from scalability at ease through our managed multi-tenanted infrastructure, or private hosting.

We are headquartered in London and have an engineering team based in Belfast.
Team and role*
As a Python engineer at Novastone, you’ll be working on the backend team. You’ll help us implement new features, integrate with other platforms, move to microservices and pay back technical debt. You’ll propose solutions that meet product and engineering requirements and design, build, and support them. You’ll work closely with colleagues in our Belfast and London offices and actively contribute to our product direction and roadmap. We follow a mature Kanban implementation, utilise Extreme Programming techniques, and our technology stack includes Python, AWS, Terraform, Serverless, Docker, Git and Jenkins.
You will*
Work closely with the product, mobile, web and infrastructure teams to build RESTful APIs for new features and integrations with other collaboration platforms
Help us continue our move to microservices
Follow cloud-native patterns to deliver cost-effective, scalable and secure services
Be prepared to try new ways of working and solving problems, challenging yourself and fellow colleagues, and embracing failure and the opportunity to learn from it
Pair up across all teams to design, review, build and maintain new product features
Love discovering and learning new things through research and training, and sharing those learnings personally or presenting in sessions to colleagues
Write high-quality automated tests, preferably following TDD
Be passionate about improving the status quo but think iteratively about how to do so
Dig into existing solutions to understand how they work
Lead technical design reviews to elicit feedback from other engineers
You should have experience in*
Python! Specifically, using it to build cloud-native and RESTful services that are scalable, secure and resilient
Writing all kinds of automated tests and TDD
Other extreme programming techniques like pair programming and trunk-based development
Integrating distributed services and considering how your decisions impact platform availability and data consistency
Building, improving and maintaining CI/CD pipelines
Leveraging services provided by AWS and others so that you don’t reinvent the wheel
Implementing serverless solutions
Iteratively improving the design of existing code
Contributing in design reviews and retros
We offer*
A competitive salary with stock options
A modern laptop, a relaxed working environment with dedicated working hours and agreements, and management that are approachable and open
A remote working policy
Training budget & dedicated time to do it
A monthly lab day (hack-day), weekly demos, lightning talks, and regular knowledge-sharing sessions
An open and inclusive team environment
Our primary office locations are London and Belfast
Job Types: Full-time, Permanent

Schedule:
Monday to Friday
Experience:
software engineering: 2 years (Required)
Python: 1 year (Required)
Work remotely:
Temporarily due to COVID-19",4.4,"Novastone
4.4","Belfast, Northern Ireland",-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Lead Software Engineer Node JS,-1,"Lead Software Engineer – Node.js - We will consider this role to be worked remotely for the right person!*
At MRP we know it’s crucial that our people reflect the diversity of our customers from around the world. And we know that having people from all walks of life makes us a more creative and innovative company. That variety of experience, culture and background allows our teams to truly drive innovation and create a great experience for both our people and our customers. MRP is a place where we value Diversity & Inclusion and we work really hard to be a great place to work, for everyone.
Title: * Lead Software Engineer – Node.js
Location: * Belfast \*open to remote location
Engagement: * Full-time
MRP is a leading provider of predictive analytics software and account-based marketing services. Positioned for yet another year of growth, we are looking for a Back-End developer to join our Belfast development team.
Company Overview: *
Founded as a company focused on providing net new sales opportunities for marketing and sales teams, MRP has evolved into a leading global predictive intelligence organization, providing fully integrated, end to end, account-based marketing services. For over 16 years, clients have relied on MRP to help them achieve their revenue goals by combining cutting-edge predictive analytics with a full suite of account-based marketing services to acquire new customers.
The role: *
• You will be working as part of the team responsible for MRP Prelytix. An enterprise class predictive ABM platform that drives higher response rates, pipelines conversions and pipelines values by enhancing sales and marketing execution with predictive analytics and intelligence.

• You will report to our back-end engineering Team Lead and will work closely with our teams in Belfast, Dublin and Philadelphia.

• As a member of the Prelytix team, you will help in modernizing and enhancing our award winning Prelytix product.
The ideal candidate will have: *
• 4+ years of experience in the architecture design and deployment of applications based on Node.js frameworks such as Express.js, Sails.js, Hapi.js.

• 4+ years of experience with the development and deployment of large scale, high availability and geographically distributed cloud applications using an agile methodology.

• 4+ years of Experience with Cloud Architecture and deployments on AWS, GCP or Azure.

• Expert proficiency in the latest versions of Javascript & Typescript.

• Experience with CI/CD pipelines and the use of containerization.

• Experience optimizing software processes to ensure your team is delivering code of the highest quality while striving to improve productivity and proficiency.

• Experience with big data technologies, streaming analytics and AI would be a great asset.

• Experience in martech or adtech would also be a great asset.
Benefits at MRP: *
• The opportunity to make a real impact within our business and ability to work in a collaborative environment.

• Competitive salary with promotion prospects.

• Competitive holiday package.

• Private healthcare plan.

• Pension Scheme.

• Continuous social events, which run throughout the year.

• Company Laptop.

• Excellent training and career development opportunities that are tailored to you
Due to current Covid-19 pandemic, MRP has made adjustments to it’s interview process as the safety of our employees and candidates is our priority.*
Until further notice, all interviews will take place either via telephone call or via a video calling platform. Should you be successful at interview stage and therefore offered a role with MRP, where possible we will onboard remotely to get you started in your new role as soon as is practically possible for MRP. This onboarding process may also require you to visit the office in order to collect essential equipment, when this is unavoidable, social distancing measures will be in place and must be observed for everybody’s safety.*
MRP is an equal opportunities employer.*
Should you have any questions regarding the above, please don’t hesitate to reach out to the recruitment team here at MRP.*
Job Types: Full-time, Permanent

Schedule:
Monday to Friday
No weekends
Experience:
software engineering: 4 years (Required)
Work remotely:
Yes",3.0,"MRP
3.0","Belfast, Northern Ireland",-1,51 to 200 Employees,2002,Company - Public,Enterprise Software & Network Solutions,Information Technology,$50 to $100 million (USD),-1
Full Stack Java Engineer,-1,"Company Description

We pledge ""to prove IT can make a real difference to our customer's businesses"". We work hard to ensure we understand what our customers need from their technology solutions and then we deliver.

We are an award-winning company who provide world class customer service; we think big and we hire great people. Version 1 are more than just another IT services company - we are leaders in implementing and supporting Oracle, Microsoft and AWS technologies.

Invest in us and we’ll invest in you; if you are driven, committed and up for a challenge, we want to meet you.

Job Description

In this role you’ll be responsible for the development of RESTful Microservices using Java 1.8 and Spring/Spring Boot Frameworks as part of a cross functional Agile team. There will also be an aspect of ReactNative app development.

Java has been a key technology throughout Version 1’s history, and our Java Practice has been responsible for delivering some of the largest eGovernment systems as well as business critical solutions to the utilities and financial services sectors across a wide range of platforms, operating systems, open source components and databases. We use best of breed Java toolsets - focused on Micro Services Architectures, powerful front- and backend frameworks, RESTful services, and everything from NoSQL databases like MongoDB and Hadoop, high-performance data grids like HazelCast to multi-node relational systems.

Qualifications

Essential

Java 1.8 experience
Excellent grasp of Spring Framework with a focus on Spring Boot
Experience of developing RESTful microservice architectures
Experience working in an Agile environment
Strong TDD practices and use of testing frameworks such as JUnit
Strong working knoweledge of GIT version control
Experience working with relational databases

Additional Information

Version 1 Talent Acquisition Team",4.0,"Version 1
4.0","Edinburgh, Scotland",-1,1001 to 5000 Employees,1996,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Software Engineer - Big Data,-1,"Heard about Facebook/Cambridge Analytica and the data challenges facing organisations today? or perhaps you have seen the 'Great Hack' on Netflix?

We are looking for multiple talented and passionate engineers who love to build products that have a tangible, positive impact on the world. We are currently open to all levels of experience, from graduates to experienced senior developers.

Privitar is a dynamic, Data Privacy start-up based in London, building software to enable the safe and ethical use of valuable data for analytics and machine learning. We work with large organisations worldwide in healthcare, financial services, telecommunications, pharma and government, enabling them to get the most out of data without compromising on privacy and security.

Backed by world-leading venture capital funds who’ve invested in companies like Facebook, Slack, Dropbox, Atlassian and Spotify, we have recently completed a $80 million Series C funding round, and are in a phase of hyper growth.

Ideal candidates for this role learn and adapt quickly. You’ll combine state-of-the-art technologies with leading-edge algorithms to understand and tackle hard data security and data anonymisation problems. You will also be involved in performance, integrations and UI.

Hiring & Onboarding during Covid-19

The Privitar team is working from home at this time, and our interviews across all roles have been adapted to operate fully remotely. As a result we’ve hired and onboarded more than 40 people virtually since the pandemic began. We have developed our ways of working to make sure new joiners feel part of our team straight away. No matter which office location, this includes virtual socials, monthly virtual company all hands, bi-weekly virtual lunches and cooking clubs. We’d love to hear from you to tell you more.

Our Eng Culture

As engineers at Privitar, we are excited and engaged with the problems we are working on. We work together in small teams in a supportive way, developing our skills, learning from each other, and building on each other's ideas. We take a deep pride in the products we build and care about writing clear, well-tested code.

We have a positive, constructive and proactive approach and enjoy working to design and architect solutions, choose technologies, and constantly improve how we work as a team. We are not afraid to question something that might seem obvious or to give it a go and learn how to do things better.


About you
Less experienced candidates
Bachelor’s or higher degree in Computer Science or a Science or Engineering discipline. We can make exceptions to this for exceptional candidates.
Experience of coding in Java. Or experience in a related language and evidence of commitment and ability to ramp up in Java.
Demonstrable interest and knowledge of maths, big data, security or privacy.
Excellent communication skills
More experienced candidates
The more Java experience the better.
You are comfortable with being dropped into challenging technical problems and being given the responsibility to solve them.
Experience building a software product, ideally over the full lifecycle from design to production and ongoing support and enhancement.
Experience of and commitment to automated testing.
Ability to deliver results with rapidly evolving propositions, client demands and business needs.
Knowledge of multiple programming languages
Desirable
Experience of multithreading or concurrent programming
Experience building complex distributed systems
Exposure to Big Data technologies, for example: Hadoop, Spark, Apache Nifi, MapReduce, HDFS, HBase, Hive, Cassandra.
Understanding of software security and threat models, and experience building secure applications
Experience with Amazon AWS and other cloud platforms
The Application Process
A phone call with a member of our recruitment team to find out more about Privitar, and to get to know you
One of the most interesting take home technical exercises you’ll see, designed by Privitar, unique to Privitar, relevant to Privitar
A ½ day visit to our offices
Offer
Privitar does not accept unsolicited referrals or CVs from any source other than directly from candidates or approved agencies with written agreements in place and instructed on specified roles.

Unsolicited CVs received from any agency not engaged as outlined above will be considered a ""free gift"", and there will be no fees due should we choose to contact the candidate directly. Receipt of unsolicited CVs will in no way establish any prior claim to the candidate should they also be submitted by another agency. We consider this type of activity an attempt to lay claim to a given candidate and therefore entirely inappropriate. Any submission of unsolicited CVs to us will be deemed as full acceptance of these terms.
We only engage with agencies who are respectful of candidates, businesses and other agencies. We abide by our agreements with them and maintain genuine, straight-forward and lasting relationships which generate the highest calibre candidates for our business.",4.8,"Privitar
4.8","London, England",-1,51 to 200 Employees,2014,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
P8 ILS Engineer,-1,"Boeing Defence UK is looking for a P8 ILS Engineer based at Bristol, United Kingdom.

Position overview:

Boeing Defence UK operates an engineering matrix organisation consisting of engineering capabilities that deliver technical skills, expertise and products into our programmes. One of the capabilities is Product Support Engineering (ILS Engineering) which provides the product supportability infrastructure comprising the following technical areas: Logistic Support Analysis, Reliability and Maintainability, Reliability Centred Maintenance Analysis, Engineering Data Exploitation, Integrated Logistic Support Engineering and Technical Publications. The Integrated Logistics Support Engineer P8 (TSP) will support the P8 (ASP) ILS Lead.

Position Responsibilities:

Support to the generation, review and assessment of tech services (ILS) documentation.
Preparation of material for briefings, meetings and formal working groups (internal and external).
Attendance as required at internal, supplier and customer meetings.
Liaison with P8 Training Systems functions (Engineering, Technical Publications, SCM, Training, Programme Management and Security) to ensure Tech Services remains informed and aligned with wider P8 developments and progress.
Liaison with the Customer on specific areas of Technical Services.
Support and co-ordinate Tech Services deliverables (CDRLs) ensuring timely inputs are received, reviewed and the final output is ready for approval and acceptance process.
Highlight any issues or opportunities within Technical Services at the earliest possible point and where required support mitigation and development plans for addressing highlighted concerns.
Support contingency planning and requirements to migrate smoothly into Sustainment.
Work as directed by the P8 ILS Lead.

Employer will not sponsor applicants for employment visa status.

PLEASE NOTE: The successful candidate will be expected to undergo a SECURITY CHECK/CLEARANCE.

Desired Qualifications/Experience:

Experience with either Logistics Support Analysis with the use of LSAR, or Reliability and Maintainability.
An amount of Support Engineering/Integrated Logistical Support related work experience.

PreferredQualifications (Experience/Education/Skills):

An understanding of Support Engineering.
Authoring of Support Product documentation (ISP and subservient plans).
Ability to work with the cross functional business stakeholders to identify optimisation opportunities and ways in which suppliers can enhance our offering to our clients.
Ability to Liaise with the OEM platform side of Boeing to integrate the UK solutions with those that exist on the base platforms
Proven ability to drive first time quality.
Understanding of the principals of Estimating.
Ideally you will be educated to degree level in a relevant Engineering subject.
Experience of engineering on Boeing Fixed Wing Platforms (preferably 737 derivatives) is highly desirable.
Experience of working with international support standards such as Def Stan 00-600, ASD/AIA Suite of S Series ILS Specifications is highly desirable.
Experience of working and developing formal Proposals is desirable.
Experience of working in the Training environment would be advantageous.

Important information regarding this requisition: This requisition is for a locally hired position in the UK. CANDIDATES MUST HAVE CURRENT LEGAL AUTHORIZATION TO WORK IMMEDIATELY IN THE UNITED KINGDOM. BOEING WILL NOT ATTEMPT TO OBTAIN IMMIGRATION AND LABOUR SPONSORSHIP FOR ANY APPLICANTS. Benefits and pay are determined at the local level and are not part of Boeing U.S. based payroll.

Relocation:

This position does not offer relocation. Candidates must live in the immediate area or relocate at their own expense.",3.7,"BOEING
3.7","Bristol, England",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
Computer Vision Engineer,-1,"We believe the teams of the future will be hybrid, with humans working alongside machines to solve persistent, global problems, and we're building that future using the latest in advanced AI technologies and connected edge devices.

With projects ranging from anti-poaching protection to rail trespass monitoring, we excel in helping companies protect their remote assets and we're proud to have won several international awards for our work. We'll provide you a high-paced, challenging and fulfilling environment to further your career, empowering you to help you shine in your role.

Role Description:

We develop novel, power-optimised, computer vision algorithms that combine machine learning with specialist cameras. We are looking for a proactive candidate with a strong understanding of computer vision and machine learning concepts, with an enthusiasm for applying their work to real life situations. To be successful you should be able to show off evidence of your personal deep learning projects

Depending on skills and experience, you may be responsible for planning the imagery collection, developing & training neural nets, optimising for power consumption, optimising for embedded devices, testing or deploying the system.

Depending on your other skills you could also get involved in embedded software development, prototyping hardware (think Raspberry Pi, drones, 3D printing etc.) and customer liaison. Let us know what you can do!

Joining us at this stage will also enable you to influence the product direction and hiring your perfect team mates as we grow.

Role Responsibilities:

Responsibilities will vary depend on your skills and desired career direction.

Key responsibilities are:

End-to-end responsibility for solving a problem and delivering end user value
Negotiating requirements
Designing a strategic approach to solving problems
Developing solutions
Communicating results clearly

Essential skills / Experience

Excellent skills in deep learning (CNN training, testing, evaluation and deployment)
Proficient with multiple machine vision and machine learning frameworks (OpenCV, TensorFlow, TensorRT, Darknet, PyTorch etc.) with a strong portfolio of development examples
Researching, designing and implementing machine learning and computer vision solutions
Excellent Python and/or C++ skills
Solid understanding of regular computer vision techniques (OpenCV, SVM, KNN etc.)
Strong data science skills
Excellent communication skills (written, and spoken)
Strong software design and development experience, including OO design
Awareness of hardware limitations
Degree in a computer science related subject

Desirable Skills / Experience:

If you bring any of these to the table, you will be able to stand out from the crowd...

Strong understanding of imaging sensors, image processing and camera interfaces
Commercial experience delivering machine learning and computer vision solutions
Automation and devops, especially leveraging the cloud for training models
Containerised solutions such as Docker and Balena
Customer / user engagement experience

Stuff you can do that we'd like to hear about in your application:

That phone app you made to solve a cool problem
Running deep learning on embedded devices such as NVIDIA Jetson, Google Coral or Intel Movidius
Anaconda knowledge (not the snake!)
Experience coding with various computing platforms (Linux, windows, mac, raspberry Pi, ARM, STM32, CUDA, etc.) or languages (Python, C, javascript, Go etc.)
That IoT project you did for your Dad last Christmas
Awareness of modern software development (CI, CD, Docker, Kubernetes etc.)
Scripting and web API ninja skills
Communication technology experiments (wireless weather station, IoT,etc.)

Further Details:

Location: Most of the work can be done remotely. Hardware-related work is based the Harwell Space Campus. Visits to the office for collaboration are encouraged (when possible).
Interested applicants may wish to join first as a fixed-term consultant although we prefer to find a good permanent match.
Security clearance: Due to the sensitive nature of some of our work, it would be beneficial for candidates to be willing and able to obtain and maintain the necessary security clearance for this role

Why join our team:

Potential bonus and significant equity for demonstrated impact
Merit-based compensations
Flexibility: Options for flexible working hours, working from home and custom arrangements that matter to you
A variety of training and learning programs, from online to residential and in-house learning
A variety of perks: Gym discounts, cinema half price, free phone insurance, shopping and supermarket discounts plus many more!
The buzzing Harwell Space Campus with regular events on site (networking, workshops)
High-performance, ambitious, like-minded team",-1,Archangel Group,"Harwell, East Midlands, England",-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Principal Engineer /Contractors Responsible Engineer – Bridges,-1,"Description

We currently have the opportunity for a talented Principal Engineer and Bridges CRE to join the Rail team based in York. This is a fantastic opportunity to join a dynamic and successful team that is growing rapidly. Successful candidates will be rewarded with a rich diet of interesting and challenging rail projects and an opportunity to develop their careers with a successful global engineering consultancy.

About Arcadis:

At Arcadis, we never lose sight of what’s most important. Because look beyond our projects and programmes and you’ll see it’s about human stories. From remaking public spaces that bring people together, to making cities easier to navigate, we’re focused on making an impact where it matters most – and improving quality of life.

It’s a big challenge. And why we need people committed to bringing their best, who deliver on their promises. People who value different perspectives, build sustainable relationships and dare to shape the future. People who seize the experiences available to transform their world – and the world around them.

It’s a shared goal amongst 27,000 Arcadians. And one we can only achieve by working together and applying our skills and expertise across design, consultancy, engineering, project and management services. It’s how we’ll find solutions to our clients’ most complex challenges. And how we’ll deliver exceptional results, today and tomorrow.

The railway sector is one of our core markets, a position it has held throughout our history. We pride ourselves on delivering new and exciting resolutions for rail infrastructure design and construction schemes.

About The Team:

The Rail North East business based in York and covering Network Rail’s Eastern Region including Anglia is growing off the back of recent wins. We’re delivering a multitude of projects for clients including Network Rail, Nexus, Tier one Contractors and Local Authorities as well as supporting other parts of the UK business to deliver HS2, Crossrail and other Network Rail Frameworks.

Requirements:

Reporting to the Bridges Team Leader as a Principal Engineer you will provide design delivery on a variety of civils led multi-disciplinary projects within the rail environment. As we operate in such a diverse marketplace, you will gain an experience of working on a wide and varied portfolio of projects which will enhance your skills and test your technical knowledge.

You will be a key technical team member in the York Rail Civils design team, responsible for and involved the delivery of project-related tasks to meet budget, time-frame and quality targets, meeting or exceeding client expectations, promoting and marketing all facets of Arcadis services during interfaces with clients and other sectors and disciplines, contributing towards the achievement of the divisional business plan and to build networks within the industry.

You will fulfil the role of Bridges and /or Civils CRE for Network Rail projects or lead bridge engineer on projects for other clients.

We will ensure that we offer personal development which will allow you to progress your career and offer you the opportunity to be mentored by industry recognised Technical Leaders in their field who will lend you their experience and ensure that the training you receive will give you the best possible chance of success.

Essential Experience

You will have a gained substantial civil / structural design experience with significant experience gained within the rail and bridge sector and in a consultancy environment

Have previous relevant experience including supervision of elements of large, complex projects (with a focus on bridge engineering)

Chartered Engineer status with ICE or IStructE

Previously fulfilled the role or bridges or civils CRE for Network Rail or similar lead engineer roles for other clients.

Experience preparing design deliverables using civil engineering design software packages

Good working relationships developed with Clients

You will be an Innovative thinker, a team player, proactive and delivery focused

An aptitude for Building Information Modelling and the workflow associated with projects delivered in a Common Data Environment

You will possess the enthusiasm to tackle stretch tasks

You will be flexible to travel throughout the UK on occasion

You will be able to demonstrate strong team building and collaboration skills

Excellent written and verbal communication skills with proven planning and organisation skills

Manage engineering activities that contribute to sustainable development

Good IT skills including Microsoft Office applications

Duties & Responsibilities:

Responsibilities of this role include, but are not limited to:

Developing skills and knowledge base in both the technical and management streams

Leading and assisting with the preparation of documentation relating to projects

Designing in 3D modelling environments such as AECOSim, Revit and Civil 3D

Fulfilling CRE / Lead Engineer roles on projects

Preparing design calculations, drawings, specifications, reports and other project documentation as required in line with company and client requirements as well as national standards and codes of practice

Taking a lead role in the resolution of technical issues

Supervision and technical development of other engineering team members

Attending site and taking a lead role in the completion of surveys in a rail environment

Gaining experience and proficiency in Arcadis systems and procedures

Becoming familiar with, and compliant with, relevant Health, Safety and Welfare regulations and to promote a culture of awareness within the team

Building relationships with Clients on projects

Performing other duties and responsibilities as required from time to time by your manager or Arcadis

Line Management responsibilities

Why Arcadis?

At Arcadis, you’ll have the opportunity to build the career that’s right for you. Because each Arcadian has their own motivations, their own career goals. And, as a ‘people ﬁrst’ business, it’s why we’ll take the time to listen, to understand what you want from your time here, and provide the support you need to achieve your ambitions.

Wherever you join us, you can look forward to a competitive reward package that includes an attractive starting salary, opportunities for career development and being part of a sociable community. We have a performance-related bonus scheme and an employee recognition scheme. Other beneﬁts include membership fees to join your relevant professional body, employer contribution pension scheme, ﬂexible working and a flexible holiday scheme.

We believe that by working together diverse people with different experiences develop the most innovative ideas. Equality, diversity and inclusion is at the heart of how we improve quality of life and we work closely with our people across six ED&I Workstreams: Age, Disability, Faith, Gender, LGBT+ and Race. A diverse and skilled workforce is essential to our success.

Qualifications

Degree in civil engineering (preferably a Masters Degree)

Chartered or Incorporated Engineer professional status, or equivalent",3.9,"Arcadis
3.9","York, England",-1,1001 to 5000 Employees,-1,Company - Public,Construction,"Construction, Repair & Maintenance",Unknown / Non-Applicable,-1
Data Science Engineer,-1,"G-Research is Europe’s leading quantitative finance research firm. We hire the brightest minds in the world to tackle some of the biggest questions in finance. We pair this expertise with machine learning, big data, and some of the most advanced technology available to predict movements in the financial markets.

The role

You will be joining G-Research’s Technology Innovation Group (TIG), who sit at the forefront of researching industry trends and testing new technologies. TIG works with engineering teams across the business to identify where new developments and products could benefit them, creating prototypes and road-testing solutions in our in-house lab and in the cloud.

This is a great opportunity for an experienced data science engineer who is interested in exploring new software platforms, libraries, and hardware accelerators that could benefit our data science and machine learning teams. You will be working as part of a small, diverse, interdisciplinary, fast-paced team. You will build working prototypes and proof-of-concepts, demonstrating the potential of new technologies to other parts of the business.

You will critically and methodically benchmark new technologies in terms of performance and assess their robustness and potential to add value and integrate into the wide technology landscape at G-Research.

Key responsibilities of the role include:
Continuously scouting and evaluating new data science and machine learning-related technologies and approaches
Creating and using benchmarking frameworks to performance and stress-test new technologies quickly and effectively against the different kinds of workload we have
Supporting functional, interoperability, and usability tests and proof-of-concepts both carried out by TIG directly or in collaboration with other teams in the business
Disseminating the results of your testing to the wider business through write-ups or internal blog posts aimed at raising awareness of the ever-changing tech landscape
Attending national and international conferences to keep up-to-date on the latest trends and services
Using your experience – and lessons learnt while experimenting in the lab – to help define what services, solutions, or approaches TIG should test next
Who are we looking for?

You will have a real passion for innovation as well as a solid and proven track-record in data science engineering, ideally in a role focused on the development of data-science pipelines and tooling. As TIG assesses cutting-edge technologies on a daily basis, you’ll enjoy working in a continuously prototyping environment and learning new skills and technologies on an ongoing basis.

The ideal candidate will also have the following:
Strong experience in data science and machine learning frameworks
Strong experience using programming languages such as Python or R and libraries, APIs and frameworks such as TensorFlow, Keras, and Spark with and without interactive notebooks
Hands-on experience in processing datasets in the low-mid TBs
Strong interest in the engineering surrounding data science and hands-on experience in building data processing pipelines including distributed ML and streaming ML
Familiarity with Linux, Kubernetes, Containers, Cloud tech, and Databases would be beneficial
Experience in moving data science workflows into production
A strong background in mathematics to be able to understand the needs of quantitative researchers and be able to assess new technologies and ML frameworks in that context
Good communication and interpersonal skills
Previous financial experience is not required, although interest in financial modelling and forecasting techniques for time-series data will be beneficial
A Masters or PhD degree in a highly quantitative subject (mathematics, statistics, computer science, physics or engineering) is desirable
Why should you apply?
Highly competitive compensation plus annual discretionary bonus
Informal dress code and excellent work/life balance
Comprehensive healthcare and life assurance
25 days holiday
9% company pension contributions
Cycle-to-work scheme
Subsidised gym membership
Monthly company events
Central London office close to 5 stations and 6 tube lines",4.8,"G-Research
4.8","London, England",-1,501 to 1000 Employees,2001,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Senior Full Stack Java Engineer,-1,"Company Description

We pledge ""to prove IT can make a real difference to our customer's businesses"". We work hard to ensure we understand what our customers need from their technology solutions and then we deliver.

We are an award-winning company who provide world class customer service; we think big and we hire great people. Version 1 are more than just another IT services company - we are leaders in implementing and supporting Oracle, Microsoft and AWS technologies.

Invest in us and we’ll invest in you; if you are driven, committed and up for a challenge, we want to meet you.

Job Description

As a Senior you will be responsible for the development of RESTful Microservices using Java 1.8 and Spring/Spring Boot Frameworks as part of a cross functional Agile team. There will also be an aspect of ReactNative app development.

Java has been a key technology throughout Version 1’s history, and our Java Practice has been responsible for delivering some of the largest eGovernment systems as well as business critical solutions to the utilities and financial services sectors across a wide range of platforms, operating systems, open source components and databases. We use best of breed Java toolsets - focused on Micro Services Architectures, powerful front- and backend frameworks, RESTful services, and everything from NoSQL databases like MongoDB and Hadoop, high-performance data grids like HazelCast to multi-node relational systems.

Qualifications

Essential

Java 1.8 experience
Excellent grasp of Spring Framework with a focus on Spring Boot
Experience of developing RESTful microservice architectures
Experience working in an Agile environment
Strong TDD practices and use of testing frameworks such as JUnit
Strong working knoweledge of GIT version control
Experience working with relational databases

Additional Information

Version 1 Talent Acquisition Team",4.0,"Version 1
4.0","Edinburgh, Scotland",-1,1001 to 5000 Employees,1996,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Senior Data Scientist,-1,"Are you an experienced Data Science who wants to join a leading Data Science team within an evolving and dynamic organisation?

You must hold UK Government clearances

Due to the success of a number of strategic Gloucestershire based programmes, we are growing our Data Science team with creative and ambitious Data Scientists and Machine Learning Engineers. With a primary focus on applying data science and machine learning to deliver digital transformation for our customers, your experience will cover different machine learning and data science technologies within an agile environment.

Different thinking for a Different world

Northrop Grumman is a leading global security company providing innovative systems, products and solutions to government and commercial customers worldwide. In Northrop Grumman’s rapidly growing UK Cyber and Intelligence business, we support our customers’ work to make the UK the safest place to live and do business, both physically and online.

Working with and alongside our customers, we use modern software engineering methods (Scaled Agile Development, DevSec Ops, Site Reliability Engineering, micro-service architectures) and cutting edge techniques (data science, Artificial Intelligence, Machine Learning) to tackle complex and challenging problems and deliver cost effective, reliable, supportable solutions.

Our solutions support complex analysis of substantial amounts of data, requiring state of the art ‘big data’, stream processing and cloud-based analytics, identifying and using ‘best of breed’ commercial and open source technologies and integrating them with our own software to meet customer needs quickly and efficiently.

At Northrop Grumman we pride ourselves on our ability to combine agile development with sound engineering and security practices to ensure that our solutions are robust and resilient; designed and built to start secure and stay secure against ever evolving cyber security threats. As well as designing for security, Information Assurance and legal / policy compliance, we actively assess products and services, identifying vulnerabilities and weaknesses that could be exploited bycyber attackers, and we create and run exercises to pit cyber security specialists against secure systems and each other.

We carry out research and innovation locally in the UK, with commercial and academic partners, and across our 85,000+ worldwide workforce.

How you will make a difference

For us, innovation is key and we have immediate opportunities for talented data scientists to join our team. We want you to help us apply data science and machine learning to transform the way our customers do business. We want to apply the latest developments in data science and machine learning, and to take technical risks – if the potential payoff is transformative. We are in a phase of rapid growth and there are opportunities to develop your career with us to meet your aspirations.

You will be helping us to solve our customer’s problems within an agile team. You will have opportunities across a range of data science and machine learning projects: from R&D to large-scale production deployment; from forecasting and decision trees to the latest developments in deep learning.

As a Senior Data Scientist youwill have had responsibility for the delivery of data science and machine learning projects.

Key criteria required...

Experience of the delivery of data science and machine learning solutions that transform ways of working and deliver measurable benefit

A deep technical background in machine learning and data science

Experience of using open source machine learning algorithms

Experience of modern software engineering practices, such as SCRUM/Agile, micro-services and containerisation (including Docker and Kubernetes) etc.

Also, we’d love it if you have experience of...

delivering solutions based on deep learning

delivering solutions based on NLP

deploying machine learning to Cloud platforms (e.g. AWS, Azure)

taking a project from an initial concept through to deployment in a production system

data engineering

an MSc or PhD in a numeric field (Mathematics, Statistics, Computing, …)

You will enjoy a growing career as we work collaboratively to innovate the world of data science and machine learning.

Additional information for your consideration...

You must hold UK Government clearances

Opportunities exist across the UK to enhance your career progression

Being a part of Northrop Grumman gives you the opportunity to use your skills to make a difference in our mission of enabling global security. Our company grows because of our employees' dedication and commitment to achieving our mission, something we always remember. In return for working for us you will have access to a benefits package that provides you with flexibility to balance your professional career with your personal life, health & well-being benefits, discount schemes, pension benefits and investment in your future development.

We are committed to equality and diversity in our workplace. Northrop Grumman provides equal employment opportunities to all employees and applicants without regard to an individual’s protected status, including race, ethnic origin, colour, nationality, national origin, ancestry, sex/gender, gender identity/expression, gender reassignment, sexual orientation, marriage/civil partnership, pregnancy/maternity, religion or belief, creed, age, disability, genetic information, or any other protected status or characteristic.

Looking for flexibility? Talk to us at the application stage about what may be possible.",3.8,"Northrop Grumman UK
3.8","Cheltenham, England",-1,10000+ Employees,1939,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
Senior Medical Device Regulatory Engineer,-1,"Life Changing**. Anything is Possible with the Right Approach…*
About Us*
Creo’s mission is to improve patient outcomes in the emerging field of surgical endoscopy, *a ground-breaking discovery* in minimally invasive surgery.

Our goal is to experience improved patient outcomes by applying advanced energy to surgical endoscopy. We started our journey in 2003 by the pioneer Professor Chris Hancock, initially to target the treatment of cancers through use of high frequency microwave energy and dynamic matching techniques.
Anything is possible with the right approach*
As a talented team with diverse backgrounds, we have a depth of expertise across all areas of the business. We succeed through applying our ‘can-do’ attitude to innovate so that we can satisfy our hunger for solutions!

Engagement and collaboration are key to our business success and to continually innovate and exchange ideas and knowledge in an open, encouraging and developmental environment whilst we challenge the status quo.
Being part of our team will mean making a real difference globally.*
Over recent times, the team at Creo has expanded significantly to introduce additional experience into the design, manufacture, production and commercialisation of electrosurgical medical devices. As such, we have developed an electrosurgical platform and are developing a pipeline of medical devices which we plan to launch commercially.
Right now, we are looking for a **Senior Medical Device Regulatory Engineer to **join our R&D - Regulatory Assurance Team.*
Key tasks for this role are:
Perform scientific literature search, review and analysis in accordance with, for example, the requirements of Annex X of Medical Device Directive 93/42/EEC (MDD), Medical Device Regulation 2017/745/EU (MDR) as necessary, and MEDDEV 2.7.1.
Identify complications and side-effects, including incident rates, for the intended use of devices.
Support to the establishment, review and revision of the clinical evaluation per MDD/MDR.
Provide input into the risk management process per ISO 14971:2012, MDD and MDR as applicable, including determination of risk/benefit ratio.
Identify potential predicate (per 510(k) submission) and equivalent (per MEDDEV 2.7.1. and MDR) devices and compare to devices under development.
Support CE marking and 510(k) submission processes in general, including device and device procedural-use descriptions.
Support regulatory submissions to other countries/regions.
Support post-market surveillance, vigilance reporting and medical device reporting for the EU, USA and other countries/regions as necessary.
Develop device instructions for use.
Provide input to device user and other training programmes based on instructions for use and risk analysis.
Provide support to chemical and biological compatibility for materials incorporated into and the manufacturing processes for complex electro-mechanical devices, including compatibility of administered substances
Ensure that standards and regulations associated with Creo’s medical devices are maintained to the latest issue.
Provide support during ISO 13485 certification, Notified Body, FDA and other QMS/regulatory compliance audit and inspections.
Additionally,
Work with project teams and other internal customers to interpret needs and design programmes of work. Influence decision-making on which studies are run, how they are run, and lead the decision-making on experimental design to ensure project objectives met.
Establish and maintain control of study budgets, liaising with project teams, internal customers, and CROs on costs, cross-charges and payments. Ensure programme plan and study plans regularly issued, resolving study clashes and planning issues in line with business priorities, make proposals on resource support required to ensure delivery.
Ensure studies and data collection tools are appropriately designed to meet objectives. Write and review study protocols and essential documentation, as well as ensure the timely preparation of data collection forms.
Liaise with the ethics committee, developing relations, attending committee meetings and ensuring appropriate approvals gained for studies. Liaise on study product supplies and labelling and ensure clarity on requirements for availability of product.
Manage and oversee Contract Research Organisations (CROs) that are contracted to carry out any studies, ensuring appropriate approvals are gained and procedures followed.
Monitor the conduct of the live phases of studies to ensure that there is compliance with the protocol and that data generated is accurate, consistent, and complete.
Key skills, behaviours, competency and experience required*:
Experience with the Medical Device Directive and the particular standards associated with Sterilisation and Biocompatibility of medical devices.
An ability to use general office software (Microsoft Office) and other specialised software (e.g. online resource tools and databases).
High level of curiosity and attention to detail, with a methodical way of working.
Ability to communicate effectively, and credibly, with all colleagues and stakeholders (internal & external).
Ability to analyse and understand data to enable decisions to be made objectively.
Ability to follow instructions accurately and diligently.
Strong technical understanding
Extensive experience in literature research
Experience in medical research preferred
Excellent organisation and prioritisation skills
Strong interpersonal, written and verbal communication skills
Excellent knowledge of IT software e.g. Excel, Word, PowerPoint
This exciting role will provide the successful candidate opportunity to become a key member of multiple product development teams supporting regulatory approvals and maintenance of clinical literature and clinical evaluation reports within the product’s technical files. This role also extends beyond to down-stream clinical coordinator activities, planning, managing and continued support for clinical trials.

To collaborate, author or review the clinical evaluation reports for new product development and as part of a yearly update. Undertake or oversee literature searches relevant to clinical evaluation or as needed by project teams. Work with Product Development teams in the preparation of regulatory documents involving risk, post market surveillance and ex-vivo verification testing. Performing tasks relating to regulatory affairs as requested by the RA/QA director.

Additionally, the successful candidate will manage and conduct a programme of studies and related clinical activities, to support project teams and provide regulatory and commercial support. This involves drafting and approval of study protocols, primary contact and coordination of development teams, study sponsors, clinical test facilities, clinicians and CROs.

Job Types: Full-time, Permanent

Benefits:
Casual dress
Company events
Company pension
Flexible schedule
Life insurance
On-site parking
Private medical insurance
Sick pay
Wellness programmes
Work from home
Schedule:
Monday to Friday
Experience:
Data Analyst: 4 years (Preferred)
Medical Device Directive: 4 years (Required)
Medical Research: 4 years (Required)
Education:
Master's (Required)
Work remotely:
Temporarily due to COVID-19",-1,Creo Medical Ltd,"Chepstow, Wales",-1,-1,-1,-1,-1,-1,-1,-1
Senior Software Engineer,-1,"One of the biggest names in travel and tourism are looking for a talented Software Engineer to join their wider engineering department. As one of the senior engineers you will be a voice within the business for software craftsmanship, expected to mentor and help grow our other engineers. You will be expected to drive yourself to stay on the leading edge of development practices and have a natural ability to clearly communicate technical detail to a non-technical audience.

They are missionaries of XP and agile values and principles, but each team is responsible for their own way of working. As a senior engineer you will help drive the teams’ processes forward by promoting continuous improvement.

The ideal candidate will undertake seamlessly the current duties of the job which is to collect, collate, and present large quantities of data from many different sources and provide a clean and simple API to our consumers within the companies’ technology stack. Engineering new API’s and tooling using *.NET Core* and a mixture of *front end* technologies including *Angular *and *React* to sit within a service orientated architecture running in *Kubernetes* powered by a CI/CD pipeline.

They deploy multiple times a day and are working towards a continuous delivery pipeline and use a variety of programming languages within teams such as ruby, C# and python so polyglot thinking is a must.

Key needed:

· C#

· .NET Core

· Front-end

· Angular

· React

· Kubernetes

· Ruby

· Python

If this fits well with your current experience and believe this is the right role for you, apply now with your latest CV and cover letter expressing your interest in the role.

A gentle reminder that we are not able to support sponsorships or visa support at this time. This job requires full eligibility to work in the UK indefinitely.

Application Deadline: 09/11/2020

Job Types: Full-time, Permanent

Salary: £45,000.00-£65,000.00 per year

Benefits:
Company pension
Discounted or free food
Employee discount
Flexible schedule
Free or subsidised travel
Private medical insurance
Store discounts
Wellness programmes
Work from home
Schedule:
Monday to Friday
Experience:
Software Engineering: 3 years (Required)
C#: 3 years (Required)
Location:
Manchester, Greater Manchester (Required)
Work remotely:
Temporarily due to COVID-19",-1,Glide Recruitment,"Manchester, England",-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Software Engineer,-1,"About the role

At QinetiQ we are looking for a bright, enthusiastic DV-cleared Software Engineer with a passion for technology and keen analytical skills to be based in our Malvern offices.

Job Specifications

What will I be doing?
You will be integrated into a dynamic and fast-paced development team, overcoming challenges and producing innovation solutions for our customer’s problems. The successful candidate is self-motivated and energetic, with a strong drive to ensure successful outcomes.
You will work as a member of a Scrum Agile development team, with the opportunity to contribute to the design, development, and deployment of software systems. You will gain experience in a broad range of technologies and toolsets.

Job description/Person specification
What do I need

You’ll need to hold a degree in Computer science or engineering subject or demonstrable equivalent experience; Knowledge and experience of the specification, design and implementation of complex software solutions.
Experience in some of the following areas would be desirable, but not essential:

• Hold current DV clearance is essential
• Skilled in designing and developing software in either Java or Python
• Knowledge of processes and tools to design, develop, test and integrate quality software
• Agile/Scrum methodologies with experience of the Atlassian suite
• Data pipeline experience using Spark/SQL/Hive

Lastly, you’ll be able to demonstrate good communication skills as you’ll be leading a team and influencing key stakeholders.
Why join us?

As we continue to grow into new markets around the world, there’s never been a more exciting time to join QinetiQ. The formula for success for QinetiQ is the appetite for innovation, courage to take on a wide variety of complex challenges and motivated people who work to deliver the best possible solutions to partners.

Joining QinetiQ offers an opportunity to work on highly technical cutting edge projects, enabling customers to protect, improve and advance their vital interests.

In return we’re offering excellent benefits package including contributory pension, Life Cover, income protection and much more
QinetiQ comprises teams of dedicated people; experts in defence, aerospace, security and related markets. We draw on our extensive technical knowledge and intellectual property to provide the know-how and support to solve some of the world’s most challenging problems. Our people make the critical difference to customers by providing unique approaches to problem solving. Why don’t you join some of the world’s finest scientific and technical minds and help us make tomorrow work today?

How to apply
To apply for the role please click on the apply button to submit your application.

#QQ
#LI – QQ",3.6,"QinetiQ
3.6","Great Malvern, England",-1,5001 to 10000 Employees,2001,Company - Public,Aerospace & Defense,Aerospace & Defense,$2 to $5 billion (USD),-1
Senior Cloud Systems Engineer,-1,"Tribal’s vision is to empower the world of education. We use our experience of implementing student information systems coupled with our tools and domain knowledge to ensure the success of our education customers moving to the cloud.
The Role *
Our Cloud Systems team manage all aspects of infrastructure, application, data and engagement for our cloud customers, ensuring high levels of availability and reliability. As a Senior Cloud Engineer you will suggest and implement proactive measures to improve the quality of the Cloud Systems services provided to the business and customers.

As a Senior Cloud Systems Engineer, you will hold a particular responsibility to lead and deliver activities and projects which may be high profile, particularly complex, or require an exceptional level of professional competence. You will also share your expert knowledge with team members, in a way that facilitates the continual growth and improvement of the whole team.

You will work with third party suppliers and other Tribal teams to safeguard and maintain cloud systems. You will ensure that Tribal’s customer facing infrastructure, applications, policies and access levels/controls are routinely secure and fit for purpose, with any risks and threats being escalated and managed from an early point. You will also ensure that all relevant servers are kept up to date with regards to security fixes, and anti-virus software is up to date and of optimum quality to protect against virus attacks.

You will work as part of a wider cloud team, and will provide high quality technical support and guidance to customers and colleagues alike, acting as a mentor and coach to Cloud Systems Engineers and act as a point of escalation for issues.
Some key aspects of the role will include: *
Providing support on Microsoft Azure platforms and Amazon AWS platforms.
Providing Linux, VM and Citrix support (to internal and external stakeholders)
Design, diagnostic and support skills in all areas of infrastructure.
Developing and improving scripts based on PowerShell and other relevant scripting languages.
To be successful in this role it will be essential that you can demonstrate expert working knowledge of the following: *
Proven AWS experience
Significant demonstrable experience supporting IaaS, or Public Cloud Environments.
Expert knowledge of Networking, Storage and Microsoft systems
Expert knowledge of Active Directory, IIS, Web services
Linux, VM and Citrix
Working knowledge of common enterprise IT technologies (virtualisation, SAN, ADFS, SQL).
Detailed knowledge of Help desk processes.
VMware and vSphere operating systems and the ability to utilise and control significant features including VMWare Site recovery manager
What can Tribal offer me?

This is an unrivalled opportunity to join a growing cloud team in a global and market leading software business who specialise in education, training, and learning.

This is a great opportunity to take on a key role at Tribal where you can use your drive and determination to make a difference to the experiences our customers have.

To apply, please complete our short application form and attach your CV and cover letter.

Tribal are an equal opportunities employer.

Reference ID: 1247

Job Types: Full-time, Permanent

Salary: £45,000.00-£50,000.00 per year

Benefits:
Work from home
Schedule:
Monday to Friday
Experience:
AWS: 1 year (Required)
Azure: 1 year (Preferred)
Work remotely:
Yes",-1,Tribal Group,"Sheffield, England",-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Job Description

Data Engineer

At Citadel, data is the core of the investment process. Data Engineers architect and build our data platforms which drive how we source, enrich, and store data that integrates into the investment process. These Data Engineers own the entire data pipeline starting with how we ingest data from the outside world, transforming that information into actionable insights, and ultimately designing the interfaces and APIs that our investment professionals and quantitative researchers use to monetize ideas. Throughout the process, our Data Engineers partner with top investment professionals and data scientists to design systems that solve our most critical problems and answer the most challenging questions in finance.

YOUR OPPORTUNITY:

Develop solutions that enable investment professionals to efficiently extract insights from data. This includes owning the ingestion (web scrapes, S3/FTP sync, sensor collection), transformations (Spark, SQL, Kafka, Python/C++/Java), and interface (API, schema design, events)
Partner with the industry’s top investment professionals, quantitative researchers, and data scientists to design, develop, and deploy solutions that answer fundamental questions about financial markets
Build tools and automation capabilities for data pipelines that improve the efficiency, quality and resiliency of our data platform
Drive the evolution of our data strategy by challenging the status quo and identifying opportunities to enhance our platform
YOUR SKILLS & TALENTS:

Passion for working with data in order to accurately model and analyze complex systems such as a publicly traded company, commodity market, economy, or financial instruments
Strong interest in financial markets and a desire to work directly with investment professionals
Proficiency with one or more programming languages such as Java or C++ or Python
Proficiency with RDBMS, NoSQL, distributed compute platforms such as Spark, Dask or Hadoop
Experience with any of the following systems: Apache Airflow, AWS/GCE/Azure, Jupyter, Kafka, Docker, Kubernetes, or Snowflake
Strong written and verbal communications skills
Bachelor’s, Master’s or PhD degree in Computer Science or equivalent experience
About Citadel


Citadel is a global investment firm built around world-class talent, sound risk management, and innovative leading-edge technology. For a quarter of a century, Citadel’s hedge funds have delivered meaningful and measurable results to top-tier investors around the world, including sovereign wealth funds, public institutions, corporate pensions, endowments and foundations.

With an unparalleled ability to identify and execute on great ideas, Citadel’s team of more than 675 investment professionals, operating from offices including Chicago, New York, San Francisco, London, Hong Kong and Shanghai, deploy capital across all major asset classes, in all major financial markets.",4.1,"Citadel
4.1","London, England",-1,1001 to 5000 Employees,1990,Company - Private,-1,-1,$50 to $100 million (USD),-1
Software Engineer,-1,"At MarketFinance, we celebrate ambitious business leaders. They bring strength to our economy and are building the world we all want to live in. MarketFinance is one of the UK's leading Fintechs and we use smart technology, backed by help from great people, to deliver flexible business finance solutions, directly and quickly. Our online platform and proprietary risk model enable us to provide business loans and advance cash against outstanding invoices, in the form of working capital funding, so that businesses can get on with growing - instead of having to worry about cash flow. We believe in the endless possibilities that arise when entrepreneurs have more time to focus on what they love.

Our values matter and as part of the team, they’ll be yours too.

#MakeItHappen | #1Team1Dream | #AlwaysBeLearning

The Role

You will be working in autonomous teams that have the freedom to drive innovation themselves. We have a strong DevOps culture too and believe CI/CD/Testing are the only ways to innovate at scale. You will add value right away with coding, building, testing, deploying, monitoring.

This role will provide you with the opportunity to work with a small team of great engineers, working alongside a product manager to prioritise and deliver work.

Your Technical Environment

You’ll be working on our core platform allowing small business to access funding seamlessly through fantastic UX and automation of complex processing such as risk analysis and payment processing.

Pretty much all of our software at MarketFinance (including the application forms, trading infrastructure and payments gateway) has been developed in-house. We recently decided to move to serverless architecture as standard, but our core platform is built in .Net C# WebAPI and ReactJS and the choice of technologies is continually evolving.

Requirements
Hard skills
5+ years of experience working with backend technologies, including C#
1+ years of experience working with a modern frontend technology
Unit / Integration / Acceptance / Regression testing experience for front-end
Good understanding of PaaS, ideally Azure
1+ years experience with Azure
Soft skills
High level of autonomy (completes task end-to-end, proactively reaches out to stakeholders to gather inputs, etc)
Capable of mentoring junior members of the team
Benefits

At MarketFinance, the opportunity for growth is as big as your ambition. Things move quickly in FinTech and that’s all part of the adventure. Our benefits include:
Competitive salary and best-in-class share options scheme
25 days annual leave, plus your birthday off
Mentoring from industry leaders and the opportunity to make an impact at one of Europe’s foremost Fintechs
Private health coverage and half-price Virgin Active gym membership
Enhanced maternity leave, Amazon Kindle and unlimited e-books
Excellent company culture and a great office in the heart of Shoreditch
Ready to help UK businesses build the future? APPLY NOW!

We do our best to reply to all applications. However if you have not had a response within 4 weeks, please assume your application has not been successful.

How will we use the information about you?

We will use your data to process your application, to allow us to assess your suitability for a role and improve our sites. We may share your data with third parties to achieve these purposes. We will not share your data for marketing purposes.

We will keep your data safe in accordance with data protection legislation.",3.7,"MarketFinance
3.7",United Kingdom,-1,51 to 200 Employees,2011,Company - Private,Financial Transaction Processing,Finance,$5 to $10 million (USD),-1
Senior Development Engineer (CDS),-1,"Do you have what it takes to join our Team?

As a key member of the Digital Delivery team, the role of the Senior Development Engineer is to assist in the development of Digital Design techniques principally for the Company’s Treatment System products using Autodesk Inventor. The position includes, responsibility for the integration of the new design process outputs into the existing Autodesk Vault platform using / developing the current Project Lifecycle Management process. You must have a tenacious approach to digital design in addition to promoting the use and development of the Company’s range of integrated tools.

Requirements:
Proven experience in a Mechanical design environment.
Knowledge and use of Autodesk.
Inventor/Inventor Professional CAD skills.
Knowledge and use of Vault at 'Administrator' levels.
Knowledge and use of Inventor API's.
Educated to a minimum of a HNC (or equivalent) in an engineering or science discipline.
Knowledge of the Water Industry.
Knowledge of electrical wiring regulations and Machinery Directive.
Ability to read and understand Process and Instrumentation Diagrams.
Ability to read and understand electrical schematics.
IT, Digital Delivery Knowledge.
.net Framework knowledge (VB or C#).
Design to Manufacture knowledge.
Design for Manufacturing experience.
Responsibilities: (but not limited to)
Embrace the Company’s digital delivery tools, interrogate, develop, and innovate current design processes.
Oversee and develop the Digital Design processes leading to the automated production of CAD models, drawing packs, design documentation and technical reports as required by the scope of Treatment projects and in a manner, which is efficient and that continually enables the Company to deliver service excellence.
Understand and develop the automation of the detailed Bill of Materials and their integration into the Business procurement systems.
Understand and develop the integration of Digital Design tools within the existing Vault environment, including components and assemblies to enable greater efficiencies in design capabilities.
Continually employ the principles of Design for Manufacture and value engineering throughout design undertakings, but never deviating from or compromising designated standards / requirements.
Where applicable to record, analyse and interpret test data.
Assist Business Assurance in the documentation of Digital Design processes.
Assist in in development of Training Documentation and the training of personnel.
Help with the development, population and harmonisation of the Company’s processes and Knowledge-based systems.
STRICTLY NO AGENCIES*
Reference ID: SDE

Job Types: Full-time, Permanent

Salary: £0.00 per year

Benefits:
Company Pension
Life Insurance
On-site Parking
Sick Pay
Wellness Programmes
Schedule:
Monday to Friday
Experience:
AutoDesk Inventor/Inventor Professional CAD Skills: 3 years (Preferred)
Mechanical Design: 2 years (Preferred)",2.6,"Lintott Control Systems Ltd
2.6","Norwich, England",-1,51 to 200 Employees,1970,Company - Private,Electrical & Electronic Manufacturing,Manufacturing,Unknown / Non-Applicable,-1
Production Support Engineer,-1,"Position Overview:
We are seeking a Production Support Engineer who will be responsible for maintaining accesso®Passport’s proprietary backend applications, including Java services and interfaces. As part of our accessoEngineering Group, you’ll contribute to helping our clients sell more tickets, streamline operations, drive revenue and improve the guest experience. Our ticketing solutions allow our clients to sell general admissions, reserved seats, time/date specific tickets, season passes, memberships and so much more.
As Production Support Engineer you will serve as the escalation point for technical and functional support to our business teams and work alongside Software Engineers to resolve complex development issues. To fulfill the level of service and commitment to our clients, you must be able to participate in an on-call rotation shared amongst the development team. We move fast and as priorities shift, you’ll need to keep up with your peers.
Location: Lake Mary, FL, Twyford, UK or Australia
***Please note in light of COVID-19, all of our employees globally are telecommuting until further notice.***
Reports to: Engineering Manager, Production Support
Travel Requirement: None
Responsibilities Include:
Troubleshooting Level 2 Production Issues in our Linux Environment
Deployment of low risk Production changes
Providing thoughtful, timely updates on all open issues to the requester
Collaborating with several development teams on issues affecting their product(s)
Monitoring of daily routine batch jobs for exceptions
Participating in an on-call monitoring schedule that supports the Passport system
Post-closure analysis of issues with the intent of detecting trends on the help desk
Technologies You May Work With:
Amazon Web Services
Java Microservices
MySQL databases (AWS Aurora)
Atlassian Suite
DataDog
Microsoft Suite
Qualifications:
Experience in writing complex SQL
Ability to read and understand code, preferably Java
Strong communication skills
Have excellent problem-solving techniques to identify root causes
Are eager to learn and grow in the development field
Thrive in a highly collaborative and team-oriented environment
You are passionate about your work… because we are about our product
BONUS: Familiarity with Linux environments
BONUS: Previous eCommerce and/or ticketing industry experience
Perks & Benefits:
Competitive compensation package including discretionary annual bonus opportunity;
26-days of paid annual leave for employees (paid leave increases with tenure);
8-hours of paid Volunteer Time Off to give back to organizations and groups you feel most passionately about;
Robust health insurance scheme with the opportunity to participate in private medical scheme after satisfactory performance;
Matching pension scheme (up to 8%);
Unlimited access to Udemy for Business for continued learning and career development;
A flexible work schedule around our core business hours.
WORKING AT accesso:
accesso is taking precautions to protect the health and wellness of our employees around the world during the current pandemic, including but not limited to the temporary suspension of business travel and the implementation of remote work.
Albert Einstein said, “In the midst of difficulty lies opportunity.” At accesso, this time of uncertainty has created opportunities for us to strengthen our partnerships as we continue innovating on future technology needs in a post-COVID world; to grow as a company as we identify areas for improvement in business processes and practices; and to focus on our wellbeing as we learn to navigate a new circumstance while staying meaningfully connected with our individual selves, families and teams.
When we are in the office, we have FUN! From our bright, open spaces, foosball and ping-pong tables, caffeine and snack-filled cafes, we’ve created office environments all over the world that nurture our team members’ creativity and foster our company’s core values: Passion, Teamwork, Commitment, Integrity, and Innovation. These values are celebrated globally, by region, and by team through a multitude of recognition programs such as iValue and Rockstar Awards. We are empowered to do our jobs and then are recognized and rewarded for doing them well.
Our teams work really hard, encourage and motivate one another, and love to celebrate personal and professional accomplishments as a family. This creates an atmosphere where people are eager to solve problems together and want to continuously do better for not only themselves, but for their teams and peers.
We believe in the power of inclusivity and are an Equal Opportunity Employer. We are committed to creating a diverse environment for our employees to celebrate one another’s unique qualities. Any hiring decision made is assessed on the basis of qualifications, merit, and business need.
ABOUT accesso:
At accesso, we understand that technology is a critical component to our client’s success and the happiness of their guests. No business should have to settle for technology that creates more issues than it solves! Technology should be the solution, not the problem.
Our clients need powerful technology solutions to grow their businesses and create connected guest experiences – and accesso delivers! That’s why over 1,000 venues in 30 countries have chosen to partner with us.
The status quo is not an option. If you’re not moving forward, you’re falling behind. With our accesso solutions, venues can empower their staff with the control, data and confidence to make informed decisions that will drive revenue, create operational efficiencies and improve guest experiences.",3.6,"accesso
3.6","Twyford, East Midlands, England",-1,201 to 500 Employees,2000,Company - Public,Computer Hardware & Software,Information Technology,$100 to $500 million (USD),-1
Machine Learning Engineer,-1,"TTP is a leading technology consulting and contract product development business with expertise across a range of markets including areas such as Medical Devices, Sensors, Life Sciences and Communications. We are looking for Data Science/ Machine Learning engineers who are excited to tackle diverse, real world challenges, from the ground up.

As someone with experience in applying machine learning and statistical methods you will be using your skills across the whole design journey, from helping to identify opportunities to exploit new or existing data, through development and implementation.

You might find yourself in a team building a medical device with a novel sensing technology, showing viability, working across disciplines to define requirements and optimisations around the electronic and mechanical system, and delivering a ground-breaking solution.

Our customers range from innovative start-ups through to mature multinationals, you’ll be joining our diverse community of biologists, engineers, physicists and other specialities to deliver products which make a difference. As with all our consultants, you’ll be encouraged to contribute to all stages of development, from project proposal through production release with opportunities to blend leadership and practice, developing your technical and business skills.

TTP is an employee-owned business operating from pleasant surroundings on our own science park in Melbourn, South Cambridgeshire. Our working culture encourages entrepreneurship with a track record of spinning out successful businesses. We share ideas and collaborate to provide you the freedom to do your best work.

Requirements

The ideal candidate will have experience of designing and deploying systems which utilise machine learning. You will take a practical approach, pulling together third party components as well as building elements yourself. Ideally, you will have broad exposure to the entire ML development cycle: from data I/O, cleaning and preparation, to rapid ML code prototyping, iterating model designs and deploying and packaging code into client-ready products.

You will have a working knowledge of Python and current ML frameworks, such as Pandas, Scikit-learn, TensorFlow, Keras or PyTorch. Experience of building ML solutions for resource constrained situations would be a bonus.

It will be added bonus if you have experiences in working extremely large datasets, such as experiences in MySQL, Hadoop, Apache Spark and Tableau. However, this is not essential.

Your strong problem solving skills will rest on a basis of curiosity, imagination, and creativity. Ideally, you will have a demonstrable track-record in solving problem relating to not only technical challenges of developing ML, but the wider implications of your solution, such as user engagement and commercial relevance as well. You’ll have a solid understanding of engineering fundamentals and physical principles with the communication skills to put them into practice. You won’t be afraid to take the initiative.

You will have a 1st or upper 2nd class degree from a leading university in Computer Science, Mathematics, Physics, Engineering or a related subject.

Benefits

We also offer fantastic employee benefits including:

A generous employer pension contribution
Employee share scheme
Private medical insurance
Profit share
25 days’ annual holiday plus bank holidays
Life insurance
Discounts and memberships to local sports facilities and the theatre
Cycle to Work scheme
A comprehensive relocation package is also available, if applicable.",4.2,"TTP
4.2","Cambridge, East of England, England",-1,201 to 500 Employees,1987,Company - Private,Consulting,Business Services,$50 to $100 million (USD),-1
Scientific Data Management Architect,-1,"Organisation STFC
Organisation Detail Science and Technology Facilities Council
Reference Number IRC255417
Location Didcot See on Map
Salary £31305 - £47300
Date Posted 15 October 2020
Grade UKRI-Band E
Contract Type Fixed Term Appointment
Hours Full Time
Closing Date 08 November 2020
Interview Date
Apply Now

Description
Job Requirements
Additional Details
How to Apply

Brief Description

Salary: £31,305 - £37,028 or £38,969 - £47,300 per annum (dependent on skills and experience and inclusive of annual role-based allowance)
Grade: Band D or Band E
Contract Type: Fixed Term (4 years)
Hours: Full Time/Part Time (minimum 25 hours per week)
Closing Date: 8th November 2020

STFC’s Central Laser Facility (CLF) is the UK’s national centre providing scientists with an unparalleled range of state-of-the-art laser technology to carry out a broad range of experiments - from biology and medicine to material science and plasma physics. Our work is helping to inspire solutions to everyday problems and outstanding fundamental questions in science alike: from developing future energy sources and novel diagnostic capabilities for cancer and bone disease to recreating astrophysical events in the early universe in the laboratory.

CLF is now building a new laser centre - the Extreme Photonics Applications Centre (EPAC). This £81.2M facility will use lasers to drive novel particle and x-ray beams, opening up novel biomedical and industrial imaging capabilities. EPAC will be world-leading scientific infrastructure combining state-of-the-art laser, accelerator and data management technologies. We now have an exciting opportunity for a highly skilled data scientist or software engineer with relevant expertise to join the EPAC team on a fixed term basis.

Your main role will be to work with a team of scientists and engineers to design and deliver the data management system of EPAC. You will join the EPAC team in CLF, working with experts from Diamond Light Source and other STFC departments such as Scientific Computing and ISIS. Depending on your expertise, you will also have the opportunity to lead parts of the data management system.

This is an excellent opportunity for an experienced or emerging data scientist/engineer to develop further: the successful candidate will have a stimulating work environment with exposure to various cutting-edge technologies.

As part of UK Research and Innovation (UKRI), STFC offers a working environment and benefits package designed to provide an excellent work/life balance. For this opportunity we welcome applications on a full-time basis and we also offer a flexible working scheme. Further benefits include 30 days’ annual leave, 10.5 public and privilege days, Christmas shut down, a workplace nursery, an exceptional defined benefit pension scheme, and social and sporting activities and societies. STFC is an open and inclusive work environment, committed to promoting equality, diversity and inclusion.

Organization Description

UK Research and Innovation is a new entity that brings together nine partners to create an independent organisation with a strong voice for research and innovation, and a vision to ensure the UK maintains its world-leading position in research and innovation. More information can be found at www.ukri.org.
The Science and Technology Facilities Council is a world-leading multi-disciplinary science organisation, and our goal is to deliver economic, societal, scientific and international benefits to the UK and its people – and more broadly to the world.

The following criteria will be assessed at either shortlisting (S), interview (I), or at both stages (S&I)

Essential

Degree or equivalent experience in computer science, software engineering, or strongly related STEM subject with significant software development experience. (S)
Sound understanding of object-oriented analysis, design, and experience developing using object-oriented programming techniques and testing frameworks. (S&I)
Experience of using code repositories and issue tracking systems. (S&I)
Good verbal and written communications skills including the ability to explain technical concepts effectively. (S&I)
Good customer focus, agreeing requirements and project managing small projects to completion. (I)
Ability to work independently and within a dynamic, agile team environment. (I)
Ability to learn quickly and share love of new tools and technologies. (I)
Ability to take initiative and proactive attitude to problem solving with a thorough and logical approach. (I)

Essential criteria for Band E

To be considered for the higher grade you will meet all of the above essential criteria and will also have:

Expertise of software development using Apache Kafka or similar platform. (S&I)
Expertise in C# / Java / C/ C++. (S&I)
Expertise in Data Management Systems. (S&I)
Experience with Big Data in real time. (S&I)
Experience of heading up the software development process using modern agile techniques. (S&I)
Experience in technical leadership of software development projects. (S& I)
Ability to contribute to team motivation and established people management skills. (I)
Project/people management experience. (S&I)
Experience in requirements capture, analysis, and specification. (I)
Experience in working with customers. (I)

Desirable

Postgraduate qualification in Computing or STEM Subject. (S)
Experience with image processing. (S&I)
Experience with EPICS framework for industrial/scientific control systems. (S&I)
Experience of whole stack software projects. (S&I)
Experience of working in a collaborative development environment. (S&I)
Experience in working in large scientific facilities. (S&I)
Experience of development on multiple platforms (Windows, Linux, MacOS). (I)
Experience of GUI development using Qt or OpenGL. (I)
Experience of unit and system testing. (I)
Experience or understanding of automated testing and continuous integration tools such as Jenkins, Hudson, Travis or similar. (S&I)

UKRI supports research in areas that include animal health, agriculture and food security, and bioscience for health which includes research on animals, genetic modification and stem cell research. Whilst you may not have direct involvement in this type of research, you should consider whether this conflicts with your personal values or beliefs.

To enable us to hire the very best people we will conduct a full and comprehensive pre-employment check as an essential part of the recruitment process on all individuals that are offered a position with UKRI. This will include a security check and an extreme organisations affiliation check.

Polaris House is located next to Swindon Train Station and has excellent public transport links. Limited parking subject to waiting list.

Employee Benefits

UK Research and Innovation recognises and values employees as individuals and aims to provide a pay and reward package that motivates staff to the best of their ability. The reward and benefit package includes a flexible working scheme, an excellent Defined Benefit pension scheme, 30 days annual leave allowance and a number of other benefits.

Developing Talent

We are committed to developing employees in their roles throughout their career. Learning and development plans enable employees to continue their professional development through training and development opportunities such as e-learning, classroom training and on-the-job experiences. We encourage our employees to share their learning across teams and organisations.

Equal Opportunities

We strive to make decisions based on individual merit and ability. We welcome applications from all sections of the community and promote equality of opportunity in accordance with the Equality Act 2010. As holders of Disability Confident Employer status, we guarantee to interview all applicants with disabilities who meet the minimum criteria for the vacancy.

Online applications only. Please submit a covering letter and CV ensuring that the IRC reference is included in the filename description of each document uploaded. Please note that failure to address the above criteria or submitted without a covering letter may result in your application not being considered.

If you would like to receive this advert in an alternative format (e.g. large print, Braille, audio or hard copy), are unable to apply online or do not wish to create an account but would still like to apply for a specific role, please contact us by telephone on 01793 867000.

If you have not already logged into iRecruitment (including as a current employee) you will be re-directed to the login/register page by clicking the ""apply now"" button. If you don't have an account with us, by choosing to register you consent to UK SBS processing the information you provide as part of the Recruitment Service. You can select appropriate job alerts and notifications as part of your account preferences, and you are able to close your account (withdraw consent) should you wish to do so. Before starting your online application and inputting your personal details, please read our Privacy Notice which contains full details of how your information is processed once you have made an application.",3.6,"STFC
3.6","Didcot, England",-1,1001 to 5000 Employees,2007,Government,Research & Development,Business Services,$100 to $500 million (USD),-1
Data Engineer,-1,"QVC is so much more than a retailer. It’s a broadcast network. It’s an ecommerce leader. And it’s a great place to work! Come discover why QVC is like no other business in the world. Be part of a team that’s reimagining shopping, entertainment and social as one.

Job Description Details

QVC are looking at building a strong advanced analytics team across our international markets and one of these Key roles is The Data Engineer.

Your main responsibilities:

Creating data models, data pipelines, providing the right format and structure for the use case solutions

Perform data cleansing and feature engineering

Participate in early data modeling and testing for use case development

Identify relevant data sets by researching, interacting with business stakeholders

Collaborate extensively and frequently with data scientists and IT leadership

Ensure that data science team has access to the required data sets

Own the structural elements of data, e.g., data storage, data piping

Provide technical support related to data structures, data models and meta data management

Participate in early data modeling and testing for use case development, provide input on how to improve proposed solutions and implement necessary changes

Extract relevant data to solve analytical problems; ensure Data Scientist team has the required data

Interact with the business to understand all data requirements to develop business insights and translate them into data structures and data models

Collaborate extensively and frequently with data scientists and IT leadership
Liaise with IT on the infrastructure, data pipelines, and productionalization of models
Document data, data structure, and data models

Research best practices, technologies, tools, and trends

The ideal candidate will have:

A Master's degree (preferably with PhD) in computer science, statistics or another quantitative discipline
Expertise in advanced data management systems (such as Spark, Hadoop, Oracle DB, MySQL, PostGresQL, SQL Server, etc.)
Profound expertise in data modelling and structuring
Advanced SQL knowledge as well as knowledge of the limitations of SQL and where alternative tools and programming languages should be used
Knowledge of ETL tools and cloud technology stacks (AWS, GCP, Azure)
Experience in dealing with large amounts of data
Very good knowledge of at least one scripting language Python (preferred), R and also knowledge of container platforms such as Docker
Very good knowledge of data structures, data models and large data volumes
A detailed working method and the ability to critically analyse existing and new methods as well as to think conceptually
The competence to simplify work processes and to communicate complex concepts in an understandable way
Strong interpersonal, written and communication skills in (German- advantageous) and English
ability to work in a team

IND_HP

About Qurate Retail Group

Qurate Retail Group comprises seven leading retail brands — QVC, HSN, zulily, Ballard Designs, Frontgate, Garnet Hill, and Grandin Road — all dedicated to providing a ‘third way to shop,’ beyond transactional ecommerce or traditional brick-and-mortar stores. Globally, Qurate Retail Group is #1 in video commerce, reaching approximately 370 million homes worldwide via 16 television networks and multiple ecommerce sites, social pages, mobile apps, print catalogs, and in-store destinations. Qurate Retail Group is #3 in ecommerce in North America and #3 in mobile commerce in the U.S. (according to Internet Retailer). Qurate Retail Group combines the best of retail, media and social to curate products, experiences, conversations and communities for millions of highly discerning shoppers - bringing joy, inspiration and humanity to shopping. Qurate Retail Group also curates large audiences, across multiple platforms, for thousands of brand vendors. Headquartered in West Chester, Pa., Qurate Retail Group has 27,000 team members in the U.S., the U.K., Germany, Japan, Italy, France, Poland and China. For more information, visit www.qurateretailgroup.com. Qurate Retail, Inc. (NASDAQ: QRTEA, QRTEB) includes the Qurate Retail Group portfolio of brands as well as other minority investments.

EEO

As an equal opportunity employer, Qurate Retail Group is committed to a diverse workforce and is also committed to a barrier-free employment process. In order to ensure reasonable accommodations for individuals pursuant to applicable law, individuals that require accommodation in the job application process for a posted position may contact us at CareersUS@QVC.com for assistance.",3.3,"QVC
3.3","London, England",-1,10000+ Employees,1986,Subsidiary or Business Segment,"Department, Clothing, & Shoe Stores",Retail,$5 to $10 billion (USD),-1
Data Architect,-1,"Data Architect – Remote Based*
_Senior Consultant / Senior Data Engineer / Solutions Architect / Data Architect_
PLEASE NOTE - YOU MUST HAVE EXPERIENCE OF WORKING FOR A DATA ANLAYTICS CONSULTANCY TO BE ELIGIBLE FOR THIS ROLE, IF YOU HAVE NO EXPERIENCE OF WORKING IN A CLIENT-FACING ROLE OF THIS DESCRIPTION, YOU WILL NOT BE CONSIDERED.*
Are you an experienced data analytics professional from a consultancy background looking for an opportunity to progress within your career? Do you have what it takes to assist in growing a consultancy? Are you looking for further exposure to bleeding-edge technologies on brand new projects? If so, then read on.......

SearchData Group is looking for a client-facing Data Architect for a growing Data Analytics Consultancy based in central London. This is a hands-on consultancy role but also a senior appointment within the team and will be working closely with the UK Managing Director to grow the business in years to come. In order to do this, we’re looking for a unique blend of commercial and conceptual understanding with expert level technical delivery skills.

You’ll be joining a company full of like-minded professionals, people that retain that human touch lost in most larger consultancies. It’s also a company that is always looking to adapt to take advantage of emerging tech, it means they can provide better solutions to their clients and it keeps their consultants at the top of their game.
What we can offer*
This is an opportunity to help grow the business and become a leader within a relatively short amount of time. If you are looking for career progression within your next role, you should apply for this job,
A competitive basic salary of £100-120k
An annual bonus of circa 10% of basic salary
Industry specific training and certifications (Snowflake etc)
Flexible working hours
The option of homeworking
Pension
Key activities*
Designing and implementing an AWS infrastructure for a data platform
Delivering high quality data management, data visualisation and analytics solutions
Consult with clients on industry technologies, services and business benefits of data and analytics
Helping design and deliver cloud-based data and analytics solutions (AWS / Snowflake)
Meet with clients to understand the customers’ needs for data, analytics, BI and technology
Take ownership of project delivery and managing stakeholders’ expectations
Manage day-to-day client relationships and be a face of the brand
Take an active role in shaping our consulting offerings
Contributing to our methodologies and IP to accelerate client deliveries
Help shape project deliveries through requirements capture, user stories creation, and delivery planning
Delivery line of business analytics solutions using predictive and statistical modelling techniques
Requirements: *
As a technology agnostic company, technical requirements are always subject to change. We need an individual able to understand the core concepts and principles behind the tools in order to adapt their knowledge to the tech used at the time.
Experience on taking a lead role on client-facing projects, including working in close-knit teams
Experience delivering Cloud Based Data Solutions on AWS
Experience with Cloud Data Warehouse tools such as Snowflake or native AWS tools
Experience with visualisation software such as Tableau, Power BI, Qlik Sense
Experience with various Data Integration tools such as Alteryx, Informatica
Strong development background with experience in scripting, object oriented or functional programming language, etc. SQL, Python
Good knowledge of industry technologies, services and business benefits of data and analytics
Ability to build operational ETL data pipelines across a number of sources, and constructing relational and dimensional data models
Implementing data ingestion / presentation / semantics data layers as guided by BA/Data governance/conceptual data models
An understanding of DevOps principles, practices and tooling, CI/CD with Jenkins etc
For more information on this position and other Business Intelligence / Data & Analytics roles please visit our website www.searchdatagroup.co.uk

Job Types: Full-time, Permanent

Salary: £100,000.00-£120,000.00 per year

Additional pay:
Bonus scheme
Benefits:
Flexible schedule
Work from home
Schedule:
Monday to Friday
Experience:
Data Architecture: 3 years (Required)
working for a consultancy in a client facing role: 2 years (Required)
Work remotely:
Yes",-1,SearchDATA Group,"London, England",-1,-1,-1,-1,-1,-1,-1,-1
Genomics Data & Analysis Engineer - SEUIT,-1,"At AstraZeneca every one of our employees makes a difference to patient lives everyday.

AstraZeneca is a global, innovation-driven biopharmaceutical business that focuses on the discovery, development and commercialization of prescription medicines for some of the world's most serious diseases. But we're more than one of the world's leading pharmaceutical companies. At AstraZeneca, we're proud to have a unique workplace culture that inspires innovation and collaboration. Here, employees are empowered to express diverse perspectives - and are made to feel valued, energized and rewarded for their ideas and creativity.

Department Data & Analytics, S&EUIT

Science and Enabling Units IT is a global IT capability supporting Drug Research, Drug Development, Product & Portfolio Strategy, Medical Affairs, Finance, HR, Compliance, Legal and Global Business Services. We are organized around 7 key capability areas: Business Partnering, Solution Delivery, Architecture, Application Support, Data & Analytics, Change & Operations, operating out of sites across the US, UK, Sweden, India and Mexico.

Data & Analytics provides analytics and data insight services and solutions critical to the Data & AI/ML emerging strategy and mission of S&EUIT and AZ. D&A is organized into teams specializing in Information Architecture, Data Engineering, Visual Engineering, Knowledge Management, Data Science, Data Analysis and Information Governance.

Role

The role holder should deliver tangible and measurable value to S&EUIT stakeholders by taking a technical role in the delivery of both large and small genomics projects. They will undertake a range of activities including business requirements analysis, solution design, agile project leadership, analytics, testing and importantly software engineering itself for genomics data engineering solutions. The D&A Engineer will identify opportunities for innovation in their delivery, leveraging emerging technologies and methodology best practices externally and internally to improve delivery performance and team capabilities. They will work closely with D&A Info architects and D&A Engineering colleagues in Chennai in the delivery of high quality engineered D&A solutions. They will work with Genomics stakeholders, Genomics Data Scientists, Bioinformatics Scientists and with wider IT to deliver performance and cost optimised capabilities for the storage, retrieval, processing, query and analytics of genomics data to the business.

Key Accountabilities for the BI Information Architect
Provide D&A solution engineering (ETL, ODS, Marts, Hadoop, Reports) support to Genomics projects requiring D&A solutions, including design, implementation and testing activities.
Deliver cost effective, automated solutions in the genomics space to include orchestration of data processing pipelines, frameworks for advanced analytics of genomics data and tools for Data Scientists and Bioinformatic Scientists for data interpretation.
Deliver robust D&A solutions to support frequently asked business questions/analytical demands.
Innovate and test new technologies as they emerge with relevance to genomics and big data, including POCs, assessments and business case development
Support D&A solution evaluation and selection decisions; buy vs. build decisions, and early-phase project estimates which contribute to the creation of business case.
Support the development of engineering standards, roadmaps (1-5 years) and blueprints for S&EUIT, working closely with Solution Architects
Undertake business analysis and business process analysis as part of solution design process
Support solution development efforts through active contribution to the D&A software engineering effort (writing code).
Test and quality assess new D&A solutions, to ensure they are fit for release: code assurance, Unit and System Integration Testing, Data testing, release management control and support of UAT processes.
Maintain an on-going professional development in analytics and D&A technologies (and methodologies)
Ensure that business data and information assets are made available as data services and artefacts for consumption by the wider AZ enterprise.
Establish strong working relationships with S&EUIT stakeholder groups to develop an in-depth understanding of business priorities and early insight into changing needs in order to inform and shape demand.
Candidate Knowledge, Skills and Experience
Experience in D&A Engineering
Ideally some genomics domain knowledge and experience
BSc / MSc in Computer Science
Experience of working with a range of BI & analytics architectures: traditional warehousing, Distributed computing (Hadoop), NoSQL, virtualization, data streaming, container technology (Docker) etc.
Experience with & knowledge in key D&A tools used within AZ: Talend Data Services, Talend Metadata Manager, Talend Data Preparation, PostgresSQL, Microstrategy, Spotfire, Oracle OBIEE
Experience with and knowledge in AWS Cloud services: AWS Lambda, AWS DynamoDB, AWS IAM, AWS Cognito, AWS Cloud formation, AWS Aurora, AWS Redshift, AWS EMR/Hive
Experience with and knowledge in a broader base of open source distributed computing tools: Apache Spark, Apache Zookeeper, Apache Cassandra, Apache Solr, Apache Mesos, Clickhouse.
Software engineering (e.g. JavaScript, Node.js, AngularJS, Java, PERL, Python, Scala, PL/SQL, UNIX, XML processing, Github etc.).
Experience and familiarity with Information Architecture models and artefacts.
Experience of working with data scientists and their methods: understanding of how data needs to be prepared for use by data scientists. Experience with genomics data preferred.
Experience of delivering D&A Solutions within IT projects delivered through Agile and Waterfall methodologies.
Experience in Test Driven Development, Unit testing, Integration Testing, Continuous Integration and Continuous Deployment.
In addition, candidates will be expected to demonstrate the following Leadership Skills
Business Leadership ability to partner and collaborate across both IT and Science teams to inform on the best Information Architecture.
Influencing and innovation skills
Excellent communication and facilitation skills
Good written and verbal skills, fluent English.
AstraZeneca is an equal opportunity employer. AstraZeneca will consider all qualified applicants for employment without discrimination on grounds of disability, sex or sexual orientation, pregnancy or maternity leave status, race or national or ethnic origin, age, religion or belief, gender identity or re-assignment, marital or civil partnership status, protected veteran status (if applicable) or any other characteristic protected by law. AstraZeneca only employs individuals with the right to work in the country/ies where the role is advertised.",4.1,"AstraZeneca
4.1","Cambridge, East of England, England",-1,10000+ Employees,1913,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$10+ billion (USD),-1
Principal Software Engineer,-1,"Are you an experienced Software Engineer who wants to join a leading cyber team within an evolving and dynamic organisation?

Due to the success of a number of strategic Gloucestershire based programmes, we are growing our Software Development team with creative and ambitious Software Engineers. With a primary focus on Java, your experience will cover different technologies within an agile environment.

Different thinking for a Different world

Northrop Grumman is a leading global security company providing innovative systems, products and solutions to government and commercial customers worldwide. In Northrop Grumman’s rapidly growing UK Cyber and Intelligence business, we support our customers’ work to make the UK the safest place to live and do business, both physically and online.

Working with and alongside our customers, we use modern software engineering methods (Scaled Agile Development, DevSec Ops, Site Reliability Engineering, micro-service architectures) and cutting edge techniques (data science, Artificial Intelligence, Machine Learning) to tackle complex and challenging problems and deliver cost effective, reliable, supportable solutions.

Our solutions support complex analysis of substantial amounts of data, requiring state of the art ‘big data’, stream processing and cloud-based analytics, identifying and using ‘best of breed’ commercial and open source technologies and integrating them with our own software to meet customer needs quickly and efficiently.

At Northrop Grumman we pride ourselves on our ability to combine agile development with sound engineering and security practices to ensure that our solutions are robust and resilient; designed and built to start secure and stay secure against ever evolving cyber security threats. As well as designing for security, Information Assurance and legal / policy compliance, we actively assess products and services, identifying vulnerabilities and weaknesses that could be exploited by cyber attackers, and we create and run exercises to pit cyber security specialists against secure systems and each other.

We carry out research and innovation locally in the UK, with commercial and academic partners, and across our 85,000+ worldwide workforce.

How you will make a difference

For us, innovation is key and we have immediate opportunities for talented software engineers to join our team to help us develop and maintain a suite of applications. We are in a phase of rapid growth and there are opportunities to develop your career with us to meet your aspirations.

You will be helping us to solve our customer’s problems within an agile team. You will have opportunities throughout the Software Life cycle from requirements capture through to R&D(Research & Development), implementation, automation and test in a wide range of technologies.

As a Principal Software Engineer you will have had responsibility for the design and delivery of software projects; supporting business development; leading teams, line managing and mentoring colleagues; and working with customers. The systems you have worked on will follow the latest methodologies on requirements capture,software development; continuous integration, deployment and requirements validation. You will be used to working with a broad variety of frameworks and/or tool sets.

Key criteria required...

Experience in design, development, test and integration of quality software

Experience in Java and the use of object oriented design

Keen to learn a broad range of technologies on the Java stack

Experience of technical leadership

Also, we’d love it if you have experience of...

Agile/Scrum methodologies using tools such as Confluence and Jira

DevOps approaches and associated tools such as Ansible, Docker and Jenkins

Messaging and Routing Technologies such as NiFi and Kafka

Cloud-based architectures

Linux operating systems (Red Hat Enterprise Linux Server/CentOS)

Different programming languages, such as: Java, C, C++ and Python

Working with open source products

Supporting business development through contributions to customer proposals and R&D projects

You will enjoy a growing career as we work collaboratively to innovate the world of cyber security.

Additional information for your consideration...

You must hold UK Government clearances

Opportunities exist across the UK to enhance your career progression

Being a part of Northrop Grumman gives you the opportunity to use your skills to make a difference in our mission of enabling global security. Our company grows because of our employees' dedication and commitment to achieving our mission, something we always remember. In return for working for us you will have access to a benefits package that provides you with flexibility to balance your professional career with your personal life, health & well-being benefits, discount schemes, pension benefits and investment in your future development.

We are committed to equality and diversity in our workplace. Northrop Grumman provides equal employment opportunities to all employees and applicants without regard to an individual’s protected status, including race, ethnic origin, colour, nationality, national origin, ancestry, sex/gender, gender identity/expression, gender reassignment, sexual orientation, marriage/civil partnership, pregnancy/maternity, religion or belief, creed, age, disability, genetic information, or any other protected status or characteristic.",3.8,"Northrop Grumman UK
3.8","Cheltenham, England",-1,10000+ Employees,1939,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
Senior Software Engineer,-1,"SENIOR WEB APPLICATION DEVELOPER*
Softools is a small but very ambitious and fast-growing software company looking for fully remove devs in the UK. Softools is the developer of a best in class web based (Enterprise) Application Platform as a Service which enables non-technical business users to build and deploy sophisticated data driven web applications in a matter of hours delivering meaningful business outcomes.

At its core, the Softools Platform is an advanced web based Rapid Application Development environment to allow non technically skilled business users to build and deploy advanced data driven web applications in a matter of hours rather than weeks. Sold via a SaaS model and hosted on Microsoft Azure. Further information on Softools can be found at softools.net

You will be involved in the on-going design and development of the core platform which is based on a modern technology stack (technologies include: HTML5, JavaScript, C#, ASP.NET Core, SQL, MongoDB, Redis). You will be working closely with our CTO and Senior Developers.

Part of Softools’ unique proposition in the marketplace comes through leveraging the underlying technology platform to offer an attractive, modern and intuitive user experience, so a passion for cutting edge development tools and techniques in addition to having an eye for great user experience is a must.

You will be used to working independently, being set small tasks, and completing them to deadlines. Asking for help when required so that we can help you in delivery of features.

We require 10+ years in c# and ASP.net as this is a senior position. You must be capably of writing well tested software, so experience in TDD or being strong at unit testing is a must.

· C# (ASP.NET Core)

· JavaScript/TypeScript

· VueJS

· SQL Server / EF Core, Dapper

· MongoDB

· Redis

You should also have good interpersonal skills your English must be very strong.

There will be a 3 month probationary period for the role.

Job Type: Full-time

Salary: £38,419.00-£50,000.00 per year

Additional pay:
Bonus scheme
Benefits:
Flexible schedule
Sick pay
Work from home
Schedule:
Monday to Friday
Experience:
Software Engineering: 3 years (Preferred)
Work remotely:
Yes",-1,Softools,"Henley on Thames, England",-1,-1,-1,-1,-1,-1,-1,-1
Big Data Platform Engineer,-1,"G-Research is Europe’s leading quantitative finance research firm. We hire the brightest minds in the world to tackle some of the biggest questions in finance. We pair this expertise with machine learning, big data, and some of the most advanced technology available to predict movements in financial markets.

The role

Our business centres on forecasting financial markets. To achieve this, G-Research uses an ever growing amount of data and processing. The Big Data Platform team builds the primarily Spark and Hadoop-based platforms that are key to enabling these business-critical functions.

The team is responsible for cutting-edge, petabyte-scale clusters which underpin diverse use-cases such as quantitative research, risk analysis and cyber security. The team works closely with various development teams, quantitative researchers, IaaS Engineering, other PaaS teams, and security. We are keen to be close to these users, understand their use-cases and challenges, and help them get the most out of our platforms.

At such a scale, automation is key, and with this role there is a significant focus on configuration management, orchestration, Infrastructure as Code and CI/CD. In addition to this, G-Research are embarking on a transformational journey in how we delivers infrastructure using open source technologies. We are investing heavily in a hybrid cloud platform on which to build the next generation of applications and distributed platforms and deliver development efficiencies. This provides a unique opportunity to re-invent how we operate our big data ecosystem, and continue to modernize and improve our tooling and practices.

Key responsibilities of the role include:
You will help shape and engineer the big data platform, ensuring it is scalable, stable, performant, and easy to use and maintain
Help our users work at pace and get the most out of the platform by providing metrics, documentation, and self-service infrastructure
Define automation standards, frameworks and reporting
Manage a complex ecosystems of distributed technologies working together
Enable the company to expand its big data capabilities using Infrastructure-as-Code principles
Build infrastructure automation
Develop Python libraries
Develop CI/CD pipelines
Use your advanced troubleshooting skills to diagnose and fix problems
Who are we looking for?

The successful candidate will be an enthusiastic Platform Engineer who is able to build an automated, scalable, reliable and high performing Big Data platform. They will work well as part of a team, but also be able to propose and run your own projects and improvement initiatives.

The team has a mixed set of skills that complement each other. Typically, team members will have strong abilities in one of infrastructure automation, Big Data technologies or software development, and be keen to expand their expertise in other areas.

The ideal candidate will have strong skills and experience in at least one of the following:
Automation tooling: exposure to a majority of the following tooling or the ability to quickly pick-up new tooling:
Ansible
Kubernetes
Jenkins (CI/CD)
Linux OS core principles, performance and tuning
Cloud technologies, e.g. Terraform, AWS, OpenStack
Big Data technologies: exposure to a number of the following big data components, including building, tuning, troubleshooting clusters:
Hadoop ecosystem, e.g. HDFS, Yarn, Zookeeper, Hive
Batch and streaming job frameworks, e.g. Spark, Storm, Flink
NoSQL databases, e.g. HBase
Security components, e.g. Kerberos, SSL certificates
Cloud technologies, e.g. AWS EMR, CDP Public Cloud
Coding:
Experience with scripting or programming languages, Python is preferred, but capability in any high-level languages is acceptable
Understanding of unit testing
Who are we looking for?
Highly competitive compensation plus annual discretionary bonus
Informal dress code and excellent work/life balance
Comprehensive healthcare and life assurance
25 days holiday
9% company pension contributions
Cycle-to-work scheme
Subsidised gym membership
Monthly company events
Central London office close to 5 stations and 6 tube lines",4.8,"G-Research
4.8","London, England",-1,501 to 1000 Employees,2001,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Senior Data Engineer,-1,"Important note:
To our wonderful friends and followers around the world, Jagex is not pausing its search for the most talented people to join its ranks. We’re a successful, robust and growing business, after all.

In light of the current situation concerning coronavirus, we have already made changes to the way we recruit, and of course are mindful of following all necessary processes to ensure the safety of our staff and anyone we might come into contact with.

Jagex has switched to working almost entirely remotely, and in line with that our recruitment and selection process has moved to an entirely remote one with video calls being the preferred method of interview.
Our hiring managers are engaged, we are well-prepared and we sincerely look forward to talking to you soon. Our team of expert recruiters will be in touch with you to talk you through the process and changes and what to expect.
So, don’t delay, get that application in today!

Company Overview:

A leader in creating deep and engaging experiences on PC and mobile, Jagex was founded in 2001 and is today one of the UK’s biggest and most respected video game developers and publishers.

Famed for its flagship MMOs RuneScape and Old School RuneScape, Jagex has welcomed more than 260million player accounts to its world and created a $1bn lifetime franchise revenue. Today the RuneScape franchise exists beyond running games in live operations; our titles are living games that connect and inspire millions of players, with content and experiences both inside and outside of inexhaustible game worlds.

Both RuneScape and Old School RuneScape, on PC and mobile, offer ever-evolving, highly-active worlds and our community-focussed development ethos empowers players to have a real say in how each game is shaped.

Jagex is expanding and extending its portfolio with fresh franchise titles, new IP and, in 2018 launched Jagex Partners, delivering third-party publishing and operational services exclusively for the living games of the future.

Jagex employs more than 400 people at its Cambridge headquarters and is on the hunt for talented people to work across the business to help the company to achieve yet another year of record growth and player satisfaction.

Job Purpose:

Analytics, Data Sciences & Engineering (ADSE) is the heart of player, product, and business insights on our titles. This role reports to the Senior Director of ADSE and is one of the most critical roles we have as it acts as both a part of the game development team and as a centre of growth for our Studio in unlocking insights about our players and our business. The person in this role is most successful when they can merge technical skill with user needs to drive incredible player experiences while guiding and growing a team of rock stars to grow, learn and succeed. If that’s you, we should talk!
The data engineering team will deliver and manage a data stack that will fuel the whole studio on insights for our games, players and overall business. Collaborate with internal and external teams and stakeholders to develop and deliver data solutions and capabilities that integrate with online gaming technology.
Key Duties Include:
Advance and maintain our core data infrastructure and ETL framework.
Develop and extend our core tools, frameworks, and Kubernetes-based platform.
Develop data sets to support reporting and exploratory analytics.
Aid in performing migrations from existing systems to new cloud stacks.
Optimise data structure and system performance for best cost / usage ratio.
Work with game and tech development teams on data flow and integration points.
Work cross functionally with analysts to ensure data integrity and velocity.
Assess and recommend available and new big data technologies.
Contribute to post implementation reviews demonstrating success.
Essential Requirements:
Expertise in Python, SQL, shell scripting, and databases.
Expertise with container technologies and container orchestration frameworks, for example, Docker and Kubernetes, and their offerings on Google Cloud Platform, AWS, and Azure.
Expertise with using IaC technologies for automated infrastructure deployment, for example, Terraform and AWS CloudFormation.
Great team player, with highly developed technical skills with unflagging energy and focus
Capability to drive initiatives and articulate their value to engineers, partners, and executives.
Experience delivering data products from conception to delivery.
Excellent personal organization, ability to prioritize, proactively drive projects to completion.
Good communication skills (written/verbal).
Skilled at designing and directing elegant ETL pipelines.
Familiar with data vault modelling, Agile methodologies, and data governance methods.
A desire to remain technically capable and an expert in current technologies.
Company Benefits:

- Flexible Working
- Bonus Scheme
- Private Health Care
- Gym Membership
- Generous Pension Contributions
- Life Insurance
- Free Cycle Repair
- Income Protection
- Dental Plan
- Free Fruit and Drinks
- Subsidised Canteen

Feel like you fit this role, but don’t meet all the requirements? We strive for fresh perspectives, so as long as you can demonstrate how your attitude and other abilities might make up for any gaps we would welcome your application!
Jagex are an equal opportunities employer and positively encourages applications from suitably qualified and eligible candidates regardless of sex, race, disability, age, sexual orientation, gender reassignment, marriage or civil partnership, pregnancy or maternity, religion or belief.",3.4,"Jagex
3.4","Cambridge, East of England, England",-1,201 to 500 Employees,2001,Company - Private,Video Games,Media,$100 to $500 million (USD),-1
Lead Data Engineer,-1,"A Lead Data Engineer will join the Data and Analytics team to lead the Data Engineering function. The Lead Data Engineer will be pivotal in further enhancing the Data Lake and implementing streaming technologies, Data services (data pipelines) and other Big Data platforms within AWS and Databricks.

The role will be focused on continued building of further data pipelines within the Data Lake to start with and delivered in an iterative fashion. The Lead will directly manage several Data Engineers and is responsible for continuing a high engineering and development standard ensuring correct use of tools, sustaining a secure platform, and ensuing logging, monitoring, TDD, BDD are further improved upon. The Lead will work closely with Data Science focused projects and other Analytics efforts including working with the Business Intelligence team.

Requirements

What you'll be doing:
Technical ownership, Developing and supporting the Data Lake and overall data architecture within AWS and Databricks.
Designing, Developing and supporting ELT/ETL landscape within AWS and Databricks.
Designing, Developing and supporting Streaming/Event sourcing services.
Designing, Developing and supporting Big Data platforms with Databricks within AWS.
Designing, developing and supporting data services within AWS.
Assisting the Data Science and Analytics functions where required.
Line management duties, leadership and championing the Data Engineering function within Tech and across the business.
About you:
You are a passionate and expert Data Engineer having excellent technical skills and a natural aptitude for data. Expert Data Engineer proficient with Big Data Technologies, Data Lake and streaming fundamentals.
Extensive experience within Spark
Extensive experience with AWS cloud services
Experience with wider distributed computing, Big Data technologies (e.g. Hadoop, NoSQL dbs, Kafka, etc).
Experienced software development/engineering skills
Expert in Scala
Proficiency with Python, Java, extensive experience in database development across a variety of platforms.
Containerisation expertise – Docker, Kubernetes
Experience with streaming technologies and concepts.
Extensive experience with REST web services and APIs
Extensive experience in CI/CD principles and DevOps methods
Extensive experience and knowledge of Test automation including TDD and BDD

We lead the way, moving our industry forward, and we are always looking for talented individuals to come in and inspire the world with us. Matchesfashion.com is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for our people.",2.7,"MATCHESFASHION
2.7","London, England",-1,501 to 1000 Employees,1987,Company - Private,"Department, Clothing, & Shoe Stores",Retail,$50 to $100 million (USD),-1
Data Engineer,-1,"Trouva is one of the fastest growing tech businesses in Europe (TNW Tech5), one of Wired Magazine's hottest European Startups and is 1st in the prestigious Startups 100 Index, ranking the UK’s best high growth startups.

A software-enabled marketplace, Trouva brings customers beautiful homewares from the best independent boutiques around the world. We know that unless people happen to be in the right place, at the right time, that perfect piece can be impossible to find. All too often, it’s sitting in a shop somewhere they don’t even know about yet. That’s where we come in. Trouva was founded to make it easy for customers to discover just the right thing for them... wherever in the world it may be hiding.

We’re using cutting edge technology to harness the expertise of the best bricks-and-mortar shops from Shoreditch to Stockholm, scaling their offering online to connect with a global customer base seeking unique, hard-to-find homewares. At Trouva, we envision a world where beautiful offline inventory is easily available to all.

We’re lucky enough to be backed by world leading investors whose successes include ASOS, Farfetch, and Dropbox (Index Ventures, Octopus Venture and BGF), with Angel Investors including current and former C level execs from Just Eat, Google, eBay & Deliveroo. We’ve been covered by the likes of Forbes, Vogue, The BBC, TechCrunch and Sky News and have won Emerging Retailer of the Year at the Retail Week Awards, as well as being recognised by the likes of Retail 100, Maserati 100 and Technation’s Future Fifty.

We’re growing incredibly quickly and are looking for exceptional people to join the Trouva family. Get a feel for what we're about through our Instagram or vision page.

The Opportunity

You will be part of the newly formed Data & Analytics team which combines the three core Data disciplines, Engineering, Analytics and Data Science. As a Data Engineer you'll actively take part in expanding our current stack and building new ETL processes. You will get to experience the opportunities and challenges of working with data streams that originate from different sources, the standardisation process and the automation triggers that are required to keep the data clean.

Collaborating with the wider Product team, you will help us define new processes and expose our data through APIs allowing the rest of the business to consume it and discover actionable insights.

At Trouva we have to constantly evolve and iterate over our data architecture and processes to match the fast growing needs of the business, and as part of that you will have the chance to work with different technologies and tools and to actively help shape the vision for Data Engineering.

Requirements
2-3 years of experience as a Data Engineer
Good experience with SQL (we’re a PostgreSQL house, but dialect experience is flexible) for Data Interrogation and Manipulation
Experience using Python to deploy Data Functions (End to End ETL Processes, Integration with API/Non-API data sources, Data cleansing using libraries such as Pandas/Numpy, Writing effective tests)
Ideally experience working in the AWS Stack (e.g. RDS, EC2, Lambda, S3) - and an inquisitive mindset for adopting other technologies such as AWS Redshift and Data Streaming
Keen to communicate and work closely on fast-moving projects with other departments ranging from other Developers to Product Specialists
Bonus: Experience with general Database Monitoring and Performance Tuning practices
Bonus: We use Airflow for our ETL workflows - any experience in that is a nice-to-have!
Benefits
Competitive salary and share options in one of Europe's most exciting start-ups. Equity is very important to us - we want you to be a shareholder in the company so you are part of the upside if we're successful together
25 days + public holidays
Flexible, remote working policy
Macbook Pro and Bose Noise cancelling headphones as standard issue, and any other tech you need to get the job done
Regular team events where we celebrate our success and people
Unlimited staff discount on all Trouva products and a Trouva gift card to get something awesome for your desk",3.5,"Trouva
3.5","London, England",-1,51 to 200 Employees,2015,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
"Software Engineer (C#, Python, Machine Learning)",-1,"The company*
CloudTrade offers a unique data capture service. We extract data from application generated documents and process that data straight into our customer's back-office system.

Our patented automatic data-capture technology processes millions of complex documents every month. Straight into a business’s back-office system, without human intervention.
The job*
Our system currently requires a template to be written for each new document format that we process, describing how to locate the required data on the document. We're moving towards using machine learning to generate these templates automatically. For a more detailed description of the project, see the link below:

https://www.cloud-trade.com/2020/09/22/project-grandalf-machine-learning-and-hybrid-solutions/
Who we’re looking for*
We're looking for someone who already has some commercial C# experience, and preferably some Python too. You'll also need to work in Prolog, but as this is a fairly exotic language we'd expect to teach you on the job.

The project you'll be working on has machine learning at it's heart, but we don't have a wealth of existing machine learning expertise in the company. We'll need to you be capable of independent research, and previous experience and interest in machine learning would be highly advantageous.

We've also invested heavily in moving to a cloud-based microservices architecture. While not essential, knowledge of relevant technology such as Azure, Kubernetes, AMQP etc. would be useful.

You will be expected to have a strong voice and actively contribute to the design and direction of the product. We're looking for someone who is passionate about technology, and really cares about making a difference to the company.
Required experience*
1+ years commercial experience in C# or similar languages.
Desirable Skills*
Python
Prolog
SQL
TensorFlow
RabbitMQ
Docker
Kubernetes
Natural Language Understanding
Recurrent Neural Networks
Deep Learning
Test Driven Development
Agile
The benefits*
Our development team is a small, tightly knit group, and you will have the opportunity to make a real difference within the company. We are also experiencing a time of exciting growth, so you will experience the company changing around you at a rapid pace.

We are also firm believers in keeping at the cutting edge of technology. You will have lots of opportunities to work on the latest and greatest, and will be encouraged to embrace new technology as it becomes available.

There will also be excellent opportunities to progress into more senior or diverse programming roles within the company as you gain more experience.

Job Type: Full-time

Salary: £25,000.00-£32,000.00 per year

Benefits:
Casual dress
Company pension
Flexible schedule
Sick pay
Work from home
Schedule:
Monday to Friday
Work remotely:
Temporarily due to COVID-19",-1,CloudTrade,"Newcastle upon Tyne, England",-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Data Engineer

Experian

Grade D

Location: Remote, Midlands

In Experian Digital, we create powerful tools that allow our clients to gain insights into their customers and markets enabling safer and lower risk decisioning. We enable tooling around affordability and safe lending which ultimately helps end users. This section of the business is growing and we are in the unique position to collaborate directly with large clients in banking who are eager to consume our services, as well as combine Open Banking and other data with advanced class-leading data science products and classic bureau data.

The role

The role represents a rare opportunity to be an important part of connecting and delivering Experian’s Data Science capability where it is needed, collaboratively developing bespoke systems and pipelines for our teams and our clients for a variety of purposes such as enabling data scientists consuming models in client organisations, batch processing hundreds of thousands of customers for analytics purposes, and connecting our services to marketplaces for easy consumption.

You will be working with both Operations and Data science teams to connect services and products to data sources, with a focus on creating and automating the best data pipelines for users, and doing so in a safe way handling sensitive data in a regulated environment.

You will be participating in the development of cloud and code based solutions to move data through systems, debugging applications and configuring systems with client technical teams.

As a Data Engineer your key responsibilities will include
Discovering the most effective way of connecting data to services
Engineer effective pipelines pragmatically, automating to a high quality what can be re-used, and creating safe but disposable code where it cannot.
Leverage your knowledge of Data Science and Engineering tooling and Cloud vendor tooling to discover opportunities in how we use Data Science products.
Collaborate with and support colleagues to aid their continuous improvement and your own
Document services and operational procedures
Engage and collaborate with product owners and stakeholders within Experian, and technical staff at clients.
What makes this role special

Affordability is a key topic in this challenging environment and as a provider of data services primarily around banking, affordability, and finance to other businesses we’re positioned to leverage Experian’s strong partnership with banks to make a genuine difference to real people in the country, and eventually internationally. Experian Digital regards Data Science as strategically important and is in a position of strong growth, and as such a positions in this team can achieve a high profile for performing individuals.

Could this role be for you?

Skills and experience
Demonstrable experience with a scripting language, preferably Python, or equivalents (Ruby, Bash, Powershell or others)
Familiarity with Databricks or Spark
Some ability with cloud automation, such as AWS CloudFormation, Hashicorp Terraform, Azure ARM scripts etc.
Good communication skills and collaborative spirit
Desirable skills
Experience with development in, or operation of Python
Multi-cloud experience, AWS, Azure and GCP, we go where our clients are.
Interest in Docker, Kubernetes, or containers
A solid understanding of agile best practices, and testing processes


Why choose us?

Our colleagues’ health and wellbeing is a top priority for us, that’s why our reward, benefits and wellbeing programmes are designed so you can come to work feeling your very best self. Our benefits focus on health, money and lifestyle so you can tailor your benefits to your own personal needs. Whether it’s your physical and mental wellness, getting to work or planning for the future, we have a range of flexible options to have you covered!

Who are Experian?

We unlock the power of data to create opportunities for consumers, businesses and society. At life’s big moments – from buying a home or car, to sending a child to university, to growing a business exponentially by connecting it with new customers – we empower consumers and our clients to manage their data with confidence so they can maximize every opportunity.

For more than 125 years, we’ve helped consumers and clients prosper, and economies and communities flourish – and we’re not done.

Our 17,000 people in 37 countries believe the possibilities for you, and our world, are growing. We’re investing in new technologies, talented people and innovation so we can help create a better tomorrow.

#LI-AB1

*",4.1,"Experian
4.1","Nottingham, England",-1,10000+ Employees,1980,Company - Public,Financial Analytics & Research,Finance,$2 to $5 billion (USD),-1
Software Engineer - Career Comeback opportunity,-1,"Funding Circle is excited to launch its very own Career Comeback opportunity! The purpose of this is to support talented professionals in re-joining the workplace after an extended career break.

Are you in search of some guidance, support, and knowledge to really help you go further?

Funding Circle is here to offer that, and help you regain traction within the workplace. We believe everyone is made to do more, and that’s why we are launching this scheme across different areas of our business.

You are a good fit for our opportunity if you:

Have been on a career break for approximately 6 months to 2 years
Would like to return to work on a full-time basis
You are a good fit with our values (Be Open, Stand Together, Live The Adventure, Make It Happen, Think Smart)
You have past experience and skills that match the opportunity you are applying for
Can provide evidence of your right to work in the United Kingdom

Your Team:

The driving force behind the world’s leading platform for small business lending is our engineering team. We are a diverse group from more than 25 different countries and cultures who bring together a wide range of backgrounds and experience (from music to aerospace engineering).

We are focused entirely on using technology to provide the best experience for our borrowers and investors. We are doing this by building elegant, sustainable, and scalable solutions that can be applied globally. We work in small agile teams practicing continuous integration, TDD, and are no strangers to pairing as we believe that working together is smarter than sitting in silos.

Here is a bit about the role:

Collaborating as part of an agile cross-functional team, as well as technology chapters
Building great user experiences for customers
Delivering innovation through software to automate processes that enable Funding Circle to operate at scale
Using Clojure, Kafka, React and Ruby currently and built entirely on AWS

About You:

This role requires someone who has;

Strong experience in at least one major coding language (E.g. Java, Javascript, C#, Python, Clojure, Ruby, Scala, Go)
Strong fundamental programming skills (data structures, algorithms)
Familiarity developing on Unix/Linux
Excellent communication skills, both written and spoken
Knowledge of Agile, Scrum, BDD, TDD, and CI/CD
An interest or experience in any of Functional Programming, Distributed Systems or Event-Driven Architectures

In addition, you will receive:

An opportunity to join a first-class team on a full-time basis from day one!
A buddy to help navigate your way in and around Funding Circle.
Real-time on the job training across our tech stack and products. We care about your development as you rise through your career at FC!
Eligibility to our full compensation and benefits program just like all of our full-time employees - you are one of us!
A great working atmosphere with lots of opportunities to bond with colleagues at regular social and volunteering events.
Flat hierarchies and a strong team spirit - our talented, diverse team values passion and drive above hierarchies and loves to celebrate success.

Why join us?

We’re gearing up for our biggest chapter yet – and it’s being driven by everyone.

We think of ourselves as the career launchpad. A place to develop yourself, fast. Real work. Real experience. Real opportunities to collect skills. Think big remits and huge ownership to make great things happen.

Our vibrant culture is built around potential and creating a place where you can really be you. We keep it agile and open. All voices heard. Because we believe great ideas come from everywhere.

If you show skill and are willing, we’ll back you all the way. This is the place for you to build something incredible.

It’s in our differences that we find our strengths.

We celebrate and support the differences that make you, you. So we’re building a culture where difference is valued. We’re proud to be an equal opportunity workplace and affirmative action employer. We truly believe diversity makes us better. We particularly encourage applications from applicants from underrepresented backgrounds. We welcome applicants who may want to work flexibly.

Want to Build The Incredible? We’d love to hear from you.",3.8,"Funding Circle UK
3.8","London, England",-1,501 to 1000 Employees,2010,Company - Private,Lending,Finance,$50 to $100 million (USD),-1
Data Engineer,-1,"Title: Data Engineer
Location:

Windsor, GB

Tetra Laval is a privately held multinational corporation with headquarters in Pully, Switzerland, providing innovative systems that improve the efficiency, quality and safety of food production, processing and packaging. Tetra Laval International (TLI) is responsible for the central corporate functions for the group, such as Treasury, Corporate Finance, Reporting, Risk management, Customer Finance & Tax. TLI has staff based in Switzerland, the UK, the Netherlands, and Singapore.

Data Engineer

We are embarking on a major transformation to become more data driven and we are looking for an enthusiastic Data Engineer with 3 to 4 years industry experience to help drive that change. This opportunity will embed you directly with decision makers and an experienced team of data specialists.

The position will be based in Windsor, UK.

What you will do

You will apply your skills and expertise in data engineering to implement automated and scalable data pipelines and support the development of a robust data platform architecture that will support TLI’s data driven business transformation journey.
You will work with business analysts and data scientists to discover opportunities for data acquisition in support of real-world business problems.
You will work with large internal operational datasets and leverage on external data sets to enrich that internal data.
You will recommend ways to improve data reliability, efficiency, and quality.

Who you are

We believe you have:

Experience working with a variety of data sources i.e. API’s, server logs, web scraping, flat files, databases, and building automated and scalable data pipelines.
Working knowledge of ETL frameworks and the Microsoft SQL Stack, including SQL Server, SSIS and SSAS.
Solid understanding of data structures, common methods in data transformation and data quality procedures and practices
Strong working knowledge of data modelling/data warehouse design & implementation
Proficient in programming languages such as Python or other scripting languages and programming design patterns
Demonstrable experience working with data visualisation tools such as Power BI/Tableau
Demonstrable experience working with on premise and cloud-based architectures
BSc/MSc in Computer Science, Computing, Data Science, Engineering, or related fields
Work on his/her own initiative, manage time effectively and work accurately and quickly under pressure
Have excellent written and spoken communication skills
Proactive attitude to learning and self-development

What we offer

Variety of exciting challenges with ample opportunities for development and training in a truly global landscape.
Culture that pioneers spirit of innovation where our engineering genius drives visible result.
Equal opportunity employment experience that values difference and diversity.
Market competitive compensation and benefits with flexible working arrangements.

Tetra Laval International is committed to protecting its employees, customers and you, our candidates. We are working towards completing all or most of the steps in the recruitment process for this position by virtual means and further information will be provided as part of the recruitment process.

Apply now!

If you are inspired to share our responsibility of protecting food to protecting the planet, please submit your resume in English through our careers page on www.tetrapak.com

The Tetra Laval Group consists of three industry groups, Tetra Pak, Sidel and DeLaval, all focused on technologies for the efficient production, packaging and distribution of food.",4.1,"Tetra Pak
4.1","Windsor, South East England, England",-1,10000+ Employees,1943,Subsidiary or Business Segment,Industrial Manufacturing,Manufacturing,$10+ billion (USD),-1
Data Engineer,-1,"Core Group are currently looking for 2 x Data Engineers in Birmingham.

Must have: ECS/CSCS, Tools and PPE.
Duties: Installing cat6 data cables, testing and termination.
Duration: 6-8 weeks work.
Paying: £140 per day

Please call 01628308282 for more info.",5.0,"Core Group Ltd
5.0","Birmingham, England",-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Principal Fire Safety Design Engineer,-1,"Description

We are seeking to recruit a Principal Fire Safety Design Engineer to join our Rail building services team based in London. Experience in delivering building services projects within rail is a must.

About Arcadis:

At Arcadis, we never lose sight of what’s most important. Because look beyond our projects and programmes and you’ll see it’s about human stories. From remaking public spaces that bring people together, to making cities easier to navigate, we’re focused on making an impact where it matters most – and improving quality of life.

It’s a big challenge. And why we need people committed to bringing their best, who deliver on their promises. People who value different perspectives, build sustainable relationships and dare to shape the future. People who seize the experiences available to transform their world – and the world around them.

It’s a shared goal amongst 27,000 Arcadians. And one we can only achieve by working together and applying our skills and expertise across design, consultancy, engineering, project and management services. It’s how we’ll find solutions to our clients’ most complex challenges. And how we’ll deliver exceptional results, today and tomorrow.

About The Role:

Reporting to the Associate Director, you will provide the technical solution for assigned projects ensuring successful delivery. As we operate in such a diverse marketplace, we can safely say that you will gain an experience of working on a wide and varied portfolio of projects which will enhance your skills and test your technical knowledge.

You will be responsible for assisting in the delivery of project to meet budget, time-frame and quality targets, meeting or exceeding client expectations, promoting and marketing all facets of Arcadis’ services during interfaces with clients and other sectors and disciplines, contributing towards the achievement of the divisional business plan and to build networks within the industry.

We will ensure that we offer personal development which will allow you to progress your career and give you the best possible chance of success.

Responsibilities:

To undertake fire system design on UK and international projects with a good understanding of regulatory requirements and relevant standards

Delivery of allocated technical assignments including authoring Fire Strategy, Fire System design including detection, alarm and hydrant

To undertake consultancy assignments and providing advisory support to Clients and contribute to formulation of design concepts and approaches.

To undertake design checks and reviews before issue

Provide technical leadership to the assigned project/s

Maintain good relationships with client’s key representative, and contribute to the marketing/networking of the company to potential customers

Contribute to the overall team development and growth through strategic inputs, bringing market intelligence, skill development, mentoring and bringing required talent

Design management, team leadership / mentoring and client relationship skills

Rise/promote the level of technical excellence relating to fire engineering within the team

Ensure consistent high-quality design delivery

Help generate repeat business from both internal and external client

Cross sale Arcadis wide capabilities to the clients

Essential Experience:
Extensive fire safety design experience in design consultancy environment
• Proven experience in authoring Fire Strategy including balance recommendation of passive and active provisions to achieve compliant and safe solution
Hand-on experience and knowledge of Fire System design including detection, alarm and Fire hydrant. The sprinkler and gaseous system design experience will be added advantage
Good understanding of the legislations (incl FSO, Building Regulations etc), London Underground, Network Rail and British Standard including BS EN 9999, BS 5839, BS 5306, BS EN 12845, etc
Experience in working with the rail environment is essential. Aviation and data centre experience will be added advantage
Be a competent user of office IT and design tools i.e. NBS/NES, AECOSim, Revit etc
Stakeholder management skills and a can-do attitude
Able to make decisions, act on own initiative and operate in proactive way
Capable of working under pressure and on several projects simultaneously
Experience of working in a multidisciplinary environment and bring value from assimilated wider knowledge of other disciplines
Able to see wider picture outside own discipline in project and business context, is essential
Financial awareness is essential for the role
Good report writing skills, experience of making presentations to and attending meetings with clients is essential
Able to understand and express technical concepts in written and verbal language
Excellent verbal and written communication skills
Be willing to be mobile, travel within the UK and abroad for project related work when required
Why Arcadis?

At Arcadis, you’ll have the opportunity to build the career that’s right for you. Because each Arcadian has their own motivations, their own career goals. And, as a ‘people ﬁrst’ business, it’s why we’ll take the time to listen, to understand what you want from your time here, and provide the support you need to achieve your ambitions.

Wherever you join us, you can look forward to a competitive reward package that includes an attractive starting salary, opportunities for career development and being part of a sociable community. We have a performance-related bonus scheme and an employee recognition scheme. Other beneﬁts include membership fees to join your relevant professional body, employer contribution pension scheme, ﬂexible working and a flexible holiday scheme.

We believe that by working together diverse people with different experiences develop the most innovative ideas. Equality, diversity and inclusion is at the heart of how we improve quality of life and we work closely with our people across six ED&I Workstreams: Age, Disability, Faith, Gender, LGBT+ and Race. A diverse and skilled workforce is essential to our success.

Qualifications
Qualifications:

BEng/BSc Degree qualified in Fire / Electrical / Mechanical / Building Services Engineering; MEng / MSc preferred

Chartered Engineer (CEng)",3.9,"Arcadis
3.9","London, England",-1,1001 to 5000 Employees,-1,Company - Public,Construction,"Construction, Repair & Maintenance",Unknown / Non-Applicable,-1
Data Engineer,-1,"The On-Site Group are looking for x1 data engineer for work in Buntingford starting ASAP

Hours: 7am-4pm

Pay rate: £145/day

Duties:
Prepping panels
Working with PCH Corning Panels
Required:
ECS card
Experience with PCH Corning Panels
An up to date cv
2 checkable references
If you are interested in this position then please call Harry on 0203 637 6576 and apply below

Contract length: 6 months

Job Types: Full-time, Temporary, Contract

Salary: £145.00 per day

Schedule:
Day shift
Experience:
PCH Corning Panel : 1 year (Required)
Licence:
ECS (Required)
Work remotely:
No",1.0,"The On-Site Group
1.0","Buntingford, England",-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Software Engineer (Core Services),-1,"Who are we?

We want to help small business win. That’s why we’re here.

We connect small business owners to investors – to create jobs, help families and power economies – because we believe that people are made to do more. And we want to help them.

So, we created the leading online marketplace for small business loans. Our investors have lent £9.8 billion in 130,000 loans to 90,000 small business owners. In a single year, we unlocked 115,000 jobs and contributed £6.5 billion to the global economy. There’s never been a better time to join!

Be part of the team that changes everything. Let’s build the place where small businesses can get the funding they need to win and leave a legacy behind, forever.

This role sits within the “Tech and Data” teams. The drivers behind our platform – brilliant people working together to create, code, and build the next game changers.

What will you be doing?

The driving force behind the world’s leading platform for small business lending is our engineering team. We are a diverse group from more than 25 different countries and cultures who bring together a wide range of backgrounds and experience (from music to aerospace engineering).

We are focused entirely on using technology to provide the best experience for our borrowers and investors. We are doing this by building elegant, sustainable, and scalable solutions that can be applied globally. We work in small agile teams practicing continuous integration, TDD and are no strangers to pairing as we believe that working together is smarter than sitting in silos.

Day to day this role will include:

Collaborating as part of an agile cross functional team, as well as technology chapters
Building great user experiences for customers
Delivering innovation through software to automate processes that enable Funding Circle to operate at scale
Using Clojure, Kafka, React and Ruby currently and built entirely on AWS
Supporting our production systems

Are You

This roles requires someone who has:

Experience in at least one major coding language (E.g. Java, Javascript, C#, Python, Clojure, Ruby, Scala, Go)
Fundamental programming skills (data structures, algorithms)
Familiarity developing on Unix/Linux
Good communication skills, both written and spoken
Knowledge of Agile, Scrum, BDD, TDD and CI/CD
An interest or experience in any of Functional Programming, Distributed Systems or Event-Driven Architectures

Why should you join us?

We’re gearing up for our biggest chapter yet – and it’s being driven by tech.

That means full steam ahead working on our global platform and real challenges for you to noodle and solve – as we build new things, reimagine the stack and go after the greenfield.

We believe that great ideas come from everywhere. So, there are no pigeonholes here. We keep it agile and open. Think big remits and huge ownership in a continuous learning environment. Close knit teams, with mentorships and global career opportunities. Everyone working together to make a genuine difference to small business owners, to us and to you.

Join the team making it happen. Help us define long-term commitments and launch the next game changers – let’s build the incredible.

It’s in our differences that we find our strengths.

At Funding Circle, we celebrate and support the differences that make you, you. We’re proud to be an equal opportunity workplace and affirmative action employer. We truly believe that diversity makes us better. We particularly encourage applications from applicants from underrepresented backgrounds. We welcome applicants who may want to work flexibly.

Want to Build the Incredible? We’d love to hear from you.",3.8,"Funding Circle UK
3.8","London, England",-1,501 to 1000 Employees,2010,Company - Private,Lending,Finance,$50 to $100 million (USD),-1
Data Engineer,-1,"FanDuel Group is a world-class team of brands and products all built with one goal in mind — to give fans new and innovative ways to interact with their favourite games, sports, teams, and leagues. That's no easy task, which is why we're so dedicated to building a winning team. And make no mistake, we are here to win, but we believe in winning right. That means we'll never compromise when it comes to looking out for our teammates. From our many opportunities for professional development to our generous insurance and paid leave policies, we're committed to making sure our employees get as much out of FanDuel as we ask them to give.

FanDuel Group is based in New York, with offices in California, New Jersey, Florida, Oregon and Scotland. Our brands include:
FanDuel — A game-changing real-money fantasy sports app
FanDuel Sportsbook — America's #1 sports betting app
TVG — The best-in-class horse racing TV/media network and betting platform
FanDuel Racing — A horse racing app built for the average sports fan
FanDuel Casino & Betfair Casino — Fan-favourite online casino apps
FOXBet — A world-class betting platform and affiliate of FanDuel Group
PokerStars — The premier online poker product and affiliate of FanDuel Group
THE POSITION

Our roster has an opening with your name on it

FanDuel Group is looking for an experienced Data Engineer with deep understanding of large-scale data handling and processing best practices in a cloud environment to help us build scalable systems. As our data is a key component of the business used by almost every facet of the company, including product development, marketing, operations, and finance. It is vital that we deliver robust solutions that ensure reliable access to data with a focus on quality and availability.

Our competitive edge comes from making decisions based on accurate and timely data and your work will provide access to that data across the whole company. Looking ahead to the next phase of our data platform we are keen to do more with real time data processing and working with our data scientists to create machine learning pipelines.

THE GAME PLAN

Everyone on our team has a part to play
Creating and maintain optimal data pipeline architecture
Designing and implementing data pipelines required in the data warehouse and data lake in batch or real-time using data transformation technologies
Identifying, designing, and implementing internal process improvements: automating manual processes, optimising data delivery, re-designing infrastructure for greater scalability
Designing and deploying data models and views with large datasets that meet functional / non-functional business requirements
Delivering data integration solutions to downstream marketing and campaign software
Delivering quality production-ready code in an agile environment
Delivering test plans, monitoring, debugging and technical documents as a part of development cycle
Creating data tools for analytics and working with stakeholders across all departments to assist with data-related technical issues and supporting their data infrastructure needs
THE STATS

What we're looking for in our next teammate
Advanced working SQL knowledge and experience working with relational databases
Build processes supporting data transformation, data structures, metadata, dependency, and workload management
Show proficiency understanding complex ETL processes
Demonstrate the ability to optimise processes (ram vs io)
Knowledge of data integrity and relational rules
Understanding of AWS and Google Cloud
Ability to quickly learn new technologies is critical
Proficiency with agile or lean development practices
Comfortable writing Python scripts
THE CONTRACT

We treat our team right

Competitive compensation is just the beginning. As part of our team, you can expect:
An exciting and fun environment committed to driving real growth
Opportunities to build really cool products that fans love
Mentorship and professional development resources to help you refine your game
Flexible vacation allowance to let you refuel
Hall of Fame benefit programs and platforms
FanDuel Group is an equal opportunities employer. Diversity and inclusion in FanDuel means that we respect and value everyone as individuals. We don't tolerate bias, judgement or harassment. Our focus is on developing employees so that they reach their full potential.",4.0,"FanDuel
4.0","Edinburgh, Scotland",-1,501 to 1000 Employees,2009,Company - Private,Sports & Recreation,"Arts, Entertainment & Recreation",$100 to $500 million (USD),-1
Data Engineer,-1,"At Pirate, we’re on a mission to make creative space available to all. Through our 24 hour, self-service Rehearsal, DJ, Recording, Podcast and Dance Studios, we’re empowering the next generation of creatives. As one of Europe’s fastest-growing companies, this is a great opportunity to join the team and help us as we take our mission global.

Data Engineer

Data is fast becoming the heart of everything we do at Pirate, and the data engineer will play a key part in building our data culture. A star collaborator, working side-by-side with the Tech Developers and the Business Functions, they will provide the refined and modelled data to enable self-service analytics for the rest of the business. This will require building and managing robust and scalable data pipelines and ETL; integrating new data sources into the data lake; tuning and maintaining the data lake and data warehouse; and modelling the data and KPIs to enable BI and data-driven decision making.

This role is a new one at Pirate and would be a great opportunity for someone interested in shaping the Data Engineering architecture and best practices, as well as providing the opportunity to work across all teams across Pirate. There is serious scope to make a BIG impact in this area.

Being the Data Engineer

The Data Engineer will ultimately be responsible for:
Maintaining existing ETL processes and data lake
Tuning the data warehouse for performance (Redshift)
Working closely with business function teams on data modelling, KPIs and metrics for the BI tool (Looker)
Data cataloguing and documentation to support self-service analytics
Adding new data integrations into the data lake and data warehouse
Building and maintaining data pipelines to other apps (e.g. a CRM system)
Improving fault-tolerance and reliability of cloud data systems infrastructure
Improving performance and cost saving of cloud data architecture
You’ll be collaborating with the functional teams to understand the business information requirements, and working with the tech team and Senior Data Engineer to ensure that the data warehouse and BI tools have robust, relevant and scalable data sources to meet and exceed these needs.

Vital Experience

We ask that you bring your skills and experience in:
Bachelor's degree in a STEM subject
Having at least 4 years experience in a data engineering, or data-leaning software engineering role
Writing complex and efficient SQL queries
Data manipulation and ETL using dataframes in Pandas, Spark, R or similar.
Cleaning and processing data for analytics
Schema design and data modelling
Processing large datasets
Cloud data architectures
Preferred skills but not a deal breaker:
Looker, or similar self-service BI tool experience
AWS
Redshift
Data streaming technologies, e.g. Kafka / Kinesis
Data lake technologies e.g. delta lake
In Return

This is yours to shape, own and run with... A huge opportunity presents itself, to move quickly, collaborating with every department of Pirate to be part of the long term vision to scale the team and business.

We also offer a competitive salary based on experience, annual training budget, discounted studio rates, cycle to work scheme and additional holidays. This role will be based in Bristol with flexible working and full-time, permanent employment.

Equal For All

At Pirate, we strive to break down barriers for people of all backgrounds, and it’s no different for our team. Equal opportunity, inclusivity and diversity are celebrated here. This means we treat people fairly, regardless of age, disability, gender identity or expression, pregnancy and maternity, marital status, race, religion or sexual orientation.",3.2,"Pirate Studios
3.2","Bristol, England",-1,51 to 200 Employees,-1,Unknown,-1,-1,Less than $1 million (USD),-1
Senior Data Engineer - Consultant,-1,"Senior Data Engineer - Consultant*
Are you a Data Engineer with consultancy experience? Do you want to work for a consultancy that pride themselves on delivering quality solutions? Would you be interested in working for an Elite Snowflake Partner?

SearchDATA is working in partnership with a growing Data & Analytics consultancy full of people that are passionate about delivering quality Data Solutions. The business has been going from strength to strength, despite all that is going on in the world, with new business being won and new partnerships being formed.

The most recent news they’re incredibly proud about is their selection as an Elite Snowflake Partner, an achievement that is sure to help them along their way to becoming an industry leader whilst also meaning their teams work on projects with the absolute latest and best data technologies.

They’re looking to grow the team with like-minded people, so if you’re a Senior Data Engineer with consultancy experience and a true passion for delivering quality data solutions, this may just be the role for you.
Overview*
· Delivering high quality data management solutions

· Consult with clients on industry technologies, services and business benefits of data and analytics

· Helping design and deliver cloud-based data and analytics solutions (AWS, Azure, Snowflake)

· Meet with clients to understand the customers’ needs for data, analytics, BI and technology

· Contribute towards project delivery and managing stakeholders’ expectations
Requirements*
As a technology agnostic company, technical requirements are always subject to change. We need an individual able to understand the core concepts and principles behind the tools in order to adapt their knowledge to the tech used at the time.

· Experience on client-facing projects, including working in close-knit teams

· Experience delivering Cloud Based Data Solutions (AWS / Azure / GCP)

· Experience with Cloud Data Warehouse tools such as Snowflake or native AWS tools

· Experience with various Data Integration tools such as Alteryx, Informatica

· Experience and interest in Big Data technologies (e.g. Apache products)

· Good knowledge of industry technologies, services and business benefits of data and analytics

· Ability to build operational ETL data pipelines across a number of sources, and constructing relational and dimensional data models

· Strong development background with experience in scripting, object oriented or functional programming language, etc. SQL, Python

· Experience with visualisation software such as Tableau, Power BI, Qlik Sense

· Experience with leveraging Metadata to quicken project delivery and improve access to data

· An understanding of DevOps principles, practices and tooling, CI/CD with Jenkins etc

For more information on this position and other Business Intelligence / Data & Analytics roles please visit our website www.searchdatagroup.co.uk

Reference ID: SDG-BS-1501

Job Types: Full-time, Permanent

Salary: £80,000.00-£100,000.00 per year

Additional pay:
Bonus scheme
Benefits:
Company pension
Flexible schedule
Work from home
Schedule:
Monday to Friday
Experience:
Data & Analytics Consultancy - Client facing: 2 years (Required)
Data Engineering / Data Architecture: 2 years (Required)
Work remotely:
Yes",-1,SearchDATA Group,"London, England",-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"At Mallzee, data is key and is used in everything we do and across all teams, as an innovation business we use quantitative information to drive our decisions. We are looking for someone to complement our data team (data scientists and engineers) and work on building data pipelines as well as data models; a large part of the role encompasses the development and deployment of Machine Learning solutions for our products. We are looking for someone that can help the scaling and improvement of our current systems, and implement ideas with new technologies.

Our data is voluminous and diversified, sitting in different databases and coming from a variety of services; as a Data Engineer at Mallzee, you’ll be directly involved in each process and will contribute to the building of solutions that change the fashion industry. You will also work on our Covid response Lost Stock that has so far provided 115,000 weeks of support for families in Bangladesh.

Mallzee has also recently been selected to take part in a large scale EU project around the use of data in retail which you will play a key role in - this project will largely rotate around the building of machine learning prototypes and services.

Requirements
Experience: 1-2 yrs experience in a similar role, ideally in an environment where you dealt with large datasets in different formats;
Cloud computing: we operate on AWS and use multiple AWS tools, but experience with any cloud service is considered equivalent;
ETL & data modelling: experience in building data pipelines from raw sources - our data warehouse sits in AWS Redshift; for data tables cleaning and modelling we use dbt (data build tool);
Languages: language-flexible: we use whatever language and tool suits best our current needs and are always looking for ways to improve, our backend software is written in Node.js, Go and Python, tables modelling is done with SQL;
Working experience with Machine Learning modelling and deployment: we normally prototype in Jupyter notebooks and deploy afterwards - working knowledge of the Python data stack (Numpy, Pandas, scikit-learn, ...) is required;
Version control & documentation: we use git and ue various tools for collaborative documentation of data and processes, so we’re looking for someone detail-oriented that can help us keep our work orderly
Advantageous skills
Experience with TensorFlow, especially for object detection within images
NLP knowledge a plus
Personal Qualities

We are a diverse and collaborative team and we always look for people who are flexible, learning-oriented and happy to work in an environment where every day is different and they would have to solve a new challenge as well as continuously improving what has already been done. We work with a variety of technologies and are always adopting new ones if we discover they can suit our needs better, so we are looking for someone who is able to grasp new tools quickly and make the most of them. We also have a culture where testing, tinkering and playing around to tackle problems is highly encouraged.

Benefits

We have high expectations of our team. In return, we offer a great environment where people thrive, develop and grow - professionally and personally.
A chance to make a real difference with your job
A great team environment with talented colleagues
Personal development support and training opportunities
A competitive salary, based on experience and potential
Access to staff share options pool
Central and well kitted out office with remote options available
Continual development and exposure to multiple parts of a fast growing tech company",5.0,"Mallzee
5.0","Edinburgh, Scotland",-1,1 to 50 Employees,2013,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Who are we?

Welcome to Tractable, we're an AI company with a mission of transforming breakthrough discoveries in deep supervised and semi-supervised learning into products that actually help people.

Engineering @ Tractable

We are a tight-knit team, taking a data-driven approach to solve real-world machine learning problems. We have a track record of taking cutting edge research and making it work for real products: we have the necessary resources (in-house labelling and domain experts) and a large volume of data to train our algorithms, so we can focus on solving those big problems and adding value to our customers!

The project you will be working on:

You will be joining our talented team working on our new Data Platform, the tool that will help bring data usage in Tractable to a different level. The Platform will be the backbone of Tractable internal reporting and AI Models improvements and training.

You'll be focussing on developing, architecting and scaling our data services, data lakes and ETLs to enable reporting, ad-hoc querying and model trainings. You will be required to gather context about the wider data space and how our data is collected and processed. Your day-to-day tasks would involve thinking of data models, ETLs, data lakes, data-warehouses and feature stores. You will also work closely with our research team to understand how the AI / ML training occurs and the data that need to be provided so we can maximize the accuracy and reduce the data preparation step for new models.

We work in a lean team comprising data engineers and product managers. We continuously learn how to best achieve our mission: we make the best of feedback and experiences brought in by everyone and we look forward to hearing about what you can bring!

The role:

You'll play a key role in developing our platform, as part of a small but high performing team. You will join as a mid-senior level Data Engineer and influence the data engineering strategy at Tractable with plenty of scope and autonomy to make meaningful impact and grow your skills.

You will:
Help build the next gen data platform in Tractable.
Make sure that data is secure, reliable and easily accessible across the company by leveraging the latest technologies
Build tools for automation, monitoring and alerting of the data pipelines.
Write complex ETL in Python/PySpark to generate reports from a variety of sources.
Build internal tools and libraries for our engineers and internal customers
Write Infrastructure as Code using Terraform
Collaborate in design and problem solving sessions.
Research and implement new tools and technologies in the data space
Work with our stakeholders to iterate on our data products
Suggest improvements and introduce best practices into the team
Our Tech Stack:
AWS - IAM, Glue, Athena, Lambda, SQS, SNS, S3
Python, Apache Spark
Postgres, Kafka
JSON, Parquet
Terraform
Airflow
What we're looking for:
This is a mid-senior level role and we're strong skills in Python and Apache Spark
Strong experience developing, architecting and scaling data services
Previous experience introducing best practices or processes into a team and a strong desire to help others succeed
Strong architectural design skills and being able to discuss the merits and trade-offs of using any particular design approach and technologies
Bonus: Experienced working in a AWS Data Stack (AWS Glue, Lambda, S3, Athena)
Bonus: Experienced using Apache Spark for data processing
Bonus: Experienced with data streaming applications middleware (e.g. Kafka, Rabbitmq)
Bonus: Experienced using Terraform for Infrastructure as code
Company benefits:
Highly competitive salary & 6 month salary reviews
Visa sponsorship if required
Equity
Pension scheme
Flexible Working (2 days WFH & Flexible hours)
Learning and Development budget
Unlimited Coursera subscription
Competitive maternity + paternity leave
Daily snacks & soft drinks
Regular company events such as Games Nights, Movie Nights, Lunch & Learns, Monthly Brunch and more
Location - Old Street, City of London (we're fully remote until Jan 2021 minimum due to COVID. We're ordinarily based in office in Old Street, London)",4.9,"Tractable
4.9","London, England",-1,51 to 200 Employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"The Company

A Teesside based software business are looking to expand their data team with the recruitment of a Data Engineer. You will help to design and build data warehouses allowing the business to enhance their reporting services for their customers via PowerBI.

The Role

Reporting into the Head of Data Operations you will help to analyse reporting requirements and design data stores to meet those requirements. Key responsibilities:

Build, test and maintain new data warehouses
Implement data flows to connect operational systems, data analytics and business intelligence solutions
Develop models from which business intelligence reports can be developed
Recommend and implement ways to improve data reliability, efficiency and quality

The Requirements

This is an exciting opportunity to join a growing data team, work on a variety of different projects which provide exposure to Azure Data Factory and Azure Synapse. Key requirements:

Demonstrable experience of design and construction of relational and dimensional data warehouses
Understand the concepts and principles of data modelling and can produce, maintain and update relevant data models
Data Transformation/ETL and SSIS experience
SSRS, SSAS, SQL Server and T-SQL
Awareness of Azure Synapse and Power BI data models is desirable",4.0,"Nigel Wright Group
4.0","Teesside County Borough, England",-1,51 to 200 Employees,1988,Company - Private,Staffing & Outsourcing,Business Services,$10 to $25 million (USD),-1
Data Engineering Consultant,-1,"Data Engineering Consultant *
Are you a Data Engineer with consultancy experience? Do you want to work for a consultancy that pride themselves on delivering quality solutions? Would you be interested in working for an Elite Snowflake Partner?

SearchDATA is working in partnership with a growing Data & Analytics consultancy full of people that are passionate about delivering quality Data Solutions. The business has been going from strength to strength, despite all that is going on in the world, with new business being won and new partnerships being formed.

The most recent news they’re incredibly proud about is their selection as an Elite Snowflake Partner, an achievement that is sure to help them along their way to becoming an industry leader whilst also meaning their teams work on projects with the absolute latest and best data technologies.

They’re looking to grow the team with like-minded people, so if you’re a Data Engineer with consultancy experience and a true passion for delivering quality data solutions, this may just be the role for you.
Overview*
· Delivering high quality data management solutions

· Consult with clients on industry technologies, services and business benefits of data and analytics

· Helping design and deliver cloud-based data and analytics solutions (AWS, Azure, Snowflake)

· Meet with clients to understand the customers’ needs for data, analytics, BI and technology

· Contribute towards project delivery and managing stakeholders’ expectations
Requirements*
As a technology agnostic company, technical requirements are always subject to change. We need an individual able to understand the core concepts and principles behind the tools in order to adapt their knowledge to the tech used at the time.

· Experience on client-facing projects, including working in close-knit teams

· Experience delivering Cloud Based Data Solutions (AWS / Azure / GCP)

· Experience with Cloud Data Warehouse tools such as Snowflake or native AWS tools

· Experience with various Data Integration tools such as Alteryx, Informatica

· Experience and interest in Big Data technologies (e.g. Apache products)

· Good knowledge of industry technologies, services and business benefits of data and analytics

· Ability to build operational ETL data pipelines across a number of sources, and constructing relational and dimensional data models

· Strong development background with experience in scripting, object oriented or functional programming language, etc. SQL, Python

· Experience with visualisation software such as Tableau, Power BI, Qlik Sense

· Experience with leveraging Metadata to quicken project delivery and improve access to data

· An understanding of DevOps principles, practices and tooling, CI/CD with Jenkins etc

For more information on this position and other Business Intelligence / Data & Analytics roles please visit our website www.searchdatagroup.co.uk

Reference ID: SDG-BS-1500

Job Types: Full-time, Permanent

Salary: £60,000.00-£80,000.00 per year

Additional pay:
Bonus scheme
Benefits:
Company pension
Flexible schedule
Work from home
Schedule:
Monday to Friday
Experience:
Cloud based Data Solutions: 2 years (Required)
Data Engineering / Data Architecture: 2 years (Required)
Data & Analytics Consultancy : 1 year (Required)
Work remotely:
Yes",-1,SearchDATA Group,"London, England",-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"ClearScore is searching for a talented data engineer. You will be working on a platform that will hold data on millions of ClearScore users across the world. This will involve designing and implementing massively high-volume and robust data pipelines that will feed user behavioural data back into production systems. You will engineer systems that will power ClearScore’s analytics which will handle thousands of events per second from users interacting with our product.

About the data team
The data team ingests and processes 90M events per day, peaking at 360k events per minute.
We use Kafka, Kinesis, Spark-streaming and SQS for stream processing.
Airflow, Spark, Spark-SQL and AWS-glue for batch processing.
AWS, Jenkins, Docker and Terraform for infrastructure.
""You build it you run it"" culture, empowering our engineers to work with AWS, Docker and Terraform.
BDD/TDD and peer-reviewing enabling us to do frequent yet resilient releases to global markets.

Pick up a new language: Some of our developers have learnt Scala on the job – we have all the resources and support available in case you are willing and keen to learn.We are always looking for ways to do things better and encourage new joiners to bring their ideas and ways of working to the table. Teach us some cool stuff and we'll teach you some, but most of all, you'll have fun doing it.

About ClearScore

""People around the world will turn to ClearScore when they think about financial decisions. We make personal finance clearer, calmer and easier to understand. We help people take decisions that create greater financial well-being."" This is the ClearScore mission, and what you will see when you come into our office.

ClearScore is one of the fastest growing FinTechs in Europe. We've changed the credit scoring and credit report market in the UK forever and our mission is to transform how people manage their personal finances around the world. From building financial literacy chatbots, to creating industry leading relationships and integrations with financial institutions, our technology and our developers enable the creation of the next generation of consumer-facing financial technology.

We are proud to say that our engineers at ClearScore are world class and at the heart of making this mission a reality for our millions of users.

For more information on our tech stack check out our Tech Radar 2020, how we work is summarised in our Engineering Principles and we have many other Tech Blogs on Medium.

Requirements
Proven industry experience in a language such a JVM language or Python.
A sound understanding of AWS technologies such as S3, RedShift, Lambda, Kinesis and EMR.
A willingness to get your hands dirty with infrastructure-related technology such as Terraform.
Code quality - you know how to ensure that the code you write is well tested.
Able to understand that the work you do has a wider impact across the company and are able to converse about what you do to people who aren’t necessarily part of the technology division.
Benefits
Holidays – 25 paid holidays and a “duvet day” on your birthday
Pension – ClearScore matches up to 6%
Market-beating medical insurance - with the option to add friends and family
Dental cover with Denplan, the LARGEST dental provider in the UK – with the option to add family members
All permanent staff are automatically included in our ClearScore Group Life Assurance Scheme – life insurance cover will be an amount that is equal to 4x your basic salary
Perkbox – a choice of different benefits
Flexible work hours and the ability to work from home
Flexible, generous and personalised maternity and paternity plans
Monthly funded GP office visits
Free breakfast and fruit...and a fully stocked drinks fridge!
Company personal trainer, boxing and yoga classes
Company clubs for football, climbing, cinema, board games... if there's not one for your passion, start one!",4.4,"ClearScore
4.4","London, England",-1,201 to 500 Employees,2015,Company - Private,Brokerage Services,Finance,Unknown / Non-Applicable,-1
Software Engineer - Manchester,-1,"The Opportunity

Would you like to help create a brand-new engineering organisation? Perhaps you know what great engineering culture looks like, or you have an entrepreneurial side as well as outstanding coding skills? Whatever your aspirations, we’re trying to create the best engineering consultancy in the UK and looking for brilliant engineers to be part of the journey.

About DMW Engineering

DMW helps organisations solve their biggest, most exciting engineering problems. We’ve created banks from scratch on Kubernetes and AWS, built streaming analytics solutions that protect the country and built platforms to enable whole organisations to move to AWS and Azure, and everything in between. We do all this in a work environment where regular social events, inclusivity and an ego-free culture mean we’ve been officially voted a “Great Place to Work” for five years in a row.

We’re not interested in cutting corners and believe in helping our clients to make the right choice for the long-term. We draw on our reputation for outstanding delivery to allow our engineers to do the right thing for our clients, and not necessarily the easy thing. Innovation is in our DNA, and we encourage our engineers and consultants to work together to rethink conventional wisdom on how problems should be solved.

Here’s what you will do (Not all of it, but some of the important stuff!)
Solve the problems others cannot
Spend a day a week working on a combination of internal products and your own development
Create platforms based around a modern, cloud-native tech stack:
Java 8+ and Kotlin
Python
AWS, Azure and Google Cloud
Kubernetes
Terraform
Dataiku
And more…
Requirements

Do you have the essentials?
Demonstrable experience with at least one JVM language (Java, Kotlin)
Experience working within an agile, iterative engineering environment
Willingness to work collaboratively
Have a drive for self-improvement and learning
Approach solving problems pragmatically
It would be great if you had these desirable skills
Experience developing software using a TDD approach, and willingness to practice TDD
Experience applying Continuous Delivery practices to deliver software to production
Experience working with one of the main cloud providers (AWS, Azure or Google, with double points if you have worked with more than one)
Experience with any infrastructure as code would be beneficial
Benefits

This is what you get in return

We’ve grown consistently over the years and offer an entrepreneurial environment within which to embark upon an exciting career path, where your contribution really counts, and we will recognise it. With personalised development opportunities, experienced colleagues and challenging client assignments, progression can be extremely rapid for high performers. We are a social bunch of people and go out as a team on a regular basis. You can also expect:
A highly collaborative working environment and great rates of pay (including base salary and bonus potential).
A range of flexible benefits consisting of well-being and lifestyle benefits.
A commitment to your development & continuous growth of skills through one-to-one mentoring and wide-ranging hands-on experience.
25 days’ holiday and the ability to flex this to 30 days if you chose to do so.
2 day’s CSR volunteering days.
Award-winning learning and development opportunities, including dedicated personal training budgets and time and a wide range of choice in training courses.
A dedicated personal budget to choose the IT equipment of your choice.
Here’s a little more about us and what we value

Independent, award-winning and ambitious, DMW are a technology and management consulting firm that places a high value on people, which is why we have been recognised as a Great Place to Work™ consecutively for the last 5 years. We have a 30-year track-record of delivering complex, business-critical IT transformation projects moving seamlessly from strategy, design, delivery through to operations. We believe we offer a significantly better work-life balance than in other IT consultancies because you are involved every step of the way, making career decisions together.

DMW is widely recognised as the place where smart, technically curious, ambitious people who value their integrity and independence want to work. We offer rewarding careers to people who are driven by the desire to do exciting work for ambitious clients.

We have helped improve some of the biggest organisations in the UK and Europe across three core sectors: Finance and Insurance, Energy and Commercial and the Public Sector. Solving complex technology problems to create competitive advantage through the advanced application of Cloud, Digital and Data technologies; growing revenues, reducing costs, and improving efficiency and effectiveness for our clients.

DMW Group is an equal opportunities employer and welcomes applications from all sections of society. We believe that diversity makes us a stronger team so seek to employ people with different ideas, styles and skill sets, each able to contribute in unique ways to our organisation’s growth and success.",4.7,"DMW Group
4.7","Manchester, England",-1,51 to 200 Employees,1989,Company - Private,IT Services,Information Technology,$10 to $25 million (USD),-1
Data Engineer,-1,"Data Engineers x 2 (SQL Server, Python) - Remote, occasional travel to Reading. You will be experienced in Data Engineering with a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.
Skills in using software languages to call APIs, extract, manipulate, and shape the data in such a way that it can be interpreted accurately, and insights revealed
Skills/experience
Solid current experience of using an object-orientated software language to obtain, extract and manipulate data, such as Python, C#, Java or equivalent
Strong daily experience of querying relational databases (SQL Server specifically) as well as a working familiarity with other database systems.
Strong analytical skills related to working with a mixed variety of both structured and unstructured datasets, finding relationships in the data
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Building automated processes and workflows supporting data transformation, data processing, and restructuring for reporting and dashboards
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment
Global, innovative and exciting organisation, apply now!
Reference ID: JSRFO4DE

Job Types: Full-time, Permanent

Salary: £55,000.00-£100,000.00 per year

Benefits:
Casual dress
Company pension
Flexible schedule
Life insurance
On-site parking
Private dental insurance
Private medical insurance
Work from home
Schedule:
8 hour shift",4.2,"INITIALIZE
4.2",Remote,-1,5001 to 10000 Employees,1907,College / University,Colleges & Universities,Education,Unknown / Non-Applicable,-1
Data Engineer,-1,"Lionbridge Gaming is looking for a motivated, imaginative Data Engineer to join our team working on some of the biggest franchises in gaming, helping us to build high quality products that delight our customers.

This is a remote-based role, but you will need to be in the Reading area as weekly site visits will be required.

A successful candidate will design and build solutions to objectively measure the progress and status of various key quality metrics as our gaming products mature during development and their integrity once released to production. The candidate will work both collaboratively and alone to understand available data sources & models, define and construct datasets for analysis applying ETL/ELT principles, and build reporting/insights to communicate status and observations to consumers. As a team we work end-to-end with our customer game development studios and quality teams to define the questions we seek to answer via data, identify appropriate methods to accurately & reliably measure confidence/risk, author & instrument required data points to support analyses, to ultimately build a product that delivers on the requirements.

The use of data in our industry to measure product quality is an emerging and fast evolving area, and as such there is great opportunity to develop new and innovative solutions to the challenges presented. The nature and subject of our work is inherently varied as we explore efficient & effective applications of data to assess quality, but is focused on the following core areas:

Product Health: Measuring the functional quality of our gaming products against key targets
Software Development Lifecycle: Measuring our own and partner team's activity during development and the artifacts that contribute towards release confidence
Customer Value: Understanding what is of most value to our end-users, so that we can recognise and articulate those quality factors that influence a successful product
Data Quality: Ensuring that the data we leverage can be trusted to serve our derived insights.

We prioritize high quality and reliable solutions, with a focus on scalability and ease of maintenance as we continue to expand our capability in this area. We typically use Azure Data Explorer (ADX), SQL Server, Azure Data Factory, R/Shiny, Power BI, SSRS, C#, PowerShell, Visual Studio, Azure DevOps, and GIT.
Skills Essentials
Strong practical experience with T-SQL or any variant from other RDBMS.
Proficient in applying data modelling approaches; normalization etc.
Comprehensive knowledge of data query concepts; joins, grouping, pivots etc.
Practical experience of at least one data visualisation platform
Experience working with source control, such as GIT, TFVC etc.
Writes clear, reliable, & easily maintainable code
Clear communication and effective collaboration
Nice To Haves
Object orientated (ideally C#) programming capability in .Net environment
Powershell
SQL Server administration
Familiarity with Visual Studio IDE
Understanding of Data Science, Machine Learning and/or Statistical concepts
Experience with statistical analysis in R or Python
Experience with Azure Data Explorer
Development of ETL & ELT pipelines
Familiarity with NoSql/Non-relational databases
Working in the Azure cloud environment
Agile principles and Scrum methodology
Understanding of GDPR/Privacy requirements
WORK RELATIONSHIPS
+ Customers Studios Quality Test Leads, Managers, SDETs
+ Lionbridge test teams (internal and external), team leads and managers
+ Development producers, designers, area owners and key stake holders

This document describes the major duties, responsibilities, and authorities of this job, and is not intended to be a complete list of all tasks and functions. It should be understood, therefore, that incumbents may be asked to perform job-related duties beyond those explicitly described. It is also a standard description and therefore neither the percentage of time devoted to the various tasks nor can the required qualifications be guaranteed to match those of any given incumbent.",3.4,"Lionbridge Technologies
3.4","Reading, England",-1,5001 to 10000 Employees,1996,Company - Private,IT Services,Information Technology,$500 million to $1 billion (USD),-1
DevOps/Platform Engineer - Manchester,-1,"The Opportunity

Would you like to help create a brand-new engineering organisation? Perhaps you know what great engineering culture looks like, or you have an entrepreneurial side as well as outstanding coding skills? Whatever your aspirations, we’re trying to create the best engineering consultancy in the UK and looking for brilliant engineers to be part of the journey.

About DMW Engineering

DMW helps organisations solve their biggest, most exciting engineering problems. We’ve created banks from scratch on Kubernetes and AWS, built streaming analytics solutions that protect the country and built platforms to enable whole organisations to move to AWS and Azure, and everything in between. We do all this in a work environment where regular social events, inclusivity and an ego-free culture mean we’ve been officially voted a “Great Place to Work” for five years in a row.

We’re not interested in cutting corners and believe in helping our clients to make the right choice for the long-term. We draw on our reputation for outstanding delivery to allow our engineers to do the right thing for our clients, and not necessarily the easy thing. Innovation is in our DNA, and we encourage our engineers and consultants to work together to rethink conventional wisdom on how problems should be solved.

Here’s what you will do (Not all of it, but some of the important stuff!)
Solve the problems others cannot
Spend a day a week working on a combination of internal products and your own development
Create platforms based around a modern, cloud-native tech stack:
Java 8+ and Kotlin
Python
AWS, Azure and Google Cloud
Kubernetes
Terraform
Dataiku
And more…
Requirements

Do you have the essentials?
Demonstrable experience in automating operations tasks with one or more scripting languages
Experience creating and/or maintaining production software delivery pipelines using common CI/CD tools (e.g. Jenkins, GoCD, CircleCI)
Experience working with one of the main cloud providers (AWS, Azure or Google)
Have a drive for self-improvement and learning, including learning new programming languages
Approach solving problems pragmatically
It would be great if you had these desirable skills
Experience with Infrastructure as Code (e.g. Terraform, Cloudformation)
Experience supporting and operating production systems
Familiarity with configuration management tooling (e.g. Ansible)
Python coding skills
Benefits

This is what you get in return

We’ve grown consistently over the years and offer an entrepreneurial environment within which to embark upon an exciting career path, where your contribution really counts, and we will recognise it. With personalised development opportunities, experienced colleagues and challenging client assignments, progression can be extremely rapid for high performers. We are a social bunch of people and go out as a team on a regular basis. You can also expect:
A highly collaborative working environment and great rates of pay (including base salary and bonus potential).
A range of flexible benefits consisting of well-being and lifestyle benefits.
A commitment to your development & continuous growth of skills through one-to-one mentoring and wide-ranging hands-on experience.
25 days’ holiday and the ability to flex this to 30 days if you chose to do so.
2 day’s CSR volunteering days.
Award-winning learning and development opportunities, including dedicated personal training budgets and time and a wide range of choice in training courses.
A dedicated personal budget to choose the IT equipment of your choice.
Here’s a little more about us and what we value

Independent, award-winning and ambitious, DMW are a technology and management consulting firm that places a high value on people, which is why we have been recognised as a Great Place to Work™ consecutively for the last 5 years. We have a 30-year track-record of delivering complex, business-critical IT transformation projects moving seamlessly from strategy, design, delivery through to operations. We believe we offer a significantly better work-life balance than in other IT consultancies because you are involved every step of the way, making career decisions together.

DMW is widely recognised as the place where smart, technically curious, ambitious people who value their integrity and independence want to work. We offer rewarding careers to people who are driven by the desire to do exciting work for ambitious clients.

We have helped improve some of the biggest organisations in the UK and Europe across three core sectors: Finance and Insurance, Energy and Commercial and the Public Sector. Solving complex technology problems to create competitive advantage through the advanced application of Cloud, Digital and Data technologies; growing revenues, reducing costs, and improving efficiency and effectiveness for our clients.

DMW Group is an equal opportunities employer and welcomes applications from all sections of society. We believe that diversity makes us a stronger team so seek to employ people with different ideas, styles and skill sets, each able to contribute in unique ways to our organisation’s growth and success.",4.7,"DMW Group
4.7","Manchester, England",-1,51 to 200 Employees,1989,Company - Private,IT Services,Information Technology,$10 to $25 million (USD),-1
Data Engineer,-1,"Working as a Data Engineer, you will be the “go to” person for all data engineering and data infrastructure related matters on our Brain Training app. You will be an invaluable partner for the data team, providing them with the solid foundation they need to transform raw data into valuable insights for the business. You will own our tracking design, manage our ETLs, optimise our data pipelines and collaborate with the rest of the data team to provide the visualisations and dashboards that drive the product decisions we make on a daily basis.

Requirements

WHAT YOU'LL DO
Be the in house expert on how to design event tracking for our apps
Build and maintain ETL and data pipelines, to be efficient, clean and scalable
Be a key partner for our current data team in all matters on data engineering
Manage our data infrastructure on AWS, continually assessing usage and needs
Contribute to our visualisation tools, sharing your magic with the wider business!
ESSENTIAL SKILLS
Expert SQL & database skills & familiarity with other languages (Python/Java/Similar)
Comfortable designing event tracking solutions and data models from scratch
Familiar with the data needs of a mobile app, games or digital business
Familiarity with AWS, related services and/or tools for scheduling jobs
Experience using github to collaborate on ETLs or other codebases within a larger data team
NICE TO HAVE
Experience in developing data pipelines for predictive models
Experience in mobile apps, F2P or subscription business models
Experience developing data sources for Tableau, Looker or similar
Experience integrating third party data sources & APIs
Experience using Terraform to manage infrastructure
Benefits

WHAT YOU'LL GET

We are an ambitious company, so we aim high in everything we do. We believe we can have a real impact on the world. We recognise that to do this we need to be open to new ideas and to challenge one another every day to ensure real personal and professional growth. Ultimately, we care about each other and we know that we will succeed as a team. It’s why, while remote working we make time to catch up, play online games and do virtual pub quizzes.It’s also why we hold regular team days and hackathons to ensure the team is always trying new things, together. In our view, ambition, openness and teamwork are the surest way to achieve our amazing goals. A few of our other benefits include:
Choice of laptop plus either an iPhone or Google Pixel
Regular hackathons. Work with different teams, try new ideas and experiment with new projects
Performance related bonus scheme
A training budget of £1,000 per year to spend on training, conferences, books and more
While we are all remote working, flexible working to us means, full autonomy in how you work and organise your day at home, even around childcare or other responsibilities;
In the office we have a relaxed and fun work environment with a pool table, board games, PS4 + PSVR for use anytime (games not available at the moment due to COVID rules) ;
Freedom and support to organise and participate in knowledge exchange events and charity activities;
Pension and BUPA health insurance, sporting allowance;
25 contractual days holiday plus bank holidays; and
In the office, Breakfast and snacks provided all day along with a fully-stocked drinks fridge (slightly limited at the moment due to COVID rules)
At Peak we are open to and encourage applications from absolutely anyone. We believe in the potential of everyone; regardless of race, religion or belief, ethnic origin, different physical ability, family structure, socio-economics, age, nationality or citizenship, marital, domestic or civil partnership status, sexual orientation, gender identity, or any other difference that makes you, well, you.",3.4,"Peak
3.4","London, England",-1,51 to 200 Employees,1992,Company - Private,Brokerage Services,Finance,Unknown / Non-Applicable,-1
Data Engineer,-1,"Our client — one of the largest UK privately owned software consultancies, with customers in the private and public sector — is looking for a Data Engineer to work out and implement technologies optimised for access patterns, with focus on how consumers use platforms and play a key role delivering end to end projects for their customers around the East Midlands.

Your job role:
You’ll work with some of the largest private and public customers in the UK
You will work on a wide variety of projects, at the heartbeat of the UK most growing industries
You will deliver strategic data platforms for the given client
Become a subject matter expert in production-grade data science pipelines and platforms
Skills:
Experience coding in Scala, python, Java with Spark
Using Hadoop: YARN, HDFS, HBase, custom MapReduce, Hive/Impala
NoSQL databases: HBase, Cassandra
Previous experience with cloud architecture: AWS, GCP or Azure
SQL
Work in an Agile environment
Benefits:
Work on exciting projects
Extensive training and development opportunities
25 Days holiday
Bonus scheme
Pension scheme and private healthcare insurance

As a Data Engineer you will work as part of an Agile development team across the entire project life-cycle from discovery to implementation, identifying data sources, analysing datasets, developing extract, transformation and load processes and creating single sources of truth. The role will involve providing guidance around data validation and helping to build a more in-depth understanding of real data usage, especially around data quality and process improvement.

Experience of the following:

ETL tools such as Talend, SSIS, PowerCentre and AWS Glue Data visualisation such as Tableau, PowerBI, SQL and NoSQL databases Programming languages such as java, C#, Node.js and Python",5.0,"Cordius
5.0","Nottingham, England",-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Data Engineer, Derby *
Porterbrook Leasing Company specialises in the leasing and asset management of passenger and freight railway rolling stock and associated equipment. Based in Derby with a corporate Head Office in London, the organisation is undertaking a period of transformational change as it responds to the changing landscape in rail and is taking an active lead in the industry in terms of innovation. The ability to maximise the advantages of digital services within the industry will be a game changer in terms of reliability and performance.

The overall objective of the role is to support Porterbrook in maintaining the value of company assets and to ensure that their customers are fully satisfied with the product they lease. This role will support the delivery and development of the Porterbrook Digital Services Portfolio. This would include architecting and delivering high performance data ingestion and transformation platform and to offer solutions to improve the performance of the data platform to create a secure and stable solution for Porterbrook’s products.

It is essential for the candidate to have experience in:

· Azure data components such as Azure SQL DB, Azure Data Lake, Azure Databricks, etc.

· Databricks Delta Lake

· Developing data models and have strong Python/Scala and SQL skills for manipulating data.

· Data profiling, cataloguing, and mapping

· Developing high impact visualisations and presenting the analytics to technical and non-technical audiences using products such as Power BI

· Understanding the business objectives and actively contribute to the team and support data scientists

· Working with big data ideally in engineering sector

· A relevant degree in Computer Science, Engineering, and/or relevant certificates including Azure Data Fundamentals, Azure Data Engineer Associate etc.

We are seeking the very best talent to join the team, and offer an excellent salary, along with bonus and benefits. The role is offered as a fixed term contract for 12 months with the potential to go permanent. Location is Derby but there may be the option for home working.

This is a fantastic opportunity to join a great organisation with excellent people and a road map for the future to grow and develop the business.

To apply please upload your CV and a covering letter with full details of why you would be a great addition to the Porterbrook team, along with details of your current salary and notice period to our retained recruitment consultant Fiona Irvine at Rainbow HR.

Porterbrook is a disability confident employer.

Contract length: 12 months

Job Types: Full-time, Contract",-1,Rainbow HR,"Derby, England",-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"As Google Cloud's premier partner in AI, we provide world-class businesses with cutting-edge data solutions in the cloud.

We help clients take leading technology to the limits by combining our expertise in machine learning, data engineering, and analytics. With Google Cloud Platform as our foundation, we help businesses future-proof their solutions, deepen their understanding of consumers, increase competitive advantage and unlock operational efficiencies.

Our team consists of experts in machine learning, data science, software engineering, mathematics, and design. We share a passion for data & analysis, operate at the cutting edge, and believe in a pragmatic approach to solving hard problems.

As a Data Engineer you will work with colleagues on the data engineering and architecture part of our consulting projects, building robust pipelines and wrangling data in a way that it becomes easy to visualise and ready to be fed into our machine learning models. In addition to that, you will be helping us to build out the data engineering side of our next-generation machine learning products.

Furthermore, you will:
Work with the most innovative and most scalable data processing technologies
Build innovative state-of-the-art solutions with our customers
Work closely with our tech partners: Google Cloud Platform, Tableau, Looker
Work in an agile and dynamic environment together with a small team with our data scientists, machine learning experts, data analysts and data engineers
Requirements
Strong programming and architectural experience, ideally in Python and/or Java, and SQL
2+ years of experience building (big) data solutions
Extremely passionate about data and analytics
Experience with ETL tools, Hadoop-based technologies (e.g. Spark) and/or data pipelines (e.g. Beam, Flink)
Experience building scalable and high-performant code
Experience in producing tested, resilient and well documented applications
The ability to take ownership, end-to-end and finding creative solutions
Experience in architecting, building, maintaining and troubleshooting cloud infrastructure
Excellent interpersonal skills, verbal and written communication skills; a team player and keen learner who loves building great things together
Working experience with Google Cloud Platform (GCP) or Amazon Web Services (AWS) would be beneficial but not essential
BSc or MSc degree in Computer Science or a related technical field
Bonus Points:
Love for the command line with optional affinity for Linux scripting
Experience building scalable REST APIs using Python or similar technologies
Experience with Agile methodologies such as Scrum
Basic knowledge of and ideally some experience with data science topics like machine learning, data mining, statistics, and visualisation
Contributions to open source projects
Benefits

The Basics: 25 days holiday in addition to bank holidays, choice of laptop & pension scheme

Learning: Datatonic encourages continuous learning at all levels with a generous conference budget, freedom to explore the latest tools and technologies as well as regular knowledge-sharing activities

Career Development: A personalised development plan to ensure you hit your professional goals with a clear roadmap for progression

Impact: The opportunity to work on cutting-edge AI and ML solutions spanning multiple industries and with market-leading organisations

Innovation: Access to Datatonic LABs, our Research & Development hub. Experiment and bring forward ideas, create impactful and meaningful work in a creative and collaborative environment - even just for fun!

Office Environment: A modern office set in the innovation hub of Canary Wharf with complimentary fruit, cookies, tea/coffee throughout the day as well as a shared café and working space with panoramic views of London

Team Vibe & Social: A welcoming and friendly team plus regular monthly social events and team offsites (or remote events)

Working for Datatonic


Our UK headquarters is based in a tech-centric environment in the centre of Canary Wharf. We also have offices in Stockholm and Geneva and we work with clients in many other European countries. We allow for flexible working hours and the possibility of remote work.

We’re an eclectic team with lots of different interests and personalities. We have many different roles across data science, engineering, analytics, consulting, marketing, business development, and operations. As a company, we have a strong emphasis on learning and professional development. Our core values are:

Cultivating Excellence

A hub for continuous learning, curiosity, developing ideas, testing things out - and then putting ‘excellence’ into practice.

Owning It

Working collaboratively in cross-functional teams to achieve customer delight. We love what we do and draw immense satisfaction from taking responsibility and seeing the results of our work.

Purposeful Impact

Creating positive change for our customers, using the most relevant machine learning and analytics approaches and the best technologies to meet real business needs.

Winning with Partners & Friends

Our business has been built on great partnerships and open-source collaboration. It’s one thing to be successful, but to do it in partnership with great people and other great companies is even better in our opinion.",4.3,"Datatonic
4.3","London, England",-1,1 to 50 Employees,2013,Company - Private,Internet,Information Technology,$1 to $5 million (USD),-1
Data Engineer,-1,"Data Engineer : I am looking for a Data Engineer for a 4 week project starting on the 02/11/2020. You will require a CSCS card and have had previous experience of working with Cat 6 A install and termination works. RATES : PAYE £105 Per day / Umbrella / Own Ltd £130 per day. If interested please apply and I will come back to you next week. - Fusion People are committed to promoting equal opportunities to people regardless of age, gender, religion, belief, race, sexuality or disability. We operate as an employment agency and employment business. You'll find a wide selection of vacancies on our website.",4.4,"Fusion People Ltd
4.4","Andover, England",-1,201 to 500 Employees,2004,Company - Private,Staffing & Outsourcing,Business Services,$100 to $500 million (USD),-1
Data Engineer,-1,"The Economist is the leading source of analysis on international business and world affairs. We deliver our information through a range of formats, from newspapers and magazines to conferences and electronic services. What ties us together is the objectivity of our opinion, the originality of our insight and our advocacy of economic and political freedom around the world.
At The Economist we are transforming our data Platform in order to support the growing needs of complex and unique business analytics and insights using the state of the art technology. As a result we are looking for an experienced Data Engineer (ETL) to work on the analytic data platform. This role will be directly reporting to the Head of Data Platform and will be responsible for building data pipelines to load data into the platform using the robust data architecture to support all our data solutions.
This opportunity is suited to someone who has proven experience in development and delivery of ETL/ELT architectures on big data platforms using large datasets such as web analytics and traditional data warehouses.

How you will contribute:
Design and build efficient and reliable data pipelines, ingest and transform data sets using Talend ,SSIS , SQL
Work with Business Analyst, Data analyst and Data Architect in order to define the data processing requirement and agree the architecture/data solutions
Work with your team of engineers in defining the problems, designing the proper solutions, developing and delivering end to end operational solutions in line with the overarching technology strategy, principles and architecture
Provide estimation, develop and test end to end data solutions by enforcing established ETL/ELT architecture and processing patterns
Conduct regular data clinics to walk through new as well as enhanced data solutions with the data platform team
Provide regular progress updates on data initiatives to the Head of Data Platform

The desirable skills for this role include:
A Bachelor of Science degree or higher within Computer Science, Mathematics or related discipline is ideal
Coding experience on ETL/ELT using Talend /SSIS/SP/sql in a data warehouse environment
Experience on defining and reviewing data mapping, transformation logic and translate to technical solutions
Experience of cloud based big data offerings such as Snowflake , AWS platforms
Previous exposure to dashboard development using Qlikview, Power BI or other data visualisation tools is ideal
Strong analytical and problem-solving skills and the ability to work with incomplete or imperfect data
Good to have Experience of working within publishing or media
Excellent communication and interpersonal skills including negotiating, good spoken and written English",3.8,"The Economist
3.8","London, England",-1,1001 to 5000 Employees,1843,Company - Private,Publishing,Media,Unknown / Non-Applicable,-1
Data Engineer,-1,"Are you a self-starter who loves working collaboratively, problem solving and making a difference to health data research and innovation? Do you get really excited by BIG data, innovative data engineering and the potential to deliver and catalyse new research into pragmatic solutions for better health outcomes? If so, you could be working with the Health Informatics Centre team (HIC - https://www.dundee.ac.uk/hic/) at the University of Dundee.

HIC are looking to recruit a Data Engineer for a new and interesting large, 18-month, health data project. The multi-disciplinary project team led by HIC will deliver a UK-wide health data analysis platform for rapid research, linkage and innovation. The outputs of the project will enable the delivery of insights from a comprehensive range of data partners and custodians including key support to government. The team will be looking to curate a standardised dataset accessed across a UK-wide platform for health data and associated datasets.

Your priorities will include:

You will be expected to learn the domain information required to deliver the projects;
You will produce system documentation in line with documentation standards and keep abreast of developments in the standards and modelling community for health information and knowledge;
Routine and ad-hoc data curation activities requiring hands-on development of bespoke ETL and cleaning scripts using languages such as SQL and Python.

Who we’re looking for:

experience of working with health data;
experience of working with customers to elucidate requirements and independently design technical solutions to meet the requirements;
Experience in manipulating and management of very large datasets;
A team player with the ability to work using own initiative, deliver outputs within agreed timeframes.

So if this exciting opportunity interests you and you have adaptable skills and experience that fit within the following role then do get in touch. We are looking to hire a successful candidate for this position immediately and would encourage all interested parties to apply as soon as possible.

For further information about this position please contact Mr Chris Hall at c.hall@dundee.ac.uk. To find out more about HIC please visit https://www.dundee.ac.uk/hic/.

At the University we benefit from having access to a range of personal and professional development courses and training opportunities. We enjoy 34 or 39 * days annual leave per year, and are supported by a range of Work Life Balance policies, staff support networks for BME, Disabled and LGBT staff, membership of Athena SWAN, the ECU Race Charter and Stonewall as well as a full range of disability services which all create an enjoyable and inclusive place to work. It is the diversity of our staff and students that make the University of Dundee an enjoyable place to work.

Closing date for applications is 03 November 2020",4.3,"University of Dundee
4.3","Dundee, Scotland",-1,1001 to 5000 Employees,1967,College / University,Colleges & Universities,Education,$100 to $500 million (USD),-1
Big Data Software Engineer - Data Engineering,-1,"G-Research is Europe’s leading quantitative finance research firm. We hire the brightest minds in the world to tackle some of the biggest questions in finance. We pair this expertise with machine learning, big data, and some of the most advanced technology available to predict movements in financial markets.

The role

We are looking for a Big Data Software Engineer to join the team responsible for the new research platform at G-Research. The platform has been built on top of leading edge big data and machine learning technologies (Spark, Tensorflow, Horovod) to accelerate research on near-petabyte-scale data. The team works closely with users of the platform to enable new avenues of research at scale.

Key responsibilities of the role include:
Working in a highly collaborative environment with regular pair and mob programming
Designing and building solutions that drive value out of near-petabyte-scale data
Collaborating regularly with quantitative research teams to maximise efficiency and value
Continuously exploring and developing solutions to improve data and compute throughput at scale
Demonstrating software engineering best practices such as TDD, CI and CD
Who are we looking for?

The ideal candidate will have:
Strong skills in at least one of Python, Java, Scala, Kotlin
The energy to persevere on complex technical problems
A curiosity and eagerness to learn and apply new technologies or domain concepts
Drive to constantly find new ways to make solutions faster, better and lower-maintenance
The ability to hold in-depth conversations with users in their domain language
Advantageous experience and skills include:
Experience with big data technologies e.g. Spark, YARN, Hadoop
Experience with ML technologies e.g. Tensorflow, Keras, Pytorch, Horovod
Experience with performance tuning
Why should you apply?
Highly competitive compensation plus annual discretionary bonus
Informal dress code and excellent work/life balance
Comprehensive healthcare and life assurance
25 days holiday
9% company pension contributions
Cycle-to-work scheme
Subsidised gym membership
Monthly company events
Central London office close to 5 stations and 6 tube lines",4.8,"G-Research
4.8","London, England",-1,501 to 1000 Employees,2001,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"If you are an experienced data engineer interested in energy systems including grid-edge, off-grid, automotive, and aerospace, and pushing their boundaries with bleeding edge digital technologies, then we are looking for you! An inquisitive, self-motivated, resourceful and team-oriented engineer, with strong leadership and project management skills, who takes initiative to ensure that results are delivered, even in an environment with a high number of unknowns.

This role involves working with software developers, data scientists, and engineers, to design, prototype, and implement mission-critical data systems using the latest technologies.

Typical responsibilities include:
Designing and prototyping Big Data pipelines that ingest, process, store and analyze time series data from multiple sources, while minimising network delays and partitions
Design, deployment and management of highly scalable applications
Implementing systems for real-time processing of data; statistical inference to impute/clean/enrich data
Mentoring and guiding junior members; performing code reviews
Proactively contributing to drafting and maintaining technical and training documentation
Requirements

Required Skills:
BS in Computer Science, Electrical Engineering, Mathematics (or equivalent work experience)
Significant experience writing data processing code in Go, Python, Java or any OOP language
Hands-on experience designing, integrating and optimising data pipelines for real time analytics
Familiarity with data architecture patterns (i.e. lake, streaming, warehouse, Lambda/Kappa)
Knowledge of relational and cloud-based databases, as well as other Big Data technologies (i.e. Hadoop, Spark, Kafka, NoSQL, Flink)
Experience with AWS/EC2 or other cloud deployment models
Understanding of API design and development
Experience of project management, team building, and working in an agile fast-paced environment
Understanding of CI/CD principles
Writing highly performant clean, modular code. Debugging and optimizing code
Experience with code management best practices
Preferred Skills (any one or more fantastic):
Proven interest in Big Data, machine learning, and artificial intelligence
Experience designing and building flexible APIs for analytics
Familiarity writing and optimizing advanced database queries
Strong Linux/UNIX systems knowledge
Experience with productionizing Machine Learning models
Exposure to research in related areas
Benefits

Lots of perks in addition to a fun and friendly working environment, including:
Professional development reimbursement
25 days annual leave plus bank holidays
Regular team socials [and yearly off-site retreats]
Health and life insurance
Mental health and wellness reimbursement
Parental leave
Competitive salary based on experience: £40k-£60k [and equity]",-1,Modularity Grid,"London, England",-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Millions of players interact daily with Outplays cloud-based server infrastructure. While it is vital that our systems are always functioning and reliable, it is equally important that we continually develop new features to improve and expand upon the needs of the business.

We are looking for an ambitious data engineer to join our DataOps team! The DataOps team is responsible for driving the technology behind ingesting millions of events every day from a variety of sources and providing them to the rest of the business for making data informed decisions.

The Role

You will be responsible for expanding and optimizing our data architecture to support our ever-growing need for deeper insights. The ideal candidate is passionate about working with data, has proven experience working with data pipelines and is excited by the prospect shaping the future of data collection and analytics infrastructure initiatives in the company.

Your teammates will consist of a small DataOps team working closely with the Insights team to support the data needs of cross-functional teams. The role will offer you a chance to provide meaningful impact to the company whilst working with modern Cloud technologies.

About You

In order to be successful in this role you will need the following:
Proven understanding of Business Intelligence stacks, including; ETL processes, data warehousing and visualisation.
Programming in at least one object-oriented language such as Python or Javascript.
Experience of collecting data from 3rd party REST APIs.
Strong database knowledge; designing databases and writing SQL.
Experience working with cloud services such as AWS EC2, RDS and Redshift.
2+ years industry experience in a data engineering or similar role.
Bonus Experience

You will find the following valuable in this role, but they aren't absolute requirements:
Familiarity of agile methodologies.
Familiarity with shell scripting.
Bachelors degree or higher in computer science, informatics or similar field.
Familiarity with DevOps approaches and CI/CD tools.
Business analysis skills.
Experience with stream processing technologies such as Kinesis.
Knowledge of machine learning for data analysis use-cases.
About Us

Outplay Entertainment is the largest independent mobile developer in the UK and based in the thriving game's hub of Dundee, Scotland. We create limitless fun for our players with lovingly crafted and innovative games for mobile phones and tablets.

This approach has seen us recognised for a stable of award-winning titles, including Mystery Match, Crafty Candy and Booty Quest. Our portfolio of awesome games is expanding, and we are always on the search for talented and passionate people to help us grow. With over 30 nationalities represented and a diverse range of experience and expertise, our teams thrive off their ability to work at the forefront of the mobile games industry, building or supporting live game experiences that are enjoyed by millions of players across the world.

The fun and passion injected into our games is reflected in our culture too. Outplay is more than just work. New team members will join a family that has conquered Munros, raced karts, taken on Tough Mudder and Rough Runner, competed in bake-offs, downward dogged, and even ventured to the wilds of Scotland together.

What we can offer

You will have the chance to benefit from our talent initiative, The Outplay Academy - and the opportunity to acquire new skills and grow alongside the business. From mentoring schemes and educational workshops to industry event attendance and guest speakers - we are proud of our dedication to development.

We also offer the following staff benefits:
Private medical and dental care
33 days holiday
Access to our team discount scheme
Employee assistance package
Childcare savings
At Outplay, our mission is to create limitless fun for everyone who plays our games, and we value every individual that helps make that goal a reality. We are committed to remaining an equal opportunities employer and provide a friendly, safe, and welcoming environment for everyone who works here irrespective of age, race, ethnicity, religion, disability, gender, gender identity and expression, physical appearance, body size, and sexual orientation. All our employees are treated with dignity and respect, because being part of Outplay is more than just work its a family.

The personal data you provide will only be processed in accordance with our privacy policy.

Powered by JazzHR",2.3,"Outplay Entertainment Ltd
2.3",Remote,-1,51 to 200 Employees,2010,Company - Private,-1,-1,$5 to $10 million (USD),-1
Data Engineer,-1,"Site Name: UK - London - Brentford, USA - North Carolina - Research Triangle Park, USA - Pennsylvania - Philadelphia
Posted Date: Oct 6 2020

Data Engineer is accountable for developing and delivering cloud-based data ingestion solutions across the Pharma Commercial. You will be working on fully up to date technologies in the Data & Analytics environment and in a team, which is fully committed to remain at the leading edge of this skill set. Therefore, the impetus to keep improving skills and acquiring skill sets in new technologies will be very strong. If you are a top-flight developer who wants to continue to keep learning and remain at the cutting edge of the very fast-moving Data Analytics technology environment, then this role is for you.

This is very hands-on development role which includes developing & delivering code through from origin to production, plus working in partnership with 3rd party development service providers to help ensure that code comes in on time, to quality and in line with the overall ecosystem being established. The Data engineer will directly contribute to the extensive and varied build and deployment activities involved in establishing the new platform then continue to work on the already significant and growing pipeline of future build-outs on the platform.

This role will provide YOU the opportunity to lead key activities to progress YOUR career, these responsibilities include some of the following
Development: Hands on, sleeves up development and delivery expected as a matter of course.
Delivery: Ensure project goals are achieved on time in alignment with the stakeholders expectation. Ability to work on complex projects and in a distributed environment. Escalate to other Data & Analytics leadership team when needing support. Work in close collaboration with other team members in the CH BI Tech team, to ensure Development/Delivery aspects are well represented in the projects requirements and deliverables.
Methodology: . Incorporate agile ways of working into the delivery process thru use of DABL (Discovery, Alpha, Beta, Launch) framework to show value periodically. Individuals will work as part of product-centric delivery team(s) that will focus on delivering value independently while fully embracing integrated DevOps approaches.
Ownership: Take ownership for the delivery/development projects and help steer until completion.
Governance: Follow governance that allows projects and stakeholders to manage overall project performance and manage programme risks within the global nature of some of the programmes.
Forward looking: Remain flexible towards technology approaches to ensure that the best advantage is being taken of new technologies. Keep abreast of industry developments in analytics and be able to interpret how these would impact services and present new opportunities.
Quality, Risk & Compliance: Ensure all risk and issues associated with owned projects are recorded and managed in the appropriate Risk & Issue logs in a timely manner. Ensure all Risks and Issues have clear action/mitigation/contingency plans defined, with named action owners and timelines for completion.
Technical Architecture: Be conversant with technical architecture to contribute to design discussions in partnership with the Delivery/Development Director and dedicated Analytics & Data Architect.
Why you?
Basic Qualifications:


We are looking for professionals with these required skills to achieve our goals:
MS/BS degree in Computer Science, Engineering, Design or equivalent experience.
6-8 years as a Developer in the Data & Analytics arena with demonstrated expertise in emerging technologies and data technology platforms and management.
Fully conversant with agile and DevOps development methodology and concepts. Must have worked in CI/CD ways of working using tools like Azure DevOps.
Preferred Qualifications:


If you have the following characteristics, it would be a plus:
Ideal candidate would have built an impressive hands-on career to date in an advanced, recognized and innovative environment around Data & Analytics.
Fully conversant with big-data processing approaches and schema-on-read methodologies is a must and knowledge of Azure Data Factory/DataBricks/Azure Data Lake/Azure DW/Analysis Services is highly preferred. Understanding AWS and GCP cloud platforms is a plus.
Experience of the Azure analytics components, Power BI, Power Apps & Microsoft Visual Studio is desirable.
Good to have an excellent development skills & extensive hand-on development & coding experience in a variety of languages, e.g. C#, Python, SQL, DAX, etc.
Have a highly innovative mind-set and experience with analytics in a healthcare or CPG company.
Ability to work in close partnership with other IT functions such as IT security, compliance, infrastructure, etc. as well as partner closely with business stakeholders in the commercial and digital organizations.
Experience in executing Data Analytics projects in an Agile manner, articulation of Value depending on the project life cycle stage, Creating MVPs, developing plans for scale up are all very important experience to be successful in this role.
Great communication skills and ability to communicate inherently complicated technical concepts to non-technical stakeholders.
Why GSK?


Our values and expectations are at the heart of everything we do and form an important part of our culture.

These include Patient focus, Transparency, Respect, Integrity along with Courage, Accountability, Development, and Teamwork. As GSK focuses on our values and expectations and a culture of innovation, performance, and trust, the successful candidate will demonstrate the following capabilities:
Agile and distributed decision-making using evidence and applying judgement to balance pace, rigour and risk
Managing individual and team performance.
Committed to delivering high quality results, overcoming challenges, focusing on what matters, execution.
Implementing change initiatives and leading change.
Sustaining energy and well-being, building resilience in teams.
Continuously looking for opportunities to learn, build skills and share learning both internally and externally.
Developing people and building a talent pipeline.
Translating strategy into action - a compelling narrative, motivating others, setting objectives and delegation.
Building strong relationships and collaboration, managing trusted stakeholder relationships internally and externally.
Budgeting and forecasting, commercial and financial acumen.
If you require an accommodation or other assistance to apply for a job at GSK, please contact the GSK Service Centre at 1-877-694-7547 (US Toll Free) or +1 801 567 5155 (outside US).

GSK is an Equal Opportunity Employer and, in the US, we adhere to Affirmative Action principles. This ensures that all qualified applicants will receive equal consideration for employment without regard to race, color, national origin, religion, sex, pregnancy, marital status, sexual orientation, gender identity/expression, age, disability, genetic information, military service, covered/protected veteran status or any other federal, state or local protected class.

Important notice to Employment businesses/ Agencies

GSK does not accept referrals from employment businesses and/or employment agencies in respect of the vacancies posted on this site. All employment businesses/agencies are required to contact GSK's commercial and general procurement/human resources department to obtain prior written authorization before referring any candidates to GSK. The obtaining of prior written authorization is a condition precedent to any agreement (verbal or written) between the employment business/ agency and GSK. In the absence of such written authorization being obtained any actions undertaken by the employment business/agency shall be deemed to have been performed without the consent or contractual agreement of GSK. GSK shall therefore not be liable for any fees arising from such actions or any fees arising from any referrals by employment businesses/agencies in respect of the vacancies posted on this site.

Please note that if you are a US Licensed Healthcare Professional or Healthcare Professional as defined by the laws of the state issuing your license, GSK may be required to capture and report expenses GSK incurs, on your behalf, in the event you are afforded an interview for employment. This capture of applicable transfers of value is necessary to ensure GSKs compliance to all federal and state US Transparency requirements. For more information, please visit GSKs Transparency Reporting For the Record site.",4.0,"GlaxoSmithKline
4.0","Brentford, England",-1,10000+ Employees,1830,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$10+ billion (USD),-1
Data Engineer,-1,"We are looking for exceptional talent to join our dynamic London team to help drive and support this sustained growth. A purely e-commerce company from day one, We are one of the rare examples of a company that has been boosted by Covid-19, as consumers spending moves online more than ever before.
The successful candidate will support our software developers, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.
The Role | What You Will Be Doing*
Thorough understanding of the business and data strategy
Create and maintain optimal data pipeline architecture
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics
Work with the Executive, Product, Tech teams to assist with data-related technical issues and support their data infrastructure needs
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions
Implementing data privacy policies and complying with data protection regulations
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader
*
Experience: *
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures, and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency, and workload management.
A successful history of manipulating, processing, and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.
*They should also have experience using the following software/tools: *
Experience with big data tools: Snowflake or similar.
Experience with relational SQL and NoSQL databases, including Metabase.
Experience with data pipeline and workflow management tools: Stitch or similar
Experience with AWS cloud services: EC2, EMR, RDS
Experience with stream-processing systems
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.
Job Types: Full-time, Permanent
Salary: £60,000.00-£70,000.00 per year

Work remotely:
No",3.7,"eCommerce Company
3.7","London, England",-1,201 to 500 Employees,1920,Company - Private,Publishing,Media,$50 to $100 million (USD),-1
Data Warehouse Developer,-1,"Heard of us?

We’re an award-winning bank; backing people to fulfil life’s hopes and dreams.

Now is your chance…

Our CTO division aims to support and help build the Aldermore business, providing excellence in IT Delivery, Enterprise Architecture, Solutions Architecture, Information Security, Operations and Development.

As we continue to grow, it’s key that the CTO team works closely with all parts of the Bank, helping to deliver activities through the supply of stable, secure and reliable technology solutions and to provide innovation in building the technology strategy for the future. We are committed to delivering an ever improving environment and better customer experience. Here you’ll find yourself at the heart of a dynamic, growing division where innovation and teamwork thrives.

The role of Data Warehouse Developer is within the Data Warehouse team which own and develop the Data Warehouse. The Data Warehouse is critical to our business and regulatory processes and is depended on by many colleagues (our customers) across the bank.

Based in our dynamic Manchester office, you will sit amongst a wider development team and report to the Data and Analytics Platform Manager.

What would your day look like?
Have a strong working relationship with the wider business (including but not limited to the Architecture and Data Science teams) to create technical requirements, best-practice driven data warehouse designs and BI solutions, that will empower business users to embrace data confidently and responsibly address their complex challenges
Design, build and manage dimensionally-modelled data warehouse
Minimise duplication of data and logic to achieve the “single source of the truth”
Build complex data visualizations, dashboards, KPI reports, etc. using Reporting Services, Tableau and other tools
Contribute to & implement continuous improvement identified as crucial to the enhancement of the data warehouse, the team & associated processes
What do we expect of you?
Strong T-SQL knowledge using SQL Server 2008/2012/2014 or later
Expertise in SQL, ELT/ETL, reporting and Visual Analytics tools including SSMS, SSRS, SSIS
Designing and implementing complex technical processes using Microsoft technologies
SQL, SQL Server, SSIS, SSRS, SSAS
Designing and implementing Data Warehouse processes using Kimball methodology
Experience of working on a Data Warehouse
What can you expect of us?
A friendly and flexible culture, synonymous with our proposition to our Customers.
A smart yet comfortable working environment, well located for the daily commute and those lunchtime errands.
A growing organisation that defines itself as being nimble, lean and strong.
A drive for continuous improvement, for which you will be empowered to get behind from day one.
A visible and approachable ExCo; who you will very likely to bump into whilst making your morning coffee.
And of course you will be compensated competitively, with a good range of core benefits and bonus potential.

Still Curious?

A lot can happen in a year!

In 2019 Aldermore Group was formed; bringing together two very successful businesses, Aldermore Bank and MotoNovo Finance, under the First Rand umbrella. Whilst our parent company operates internationally from their HQ in South Africa, we are a UK-based financial services specialist that supports our customers across a range of products and services, with hubs throughout the UK, including London, Reading, Manchester and Cardiff.

We also celebrated our 10th Birthday and fundamentally 10 years of helping those with ideas; by saying yes to our customers. We’ve propelled entrepreneurs on their journeys; we’ve given first-timers a leg-up onto the property ladder; and we’ve opened up the lending market to many.

As for what the next 12 months has to offer; we are embarking upon the delivery of our Purpose; a Purpose that underpins our next 3 to 5 years as a growing business. Join us today and we will make the same Promises to you as an employee, as we do to each of our Customers.

We do not accept speculative agency CVs. Any CV received by Aldermore will be treated as a gift and not eligible for an agency fee. PSL agencies should only send CVs if authorised to do so by HR.

Where a DBS check or CIFAS check is identified as necessary, all application forms, job adverts and recruitment briefs will contain a statement that an application for a DBS certificate or a CIFAS check will be submitted in the event of the individual being offered the position.

Aldermore is an equal opportunities employer.",3.6,"Aldermore Bank
3.6",United Kingdom,-1,1001 to 5000 Employees,2009,Company - Public,Banks & Credit Unions,Finance,$100 to $500 million (USD),-1
Data Engineer,-1,"If you are a strong Data Engineer, with experience working with Python, R and SQL then this role is ideal. I am working with a large organisation that are market leaders in their respected field. This role will report in to the Chief Data Architect playing a vital role in the continual development of analystics and digital transformation.

The role:

You will be working alongside our experts to analyse data workflows and develop the database and dynamic data-driven improvements.
You will be responsible for developing and implementing technologies and efficient workflows to identify, extract, transform, load, manipulate, manage, explore, analyse, report, and visualise data.
This role forms a key part of the digitalisation programme.

Skills Required

You are likely to be educated to a degree level in either computer science, data science or similar.
You will be experienced at working with data, data processes, software and databases.
Advanced problem-solving skills, especially focused on finding new solutions to data identification, ingestion, consistency, loading, and output problems
Active interest in the latest technology and open source trends
Advanced skills in Python or similar general purpose programming and scripting languages
Advanced Microsoft Excel skills including VBA
Working knowledge of databases and SQL
Working knowledge of data loading and ETL
Working knowledge of OCR
Working knowledge of PDF page description and common image formats
Familiarity with data extraction techniques from a variety of file types
Proficiency to design, build, test and support innovation solutions
The ability to define and manage project deadlines
Excellent communication and collaboration skills
An enthusiastic attitude towards learning and flexibility to adapt to new challenges or changes in direction

The following skills may also be beneficial:

Machine learning techniques including NLP, NER, and computer vision
Other programming languages such as Java
Familiarity with Microsoft Azure configuration and native technologies
Agile methodologies and tools

This is a great opportunity for a Data Engineer to join an organisation and professionally develop your career. There is also a highly attractive bonus scheme, with the chance to work remotely and among some of the best experts in the industry.

Services advertised by Gold Group are those of an Agency and/or an Employment Business.
We will contact you within the next 14 days if you are selected for interview. Privacy Policy. Equal Opportunity and Diversity Policy.",4.6,"Gold Group
4.6","London, England",-1,1 to 50 Employees,2000,Company - Private,Staffing & Outsourcing,Business Services,$10 to $25 million (USD),-1
Senior Big Data Engineer (f/m/x) (relocated to Germany),-1,"Senior Big Data Engineer (f/m/x)

Location: Tettnang

The Challenge
As a Data Engineer in the Threat Intelligence team, you will design, implement and maintain the Threat Intelligence Platform that transforms massive amounts of (real-time) data from various sources into descriptive knowledge about emerging threats. You challenge our status quo and define standards for data-intensive analytic pipelines. Your projects will collect and process security-related intelligence and will then provide that data to the company as a whole so Avira can protect its users on a global scale.

The team
We are an international team of engineers and researchers. We are a self-organized and result-oriented team, always looking to perfect the art of automation. Our systems and services are integrated within the Avira Protection Cloud that protect consumers and businesses around the world.

What you will do
Starting from day one you will familiarize yourself with our big data ecosystem and tool stack, as well as the main data source systems.

Within the first 3 months, you are fully integrated into the Threat Intelligence Platform development and maintenance. You are taking responsibilities for certain data stream integrations.

Within the first 6 months you are an expert for the Threat Intelligence Platform having a complete understanding of its integration into Avira’s protection technologies and architecture landscape.

Within the first year you will be truly integrated within a team that delivers the most up-to-date Threat Intelligence solutions to millions of customers. You take full ownership of cross-department projects and collaborate efficiently with other teams. You are keen to improve existing technologies and implement new and innovative features. You also play a big part in securing and supporting the digital lifestyle of our customers and making the Internet a more secure place.

Your Qualifications
3+ years' experience in software development, with excellent development skills in Python
Industrial experience with data-intensive projects in the Hadoop ecosystem, Spark, Kafka, and Airflow
Experience in building data ingestion pipelines
Good knowledge in designing, building, using and maintaining REST APIs
Experience with SQL/NoSQL databases, especially creating scalable, multi-node deployments
Experience with AWS components and principles are a plus
Strong analytical, technical, organizational and communication skills
The position is based in Tettnang, Germany, near lake Constance.

Benefits and perks:
New Work
Stylish building with roof terraces
Canteen and ChocaVira
Modern office concept
Learning & Development
Unlimited access to Udemy
Trainings & Conferences
Specialist Career
Health & Wellbeing
Gym and fitness courses
“JobRad” bike leasing
Medical checkups
Family & Living
Relocation Package
Vacation child care
Avira Prime licences
Events
Onboarding events
Monthly Employee Meetings
Summer & Christmas parties
AN OPPORTUNITY TO MAKE A DIFFERENCE
Update: Although there’s a lot of disruption nowadays due to Covid-19, we at Avira are continuing to run our daily business activities so that we stay true to the promise to our customers - now even more than ever: Protecting people in the connected world.

And we are doing this from the safeness of our own homes. Among other things, this means we are still hiring, but we have moved all our interviews online and all our colleagues are being onboarded remotely

So join us and you will be able to work from home until the danger is over.

We’re an international software company at the forefront of imagining the future of digital security. Avira’s award-winning products and technology protect over 500 million users in the connected world.

What makes us special? First and foremost – it’s the authentic people at Avira. We have a great community feeling that fosters your uniqueness and offers the space to reflect, the feedback to grow, and the freedom to innovate. If you are looking for a culture that also encourages aspiration and professional excellence, get in touch with us and discover the Avira experience firsthand.

Lena Komarek
HR Recruiter
Avira Operations GmbH & Co. KG
Human Resources
Kaplaneiweg 1
D-88069 Tettnang, Germany
Phone: +49 (0) 7542-500 -2207
E-Mail: lena.komarek(at)avira.com",3.6,"Avira Operations GmbH & Co. KG
3.6",United Kingdom,-1,201 to 500 Employees,1986,Company - Private,Enterprise Software & Network Solutions,Information Technology,$50 to $100 million (USD),-1
Infrastructure Engineer - Systems,-1,"Role Objective (brief summary of key function of role and where it fits into the organisation)*
Reporting to the IT Operations Manager, the Infrastructure Engineer will be responsible for the provision of technical support and systems expertise covering the monitoring, patching and performance tuning of all mission critical production, test and development infrastructure for key customers. This includes ensuring high levels of availability and optimal performance for all supported systems infrastructure.
Key Responsibilities (list key tasks, responsibility, deliverables etc.)*
Technical Support*
· Working as a member of a multi-disciplinary Infrastructure Services Team, providing mission critical support for customer infrastructure, covering the monitoring, patching and performance tuning of all supported production, test and development environments. This includes ensuring high levels of availability and optimal performance delivered to pre-agreed KPIs.

· Provide technical expertise and on-call out of hours (on rota) escalation support for NAK’s 24/7/365 Support team, assisting in the resolution of internal and customer faults and queries and providing documented root cause analysis.

· Planning and organising daily workload. This includes managing time effectively between technical support and project delivery, and where necessary prioritising service calls and adjusting work plans to support high priority incidents and the delivery of services to pre-agreed SLAs and KPIs. The types of support provided will include the use of remote-control software, email advice, instant messaging software and where necessary onsite assistance.

· Responsible for the management of all issues assigned to them through NAK’s Service Management System. Ensuring that the status and history of issues are monitored, updated and closed on completion.

· Responsible for providing specialist third line expertise, guidance and support for a range of systems infrastructure solutions, including cloud based managed services, on premise server solutions, backups and where required desktop applications including Skype for Business and Teams.

· Utilising analytical skills for assessing and interpreting highly complex and conflicting information to ensure that server infrastructure related incidents are investigated and that those with unknown underlying root causes are managed according to documented Problem Management procedures.

· Responsible for maintaining the flow of information to all customers providing both timely feedback and information. This includes retaining responsibility for the progress and resolution of complex technical requests and communicating any updates directly to them.

· Responsible for ensuring that all policies and procedures are followed and propose changes to support processes to improve the quality of service.
Technical Delivery*
· Configuring and deploying high-quality solutions that leverage the latest technologies to underpin NAK’s customer’s business operations and support the future growth of the business.

· Maintain close, and mutually beneficial long-term working relationships with key customers’ so that NAK remains as the technology partner of choice for their business. This responsibility includes maintaining the flow of information to all customers providing both timely feedback and information. This includes retaining responsibility for the progress and resolution of complex technical requests and communicating any updates directly to them.

· Ensure continuity for the customer by providing an effective operational handover of all new systems and services. This responsibility includes acting as a subject matter expert for all future support issues and the provision of specialist training to all NAK and customer support personnel, as and when required.
Pre-Sales Engagement*
· Work with Sales to prepare detailed quotations for new business prospects and qualify sales opportunities for feasibility of solution offering. This includes ensuring that the type of services required are within the Company’s field of competence, and that delivery capabilities and capacity align with expectations committed to NAK’s clients.

· Acting as an ambassador for the company, raise its profile, branding and credibility within the market. This includes representing the Company at conferences, trade shows and other external industry events.
Strategy Development*
· Propose new areas of work and new product ideas to Senior Management. Identify risks associated with various strategies on both technical and business issues and recommend a course of action.

· Keep up to date with new developments in hosting and infrastructure technologies and their application within the customer and supplier marketplaces in order to appreciate future customer requirements and improve NAK’s solutions.

· Contribute significantly to the development of Company goals, growth and profitability targets by being an active member of the NAK team and culture.
Skills & Experience (include generic, specific sector, people management, languages etc.)*
· A minimum of five years’ system administration experience within a Windows Enterprise environment, working with on-premise infrastructure and/or hybrid cloud solutions

· Advanced knowledge and support expertise across a wide range of technologies including:

o Microsoft Windows operating systems (7, 8.1 and 10)

o Microsoft Server Operating Systems (2008R2 and above)

o Office 365, Skype for Business, Teams and Hybrid Exchange

o Hypervisor Technologies either VMware or Microsoft HyperV

o Microsoft Active Directory - LDS, ADCS, ADDS, ADFS, RMS etc

o Endpoint protection and encryption technologies such Microsoft ATP

o DNS, DHCP, GPO, IIS and PowerShell scripting

· Functional understanding of Enterprise Storage, LAN Switching, Hyper-V & System Centre, VMware ESXi & vSphere, Veeam Backup & Replication, Deployment and migration to Azure & AWS

· Excellent interpersonal and communication skills, across many levels within an organisation

· Logical and methodical approach to working with strong problem-solving skills.

· Excellent customer focused approach and commitment to service delivery.

· Ability to prioritise workload.

· Good interpersonal and communication skills, both verbal and written.

· Confidence, enthusiasm and commitment to finding new ways of working.

· Professional – punctual, reliable, trustworthy, inspires confidence.

· Able to work as part of a team or independently.

· Highly self-motivated with the capability to influence and deal with issues head on
Competencies (include generic, specific sector, people management, languages etc.)*
NAK Competencies*
Strategic Approach*
· *Seeing the Big Picture *- Having an in-depth understanding and knowledge of how your role fits with and supports organisational objectives. For all staff, it is about focusing your contribution on the activities which will meet NAK’s goals and deliver the greatest value.

· *Changing and Improving* - Taking initiative, being innovative and seeking out opportunities to create effective change, learning from what has worked as well as what has not. It is about being open to change and improvement, and working in ‘smarter’, more focused ways.

· *Making Effective Decisions *-Using sound judgement, evidence and knowledge to arrive at accurate, expert and professional decisions and advice. Being careful and thoughtful about the use and protection of customer information to ensure it is handled securely and with care.
Engagement*
· *Leading and Communicating*– Showing pride and passion for service, communicating purpose and direction with clarity, integrity, and enthusiasm, championing difference and external experience and supporting principles of fairness of opportunity for all.

· *Collaboration* – Working collaboratively, sharing information appropriately and building supportive, trusting and professional relationships with colleagues and customers, whilst having the confidence to challenge assumptions.

· *Building Capabilities*-Having a strong focus on continuous learning for yourself, others and the organisation, being open to learning, and keeping your knowledge and skill set current and ever evolving.
Delivering Results*
· *Delivering Value for Money* – Seeking out and implementing solutions which achieve the best mix of quality, and effectiveness at a reduced cost to NAK. People who do this well base their decisions on evidenced information and follow agreed processes and policies, challenging these appropriately where they appear to prevent good value for money.

· *Delivering a Quality Service* *- *Organising and managing your time and activities to deliver a high quality, secure, reliable and efficient service, applying programme, project and risk management approaches to support service delivery.

· *Delivering at Pace *- Working to agreed goals and activities and dealing with challenges in a responsive and constructive way.
Educational Qualifications*
Minimum academic level required: A-level

Ideal academic level preferred: Degree or HND level or BTec

Professional qualifications (Desirable): Current MCSA/MCSE or equivalent

Mobility Requirements (requirement for national/international travel, overseas assignments)
Confidentiality*
The post holder must not disclose any information of a confidential nature relating to NAK or the services that it provides to any customer or third party during or after their employment except in the proper course of their employment or as required by law.
Data Protection*
The post holder should be aware of the legislation behind data protection within their jurisdiction and follow relevant regulations and codes of practice to ensure appropriate action is taken to safeguard confidential information.
Mobility Requirements (requirement for national/international travel, overseas assignments)*
This role is based within NAK’s office with frequent travel to customer sites.
Additional Specifications / Comments*
This job description is not intended to be an exhaustive list of duties to be performed by the employee. This job description may be altered to reflect the business needs of the company.

Job Types: Full-time, Permanent

Salary: £30,000.00-£43,000.00 per year

Benefits:
Casual dress
Company pension
On-site parking
Store discounts
Work from home
Schedule:
8 hour shift
Monday to Friday
Overtime
COVID-19 considerations:
Currently our team are working from home, using Microsoft Teams and SharePoint for collaboration

Experience:
3rd line support: 5 years (Preferred)
Education:
A-Level or equivalent (Required)
Licence:
driving (Required)
Language:
English (Required)
Work remotely:
Temporarily due to COVID-19",-1,NAK Consulting Services,"Northampton, England",-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We are seeking a Data Engineer to join us in our Manchester office
to support our plans to develop our data warehouse, consisting of social,
video and financial data. The candidate will be picking up some of our
current techniques, and bringing with them their own ideas and areas
of expertise to enrich the collective knowledge base of the team. You will be
working with the latest technologies as well as being part of a team who is not
afraid to try revolutionary ideas to help the business keep growing.

What will you be doing?

Working to:
Implement data flows to connect operational systems, finance/revenue data for analytics and business intelligence (BI) systems
Document source-to-target mappings
Re-engineer manual data flows to enable scaling and repeatable use
Support the build of data streaming systems
Write ETL scripts and code to make sure the ETL process performs optimally
Develop business intelligence reports that can be reused
Build accessible data for analysis
Working with:
Google Cloud and other platforms
Apache Beam
CircleCI
Terraform
Social media APIs and more
What we are offering?
A supportive, trusting, and transparent working environment
Supported personal development plan and subscription to online learning tools (eg Pluralsight)
A highly collaborative Data Science and Engineering Team and the rest of the Data, Intelligence and Planning department
A place to look at things differently and challenge and offer solutions
What do you need to have done before?
Previous experience as a Data Engineer or a Software Engineer
Proficient manipulating and processing data with SQL, Python, or a similar scripting language
Able to design, build, test, and document code and data products that are scalable and reusable
Able to manage and maintain metadata
Understand potential or common issues with databases, processes, products and services
Experience working with relational and non-relational database technologies: SQL, NoSQL, basics of database design and operation
Familiarity with APIs
Experience with git / version control
Interest in the whole data journey, from collection and cleaning through to analysis and modelling
Communication skills: comfortable asking questions, pair coding, code review, ability to discuss and execute project requirements, and ability to explain the output concisely to non-technical stakeholders
Comfortable with statistics
Comfortable working independently and as part of a team
Beneficial
Google Data Engineer Certification
Experience with Financial data
Experience with Terraform and CircleCI
LADbible Group is an equal opportunities employer. We are determined to create a diverse group at all levels of our company and we welcome all members of the community to apply for openings with us.",4.5,"LADbible Group
4.5","Manchester, England",-1,201 to 500 Employees,2012,Company - Private,Publishing,Media,Unknown / Non-Applicable,-1
Data Engineer,-1,"Data Engineer
Location


Basingstoke

Job Code

239

# of openings

1

Job Purpose

Reassured's web based CRM system has been developed internally and has currently got a strong team of developers maintaining, expanding and creating functionalities, providing the business with the flexibility to quickly expand, adapt and/or change depending on the market and business needs.

The role of the Data Engineer is to look after all of the company maintained databases across our entire estate, the internal CRM and those connected to public facing websites. The Data Engineer will develop and implement data flows to connect the different operational systems as well as data required for analytics and business intelligence systems.

The Data Engineer will take responsibility for our data pipelines, databases, data warehouse and data lakes, working closely with the IT teams and Senior IT Managers to ensure maximum uptime, appropriate back-up and disaster recovery solutions in place as well as ensuring Information Security, Cybersecurity and GDPR policies are applied on our day to day processes.

The ideal person has to have a significant set of technically skills, including deep knowledge of (My)SQL. Likewise, an excellent communicator, the person will have the ability to question non-technical colleagues and be able to work across departments to understand what MI is important to business leaders from the different datasets.

Key Responsibilities
Develop and implement data flows to connect the different operational systems as well as data required for analytics and business intelligence systems.
Maintain and update existing databases across Reassured’s internal and external systems
Writing and optimising SQL statements
Writing and optimising ETL scripts.
Maintain data dictionaries and source-to-target mappings
Support the IT developers to write better SQL statements
Design, build and test data products based on feeds from multiple systems using a range of different storage technologies and/or access methods.
Plan resource requirements from high level specifications
Creating technical specifications and test plans
Provide regular reports on the state of the company’s databases
Translates data into valuable insights that inform technical and business decisions
Keep up to date with advances in digital analytics tools and data manipulation products
Carry out other responsibilities as required by management
Overnight maintenance and updates on an as required basis
Always be punctual and respectful of other employees
Be polite and represent the business respectfully
Knowledge, Skills & Experience
Proven data, analytics and engineering skills
Writing and optimising SQL, MySQL
Database Administration
Data Warehousing
Data Streaming
Data Integration and Analytics (Snowflake, Wherescape, Power BI, etc)
Managing and testing database backup and restore procedures
Monitoring system performance with a view to capacity planning
MySQL clustering and database replication
Familiarity with other SQL/NoSQL databases such as PostgreSQL and MongoDB
Replication configuration using Percona XtraBackup
De-facto standards and best practices in MySQL/Percona, particularly security
Knowledge of MySQL and Percona-specific features and functions",4.2,"Reassured
4.2","Basingstoke, England",-1,501 to 1000 Employees,2009,Company - Private,Insurance Agencies & Brokerages,Insurance,Unknown / Non-Applicable,-1
Data Engineer,-1,"We are looking for an Engineer from a computer science or numerical/statistical background to join our data and analytics
practice at Aiimi. You will join an established team consisting of data scientists, data visualisation consultants, AI developers
and data analysts, working collaboratively on both internal and external projects. You will help this team get the data they
need by sourcing it from disparate systems, cleansing, transforming and prepping the data for use within analytical and
predictive models.

We will train you in the tools and tech required to do this but analytical thinking, problem solving and coding skills are
required for this role. Aiimi will invest in your personal development, providing opportunities to obtain professional
qualifications, attend technology conferences, and taking part in team hacks to explore cutting-edge technologies and
ideas.

You will have the opportunity to help businesses grow through adopting new and exciting technologies, such as: cloudbased
analytics, enterprise search, predictive modelling and real-time reporting. We help our customers solve problems
and make the right decisions using data insight and advanced analytics. Almost all our work is done by embedding
ourselves into customer teams, so you will be required to travel onsite to be part of one of the many innovative projects that
we run within utilities, manufacturing, retail and finance sectors.

Due to the nature of the work we do, all applicants will need to be able to travel and potentially work away from home as
part of the role.

Requirements

The key areas of responsibility for the Data Engineer include:
• Collaboration: you will be excited by working as part of a team of data scientists, analysts and visualisation
professionals
• Communication: you will possess an ability to communicate complex technical concepts to non-technical/business
users
• Problem Solving: be able to use data as a foundation to solve business problems
• Analytical Thinking: an ability to break down complex problems into single and manageable components
• Detail Oriented: an ability to maintain a high standard of outputs under tight deadlines
• Lead by Example: help inspire our clients to embrace new technologies and ways of thinking
• Understanding legacy processes and adapting new technology to manage change
• Meeting with areas/of business to gather requirements and an understanding of data

We would like to hear from people with academic and or commercial experience in the following areas:
• SQL coding skills
• Python coding skills
• Experience optimising database queries and ETL processes including performant joins and indexes
• SQL Server Integration Services to setup, design and manage ETL jobs
• SQL Server Management Studio for setup, administration and management of databases
• Knowledge of Azure data services (ADF, Azure Data Lake Analytics, Data bricks)
• Familiarity with distributed systems (Hadoop, MapReduce, Hive, U-SQL, Spark, etc.)
• Familiarity with unstructured data and No-SQL technologies

Qualifications
Academic background in Computer Science, Maths, Physics, numerical or statistical discipline or demonstrable
commercial experience in lieu of this

Benefits

• Competitive starting salary
• Up to 10% of basic salary in flexible benefits (to include death in service and critical illness cover as standard
plus private healthcare, dental, pension etc.)
• Up to 10% of basic salary in bonus
• 25 Days holiday (excluding bank holidays) – increasing by a day every 2 years
• Promote training and personal development
• Bi-annual company retreats

We’re a small team working our way through lots of applications, so please bear with us. If you don’t hear from us within two weeks, we’re sorry that it’s not worked out this time. We’ll keep your details on file for any relevant roles that come up – to opt out of this, just drop us an email: crichmond@aiimi.com.

Aiimi is an Equal Opportunities employer and applicants are selected solely based on their relevant aptitudes, skills and abilities in line with the job they are applying for. No applicant shall receive less favourable treatment on the grounds of sex, marital status, civil partnership status, trans-gender status, pregnancy, maternity, race, nationality, ethnic origin, religion, belief, sexual orientation, disability, age. This is not an exclusive list.",4.8,"Aiimi Ltd
4.8","Milton Keynes, England",-1,51 to 200 Employees,2007,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"This multi-disciplinary role broadly support the aim to modernise the way in which economic statistics are developed; providing data science supported evidence and data engineering support to projects. At the outset of each project, staff in this role will work from an initial design or concept phase, to successful implementation of both regularly published statistics and ‘one-off’ experimental sets of statistics.

This involves data interrogation, the coding of functions that conduct statistical or data manipulation tasks, as well as the coding of data processing pipelines. The team are developing better economic statistics using new tools and techniques.

That primarily includes a new cloud computing platform (DAP), making use of the Spark libraries to process and analyse large datasets (Python and Spark are the main tools that are used in the team) and secondarily supporting smaller projects with local systems built upon Python or R libraries. With this, we can apply data science and data engineering techniques to produce timelier, more granular and more insightful statistics

Responsibilities
• Work with Economic Statistics experts to understand what statistics need to be produced.
• Conduct data analysis and visualization of the key datasets used to produce the required statistics.
• Produce initial design documents and diagrams for data processing systems, considering the statistical or data processing methods that are needed for the task, as well as the design of the overall data model.
• Contribute to Python libraries of statistical or data processing functions, ensuring that any functions are well unit tested.
• Write Python code that will systemize the processing of data, based on initial design documents. This includes writing unit / integration tests and managing versions of code with Git.
• Report on the progress of prototype systems to customers, clearly articulating the impact of various data processing steps on the outputs.
• Maintain and review documentation for statistical and data processing functions, as well as data processing pipelines.
• Manage working relationships with stakeholders across Economic Statistics, keeping people up to date on progress and highlighting any risks with projects.
• Apply agile project management principles to managing projects and tasks on a day-to-day basis
• These roles provide an opportunity to meet these responsibilities using newly acquired software tools, processing, analysing and validating data in a Cloudera Environment using tools such and languages such as SQL, Impala, Hive, PySpark etc.

Person Specification

Essential Criteria:
• Expertise and experience in using Python in the context of PySpark.
• Able to listen to the needs of technical and business stakeholders and interpret between them. Able to manage stakeholders’ expectations and be flexible, is capable of proactive and reactive communication. Facilitates difficult discussions within the team or with diverse senior stakeholders.
• Uses agreed standards and tools to design, code, test, correct and document moderate to complex programs and scripts from agreed specifications and subsequent iterations. Collaborates with others to review specifications where appropriate.
• Able to review, and guide others in reviewing, requirements, specifications and define test conditions. Able to identify, and guide others in identifying, issues and risks associated with work whilst being able to analyse and report test activities and results.

Desirable Skills:
• Experience with SQL (especially in the context of HADOOP).
Behaviours

We'll assess you against these behaviours during the selection process:

Communicating and Influencing
Changing and Improving
Managing a Quality Service
Benefits
The Office for National Statistics is part of the Civil Service, and as such we share a number of key benefits with other departments, whilst also having our own unique offerings to support our 5000+ valued employees across the business.

Whether you are hearing about us for the first time or already know a bit about our organisation, we hope that the benefits pack attached (bottom of page) will give you a great insight into the benefits and facilities available to our employees, and our fantastic working culture.

We are an organisation that takes the well-being of its employees seriously and lives and breathes the desire to modernise the workplace of the future. Everyone, from our office-based staff in Newport, London and Titchfield, to our field interviewers and airports and ports passenger survey staff, are part of a diverse and inclusive family.

Inclusion & Accessibility

At ONS we're always looking to attract the very best people from the widest possible talent pool, and we are proud to be an inclusive, equal opportunities employer. As a member of the Business Disability Forum and a Disability Confident Leader we’re committed to ensuring that all candidates are treated fairly throughout the recruitment process.

As part of our application process, you will be prompted to provide details of any reasonable adjustments to our recruitment process that you need. If you would like to discuss any reasonable adjustments before applying, please contact the recruitment team in the first instance.

If you would like an accessible version of any of the attachments or recruitment documents below or linked to in this advert, please contact the recruitment team who will be happy to assist.",4.1,"UK Government - Office for National Statistics
4.1","London, England",-1,51 to 200 Employees,-1,Government,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Data Engineer

About us

TravelNest is an Edinburgh based travel tech startup. We have created a platform that enables holiday let owners to set up, manage and optimise all of their marketing from one place. We aim to become the world's most host centric company, empowering hosts to realise their ambitions by unlocking the potential of accommodation, everywhere.

By joining us you will be working on a product that has the potential to really transform booking gains for our customers. In a fragmented marketplace where there is rapid growth you could be growing our acquisition of customers for a product that will truly delight users like never before.

We have an ambitious goal of winning the global market and we believe that our team can build a product our customers love and use, time and time again.

About the Role

At present we're a small data team working closely with marketing, customer experience and product engineering teams on the full breadth of data work. We're doing everything from building data pipelines and defining and creating datasets, to building reports and dashboards, to more advanced data science and analytics.

We've worked closely in the past with our engineering team to build our data pipelines to where we are today but now we're looking for someone to focus on the analytics engineering side of our current work. That is:
Building and maintaining data pipelines
Working with teams to define and build the datasets they need to make better decisions
Building reporting off these datasets and
Helping the teams self-serve data wherever possible.
Our current stack is fully cloud-based in AWS. We have a data lake in S3 populated via AWS Lambdas and Stitch. Our ETL jobs are scheduled and run in Apache Airflow and our datasets are stored as parquet files in S3 and served via AWS Athena.

Our main dashboarding and reporting tools are Sisense for Cloud Data Teams (formerly Periscope) and Google Data Studio. Our data scientists While this is our current setup, we're not constrained by this stack. There's flexibility to choose the right tool for the job if that will deliver the outcomes we need.

What you'll do

You'll bring our data together and make it available to TravelNest so we can all make better decisions on a daily basis.

What does that mean in practice? In any given week you could be:
Building and maintaining the data pipelines that bring all of our data together form internal databases and 3rd party tools like Google Analytics, Facebook Ads and Salesforce into our analytics archive.
Ensuring data cleanliness and quality in all of our datasets. This will include writing tests, documentation and maintaining automated alerting to ensure we catch data issues fast.
Working with teams across the business to develop the datasets and reporting tools they need to do their jobs and make better decisions.
Help build
Working with data scientists to build more advanced analytics into the product or to serve model outputs to teams around the business.
What we're looking for

Strong Python and SQL skills. We write SQL and Python on a daily basis. Our ETL processes are SQL based and we use Airflow (written in Python) as our current data pipelining tool. We also use Python extensively for more advanced analytical work. We use Git to version control all of our analytical projects and data pipeline code so experience of this is also a plus.

Experience with cloud technologies - we use AWS for all of our data and engineering work. This includes running Airflow on EC2, S3 for data storage and AWS Glue/Athena for data warehousing.

A self-starter who isn't afraid to get their hands dirty, prioritises your focus based on impact, and owns projects from start to finish.

Someone who can work effectively with less technical teams/staff to understand their requirements and translate these needs into high-quality data products that help people make better decisions.

Strong analytical and data visualisation skills. We're not just looking for someone who can build high performing data pipelines. We want someone who understands and cares about what data is flowing through those pipelines. You'll be working with teams to build dashboards and reporting and with data scientists and engineers to deliver data driven products so having the analytical chops to deliver these is essential.

In Return

We offer a competitive salary, stock options, a great working environment and the opportunity to grow our product and business together.

We are only just getting started and believe there is a better way for our customers.

Equal Opportunities

We are an equal opportunity employer and value diversity. We do not discriminate on the basis of gender, race, religion, sexual orientation, disability or age.",4.5,"TravelNest
4.5","Edinburgh, Scotland",-1,1 to 50 Employees,-1,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"We are looking for an experienced Senior Software Engineer to join our Data Services team and help us build products that fundamentally change the way insurers see the world, enabling them to move from an assumption based understanding of risk, to an empirical, data-driven view.

Your role:

You will be working on some of the company’s biggest challenges. Our Data Services team are focused on developing a cutting edge data platform with highly sophisticated observability and automation capable of handling large data sets to serve more data with increased clarity to our customers. This is a greenfield project and the team is a mixture of engineers and data scientists using GoLang, Python, ElasticSearch, Docker, and AWS.

We are looking for candidates who are driven to build effective technology solutions that solve significant real world problems. You are a great technologist and regardless of which language you use, you take pride in writing clean, effective code.

As a Senior Software Engineer at Cytora, we also expect you to contribute to higher level technical architecture discussions and take opportunities to mentor and coach less experienced colleagues.

What your day-to-day would look like:
Beginning each day with a stand up to synchronise efforts across the team, informed by weekly sprint planning with the whole company
Contributing to the refinement our development process, which already includes a well-maintained customer driven feature backlog, strong code review/testing processes and frequent continuous integration driven deploys of production features
Working on exciting long-term, high-value projects based on the latest research from the fields of AI and NLP
We take pride in test driven development and peer reviewing colleagues’ pull requests to ensure what we build is simple, elegant, reliable and self-documenting
Each week includes at least one opportunity for learning, typically in the form of a reading group with a presentation from somebody in your team
Requirements

What we are looking for in candidates:
Strong data engineering background - designing data pipelines, ETL tools, data warehouse/data lake, dashboards, etc
Experience building large data processing pipelines and data platforms
An understanding of Data Science if not experience in this area
Strong programming skills gained in a production environment - we use Go and Python but are open to Engineers from any background
Excellent knowledge of data structures, storage systems and cloud infrastructure (GCP, AWS or Azure)
Excellent communication skills, with the ability to articulate detailed technical concepts at a high level
Bonus points:
Familiar with orchestration tools such as AWS simple workflow, step functions, airflow, kubeflow
Exposure to machine learning and natural language processing
Familiarity with Agile development methodologies (including test driven development and continuous integration)
An understanding of or experience working with temporal modelling
Experience with mentoring and coaching other less experienced engineers
Benefits
Remote working
Private Health Insurance
Pension Plan
Training & Development
Stock Options
Flexi hours
Learning and Development budget
Mental Health initiative inc CBT counselling
Team and company event budget
About Cytora

Cytora transforms underwriting for commercial insurance. The Cytora Platform enables insurers to underwrite more efficiently and deliver fairer prices to their customers. Cytora is a trusted partner to global insurers, backed by leading venture capital, and supported by builders of some of the world’s most successful technology companies. With a world-class team of experts in machine learning, risk modelling, and strategy, Cytora is powering the future of commercial insurance.

To learn more about our culture and benefits visit our careers page: http://www.cytora.com/careers

Equal Opportunities

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",3.7,"Cytora
3.7","London, England",-1,51 to 200 Employees,2014,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Due to constant growth and four more software engineers joining this month alone, they are now opening a Data team in the Belfast office

You know you’re joining a good company when they have a huge recruitment drive amidst a pandemic

Your role:

You will be the first Data Engineer working on business-critical projects from the get-go

They are currently migrating their entire Data Warehouse to AWS whilst rebuilding and re-factoring their current suites to help understand customer demographics

This is fully encompassed role, as you will be involved in data design and requirements as well as building and re-designing data structures

Your skill set:

Strong SQL experience
Understanding of basis Data principals- SSRS/SSIS/Tableau etc
Determined- You’ll be joining one of the most technical companies in Belfast
Craic- Good craic is needed!
AWS experience would be highly desirable

Why join?

Be part of the family. Everyone’s opinion counts
Tech first- Unrivalled cloud experience
Flexible- It’s an adult environment with no clock watching
Potential to build a future team

Next Steps:

Please submit your application or speak to a specialist consultant from the Abacus team on 0044 (0) 28 9031 3157 for a confidential discussion. We aim to respond to all inquiries within 4 business hours.

The team at Abacus manages a range of permanent and contract positions throughout Northern Ireland, the UK and the Republic of Ireland. If you are professionally qualified we can support your job search.

Terms and Conditions and Privacy Policy on www.abacus.careers",-1,Abacus Professional Recruitment,"Belfast, Northern Ireland",-1,1 to 50 Employees,-1,Company - Private,Staffing & Outsourcing,Business Services,Less than $1 million (USD),-1
Data Engineer,-1,"Working as a Data Engineer, you will be the “go to” person for all data engineering and data infrastructure related matters on our Brain Training app. You will be an invaluable partner for the data team, providing them with the solid foundation they need to transform raw data into valuable insights for the business. You will own our tracking design, manage our ETLs, optimise our data pipelines and collaborate with the rest of the data team to provide the visualisations and dashboards that drive the product decisions we make on a daily basis.

Requirements

WHAT YOU'LL DO

Be the in house expert on how to design event tracking for our apps
Build and maintain ETL and data pipelines, to be efficient, clean and scalable
Be a key partner for our current data team in all matters on data engineering
Manage our data infrastructure on AWS, continually assessing usage and needs
Contribute to our visualisation tools, sharing your magic with the wider business!

ESSENTIAL SKILLS

Expert SQL & database skills & familiarity with other languages (Python/Java/Similar)
Comfortable designing event tracking solutions and data models from scratch
Familiar with the data needs of a mobile app, games or digital business
Familiarity with AWS, related services and/or tools for scheduling jobs
Experience using github to collaborate on ETLs or other codebases within a larger data team

NICE TO HAVE

Experience in developing data pipelines for predictive models
Experience in mobile apps, F2P or subscription business models
Experience developing data sources for Tableau, Looker or similar
Experience integrating third party data sources & APIs
Experience using Terraform to manage infrastructure

Benefits

WHAT YOU'LL GET

We are an ambitious company, so we aim high in everything we do. We believe we can have a real impact on the world. We recognise that to do this we need to be open to new ideas and to challenge one another every day to ensure real personal and professional growth. Ultimately, we care about each other and we know that we will succeed as a team. It’s why, while remote working we make time to catch up, play online games and do virtual pub quizzes.It’s also why we hold regular team days and hackathons to ensure the team is always trying new things, together. In our view, ambition, openness and teamwork are the surest way to achieve our amazing goals. A few of our other benefits include:

Choice of laptop plus either an iPhone or Google Pixel
Regular hackathons. Work with different teams, try new ideas and experiment with new projects
Performance related bonus scheme
A training budget of £1,000 per year to spend on training, conferences, books and more
While we are all remote working, flexible working to us means, full autonomy in how you work and organise your day at home, even around childcare or other responsibilities;
In the office we have a relaxed and fun work environment with a pool table, board games, PS4 + PSVR for use anytime (games not available at the moment due to COVID rules) ;
Freedom and support to organise and participate in knowledge exchange events and charity activities;
Pension and BUPA health insurance, sporting allowance;
25 contractual days holiday plus bank holidays; and
In the office, Breakfast and snacks provided all day along with a fully-stocked drinks fridge (slightly limited at the moment due to COVID rules)

At Peak we are open to and encourage applications from absolutely anyone. We believe in the potential of everyone; regardless of race, religion or belief, ethnic origin, different physical ability, family structure, socio-economics, age, nationality or citizenship, marital, domestic or civil partnership status, sexual orientation, gender identity, or any other difference that makes you, well, you.",3.4,"Peak
3.4","London, England",-1,51 to 200 Employees,2012,Company - Private,Computer Hardware & Software,Information Technology,$1 to $5 million (USD),-1
Data Engineer,-1,"Description

Data Engineer – Surrey – 5 months plus – Competitive

My client is looking for a Data Engineer with the following skills:

Data Modelling and Implementation
Design and implement data models in distributed database systems
To capture business processes
That enable business to carry out summary and detailed analysis in accurate and consistent manner
ETL and ELT implementations:
Design and implement ETL/ELT solutions
Based on understanding the different paradigms and knowing which and when each is appropriate in different circumstances
Design ETL/ETL solutions that are lean, efficient, scalable, with transparent and centralized business logic processing layer.
Implement data warehouse, storage and data structures in Azure Synapse, and Data Lake to support reporting, analysis and Machine Learning workflows
An industry background from Retail, Omni-channel or Digital marketing,

Technical skills as follows:

Azure Synapse Database Administration
Kimball dimensional modelling in big data environment
Knowledge and implementation of Rapidly Changing Dimensions
Methodologies to implement and manage large dimensions (over 200m)
Methodologies to implement and manage very large fact tables (over 40bn)
Methodologies to provide appropriate data structures for use by visualization tools e.g. Qlik, Tableau, Power BI
Experience in building and applying predictive, classification and time series models
Create and manage user permissions
Allocate appropriate resource to different user types e.g. ETL Loaders, regular database users, group users for dashboards
Workload management and monitoring SSIS including utilizing Azure components within SSIS
Extensive Python (and applicable modules) experience, data processing, compression and storage
Azure Data Factory
PySpark",4.0,"PSD Group
4.0","London, England",-1,51 to 200 Employees,1991,Company - Private,Staffing & Outsourcing,Business Services,$500 million to $1 billion (USD),-1
Data Engineer,-1,"Data Engineer
Overview


EF is the world leader in international education. Our mission is to break down barriers in language, culture, and geography and so far, we have helped over 15 million people learn a language, discover the world or earn an academic degree. We have 500 schools and offices in over 50 countries and employs over 52,000 staff and teachers. In today’s increasingly complex and interdependent world our mission is more relevant than ever.

The Role


This role is a crucial part of our EdTech Data Science team. We’re a lean and agile team of Data Engineers and Data Scientist focused on building modern cloud-based infrastructure to enable ML for Education. You will be contributing to our event-based streaming data platform that enables real time insights for teachers and students in the classroom or when studying remotely online. You will also help us build a world-class cloud data warehouse for our Data Scientists, Analysts and BI specialists.

Our current EdTech stack is based on AWS and includes Kubernetes, Kafka, Kinesis, Flink, Snowflake but you will also work with the wider business to develop ETL processes to move data from multiple data sources into our data lake/ warehouse.

Main Responsibilities
Create and contribute to a data platform that enables self-service analytics and creates the foundation for data science applications across our businesses
Build batch and streaming pipelines for the purpose of analysis & data science
Design, implement and maintain the data warehouse
Support and maintain existing production services
We ask that you have
AWS, GCP or Azure cloud expertise
Experience with cloud-based data warehousing (Snowflake, Redshift or similar)
Experience with Agile methodologies and practices
Experience using distributed version control systems (e.g. git, mercurial)
Experience in developing data processing applications in Java/Scala/Python
Experience working with streaming data sources (e.g. Kinesis Streams or Apache Kafka)
Experience with Kubernetes, Helm charts and Docker
Experience with real-time processing engines (e.g. Apache Flink, Apache Beam, Apache Storm)
Excellent verbal and written skills in order to effectively communicate with partner teams
Other useful skills include
Ability to write efficient SQL statements
Understand data warehouse design and ETL performance techniques
Experience with 3NF, Data Vault & Dimensional modelling
Experience with Master Data Management
Experience with Data Governance",3.3,"EF Education First
3.3","London, England",-1,10000+ Employees,1965,Company - Private,Education Training Services,Education,Unknown / Non-Applicable,-1
Data Engineer,-1,"Our company and vision

On the Beach sends over 1.5 million people on their perfect beach holiday every year, and while the Covid-19 pandemic has caused disruption for the travel industry, we have not paused our ambition to become Europe’s leading online retailer of beach holidays. We’re completely focused on making it easy for people to find, book and enjoy their perfect beach holiday. To reach our goals, we work as a team to a clearly defined set of values; these are what make On the Beach a great place to work for our colleagues and help us deliver the best experience possible for our customers. We’re bold. We’re open. We’re dynamic.

On the Beach is a data-driven business. Whether leveraging real-time analytics to drive decision making, propensity modelling, optimising PPC spend or aggregating fast-moving travel data - accurate, timely and accessible data is fundamental. Working primarily in a greenfield environment, you will be joining us early on our journey to the cloud. You will be an early member of the team responsible for building out an industry leading data platform, supporting our vision of democratising data access across the business, empowering our teams and putting data at the heart of everything we do.

The future of Personalisation

The personalisation team is responsible for building out the platform that powers all personalisation on site. This is a high impact team aiming to show the right product, to the right customer, at the right time. We’re using machine learning to rank search results and recommend the perfect beach holiday to all of our customers. The team are iterating on our current algorithms and are looking for someone who can bring more experience and new ideas to the team. This is the next chapter of personalisation at On the Beach, so a real opportunity to shape a core part of the business.

The role

We work in cross-functional teams where every data engineer is both a member of the wider Data community and fully embedded into a cross-functional team alongside engineers, data scientists and product managers.

As a data engineer in Personalisation, you’ll support the team in meeting their goals, using their priorities to build out new capabilities in our Data Platform in line with the Architectural strategy. You""ll be able to build, deploy, operationalise and monitor data systems with a focus on security and reliability.

You’ll also work closely with our Data Scientists to apply Continuous Delivery and DevOps principles to model training and deployment. You""ll have experience in a variety of data modelling approaches, really understand the challenges that come with working with very large data sets. You’re comfortable working with structured, unstructured and semi-structured data, have practical knowledge of event driven approaches and tooling, and you get a real kick from performance tuning.

As part of the wider Data team, you’ll play a key role in shaping the technical direction of our platform and our approach to data. You’ll bring robust engineering practises including TDD and pair programming, along with hands-on experience of building scalable pipelines and re-usable infrastructure.

We’re evangelists of agile values and principles but each team is responsible for their own way of working. All members of the team have the opportunity to help influence the teams’ processes through a continuous improvement mindset. We work in a fast paced, low ceremony environment and deploy multiple times a day.

We use a variety of programming languages across teams such as Ruby, C# and Python so polyglot thinking is a must.

Benefits

Generous discount on holidays
Flexible working hours
Annual Hack Week
Simplyhealth Optimise Health Plan and eye care contribution
Travel to work scheme - interest free tram and train loans and cycle to work scheme
Onsite subsidised coffee shop - barista-style coffee and snacks
Food and drink discounts across a number of venues in Manchester City Centre
Gym discount
Share incentive plan
Enhanced maternity, paternity and adoption pay
The Sandbox - free bar every Friday PM
Charity contribution - we match any funds raised by an employer for charity, doubling the total funds raised.

Remote Working

For an immediate start you will work fully remotely then will be based out of our bespoke tech-hub in the heart of Manchester city centre. However after a successful switch to remote working due to the Covid crisis, flexible remote working opportunities are available; please discuss with the hiring manager when applying.

Equal opportunities

As an equal opportunities employer we value diversity and welcome applicants from all sections of the community regardless of gender, ethnicity, disability, and sexual orientation.

You will be kindly asked to provide your equality information as part of your application process to On the Beach. Any personal equality information given to On the Beach will be handled with the utmost confidentiality and will only be used for monitoring and identifying improvement areas. All the information disclosed by applicants is stored on our ATS, in line with the General Data Protection Regulation (GDPR) and can only be accessed by selected Human Resources team members.",4.3,"On The Beach
4.3","Cheadle, West Midlands, England",-1,201 to 500 Employees,2004,Company - Public,Internet,Information Technology,$100 to $500 million (USD),-1
Data Engineer,-1,"Our Data, Analytics & Intelligence team are at the core of the latest developments and key decisions within our business. They’re a constantly expanding team and currently on the lookout for a Data Engineer to join them on a permanent basis.

Our team are driven by a passion to help make a tangible and lasting difference in people’s lives through the innovative transformation of our products, and you’ll have that same passion.

Within this role, you’ll hold responsibility for the creation and maintenance of a logical data model, integrating data from multiple data sources in to a central Enterprise data warehouse. You’ll be able to design and apply data cleansing and data standardisation rules, providing clear documentation of the business rules embedded in the system, with the potential of solving data quality issues.

Whilst you’ll have a variety of stakeholders, you’ll work closely with the wider Data team to understand what the data journey needs to look like (conversion, processing, etc), specifically working closely with the Data Architect to create an overview of the data lineage.

Please note this role will initially be working from home, with a shift to a hybrid office/home working set up as lockdown restrictions evolve. We’re also committed to the work/life balance of our teams, so we’re happy to consider flexible working options.",3.8,"AXA
3.8",Kent,-1,10000+ Employees,1985,Company - Private,Insurance Carriers,Insurance,Unknown / Non-Applicable,-1
Data Engineer,-1,"Role Purpose:


To work on a range of projects supporting the data driven principles of Greensill. Design and build solutions that will consolidate and integrate data from both internal and external sources into a cloud-based enterprise data lake. Provision this data to consumers such as BI, data science, etc.

Accountabilities:
Quickly identify and understand user requirements and translate them into deliverables.
To design, build and maintain batch and streaming data pipelines into the data lake as well as provisioning data to support consumers.
Structure data in the appropriate manner for efficient storage and accessibility for APIs, reporting, analytics, machine learning and data exploration.
Performance tuning and optimisation.
Promote effective and efficient use of data within the organisation.
Skills and Abilities:


Kafka/Spark for building data pipelines
File storage using S3 (Parquet, JSON, etc.)
Apache Airflow
Logging and audit e.g. CloudWatch
Implementing single sign-on and security models e.g. AWS IAM, Active Directory, etc.
Structured relational data in 3NF, fact/dimensional models and unstructured data in NoSQL databases
CI/CD tools; Terraform, Jenkins, Docker and Kubernetes
ETL/ELT design & development
AWS Athena
AWS Glue
API design and build
Data manipulation/analysis using SQL
Analysis techniques to identify potential process improvements
Excellent verbal and written communication skills and interpersonal skillso Acts with honesty and integrity
o Curious and resourceful seeks out difficult questions and finds solutions
o Resilient, able to learn from mistakes and move forward
o Flexible, adaptable and able to deal with ambiguity
o Collaborative, thrives when working towards shared goals
Desirable
Additional programming skills e.g. SOAP, Java
Jupyter notebooks
API access to 3rd party data services e.g. Dun & Bradstreet, Thompson Reuters, SAS, Encompass, etc.
PostgreSQL
Redshift
MongoDB
Report & dashboard design and development using enterprise BI tools e.g. Tableau, SAP BI, or similar
Enterprise ETL tools e.g. Talend, Informatica, or similar
Familiar with MDM and related tools e.g. Tibco EBX or similar
Familiar with Metadata Management and related tools e.g. Alation or similar
Familiar with any Data Quality tools
Previous experience working in a complex and demanding Financial Services environment
Our culture is founded in a commitment to challenging the status quo.


To help make finance fairer for everyone, we're changing the way Working Capital Finance works. Our diverse, global offices combine bright thinkers from different backgrounds working autonomously and creatively to find new ways to re-invent the industry.

Entrepreneurial


We're not afraid to fail, pivot and adapt when it comes to our products and believe that our people should be given the same opportunities to pave their own path. Our dynamic structure and agile organization means everyone, in every team can make an impact and find purpose and pride in their work.

Innovative


We love trying new things, and most days you'll find us 'innovating on the fly', pushing the limits of what's possible to create new solutions to seemingly impossible challenges. We're data-driven and tech-focused, but still centred around our customers. As active problem-solvers, we also firmly believe that just because that's the way it's always been, doesn't mean that's the way it should be.

Collaborative


We're a tight-knit bunch, who are proud of our heritage, and like nothing better than welcoming new people to the team. In fact, working as a team is at the heart of everything we do from our diverse and inclusive global family to a truly accessible, flat structure than encourages transparency and participation in all aspects of the company.",4.0,"Greensill
4.0","Daresbury, England",-1,201 to 500 Employees,2011,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
Data Engineer,-1,"A motivated Data Engineer is required to join a team within a hugely successful corporate company based in Cardiff utilising Cloud base Data Warehousing. Salary £30,000 - £42,000 Plus Bonus & Benefits Package

As a Data Engineer for this large & complex corporate company based in Cardiff, you will design, build & enhance data platforms & solutions that provide the business with actionable insights derived from their data.

The Data Engineer’s work will include:
Planning and achieving sprint tasks from which the technical solutions will be created. These solutions will mean that the business can identify commercial opportunities or understand why they are needed

Supporting the data visualisation and data pipelines, ensuring that the services are up to date and the business can rely on them

Inputting into and managing the data artefacts, which will include planning, task completion, unit testing, peer review, release, meta data, data modelling and deployment. This will ensure that the right controls have been applied whilst maintaining the accuracy of the process’s and controls to maintain quality of work

Attending DataOps Design Authority meetings to provide input to the data value delivery methods, providing operational efficiency and fostering effective collaboration

Being responsible for the creation and input of meta data to sufficient levels, to assist the business in understanding what they are able to do with it

Converting user stories to technical tasks, translating the business goal to a technical one & enabling the delivery of a technical solution

Using a number of modern data platform tools set up in an agile delivery method to progress in a journey towards continuous integration and deployment of projects in the cloud

Skills & Experience:
A proven track record of delivering data engineering solutions including ETL development, data streaming, data integration and analytics

The ability to communicate effectively to all levels of stakeholders is essential including the communication of complex data management issues to non-technical stakeholders

Have knowledge of modern data paradigms within the cloud in order to enable a business to maximise its value from data

Experience with some of the following is required - Wherescape, SSIS, ADF, Snowflake, PowerBI, Tableau, RBDMS: Oracle, MSSQL, Postgress, Databricks, Kafka, DataIQ and QuerySurge, Jenkins

Proven data, ETL, analytics and engineering experience

Can demonstrate logical and lateral thinking considering all angles in decision making

Communicates clearly and logically using ""story telling techniques"" via simple language and visuals to suit the audience

Interested candidates need to apply now and can expect initial feedback on their application within 72 hours.",4.9,"Jenrick Group
4.9","Cardiff, Wales",-1,1 to 50 Employees,1967,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Data Engineer,-1,"Caval require 2x Data Cabling Engineers for work in Buxton.

4 weeks work

45-50 hours per week!

FREE PARKING!

CSCS card required and experience.

If available please hand your CV into the e-mail address provided.

Caval Ltd

Contract length: 1 month

Job Types: Full-time, Contract

Schedule:
10 hour shift",-1,Caval Ltd,"Buxton, East Midlands, England",-1,1 to 50 Employees,2012,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
Data Engineer,-1,"We are combining science, large scale data and machine learning to tell you what to eat based on your unique metabolism. We’re leading the world’s largest ongoing nutritional research project in collaboration with scientists from leading universities including Harvard, King's College London, Massachusetts General Hospital, Oxford and Stanford.

We are a well-funded start-up based in London and Boston, and are backed by founders, investors and entrepreneurs who have built multi-billion dollar technology companies. Join us in tackling wide-ranging technical challenges from DNA analysis, to machine learning, to building apps and products for millions of users.

We're also the Engineering team behind the popular COVID Symptom Tracker - designed by doctors and scientists at Kings College London, Guys and St Thomas' Hospital and our talented development team. This app is contributing to advance vital research on COVID-19 and helping our nation track it's spread.

Key Responsibilities
Develop reliable and flexible data processing pipelines that can rapidly evolve to handle new technologies and modelling techniques
Work alongside our Data Scientists to improve their research workflow and access to automation.
Be an active contributor to the evolution of our architecture, tools and processes.
Build tools to assess models’ quality and automate their rollout
Must Have
Experience writing clean code and doing TDD with languages like Python, Go, Java, Typescript, C#, or similar
Experience building complex APIs with microservices oriented architecture, ideally running on Kubernetes
An understanding of Distributed Computing and the trade-offs between various software architectures as they relate to performance, resiliency/fault tolerance, data consistency and more.
Working experience of SQL
As a Series A Start-up, we frequently deal with high levels of ambiguity. It’s imperative that you can perform under these conditions. We work in an incredibly supportive environment with cross-functional teams that aim to help each other grow.
We believe in outcome over output. As such, we prefer a “technology agnostic” mindset that’s aimed to get the job done - whatever tool is required.
Nice to Have
Bridge Data Science and Engineering by building a shared understanding and reconciling approaches.
Experience working closely with data scientists as end-users.
Experience with Python machine learning libraries.
Understanding of best practices around CI/CD and release process
BSc or MSc in Computer Science or an equivalently rigorous discipline
Past experience with data processing frameworks, like Spark or similar
We appreciate those who dedicate themselves to lifelong learning.
Possessing a self-improvement mindset, reading software engineering books, attending meet-ups, speaking at events or generally contributing to the world of OSS is a huge plus!
What we can offer
Competitive Salary & Share Options
The opportunity to make the world healthier, and have fun learning about cutting-edge science across biology and genomics
Active contribution against the fight with COVID19 and the opportunity to save lives
An exciting early-stage start-up environment, without the funding worries, and with a commercial team that has built billion-dollar revenue businesses
A crucial role as one of the first colleagues in a truly world-class multidisciplinary and diverse team",5.0,"ZOE
5.0","London, England",-1,1 to 50 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Senior Salesforce Engineer,-1,"About Us

We want to help small businesses win. That’s why we’re here.

We connect small business owners to investors – to create jobs, help families and power economies – because we believe that people are made to do more. And we want to help them.

So, we created the leading online marketplace for small business loans. Our investors have lent £8.1 billion in 110,000 loans to 77,000 small business owners. In a single year, we unlocked 115,000 jobs and contributed £6.5 billion to the global economy. There’s never been a better time to join!

Be part of the team that changes everything. Let’s build the place where small businesses can get the funding they need to win and leave a legacy behind, forever.

This role sits within the “Tech” team. The drivers behind our platform – brilliant people working together to create, code, and build the next game changers.

About the team

We are looking for a highly organised and communicative Salesforce Engineer who will provide technical know-how for our Salesforce engineers through championing good Salesforce engineering practices while supporting other engineers in both improving our business systems and delivery of new features.

We are a passionate bunch of problem solvers whose bread and butter is learning new technologies and fostering a collaborative and inclusive environment - we’re looking for partners in crime who feel the same.

As a Senior Salesforce Engineer you will:

Perform hands-on technical implementation, with a focus on delivering functional and programmatic solutions in Salesforce. You will customise and implement profiles, roles, security settings, sharing rules, applications, custom objects, custom fields, page layouts, workflow, validation rules, approvals, reports and dashboards etc.
Provide prompt support to end users to resolve issues with Salesforce and related applications. You will address development issues and work multi-functionally with our product and wider engineering teams.
Work with other engineering teams to integrate backend data with Salesforce via middleware to give our end users an enhanced data experience.
Design, document, and implement specific initiatives to improve business processes and Funding Circle’s CRM environment. You will support design and ongoing schema changes to promote Funding Circle’s growth and business evolution.
Undertake Salesforce release management including Sandbox management, commits to Github and continuous integration.
Provide technical leadership and guidance to less experienced engineers on the team.
About You

Proven previous hands-on experience with enterprise Salesforce implementations, testing and support.
Extensive experience of using Salesforce platform languages: Apex, SOQL and Lightning as well as advanced administration tools like process builder, flow and custom settings.
Familiarity with Agile software delivery and use of tools such as git (GitHub) and CircleCI for source control and continuous integration.
Experience with creation of unit tests in the Salesforce environment
Listening skills, excellent customer service skills, and strong professional written and oral communication skills.
Attention to detail with the ability to analyse and solve complex problems as well as provide documentation, guidance, and instructions to users.
Salesforce Developer Certifications – App Builder, Platform Developer I, and ideally Platform Developer II.
Experience at integrating Salesforce with 3rd party applications (NewVoice Media/Conga/DocuSign) is a plus.
Experience working at a financial services company or within another highly regulated industry would be beneficial.
Why join us?

We’re gearing up for our biggest chapter yet – and it’s being driven by everyone.

We think of ourselves as the career launchpad. A place to develop yourself, fast. Real work. Real experience. Real opportunities to collect skills. Think big remits and huge ownership to make great things happen.

Our vibrant culture is built around potential and creating a place where you can really be you. We keep it agile and open. All voices heard. Because we believe great ideas come from everywhere.

If you show skill and are willing, we’ll back you all the way. This is the place for you to build something incredible.

It’s in our differences that we find our strengths.

We celebrate and support the differences that make you, you. So we’re building a culture where difference is valued. We’re proud to be an equal opportunity workplace and affirmative action employer. We truly believe diversity makes us better. We particularly encourage applications from applicants from underrepresented backgrounds. We welcome applicants who may want to work flexibly.

Want to Build The Incredible? We’d love to hear from you.",3.8,"Funding Circle UK
3.8","London, England",-1,501 to 1000 Employees,2010,Company - Private,Lending,Finance,$50 to $100 million (USD),-1
Data Engineer,-1,"Data Engineer - Hatfield - (Remote working) - £50,000-£55,000

*Option for remote working* - 1 day a week in the office a week ideally long term

*Urgent requirement - interviews next week

My client invest heavily in staff and have thrived despite recent market conditions and have not furloughed or let go any staff during this time. This role will require extensive experience with BI platforms, Cloud based Data management and Data Governance. You will support the progression of the Data Transformation Programme across the wider business and you will be responsible for designing and delivering the implementation of there platform.

Experience;-
ETL Process
Data Governance
Data Transformation projects
Virtualisation
AWS platform
Development - BI/Qlik/ Power BI
Design of Master data management
Desirable;-
Python / Agile
SQL , Java, Scala, Javascript
If interested, please call Elisha Bailey on 01189 006750 or send an updated CV via the link.

As a professional company we gladly welcome applications from persons of any age and background and do not intend to discriminate with advert text and terminology.",3.9,"Roc Search
3.9","Hatfield, East of England, England",-1,51 to 200 Employees,2007,Company - Private,Staffing & Outsourcing,Business Services,$25 to $50 million (USD),-1
Data Engineer,-1,"Energy Aspects currently have an exciting opportunity available for a Data Engineer to join our Data Team based out of our London office. This is a fantastic opportunity for an experienced data engineer to support the infrastructure and strategic projects underpinning the work of our highly regarded global oil, natural gas and energy teams, optimizing our data content and capabilities.

The successful candidate will be responsible for building entirely new services and maintaining/iterating on our existing infrastructure in use daily at Energy Aspects by the Data Team. You will closely support Data Analysts/other technical analysts by ensuring the availability of our core platforms, while helping to shape and drive forward the future state of data engineering at Energy Aspects.

Duties
Build/maintain ETL jobs in Python
Ensure performance and operations of our data infrastructure, data products & data APIs
Design and implement new solutions for use by the Data Team and others
Provide thought-leadership in your domain and advocate for best practice within Data Team
Prefer deploying industry-standard technology & tooling vs. building solutions in-house
Requirements
4+ years’ experience as a Data Engineer, working primarily in Python
Hands on management of cloud infrastructure
Experience deploying/managing infrastructure as code
Experience with Airflow (and/or other similar tools)
A firm grasp of containerization, associated tools and best practice (especially Docker)
Building and managing relational databases (ideally PostgreSQL, MySQL
Understanding of how to best organize and model data for storage, retrieval and analysis
Building/maintaining data APIs (AWS API Gateway)
Comfortable working across Unix and Windows
Best practice in data development: documentation, version control, testing and automation
Understanding of the importance of data governance and metadata
A methodical, analytical and organised approach to tackling large scale projects and data sets
Effective communication skills, comfortable presenting to technical and non-technical audiences
Desirable skills
Experience working with high frequency timeseries data and/or streaming data
Building and managing other database/datastore technologies (NoSQL variants, file stores, etc.)
Experience working with Python web frameworks, Jinja templating and/or JavaScript
Prior forecasting or modeling experience or training
An interest in commodities, energy or financial markets would be beneficial
About Energy Aspects

Founded in 2012, Energy Aspects is a rapidly growing independent research consultancy. The company is committed to providing indispensable analysis of energy markets to its clients to help guide their investment, trading and research decisions.

We combine a data-rich approach with our extensive network of contacts throughout the oil and gas industry and insight on geopolitics and energy policy to provide best-in-class assessment and analysis of major topics, regions and trends. We also deliver timely analysis of breaking news with our E-mail Alert service and offer Database services consisting of our proprietary fundamental trade and supply/demand data.

We offer a suite of subscription services spanning our research products which can be tailored to meet our clients’ specific needs.

Culture & benefits

Please note that, due to the Covid-19 pandemic and in the interest of our employees’ health and safety, Energy Aspects is currently operating a temporary remote working and onboarding arrangement, until further notice. We have continued our hiring and onboarding approach throughout lockdown and have successfully hired and remotely onboarded a number of new starters.

At Energy Aspects you could be part of an active, social and friendly team where you will have the opportunity to join our running, circuit training, five-a-side football or lunch clubs. You might also enjoy letting loose at our winter and summer parties or just sharing an unwinding drink on a Friday afternoon at our in-house bar the Nodding Donkey.

Working out of our Canary Wharf office, you can take advantage of low commute times and easy access from across London, excellent amenities for shopping, gyms and healthcare, restaurants and bars. We do also provide daily fresh fruit, hot drinks, soft drinks, snacks and the occasional exotic treats from our international travels.

Our compensation packages include annual bonuses, private health insurance, generous pension contributions and company share options scheme, as well as a subsidised gym membership and considerable holiday time",4.2,"Energy Aspects Ltd
4.2","London, England",-1,51 to 200 Employees,2012,Company - Private,Energy,"Oil, Gas, Energy & Utilities",Unknown / Non-Applicable,-1
Data Engineer,-1,"About Us:

What makes the difference between a product that's engaging, compelling, and easy to use and one that's frustrating, broken, and complicated? The answer is user experience. Here at UserTesting, our mission is to help our customers create great experiences. We enable every organization to deliver the best customer experience powered by human insight.

About the team:

Our data platform enables analytics, experimentation, machine learning models, streaming, reporting infrastructure and systems metrics which powers and drives innovation at UserTesting. Our team of data engineers and scientists is focused on creating a competitive advantage for UserTesting and our customers through novel data infrastructure, metrics, insights and data services. We are a small but rapidly growing team that builds and leverages state-of-the-art analytics systems, especially around video and Natural Language Processing (NLP).

The Opportunity:

As a Data Engineer, you'll design, develop & tune data products, applications and integrations on large scale data platforms with an emphasis on performance, reliability and scalability and most of all quality. You'll support our Machine Learning efforts by building large-scale distributed infrastructure for rapid experimentation, training, and inference. You are passionate about applying cutting-edge machine learning to real-world problems and building the required frameworks and tools to do so.

You will play a key role in the evolution of our Data Platform, duties include:
Work closely with product and design to discover and build solutions that help our customers build great user experiences
Collaborate with engineers who are both remote and co-located in our Mountain View, San Francisco, and Atlanta offices
Work effectively within a team environment, to regularly solicit and act on feedback, focus on root causes, and continually strive to improve
Enhance our customer-facing platform, tester panel distribution systems, video playback tools, and mobile device recording capabilities
Advocate and lead-by-example best practices for code quality in architecture and design, maintainability, performance, and scalability
Lead on promoting just-right solutions to build for the future while also avoiding costly premature optimizations
What We're Looking For:
At least 5 years of software development experience.
At least 3 years of experience of using Big Data systems.
Strong in one or more languages (Python/Ruby/Scala/Java/C++)
Strong experience on a professional software development team building highly scalable, distributed systems in the cloud
Experience in REST API design and implementation
Experience with messaging, queuing, and workflow systems, especially Kafka or Amazon Kinesis
Experience with non-relational, NoSQL databases and various data-storage systems, especially: Cassandra, ElasticSearch/Solr, Neo4j, etc.
Bonus points:
Experience working with Machine Learning, especially NLP
Experience with software development on top of Deep Learning Frameworks, especially Tensorflow/Keras
Data engineering knowledge including ETL, DataWarehouse, Data Visualization, etc.
Data modeling experience with columnar data formats
Experience integrating with CI tools programmatically
Experience with Docker, registries and container deployment services (e.g., AWS ECS, Kubernetes).
Why you'll love working for UserTesting:

We're honored to be named a 2020 Inc. Best Workplace. Joining UserTesting means being part of a passionate team focused on transforming the way companies learn about their users.

Founded in 2007 and backed by Accel and OpenView, UserTesting is headquartered in San Francisco with offices in Atlanta and Edinburgh. To learn more about our team, culture, and customers, check out our careers page, company blog, and press/awards. Besides a great work environment and the opportunity to change the world we're also growing fast join us!",3.4,"UserTesting
3.4","Edinburgh, Scotland",-1,501 to 1000 Employees,2007,Company - Private,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),-1
Data Engineer,-1,"Due to my client’s continued success and growth, they have an exciting opportunity for a Data Engineer to join their business based in Milton Keynes.

You will be working with the software development team to scope out new potential developments and redevelopments of the current legacy applications. You will also be working as a part of the wider BI team.

This is an exciting role for someone with experience in developing Data Warehouse and ETL. You will be responsible for designing and developing data integrations and identifying and integrating new sources of data into the Data Warehouse as required by the business.

Essential Knowledge:

Strong experience with data integration tools, ideally SSIS, Informatica or Talend
Extensive MS SQL Server/TSQL experience
Thorough understanding of full software development lifecycle
Understand SCRUM/Agile working practices
Azure/AWS development is desirable

This is an opportunity for you to join a globally recognised company who go the extra mile, and provides an industry leading employment package.

If you are interested in this opportunity please contact Kate Wardle at Evolution Recruitment Solutions.",4.4,"Evolution Recruitment Solutions
4.4","Milton Keynes, England",-1,51 to 200 Employees,2000,Company - Private,Staffing & Outsourcing,Business Services,$1 to $5 million (USD),-1
Data Engineer,-1,"Who are QC?

QC combines performance marketing services with our unique data rebuilding software, to help clients to remove wasted spend and grow at the lowest possible CPA.

Founded in 2008, we’re an independent digital marketing agency and SaaS provider focused on data-driven insights and pioneering in-house technology. We are a 'Remote First' company with offices in London and Edinburgh. We deliver multi-channel insights and strategic consultancy so blue-chip businesses can maximise growth, working with well-known brands such as BT, EE, Quiz and Aggreko, treating our clients as partners and putting their business objectives at the heart of what we do.

The QueryClick vision: reinventing the future of marketing by delivering results that no one else can. We use our flywheel to make that happen, bringing our vision, passionate people, and client-centred approach together in one continuous cycle. This builds momentum for sustainable growth while also inspiring innovation among our team and clients. And at QueryClick, “culture” is more than a buzzword. We’re committed to making our agency a great place to work by hiring talented people and investing in their growth and wellbeing

What are we looking for?

We are building a brand new software product. Powered by machine learning and capable of handling massive amounts of marketing behaviour data, the Corvidae product allows its users to understand the value of their marketing activity and use this information to automatically optimise that activity. We need skilled, passionate technical team members to be part of building Corvidae from initial working version into a fully fledged, production capable software product.

As our Data Engineer in the Corvidae project you will be expected to implement, deploy, and manage the data pipeline and storage components of the Corvidae delivery process from end to end, effectively and efficiently. Understanding the data pipeline requirements which enable the reporting and modelling needs of the product and ensuring that enables high quality and robust delivery to Corvidae clients. You will be responsible for setup, deployment, and maintenance of data processing infrastructure (cloud storage, cloud compute, clustering, etc.), data cleansing, and data enrichment.

Requirements

Are you QC?
Extensive professional experience in the building and maintenance of production quality data management pipelines
Excellent experience with Python, SQL and commonly related tools and libraries
Excellent experience of the setup, use, and maintenance of cloud storage and cloud compute products (preferably Azure)
Experience in the setup and maintenance of container solutions such as Kubernetes
Experience in enabling output delivery through data enablement
Experience working with web technologies
Working knowledge of database administration
Experience in data extraction and manipulation
Using distributed/clustered computing systems
Benefits

Some of our benefits include:
Your Development
We believe in continuously investing in your talent and offer an industry-leading training and development programme
Work/Life Balance
Remote First, flexi hours, reduce travel costs and still have office space to collaborate as a team.
Monthly staff rewards
Flexible annual leave (34 days) with options to buy/sell leave.
Travel loan options & Technology loans and discounts
Perkbox - high street discounts, reduced gym membership and cycle to work scheme
Company pension contributions, life insurance and private medical scheme
Location

UK Remote - Although role is remote there will be expected travel to our Edinburgh office, this will be easier, more accessible for those who are already UK based or those happy to relocate to UK.

Competitive Salary dependent on skills and experience

Follow our company instagram for a snapshot into life at QC @Queryclick

If you are QC then please apply now - we look forward to receiving your application.",3.2,"QueryClick
3.2","Edinburgh, Scotland",-1,51 to 200 Employees,2008,Company - Private,Advertising & Marketing,Business Services,$5 to $10 million (USD),-1
Data Engineer,-1,"ABOUT LIVERAMP

LiveRamp is the trusted platform that makes data accessible and meaningful. Our services power people-based customer experiences that improve the relevance of marketing and allow consumers to better connect with the brands and products they love. We thrive on solving the toughest technical and customer challenges, and we're always looking for smart, compassionate people to help us blaze a trail.

Mission: LiveRamp makes it safe and easy for businesses to use data effectively.

ABOUT THIS JOB

Do you crave volumes of data and the tools and resources to analyze it? Do you delight at the prospect of discovering patterns and transforming data into actionable insights? Do you love working collaboratively with intelligent, energetic, no-nonsense colleagues? If you've answered ""yes"" to all these questions, we'd like to introduce ourselves.

LiveRamp is looking for a talented Data Engineer to join our team. As a Data Engineer at LiveRamp, you'll support all aspects of analytic initiatives from conception to completion. We're seeking a passionate data analyst that is creative, analytical and experienced at delivering insights and reporting to assist in driving key business decisions. Sounds like that could be you? Keep reading!

RESPONSIBILITIES
Develop effective and insightful data observations in collaboration with your team.
Review and analyze data trends and make recommendations while being creative in data contextual integrations.
Collaborate with various stakeholders to manage data logistics - including data transfers, understanding data structures, business rules, etc. - to enable project execution
Develop and automate analytical reports throughout the organization utilizing GCP, and SQL to enable educated decision making.
Apply advanced data integration methods to massive data sets in order to create solutions which can be utilized in descriptive, diagnostic, predictive, and prescriptive analytics.
Manipulate and analyze complex, high-volume, high-dimensionality data from varying sources using a variety of tools and data analysis techniques.
ABOUT YOU
You have advanced SQL / query language skills with large-scale, complex data sets.
You can analyze large data sets, manipulate data, and make data driven recommendations.
Hands-on experience with Hadoop eco-systems (Hive, Pig, Spark, etc.).
Hands-on experience with GCP eco-systems (DataFlow, Data proc).
Experience in data extraction and analysis
3+ years of experience performing complex data analysis at scale
Must be proficient in integrating, storing, and processing data in a cloud based environment.
Must have experience with technology platforms and architectures applicable to developing and maintaining cloud based data assets.
Must be comfortable with both inductive and deductive reasoning and problem solving approaches
Advanced working knowledge of large data manipulation and data mining
Strong programming/scripting knowledge (proficient in SQL, Python)
Proficiency in French would be a bonus",4.4,"LiveRamp
4.4","London, England",-1,1001 to 5000 Employees,2005,Company - Public,Computer Hardware & Software,Information Technology,$100 to $500 million (USD),-1
Data Engineer,-1,"About us

Perkbox is a platform that provides a unique employee experience, enriching the personal and working life of employees. It offers a suite of products including access to best in class Perks, Perkbox Medical, Perkbox Recognition and Perkbox Insights. It serves companies of all sizes from SMEs to large companies, with brands such as Nando’s, Caffe Nero, Krispy Kreme and Levi Strauss & Co. Headquartered in London, Perkbox has offices in Sheffield, Paris and Australia and are on a mission to improve the employee experience at a Global level.

The Data Team

The Data Team is part of the Product and Engineering department. It exists to devise, communicate, maintain and contribute to the data strategy for the organisation by directly working with those conducting data analysis across the organisation to formulate the ongoing strategy. It is responsible for the delivery and maintenance of the required infrastructure to execute that strategy while ensuring that the infrastructure remains operational and fit for purpose on a day-to-day basis. The Team is composed of data engineers, BI developers and analyst support roles and is one of the most integral teams within the business.

About The Role

As Perkbox evolves and embarks on its mission to become a global platform, our success will depend on our ability to make data driven decisions. As a crucial member of this team, your role will be to support the data team as a centralised function of the engineering department and improve the accuracy and the availability of our data. In the few months you’ll become familiar and learn all about our data pipelines and collaborate on how to proceed with our architecture based on Spark and Databricks. You’ll be building and supporting old and new pipelines, own pipeline deployment and understand our business logic in depth to be able to find gaps and issues in data reconciliation. You will become the point of contact for any data that comes and goes from our data lake and enjoy.

On a day to day basis you can expect to:
Work with big data technologies such as Spark and complex microservices data
Work with structured, semi-structured and unstructured data from a wide variety of internal and external sources such as Salesforce, NetSuite, Mixpanel, and our own platform.
Design, build and Contribute to the development of our core data lake
""Work with data stakeholders to prioritise additions to the data warehouse, and to help them make sense of data coming from multiple sources.
Help consolidate our current technology set into a coherent and consistent solution.
Requirements

About You

You’ll be someone who is passionate about building the right foundations with experience in a data engineering role and responsible for the development of or contribution to ETL pipelines, data lakes, and analytical warehouses
Have a clear view on how to develop a structured data environment
Strong knowledge of Python
Deep understanding of data storage and processing technologies (in particular Spark, SQL, s3, and Redshift)
Experience building data pipelines in a cloud environment
Knowledge of professional data warehouse design, with a focus on Kimball-style fact and dimension tables.
Love automating tasks and work to deploy production standard code (with unit testing, continuous integration, versioning etc)
A passion for building high quality products to drive real change for businesses
Benefits

Are there any benefits besides the salary?

When you think of Perkbox, you probably think about all our free perks – like free coffee from Caffé Nero, free cinema tickets, gym discounts, birthday boxes, our employee assistance programme (EAP), and access to an online GP.

And yes – everyone who works here gets all the same great perks we give to our customers. But don't go thinking that's everything. Our culture goes well beyond the perks we're famous for!

We're also all about celebrating anniversaries and recognising your biggest achievements. We stoke the fires of your curiosity with external speakers and generous learning budgets. We practice transparency with regular 'Let's Talk' sessions from the senior leadership team. We take the time to listen to every single employee and use your feedback to make improvements to our company culture. We support working parents, provide pension plans – are you ready for this one? We're a dog-friendly office too!

It's all about delivering a work-life balance that lets you live your very best life.",3.7,"Perkbox
3.7","London, England",-1,51 to 200 Employees,2010,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"About us

Perkbox is a platform that provides a unique employee experience, enriching the personal and working life of employees. It offers a suite of products including access to best in class Perks, Perkbox Medical, Perkbox Recognition and Perkbox Insights. It serves companies of all sizes from SMEs to large companies, with brands such as Nando’s, Caffe Nero, Krispy Kreme and Levi Strauss & Co. Headquartered in London, Perkbox has offices in Sheffield, Paris and Australia and are on a mission to improve the employee experience at a Global level.

The Data Team

The Data Team is part of the Product and Engineering department. It exists to devise, communicate, maintain and contribute to the data strategy for the organisation by directly working with those conducting data analysis across the organisation to formulate the ongoing strategy. It is responsible for the delivery and maintenance of the required infrastructure to execute that strategy while ensuring that the infrastructure remains operational and fit for purpose on a day-to-day basis. The Team is composed of data engineers, BI developers and analyst support roles and is one of the most integral teams within the business.

About The Role

As Perkbox evolves and embarks on its mission to become a global platform, our success will depend on our ability to make data driven decisions. As a crucial member of this team, your role will be to support the data team as a centralised function of the engineering department and improve the accuracy and the availability of our data. In the few months you’ll become familiar and learn all about our data pipelines and collaborate on how to proceed with our architecture based on Spark and Databricks. You’ll be building and supporting old and new pipelines, own pipeline deployment and understand our business logic in depth to be able to find gaps and issues in data reconciliation. You will become the point of contact for any data that comes and goes from our data lake and enjoy.

On a day to day basis you can expect to:
Work with big data technologies such as Spark and complex microservices data
Work with structured, semi-structured and unstructured data from a wide variety of internal and external sources such as Salesforce, NetSuite, Mixpanel, and our own platform.
Design, build and Contribute to the development of our core data lake
""Work with data stakeholders to prioritise additions to the data warehouse, and to help them make sense of data coming from multiple sources.
Help consolidate our current technology set into a coherent and consistent solution.
Requirements

About You

You’ll be someone who is passionate about building the right foundations with experience in a data engineering role and responsible for the development of or contribution to ETL pipelines, data lakes, and analytical warehouses
Have a clear view on how to develop a structured data environment
Strong knowledge of Python
Deep understanding of data storage and processing technologies (in particular Spark, SQL, s3, and Redshift)
Experience building data pipelines in a cloud environment
Knowledge of professional data warehouse design, with a focus on Kimball-style fact and dimension tables.
Love automating tasks and work to deploy production standard code (with unit testing, continuous integration, versioning etc)
A passion for building high quality products to drive real change for businesses
Benefits

Are there any benefits besides the salary?

When you think of Perkbox, you probably think about all our free perks – like free coffee from Caffé Nero, free cinema tickets, gym discounts, birthday boxes, our employee assistance programme (EAP), and access to an online GP.

And yes – everyone who works here gets all the same great perks we give to our customers. But don't go thinking that's everything. Our culture goes well beyond the perks we're famous for!

We're also all about celebrating anniversaries and recognising your biggest achievements. We stoke the fires of your curiosity with external speakers and generous learning budgets. We practice transparency with regular 'Let's Talk' sessions from the senior leadership team. We take the time to listen to every single employee and use your feedback to make improvements to our company culture. We support working parents, provide pension plans – are you ready for this one? We're a dog-friendly office too!

It's all about delivering a work-life balance that lets you live your very best life.",3.7,"Perkbox
3.7","London, England",-1,51 to 200 Employees,2010,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"About the role:

Abcam
is looking for a Data Engineer to join Abcam’s growing Data Engineering team. The
Data Engineer will work on several projects including data migrations from
legacy systems into an ERP and a PIM system, as well as developing scalable Big
data processing and analytics solutions. They will be responsible for
implementing technical solutions to business requirements and providing input
on solution design.
About Data Engineering:

The
Data Engineering team is responsible for Abcam’s self-service BI stack,
including a data warehouse and Tableau, as well as Abcam’s AWS data platform
and data lake and several data migration projects.
Roles & responsibilities:
You will work on the design, build and support of
our data migration stack.
You will design and develop scalable Big data
processing and analytics solutions.
You will write performant, functional code whilst
applying best practise.
You will work closely with IT stakeholders
including Data Scientists, Data Analysts, Architects, Infrastructure Engineers,
Project Managers and Business Analysts.
You will work closely with non-technical business
stakeholders and communicate complex technical concepts in a way they can
understand.
You will keep abreast of developments in the world
of Data Engineering and make recommendations about new technologies and ways of
working.
Essential skills: SQL, Data Warehouse,
Oracle, ETL, Git, Python, Data Architecture

Desirable
skills: Mulesoft, ODI, Spark, AWS, APEX
About you:

You will be proactive, seeking to resolve issues
quickly.
You will build strong relationships with IT
stakeholders including Data Scientists, Data Analysts, Architects, Infrastructure
Engineers, Project Managers and Business Analysts.
You will be a team player who supports other team
members as necessary to ensure success.
You will be skilled in SQL. Experience of Oracle
SQL would be beneficial.
You will have experience designing and building
Data Warehouses, and using ETL tools. You will preferably have worked with
Oracle ODI before.
You will be experienced in using Git and CI/CD
tools for version control and code releases.
Experience implementing Big Data solutions using
AWS Data platform and AWS Data Services would be beneficial.
Some background in life science would be
beneficial, but is not essential.
If
this sounds like you and you’d like to be a part of a fast paced, growing business
with the vision to become the most influential company and best-loved brand in
life sciences please apply now!
About Us

Ever
since 1998, when our founder, Jonathan Milner, started selling antibodies from
the back of his bike, Abcam has aimed to help scientific researchers make
breakthroughs faster. We now have offices and labs in the UK, the US, China and
Japan, and as we continue to grow, we remain ambitious, driven by our
customers’ success and their research needs.

It’s our goal to provide a world-standard in protein research tools, technical
support and delivery. When you join Abcam, you’ll join a global business with
the passion and the vision to become the most influential company, and,
best-loved brand in life sciences.

Our culture is our key differentiator. We believe in empowering individuals,
with responsibility given at an early stage. The working environment is fun and
fast-paced, collaborative and outcome focused, with a strong customer focus. In
addition to competitive salaries, we offer an attractive and flexible benefits
package (which includes shares for eligible employees), a culture focused on
wellbeing and opportunities for growth.",4.8,"Abcam
4.8","Cambridge, East of England, England",-1,1001 to 5000 Employees,1998,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$100 to $500 million (USD),-1
Data Engineer,-1,"This role is working on the “secret sauce” so to speak as it this is the team that seeks to build data processing tools that apply machine learning principals to customer data to provide clear and actionable insights for customers of the platform.

The work will be incredibly challenging and strong candidates will have good skills in data engineering and will likely also be interested in machine learning.

Location:
CENTRAL LONDON
Get in touch
T: 0203 805 7799
E: info@tecknuovo.com",4.4,"Tecknuovo
4.4","London, England",-1,1 to 50 Employees,2015,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
Data Engineer,-1,"As part of our service transition to a stand-alone Business Intelligence capability and the development of a BI & Analytics Strategy that can support the needs of the business; we are recruiting to extend the team.

Company Vision, Priorities & Values

Opel Vauxhall Finance’s vision is to meet the mobility needs of our customers through financial services solutions for the Opel and Vauxhall brands. Our Strategic Priorities focus on the development of our people, performance delivery, penetration, efficiency, customer loyalty and protection - maintaining strong risk management and compliance practices. We promote a collaborative culture of people who actively contribute with integrity. We are agile, open minded and adaptive to deliver at pace, with customers at the heart of all we do.

A little more about us…

We are the captive automotive financial organization of Opel and Vauxhall, part of the PSA Group and BNP Paribas Personal Finance. With a team of 1,100 people in 12 European countries, and strong shareholder support, we offer a wide range of career opportunities. What makes us unique is the ability to work in a European environment in a collaborative culture.

We offer continuous internal and external training that gives you the opportunity to improve the skills you already have or to learn something new. We support professional qualifications when necessary, in addition to training courses to aid your development. We are committed to offering a fair and balanced work environment, with equal opportunities and respect for all.

Position, Objectives, Responsibilities

Create complex data loading processes for Operational Data Stores, Data Warehouses and Data Marts that satisfy all functional, non-functional and technical requirements.
Responsible for extracting data from various sources, transforming the data as required and loading it to various target (ETL) database(s) and/or structures
Drive the ETL design approach and ETL design strategy to help OVF achieve its objectives by making data more quickly and more widely available.
Analyse and review complex object and data models and the metadata repository in order to structure and processes data for accuracy, efficiency, and maintainability
Collaborate with various teams from data architects, solution designers, technical and project managers to implement solutions to specification and timelines
Translates detailed logical design into ETL programming and physical database design using tools such as IBM Infosphere Data Stage and Quality Stage.
Work with business customers and technical analysts to understand, analyse and resolve data integrity issues in a timely manner.
System testing, participation in User Acceptance Testing (UAT) and implementation of the process.
Adhere to the project development cycle methodology and for every development and produce documentation that will include plans, diagrams, data dictionaries, etc.
Respond to scheduled requests for off hours resolution of production problems.
Assist in driving improvements in right first time deliveries and sustainability of the ETL platform
Support engineering work planning and estimation of project work
Support the Technical Manager by guiding and supporting disparate development teams through the delivery of technical solutions aligned to high level design (through both waterfall and Agile methodologies). Defining, driving and enforcing engineering standards with internal staff and third party developers.

Qualifications and Experience

Bachelor Degree or equivalent work experience in Computer Science, Information Technology or related filed
Extensive experience in ETL development in data warehouse environments
Preferred experience IBM InfoSphere products specifically IBM DataStage
Extensive experience of delivering BI solutions within Data Warehouse with data modelling experience a plus
Experience of Workload Manager / MPP / Grid Architectures for implementing scalable parallel processing Infosphere Datastage environments.
Experience with installations in a Linux based estate

Skills & Knowledge

Recent ETL experience – Preferred DataStage
Extensive skills with Oracle Sql and relational databases
Proven agile methodology skills
Strong collaboration and communication skills
Proven analytical thinking, design, coding and testing skills
Strong Unix Linux skills including scripting languages such as Shell
Knowledge of best practice and standards in a ETL, BI and Data Warehouse environment
Translate requirements and designs into sustainable technical outputs
Knowledge of Java desirable.
Knowledge IIS Data Stage v11. x systems administration, performance tuning, work load management server, troubleshooting, high availability, backup and recovery desirable.

What we offer

Further learning and development opportunities
A competitive salary
25 days holiday (buy/sell available)
X4 life assurance
Vauxhall Lease Scheme
Excellent pension scheme
Discount schemes
On-site car park
Modern open planned offices
Free fruit & hot drinks
Please note that due to the current situation with COVID19 this role will be working from home. However you would still be contracted to our Cardiff office and required to return once the office has reopened.",3.4,"Opel Vauxhall Finance
3.4","High Wycombe, England",-1,1001 to 5000 Employees,1920,Company - Private,Lending,Finance,Unknown / Non-Applicable,-1
Data Engineer,-1,"Big Data Engineer – FinTech

How would you like to join an innovative business with an amazing vision of how and where to take the tech and product in the future?

We are looking for a Big Data Engineer to join one of Europe’s most progressive FinTech’s.

You will join a diverse team of extraordinary data specialists working on a broad range of Data Engineering and Big Data projects. The Data team are using the latest tech, the latest data platforms and as of such are looking for a Data Engineer who’s open to learning and using cutting edge technologies.

This FinTech is growing their data team due to new products and other exciting ventures which you could be a part of!

As a Big Data Engineer, you will need experience:

Working with cloud platforms, ideally GCP or AWS
Working across structured and unstructured data
With Python, Scala, SQL, Spark, Hadoop, PySpark
Collaborating with a team on complex problems

The benefits of joining this FinTech as a Big Data Engineer:

Progressive environment, where you can learn, grow and have fun
Utilising modern technologies daily
Freedom, autonomy and ownership – no micromanagement!
Vibrant company culture and social scene – events and activities
Working with passionate teammates on exciting tech projects

If you’d like to learn more about this Big Data Engineer opportunity, APPLY!",4.9,"Consortia
4.9","London, England",-1,1 to 50 Employees,2010,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Data Engineer,-1,"* The Company **
A start-up with fantastic long term plans, who specialise in private security services for businesses and homes. The biggest company of its kind in the country, they have secured funding and major clients, and are now looking to expand their data team.

In a fast paced and exciting start-up environment, there is significant opportunity for long term progression and growth, as the company itself grows. Its a really exciting time to join the team, with major new projects and tech updates in the pipeline.

The Role

They are looking for a bright and well-rounded data engineer who can keep up in a fast paced start-up environment. You will be working on a broad range of projects, from developing ETL process and pipelines, to opportunities to be hands on with data science. You will be working on a variety of projects, from developing internal processes, to aggregating crime data to help clients better understand the security risks posed to them.

It the perfect job for someone who likes to be working with a variety of tools and techniques, whilst also working with stakeholders. There is also plenty of flexibility to work from home.

Who They're Looking For

2-3 years of working in a data engineering environment, particularly working with cloud platforms
Data warehousing and ETL processing experience
Strong data modelling background, as well as being comfortable working with internal and external data sets
Experience with Python and R
Experience working with data science and machine learning would also be beneficial
Job Owner: d.prosser",-1,Metrica Recruitment,"London, England",-1,1 to 50 Employees,2014,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
Data Engineer,-1,"Data Engineer
Location: London

Salary: £Competitive + Bonus + Benefits

Closing Date: Friday 27 November 2020

Division: IT
Vitality is an award winning, dynamic and vibrant financial services provider, with a ground-breaking vision for the future, where individuals are enabled to succeed and are rewarded and recognised for their contribution to our business. We’re the UK insurer and investment provider that rewards people for positive lifestyle choices. With 1.25m+ UK members and more than 25m globally, we’re out to make the world a healthier, happier place. This applies as much to our people as it does to our members.

Our CORE PURPOSE is to make people healthier and to enhance and protect their lives. From people to products and processes, we aspire to deliver on our purpose in everything we do.

Our VISION is to be the BEST financial services provider in the UK

We are looking for talented individuals who are committed to living our values and delivering an award winning service to our customers.

Overall Job Purpose

The Data Engineer role will be responsible for delivering the underlying data and APIs to support the implementation of innovative machine learning applications. You will enjoy working with rich datasets, cutting edge technology and help shape new data science projects in an innovative company that helps people live healthier lives. The right candidate will possess a desire to work in fast-paced environment, with the ability to consistently deliver exceptional results on demanding timelines. Travel will be required on a weekly basis between our different Office locations.

Accountabilities
Work with Data Scientists to implement robust and trustworthy data to support highperformance
algorithms and predictive models
Deploy and maintain machine learning models as APIs for use in our live environments
Employ a variety of languages and tools (e.g. scripting languages) to develop and manage
robust data pipelines connecting various systems
Develop datasets and processes that facilitate data modelling, mining and production
Provide clean, usable data to data scientists and recommend ways to improve data reliability, efficiency and quality
Research opportunities for data acquisition and new uses for existing data
Work collaboratively with the Data Science, Data Architecture and other IT delivery teams to design, construct, install, test and maintain highly scalable data management systems.
Skills Required

Essential
Bachelor’s degree in Information Technology/Systems/Sciences/Maths
Strong experience in business intelligence, data warehousing, data management and data delivery, database and ETL technologies
Experience using languages / tools / databases such as SQL and NoSQL, Python, Nifi, Docker.
Strong technical experience in designing and delivering data in BI warehouse and/or Big Data Lakes, supporting on premise and cloud architecture
Microsoft SQL Server technologies
Hands-on/technical experience with high proficiency on Big Data technology and toolsets
Experience developing, deploying and maintaining machine learning APIs – using flask and java springboot
Experience working with data scientists or quantitative / statistical analysts
Experience working with AWS EMR
Desirable
Prior experience on Big Data appliances like Hadoop.
Prior experience in using Agile methodology
Understanding of data architecture & modelling
Previous insurance or financial services industry experience
Open Source ETL tools (Jupyter, Spark)
Working for Vitality, you'll experience an exciting mix of creativity and innovation, within a framework of challenging objectives and a passion for delivering the best. We think work should be fun and sociable, and we want our people to get the most out of every day. Our people are chosen for their skills, knowledge, enthusiasm and attitude but above all, their belief that anything can be achieved.

As well as a highly competitive pay package, you’ll enjoy: complimentary breakfasts; regular onsite physical and mental wellness workshops; on-site health checks; annual flu jabs and access to our full range of partners and rewards. It’s what we call offering shared value, because a healthy, happy team is good for us, good for our members and good for you.",3.7,"Vitality UK
3.7","London, England",-1,1001 to 5000 Employees,2006,Company - Private,Insurance Carriers,Insurance,$100 to $500 million (USD),-1
Data Engineer,-1,"What do we want? A Data Engineer. When do we want you? Now!

We are looking for a Data Engineer to join an exciting new team developing Insight solutions that will use analytics, AI and statistical processes to enhance our products capabilities and provide our healthcare clients with the right tools to continue to meet the rising patient need.

As a Data Engineer you will be a key member of the product team working on our transactional and analytics databases. You will be creating the scalable, efficient and testable production ready pipelines to move and transform the data using our CI/CD tool, as well as be responsible for modelling the data objects, designing the structure of the new schemas and improving the performance of queries.

You will have a key role in our nascent data function as you work cross-functionally with business domain experts, engineers, product analysts and client delivery teams. You’ll understand data and reporting requirements from our BI and will ensure the teams have the information they need in order to make key decisions using data.

This opportunity will allow you to have a direct effect on what we do and how we do it. If you have a desire to learn and wish to accelerate your career, we can give you exposure to every facet of enterprise SaaS software and as much responsibility as you are ready to handle!

OK, that’s me, but who are you?

DrDoctor is a fast-growing digital health company founded in 2012. Our technology improves appointment scheduling, increases clinic efficiency by reducing no-shows and fills empty slots. We save the NHS millions of pounds each year and are currently deployed across 22 major hospitals around the UK including Guy’s and St Thomas’ & Great Ormond Street. With over 7 million patients active on the platform already, we’re on a journey to deliver the tools to radically transform the delivery of health services to make healthcare work for everyone – for patients, doctors, administrative teams and taxpayers.

Tell me more! Who will I be working with?

In this role you really will interact with every part of the business on a daily basis, even as we grow! But meet Chloë:

'I’m Chloë, I work in the product team with a focus on data engineering and analytics. I love the idea that my work is contributing towards the improvement of the NHS. To me it’s also the ultimate challenge. How can you take a complex and interconnected web of systems and help them to operate more efficiently? A great question to have at the back of your mind. To succeed at DrDoctor, you need a degree of aptitude, but bags of drive and a willingness to learn both within and beyond your role. We’re a close-knit bunch who all socialise regularly with each other, and our work is fundamentally collaborative, so you must be comfortable working in groups.'

OK, I’m interested. What experience do I need to have?

Must haves:
Comfortable working in an agile environment
T- SQL
SQL DB
Data Factory (with exp. In Mapping Data Flows)
Azure Data Lake V2
Software development lifecycle and tools (source control, code build & deployment)
Performance tuning & Database Design
Experience visualizing/presenting data for stakeholders and customers.
Data Security
Nice to haves:
NoSQL databases
Experience of graph databases
PowerBI / DAX, Tableau
Python / Databricks
Data Vault Methodology
Automated testing (one or more of: Unit Testing, Spec Testing, TDD, BDD)
Understanding of FHIR data standards
Health tech experience
Experience of methodologies for managing data quality
We are currently recruiting heavily and have a lot of CV’s to go through. However, we don’t wait for roles to close before going through your CV. We will be in touch in a few days to let you know if we think we might be a match, and if we are not. Unfortunately, because we get so many CV’s we are not able to send an individual response if it’s not a match. However, if you want more details as to why, just drop us a note and we will arrange to get some feedback over to you.

If it’s a match, then we will arrange a time to talk to you on a quick 30 minute call. It’s just an informal chat so you can relax! We will tell you more about the role, the team and why you should want to join us.

If we continue then we will invite you in to meet the team and founders. Depending on your role we may also ask you to complete an assessment.

We get there are a lot of great roles out there, so we will make sure to get through the rounds as quickly as possible. All we ask is you keep us up to date with your plans.

I can’t wait to get started, what are the perks?

An awesome team? Ok, you want more?

Benefits include:

Remote by default - Everyone at DrDoctor will work remotely, most or all the time with regular opportunities to socialise and engage. Flexible working (work where you are at you best and at times where you are your most productive), 25 days holiday plus Bank Holidays, discretionary bonus, Summer rooftop party, Christmas extravaganza, yearly ski trip, yoga on Monday and lunch and beer every other Friday!

Salary competitive and dependant on experience",4.8,"DrDoctor
4.8","London, England",-1,1 to 50 Employees,2012,Company - Private,Health Care Services & Hospitals,Health Care,Unknown / Non-Applicable,-1
Data Engineer,-1,"Founded in 2016 with only a handful of individuals, Quantexa was built with a purpose that through a greater understanding of context, better decisions can be made. 4 years, 6 locations and 260+ employees later we still believe that today. We connect the dots within our Customers data using dynamic entity resolution and advanced network analytics to create context, empowering businesses to see the bigger picture and drive real value from their data.

Due to the continuous success and high demand from our Customers, we are looking for Data Engineers with a proven track record in big data projects to join the Quantexa family.

What does a Data Engineer role at Quantexa look like?

In order to be a successful data Engineer at Quantexa, you’ll need to be comfortable dealing with both internal and external stakeholders You will be managing, transforming and cleansing high volume data, helping our Tier 1 clients solve business problems in the area of fraud, compliance and financial crime.

Being Agile is an integral part to the success we have at Quantexa and having regular team sprints and Scrum meetings with your Projects team is essential. You’ll be working closely with Data Scientists, Business Analysts, Technical Leads, Project Managers and Solutions Architects, with everyone following the same goal of meeting our Clients expectations and delivering a first-class service.

We want our employees to use the latest and leading open source big-data technology possible. You will be using tools such as Spark, Hadoop, Scala and Elasticsearch, with our platform being hosted on Google cloud (GCP). Our primary language is written in Scala, but don’t worry If that’s not your strongest language or if you haven’t used it before, we make sure that every Quantexan goes through our training academy so they’re comfortable and confident with using our platform.

Requirements

What do I need to have?
We’re looking for individuals who have proven big data experience, either from an implementation or a data science prospective.
The desire to learn and code in Scala
Experience in working in an Agile environment
Expert knowledge of at least one big data technology such as Spark, Hadoop, or Elasticsearch.
A strong coding background in either Java, Python or Scala
Experience of building data processing pipelines for use in production “hands off” batch systems, including either traditional ETL pipelines and/or analytics pipelines.
Passion and drive to grow within one of the UK’s fastest growing Start-ups
Benefits

Why join Quantexa?

We know that just having an excellent glass door rating isn’t enough, so we’ve moved to a brand-new WeWork office and put together a competitive package as a way of saying thank you for all your hard work and dedication.

We offer:
Competitive Salary
Company Bonus
Private Healthcare, Life Insurance, and Income Protection
Cyclescheme and Techscheme
Pension Scheme with a company contribution of 6% (if you contribute 3%)
25 days annual leave (with the option to buy/sell up to 5 days) + birthday off!
Amazing work environment",4.6,"Quantexa
4.6","London, England",-1,201 to 500 Employees,2016,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Adria Solutions has an exciting opportunity for a talented Data Engineer to join our rapidly expanding client based near Manchester.

The role requires you to work closely with other members of the data team and stakeholders to build out new data platforms.

Role and Responsibilities

Developing ETL processes in Python using Apache Spark
Data modeling
Estimation of user stories and tasks
Creating and maintaining technical documentation
Building data integration/exchange processes

Essential Skills

Strong understanding of data warehousing and developing ETL processes
Experience using Python and Apache Spark (Pyspark, Spark SQL)
Experience of a data warehouse database (e.g. Redshift, Snowflake, Vertica, Azure SQL Warehouse, etc.)

Benefits

Gym membership
Casual Dress code
Free parking both onsite and an off site

Data Engineer- £60K Manchester",4.6,"Adria Solutions
4.6","Manchester, England",-1,1 to 50 Employees,2004,Company - Private,Staffing & Outsourcing,Business Services,Less than $1 million (USD),-1
Azure DevOps Engineer,-1,"As one of Microsoft’s leading cloud partners we are always looking to for new talent. We have an outstanding team of Architects, Consultants, Engineers and Developers and we are always looking to add more talent.

We look for people who are passionate about technology and want to become part of an organisation who are committed to delivering quality to our clients. We can offer a very real opportunity for you to grow your cloud knowledge and make your mark on some exciting projects.

We are looking for an Azure DevOps engineers to join an established team at our client site in Coventry.

If you have a passion for problem solving and can articulate and present complex problems to a technical audience, this could be for you.

Your knowledge and skillset will be:

· *PowerShell* - this will be used on a daily basis and you will need to be efficient in its use to a reasonable level

· *Additional programming language *- at least one other programming language, preferably C# with working knowledge of developing dotnet Core applications

· *Azure Cloud Engineering* – you will need reasonable knowledge and understanding of Azure Resource Manager implementations of both Infrastructure and Platform as a Service offerings.

Knowledge and experience developing, testing, deploying, and maintaining Azure Resource Manager template-based deployments in an enterprise environment.

Knowledge of the deployment and configuration of Azure Virtual Machines, Azure Virtual Networks, Application Services

Knowledge of the deployment and configuration of event and message-based technologies such as Event Grid and Service Bus

Experience deploying, configuring, and managing Microsoft Azure Active Directory, Including
Governance and Policy Management
Role Base Access Control
Privileged Identity Management
Implementing enhanced auditing
· *Azure DevOps* – Able to effectively use Azure DevOps for
Planning using Azure Boards
Source Control using Azure Repositories
Build and Release using Azure Pipelines
· Knowledge of both supporting and building of complex Windows Server or Linux environments would be of benefit.

· Working knowledge and experience supporting multiple CI/CD pipelines with live deployments.

· Working knowledge and experience migrating legacy applications into the Cloud, preferably Microsoft Azure.

· Working knowledge and experience deploying data hosting solutions to the Cloud, preferably Microsoft Azure

In return for your hard work and commitment, we can guarantee you will be part of a friendly, innovative and dedicated team. It’s a fast-paced environment that offers strong growth potential. We are committed to providing flexible working options, a wide range of benefits and plenty of fun opportunities to unwind and connect with your colleagues

Don’t hesitate to send us your CV and continue your amazing career with Sol-Tec.

Job Types: Full-time, Permanent

Schedule:
Monday to Friday
Experience:
DevOps: 5 years (Preferred)",4.4,"Sol-Tec Ltd
4.4","Coventry, England",-1,51 to 200 Employees,1992,Company - Private,IT Services,Information Technology,$5 to $10 million (USD),-1
Data Engineer,-1,"Wefarm is the world’s largest platform connecting the small-scale farming community. Millions of farmers, retailers, and brands come together on Wefarm to grow their businesses.

Small-scale farming is one of the largest and most important industries in the world, with over one billion people globally involved in it. We’re working towards connecting this community so small-scale farmers can gain a better position in global agricultural supply chains. Some of the world’s leading VCs are backing us on this mission, including True Ventures in Silicon Valley.

Since our launch in 2015, we’ve grown to serve over two million farmers across Kenya, Uganda, and Tanzania. Our platform has facilitated the (free) exchange of over 18 million messages to share knowledge, generated over $5 million in marketplace sales, and sold nearly half a million products. So far, we’ve partnered with 100+ brands to give our members fair prices on the quality products they are looking for.

Our next milestone is to have 100 million farmers benefiting from Wefarm. Join us and be part of our mission to build an ecosystem for global agriculture, with the farmer at the centre.

The Role

We are looking for a Data Engineer to join our growing technical team, as our first full-time hire in this field. You will have responsibility for architecting and managing new data management processes, including data schemas and ELT (extract-load-transform) data pipelines. You will lead on greenfield projects, owning research and development, as well as having the remit to optimize our existing infrastructure.

The role sits within Wefarm’s Technology team and will report directly to the CTO.

Wefarm currently sends and receives millions of SMS per month, leading to tens of millions of independent system events. You will be responsible for the storage and transfer of this unique dataset. You must be self-directed, and comfortable supporting the data needs of multiple teams, including developers, BI, and data scientists, enabling Wefarm to use data to build insight, grow the company, and support the needs of our farmers.

There is a rich, vibrant, and open culture within Wefarm. Even though we are separated geographically, we maintain a highly collaborative and communicative outlook and are keen to maintain this as we expand into new roles and new territories.

Essential Duties

Build and maintain ELT (extract-load-transform) pipelines to get data from various systems and databases into our existing Snowflake data lake
Build and maintain SQL (and non-SQL) data transformations to enrich our data, including using DBT as the transformation step within our data lake
Enable stakeholders, including the BI, Product, and Growth teams, to get access to the data they need to perform their duties
Collaborate with Product Development teams to research and develop new data infrastructure projects, and architect reliable, accurate, and useful data schemas which can work for both operational and reporting purposes
Work across the company on data-related technical issues, and monitor database usage and performance to maximise efficiency
Ensure data security and data protection regulatory compliance by implementing optimal access policies and following industry best practice
Razor-focused on personal and team OKRs to ensure work is aligned with company goals

Extensive commercial experience working in a Data Engineer role (or equivalent experience in a backend engineering role)
A successful history of manipulating and processing large disconnected unstructured datasets, and enabling others to use data to build value
Advanced SQL (PostgreSQL and Snowflake)
Working knowledge of Git and GitHub
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores (e.g. SQS, Kafka, Snowflake)
Strong project management and organizational skills
Experience supporting and working with cross-functional teams in a dynamic environment
Able to clearly articulate and communicate with non-technical team members
Desirable: Clojure, Python and/or R
Excited about Wefarm’s mission

Rewards package and remuneration

The total rewards package and remuneration will be based on experience and potential, but is highly competitive and will include share options. We believe in our team being not only the executors of Wefarm’s visions but the makers and owners of it!

As a global business, travel is essential to who we are (when and where possible), and will be a perk of the job. We've hosted annual whole company offsites (Wecamp), previously held in Kenya and Uganda. In addition, we have a generous pension package, flexible working environment (within reason of course!), and we value spending time together - boarding the weekly lunch train, sharing some drinks on a Friday and frequent social events throughout the year.

N.B. You must have the right to work in the UK",4.3,"Wefarm
4.3","London, England",-1,1 to 50 Employees,2015,Company - Private,Telecommunications Services,Telecommunications,Unknown / Non-Applicable,-1
Data Engineer,-1,"Location:

Edinburgh, Scotland

Sector:

Database Development & Administration

Job type:

Permanent


Salary:

£50000 - £68000 per annum + bonus, benefits


Contact:

Femi Akintoye


Contact email:

Femi.Akintoye@oscar-tech.com


Job ref:

25376/FA_1599585112


Published:

20 days ago


Expiry date:

2020-10-08


Consultant:

Femi Akintoye
Data Engineer
Edinburgh
Up to £68,000 + bonus + benefits

A great opportunity to work for a leading, specialist data consultancy within their specialist Data Engineering team. You will be working with Tier 1 banks and insurance brands to improve their data pipelining and cloud infrastructures. The ideal candidate will have the experience with Python programming, as well as experience within either consultancy or financial services.

THE ROLE - DATA ENGINEER:
Building and managing data pipelines for leading banks and insurance companies;
Lead data projects on site at leading, Tier 1 banks and insurance companies;
Manage and store big datasets on cloud data platforms (AWS, Azure, GCP).

YOUR SKILLS AND EXPERIENCE:
To qualify for this Data Engineer role, you must have:
Extensive experience of Python programming;
Demonstrable experience of cloud platforms (AWS, Azure, GCP)
Experience with open source technology (Spark, Kafka, Snowflake, Hadoop)
Experience working for either: a consultancy or; a financial services institution.

HOW TO APPLY:
To apply, please do so via this site. For more information, reach out to Femi Akintoye at Oscar Technology

KEYWORDS:
Data Engineer, Data Engineering, AWS, GCP, Azure, Finance, Consultancy, Python, SQL, ETL

Oscar Technology is acting as an Employment Agency in relation to this vacancy.

To understand more about what we do with your data please review our privacy policy at https://www.oscar-tech.com/our-privacy-policy.",4.6,"Oscar Associates
4.6","Edinburgh, Scotland",-1,51 to 200 Employees,2001,Company - Private,Staffing & Outsourcing,Business Services,$25 to $50 million (USD),-1
Data Engineer,-1,"SoulTek’s client a leading Edinburgh fintech are looking for a Data Engineer to join the team ASAP. This role is fully remote initially but then will move to an in office environment, this is a really exciting time to be joining the company as they go through a fantastic period of growth.

The key skills needed are:

1-2 years of experience in an engineering role
Experience with Spark, Python, SQL and RDBMS is essential.
Previous experience of Databricks would be beneficial.
Experience in Java / Scala would be beneficial.
Strong entrepreneurial skills that bring customer-focused ideas to the projects.
Knowledge of best practices of software development including coding standards, code reviews, source control management, build processes, testing, and operations.
A natural collaborator with a proven ability to work across teams to get things done.

If this role sounds like something you could be interested in please apply.
Job Overview

Expiration date:
30th November 2020
Location:
Edinburgh
Job Title:
Data Engineer
Salary:
£30,000 - £40,000",-1,SoulTek,"Edinburgh, Scotland",-1,Unknown,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Start Date: Negotiable

Salary: Competitive compensation package including share options, subject to experience

Closing Date: N/A

Do you want to use your technical skills to help improve the lives of others?

About Healx

Healx is a fast-growing UK startup combining computational methods and drug discovery expertise to identify existing drugs that may treat rare diseases, enabling treatments to be found at a fraction of the time and cost of traditional drug discovery. There are over 7,000 rare diseases that affect an estimated 350 million people worldwide, most of which lack effective treatment. Working closely with patient groups and charities to understand clinical unmet need we have a growing portfolio of treatments derived from our AI platform which are now moving into clinical evaluation.

The role

Right now we are focussing on developing the next generation of our data platform, which underpins both the AI and bioinformatics products that we build to help our scientists, curators, pharmacologists and clinicians to develop new rare disease treatments. As a Data Engineer, you will be building an infrastructure to aggregate, annotate and serve a variety of scientific data in support of our AI-powered discovery process.

What you will be doing:
Working with engineers in a positive, collaborative environment to understand technical requirements
Helping build a data environment to support the acquisition and integration of data
Implementing technology to ensure our world-leading platform evolves to support the growing needs of our drug discovery and research colleagues
We'd love to hear from you if you are:
Enjoy automating data management and data modelling
Experienced Python programmer with relational and/or NoSQL databases. Experience in Snowflake is of particular interest.
Desirable:
Experience of AWS
An interest in Data Management
Have worked with ontological data
Working at Healx

Healx works from a modern accessible office in the centre of Cambridge within easy reach of the train station. We offer a flexible, diverse and inclusive working environment that considers your individual needs and believes in maintaining a sustainable work-life balance. You will be welcomed by a team of colleagues with decades of accumulated experience in their areas of expertise, happy to help you develop your own skills in a highly collaborative environment and who are keen to provide guidance and support in your personal and career development plans.

How to apply

Please submit your CV and cover letter below. Applying by any other means may not be successful.

For more information about Healx and how we use your data please go to https://healx.io/privacy/",4.6,"Healx
4.6","Cambridge, East of England, England",-1,1 to 50 Employees,2014,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable,-1
Data Engineer,-1,"Exscientia is at the forefront of Artificial Intelligence (AI) driven drug discovery and the only company to successfully design drug molecules entirely by AI that are in clinical studies. As a full stack AI Pharmatech, we are capable of generating our own experimental data to complement the analytical power of AI and the creativity and expertise of our world-class scientists. We aim to revolutionise the pharmaceutical industry by significantly shortening the preclinical drug discovery stage to accelerate new treatments to patients globally. Exscientia is collectively working to build a cutting-edge future and we are looking for like-minded individuals to join our journey.

We are currently seeking a highly-motivated data engineer with a strong background in software development and experience or interest in building innovative products. Bring your whole self to work and use your hard earned skills for the benefit of the whole of society and deliver AI as a force for good.

As a data engineer in the Centaur BiologistTM squad you’ll be working closely with an agile team of data scientists and bioinformaticians building systems of innovation with real impact for the business. There’s a good mix of greenfield projects, building on the existing platform and collaborating closely with the software engineering and devops squads to deliver scalable solutions.
You’ll have the opportunity to
Help us build the next generation of Centaur BiologistTM our innovative portfolio creation platform.
Productise data ingest pipelines using Python and ETL tools to populate Knowledge Graphs.
Design and implement a robust data layer to enable research teams supporting key decision making for the business.
Support and influence Devops strategies to operationalise large scale knowledge graphs and biological networks deployment on AWS.
What you will need
Highly motivated with a track record of success.
3+ years data engineering experience.
Knowledge of graph technologies such as RDF(S), SPARLQL, graph and triple-stores.
BSc degree in Computer Science, Bioinformatics or relevant field.
Solid experience building ETL processes using Python.
Proven experience with one the major cloud platforms AWS, GCP or Azure.
Experience with large data set ingest techniques.
Excellent interpersonal skills and ability to work in a multi-discipline squad.
What would be great to have
Experience or interest in Life Sciences / Drug Discovery.
Previous experience in knowledge graph or biological network creation.
Experience with containerization technologies such as Docker and Kubernetes.
Experience with natural language processing techniques.
Familiar with engineering best practises such as planning, and developing automation pipelines.
What can you expect from us?
Making a positive contribution to patients by revolutionising the pharmaceutical industry through AI driven discovery
Joining a scaling AI organisation with world class technical and scientific leaders
An opportunity to develop your career with us as we grow
We offer a highly competitive compensation to support our employees as we continue to grow and thrive
The opportunity to join an inclusive, collaborative and intellectually stimulating culture
Working in modern offices with fantastic free food on offer",-1,Exscientia,"Dundee, Scotland",-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"DATA ENGINEER

(DEPLOYMENT SUPPORT)

Expected Contract term length: Provisionally set at 35 days but this is to be to agreed at the point of contract award.

Security Clearance : BPSS or DBS

Essential Skills and Experience:

\*Demonstrable experience delivering Deployments.

\*Experience deploying windows 10 devices.

\* Excellent customer engagement experience and communication skills

\* Demonstrable experience delivering projects to time and budget.

\* Knowledge of DCM portfolio

\*Knowledge of windows Auto-pilot

\*Knowledge of Apple DEP

\*Evidence of delivering at scale

Note: Must have all the skills mentioned above.

Reference ID: DE/LON23

Contract length: 35 days

Application Deadline: 09/10/2020

Expected Start Date: 13/10/2020

Job Type: Contract

Salary: £400.00-£500.00 per day

Schedule:
Monday to Friday
Work remotely:
Temporarily due to COVID-19",5.0,Exscientia,"Dundee, Scotland",-1,1 to 50 Employees,2017,Private Practice / Firm,Consulting,Business Services,Unknown / Non-Applicable,-1
Data Engineer,-1,"implement data flows to connect operational systems, data for analytics and business intelligence (BI) systems
engineer data flows to enable scaling and repeatable use
support the build of data streaming systems that provide robust, clean data. including removal of Personally identifiable information (PII)
develop reporting to feed into the programme insights dashboard and - provide trend modelling to forecast performance against KPIs (key performance indicators)
build accessible data for analysis, supporting the development and underlying data infrastructure of tools that improve our understanding of data
support data infrastructure and work streams on cross-domain data
participate in a performance and data analysis community of practice - sharing knowledge through show and tells, case studies and blog posts
Responsibilities
demonstrable experience of data analysis and synthesis including data profiling and source system analysis
experience of the data development process with the ability to design, build and test data products and pipelines that are complex or large-scale
experience in data integration design that delivers resilient and scalable data solutions
experience of data modelling, including reverse engineering from live, with good knowledge of data modelling patterns and standards
strong ability to communicate concepts and insights to technical and non-technical audiences to present clear insights and support the end use of the data
knowledge of designing metadata repositories, presenting changes to existing metadata and the range of tools for storing and working with metadata
experience of defining test conditions and identifying associated issues and risks
knowledge of data governance and data security and privacy
ability to work to tight deadlines and under pressure in an agile environment
Benefits
25 days annual leave + an extra day off for the Queen's birthday
flexible working options to enable you to achieve the work life balance that right for you including part-time, flexi time and job sharing
civil service pension with an average employer contribution of 27%
training and development opportunities
interest free season ticket, tenancy deposits and holiday advances
an in-year bonus scheme
bike loans
eye care vouchers
on site showers, mothers room, multi-faith room, secure bike parking (subject to availability),
quiet spaces and cafe/wine bar
free networks and clubs",4.0,"UK Government - Government Digital Service
4.0","Bristol, England",-1,501 to 1000 Employees,2012,Government,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Description

Our Data, Analytics & Intelligence team are at the core of the latest developments and key decisions within our business. They’re a constantly expanding team and currently on the lookout for a Data Engineer to join them on a permanent basis.

Our team are driven by a passion to help make a tangible and lasting difference in people’s lives through the innovative transformation of our products, and you’ll have that same passion.

Within this role, you’ll hold responsibility for the creation and maintenance of a logical data model, integrating data from multiple data sources in to a central Enterprise data warehouse. You’ll be able to design and apply data cleansing and data standardisation rules, providing clear documentation of the business rules embedded in the system, with the potential of solving data quality issues.

Whilst you’ll have a variety of stakeholders, you’ll work closely with the wider Data team to understand what the data journey needs to look like (conversion, processing, etc), specifically working closely with the Data Architect to create an overview of the data lineage.

Please note this role will initially be working from home, with a shift to a hybrid office/home working set up as lockdown restrictions evolve. We’re also committed to the work/life balance of our teams, so we’re happy to consider flexible working options.

Qualifications

You’ll have a strong development background with experience using SQL for OLAP/Data Warehouse style modelling, and will have a track record in creating Star Schema Data models for BI solutions. You’ll also feel comfortable working with modern Big Data technology and tooling. A sound awareness of Data Management best practice is a must, including Data Lifecycle Management across Core IT and Big Data eco-systems, as well as a firm understanding of Data Privacy and Security constraints.

You’ll naturally be someone who adapts well to change and actively seeks out ways to improve efficiency, as well as having an interest in learning new frameworks and languages. You’ll feel at ease advising on the use of data for actionable analytics, and also share our passion for putting our customers first with the end user being at the forefront of your decisions.

As the role offers a healthy level of autonomy, you’ll thrive working with minimal guidance, and feel comfortable using your own initiative. You’ll apply your analytical thinking to ensure effective problems solving.

About AXA

With a presence in over 60 countries, and 165,000 employees serving the needs of 107 million customers, AXA is big.

But never too big to care for every single person who works here. We’ve been recognised as one of the Sunday Times Top 25 Best Big Companies to work for. So when you join us, we promise to put our collective might behind you and your career.

You’ll work in an open and supportive environment where you’ll be developed, challenged and encouraged to move around to achieve even bigger and better things – nationally and internationally. You’ll learn directly from senior leaders, from the best in our business. And you’ll enjoy real responsibility, really early on.

Proud to be part of the AXA Group, the number one global insurance brand, a worldwide leader in financial services, AXA PPP healthcare is leading the way to better health. We’re one of the UK's largest and most experienced private medical insurance providers, and we’ve been helping people access the medical care they need, when and where they need it, for over 70 years now.

What We Offer

As well as being a part of our inclusive and supportive culture, you’ll enjoy a variety of benefits as part of this role, some of which are listed below:
Annual bonus scheme (eligibility rules apply)
Contributory pension scheme
Private medical insurance
28 days holiday plus statutory holidays (pro rata), with the option to purchase additional holidays
A variety of local and national discounts, including on AXA Insurance products
Access to a varity of flexible benefits which you can opt in to

AXA is proud to support the needs of our employees and as such understands everyone has individual work and home life responsibilities. We are therefore happy to discuss flexible working arrangements for this role.",4.3,"AXA UK
4.3","Royal Tunbridge Wells, England",-1,5001 to 10000 Employees,1996,Company - Private,Insurance Carriers,Insurance,Unknown / Non-Applicable,-1
Data Engineer,-1,"Data Services and Analytics is a critical enabling capability for the Home Office providing both key business data services and ad hoc analytics requests. DSA’s Vision and mission statements are as follows is as follows:

Vision:
“Recognised as the leading provider of data insight services in Government”

Mission:
We work together as a committed, proud, expert resource providing clearly defined data services and analytics for all of the Home Office.

We are secure in a growing team, with extra capacity to provide flexibility and opportunity for more innovation and production level services for all the Home Office, with effective centralised funding and 3 times growth over four years.

We operate on a common technology and data platform used by all parts of the Home Office for data science and analytics.

DSA is currently in the process of transitioning an on premises capability to AWS utilising a bespoke Java based platform.
DSA comprises multi-disciplinary teams including data engineering, data science, infrastructure, platforms, MI and data analysis and product teams.
The data engineering team are pivotal in both making new data available for our products and services and ensuring that established data pipelines operate in the most optimal way.
DSA Data Engineers deliver data to facilitate the analytics vision for the organisation as set by the DSA Senior Leadership Team. You will focus on the design and implementation of numerous data flows to connect operational systems, data for analytics and BI systems.

As a Data Engineer, you will identify and deliver new data sources and develop ETL processes. You will also collaborate with the Data Acquisition, Analytics and Infrastructure teams to deliver the data strategy through the design and implementation of technology systems.
You will support Senior Data Engineers in analysing problems and data analysis issues, looking for underlying causes and assisting in developing solutions. You will also be responsible for delivering data solutions in accordance with agreed organisational standards that ensure services are resilient, scalable and future-proof.
You will work closely with the Data Services Science community, who will set the scope of your data engineering work through their research of user and business needs and by their designing data pipelines through writing user stories.

Responsibilities
Your main day to day responsibilities will be:

Assisting in the development of new data models and ETL processes, working collaboratively with the Analytics team to build data streaming systems.

Designing, building and testing data products based on feeds from multiple systems using a range of different storage technologies and/or access methods.

Applying the concepts and principles of data modelling to produce, maintain and update relevant data models for specific business needs, including reverse engineering data models from a live system.

Assisting in designing, writing, iterating and optimising code from prototype to production-ready.

Undertaking data profiling and source system analysis and presenting clear insights to colleagues to support the end use of the data.

Assisting in the successful delivery of completed data loads for customers, Data Engineers and Data Scientists, putting in place remedies and troubleshooting when required and assisting in the development of new data load programmes.

Supporting change and bug fix for complex data products in response to business and product managers needs.

You will also be expected to carry out the following day to day activities:

Supporting the development of requirements from full development, test and through to deployment lifecycles, while maintaining the schedule of work.

Designing, coding, testing, correcting and documenting simple programs or scripts under the direction of others.

Supporting with the development of methods to monitor and improve data quality in source systems using feedback from the Analytics team.

Undertaking changes to existing routines following change control procedures and then liaising with team members and other teams to communicate delivery and impact of change.

Working with data privacy and information security staff to assure that security and privacy requirements are identified and addressed in your solutions.

Working closely with the Data Engineering community to promote challenge from, collaborate with, and ensure an agile approach to working is being adopted. You will also mentor new Data Engineers and Associate Data Engineers.

Essential Skills

You’ll have a demonstrable passion for Data, with the following skills or some experience in:

IT programming.

Using tools such as industry standard ETL tools, network databases and scheduling and orchestration tools. Knowledge of SQL is a must have skill and candidates must be capable of writing performant and complex database queries. Python is used extensively in DSA products and core ETL platforms and is a requirement of the job.

Effectively managing and communicating with a variety of stakeholders by translating technical concepts into non-technical language.

Managing the development and delivery of technical products.

Understanding Cloud Data technologies, solutions and future Cloud Data Strategies. An appreciation of core basic AWS components, S3, EC2, Redshift, Glue, Athena, DMS, MSK, and Redshift Spectrum is required (in depth knowledge and operational experience is not required).

Applying data development / engineering techniques – both in theory and practice or a strong aptitude to learn.

The skills listed above are reflective of the Home Office DDaT Profession Skills and Competency Model (based on the industry standard SFIA framework). Please see below for the relevant skills required for your role:

Strategy and Architecture:
Business Strategy and Planning
Innovation INOV – Level 3

Technical Strategy and Planning:
Data Management DATM – Level 2
Methods and Tools METL – Level 2

Development and Implementation:
Systems Development
Data Modelling and Design DTAN – Level 3
Database design DBDS – Level 2

Delivery and Operation:
Service Operation
Database Administration DBAD – Level 2

Desirable Skills:

Ideally, you will also have the following skills or some experience in:

Working with Big Data tools and data stores.

Using modern / open source programming languages and tools – including to deliver data development / engineering products. Experience of Java would be highly advantageous, as would knowledge of streamed data technologies, particularly Kafka.

Knowledge of containerisation, Docker would be advantageous.

Some experience of existing Home Office and OGD data sets (e.g. CID, CRS, API etc.)

Qualifications:

A numerate degree or equivalent experience.

An Agile Foundation is desirable.

AWS practitioner level certification (or demonstrable evidence of working towards gaining certification would be desirable).",3.6,"Home Office
3.6","Croydon, England",-1,10000+ Employees,1782,Government,Federal Agencies,Government,Unknown / Non-Applicable,-1
Data Engineer,-1,"At One Manchester we’re passionate about working together to improve lives and help our communities thrive. We see the difference our work makes across our great city every day. Join our business to be part of a team that is transforming the way we work and use technology to help our people and customers engage with us in an easier and more meaningful way.

As part of modernising our business and preparing for the future, we are under-taking several critical projects in the area of corporate IT and data services. These include cloud migration, network & telephony refresh, agile working, colleague experience, data and integration.

As a Data Engineer you’ll be responsible for designing, implementing and improving our data management infrastructure that underpins the success of the One Manchester business. You’ll be part of our IT team, which sits within One Manchester’s Business Change portfolio.

We’re looking for someone with technical experience designing, implementing and supporting data systems within the Microsoft data platform, and integrating with non-Microsoft databases and other data sources. We are also looking for someone who can play an active part in developing our approach to data and system integration, using API’s and system-to-system integration techniques. You’ll have strong core SQL skills (principally T-SQL), with experience in SSRS, SSIS and Azure Data Factory. You’ll have a firm grasp of ETL principles and construction of data pipelines. You’ll be able to design and support Power BI data models and have some experience of consuming those models. We’d be delighted if you have experience or familiarity with the wider Microsoft Power platform, or Microsoft Azure more generally.

You’ll have experience contributing to and supporting these functional activities:

Data cataloguing and data modelling

Data quality management

Data and system integration

Project planning, task tracking and progress reporting

Technical leadership within mixed-discipline teams combining subject matter experts and practitioners, project management and technical functions

Delivering change in a lightweight ITIL-type environment

You’ll work closely with colleagues in the wider IT and Business Change teams, our Business Insight team, and across the organisation, through a period of significant change. You’ll be able to embrace a demanding workload, working to agreed high standards and responding to changing priorities effectively.

We’re heavily investing in great people across our IT and business change teams, so this is a great time to join. This is a challenging but rewarding role where you’ll really see the difference you make to people’s lives every day. At One Manchester, we’re supportive, flexible and rightly proud of our work. We’re also really excited about the future. You’ll get a brilliant benefits package and so much support and guidance. So, join us now and see the difference you can make in our great city.

If this sounds like you then apply today, we’d love to hear from you.

Closing date is 18 November 2020 and interviews/assessments will take place from week commencing 23 November 2020.",-1,One Manchester,"Manchester, England",-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"We believe energy should be better - for you and the environment.

We’re a leading energy technology company providing a better experience for our customers through transparency, honesty and simplicity. Better for the planet, through real long-term investment in renewable generation and a low CO2 future. Better value, by throwing away the old business models of the “Big 6” and instead building a business that’s fit for the 21st century. We make energy green and flexible for consumers, with fair and transparent pricing. Through our home developed platform, cloud-based billing, and sophisticated use of data science, modelling and AI, we’re redefining what is possible in energy.

Our breakthrough Agile tariff has been widely reported as leading the way in energy innovation, and we’re passionate about fairness – we were first to uncover the widespread strategy of energy company tease and squeeze pricing and following on from this campaign, our CEO and Founder Greg Jackson presented evidence in favour of capping energy tariff prices before the bill committee in Parliament.

We already supply 100% renewable energy to over 1.5 million homes and over 12,000 businesses (including Arsenal FC and the Cardiff Blues to help them power their stadiums with 100% renewable energy) throughout Great Britain and we’re also the supplier behind M&S Energy. We’re award winning for our disruptive technology and are delighted to be the only energy supplier to pass the rigorous Which? customer service tests and be their only recommended energy supplier for 3 years in a row.

We also proudly enjoy a 5-star TrustPilot ranking from our customers. We were named the Company that’s done the most in the past year to advance UK renewables at the REA Awards 2019, and most recently, our proudest award, that of Best Company to Work For. Our group includes Octopus Energy, Kraken Technology, Octopus Electric Vehicles and Octopus Energy Services.

We recently secured over £300 million of investment from Origin, Australia's largest Energy Company, to help us continue our mission. This will help power our growth into new markets, build more tech to make energy greener, and increase our investment in service and growth in our existing markets (the UK and Germany). You can read more about the impact of this investment here.

Octopus’ proprietary platform offers a market leading level of operational efficiency and flexibility to support a wide range of offers and pricing constructs including the only dynamic half hourly tariff in the UK. We are also able to offer white label solutions and work with brands such as Arsenal Football Club and Marks & Spencer plc.

Over the last 18 months we have built a market leading Gross Margin platform that provides daily meter point level granularity on revenue and cost. Working alongside Kraken, our proprietary CRM, billing and industry interfacing software, every day our automated platform produces billions of rows of data giving us detailed historic and forecasted insight into the profitability of the customer base and any risks/opportunities we are facing.

We use the data for:
Providing the base inputs for the majority of our financial reporting.
Performing Revenue Assurance and accurately tracking associated risks
Validating portfolio billed & unbilled volumes against industry settled volumes.
Reconciling invoices against our cost calculations.
Tracking portfolio health via integrity checks

We are looking for an experienced, data-driven developer to assist globalise the platform. We are currently active in UK, Germany, USA and New Zealand with ambitious global expansion plans. The vision is to build a single global platform that incorporates country specific inputs and generates consistent outputs to enable clear and easy understanding of global financial performance. With each new market there are new datapoints we need to incorporate into the platform. Whilst the Data Science team are responsible for generating these inputs we need to have a detailed understanding of them and integrate them into the RA platform so that global reporting outputs having a single theme and represent the company as a whole, rather than by country.
What you'll do
Work closely with the Platform Engineer to deliver platform strategy and requirements and to make recommendations where appropriate
Decouple the platform inputs from the UK specific variant of Kraken so that we can input industry, meter point and cost data from any country we expand to and the platform continues to run seamlessly.
Expand the platform granularity to the relevant time periods (reporting varies from 30 minute time bands to 5 minute time bands dependent on the local market).
Ensure the platform is designed for scale – as we expand into new markets we expect the data generated from the platform to increase exponentially.
Work closely with the Data Science team and the Platform Engineer to add the following to the platform for each new country entered:
New industry data (settlement coefficients, line losses, settled volumes)
New cost matrices (historic and forecast)
Work closely with the Finance team and the Platform Engineer to add the following to the platform for each new country entered:
Import of invoice data (e.g. wholesale / metering costs etc) & reconciliation
Work closely with the Strategic Finance team and the Platform Engineer to incorporate forecasted gross margin for acquisitions / scenario modelling.
Keep up to date with the latest big data tools and implement them where you think they are beneficial.
What you'll have
Knowledge of electricity and gas supply or similar utility markets would be an advantage but not essential
Proficient in design and implementation of robust production systems in Python
Experience with SQL and AWS
Experience working with big data
Experience with Spark, Airflow, Github and K8s advantageous
Very bright, highly numerate, ability to handle multidimensional concepts
Excellent communication skills
Flexibility to grow and adapt as the business grows
Able to challenge with empathy and ‘muck in’ as required at times as we develop the business
Comfortable with some ambiguity (our world is changing fast)
What you'll get
Equity Option Scheme (own part of the business)
Pension Scheme - Employer 5% Employee 3% - you can opt to contribute more!
Flexible working environment
Cycle to Work Scheme
Fruit, breakfast and hot drinks
Weekly free Friday drinks
Access to Hatch - Financial advice and planning for employees
Childcare Vouchers
Support to help with development (courses, learning, development)
If you this sounds like you and you have a genuine passion for what we are doing then we'd love to hear from you!",4.7,"Octopus Energy
4.7","London, England",-1,201 to 500 Employees,2015,Company - Private,Energy,"Oil, Gas, Energy & Utilities",Unknown / Non-Applicable,-1
Data Engineer,-1,"We are looking for a experienced Data Engineer to join our clients growing company on a contract basis. The successful candidate will be proficient in building and maintaining data pipelines on GCP stack. Proficient in ETL/ELT process, data migration from on-premise to GCP.

Skills and Experience:

Experience in ETL/ELT process
Experience in data visualisation
Experience with NIFI tool
Experience in writing and maintaining data pipelines using DataFlow (Apache Beam)
Experience in applying orchestration to the data pipelines using Apache Airflow or/and Data Composer
Hands-on experience working with Data stack on GCP
Pub/Sub
GCS
Data Flow
Data Composer (Airflow)
BigQuery
Ability to write and modify templates for DataFlow written in Java (is a must)
Experience in writing complex SQL queries
Experience in modifying jobs in Jenkins (on developer level, not a DevOps)

Please apply with your latest CV and someone will contact you to set up a call and discuss the role in detail.

GCS Computer Recruitment Services is acting as an Employment Business in relation to this vacancy.",4.2,"GCS Recruitment Specialists Ltd
4.2","London, England",-1,51 to 200 Employees,1991,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Data Engineer,-1,"Depop is the fashion marketplace where the next generation buy, sell and get inspired. We are headquartered in London, UK with locations in New York and LA. We have more than 20 million registered users in 147 countries. In the UK, 1 in 3 Gen Z/Millennials are registered and in the US we have grown 300% over two years. We are also the only European player to have recently entered the top 25 shopping apps by daily active users.

Our mission is to empower the next generation to transform fashion, and our team of nearly 200 people are dedicated to serving the needs of our global community.

We operate on three pillars:
Community: Our buyers, sellers and employees are inclusive, diverse and accessible. We are committed to empowering diversity within the fashion community.
Entrepreneurship: We support our community and help them build their business with Depop. We thrive on supporting innovation by shaping an environment where creators, makers or hustlers can thrive.
Sustainability: Depop helps extend the life of garments and reduce waste, we care about the world and want to make a positive change within the fashion industry.

The Role

Data is at the heart of what we do.

Depop is looking for a Data Engineer to join our growing team! Our platform receives 10,000's of requests every second; we're looking to cut through the noise, leverage this vast data, and find value.

We're building scalable and robust systems to harvest, process and analyse the vast data within our tech ecosystem. With an increasing demand to service other areas of the business, and ultimately our 16 million users, you'll be at the forefront of pioneering Data-as-a-Service.

Want to find out more about Depop & our engineering team?

We write about technology, people and smart engineering right here -https://engineering.depop.com/

Responsibilities:

You'll be...
building out our data infrastructure, in terms of scalability and availability, with an additional focus on ensuring data integrity
working on projects centred around real-time streaming, data lake optimisation and a novel user-tracking and personalisation system
continuously developing Data and Software Engineering knowledge and best practices
interacting with internal members of the Depop team to solve business problems
Requirements:

You have
software development experience using either Scala or Python, and understanding of SDLC best practices
a deep understanding of the importance of testing
experience working with distributed systems
knowledge around data processing and warehousing systems (batch or stream), through leveraging the latest data engineering technologies (e.g. Spark and Kafka)
a willingness to deliver user value quickly
Technologies and Tools:
Airflow
Kubernetes
Scala
Python
Terraform
Kafka
Spark
Benefits
Learn and Grow: We want to give our people the opportunity to learn. We sponsor and run a myriad of programs, conferences and meet-ups to upskill our employees and enhance their journey with us, just ask!
Wellbeing: We care about our employees wellbeing. We offer a cycle to work scheme, healthy fruit and snacks in the office, breakfast every Tuesday, eyecare vouchers and a discounted gym membership at Nuffield Health.
Mental Health: Our employees mental health is a top priority. We offer subsidised counseling appointments with a qualified therapist through SelfSpace, we have trained mental health first aiders and we also run yoga, meditation and more.
Work/life balance: We have 25 days of holiday with the opportunity to buy or sell 5 more, a day off for activism to allow you the opportunity to make a difference and we offer sabbaticals for our long serving employees
Family life: We offer flexible working (based on the team you will be joining), generous maternity/paternity and parental leave policies which includes adoption and paid time off for fertility treatments. Also, all of our offices are dog-friendly! Do your best work with your best friend.
Fun: We love to hang out with each other at Depop. On Friday we finish an hour early to socialise with free food, and have amazing Winter and Summer Parties to celebrate our successes. We also host internal employee socials such as quiz night, games night, movie night and more...we've taken this virtual for now!
Equality and Diversity Monitoring

Depop is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.

Depop recognises the benefits of a diverse workforce which reflects the wider population and welcomes applications from all sections of the community. Under the Equality Act (2010), Depop must demonstrate that their recruitment processes are fair and that we are not discriminating against or disadvantaging anyone because of their age, disability, gender reassignment status, marriage or civil partnership status, pregnancy or maternity, race, religion or belief, sex or sexual orientation. We need to ask applicants some questions to make sure that no one is being unfairly discriminated against or disadvantaged.

We collect this information only for anonymised monitoring purposes to help the organisation look at the profile of individuals who apply, are shortlisted for and appointed to each vacancy. In this way, we can check that we are complying with the Equality Act (2010).

Under the Equality Act 2010 the definition of disability is if you have a physical or mental impairment that has a 'substantial' and 'long-term' adverse effect on your ability to carry out normal day to day activities. Further information regarding the definition of disability can be found at: www.gov.uk/definition-of-disability-under-equality-act-2010

Reasonable adjustments will be made available should you be invited to interview.

GDPR Statement

When you apply to a job on this site, the personal data contained in your application will be collected by Depop Ltd, 08316342 (""Controller""), 9th Floor 107 Cheapside, London, United Kingdom, EC2V 6DN (""We"", ""Us"") and can be contacted by emailing people@depop.com.

Your personal data will be processed for the purposes of managing Controller's recruitment related activities, which include setting up and conducting interviews and tests for applicants, evaluating and assessing the results thereto, and as is otherwise needed in the recruitment and hiring processes. Such processing is legally permissible under Art. 6(1)(f) of Regulation (EU) 2016/679 (General Data Protection Regulation) as necessary for the purposes of the legitimate interests pursued by the Controller, which are the solicitation, evaluation, and selection of applicants for employment.

Your personal data will be shared with Greenhouse Software, Inc., a cloud services provider located in the United States of America and engaged by Controller to help manage its recruitment and hiring process on Controller's behalf. Accordingly, if you are located outside of the United States, your personal data will be transferred to the United States once you submit it through this site. Because the European Union Commission has determined that United States data privacy laws do not ensure an adequate level of protection for personal data collected from EU data subjects, the transfer will be subject to appropriate additional safeguards under [either the standard contractual clauses or the Privacy Shield]. You can obtain a copy of the standard contractual clauses by contacting us at people@depop.com.

Your personal data will be retained by Controller as long as Controller determines it is necessary to evaluate your application for employment. Under the GDPR, you have the right to request access to your personal data, to request that your personal data be rectified or erased, and to request that processing of your personal data be restricted. You also have to right to data portability. In addition, you may lodge a complaint with an EU supervisory authority.",4.4,"Depop
4.4","London, England",-1,201 to 500 Employees,2011,Company - Private,Other Retail Stores,Retail,Unknown / Non-Applicable,-1
Data Engineer,-1,"At Cervest data is the connective tissue that runs through the whole organisation and our product offering. The domain we work in of climate, climate change and its impact on every single physical asset in the world, is represented by a complex data ecosystem.

We are looking for a Data Engineer with experience of working with Geospatial data to join the team, and help us develop our data platform. The role offers a unique opportunity to join an exciting, early-stage, highly mission-driven team where you’ll have the ability to make a significant impact on our company and our users.

Main responsibilities
Working closely with our scientists, engineers and product designers to build the core components of our data platform that satisfies a set of cross functional requirements.
Work with senior leaders throughout Cervest to make sure that what we are building is best in class for what we are trying to achieve today as well as 12 months from now.
Supporting the delivery of tactical requirements both internal and external as and when they occur
Build and grow the Data Engineering team at Cervest and unify the culture of data usage across the organisation.
Requirements
Experience of developing data engineering pipelines and services using Geospatial data
Knowledge of cloud native architectures and Big Data frameworks
Working knowledge of some of the following domains:
Machine Learning
BI and Reporting Analytics
Graph Technology
Benefits

Salary – £65-75K / annum (dependent on experience) or local equivalent

Opportunities to learn, grow and thrive with support from talented and empathetic team mates

We are a remote first company and, given the time frame for this role, we are anticipating that it will be fully remote. We are looking for candidates who would be able to come to our office in London (once travel is sensible) once a quarter using more sustainable transport methods (we'll help with that) so generally within one time zone of the UK.

Fuller list of benefits on our main career page - we’re an early stage startup and currently reviewing our benefits in light of becoming a remote-first company. We are committed to ensuring that we support our team in developing in line with their aspirations and talents as well as continuing to develop our culture in line with our values.",5.0,"Cervest
5.0","London, England",-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Join us as a Data Engineer

This is an exciting opportunity to use your technical expertise to collaborate with colleagues and build effortless, digital first customer experiences
You’ll be simplifying the bank through developing innovative data driven solutions, inspiring to be commercially successful through insight, and keeping our customers’ and the bank’s data safe and secure
Participating actively in the data engineering community, you’ll deliver opportunities to support the bank’s strategic direction while building your network across the bank

What you'll do

As a Data Engineer, you’ll play a key role in delivering value for our customers by building data solutions. You’ll be carrying out data engineering tasks to build a scalable data architecture including carrying out data extractions, transforming data to make it usable to analysts and data scientists, and loading data into data platforms.

We’ll also expect you to be:

Developing comprehensive knowledge of the bank’s data structures and metrics, advocating change where needed for product development
Building automated data engineering pipelines through the removal of manual stages
Working closely with core technology and architecture teams in the bank to build data knowledge and data solutions
Developing a clear understanding of data platform cost levers to build cost effective and strategic solutions

The skills you'll need

To be successful in this role, you’ll need to be an entry level programmer and data engineer with a qualification in Computer Science or Software Engineering. You’ll also need a good understanding of data usage and dependencies with wider teams and the end customer, as well as a proven track record in extracting value and features from large scale data.

You’ll also demonstrate:

Good critical thinking and proven problem solving capabilities
Experience of ETL technical design, automated data quality testing, QA and documentation, data warehousing, data modelling and data wrangling
Extensive experience using RDMS, ETL pipelines, Python,, Scala and SQL
A good understanding of modern code development practices
Evidence of working in model development and deployment environment with appropriate practices, such as testing, version control and logging
Evidence of working in a cloud environment with some of the following technologies EMR, Spark, Hadoop, HIVE and similar big data technologies, Apache Airflow, Luigi and similar orchestration systems

If you need any adjustments to support your application, such as information in alternative formats or special requirements to access our buildings, or if you’re eligible under the Disability Confident Scheme please contact us and we’ll do everything we can to help.",3.9,"NatWest Group
3.9","Edinburgh, Scotland",-1,10000+ Employees,1727,Company - Public,Banks & Credit Unions,Finance,$10+ billion (USD),-1
Data Engineer,-1,"*Job Title: *Data Engineer

*Location: * Worsley, Manchester

*Salary: * £14/hr

Focused Construction are a long established, well respected & reliable labour supplier to the construction, engineering and industrial sectors. We pride ourselves on the service we provide to our clients & contactors.

*Job Description: *Focused Construction are looking for a data engineer in Manchester!

*Essential Requirements: * CSCS Card

IPAF preferred

*Contact name: * Eleanor

*Phone number: *07714383111

*Focused Construction are an equal opportunities employer. All applicants will be considered on their merits regardless of race, ethnic or national origin, nationality, disability, sex, marital status, religious belief, sexual orientation.*

Job Type: Full-time

Salary: £14.00 per hour

Schedule:
* Day shift

Experience:
* Data Engineer: 5 years (Required)

Licence:
* CSCS (Required)
* IPAF (Preferred)",3.7,"Focused Construction LTD
3.7","Worsley, England",-1,51 to 200 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Company description

We are the AA. And we keep everyone’s show on the road. There for our customers wherever and whenever they need us, we’re always ready for anything. That’s why, for over 100 years, we’ve continued to evolve and adapt. Today, as the nation’s number one motoring organization, we offer a range of excellent products and services to millions of customers.

This is the job

Reporting to the Senior Data Engineer, this role is responsible for extracting, transforming and loading data within a data warehouse solution, in line with the requirements agreed with the business.

You will be responsible for developing new and amending existing data warehouse solutions within agile and waterfall delivery methodologies. You will collaborate with design and testing teams to ensure that your development work has been completed as per the technical specifications, is in line with the Data Tower development standards and guidelines, and meets the business requirements",2.9,"The AA
2.9","Basingstoke, England",-1,5001 to 10000 Employees,1905,Company - Public,Auto Repair & Maintenance,"Construction, Repair & Maintenance",Unknown / Non-Applicable,-1
Data Engineer,-1,"About us

It’s an exciting time to join the Oakland Group, we’re a technically excellent tech start-up with a long history in operational excellence. In the past 18 months, we’ve seen huge growth and we’ve exciting plans for the future.

We work with clients such as Vodafone, Network Rail, and Yorkshire Water but we’d like more!

This is a fantastic opportunity to join our young and passionate team, we’re still small enough for everyone’s voice to be heard and for you to forge your path and play an essential role in the growth of our business.

Job description

We are looking for a data engineer with experience in big data projects who has an appreciation of frontend technologies & is interested in working across multiple projects.

You will play a critical role in building and maintaining applications for data & analytics projects and products we provide to our clients. As we specialise in data and analytics, we are looking for developers who are excited by the ability to work across different problems, projects and clients and who genuinely cares about the end to end data space (including engineering, science, quality, analytics and BI). These are client-facing roles, focused on helping clients solve operational problems, using data and analytics. An integral part of our data team, you will be happy to use modern tools to solve old legacy problems.

Dealing with ambiguity is a critical part of the job, as well as helping the client and internal team focus on specific problem statements and use cases.

The person

You will be extremely comfortable working in a small team, with a tech start-up mentality.

What do we require:
Demonstratable 2-3 years’ worth of experience in big data projects
Experience in working with Spark or extensively with Pandas
Has experience in production-grade applications in the cloud (AWS / Azure / GCP)
Has experience in working with serverless technologies
Has worked in a full-stack environment & has an appreciation of front end technologies
Experience with CI/CD Pipelines
Experience in client-facing roles
Someone who likes to work on specific problem statements and use cases
Our values are important to us, we want to work with people who feel the same
Benefits

£TBC OTE

25 days annual leave plus bank holidays

Pension scheme

Private healthcare",5.0,"The Oakland Group
5.0","London, England",-1,1 to 50 Employees,1985,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1
Data Engineer,-1,"The Job: Data Engineer

The Company

First People Solutions are working with a leading Intelligent Building Systems contractor based in Glasgow who are looking for experenced Data Engineers to join their team based in Edinburgh

The Role

The successful candidates will be required to have previously worked as a Data Engineer and have experience in terminating cables. Experience in Fire & Security Systems will also be advantageous

To apply you must supply the following:

CV
ECS/CSCS
Cat5/Cat6 experience
Fibre Optic experience
Terminating cables

For more information please contact me on 0141 270 5130.",4.5,"FPS
4.5","Edinburgh, Scotland",-1,Unknown,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"As a Data Engineer at Unipart Digital you will work to build and improve the tools and infrastructure that the Data Scientists use for working with large volumes of data and that power user-facing applications. You will work on our data pipeline project, with plenty of scope to guide its direction and growth; and regularly collaborate with both the Data Scientists and data providers in the wider business to understand their needs. You will build and customise open-source components to create a pipeline that will enable Unipart to drive decision making and process improvement with real-world data from its numerous logistics and warehousing operations. You will create and maintain the ETL infrastructure on our own OpenStack private cloud, and work with Data Scientists to help them turn their models and analysis into production systems.

Data Engineer Requirements:

Have at least 5 years’ experience working in software development
Be expert in Python
Have experience working with PostgreSQL (or other relational database system)
Be skilled in common tools such as Puppet and Git, or equivalents
Be comfortable developing for distributed systems
Have a keen interest in learning and a desire to help educate those around them in new technology
Work effectively with a distributed team and in an agile environment

About Unipart Group Limited:

You may remember Unipart as the company that revolutionised the automotive parts industry in the 1970s. Unipart is different company today with clients such as McLaren, Apple, Vodafone, BSkyB, Jaguar Land Rover and, the NHS. The Unipart Group is an independent manufacturing, logistics and consultancy company that employs nearly 10,000 employees worldwide and has an annual turnover of more than £1 billion.

Location: Homebased / Cambridge

Job type: Full Time, Permanent

Salary: Competitive",3.7,"Unipart Logistics
3.7","Cambridge, East of England, England",-1,1001 to 5000 Employees,2001,Company - Private,Logistics & Supply Chain,Transportation & Logistics,$500 million to $1 billion (USD),-1
Data Engineer,-1,"Role overview

Data Engineer

REFERENCE : T26

REPORTING TO : Head of Technology

DATE : October 2020

AUDIO NETWORK IS A GLOBAL MUSIC COMPANY CREATING ORIGINAL, HIGH-QUALITY MUSIC FOR USE IN TV, FILM AND ADVERTISING AND FOR USER-GENERATED CONTENT ACROSS DIGITAL AND SOCIAL PLATFORMS.

WITH A ROSTER OF OVER 1,000 ARTISTS AND A CATALOGUE OF +175,000 TRACKS ACROSS EVERY CONCEIVABLE GENRE – WE’RE HELPING OUR CUSTOMERS FIND THE PERFECT TRACK TO TELL THEIR STORY.

WHO ARE WE LOOKING FOR?

A senior Data Engineer to join our technology team in London

THE ROLE

This role is responsible for the Data and Analytics platform across Audio Network, which collects and transforms data from a number of sources to drive key business decisions

SPECIAL SKILLS

- Senior Software Engineer who has written well tested and documented Python for multiple production ETL environments

- Experienced at using a range of AWS technologies such as EC2, Lambda, Redshift, Redshift Spectrum and S3

- Comfortable using a range of operating systems and cloud environments

- Experience at automating repetitive tasks using continuous integration and deployment

- Strong SQL Skills with one or more of Postgres/Redshift or MS SQL

- A degree in Computer Science, Statistics, Mathematics, Engineering or equivalent professional experience

ABOUT YOU

- Great interpersonal skills and superb communicator

- Proven analytical and problem-solving skills

- Able to communicate sophisticated technical matters to non-technical audience

- Motivated self-starter capable of seeing tasks through to delivery

- Attention to detail, priorities and management of multiple tasks

PREFERRED EXPERIENCE IN

- Data modelling/governance and their best practices

- Deployment pipelines, from source control through build, test and deploy

- ETL tools and associated processes

- Business intelligence and analytics tools such as Birst/Tableau/QlikView

- CRM tools such as Salesforce

- Serverless/Terraform

COMPENSATION PACKAGE

- Competitive salary

- Discretionary bonus

- Private Health

- Pension

BE YOUR ORIGINAL SELF

OUR COMMITMENT TO DIVERSITY AND INCLUSION

At Audio Network, and across eOne and Hasbro, we not only celebrate originality – it’s a key part of our business. We strongly believe that to create the best entertainment content for everyone, we need diverse teams, telling diverse stories. We’re committed to building these teams– and we know our work here is never done. We‘re always striving to ensure everyone feels empowered to bring their whole, unique selves to work each day. Each Audio Networker is unique – but they are all treated the same: with dignity, respect, compassion, and equality.

eOne is committed to equality of opportunity in all aspects of employment. We are committed to making all employment decisions without regard to race, color, religion, sex, sexual orientation, gender identity or expression, national origin, age, marital status, or any other legally protected status. If you are contacted for a job opportunity, please advise us of any accommodation needed to ensure you have access to a fair and equitable process.",3.6,"Audio Network
3.6","London, England",-1,51 to 200 Employees,2001,Company - Private,Music Production & Distribution,Media,$10 to $25 million (USD),-1
Big Data Engineer,-1,"The job in a nutshell
Are you interested in an opportunity to utilise cutting edge capability in Big Data technologies to further build the foundations upon which GoCo Group can advance further benefit to the business? Are you keen to be an instrumental force in creating big data platforms and pipelines to give multiple businesses within GoCo Group access to data via data lakes and Big Data cloud tech?
Data is at the heart of everything we do at GoCo and you will work with a well established data team inclusive of data science, web analytics, data warehousing and data intelligence. You will be a key point of contact for stakeholders across the business to understand data requirements, data structures, data frequency and ingest the data models into the data lake. You will be able to build appropriate schemes to allow data teams to automate reporting.
This role will involve you working on a blank canvass for a newly acquired GoCo Group business to integrate this into the wider group
Skills and experience you’ll need to have
Knowledge in big data cloud architectures with proven experience working with Microsoft Azure big data technologies e.g. data lakes, data factory etc.
Experience of several programming languages such as Python, Scala or Java.
Experience in data warehousing, within a data platform.
Strong background in data processing, software engineering design and data modelling concepts.
Good understanding of application life cycle management ideally using TFS or Visual Studio Online.
Strong communication skills to effectively partner with data scientists and engineering stakeholders.
Very good experience in gathering and analysing business requirements and translating them into solutions.
A track record of delivering solutions against challenging timescales with quality.
Ability to pick up new languages and technology quickly.
What you’ll be responsible for
Acts as subject matter expert for cloud data services, technically leading the company approach to big data solutions, designing and implementing cloud data services, as appropriate.
Leads on the migration, transformation, cleansing and ingesting of high volume data from the group into the Group Data Platform.
Creates reliable, distributed data pipelines and builds intuitive data products that allow our stakeholders to easily leverage data in a self-service manner.
Contributes to the group data platform roadmap, utilising the latest technologies, as required.
Designs and implements ETL strategies and solutions.
Works with data science team to ensure that data is appropriate for Machine Learning and Deep Learning work.
Designs, develops, configures, debugs/tests, implements, manages and documents BI solutions and processes.
Undertakes Data Transformation and tuning / optimisation of code and ensures all code is version controlled with work clearly documented and centrally located, enforcing coding standards & design styles across the team.
Provides technical oversight and coaching to the rest of the team for Cloud/Big data services including peer reviews of team members work as part of the release process.
Ensures the provision of a stable environment and continuity of service.
Identifies opportunities to automate tasks and deliver generic frameworks which can be leveraged by different technical teams.
Participates in the development of architectures, strategies, and policies around data governance; including master data management, metadata management, data quality and data profiling.
Who you’ll be working with
Works closely with the business to ensure clear understanding of data.
Works with business stakeholders to understand business needs and requirements and in keeping them informed of progress.
MyVoucherCodes team / AutoSave team
Data science team.
Wider tech team members.
About us
We’re on a mission to help people everywhere save time and money – whether that’s on essential outgoings or on the things that they enjoy.
If someone is looking for an insurance policy for the first time, wants to beat their renewal quote, is searching for the right financial product, or is after an outstanding utility deal, our comparison website – GoCompare – is there to help. We work with trusted insurance providers, financial services organisations and partners to provide a real breadth of coverage across the market.
Through MyVoucherCodes we bring savings from thousands of fashion, retail, restaurant, entertainment, travel and tech brands to millions of people.
Look After My Bills is a leading automated energy savings service. The free service cuts customers’ gas and electricity bills without them having to do a thing. Customers sign up once and Look After My Bills seeks to get them the best deal they can from an energy supplier they trust with good customer service. When that deal ends they automatically switch customers on to another.
Our Platform Services business partner with third party brands so that they can offer savings opportunities to their customers. godemand is a cloud based SaaS platform that will allow any market-vertical, be it broadband, energy, insurance, rewards and more, to be introduced by a third-party website or app on-demand.
Being your authentic self at work is vital to success
GoCompare embraces diversity and truly believe in equal opportunities for all. We believe that inclusion and diversity increases creativity, delivers innovation, improves performance and better serves our customers.
We truly believe in the ethos that companies with greater diversity perform better than those without. It is for these reasons that all qualified applicants will be considered for employment regardless of age, race, religion, genetic information, sexual orientation, gender identity, parental status, disability, educational background or any other characteristic for that matter that doesn’t relate to your ability to perform the role.
Benefits
GoCompare offer a competitive benefits package including:
Flexible working hours
Bonus
25 days holidays plus bank holidays
Birthday day off
Death in service
Matched pension (up to 6%)
Private medical cover
Buy and sell holiday options
Extra holidays for length of service
Share save scheme
Enhanced maternity and paternity policies
Go for it
Salary:
Up to £60,000 plus benefits (Flexible working, bonus etc.)
Location:
Newport / Remote
Job Reference:
gocompare/TP/41/356
Closing date:
9th November 2020
Contract type:
Full time
Go for it",4.1,"Gocompare
4.1","Newport, Newport, Wales",-1,51 to 200 Employees,2006,Company - Public,Internet,Information Technology,$25 to $50 million (USD),-1
Data Engineer,-1,"Job Description
Data Engineer

We are the biggest UK Homeware Retailer and the largest adopter of AWS Serverless in

Europe. We have recently transformed our digital platform using the latest technology to

build highly scalable, performant cloud-based data infrastructure, and we now have an

exciting opportunity for another Data Engineer to join our rapidly growing agile team.

You will be joining our Data Insight, Science and Engineering Team. Your primary focus will

be on building, expanding and optimising our data pipelines. You will develop high

performance data products to further enable our data driven approach. You will support the

improvement of our data self-service capability, building the technology to allow users to

access the data they need on demand.

You will be a part of a highly-skilled, self-organising team building forward-thinking solutions

and creating new capabilities to support multiple, cross-functional teams. We are

continuously looking to further improve our technology stack, data quality and reliability, and

your vision and ambition will contribute to shaping our solutions toward data-driven

decisions across the business.

You will be working to define AWS cloud based infrastructure as code using CI/CD

practices, developing high quality code in python, and designing data solutions that align

with business goals. The ideal candidate is self-directed, comfortable with challenging and

leading on best practice, and able to adapt to regularly shifting business requirements and

occasional ambiguity.

This is a fast-paced hands-on role, and would be well-suited to someone who loves coding,

clean design, clean architecture and using the latest tools and technology to tackle

constantly evolving business and tech challenges.

Responsibilities for Data Engineer

● Create and maintain optimal data pipeline architecture

● Assemble large, complex data sets that meet functional / non-functional business

requirements

● Identify, design, and implement internal process improvements: automating manual

processes, optimizing data delivery, re-designing infrastructure for greater scalability,

etc

● Build the infrastructure required for optimal extraction, transformation, and loading of

data from a wide variety of data sources using SQL and AWS ‘big data’ technologies

● Work with stakeholders, including Analytics and BI reporting teams, to assist with

data-related technical issues and delivery

● Work with data and analytics experts to strive for greater functionality in our data

systems

Experience required for Data Engineer

We are looking for a candidate with experience in a Data Engineer role, you should also have

hands-on experience in most of the following key areas:

● Object-oriented/object function scripting languages in Python

● Building and optimising ETL / ELT data pipelines

● Advanced working SQL knowledge and experience working with relational

databases, as well as familiarity with one or more cloud-based data warehouses

such as Snowflake, Redshift, BigQuery

● Experience using noSQL databases such as DocumentDB or MongoDB

● Working with AWS cloud services in production (Cloudformation, API Gateway, AWS

Lambda, Step Functions, SSM, SNS, SQS, Firehose, S3, EMR/Glue, SageMaker

etc)

● Working with raw data, structured, semi-structured and unstructured data

● Experience combining large disconnected datasets using relevant tools/frameworks

such as Spark

● Experience of source control, Continuous Integration, Delivery and Deployment

through CI Pipelines

● Supporting and working with BI and Analytics teams in a dynamic environment

● Able to collaborate and effectively pair program with other engineers

● Strong analytical skills and problem-solving skills

● Knowledge of Scrum, Kanban or other agile frameworks is beneficial, but not

Required

If the opportunity to be part of shaping and transforming Dunelm’s Digital presence excites you, please apply for our immediate attention!
Qualifications
Not Specified
Benefits
Not Specified",4.0,"Dunelm
4.0","London, England",-1,5001 to 10000 Employees,1979,Company - Public,Home Furniture & Housewares Stores,Retail,$500 million to $1 billion (USD),-1
Data Engineer,-1,"Critical project, of national importance.
Valid Security Clearance (SC) Essential.
Newcastle/ Remote working initially.

Data Engineer

6 month engagement with possible extensions

Job description:

As a Data Engineer, you are responsible for developing accurate, efficient data solutions which meet customer needs to agreed timescales.
You ensure the stability, robustness and resilience of the products you design and build, and are in a position to effect changes to those products where necessary.

As a Data Engineer you support continuous improvement of standards and provide leadership to develop Associate Data Engineers, providing technical guidance alongside other data engineering functions for customers.

Skills and Experience

Knowledge in the following software -

AIX Unix, Inges DB, SQL scripting and querying knowledge. Also MS Access and knowledge of VBA

Ideal extras would be Data Services, Business Objects, Qlik Sense and Informatica.

Able to identify simple patterns and trends. Investigates problems and opportunities in existing processes and contributes to recommending solutions to these. Works with stakeholders to identify objectives and potential benefits available.
Designs, develops. codes, tests, corrects and documents simple programs or scripts under the direction of others.
Understands core technical concepts related to their role and is able to apply them.
Understands the appropriate media to communicate findings. Shapes and shares communications cognisant of the audience. Able to give tactical recommendations.

If this is something you feel suited to and would like to apply, please send in your CV. Because of the expected volume of applications, we will endeavour to come back to you asap",4.0,"Talent International
4.0","Newcastle upon Tyne, England",-1,201 to 500 Employees,1995,Company - Private,Staffing & Outsourcing,Business Services,$500 million to $1 billion (USD),-1
Data Engineer,-1,"The big question: why on earth should a Tech professional like you work for a 150-year-old retail chain? Because we’re on a journey. Changing the way we operate. Learning to think nimble. Giving our teams the time and freedom they need to push boundaries. To create amazing systems and technologies. To give our colleagues and our customers even more incredible experiences.

There are thousands of experts to talk to and learn from. We’ve got data from billions of transactions for our teams to play with. Things get built here. They get made here. They hit customers and colleagues quickly. Welcome to the home of Sainsbury's Tech.

More about the role:

Build and design large scale real-time and batch data pipelines using technologies such as Apache Spark, Kafka, SQS and Airflow
Programming in one or more languages within our data eco-system e.g. Python
Implement cloud technologies such as GCP, Azure. AWS including S3, and EMR
Use best practices in continuous integration and delivery
Work collaboratively within a team of cross-functional engineers
Work with structured, semi-structure and unstructured data

What we’re looking for:

An engineer with a passion for delivering solutions to customers.
Someone who likes to roll up their sleeves and has hands on experience of the languages, tools and infrastructure
Knowledgeable about data modelling, access and storage
Self-driven and constantly striving to improve your team
Advocate of Agile/Lean delivery methodologies

In return you’ll get:

Colleague discount across the multi-brands – Sainsbury’s, Argos and Habitat
Holiday allowance
Bonus scheme
Pension plan
Special offers on gym memberships, restaurants, holidays, retail vouchers and more

Flexible working and job share conversations are encouraged. Across our multi-brands, we’re proud to be an equal opportunities employer that champions a diverse and inclusive culture. If you’re reading this, even if you’re not 100% sure you’re there with your experience, we’d still love to hear from you. If you’d like to find out more head to Sainsbury's Tech

#DTDJOBS",3.6,"Sainsburys
3.6","London, England",-1,10000+ Employees,1869,Company - Public,Grocery Stores & Supermarkets,Retail,$10+ billion (USD),-1
Data Engineer,-1,"Who We Are:

Take-Two Interactive Software, Inc. is a leading developer, publisher, and marketer of interactive entertainment for consumers around the globe. For more than 25 years, our development teams have created some of the most critically acclaimed and commercially successful entertainment experiences, captivating and engaging audiences around the world. We are incredibly proud of our ability to deliver consistently the highest-quality titles, as well as our colleagues who help to create our unique culture and work environment that is inclusive, diverse, and dynamic.

While our offices are casual and inviting, we are deeply committed to our core tenets of creativity, innovation and efficiency, and individual and team development opportunities. Our industry and business are continually evolving and fast-paced, providing numerous opportunities to learn and hone your skills. We work hard, but we also like to have fun, and believe that we provide a great place to come to work each day to pursue your passions.

The Challenge:

A dynamic Python Data Engineer to join a team building a cloud-based data and analytics platform. The Data Engineer will craft, build, and maintain reliable and scalable data pipelines.
Develop data quality framework to provide transparency into data quality across systems (timeliness, accuracy, completeness, etc.) and ensure delivery of high-quality data to business teams.
Provide thought leadership and collaborate with other team members to continue to scale our architecture to evolve for the needs of tomorrow.
Maintain API based ETL/ELT processes from multi source raw data collection to reporting/visualization.
Develop and support continuous integrations build and deployment processes using Jenkins, Docker, Git, etc.
Define and implement monitoring and alerting policies for data solutions.
What You Bring:
2+ years of hands-on experience in Python.
3+ years of hands-on experience in using sophisticated SQL queries and writing/optimizing highly efficient SQL queries.
Experience integrating with 3rd party APIs.
Comfortable working with business customers to collect requirements and gain a deep understanding of varied business domains.
Experienced in testing and monitoring data for anomalies and rectifying them.
Knowledge of software coding practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations.
Preferred Qualifications:
Python (required)
SQL (required)
Git (required)
Developing solutions using Docker (required)
Data modeling for data warehousing (nice to have)
Developing microservices (nice to have)


What We Offer You:
Great Company Culture. We pride ourselves as being one of the most creative and innovative places to work, creativity, innovation, efficiency, diversity and philanthropy are among the core tenets of our organization and are integral drivers of our continued success.
Growth: As a global entertainment company, we pride ourselves on creating environments where employees are encouraged to be themselves, inquisitive, collaborative and to grow within and around the company.
Work Hard, Play Hard. Our employees' bond, blow-off steam, and flex some creative muscles – through corporate boot camp classes, our onsite Gym, company parties, our Office bar, game release events, monthly socials, and team challenges.
Benefits. Benefits include, but are not limited to Private healthcare with Bupa, Private dental with Bupa, A double matching pension policy where the employer will double match up to a 4% contribution from the employee, Employee stock purchase scheme with a 15% discount, Eye tests and vouchers towards glasses, Cycle to work scheme, Flu vouchers, Annual health checks with Bupa, 4X death in service insurance, Income protection (60% salary), 25 days holiday, + other great perks and great office facilities!
Perks. Gym reimbursement up to £25 per month, an onsite Gym, an Office bar, employee discount programs, free games & events, stocked pantries, a dog friendly workplace and the ability to earn £350+ per year for taking care of yourself and more!


Take-Two Interactive Software, Inc. (""T2"") is proud to be an equal opportunity employer, which means we are committed to creating and celebrating diverse thoughts, cultures, and backgrounds throughout our organization. Employment at T2 is based on substantive ability, objective qualifications, and work ethic – not an individual's race, creed, color, religion, sex or gender, gender identity or expression, sexual orientation, national origin or ancestry, alienage or citizenship status, physical or mental disability, pregnancy, age, genetic information, veteran status, marital status, status as a victim of domestic violence or sex offenses, reproductive health decision, or any other characteristics protected by applicable law.",3.9,"Take-Two Interactive Software, Inc.
3.9","London, England",-1,1001 to 5000 Employees,1993,Company - Public,Video Games,Media,$1 to $2 billion (USD),-1
Data Engineer,-1,"Our product is all about collaboration and innovation. So are our people. We’re a small team, but we’ve got a big vision: to build a brand new infrastructure for operational risk management. It’s not easy. We’re redefining the way some of the world’s biggest financial services companies and banks work with data. There are a lot of challenges – but a lot of opportunities to think and act creatively, too.

We’re growing fast. We’ve just closed our Series A funding round, led by Notion Capital – one of the world’s leading VCs – and financial information specialists Fitch Ventures. Now we want to scale our world-class team.

We’re looking for people who are energetic and curious; people who are persistent and resilient; people who like tackling problems and take pride in building best-in-class solutions to them. Being a part of the Acin team means creating the operating system for a safer financial future from scratch. We think it’s a pretty exciting prospect.

If you think the same, this could be the role for you.

The Role

We're looking for an ambitious Data Engineering to join our growing Engineering team.

Our Engineering team is split into two main disciplines - data and front end. The data team is responsible for the management of our data assets and driving business benefit from them. Working alongside our front end team who work with these data assets to deliver value to customers in an attractive, informative fashion.

In terms of tech, we primarily use Microsoft Azure components. The future tech landscape is for the team to shape - we expect to explore NLP in the near future and we're open to use of all technology as long it demonstrates value.

Our technology stack uses primarily Microsoft Azure components, but we are open to use of all technology as long it demonstrates value.

In this role, you will be responsible for:
Data Design and Modelling – defining the Acin logical and physical data structures
Data Work Flow - data development, data structuring, version management (data best practice, sql, graphing techniques)
Data Ingestion - analysis and development (python, sql, web scraping)
NLP/Matching - engine development (python)
Data insights – identification and development of new data insights (data mining and visualisation, power bi, r, python)
API - business logic development (c#, open api)
Requirements
What we are doing at Acin excites you!
You’re energised about data problems and using technology to solve them
You enjoy working with other developers and designers, leading them to great outcomes
You can demonstrate a good working knowledge of data technologies (Azure is a bonus!)
You have: strong data design and development skills; SQL, Python experience; experience with DevOps development environments
Have a passion for data centric systems or data
You have worked in an agile minded development team
You’re highly organised and have great prioritisation skills
You’ve got patience, tact, diplomacy and approachability with the ability to develop effective working relationships with employees at all levels
You possess an intellectual curiosity and bring valuable insight into the team
Benefits
25 days holiday
Medical Insurance including Dental & Optical cover
Life Insurance
Perkbox Subscription
Pension Scheme",-1,Acin,"Farnborough, Hampshire, South East England, England",-1,1 to 50 Employees,-1,College / University,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"BGL Group are looking for an experienced Data Engineer to join our Data Solutions team. Working in an Agile environment you’ll be responsible for engineering first class technical solutions as required to support the IDO strategic agenda. You’ll contribute to the evolving culture of innovation and continuous improvement and be the voice of the customer. You'll also have a strong focus on delivering the best customer experience.

Within our digitally focussed FinTech organisation,your role will involve delivering robust solutions that meet the functional and technical requirements of the customer. You’ll show strict adherence to technical and quality standards within agreed timeframes and champion the need for a ""quality first"" approach. As an active learner you’ll be responsible for keeping up to date with developments in your technical and professional area of expertise. Your role is imperative to ensure we always have suitable performance and capacity for our key business systems.

What will it take to be successful as a Database Engineer?

Knowledge and experience of:

- SQL Server 2017/19 and writing T-SQL

- ETL/SSIS principles

- Relational database design principles

- Excellent written and oral communication skills

- Intermediate industry experience of Data Warehousing

- Experience in effectively coaching other team members

- Be a keen advocate of modern data engineering design and practice

About Us

Founded in 1992, the BGL Group has grown significantly in size and capability. From 30 to 3,000 people, we are a leading digital distributor of insurance and household financial services. We have reached 10 million customers through brands including comparethemarket.com, LesFurets.com, BGL Life, Budget Insurance & Dial Direct, as well as our partnerships business which provides insurance for some of the UK’s leading high street brands. We make a difference for our customers, colleagues and communities by working, growing and winning together. We enjoy what we do and have fun doing it!

Diversity and Inclusion

We're a diverse community of dedicated, innovative and talented professionals. With an inclusive and open workplace, we encourage our people to create and share ideas – supporting their growth and celebrating their uniqueness. We're proud to be an equal opportunity employer and stand firmly against discrimination of any kind.

Flexible working

We understand the importance of achieving a healthy lifestyle balance, whether it’s working remotely or flexibly we have an environment where people are empowered to embrace flexible working in a way that works for them and for the business.

Apply Now!",3.7,"BGL Group
3.7","Peterborough, England",-1,1001 to 5000 Employees,1992,Company - Private,Insurance Carriers,Insurance,$500 million to $1 billion (USD),-1
Data Engineer,-1,"Job Number: R0084562

Data Engineer

The Challenge:

Do you find yourself constantly looking for more and better information? Do you want a job where you can use your knowledge and research skills to improve national security? More connected devices, larger storage capacity, and faster connections have resulted in an explosion of available information. The problem facing the intelligence community (IC) is no longer how to get more data – it's understanding how to turn massive amounts of data into answers. That's where you come in. With critical thinking and flexibility, you quickly seek out the accurate data sources, sift through the raw open-source data, and turn it into valuable intelligence. If you have strong analytical skills and a problem-solving mindset, we have an opportunity to use those skills to support our warfighters, protect our national security, and inform our nation's leaders.

As a Data Engineer on our team, you'll explore new data sources, including publicly available information (PAI), to create effective queries, and combine information from disparate sources to support clients and operational partners. You'll apply expertise in operations, intelligence, qualitative and quantitative analyses, and collections to enhance the client's mission. You'll find and work with available web and social media content, construct new OSINT and PAI tradecraft documents and workflows, and analyze the development of OSINT and PAI tradecraft, including integration across multiple intelligence disciplines and systems. You'll leverage knowledge of Python or R, customize tools for select acquisition of bulk PAI data, and use internet technologies and observables, including process automation.

Empower change with us.

You Have:

-5+ years experience as a Data or Software Engineer

-Experience with Python and R

-Experience in working with Big Data platforms, including Hadoop, AWS, Azure, or DataBricks

-Experience with data evaluation, and analytical tools and databases

-Ability to conduct independent analysis to support mission requirements and use enhanced search procedures and tools to support the usage of PAI

-TS/SCI clearance

-BA or BS degree

Nice If You Have:

-Experience with PAI analytic principals, including database administration, the web, geo-enabled PAI, and the Berber Hunter Tool Kit tools

-Experience with all-source intelligence processes

-Knowledge of national and service-specific OSINT policy and regulations, internet-based research, including Boolean logic, search engine, database resources, and internet sources, including social media, social networking tools, data exploitation, and commercial- and industry-based databases

-Experience with OSINT analysis, including authoring intelligence products and risk assessments

-Experience with advanced search techniques, information databases, data visualization, and related tools

-Knowledge of other intelligence disciplines, including signals intelligence (SIGINT), human intelligence (HUMINT), and geospatial intelligence (GEOINT)

-Ability to manage research and coordination for long-term projects

-MA or MS degree in International Affairs, Political Science, Foreign Area Studies, National Security Studies, Linguistics, Business, Library Science, or a related research field a plus

-Completion of OS301 Basic Open Source Intelligence Course

-Completion of OS302 Intermediate OSINT Tools and Tradecraft Course

-Completion of OS303 Advanced OSINT Tradecraft Course

Clearance:

Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS/SCI clearance is required.

Build Your Career:

At Booz Allen, we know the power of analytics and intelligence. When you join Booz Allen, we'll help you develop the career you want.

Challenging projects – Whether training analysts on military equipment through VR technology; developing a simulation capability to allow teams to rehearse missions together; or integrating RFID tags into mobile devices to enable data access within a geo parameter, you'll get to solve some of the world's toughest problems

Meaningful work – Use your skills to empower change. Your work will keep citizens and warfighters safe and well both at home and abroad

State-of-the-art technology – Broaden your intelligence capabilities with digital forensics, telematics, precision navigation, secure mobile operations, and advanced analytics

New skills – In-house experts and partnerships with tech leaders, like Nvidia and Splunk, mean you can get practical experience with advanced GPU technologies, cyber security, and data science

Room to grow – You'll be inspired to grow your career while making your ideas a reality thanks to new opportunities across the US and abroad, encouraging mentors, and collaborative colleagues

We’re an EOE that empowers our people—no matter their race, color, religion, sex, gender identity, sexual orientation, national origin, disability, veteran status, or other protected characteristic—to fearlessly drive change.

#LI-AH1",4.0,"Booz Allen Hamilton Inc.
4.0","Huntingdon, England",-1,10000+ Employees,1914,Company - Public,Consulting,Business Services,$5 to $10 billion (USD),-1
Software Engineer (Ruby),-1,"About Us

We want to help small businesses win. That’s why we’re here.

We connect small business owners to investors – to create jobs, help families and power economies – because we believe that people are made to do more. And we want to help them.

So, we created the leading online marketplace for small business loans. Our investors have lent £8.1 billion in 110,000 loans to 77,000 small business owners. In a single year, we unlocked 115,000 jobs and contributed £6.5 billion to the global economy. There’s never been a better time to join!

Be part of the team that changes everything. Let’s build the place where small businesses can get the funding they need to win and leave a legacy behind, forever.

This role sits within the “Tech” team. The drivers behind our platform – brilliant people working together to create, code, and build the next game changers.

About the team

The driving force behind the world’s leading platform for small business lending is our engineering team. We are a diverse group from more than 25 different countries and cultures who bring together a wide range of backgrounds and experience (from music to aerospace engineering).

We are focused entirely on using technology to provide the best experience for our borrowers and investors. We are doing this by building elegant, sustainable, and scalable solutions that can be applied globally. We work in small agile teams practicing continuous integration, TDD and are no strangers to pairing as we believe that working together is smarter than sitting in silos.

About the role

Day to Day, this role will include:

Collaborating as part of an agile cross functional team, as well as technology chapters
Building great user experiences for customers
Delivering innovation through software to automate processes that enable Funding Circle to operate at scale
Using Clojure, Kafka, React and Ruby currently and built entirely on AWS
Supporting our production systems
About You

This roles requires someone who has:

Production experience in Clojure
Fundamental programming skills (data structures, algorithms)
Familiarity developing on Unix/Linux
Good communication skills, both written and spoken
Knowledge of Agile, Scrum, BDD, TDD and CI/CD
An interest or experience in any of Functional Programming, Distributed Systems or Event-Driven Architectures

Why join us?

We’re gearing up for our biggest chapter yet – and it’s being driven by everyone.

We think of ourselves as the career launchpad. A place to develop yourself, fast. Real work. Real experience. Real opportunities to collect skills. Think big remits and huge ownership to make great things happen.

Yes, it’s target-driven and high-octane – but we like to play hard too. That’s what makes us, us. Our vibrant culture is built around potential and creating a place where you can really be you. We keep it agile and open. All voices heard. Because we believe great ideas come from everywhere.

If you show skill and are willing, we’ll back you all the way. This is the place for you to build something incredible.

It’s in our differences that we find our strengths.

We celebrate and support the differences that make you, you. So we’re building a culture where difference is valued. We’re proud to be an equal opportunity workplace and affirmative action employer. We truly believe diversity makes us better. We particularly encourage applications from applicants from underrepresented backgrounds. We welcome applicants who may want to work flexibly.

Want to Build The Incredible? We’d love to hear from you.",3.8,"Funding Circle UK
3.8","London, England",-1,501 to 1000 Employees,2010,Company - Private,Lending,Finance,$50 to $100 million (USD),-1
Data Engineer,-1,"Founded in 2016 with only a handful of individuals, Quantexa was founded on the vision that through a greater understanding of context, better decisions can be made. 3 years, 6 locations and 260+ employees later we still believe that today. Working within industries such as Finance, Insurance, Energy and Government, we connect the dots within our Customers data using dynamic entity resolution and advanced network analytics to create context, empowering businesses to see the bigger picture and drive real value from their data.

Our success is driven by the talent of our staff and our commitment to quality. We are looking for Data Engineering Accelerator with a proven track record in big data projects to join the Quantexa family.

What does a Data Engineering Accelerators role at Quantexa look like?

You’ll be joining a team of technical experts who will develop, test and document a variety of data engineering tools and best practice materials that will be used across Quantexa software deployments globally.

The team is continuously working on new and innovative ways to help improve our data engineering function, building methodologies and tooling to improve both the quality and efficiency of project delivery. As part of the role, you will help define big data best practice across the business, with the end goal of helping our Tier 1 clients solve business problems in the areas of lead generation, customer insight, fraud and financial crime.

Stakeholder engagement is an essential part of this role and you’ll be working with our delivery teams, clients and partners to provide them with high quality solutions, deploying to both cloud and on-premise environments. You will be given the autonomy to see your tasks through the entire development life cycle, from requirements gathering all the way to software release, taking ownership of building new functionality that the entire business will be using.

Things you may work on include:
Big data processing/ETL pipelines
Cleansing, parsing and standardising global datasets
Data classification
Entity extraction/resolution
Pre-packaged code for processing and utilising third party data sources
Efficiency/performance improvements through big data testing
Requirements

What do I need to have?
We’re looking for individuals who have proven big data experience, either from a software deployment/implementation or a data science perspective
Expert knowledge of at least one big data technology such as Spark, Hadoop or Elasticsearch
A strong coding background in either Java, Python or Scala
The desire to learn and code in Spark/Scala
Experience working in an Agile environment
Experience of building data processing pipelines for use in production batch systems, including either traditional ETL pipelines and/or analytics pipelines
Experience in manipulating data through cleansing, parsing, standardising etc, especially in relation to improving data quality/integrity
Passion and drive to grow within one of the UK’s fastest growing scale-ups
Benefits

Why join Quantexa?

We know that just having an excellent glass door rating isn’t enough so brand-new WeWork office and put together a competitive package as a way of saying thank you for all your hard work and dedication.

We offer:
Competitive Salary
Company Bonus
Private Healthcare, Life Insurance, and Income Protection
Cyclescheme and Techscheme
Pension Scheme with a company contribution of 6% (if you contribute 3%)
25 days annual leave (with the option to buy/sell up to 5 days) + birthday off!
Amazing work environment",4.6,"Quantexa
4.6","London, England",-1,201 to 500 Employees,2016,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Data Engineer - Permanent - Glasgow - Remote Start

Our brilliant large-scale global client is looking to recruit a Data Engineer on a permanent basis. This is a fantastic opportunity to grow your career with a highly regarded and well-established organisation.

The ideal candidate will have the following experience:
Datamodelling and Data Warehousing
Experience and familiarisation with multiple RDBMS platforms, ETL Tools, data migration approaches, and data framework design patterns.
Designing and implementing information solutions
Working on Business Intelligence and analytical projects
Experience with AWS or Azure
Demonstrable experience with ETL and/or cloud integration service capabilities.
Knowledge of programming and Scripting languages
If you think you could be a good match then apply today or email me directly on

...",4.1,"Hydrogen Group
4.1",North Lanarkshire,-1,201 to 500 Employees,1997,Company - Public,Staffing & Outsourcing,Business Services,$100 to $500 million (USD),-1
Data Engineer,-1,"Data engineer

We’re looking for a smart, self-motivated Data Engineer to join our team. This role will be responsible for data collection, extraction, maintaining pipelines and actively researching and verifying new data sources.

About you:

You care about getting the best possible outcome, you have a passion for what you do which you can clearly convey by your actions.
You have an eye for detail and order, being able to spot problems in code or data which others might miss or take longer to find.
You have a desire to explore and test concepts, ideas and theories.
You have a strong sense of responsibility, and the ability to breakdown, estimate and manage your workflow with stakeholders.
You have a keen interest in cloud computing (we work with AWS) and have some knowledge on cloud and data security, networking and running complex data pipelines in the cloud.

About Us:

We’re small (20+ people and growing fast), innovative and varied group, solving big problems in real estate data and analytics. We are seeking enthusiastic, creative, intelligent and fun individuals to join us in helping build the best platform on the market. In return we can offer you a fun and hard-working environment where you can clearly see your contribution to the company’s success.

What you’ll be doing:

The hire will be working with our team who are responsible for optimising data flow and collection, researching and investigating new data sources, and expanding and maintaining our existing data pipelines. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys working in a fast paced and interesting environment. The Data Engineer will support our software developers and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple product verticals. The right candidate will be excited by the prospect of supporting our next generation of products and data initiatives.

Research and assemble large, complex data sets that meet functional / non-functional business requirements.
Work with stakeholders in the wider Product and Sales teams to assist with data-related technical questions and support their data infrastructure needs.
Continually improve the infrastructure required for optimal collection, extraction and initial transformation of data from a wide variety of data sources using AWS big data processing technologies such as Glue.
Work with existing data and analytics experts to strive for greater functionality in our data systems.

Our Stack

The current data collection and extraction processes are written in Go and Python, and our processing and pipelines are written in PSQL, Spark (Python and Scala) using AWS Glue to orchestrate. We work mostly with batch data rather than streams.

Excellent SQL skills are required, and knowledge of window functions, optimising queries, geospatial queries, GIS, and general data wrangling are a must.

We are open to people from a diverse range of backgrounds and would have a preference for people with an understanding of most of the following:

Python/Go for data collection
Postgres and PostGIS
AWS Glue/S3/RDS/EC2
Spark/Scala is nice to have but not required initially

We are looking for someone with proven experience of data collection and data pipelines, and who is comfortable working with stakeholders and directly with the CTO and Product Owner. We are a relatively small team, so you must be comfortable with conversing across all aspects of development and reacting quickly to new information.",4.9,"REalyse
4.9",Remote,-1,1 to 50 Employees,2016,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Data Engineer
Overview


EF is the world leader in international education. Our mission is to break down barriers in language, culture, and geography and so far, we have helped over 15 million people learn a language, discover the world or earn an academic degree. We have 500 schools and offices in over 50 countries and employs over 52,000 staff and teachers. In today’s increasingly complex and interdependent world our mission is more relevant than ever.

The Role


This role is a crucial part of our EdTech Data Science team. We’re a lean and agile team of Data Engineers and Data Scientist focused on building modern cloud-based infrastructure to enable ML for Education. You will be contributing to our event-based streaming data platform that enables real time insights for teachers and students in the classroom or when studying remotely online. You will also help us build a world-class cloud data warehouse for our Data Scientists, Analysts and BI specialists.

Our current EdTech stack is based on AWS and includes Kubernetes, Kafka, Kinesis, Flink, Snowflake but you will also work with the wider business to develop ETL processes to move data from multiple data sources into our data lake/ warehouse.

Main Responsibilities
Create and contribute to a data platform that enables self-service analytics and creates the foundation for data science applications across our businesses
Build batch and streaming pipelines for the purpose of analysis & data science
Design, implement and maintain the data warehouse
Support and maintain existing production services
We ask that you have
AWS, GCP or Azure cloud expertise
Experience with cloud-based data warehousing (Snowflake, Redshift or similar)
Experience with Agile methodologies and practices
Experience using distributed version control systems (e.g. git, mercurial)
Experience in developing data processing applications in Java/Scala/Python
Experience working with streaming data sources (e.g. Kinesis Streams or Apache Kafka)
Experience with Kubernetes, Helm charts and Docker
Experience with real-time processing engines (e.g. Apache Flink, Apache Beam, Apache Storm)
Excellent verbal and written skills in order to effectively communicate with partner teams
Other useful skills include
Ability to write efficient SQL statements
Understand data warehouse design and ETL performance techniques
Experience with 3NF, Data Vault & Dimensional modelling
Experience with Master Data Management
Experience with Data Governance",-1,EF EdTech,"London, England",-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Come build the future of entertainment with us.
Are you interested in shaping the future of movies and television? Do you want to define the next generation of how and what Amazon customers are watching?
Prime Video is a premium streaming service that offers customers a vast collection of TV shows and movies - all with the ease of finding what they love to watch in one place. We offer customers thousands of popular movies and TV shows from Originals and Exclusive content to exciting live sports events. We also offer our members the opportunity to subscribe to add-on channels which they can cancel at anytime and to rent or buy new release movies and TV box sets on the Prime Video Store. Prime Video is a fast-paced, growth business - available in over 240 countries and territories worldwide. The team works in a dynamic environment where innovating on behalf of our customers is at the heart of everything we do. If this sounds exciting to you, please read on.

The marketing team for Amazon Prime Video in the UK, have the responsibility for driving the customer growth and engagement with this service through a very broad combination of marketing channels across EU.

As a Data Engineer in this team, you will work with a team of Data Scientist, Data Engineers and BI Analysts to build our data layer to innovate the way we do Marketing for Prime Video and understand our customers. You will work closely with the business and technical teams on many non-standard and unique business problems requiring a creative approach to problem solving.

Analytical and modeling skills will be required to work across several Amazons Business teams. The work may include working with Marketing, Business Development, Data/BI Engineers, Software Developers, Finance, and Accounting teams. The role requires interpersonal and communication skills, a keen attention to detail, ability to be hands-on as well as work with minimal direction.

The successful candidate will be able to thrive in an environment demanding data-driven decision support and business intelligence that is timely, accurate and actionable. Obsessed with solving complex problems and passionate about the potential of analytics to drive a business forward; the successful candidate will relish the prospect of driving forward Prime Video's Analytics to the next level. Mindful of dependencies, able to make sensible trade-offs, and able to be hands-on a passion for code and design, your end product is usable datasets with business value!


Basic Qualifications

· Bachelor's Degree in Computer Science or a related technical discipline.
· Experience writing high quality, maintainable SQL on large datasets.
· Ability to write code in Python, Ruby, Scala or other platform-related Big data technology.
· Exposure/Experience in big data Technologies (hadoop, spark, presto, etc.).
· Expertise in the design, creation and management of large datasets/data models.
· Experience working on building /optimizing logical data model and data pipelines while delivering high data quality solutions that are testable and adhere to SLAs.
· Experience in using various data design patterns and knows when/when not to use one.
· Excellent verbal and written communication skills.
· Ability to work with business owners to define key business requirements and convert to technical specifications.

Preferred Qualifications

· Ability to work with cross-functional teams
· Experience with Amazon Redshift
· Experience with cloud-based architecture and deployment
· Experience with AWS technologies
· Proven track record of strong verbal/written communication & data presentation skills, including an ability to effectively communicate with both business and technical teams.
·

Amazon is an equal opportunities employer. We believe passionately that employing a diverse workforce is central to our success. We make recruiting decisions based on objective criteria including your experience and skills. We value your passion to discover, invent, simplify and build. We welcome applications from all sections of society irrespective of belief colour, race, religion or belief, nationality, ethnic or national origin, gender, gender reassignment, sexual orientation, sex, marital status, disability, age or trade union membership. Please let us know if you have any special requirements in relation to this recruitment process.

All offers are conditional on references, verification of the right to work in the UK, and successful background screening check. This will include previous employment verification, qualification verification (if relevant) and a basic criminal check. Further details of this policy/procedure will be sent to you along with your conditional offer.",3.9,"Amazon
3.9","London, England",-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer,-1,"Data Engineer – Remote – 6 months - Outside IR35
Data Engineer on an initial six month contract. This role will be carried out on a fully remote basis.
Essential Requirements:

Delphi 6
ETL
C#
If this sounds like an appealing opportunity to you then get in touch with me ASAP. Naturally there could be scope for extension, due to the nature of the work.",3.2,"Opus Recruitment Solutions
3.2","London, England",-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Data Engineer
APPLY NOW
Data Engineer / Hadoop, Scala, Spark, Python / up to £51k, excellent work life balance, training opportunities and remote working
Are you a Data Engineer who would like to be involved in a company-wide data transformation with a globally recognised brand? Would you like to have a real say in the technical direction and ultimately provide real business benefit?
Corecom Consulting has partnered with a prestigious company based in the heart of Manchester who are rapidly growing their business offering from a data perspective. This is a fantastic time to join an ever-growing business that offer real career development opportunities, both from a career progression and technical perspective.
Their long term vision is to move everything from their data warehouse in to their newly built data lake so they can move from pure reporting to creating more interactive visualisations, whilst looking at patterns in data which will lead to predictive analytics which will allow a complete 360 view of their customers.
Their state-of-the-art offices are in the Greater Manchester Area and boast a friendly, but ambitious technology-driven environment. However, they are working from home at the moment, and have the confirmation that this can be done permanently moving forward (if required).
What can you look forward to?
Remote working
Excellent internal and external training opportunities
Progression opportunities
A chance to work on a “UK sector first” data solution
Generous holiday allowance
Strong pension
Childcare vouchers
What we need from you
Hadoop
SQL
Talend
What would be great to have
Python / R / Scala / Java
Data modelling experience
You will form part of their existing Data Analytics team as you build and maintain their Hadoop solution. The aim is to provide their customers with ownership of their journey as well as employees with the MI needed to implement business decisions. The exciting part of this role is that you will be involved in a “UK sector first” data solution which will not only offer you the scope to develop personally but will add to your current career.
I have interview slots for this role in the next couple of weeks so please apply as soon as possible to avoid disappointment!
Data Engineer / Hadoop, Scala, Spark, Python / up to £51k, excellent work life balance, training opportunities and remote working
Job Reference: 5841
Salary: Up to £51000 per annum
Salary per: Annum
Job Duration: Perm
Job Start Date: ASAP
Job Type: Permanent
Job Location: Manchester, Greater Manchester
Job Regions: North West
Job Industry: IT
Job Skill: data engineer, scala, hadoop, talend, Python, Java
Job Specialism: Business Intelligence and Data Warehousing",5.0,"Corecom Consulting
5.0","Manchester, England",-1,1 to 50 Employees,2008,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Are you the kind of person that loves the idea of grabbing a project and running with it? Do you thrive of solving complex problems and delivering the best solutions possible?

We are working with a brand-new team that are launching a digital side of the business and they have some extremely talented Data Scientist that need an equally talented Data Engineer to help them succeed.
If you want to push the boundaries of technology and innovate and have the freedom to do so then please reach out.

Technical requirements;
ETL
Python
Puppet/ Git
PostgreSQL or relevant Database
So if this sounds like you please reach out to Todd Mills - 01223 237888 -",3.0,"The One Group
3.0","Cambridge, East of England, England",-1,1001 to 5000 Employees,-1,Company - Public,Casual Restaurants,"Restaurants, Bars & Food Services",Unknown / Non-Applicable,-1
Data Engineer,-1,"Want to do the best work of your life? With 24 million customers in 7 countries, make your mark at Europe’s leading media and entertainment brand. A workplace where you can proudly be yourself; our people make Sky a truly exciting and inclusive place to work.

Making bold decisions is a big part of our history – and with talented people like you on board, we’re confident it’s going to be a big part of our future. NOW TV is our exciting internet TV that’s revolutionising the sector with a bold approach, fresh ideas and the latest technologies. We’re transforming the way our customers view content by making Sky Movies, Entertainment and Sports available across a range of devices.

“This role contributes to a small team responsible for the delivery of robust Data Intelligence operations, creation of data marts, DevOps/change management, service management, scheduling and orchestration based on standard Google Cloud Platform tools and techniques” - Tom Dalglish, Head of Data Governance and Enablement

What you’ll do:

As a Data Engineer, you will help drive NOW TV’s Data Enablement across all products including maintenance of data marts, batch scheduling and operational support, event detection, alerts, escalation and capture of production metrics. You will be working side-by-side with the lead engineer in the design and construction of scalable data management systems.

- Work within a small team of 2 to 3 engineers to deliver the overall Data Enablement strategy.
Write code in Python and GCP tech-stack for manage our operational services
Have strong knowledge of the data sets required to run a Data Intelligence business. Deliver plans with NOW TV teams on operational capabilities, new dashboards, data distribution, Adobe product interfaces and general programming and scripting
Build real-time APIs for system integration, batch operations (Airflow, Control-M.) with in-house development teams and third-party suppliers, ensuring that developed solutions meet business requirements
API programming (REST), Python, SQL script, Unix, MS Teams. Mobile alerts and escalation management. Database table design, querying and troubleshooting
Integrate modern data management and software engineering technologies into existing data structures. Develop processes for data mining, data modelling, and data production. Create custom software components and operations
Design and build systems for Issue Detection, Notification Escalation, Triage, Resolution, Troubleshooting and Prevention

What you’ll bring:

- Ability to interpret the business needs into data requirements
Broad Experience in Google Cloud
Experience in an OTT and VOD environments Experience gathering/defining business metrics
Technical grounding across digital systems architecture, design and development and working knowledge of agile software development methodologies
Integrity: Willingness to speak up on difficult issues with own opinions, at the same time be humble and be able to ask for help
Strong interpersonal skills and leadership qualities with proven record in fast paced and quick changing environment

The rewards:

There's a reason people can't stop talking about #LifeAtSky. Our great range of rewards really are something special, here are just a few:

- Access to free NOWTV, for streaming all your favourite shows
A generous pension package
Private healthcare
Discounted mobile and broadband

Where you’ll work:

Osterley

Our Osterley campus is a 10-minute walk from Syon Lane train station. Or you can hop on one of our free shuttle buses that run to and from Osterley, Chiswick Park, Gunnersbury, Acton Town and Ealing Broadway tube stations. There’s also plenty of parking, bike shelters and showers.

On campus you’ll find six subsidised restaurants and a Waitrose. You can keep in shape at our subsidised gym, catch the latest shows and movies at our cinema, get your car washed and even get pampered at our beauty salon.

Inclusion:

Recognised as an ‘Inclusive Top 50 Employer’ and a ‘Times Top 50 Employer for Women’, we’re working hard to ensure we’re a truly inclusive place to work. This means we don’t just look at your CV. We’re more focused on who you are and the potential you’ll bring to Sky. We also know that everyone has a life outside work, so we’re happy to discuss flexible working.

And we’ll do everything we can to support you during your application. If you need us to make any adjustments to our recruitment process, speak to our recruitment team who will be happy to support you.

Why wait?

Apply now to build an amazing career and be part of a brilliant team. We can’t wait to hear from you.

To find out more about working with us, search #LifeAtSky on social media. A job you love to talk about.

Just so you know: if your application is successful, we’ll ask you to complete a criminal record check. And depending on the role you have applied for and the nature of any convictions you may have, we might have to withdraw the offer.",3.8,"Sky
3.8","London, England",-1,10000+ Employees,1989,Company - Public,TV Broadcast & Cable Networks,Media,$5 to $10 billion (USD),-1
Data Engineer,-1,"Permanent Data Engineer opportunity within the professional services industry.

Responsibilities:

Design, build, implement and maintain Data Migration processes;
Design, build, implement and maintain Data Integration and ETL/ELT pipelines;
Design, build, implement and maintain databases (Snowflake, Dynamics, PostgreSQL, MySQL/MariaDB, Oracle, Sybase);
Design, build and maintain solutions incorporating the company’s Data Lake;
Provide Business Level through to Technical Level analytical expertise for data-related aspects of IT projects;
Design, build, implement and support programs and applications for database management, data management and user interaction with various data sources;
Design and document the architectural components needed to transform raw transactional data in to a consistent and coherent dataset suitable for BI use. Ensure guidelines exist for integration, cleansing and data modelling including data warehouse structures (aggregation, federation, virtualisation);
Understand the data components needed to meet business requirements including currency, quality, granularity, velocity and structure.

Skills/Knowledge Required:-

Extensive experience designing, building and maintaining Data Migration and Integration solutions using a recognised Business Integration tool, including the use of a programming language within a tool;
Experience designing, building and maintaining databases, including procedural programming and SQL scripting on a major RDBMS;
Experience working with one of the major cloud platforms (Amazon AWS / Microsoft Azure / Google Cloud);
Experience working with event-based and streaming technologies such as Apache Kafka;
Experience working within the Scrum agile framework.

Skills/Knowledge Desired:-

Experience with Sybase ASA on Windows including replication, procedural programming and general SQL scripting;
Experience in AWS data pipeline services;
Experience with Microsoft SQL Server 5 or above;
Experience in Oracle 11g on Windows and Unix/Linux;
Experience designing and building Data Lakes;
Experience of working with NoSQL databases, e.g. MongoDB;
AWS Certified Developer (Associate) and/or AWS Certified Solutions Architect (Associate) certifications;
Certified Data Vault 2.0 Practitioner (CDVP2TM)

Qualifications

University degree or Technical diploma, preferably in an Information Technology / Information Systems subject.

Permanent Data Engineer opportunity within the professional services industry.",4.2,"Robert Walters
4.2","London, England",-1,1001 to 5000 Employees,1985,Company - Public,Staffing & Outsourcing,Business Services,$1 to $2 billion (USD),-1
Data Engineer,-1,"Let’s make passion pay

We started from one belief: that businesses deserved better. That people pouring their hearts into their passion should be paid reliably, efficiently and affordably. After all, passion, not money makes the world go round. So we decided to shake up the payments industry for good.

From humble beginnings, we’ve become one of Europe’s fastest-growing FinTech companies, winning numerous awards (including the Tech Track 100, National Business Awards and the Europe-wide Inc 5000). We pride ourselves on using smart technology and an unswerving dedication to service, leaving customers free to grow their companies. After all, doing so is hard work - taking payments shouldn’t be.

To continue innovating and leading the payments industry, we need exceptional individuals. Our success is due to our talented teams going above and beyond to make payments painless, security simple and compliance easy for our customers. Our core values of Brave, Defiant, Supportive and Honest underpin everything we do. As employees you are given the freedom to work autonomously, challenge the norm, bring new ideas and take ownership. Sound good? Then keep reading...

The Role

We have a need for an experienced data engineer to join our data team and play a key role in the formation of a new problem-focussed, multi-disciplinary “squad”.

What you’ll do...
You’ll bring your expertise in data engineering to design and build robust data pipelines and solutions that support important business processes, primarily in our finance team. Often the sources and outputs of the data are atypical so you’ll need to be resourceful and creative to find a solution.
Comprising of BI and business specialists, you’ll play a leading role in the squad, providing engineering guidance and leadership on how problems can be solved efficiently and communicating proactively on progress and best practice.
You’ll work closely with our main Data Engineering team to ensure solutions developed sit comfortably within the organisational preferences on technology and methodology.
You’ll support the wider BI team on best practice, especially in Python, git, TDD and CI/CD.
What you'll bring...
You have extensive experience developing ELT pipelines, data warehousing, data modelling and automating processes.
You are motivated by making a commercial impact through your work. You’re pragmatic and know when to use which technology.
You have got demonstrable experience in leading and developing solutions that support analysis and business processes in commercial environments. You know how to shape requirements, work productively, communicate with your stakeholders and organise resources.
You can communicate effectively within a team and with non-technical stakeholders to understand requirements.
You have got a keen eye for detail and are renowned for having high standards in your work.
Ideally you will also have experience with...
MPPs, especially BigQuery.
MSSQL, SSIS and SSAS
A scripting language such as Python and orchestrating processes with Airflow.
Dbt for transformation.
Cloud services and infrastructure, especially GCP.
Implementing and following best practices in CICD and Git in a data environment.
Some knowledge of. BI dashboarding and self-service tools, especially PowerBI and Looker would be useful.
You’re comfortable working in an agile environment.
What you will get…

We have a lively social scene including Film nights, Book Club, Cheese Club, Sports and Fitness Clubs, seasonal parties and a welcoming culture to make you feel right at home when you’re at work.

We also have 25 days annual holiday (which increases over time), discounted private healthcare, travel loans, a cycle to work scheme, subsidised gym membership, free fruit and drinks and exclusive discounts at many High Street stores.

So if you want to help make passion pay, get in touch",3.8,"PaymentSense
3.8","London, England",-1,201 to 500 Employees,2009,Company - Private,Financial Transaction Processing,Finance,$500 million to $1 billion (USD),-1
Data Engineer,-1,"Data Engineer - London


London

Apply now

Refer someone

As a Data Engineer in the Data and Analytics team, you will be working on a global initiative to take our data platforms and practice to the next level.

Using the latest technologies and techniques, you will be developing analytic reporting solutions as part of an agile team for our trading businesses. The platform is one year old and this is an opportunity to contribute to the evolution of the platform.

We are looking for an experienced data engineer. Experience in Spark and building data pipelines is a must. Containerization/Kubernetes experience is highly desirable, as is experience in application monitoring solutions such as Grafana/Prometheus.

This is a rapidly evolving area and we want people who will bring a learning mindset. Your success will be enabled by the ability to communicate effectively with a diverse set of stakeholders. If you can code, love data and want to work on innovative projects, then apply now!

The Corporate Operations Group (COG) brings together specialist support services including workplace, human resources, market operations and technology. COG's purpose is to drive operational excellence through business-aligned services with a focus on quality, cost and risk. COG comprises the following divisions: Business Improvement and Strategy, Business Services, Human Resources, Market Operations, and Technology.

Find out more about Macquarie at www.macquarie.com/about

Macquarie understands the importance of diversity and inclusion - our long history of success has come from being different. At Macquarie we value the innovation and creativity that diversity of thought brings. The one thing we all have in common is our focus on high performance. If you're capable, motivated and can deliver, we want you on our team.

Macquarie is an equal opportunities employer and does not discriminate on the grounds of age, disability, sex, sexual orientation, gender reassignment, gender identity, marriage, civil partnership, pregnancy, maternity, race (including colour and ethnic or national origins), religion or belief.",3.8,"Macquarie Group
3.8","London, England",-1,10000+ Employees,1969,Company - Public,Investment Banking & Asset Management,Finance,$5 to $10 billion (USD),-1
Data Engineer,-1,"We are looking for a passionate Senior Data Engineer to join us in our goal; to become the world's best print on demand consumer. We’re always on the hunt for amazing people, keen to make an impact every single day!

Our mission is simple: we aim to remove all barriers and enable entrepreneurs, brands and influencers to test and scale new product ideas and e-commerce businesses faster and further than ever before by digitalising traditional print environments stimulating the global adoption of print-on-demand.

Our platform allows clients to easily design new products and publish them instantly to the landing pages and highly customisable white-label e-commerce stores included within the Moteefe platform, or to a third-party e-commerce store solution of the client’s choice. Production is on-demand. This means that sales can be made before the item is produced. This agility transforms the economics of the supply chain.

Recognised by The Sunday Times Fast Track as one of the fastest growing tech companies in the UK and by Deloitte in 2020 as one of the fastest growing e-commerce businesses.

We truly believe in the power of human potential, that's why at Moteefe we give our employees

freedom to operate with their own entrepreneurial ambition. We strive for the best possible results by working as a team to enable partnerships across our community. These are our core values and beliefs. We encourage our employees to take as much annual leave as they need and are keen advocates in well-being with our flexible working from home policy, health is wealth! We ensure you have everything you need to do your job successfully, you can pick your own technical equipment that suits the way you work, whether that's in an office that is fully stocked with snacks to keep you going, or working from a coffee shop or from home.

What you’ll do with us:

You will be joining our Data and Insights team, and be key to transforming how the business leverages its data asset. Data and Analytics has been identified as a key enabler for the company to scale. Our vision is for decisions, investments, interventions and developments to be driven by robust measurement, analysis and insight across all business units. It’s an exciting part of our journey, and you have an opportunity to shape how we become truly ‘data-first’ as an organisation.

Working with our new data infrastructure stack, you’ll become an expert in our data sources as well as being passionate about the outcomes that we need to drive. You’ll partner with our awesome engineering teams to ensure a high quality and comprehensive data flow, integrity in our metrics logic, and provide a consumption layer where the business has access to all the data it needs.

In addition you will facilitate the wide-scale adoption for feature-testing in the business. managing the process and reporting back to senior management on what we have learnt and how we can optimise further.

In short this is a high-impact role for a technical individual who is commercially astute and wants to be close to the decision-making part of the action. It’s the opportunity to make a difference and to define the data-dna of the company that will serve us well for years to come.

Requirements

What we need from you (must have skills):
Have extensive skills in sql, both at production grade and at analytical level, gained through intensive application in a commercial business environment
Have skills in extracting, transforming and transporting data within and between data environments
Hands-on exposure to development of ‘data views’ with one or more BI tools such as PowerBI, Looker, Tableau, Microstrategy.
Thought leadership on Data Engineering best practices, and what ‘good looks like’ from a consumption-layer design perspective
Familiar with the concept of AB testing within an e-commerce environment, with a good appreciation of ‘best practice’
Strong communication and collaboration skills
Passion for delivering insights from data
Pragmatic, self-starter with a proven track record for delivering impactful work
Attention to detail
What we'd love from you (nice to have skills):
Skills gained in data governance and/or metric management
Retail/Technology sector experience
Start-up experience
What to expect when interviewing with us:

We have the flexibility to interview at the pace that is convenient for you! Our Recruitment team will reach out to you and have an in depth conversation to find out more about you, if interested we will then proceed to interview. Your recruiter will guide you through the full process.

We will send you a Tech challenge to complete, if it looks good we will have an interview to discuss this in further detail. If everything is aligned you will meet our Head of Data and our CTO to discuss further about the way we work and ask any questions you may have, followed by an Architectural design interview and code review.

*We are a truly inclusive environment and encourage anyone to apply regardless of age, cultural background, disability, gender, marital status, nationality, political belief, race, religious or sexual orientation.",3.7,"Moteefe
3.7","London, England",-1,51 to 200 Employees,2015,Company - Private,General Merchandise & Superstores,Retail,Unknown / Non-Applicable,-1
Data Engineer,-1,"Are you a skilled data engineer who has helped enterprises deploy production-ready data platforms?

Are you keen to implement cutting edge cloud data services, with focus on how consumers use the platform?

Are you interested in building on your existing data and cloud experience?

About Us

We’re an innovative tech consultancy - a team of problem solvers. Since 1993 we’ve been finding better ways to solve complex technology problems for some of the world’s leading organisations and delivered solutions that millions of people use every day.

We bring together experts from diverse backgrounds and experiences in a collaborative and open culture to deliver outstanding outcomes for our clients, and a stimulating and rewarding environment for our people.

We’re looking for data specialists with experience in Data Development, ETL, Data Warehousing and dealing with large sets of structured, semi-structured and unstructured data.

About the Role

As a BJSS data engineer you’ll help our clients deploy data pipelines and processes in a production-safe manner, using the latest technologies and with a DataOps culture.

You’ll work in a fast moving, agile environment, within multi-disciplinary teams, delivering modern data platforms into large organisations.

You’ll get to work with some of the brightest and best in the industry on some of the most exciting digital programmes around.

About You

You’ll have the expertise and confidence to work collaboratively with engineers, architects and business analysts in multi-disciplinary teams on client site, and have experience in several of these areas:
Python
AWS or Azure data services (e.g. Data Factory, Synapse, Redshift, Glue, Athena etc.)
Databricks or Apache Spark.
At least one distributed NoSQL database (e.g. HBase, Cassandra).
Stream processing technologies such as Kafka, Kinesis etc.
Hadoop ecosystem exposure.
Apply Now!",3.8,"BJSS
3.8",Greater Manchester,-1,1001 to 5000 Employees,1993,Company - Private,IT Services,Information Technology,$100 to $500 million (USD),-1
Data Engineer,-1,"Moneybox is growing rapidly, and our technical and data teams are no exception. We have more users, more accounts, more money invested, more features, more code, more data, and more team-members than ever before. We’re looking for a database administrator & data modeller who can take our set-up and infrastructure to the next level. In this unique role, you’ll be the interface between the cloud apps and insight teams, collating, ingesting and organizing data to drive action and results.

Our tech stack:

Microsoft Azure
GitHub
TeamCity
Terraform
Azure DevOps
Azure Application Insights
Octopus Deploy
BASH / Shell Script
Power Shell
C# / .NET Framework, .Net Core ASP.NET Web API
Sql Server
CosmosDb
Azure Service Bus
What you'll do
Working directly with the Head of Insight and Head of Cloud Apps and their teams, this role will be responsible for but not limited to the following:
Responsibilities:
Own, maintain, and improve our data processing and analytical platforms including choosing and adding new tools.
Support the insight team with more complex or novel data processing tasks (e.g. python scripting)
Act as a best practice resource for SQL query optimization and performance for the Insight and Dev Teams.
Build and maintain new integrations to ingest and integrate new sources of data
Work with moneybox dev teams and insight team to build and maintain a reliable, meaningful, and accurate core analytical data warehouse which stays up-to-date as our products grow and change
Organise core data into references and summary tables (e.g. customer segmentation) making the Insight data analysts more efficient.
Advise the senior leaders on the selection and evaluation of suitable tools including a business intelligence tool that is flexible to the future needs of the business. Lead implementation of this once selected.
Work with tech teams, and compliance to ensure that analytical data and supporting platforms are secure, appropriately restricted, and comply with policy
Stay up-to-date with industry trends and help insight and tech teams understand where new technology could pragmatically deliver value
Manage and monitor the cost, efficiency, and speed of data processing
Who you are
A driven, ambitious individual who’s looking to build their career at an exciting very- fast-growing company
Curious mindset who is motivated by improving processes and organizing information in practical ways.
Bias for action, valuing execution over complexity.
Naturally personable, great communicator who has a passion for their work and the people they work with.
Excited about being part of a fast-growing company that’s trying to make a positive mark on the world.
Knows how to have fun whilst maintaining a professional outlook
Experience and Skills
Essential skills:
Fundamentals of database administration and optimisation
Practical experience of analytical data structures, and data modelling approaches
Working with APIs, and Extract Transform Load processes
Python (or similar scripting language) for data processing
Desirable skills:
Hadoop and big data processing
Data Warehousing, Data Lakes, and master data management
Scripted data processing and visualisation (e.g R language and processing)
Cloud storage and compute systems (- particularly Azure Data Factory, Data Lakes, and Data Bricks)
BI Experience on tools such as Power BI, Tableau, Looker etc.
What's in it for you?
Opportunity to join a fast-growing, award-winning and super ambitious startup
Work with a friendly team of highly motivated individuals
Be in an environment where you are listened to and can actually have an impact
Thriving collaborative and inclusive company culture
Competitive remuneration package
Company Share options
Perkbox – selection of 200+ perks
25 days holiday + bank holidays
Please read before you apply!
By sending us your application you acknowledge and agree to Moneybox using your personal data as described below.
We collect applicants’ personal data to manage our recruitment related activities. Consequently, we may use your personal data to evaluate your application, to select and shortlist applicants, to set up and conduct interviews and tests, to evaluate and assess the results, and as is otherwise needed in the recruitment process generally.
We do not share your personal data with unauthorised third parties. However, we may, if necessary, share your personal data to carefully selected third parties acting on our behalf. This may include transfers to servers and databases outside the country where you provided us with your personal data. Such transfers may include for example transfers and/or disclosures outside the European Economic Area and in the United States of America.
If you are unsuccessful in your application, we may keep your details on file so that we can tell you about other suitable vacancies which may be of interest to you when they arise in the future. If you would rather we did not keep your details on file, you can contact us at email: DPO@moneyboxapp.com",4.4,"Moneybox
4.4","London, England",-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"This is a fantastic opportunity for a junior Data Engineer to join a global blue chip company as a Data Engineer, working on high profile data projects in AWS environment.

This Data Engineer position will initially be on a remote contract (outside IR35) and will eventually (from next year) be split between remote working on and on site working in Cambridgeshire and this will be a long term project.

The key skills required for this Data Engineer position are:

R and/or python (preferably both, but expert in a least one)
Good communications with stakeholders and customers from a technical point of view
Exposure/experience of at least two of the following
Git
Jira
AWS

Desirable

Exposure/Experience to the Pharmaceutical/Life Science Sector
Apache Spark
Kanban

If you do have the relevant experience for this Data Engineer contract role, please do apply.",3.2,"The Bridge
3.2","Cambridge, East of England, England",-1,201 to 500 Employees,-1,Nonprofit Organization,Industrial Manufacturing,Manufacturing,$5 to $10 million (USD),-1
Senior Software Engineer - FX Trading,-1,"FXGO is a world-class trading platform that allows traders to buy and sell currencies (FX) 24/5. The FX market is the largest market in the world, with more than $6 trillion traded every day— and our platform is used by the industry's biggest players in over 120 countries. Our trading applications are distributed, fault-tolerant, highly transactional and low-latency.

Our team:

FXGO is a growing team of talented engineers who are passionate about our product. We take pride in building one of the premier FX trading platforms in the world! In London, we are expanding in Shared Services and the FX Trading Grid application.

Shared Services comprises Enablements, Post Trade and the Regulatory Reporting and Clearing teams. All 3 teams are service oriented, focusing on delivering highly available, low latency and highly adaptable services to front end trading applications across FXGO and beyond. Together, they form the lower layer of the FXGO trading platform. The teams own software across the stack but with more focus on the backend.

The FX Trading Grid application allows traders to buy and sell currencies at the click of a button. The application has to process large amount of continuous real-time data and process trade execution as fast as possible. The engineers are client facing and implement workflows for the front end as equally as low latency-scalable solutions for the back end.

Who are you?

An engineer who is motivated by building and adding value to financial products that are used by clients, and who appreciates the impact of your work. You are someone who always takes ownership of what you're doing, and you're excited by the opportunity to work on problems that range from engineering to business logic to usability. You love to see what you build in the hands of clients and the challenge of building a live real-time trading platform energizes you.

You'll need to have:
Strong problem solving skills
Solid C++ or related OOP programming skills
Exposure to all phases of software development life cycle
Appetite to understand and appreciate complex systems
Passion to drive technology and product evolution
We'd love to see:
Experience with high volume, high availability distributed systems.
Experience with messaging queues
Good working knowledge of databases
Experience with distributed cache technologies
Interview process

We believe interviewing is a two way street. It's a way for us to get to know you and your skills, and also a way for you to learn more about the team, our technical challenges, and what you'd be working on. The content of each interview round will be tailored to the role and your background, but the general framework can be found here:https://www.bloomberg.com/careers/technology/engineering/software-engineering-experienced-hire

We have a lot of opportunities to choose from in Engineering, and it is important to us that your skills and experience align best with the team you are interviewing with. To help ensure you are placed on the right team, your application will be considered for all of our current vacancies in Engineering at the first stage of the interview process.",3.9,"Bloomberg
3.9","London, England",-1,10000+ Employees,1981,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Who are Metapack?

We are a tech company that works with a lot of the world’s biggest ecommerce players to integrate them with over 450 carriers around the world to make delivery easy. We are a multi-tenant SaaS platform. We give them the platform to help consumers decide their delivery preference and track the parcel’s progress whilst also providing the retailer with intelligent smart decisions about how to send the parcel – all underpinned with lots of data. We work with well-known global retailers and major brands such as ASOS, Adidas, Burberry, John Lewis, Boohoo, eBay, and Zalando. In fact, we work with so many retailers and carriers it’s highly likely that you’ve interacted with us at some point when ordering goods online!

In August 2018, we were acquired by Fortune 100’s 2nd fastest growing company, stamps.com. We have super ambitious and exciting plans all centred around our tech. Metapack will play a role in shipping around 600 million parcels in 2018 and with the wider stamps.com family the number rises to 2.5bn parcels. Metapack has been growing at 40% year on year over the last 5 years and continues to grow at a rapid rate.

Our Values;

The way we work really is at the heart of Metapack, and our 4 core values are brought together to give a sense of our culture.

With Innovation and Integrity at our core, we have a flat and open culture where data & evidence, backed by honest and frank discussions, beats subjective opinion and hierarchy. We Collaborate with energy and Passion on meeting the needs of our fantastic customers and partners.

We passionately believe in forming autonomous, cross functional teams who are empowered to deliver our ambitious strategy. With stamps.com ownership comes the ability to operate largely independently away from Board meetings and old world thinking but with the financial support of a high performing tech company. Energy and passion for our business and customers is a part of the MetaPack culture – and we love working with like-minded people.

Why would I want to be a Data Engineer at Metapack?

Data is key to the Metapack’s strategy. We work at scale, pace and with the latest architecture patterns and tech. We process thousands of events per second and our massive dataset keeps growing at a staggering pace. We keep improving our data platform and data engineering stack to accommodate growth, enable novel solutions and provide the best service to our customers.

We have a flat and open engineering culture where data, & evidence beats opinion and hierarchy, backed by honest and frank discussions. We passionately believe in forming autonomous, cross functional teams who are empowered to deliver our ambitious strategy. With stamps.com ownership comes the ability to operate largely independently away from Board meetings and old world thinking but with the financial support of a high performing tech company. Energy and passion for our business and customers is a part of the Metapack culture – and we love working with like-minded people.

What would I be doing?

Contributing to the design, build and operational management of our data lake and analytics solution on top of proven AWS data technologies like S3, Athena, Lambda, Kinesis, Glue
Using state of the art technologies like Airflow and Spark to process data and get our dataset just right
Developing frameworks and solutions that enable us to acquire, process, monitor and extract value from our massive dataset
Supporting the Data Analysts and Data Scientists with automation, tooling, data pipelines and data engineering expertise
Delivering highly reliable software and data pipelines using Software Engineering best practices like automation, version control, continuous integration/continuous delivery, testing, security, etc.
Define, implement and enforce automated data security and data governance best practices within the solutions designed
Mentoring more junior colleagues and being mentored by more senior colleagues

What key skills and experience do I need?

A Software Engineering background
Experience developing and supporting robust, automated and reliable data pipelines in Python and SQL
Experience with data processing frameworks like Pandas or Spark
Experience with streaming data processing
AWS, Azure or Google Cloud experience
Continuous integration/delivery environment experience with a passion for automation
Knowledge of a Data Orchestration solutions like Airflow, Oozie, Luigi or Talend
Knowledge of both relational and non-relational database design and internals
Knowledge of how to design distributed systems and the trade-offs involved
Experience with working with software engineering best practices for development, including source control systems, automated deployment pipelines like Jenkins and devops tools like Terraform

It would be great if you also could bring

Practical understanding of GDPR and other considerations regarding data security
Knowledge and direct experience of using business intelligence and analytics tools (Tableau, Looker, Power BI, etc.)
Production experience working with very large datasets
Experience with big data cloud technologies like EMR, Athena, Glue, Big Query, Dataproc, Dataflow.
Data Science/Machine Learning know-how
A desire to constantly challenge the norm
Willing to attend conferences, webinars and meet-ups and share the learning

What are the perks?

25 days holiday, 10% bonus (paid quarterly), pension, enhanced maternity and paternity leave, group life insurance scheme, private medical healthcare
Discounted gym membership, cycle to work scheme, interest free season ticket loan
Dynamic, open culture with lots of social activities",3.9,"MetaPack
3.9","London, England",-1,201 to 500 Employees,1999,Company - Public,Computer Hardware & Software,Information Technology,$25 to $50 million (USD),-1
Data Engineer,-1,"Company:
Telefónica S.A.
giffgaff is the commercial brand of Telefónica UK Limited, a leading digital communications company owned by Telefónica S.A. We like to do things a little differently here at giffgaff.

We may be a small company, but we like to think big and create some radical waves in the telco land. At the heart of it, we believe in simplicity. A better way to do mobile. We'd rather you stay with us because you want to, not because there's a nasty contract forcing you to. It's why we work our socks off every day to keep you and guess what? It works. We're uSwitch Network of the Year 2019.

About the Team:

The core mission of Data Engineering team is to deliver the core data infrastructure and data processing pipelines that support giffgaff’s data products and business insights. Our team works horizontally supporting all areas of the business from a data warehousing perspective and has a strong technology focus.

Your Role:

Reporting into the Data Engineering Technical Lead, the Data Engineer is expected to have deep understanding of data technologies and strong software engineering expertise, along with a deep interest in data analytics, machine learning and AI.

The role involves creating data solutions to process data at scale, both in batch and real-time pipelines, to support a wide range of data-driven projects and support our transformation into an AI-ready organisation.

Responsibilities:

The key responsibilities of the Data Engineer are:
Implement workflows to ingest data into a Snowflake data warehouse for a variety of data sources
Implement data transformation pipelines in real-time and batch environments
Support all product teams in adopting our data engineering tech stack to generate new data streams
Collaborate with Data Science and Business Intelligence teams to identify requirements and develop the necessary data workflows to deliver against those requirements
Skills & experience:
University degree in Computer Science, Software Engineering or related subjects or equivilent experience
Experienced in Java 8+ and Python
Relational and non-relational databases. Experience with Snowflake a plus.
Batch processing frameworks, such as DBT, Flink, Apache Airflow, etc.
Message brokers / stream processing technologies (Kinesis, Kafka, Storm, Spark Streaming, Flink, etc.)
Familiarity AWS, Docker, Kubernetes, Amazon EKS
Continuous Integration with Jenkins
Test-Driven Development and XP
Additional Information:

This role involves close collaboration with data scientists, data analysts and product engineers.

Note this role was previously advertised as a 12 month FTC but is now a permanent role

Grade:MPG4

Finally...

This is a chance to work for one of the most sought after UK companies, highly regarded for its community model. In return for your outstanding efforts, you’ll be rewarded with a competitive salary and excellent benefits.

We believe that hard work should be supported and recognised. This position plays an important role across the business, allowing you to work cross functionality, take on more responsibility and gain experience, which will greatly benefit you in the future.",4.0,"Telefónica
4.0","Uxbridge, England",-1,10000+ Employees,1924,Company - Public,Telecommunications Services,Telecommunications,$10+ billion (USD),-1
Senior Software Engineer - FX Trading,-1,"FXGO is a world-class trading platform that allows traders to buy and sell currencies (FX) 24/5. The FX market is the largest market in the world, with more than $6 trillion traded every day— and our platform is used by the industry's biggest players in over 120 countries. Our trading applications are distributed, fault-tolerant, highly transactional and low-latency.

Our team:

FXGO is a growing team of talented engineers who are passionate about our product. We take pride in building one of the premier FX trading platforms in the world! In London, we are expanding in Shared Services and the FX Trading Grid application.

Shared Services comprises Enablements, Post Trade and the Regulatory Reporting and Clearing teams. All 3 teams are service oriented, focusing on delivering highly available, low latency and highly adaptable services to front end trading applications across FXGO and beyond. Together, they form the lower layer of the FXGO trading platform. The teams own software across the stack but with more focus on the backend.

The FX Trading Grid application allows traders to buy and sell currencies at the click of a button. The application has to process large amount of continuous real-time data and process trade execution as fast as possible. The engineers are client facing and implement workflows for the front end as equally as low latency-scalable solutions for the back end.

Who are you?

An engineer who is motivated by building and adding value to financial products that are used by clients, and who appreciates the impact of your work. You are someone who always takes ownership of what you're doing, and you're excited by the opportunity to work on problems that range from engineering to business logic to usability. You love to see what you build in the hands of clients and the challenge of building a live real-time trading platform energizes you.

You'll need to have:
Strong problem solving skills
Solid C++ or related OOP programming skills
Exposure to all phases of software development life cycle
Appetite to understand and appreciate complex systems
Passion to drive technology and product evolution
We'd love to see:
Experience with high volume, high availability distributed systems.
Experience with messaging queues
Good working knowledge of databases
Experience with distributed cache technologies
Interview process

We believe interviewing is a two way street. It's a way for us to get to know you and your skills, and also a way for you to learn more about the team, our technical challenges, and what you'd be working on. The content of each interview round will be tailored to the role and your background, but the general framework can be found here:https://www.bloomberg.com/careers/technology/engineering/software-engineering-experienced-hire

We have a lot of opportunities to choose from in Engineering, and it is important to us that your skills and experience align best with the team you are interviewing with. To help ensure you are placed on the right team, your application will be considered for all of our current vacancies in Engineering at the first stage of the interview process.",3.9,"Bloomberg
3.9","London, England",-1,10000+ Employees,1981,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Are you a skilled data engineer who has helped enterprises deploy production-ready data platforms?

Are you keen to implement cutting edge cloud data services, with focus on how consumers use the platform?

Are you interested in building on your existing data and cloud experience?

About Us

We’re an innovative tech consultancy - a team of problem solvers. Since 1993 we’ve been finding better ways to solve complex technology problems for some of the world’s leading organisations and delivered solutions that millions of people use every day.

We bring together experts from diverse backgrounds and experiences in a collaborative and open culture to deliver outstanding outcomes for our clients, and a stimulating and rewarding environment for our people.

We’re looking for data specialists with experience in Data Development, ETL, Data Warehousing and dealing with large sets of structured, semi-structured and unstructured data.

About the Role

As a BJSS data engineer you’ll help our clients deploy data pipelines and processes in a production-safe manner, using the latest technologies and with a DataOps culture.

You’ll work in a fast moving, agile environment, within multi-disciplinary teams, delivering modern data platforms into large organisations.

You’ll get to work with some of the brightest and best in the industry on some of the most exciting digital programmes around.

About You

You’ll have the expertise and confidence to work collaboratively with engineers, architects and business analysts in multi-disciplinary teams on client site, and have experience in several of these areas:
Python
AWS or Azure data services (e.g. Data Factory, Synapse, Redshift, Glue, Athena etc.)
Databricks or Apache Spark.
At least one distributed NoSQL database (e.g. HBase, Cassandra).
Stream processing technologies such as Kafka, Kinesis etc.
Hadoop ecosystem exposure.
Apply Now!",3.8,"BJSS
3.8",Greater Manchester,-1,1001 to 5000 Employees,1993,Company - Private,IT Services,Information Technology,$100 to $500 million (USD),-1
Data Engineer,-1,"Who are Metapack?

We are a tech company that works with a lot of the world’s biggest ecommerce players to integrate them with over 450 carriers around the world to make delivery easy. We are a multi-tenant SaaS platform. We give them the platform to help consumers decide their delivery preference and track the parcel’s progress whilst also providing the retailer with intelligent smart decisions about how to send the parcel – all underpinned with lots of data. We work with well-known global retailers and major brands such as ASOS, Adidas, Burberry, John Lewis, Boohoo, eBay, and Zalando. In fact, we work with so many retailers and carriers it’s highly likely that you’ve interacted with us at some point when ordering goods online!

In August 2018, we were acquired by Fortune 100’s 2nd fastest growing company, stamps.com. We have super ambitious and exciting plans all centred around our tech. Metapack will play a role in shipping around 600 million parcels in 2018 and with the wider stamps.com family the number rises to 2.5bn parcels. Metapack has been growing at 40% year on year over the last 5 years and continues to grow at a rapid rate.

Our Values;

The way we work really is at the heart of Metapack, and our 4 core values are brought together to give a sense of our culture.

With Innovation and Integrity at our core, we have a flat and open culture where data & evidence, backed by honest and frank discussions, beats subjective opinion and hierarchy. We Collaborate with energy and Passion on meeting the needs of our fantastic customers and partners.

We passionately believe in forming autonomous, cross functional teams who are empowered to deliver our ambitious strategy. With stamps.com ownership comes the ability to operate largely independently away from Board meetings and old world thinking but with the financial support of a high performing tech company. Energy and passion for our business and customers is a part of the MetaPack culture – and we love working with like-minded people.

Why would I want to be a Data Engineer at Metapack?

Data is key to the Metapack’s strategy. We work at scale, pace and with the latest architecture patterns and tech. We process thousands of events per second and our massive dataset keeps growing at a staggering pace. We keep improving our data platform and data engineering stack to accommodate growth, enable novel solutions and provide the best service to our customers.

We have a flat and open engineering culture where data, & evidence beats opinion and hierarchy, backed by honest and frank discussions. We passionately believe in forming autonomous, cross functional teams who are empowered to deliver our ambitious strategy. With stamps.com ownership comes the ability to operate largely independently away from Board meetings and old world thinking but with the financial support of a high performing tech company. Energy and passion for our business and customers is a part of the Metapack culture – and we love working with like-minded people.

What would I be doing?

Contributing to the design, build and operational management of our data lake and analytics solution on top of proven AWS data technologies like S3, Athena, Lambda, Kinesis, Glue
Using state of the art technologies like Airflow and Spark to process data and get our dataset just right
Developing frameworks and solutions that enable us to acquire, process, monitor and extract value from our massive dataset
Supporting the Data Analysts and Data Scientists with automation, tooling, data pipelines and data engineering expertise
Delivering highly reliable software and data pipelines using Software Engineering best practices like automation, version control, continuous integration/continuous delivery, testing, security, etc.
Define, implement and enforce automated data security and data governance best practices within the solutions designed
Mentoring more junior colleagues and being mentored by more senior colleagues

What key skills and experience do I need?

A Software Engineering background
Experience developing and supporting robust, automated and reliable data pipelines in Python and SQL
Experience with data processing frameworks like Pandas or Spark
Experience with streaming data processing
AWS, Azure or Google Cloud experience
Continuous integration/delivery environment experience with a passion for automation
Knowledge of a Data Orchestration solutions like Airflow, Oozie, Luigi or Talend
Knowledge of both relational and non-relational database design and internals
Knowledge of how to design distributed systems and the trade-offs involved
Experience with working with software engineering best practices for development, including source control systems, automated deployment pipelines like Jenkins and devops tools like Terraform

It would be great if you also could bring

Practical understanding of GDPR and other considerations regarding data security
Knowledge and direct experience of using business intelligence and analytics tools (Tableau, Looker, Power BI, etc.)
Production experience working with very large datasets
Experience with big data cloud technologies like EMR, Athena, Glue, Big Query, Dataproc, Dataflow.
Data Science/Machine Learning know-how
A desire to constantly challenge the norm
Willing to attend conferences, webinars and meet-ups and share the learning

What are the perks?

25 days holiday, 10% bonus (paid quarterly), pension, enhanced maternity and paternity leave, group life insurance scheme, private medical healthcare
Discounted gym membership, cycle to work scheme, interest free season ticket loan
Dynamic, open culture with lots of social activities",3.9,"MetaPack
3.9","London, England",-1,201 to 500 Employees,1999,Company - Public,Computer Hardware & Software,Information Technology,$25 to $50 million (USD),-1
Data Engineer,-1,"This is a fantastic opportunity for a junior Data Engineer to join a global blue chip company as a Data Engineer, working on high profile data projects in AWS environment.

This Data Engineer position will initially be on a remote contract (outside IR35) and will eventually (from next year) be split between remote working on and on site working in Cambridgeshire and this will be a long term project.

The key skills required for this Data Engineer position are:

R and/or python (preferably both, but expert in a least one)
Good communications with stakeholders and customers from a technical point of view
Exposure/experience of at least two of the following
Git
Jira
AWS

Desirable

Exposure/Experience to the Pharmaceutical/Life Science Sector
Apache Spark
Kanban

If you do have the relevant experience for this Data Engineer contract role, please do apply.",3.2,"The Bridge
3.2","Cambridge, East of England, England",-1,201 to 500 Employees,-1,Nonprofit Organization,Industrial Manufacturing,Manufacturing,$5 to $10 million (USD),-1
Data Engineer,-1,"£35,000 – £40,000/annum

As a data engineer within the exciting, new claims advanced analytics capability, you will be building big data solutions to solve some of the organization’s toughest problems and delivering significant business value. This is a really exciting time to join as you will be helping to shape the big data analytics architecture and technology stack within a new cloud based data lake

Responsibilities:

Shape the portfolio of business problems to solve by building detailed knowledge of data sources (internal and external)
Model data landscape, obtain data extracts and define secure data exchange approaches
Acquire, ingest, and process data from multiple sources and systems into Cloud Data Lake
Operate in fast-paced, iterative environment while remaining compliant with Information Sec policies/standards
Collaborate with data scientists to map data fields to hypotheses and curate, wrangle, and prepare data for use in their advanced analytical models
Help architect the strategic advanced analytics technology landscape
Build re-usable code and data assets

Codify best practices, methodology and share knowledge with other data engineers/scientists in the organisation

Measures:

Become expert in claims data sources
Framework set up across the company to define best practice in data engineering space
Robust data sources in the data lake with increasing proportion of data held in the lake
No unexpected issues arise
Successful delivery of cloud projects

“Single version of the truth” tables and views in the cloud that are used by a wide variety of end users providing accurate re-producible

Skills & Experience:

Meaningful experience (2+ years) with at least two of the following technologies: Python, Scala, SQL, Java
Experience and interest in Cloud platforms such as:, Azure, AWS or Databricks
The ability to work across structured, semi-structured, and unstructured data, extracting information and identifying linkages across disparate data sets
Meaningful experience in at least one database technology such as:
Distributed Processing (Spark, Hadoop, EMR)
Traditional RDBMS (MS SQL Server, Oracle, MySQL, PostgreSQL)
MPP (AWS Redshift, Teradata)
NoSQL (MongoDB, DynamoDB, Cassandra, Neo4J, Titan)
Understanding of Information Security principles to ensure compliant handling and management of data
Experience in traditional data warehousing / ETL tools (Informatica, Talend, Pentaho, DataStage)

Ability to clearly communicate complex solutions.

Please email your CV to: paul@dynamix-recruitment.co.uk",5.0,"Dynamix Recruitment Ltd
5.0","Ipswich, England",-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"H&R Talent are seeking a Data Engineer for a large-scale business located in London to join their growing team of analytics experts. You will be working within a team to ensure the company’s data processing and analytical platforms are efficient and complete. You will be developing, maintaining, and testing infrastructures for data generation. You must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products.

Requirements:

Experience in cloud platforms (Google Cloud, AWS & Azure)
Strong knowledge in PowerShell
Knowledge of Docker and Kubernetes
Expert with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.",-1,H&R Talent,"London, England",-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Who are Metapack?

We are a tech company that works with a lot of the world’s biggest ecommerce players to integrate them with over 450 carriers around the world to make delivery easy. We are a multi-tenant SaaS platform. We give them the platform to help consumers decide their delivery preference and track the parcel’s progress whilst also providing the retailer with intelligent smart decisions about how to send the parcel – all underpinned with lots of data. We work with well-known global retailers and major brands such as ASOS, Adidas, Burberry, John Lewis, Boohoo, eBay, and Zalando. In fact, we work with so many retailers and carriers it’s highly likely that you’ve interacted with us at some point when ordering goods online!

In August 2018, we were acquired by Fortune 100’s 2nd fastest growing company, stamps.com. We have super ambitious and exciting plans all centred around our tech. Metapack will play a role in shipping around 600 million parcels in 2018 and with the wider stamps.com family the number rises to 2.5bn parcels. Metapack has been growing at 40% year on year over the last 5 years and continues to grow at a rapid rate.

Our Values;

The way we work really is at the heart of Metapack, and our 4 core values are brought together to give a sense of our culture.

With Innovation and Integrity at our core, we have a flat and open culture where data & evidence, backed by honest and frank discussions, beats subjective opinion and hierarchy. We Collaborate with energy and Passion on meeting the needs of our fantastic customers and partners.

We passionately believe in forming autonomous, cross functional teams who are empowered to deliver our ambitious strategy. With stamps.com ownership comes the ability to operate largely independently away from Board meetings and old world thinking but with the financial support of a high performing tech company. Energy and passion for our business and customers is a part of the MetaPack culture – and we love working with like-minded people.

Why would I want to be a Data Engineer at Metapack?

Data is key to the Metapack’s strategy. We work at scale, pace and with the latest architecture patterns and tech. We process thousands of events per second and our massive dataset keeps growing at a staggering pace. We keep improving our data platform and data engineering stack to accommodate growth, enable novel solutions and provide the best service to our customers.

We have a flat and open engineering culture where data, & evidence beats opinion and hierarchy, backed by honest and frank discussions. We passionately believe in forming autonomous, cross functional teams who are empowered to deliver our ambitious strategy. With stamps.com ownership comes the ability to operate largely independently away from Board meetings and old world thinking but with the financial support of a high performing tech company. Energy and passion for our business and customers is a part of the Metapack culture – and we love working with like-minded people.

What would I be doing?

Contributing to the design, build and operational management of our data lake and analytics solution on top of proven AWS data technologies like S3, Athena, Lambda, Kinesis, Glue
Using state of the art technologies like Airflow and Spark to process data and get our dataset just right
Developing frameworks and solutions that enable us to acquire, process, monitor and extract value from our massive dataset
Supporting the Data Analysts and Data Scientists with automation, tooling, data pipelines and data engineering expertise
Delivering highly reliable software and data pipelines using Software Engineering best practices like automation, version control, continuous integration/continuous delivery, testing, security, etc.
Define, implement and enforce automated data security and data governance best practices within the solutions designed
Mentoring more junior colleagues and being mentored by more senior colleagues

What key skills and experience do I need?

A Software Engineering background
Experience developing and supporting robust, automated and reliable data pipelines in Python and SQL
Experience with data processing frameworks like Pandas or Spark
Experience with streaming data processing
AWS, Azure or Google Cloud experience
Continuous integration/delivery environment experience with a passion for automation
Knowledge of a Data Orchestration solutions like Airflow, Oozie, Luigi or Talend
Knowledge of both relational and non-relational database design and internals
Knowledge of how to design distributed systems and the trade-offs involved
Experience with working with software engineering best practices for development, including source control systems, automated deployment pipelines like Jenkins and devops tools like Terraform

It would be great if you also could bring

Practical understanding of GDPR and other considerations regarding data security
Knowledge and direct experience of using business intelligence and analytics tools (Tableau, Looker, Power BI, etc.)
Production experience working with very large datasets
Experience with big data cloud technologies like EMR, Athena, Glue, Big Query, Dataproc, Dataflow.
Data Science/Machine Learning know-how
A desire to constantly challenge the norm
Willing to attend conferences, webinars and meet-ups and share the learning

What are the perks?

25 days holiday, 10% bonus (paid quarterly), pension, enhanced maternity and paternity leave, group life insurance scheme, private medical healthcare
Discounted gym membership, cycle to work scheme, interest free season ticket loan
Dynamic, open culture with lots of social activities",3.9,"Stamps.com
3.9","London, England",-1,1001 to 5000 Employees,1996,Company - Public,Computer Hardware & Software,Information Technology,$100 to $500 million (USD),-1
Data Engineer,-1,"About graze

graze started in 2008 as a healthy snack subscription service, delivering customised boxes of snacks directly to customers through the post. At the time, there were very few platforms to help us with such a novel idea, so we built our own: from factory machines and systems, to a subscription website and data warehouse.

Ever since those early start-up days, technology and data have always been important in driving our success. Our ability to rapidly develop and iterate tech solutions has been a vital ingredient of our launches into eCommerce and retail, helping us to establish ourselves one of the UK's healthiest snack brands!

In 2019 we were acquired by Unilever, and we're now expanding into Europe. We've already launched graze into Ireland and the Netherlands - and that's just the beginning...

The role, Data Engineer...

Were looking for a Data Engineer to provide technical leadership in our Data team. You will be responsible for managing our data warehouse platform, building and maintaining data pipelines, and designing and delivering technical solutions to business problems.

Our tech stack...

Our AWS Redshift data warehouse is populated by a custom-built batch job scheduling system, which orchestrates hundreds of ETL processes per day. The wealth of data that comes from a vertically-integrated and multi-market consumer goods business means that our pipelines are really diverse... we have processors that deal with anything from ingesting subscription website session data, to retailer sales data, to product weight data from the production lines in our factory!

Our data platform is primarily written in PHP, deployed on Docker on AWS ECS, and we rely on other AWS services like S3, RDS and SQS. Business users can download and upload data via self-serve tools in our internal web application, as well as Tableau dashboards.

Its now been 10 years since graze made our first data hire. A lot has changed in this time, and were always looking for ways to further improve our data systems. Which parts of our system continue to drive real value to the business - how can we make these better? What new tools are out there that were not yet using? Should we migrate our customer-built batch job scheduling to Airflow? We are looking for someone who is excited to get involved in answering these big questions and defining the technical direction that we move in!

What we are looking for in you
Youre curious! You have an ability to quickly learn and adapt, with fast problem-solving capabilities
You have experience in building and maintaining data platforms and pipelines
You love to write clean, efficient, maintainable, version-controlled and well-documented code
You have excellent SQL skills
You enjoy working with end users to build and deploy quality solutions that are valuable to them and the business
What we expect in the first 6 months
Gain a comprehensive understanding of the data technology stack we have at graze.
Gain enough familiarity with the existing codebase that you can comfortably make and review significant changes.
Be instrumental in scoping and specifying changes to the systems.
Be able to identify areas of improvement and progress changes.
Be able to respond to, triage and fix most operational issues.
Build strong relationships with your team and key people you work with.
Whats in it for you?
A competitive salary, BUPA private medical insurance and pension scheme
25 days holiday + 1 health day + 1 volunteering day, per year
Flexible working - throughout 2020, weve all been working from home. We will continue to offer flexible working in future, allowing for a balance between office and remote working days.
Hacker Time: one day per month dedicated to hacking away (no distractions!) on whatever youd like, learning a new language, trying out some new tech, open sourcing some code
We encourage active learning with learning lunches, networking events or more formal qualifications
Opportunities for presenting on technical subjects, in learning and conference-style environments both internally and externally
Plenty of free snacks!
Were all about inclusivity and making you feel like you belong. We are passionate about having an excellent culture with strong meaningful values so the biggest ask we have is for you to be your authentic self every day whilst doing a great job.

Powered by JazzHR",3.7,"graze.com
3.7","Richmond upon Thames, England",-1,201 to 500 Employees,2009,Company - Public,Food & Beverage Manufacturing,Manufacturing,$50 to $100 million (USD),-1
Data Engineer,-1,"About Evaluate Ltd

Evaluate provides trusted commercial intelligence for the pharmaceutical and medical device industries.

Our EvaluatePharma® online subscription services provides a seamless view of the past, present and future of the global pharmaceutical market in a single, standardised platform. Vantage – our award-winning, independent editorial team – provide thought-provoking news and insights into the current and future developments in the industry. Evaluate has been a trusted partner to industry-leading organisations for over 20 years. For more information on how we give our clients the time and understanding to drive better decisions, visit www.evaluate.com.

Requirements

Position Description: A Data Engineer is needed to support the product development team in data design and structuring, ETL processes, and pipeline generation.

Responsibilities:
Support the product development team in the creation of features for predictive ML models.
Support the product development team in the manipulation of large data sets, and the extraction of insights.
Support the product development team in the design and optimisation of database solutions that sit upstream of main production environment.
Develop & maintain data publication and synchronisation processes, supporting Tableau.
Designing robust & efficient data processes, aggregations and pipelines.
Establish industry best practices using modern tools and processes.
Productionising Tableau data transforms.
Creation of attributes for data science models.
Manipulation of large data to create aggregated analyses.
Creation of optimised upstream database systems, e.g. consolidated/standardised clinical trial or pricing database (across multiple geographies).
Pulling bespoke database extracts for hypothesis testing, and ideation.
Trend analysis.
Pulling, processing and structuring new data sets, from public and private sources, e.g. grant information.
Working Conditions:

Based in the London office with flexible working. Occasional travel to other offices, subsidiaries & partner locations. Initially 100% working from home while government travel restrictions remain in place due to Covid-19.

Required skills & qualifications:
Have a good grasp of modern data practises and apply them to complex problems.
Building services features and libraries that contribution to library code and core services.
Have a good understanding of data architecture.
Experience with AWS
Ability to write code in Python
Experience wielding large data sets in formats such as XML, JSON and CSV.
Data manipulation using ETL tools and databases (Alteryx, Matillion, Redshift/Snowflake, RDS, S3).
Knowledge of database design, consolidating and flow outputs into current/new database.
Experience with data visualisation tools such as Tableau, Power BI or QuickSight.
Experience with big data technologies.
Experience in data processing using traditional and distributed systems.
Experience designing data models
Experience in SQL, NoSQL database management systems
Bachelor degree in Computer Science, similar technical field of study or equivalent practical experience.
Expertise in the design, creation and management of large datasets/data models.
Experience working on building and optimising logical data model and data pipelines while delivering high data quality solutions that are testable and adhere to SLAs.
Experience in using various data design patterns and knowledge of when/when not to use one.
Experience of working in an Agile (Scrum) environment
Nice to have:
R or MATLAB.
Knowledge of pharmaceutical industry, in particular the stages of pharmaceutical product development.
Familiarity with research, clinical trial or patent documents.
Personal attributes:

In addition to buying into Evaluate’s values as per below candidates should display the following attributes:
Friendly approach to business
Superior communication skills with all
Innovative approach to function
Ability to grow and adapt as business does
Open and honest approach to communication
Finger on the pulse with new & emerging technologies
Values Statement

Focus on the client

Our clients’ success is our success.

We do our utmost to understand our clients and ensure they are successful in their roles.

Improve

Be better.

We strive to improve and innovate, challenging industry norms and ourselves.

Be one team

Communicate, collaborate, challenge.

We believe that two heads are always better than one; in being generous with our time, and collaborating to get the job done

Empower

Enable Success.

We empower each other to deliver, celebrate our successes and learn from our mistakes.

Be Accountable

Own it.

We take responsibility and do the right thing. Through guidance and support we hold each other accountable.",3.9,"Evaluate Group
3.9","London, England",-1,51 to 200 Employees,1996,Company - Private,Research & Development,Business Services,$25 to $50 million (USD),-1
Data Engineer,-1,"Data Engineer

Great Ormond Street Hospital for Children

As the Data Engineer for the DRE and Genomics and Systems Medicine BRC Theme, the post holder will primarily have responsibility for developing and implementing a system of capturing and ingesting structured data from genomics reports using established healthcare industry standards.

The role may also support users in the upload and processing of their data to prepare them for data analytics.

The post holder will develop generic methods and tools for handling genetic/genomic data from reports, to facilitate data analytics and document best practice guidelines. In addition to the research platform, they will support the deployment and optimisation of other associated systems at GOSH.

Their key responsibilities are:

Development and optimisation of data integration of genomic and genetic data from clinical reports into the core DRE data model adhering to standards and ensuring data quality;
Develop data engineering methods and tools to transform such data, plus associated structured clinical data, for analytics and support individual projects and users with data provision and processing;
Develop best practice guidelines on the use of such data for projects and provide relevant user training;
Assisting with deployment and optimisation of the research platform and associated systems within the DRE in relation to use of genomic and genetic report and clinical phenomic data;
There is no requirement to undertake any bioinformatics analysis or data handling

For further details / informal visits contact:

Gemma Molyneux | Clinical Informatics Research Coordinator | DRIVE | Great Ormond Street Hospital for Children |Tel: 0207 405 9200 ext 4778 | email: gemma.molyneux@gosh.nhs.uk

Please be advised that:

The recruitment process for all admin and clerical roles at Bands 2-5 will be a two stage recruitment process whereby shortlisted candidates will undertake an online literacy, numeracy, ICT and typing test.Only those candidates who pass the competency test will proceed to a formal interview.

The closing date given is a guide only. There may be some occasions where we have to close a vacancy once sufficient applications have been received. It is therefore advisable that you submit your application as early as possible to avoid disappointment.

Only those candidates who clearly demonstrate how they meet the person specification criteria for this post will be shortlisted. Please note that where high volumes of applicants have been received, additional criteria may on occasion be used to determine the final shortlist.

Please also note that all recruitment is currently subject to restrictions on the allocation of Certificates of Sponsorship.

We are an accredited Living Wage Employer.

Please note that the Trust will shortly be introducing the TRAC recruitment system. Once the system goes live, after applying via NHS Jobs, your submitted application will be imported into TRAC. All subsequent information regarding your application will be generated from apps.trac.jobs. You will not be able to track the progress of your application or receive messages through the NHS Jobs website, and furthermore, that as an employer, we will not be able to respond to any e-mails sent to us via the NHS Jobs website. By applying for this post you are agreeing to Great Ormond Street Hospital for Children NHS Foundation Trust transferring the information contained in this application to its preferred applicant management system. If you are offered a job, information will also be transferred into the national NHS Electronic Staff Records system. Please note, all communication regarding your application will be made via email, please ensure you check your junk/spam folders as emails are sometimes filtered there.

Disclosure and Barring Service Check

This post is subject to the Rehabilitation of Offenders Act (Exceptions Order) 1975 and as such it will be necessary for a submission for Disclosure to be made to the Disclosure and Barring Service (formerly known as CRB) to check for any previous criminal convictions.

To stay safe in your job search we recommend that you visit SAFERjobs (https://www.safer-jobs.com), a non-profit, joint industry and law enforcement organisation working to combat job scams. Visit the SAFERjobs website for information on common scams and to get free, expert advice for a safer job search.",3.5,"Great Ormond Street Hospital NHS Foundation Trust
3.5","London, England",-1,1001 to 5000 Employees,1852,Hospital,Health Care Services & Hospitals,Health Care,$100 to $500 million (USD),-1
Senior Software Engineer,-1,"Are you a Software Engineer who wants to join a leading cyber team within an evolving and dynamic organisation?

Due to the success of a number of strategic Gloucestershire based programmes, we are growing our Software Development team with creative and ambitious Software Engineers. With a primary focus on Java, your experience will cover different technologies within an agile environment

Different thinking for a Different world

Northrop Grumman is a leading global security company providing innovative systems, products an solutions to government and commercial customers worldwide. In Northrop Grumman’s rapidly growing UK Cyber and Intelligence business, we support our customers’ work to make the UK the safest place to live and do business, both physically and online.

Working with and alongside our customers, we use modern software engineering methods (Scaled Agile Development, DevSec Ops, Site Reliability Engineering, micro-service architectures) and cutting edge techniques (data science, Artificial Intelligence,Machine Learning) to tackle complex and challenging problems and deliver cost effective, reliable, supportable solutions.

Our solutions support complex analysis of substantial amounts of data, requiring state of the art ‘big data’, stream processing and cloud-based analytics, identifying and using ‘best of breed’ commercial and open source technologies and integrating them with our own software to meet customer needs quickly and efficiently.

At Northrop Grumman we pride ourselves on our ability to combine agile development with sound engineering and security practices to ensure that our solutions are robust and resilient; designed and built to start secure and stay secure against ever evolving cyber security threats. As well as designing for security, Information Assurance and legal / policy compliance, we actively assess products and services, identifying vulnerabilities and weaknesses that could be exploited by cyber attackers, and we create and run exercises to pit cyber security specialists against secure systems and each other.

We carry out research and innovation locally in the UK, with commercial and academic partners, and across our 85,000+ worldwide workforce.

How you will make a difference

For us, innovation is key and we have immediate opportunities for talented software engineers to join our team to help us develop and maintain a suite of applications.. We are in a phase of rapid growth and there are opportunities to develop your career with us to meet your aspirations.

You will be helping us to solve our customer’s problems within an agile team. You will have opportunities throughout the Software Life cycle from requirements capture through to R&D(Research & Development), implementation, automation and test in a wide range of technologies.

As a Senior Software Engineer you will have had responsibility for parcels of work and should be used to working with customers. You will be able to deploy applications in a controlled, repeatable way and be developing technical specialisms in frameworks and/or tool sets. Experience of mentoring or team leading would be advantageous.

Key criteria required...

Experience in design, development, test and integration of quality software

Experience in Java and the use of object oriented design

Keen to learn a broad range of technologies on the Java stack

Also, we’d love it if you have experience of...

Agile/Scrum methodologies using tools such as Confluence and Jira

DevOps approaches and associated tools such as Ansible, Docker and Jenkins

Messaging and Routing Technologies such as NiFi and Kafka

Cloud-based architectures

Linux operating systems (Red Hat Enterprise Linux Server/CentOS)

Different programming languages, such as: Java, C, C++ and Python

Working with open source products

You will enjoy a growing career as we work collaboratively to innovate the world of cyber security.

Additional information for your consideration...

You must hold UK Government clearance

Opportunities exist across the UK to enhance your career progression

Being a part of Northrop Grumman gives you the opportunity to use your skills to make a difference in our mission of enabling global security. Our company grows because of our employees' dedication and commitment to achieving our mission, something we always remember. In return for working for us you will have access to a benefits package that provides you with flexibility to balance your professional career with your personal life, health & well-being benefits, discount schemes, pension benefits and investment in your future development.

We are committed to equality and diversity in our workplace. Northrop Grumman provides equal employment opportunities to all employees and applicants without regard to an individual’s protected status, including race, ethnic origin, colour, nationality, national origin, ancestry, sex/gender, gender identity/expression, gender reassignment, sexual orientation, marriage/civil partnership, pregnancy/maternity, religion or belief, creed, age, disability, genetic information, or any other protected status or characteristic.",3.8,"Northrop Grumman UK
3.8","Cheltenham, England",-1,10000+ Employees,1939,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
Data Engineer,-1,"Data Engineer

Add

Email to a friend
Share:



Sector:IT/ICTLocation:UK & IrelandSub-location:AnyCurrency:£Job Type:Any

Salary Description:
Excellent Day Rate

Posted:
27/10/2020

Ref No:
CR/104177

Data Engineer urgently required to work on 6 months + contract.

Location: London / WFH

The ideal candidate will have an in-depth back ground working as Data Engineer within Central Government / GDS, Strong automatic testing, Oracle SQL server to Microsoft Azure , Strong understanding of Microsoft SQL Server, Azure and Power BI

Essential skills required:

Strong background in Data Engineering and Architecture.

Strong understanding of Microsoft SQL Server, Azure and Power BI

Strong mentoring skills

End-to-end data solutions and ELT/ETL pipeline development skills.

Data Warehouse and Data Lake solutions.

Desirable experience

Azure / Data Factory / Power BI

Experience in leading data engineering projects is a big plus. • Experience working with large-scale data environments

Please submit updated CV to apply + call to confirm your application and to review full JD.

Michael Bailey International is acting as an Employment Business in relation to this vacancy.",4.0,"Michael Bailey Associates
4.0",United Kingdom,-1,51 to 200 Employees,1989,Company - Private,Staffing & Outsourcing,Business Services,$50 to $100 million (USD),-1
Data Engineer,-1,"We’re looking to add a full-time Data Engineer to our team and build on our strong data foundation. You'll have complete technical ownership of our data platform, the ideal person would be ambitious, strong technically and a great communicator.

You’ll be responsible for:
Developing new ETL processes to support internal analytics - e.g. for business intelligence;
On-going monitoring and maintenance for existing ETL processes.
Running queries and creating dashboards to address ad hoc reporting needs.
Being an advocate and expert technical owner for our data platform.
Supporting the business with all data and data science related initiatives.
Creating data pipelines to integrate new data sources into the data lake – e.g. from across the business and from external 3rd party data vendors;
Tech Stack:
Python to write our application code.
Docker, ECS and Kubernetes to run our services.
Django as our Web App framework.
AWS for our infrastructure.
JavaScript frameworks, React is our chosen technology for frontends.
AWS Athena, Apache Airflow, S3, Apache Spark for our Data platform
Requirements

You should apply if you:
Have shipped code in high-level languages such as Python.
Are a competent Python developer that appreciates software engineering best practices.
Are comfortable working with relational databases such as Postgres.
Can write complex SQL queries for answering management questions - i.e. be able to use efficient joins, aggregations and window functions;
Have some experience in using workflow orchestration tools such as Apache Airflow;
Are comfortable working with AWS managed services such as S3, Athena and DMS; and,
Are self-motivated and able to operate independently.
Are comfortable working in a team that deals with challenging problems.
Have a tolerance for ambiguity and a willingness to get stuck-in;
Have a demonstrable ability to work to very tight deadlines in an exciting and fast paced start-up environment.
Have studied Comp Sci or STEM to degree level.
Nice-to-Have Experiences

If would be awesome if:
You're interested in data science and machine learning;
You have hands-on experience using Docker and Kubernetes;
You have experience creating BI dashboards using tools such as Redash, Apache Superset or Tableau;
You've had some exposure to the 'PyData stack' - i.e. Pandas, NumPy, SciKit-Learn, MatPlotLib and/or Seaborn; and,
You know how to manage data and compute services on AWS using infrastructure-as-code - e.g. AWS CloudFormation templates and/or Terraform.
Benefits
Competitive compensation (base + equity);
Flexible and remote working opportunities.
A compelling mission, to simplify lending for an underserved segment of society; and
An exceptional team, bringing diverse experience from the worlds of technology, strategy consulting, banking, private equity, hedge funds and credit.",-1,LiveMore Capital,United Kingdom,-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Lab49 is currently looking for a Data Engineer to help us build a strategic Risk calculation engine and associated workflows. The candidate will participate in the design and development of the platform, interacting with globally distributed Risk Officers (Market Risk, Credit Risk), Quants and IT Dev/QA team.
The successful candidate will:
Design and develop high-quality software solutions for Risk platform.
Create new modules & data flows to meet regulatory requirements (FRTB, GMETH).
Use Scala, Java or Python programming languages to build required functionality.
Implement data pipelines using big data/cloud technologies Apache Spark, Hadoop, Microsoft Azure Cloud (Data Lake, Data Factory, Batch) and Databricks.
Design and develop microservices using Spring Boot and Azure Kubernetes Service (PKS) cluster.
Profile Requirements
Expertise with Scala, Java or Python languages.
Experience with Spark, Hadoop, and Databricks (a must-have).
Experience with any of the Big-3 Cloud platforms - Azure (preferred), AWS or Google. Experience building data lakes and data pipelines in the cloud.
Experience designing high-performance, high-load systems.
Understanding of the distributed Agile SDLC model.

Preferred experiences:
Spark Developer certification is an added advantage.
Azure Data Factory, Azure Batch.
Expertise in Financial Services industry.",3.2,"ION
3.2","London, England",-1,1 to 50 Employees,-1,Unknown,-1,-1,$10 to $25 million (USD),-1
Data Engineer,-1,"We’re Chip. We’re here to make saving effortless, easy and fun. Our mission is to build the best savings app in the world.

We help people save up money automatically. In fact, we’ve automatically saved more than £150 million for tens of thousands of our savers already.

We’ve done all this by using AI, Open Banking and a disruptive approach to traditional banking.

Now, we’re helping people get better returns automatically, too.

You can open a market leading savings account in a couple of taps in Chip, as well as deposit, track and withdraw your money.

As you sit back, save and earn interest, we’ll keep going to the banks on your behalf to negotiate better rates.

This was a service that used to only be available to the super-rich, but we've done some clever things to pool Chip savers' money, so we can negotiate with banks like you're a millionaire.

Sounds pretty good, eh? And we’re just getting started.

Chip is being built by a fast-growing team of designers, developers, customer service professionals, marketers, banking experts, and entrepreneurs, with the backing of more than 11,000 investors and a huge community of Chip savers.
We’re growing fast, and we have some very exciting plans. So we need a Data Engineer to help us make them happen.

Good data should be the heart of any business and here at Chip we're striving for excellent data to empower us to make excellent decisions. Working alongside our engineering team we are looking to find a Data Engineer to help us collect, transform and store and serve that data across all sectors of the business.

We collect a lot of important data from all aspects of our business and we need engineers to help us write tools to ensure that data is accurate and consistent. Using any and all tools and languages necessary to give us the power to do everything from lending decisions to deciding which features we should develop.

What you can expect to be doing:

Develop robust ETL pipelines and automated processes for ingesting and processing data
Developing, managing and extending data warehouse and data models to provide a robust foundation for internal reporting.
Ensure best practices are followed with regard to security and infrastructure
Creating and maintaining relevant documentation
Spot opportunities for improvement on data engineering and business intelligence best practices
Advise on data modelling and reporting best practice
Working with the engineering team to ensure application design accommodates reporting and analytics requirements

What we’re really looking for

Advanced level knowledge of SQL and/or experience managing Data Warehouses
Knowledge of AWS and GCP cloud platforms
Confident getting hands-on with Python to process data and automate processes
Confident interacting with Databases and web APIs and processing data
Good understanding of reporting and data modelling best practices
Good written and verbal communication skills and an ability to translate problems into technical requirements and implement a solution.
Take requirements from someone non-technically minded, implement the solution and then explain your solution to a software engineer
Work within the Data team reporting to the Head of Data Engineering

What we’re really looking for: ✍️

Although we’re in the financial space, and under the scrutiny that comes with it, the current engineering team works well together, and even sometimes with a smile. We’re sure you’ve got the technical skills, otherwise you would have stopped reading by now, so let us be clear in what will make us want to work with you.

We want a real person, with interests outside of code, to join our work family. You could be a dancer, a gamer, a musician, a parent, a hockey fan, or even that one person that still writes Twilight fan-fiction. Doesn’t matter to us. At the interview stages will be looking for empathy, eq, fun stories, and ability to smile even when things are tough. Code monkeys need not apply.

PERKS

£45,000 - £50,000 per annum dependant on experience
Discretionary share option bonus every 6 months
Workplace pension scheme (Employer: 3% / Employee: 4% / Tax Relief: 1% / Total: 8%)
We are an equal opportunity employer and value diversity
Flexible working arrangements
Unlimited holiday (28 days contracted but policy not to count) ✈️
Free Classpass membership or gym membership
Company laptop
Based in the heart of Chancery Lane
Opportunity to have a huge impact on our product while fast-tracking your knowledge, responsibility and skills in a high growth fintech startup

Our Interview process:

Phone Screen with someone from our Talent team
Short take home test
Video interview with the hiring manager
Final Interview with HR

Note to Agencies

Chip does not accept unsolicited CVs from recruiters or employment agencies in response to any of our live roles on our career page. Chip will not consider or agree to payment of any referral compensation or recruiter fee relating to these unsolicited CVs. Chip explicitly reserves the right to hire those candidate(s) without any financial obligation to the recruiter or agency. Any unsolicited CVs, including those submitted to hiring managers, are deemed to be the property of Chip.",2.3,"Chip
2.3",Remote,-1,51 to 200 Employees,1986,Company - Private,Lending,Finance,$10 to $25 million (USD),-1
Data Engineer,-1,"Role: Data Engineer
Contracting Authority: Public Sector
Contract Length: 6 months
Location: London (work from home)
IR35: Inside

Knowledge and Experience required:

Proven experience of big data engineering techniques and concepts using the Hadoop Stack (Cloudera/EMR), including data ingestion, processing and storage using HDFS, Spark, Hive and Impala.
Extensive, hands-on experience of large complex Data Engineering projects designing and developing ETL pipelines in a cloud or on premise environment
Experience of design and implementation of data storage, including HDFS, S3, relational and NoSQL
Experience of developing/utilising programming and query languages e.g. SQL, Java, Scala
Monitoring performance and advising on any required infrastructure or changes.
A good understanding of data management, governance and quality frameworks, and how these integrate with big data solutions

Other:

This is the nice to have but not essential criteria

Strong stakeholder management skills and experience working with stakeholders across all grades and working with internal / external stakeholders to deliver results
Confident written and verbal communicator with the ability to present complex ideas in a compelling way to senior technical and non-technical audiences
Comfortable with Agile methodology and ability to manage diverse projects with changing user needs
Security Clearance will be required for this role, therefore only candidates who have continuous UK-based residence over the last 5 years will be considered",4.7,"Heat Recruitment
4.7","London, England",-1,51 to 200 Employees,2005,Company - Private,Staffing & Outsourcing,Business Services,$5 to $10 million (USD),-1
Data Engineer,-1,"Location: West London, however, role would support remote working

Salary details: £55,000 – £65,000 (depending on experience and qualification)

Contract: Permanent

Closing date: 10am Friday 20 November

Interviews: w/c 23 November, or as soon as suitable candidates are identified, so early application is strongly advised

Start date: Asap

About the role:

Ark Schools prides itself on having a sector-leading approach to information systems and data analysis. With ambitious plans to embed advanced analytical practices, we are looking for a Data Engineer to help us to optimise our data architecture, pipeline and flows so that they continue to support the network’s analytics and reporting needs.

This is a fantastic opportunity if you’d like to:

Take on a key role in defining and delivering Ark’s future data and analytics platform, enabling us to fully leverage the value of the data we hold for our c.28,500 students across 38 schools
Be pivotal in supporting the organisation to move towards advanced analytical practices
Work for an organisation that exists to make sure that all children, regardless of their background, have access to a great education and real choices in life

If preferred, the role would be suitable for remote/flexible working, with periodic travel to Ark’s central office in West London.

About you:

5+ years’ experience in a data engineer or similar BI role, and have attained a Graduate degree (or relevant professional experience) in Computer Science, Statistics, Informatics, Information Systems or another quantitative field
A strong understanding of best practice and emerging data systems, and demonstrable experience in these areas
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases (e.g. Postgres)
Able to demonstrate a successful history of manipulating, processing and extracting value from large, disconnected datasets
Able to quickly understand and become familiar with new data sets – particularly if new to education
Aligned with the Ark Schools' vision and values

About Ark:

Ark is an international charity, transforming lives through education. We exist to give every young person, regardless of their background, a great education and real choices in life. In the UK, we are a network of 38 schools, educating around 28,500 pupils in areas where we can make the biggest difference. We also incubate start-up programmes (Ark Ventures) that improve the education system.

We offer:

27 days annual leave plus bank holidays, rising with each year of service
We are committed to providing high-quality professional learning throughout your career with us and offer a variety of training sessions and experiences designed to meet your needs
Access to Ark Rewards scheme offering savings from over 3,000 major retailers, interest-free loans available for season tickets or a bicycle and gym discounts offering up to 40% off your local gym

How to apply

Apply with a CV and cover letter on our online recruitment portal. Applications to be submitted by 10am on Friday 20 November 2020 but please note: we will be reviewing applications on an on-going basis and this advert may close earlier than advertised depending on the level of response.

Interviews will be arranged as suitable candidates are identified, so early application is strongly advised

Ark is committed to safeguarding and promoting the welfare of children and young people; all successful candidates will be subject to an enhanced Disclosure and Barring Service check.

Ark Schools are committed to attracting, developing and retaining a diverse workforce, with a broad range of backgrounds, experiences and perspectives.",-1,Ark Schools Central,"London, England",-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Our people love the exciting and meaningful work they do, the cutting-edge resources and technology they have access to, the benefits we offer and the great community we’ve built. Want to join them?

The Senior Data Engineer is responsible for designing and developing data processing and data persistence software components for solutions which handle data at scale. Working in agile teams, Lead Data Engineers providing strong development leadership for team members and take responsibility for the quality of the codebase as well as the match to user needs.

Most of our work comes through repeat business and direct referrals, which comes down to the quality of our people. The success of our Data Engineering teams means that customers are bringing us an increasing number of exciting data projects using cutting-edge technology to solve real-world problems. We are seeking more high calibre people to join our Data & Analytics capability where you will grow and contribute to industry-leading technical expertise.

Essential Experience
Software development experience with distributed data storage and processing technologies including Hadoop and Spark and using JVM languages.
Experience of leading the development of substantial components for large-scale data processing solutions, taking responsibility for non-functional needs of ETL/ELT data processing pipelines such as robustness, performance and security. ‘Development’ incorporates design, code, test defect resolution and operational readiness, and includes setting the standards for these activities.
Coaching and mentoring experience in data development disciplines with the ability to gain the respect of a junior team.
Ability to advise architects and other stakeholder on detailed technology and development practice and on development estimates.
Ability to make effective decisions within fast-moving Agile delivery and to lead on troubleshooting.
Strong understanding of tools, design methodologies and best practice.
Ability to clearly communicate technical design both written and verbally.
Desirable Experience
Software development experience with Cloudera’s distribution of Apache Hadoop and with Python.
Experience of data visualisation and data complex data transformations, including ETL tools such as Talend.
Able to productionise machine learning algorithms.
Understanding of text processing including Natural Language Processing.
Experience with steaming and event-processing architectures including technologies such as Kafka and change-data-capture products.
Data modelling experience with data storage technology, such as document, graph, log stores and other non-relational platforms.
Open source contributor
Kainos is a professional services organisation with clients spread across the globe and we deliver projects both from client site, and from our offices. While we will attempt to base you on projects near or at your contracted office location, you need to be willing to travel to client sites and spend time away during the week if it is required.

Given the range and nature of work that we carry out for our clients, all Kainos employees are required to possesses up to date security clearance (Basic Disclosure, Access NI etc), if you do not already possess this, you will be asked to apply for it prior to joining Kainos.

Everyone who is offered a position here undergoes a background check; whether a criminal record excludes you from a career with Kainos depends on the role and the offences.

WHO YOU ARE:
Our vision is to enable outstanding people to create digital solutions that have a positive impact on people’s lives. Our values aren't abstract; they are the behaviours we expect from each other every day and underpin everything that we do. We expect everyone to display our values by being determined in how obstacles are overcome; honest when dealing with others; respectful of how you treat others; creative to find solutions to complex problems and cooperative by sharing information, knowledge and experience. These values, applied collectively, help to produce an outstanding Kainos person, team and culture.",4.1,"Kainos
4.1","Leeds, England",-1,1001 to 5000 Employees,1986,Company - Public,IT Services,Information Technology,$100 to $500 million (USD),-1
Data Engineer,-1,"Data Engineer

You will act as a key member of the Azure Data Team, working directly with various

stakeholders from across the business, designing stable and reliable data warehousing technology that surfaces the data our business uses, proactively monitoring the company's data warehouse and participating in the design and implementation of the associated data pipeline technology that moves data from our operational systems to the data warehouse.

PRINCIPLE DUTIES AND RESPONSIBILITIES

The responsiblities for this role will be:

● Developing the data warehouse platform

● Collaborating with operational Systems Owners to identify issues with existing pipelines

● Designing stable, reliable and effective data pipelines

● Providing data design consultancy to operational Systems Owners

● Providing expert data and domain advice to Management Information specialists

● Contributing to data technology roadmaps

● Schema design and data modelling

● Ensuring the data warehouse technology complies with operational and service management standards

● Managing data technology across distributed Azure Regions and Technology

● Escalating data problems to operational Systems Owners

● Researching and suggesting new data products, services and technologies

● Working in a 24x7 high-availability environment

● Providing on call support including out-of-hours incident support

Requirements

As an exceptional applicant, with a proven track in a similar role, you will have:

● Experience in developing, building and deploying solutions based on Microsoft Azure SQL, Databricks, Data Factory and Blob Storage

● Infrastructure as Code technologies

● Ability to produce production-quality code using git source control

● In-depth understanding of data management

● Ability to quickly understand new schemas

● Ability to convert business requirements into data pipelines

● Experience of working with MI/BI Analysts/Visualisers

● Performance tuning of Azure Data Technology

Benefits

How would you like to make business communication brilliant! Working with more than 45,000 clients, helping them to transform their mobile communication. To thrive in this role you will enjoy working in an environment of passion, integrity, ownership and innovation, where development and progression is a real focus.

With regards to benefits package, you should expect 27 days holiday and your birthday off work, to private medical cover, dental cover and bi-monthly social events! On top of this you can expect £350 of Christmas vouchers and added extras like beer o’clock and an amazing Christmas party (after Covid restrictions).

To apply contact Charlene now for information by clicking apply!

As an exceptional applicant, with a proven track in a similar role, you will have:

● Experience in developing, building and deploying solutions based on Microsoft Azure SQL, Databricks, Data Factory and Blob Storage

● Infrastructure as Code technologies

● Ability to produce production-quality code using git source control

● In-depth understanding of data management

● Ability to quickly understand new schemas

● Ability to convert business requirements into data pipelines

● Experience of working with MI/BI Analysts/Visualisers

● Performance tuning of Azure Data Technology",5.0,"Park Lane Recruitment Ltd
5.0","Nottingham, England",-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"We are recruiting for a Data Engineer to join our TP&A Process Team within Aviva.

Data is the lifeline of any modern organisation and Aviva is no different. The role sits within a team responsible for the data pipeline that provides Quantum Data Science Practice (covering areas like Machine Learning and AI, Pricing, Financial Crimes, Fraud and Underwriting) with the data they need to provide our customers with the best products.

This is an exciting opportunity to work within our Oracle Cloud environment, which is helping to craft the future of insurance through ground-breaking data delivery to predictive analytics and Data Science. As a team we are part of Aviva’s global Data Science Practise (Quantum) which is recognised as a centre of excellence - providing an Oracle Cloud platform that delivers the data needed to drive improved decision making and performance within Aviva.

Duties & Responsibilities:

Undertake application design, development and testing work to ensure delivery of robust Data applications, enhancements and meeting the needs of the customers.

To work closely with other members of the development team, the I.T. department and with other teams in Quantum Data Science on an ongoing basis.

To contribute during planning meetings, requirement gathering, and meetings with application stakeholders.

Tasks will also include production of relevant technical documentation to support the application.

Skills & Experience required :

Degree, diploma or Computer Science or equivalent numerate subject or equivalent relevant experience and knowledge.

Experience using SQL and PL/SQL, preferably in a financial services environment.

Good knowledge of general insurance.

Knowledge of System Design and Application Development Lifecycle.

Knowledge of other Development Languages including Python, R, Informatica would be advantageous.

Organised self-starter, with drive and commitment; able to work independently with little supervision.

What will you get for this role?

Salary of circa £25,0000 depending on skills, experience and qualifications.

Generous defined contribution pension scheme.

Annual performance related bonus and pay review.

Holiday allowance of 29 days plus bank holidays and the option to buy/sell up to 5 additional days.

Up to 40% discount for some Aviva products through “My Aviva Extras” plus discounts for Friends and Family. (Some exclusions apply).

Excellent range of flexible benefits to include a matching share save scheme.

Working at Aviva

At Aviva, we’re people with a purpose. To be with you today, for a better tomorrow.

We bring this to life by ensuring managing risk is at the heart of the way we all work. We love people who do the right thing for our customers, and our colleagues. We want people who speak up, who take responsibility, and who make good decisions.

The way we do this is important too. We always ‘Care More’. It’s our thing. We’re all about our people – that’s you – so we can be pretty flexible. If you want to work from home some of the time or change your hours so you can pick up your kids or care for someone in your family, we’re very open to that. In fact, we don’t advertise roles as either part or full time, because we know each person has different needs, just as each business area has different needs. So, it’s up to you to discuss working hours during your interview.

We care deeply about being inclusive and that means we encourage applications from people with diverse backgrounds and experiences. We want our employees to bring their whole self to work and that starts with you.

We interview every disabled applicant* that meets the minimum criteria for the job . Just send us an email once you’ve applied stating that you have a disclosed disability and we’ll make sure we interview you.

We’d love it if you could submit your application online . If you require an alternative method of applying, please give Alice Neal a call on 0121 200 5926 or send an email to alice. neal@aviva.com.
As defined in The Equality Act 2010 *. By ‘ minimum criteria’ we mean you should provide us with evidence which demonstrates that you generally meet the level of competence required and have the qualifications, skills or experience defined as essential to perform the role.",3.6,"Aviva
3.6","Norwich, England",-1,10000+ Employees,1861,Company - Public,Insurance Carriers,Insurance,$5 to $10 billion (USD),-1
Data Engineer,-1,"Would you like to help create a brand-new engineering organisation? Perhaps you know what great engineering culture looks like, or you have an entrepreneurial side as well as outstanding coding skills? Whatever your aspirations, we’re trying to create the best engineering consultancy in the UK and looking for brilliant engineers to be part of the journey.

About DMW Engineering
DMW helps organisations solve their biggest, most exciting engineering problems. We’ve created banks from scratch on Kubernetes and AWS, built streaming analytics solutions that protect the country and built platforms to enable whole organisations to move to AWS and Azure, and everything in between. We do all this in a work environment where regular social events, inclusivity and an ego-free culture mean we’ve been officially voted a “Great Place to Work” for five years in a row.
We’re not interested in cutting corners and believe in helping our clients to make the right choice for the long-term. We draw on our reputation for outstanding delivery to allow our engineers to do the right thing for our clients, and not necessarily the easy thing. Innovation is in our DNA, and we encourage our engineers and consultants to work together to rethink conventional wisdom on how problems should be solved.
Location:
Based in the vibrant and modern Labs House, we are a stone’s throw away from Holborn station. Boasting coffee lounges, co-working spaces, ping pong/table tennis tables, free on-site gym and weekly yoga classes all the way through to fortnightly free breakfasts.
Here’s what you will do (Not all of it, but some of the important stuff!)
• Solve the problems others cannot
• Spend a day a week working on a combination of internal products and your own development
• Create data platforms based around modern open source products and cloud-native technologies:
• AWS, Azure and Google Cloud
• Python
• Kafka / NiFi / Flume
• DB technologies: SQL Server / PosteSQL / MySQL
• Hive/Spark/Impala
• Dataiku
• Terraform
• Kubernetes

Requirements:

The essentials?
• Experiece building data platforms using either cloud native products or commercial data analytics / data warehouse software
• Working knowledge of data pipelines & data transformation processes
• Experience creating and/or maintaining production software delivery pipelines using common CI/CD tools (e.g. Jenkins, GoCD, CircleCI)
• Demonstrable experience in automating operations tasks with one or more scripting languages
• Experience working with one or more of the main cloud providers (AWS, Azure or Google)
• Have a drive for self-improvement and learning, including learning new programming languages
• Approach solving problems pragmatically
• Experience of Hadoop big data platforms (either Cloudera / Hortonworks or cloud native equivalents)
• Experience with data reporting and visualisation tools (PowerBI, Tableau, Qlik)
• Experience productionising machine learning algorithms
• Experience with Infrastructure as Code (e.g. Terraform, Cloudformation)
• Experience supporting and operating production systems
• Familiarity with configuration management tooling (e.g. Ansible)
It would be great if you had these desirable skills • Experience of Hadoop big data platforms (either Cloudera / Hortonworks or cloud native equivalents)
• Experience with data reporting and visualisation tools (PowerBI, Tableau, Qlik)
• Experience productionising machine learning algorithms
• Experience with Infrastructure as Code (e.g. Terraform, Cloudformation)
• Experience supporting and operating production systems
• Familiarity with configuration management tooling (e.g. Ansible)

Benefits:

We’ve grown consistently over the years and offer an entrepreneurial environment within which to embark upon an exciting career path, where your contribution really counts, and we will recognise it. With personalised development opportunities, experienced colleagues and challenging client assignments, progression can be extremely rapid for high performers. We are a social bunch of people and go out as a team on a regular basis. You can also expect:
• A highly collaborative working environment and great rates of pay (including base salary and bonus potential).
• A range of flexible benefits consisting of well-being and lifestyle benefits.
• A commitment to your development & continuous growth of skills through one-to-one mentoring and wide-ranging hands-on experience.
• 25 days’ holiday and the ability to flex this to 30 days if you chose to do so.
• 2 day’s CSR volunteering days.
• Award-winning learning and development opportunities, including dedicated personal training budgets and time and a wide range of choice in training courses.
• A dedicated personal budget to choose the IT equipment of your choice.",4.7,"DMW Group
4.7","London, England",-1,51 to 200 Employees,1989,Company - Private,IT Services,Information Technology,$10 to $25 million (USD),-1
Data Engineer,-1,"Job Title: *Data Engineer
Job Type: *Contract/ Temporary
Duration: *6 Months
Rate: *£432.34 per day
Location: *London
IR35 Status: *In scope
Security Clearance: *SC Clearance is required
Essential Experience:
Strong background in Data Engineering and Architecture.
Strong understanding of Microsoft SQL Server, Azure and Power BI
Track record that of implementing end-to-end data solutions and ELT/ETL pipeline development skills.
Maintain and optimize the Data Warehouse and Data Lake solutions to maximize performance.
Experience working with solutions in the Cloud
Implement dashboards on Power BI for data analysis.
Strong experience with SQL.
Good documentation experience.
Ability to communicate well with key stakeholders and non-technical audiences.
Desirable experience required for the Data Engineer includes:
Experience in leading data engineering projects
Experience working with large-scale data environments in a data engineering role
Experience in working with teams of Data Scientists
Microsoft Azure related Certifications
Experience working with Big Query
Please ensure your submitted CV has all gaps in employment explained. So, if you were looking for employment during any gaps please state this on your CV.

Ensure your CV fully covers all the criteria stated above to maximise your chances on being successfully placed for this role.

Let us know of your availability and whether there are any specific dates if you are unavailable to attend an interview. Notifying us of any holiday dates is advantages and allows us to notify parties in advance so they can plan accordingly.

All CVs received are acknowledged and held for the job applied for. If you would like us to remove your details at anytime please do let us know in writing so we can remove all your details accordingly.

By applying to this role you are giving us your permission to represent you by submitting your CV (by way of right to represent) unless you inform us otherwise. You will also be required to confirm whether you wish to Opt-in or Opt-out of Conduct Regulations. For your protection, we will assume you are Opting-in unless you inform us otherwise.

We wish you the best in your search for an ideal role and look forward to hearing from you soon.

Please note, we try to remove roles advertised as they become unavailable in a timely manner. If you have applied for a role and it is no longer available we will inform you as soon as possible.

AJACO is an equal opportunities employer.

Contract length: 6 months

Job Types: Full-time, Temporary

Salary: £432.34 per day

Experience:
Microsoft SQL Server: 1 year (Required)
Working with Data Scientists: 1 year (Required)
Data Engineering: 1 year (Required)
Licence:
SC Clearance (Required)
Work remotely:
No",-1,AJACO,"London, England",-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"My client is a great success story that grew from being a start up to one of the market leaders in their field today.
The role, the team, what you will be doing*
This team is responsible for building out the platform that powers all personalisation on site. This is a high impact team aiming to show the right product, to the right customer, at the right time.

The team use machine learning to rank search results and recommend the perfect offering to the customer base.

The team are iterating on current algorithms and are looking for someone who can bring more experience and new ideas to the team. This is the next chapter of personalisation in the business so a real opportunity to shape a core part going forwards.

They work in cross-functional teams where every data engineer is both a member of the wider Data community and fully embedded into a cross-functional team alongside engineers, data scientists and product managers.

As a data engineer within Personalisation, you’ll support the team in meeting their goals, using their priorities to build out new capabilities in the Data Platform in line with the Architectural strategy. You'll be able to build, deploy, operationalise and monitor data systems with a focus on security and reliability.

You’ll also work closely with the Data Scientists to apply Continuous Delivery and DevOps principles to model training and deployment. You'll have experience in a variety of data modelling approaches, really understand the challenges that come with working with very large data sets.

You’re comfortable working with structured, unstructured and semi-structured data, have practical knowledge of event driven approaches and tooling, and you get a real kick from performance tuning.

As part of the wider Data team, you’ll play a key role in shaping the technical direction of the platform and approach to data.

You’ll bring robust engineering practises including TDD and pair programming, along with hands-on experience of building scalable pipelines and re-usable infrastructure.

The team are evangelists of agile values and principles but each team is responsible for their own way of working.

All members of the team have the opportunity to help influence the teams’ processes through a continuous improvement mindset. Working in a fast paced, low ceremony environment and deploy multiple times a day.

They use a variety of programming languages across teams such as Ruby, C# and Python so polyglot thinking is a must.
What are they looking for?*
Working in cross-functional teams (e.g. Engineers, Product Owners, etc.) in an agile environment
Strong working knowledge of Python and R, experience of robust engineering practises including TDD and pair programming
Experience working with Data Scientists to apply DevOps principles to model training and deployment
Extensive SQL experience including performance, query optimisation and data modelling
Experience of testing and automation processes associated with big data solution development
Demonstrable history of manipulating, processing and extracting value from large disconnected datasets
Experience building data pipelines at scale using a range of tools and technologies
Experience with data lakes, message queuing, stream processing, and highly scalable big data stores
Understanding of the governance and security challenges associated with data
Commercial experience working with big data tooling from at least one major cloud vendor (AWS, Azure, GCP) including the development, setup, configuration and monitoring of solutions running on these platforms
The essentials*
Agile environment
Python and R
Experience of robust engineering practises including TDD and pair programming
Reference ID: FRC3056

Job Types: Full-time, Permanent

Salary: £50,000.00-£60,000.00 per year

Benefits:
Casual dress
Company events
Discounted or free food
Employee discount
Flexible schedule
Free or subsidised travel
Private dental insurance
Private medical insurance
Profit sharing
Work from home
Schedule:
Monday to Friday
Work remotely:
Yes",-1,Fox-Rees Consulting,"Manchester, England",-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data focused business, by maintaining and enhancing a new Snowflake Data Warehouse, along with development of Power BI dashboards to replace existing reports.

As the Data Engineer, you will be responsible for developing dashboards and visualisations to ensure the company is getting the most out of its data. You will also be designing and developing data pipelines, using all the latest technology.

This role allows the successful candidate the opportunity to learn new skills on technologies such as Snowflake, Wherescape, Redgate and many others, particularly as the business needs change and evolve. Using these technologies, you will be largely involved in rolling out and integrating new data products within the wider company, to meet business needs.

Key skills and experience required for the Data Engineer Role:

Proven experience within a data warehouse focused role.
Strong experience of using ELT/ETL based approaches to develop solutions.
Previous experience with Snowflake is highly beneficial.
Hands on experience building data visualisation and dashboards from scratch.
Experience with using SQL.
Experience with using Power BI (Dax).
Excellent stakeholder management skills.

Data Engineer: Data, Data Engineering, BI Development, BI Developer, Dax, Wherescape, Power BI, Snowflake, Azure, SQL, Git, Jenkins, Redgate, DataOps, Data Pipelines, ELT, ETL

Location: Hove

Salary: £45,000 - £55,000 (depending on experience) + bonus + benefits (including flexi-working, work from home, private medical, pension plan)

Apply now for further details and immediate consideration.
Understanding Recruitment is acting as an employment agency for this vacancy",4.5,"Understanding Recruitment
4.5","Hove, England",-1,1 to 50 Employees,2007,Company - Private,Staffing & Outsourcing,Business Services,$1 to $5 million (USD),-1
Data Engineer,-1,"Marex Spectron is a global leader in the commodities industry, broking and trading across most asset classes. Based next to Liverpool Street station, we are a short walk from most of the tube stations and British Rail stations in the square mile as well as Shoreditch High Street on the London Overground network.

The last few years have seen our organisation grow rapidly in terms of both size and complexity. We've acquired businesses, opened offices in new locations, joined new exchanges, added new products and asset classes, all within an ever changing regulatory environment against a background of geopolitical instability.

We are currently looking for someone to join our team and scope out then lead the development of a high-availability, easily scalable data platform to be used across the business. This platform will be used to collate, organise, store and process vast amounts of structured and unstructured data, developing efficient data pipelines and allowing us to effectively and efficiently analyse our information as well as creating new heterogenous data sets for further consumption and analysis.

You will have already gained significant experience in the field, having already built large data platforms with teams of data engineers and scientists. You will be familiar with agile and scrum methodologies, used to working on organically evolving projects. Your communications skills will be highly advanced, you'll be adept at getting to the root of what is required and have the problem solving-ability to create systems that elegantly fulfill the needs of the business. In terms of technical skills, you will have experience of cloud-based enterprise solutions and will have worked with some or all of: SQL Server, Oracle, MongoDB, Data Warehouse, Data Lake, Apache Kafka, Python, Javascript/Typescript, Apache Spark and PowerBI as well as other components of the Microsoft Power Platform.

If you're looking for a role where the tools you build influence and advise strategic decision-making at the highest level in a nimble and ambitious organisation, if you thrive in complex, dynamic environments and have an innate sense W(with some corresponding experience) of the opportunities that effective data analysis can unlock, we'd love to hear from you!

#LI-MH1",3.5,"Marex Spectron
3.5","London, England",-1,501 to 1000 Employees,2006,Company - Private,Brokerage Services,Finance,$100 to $500 million (USD),-1
Data Engineer,-1,"Data Engineer Role!

What you’ll be doing?

· Work with the applications and database team to meet the key business strategies and objectives.

· Development of the warehouse to encompass more sources and additional datasets

· Create and maintain SQL procedures, User Defined Functions and Views to support and maintain new and existing reporting requirements.

· Proactively improve the performance, logical structure, physical structure and availability of the Data Warehouse and other reporting environments

· Issue resolution for any incoming data inconsistencies

· To support the build and maintenance of the Data Warehouse

· Work as part of the team to build and maintain the data reporting environments

· Using SQL services, SSAS and MDS to support the existing business solutions and technologies

· Work as part of the team to provide application and reporting development services/support

· To work with the team to ensure that core applications and strategies are aligned",3.1,"QA Limited
3.1",Remote,-1,1001 to 5000 Employees,1985,Company - Private,Education Training Services,Education,$100 to $500 million (USD),-1
Data Engineer,-1,"DATA ENGINEER – BIRMINGHAM

Role Overview

We are currently recruiting for an Data Engineer to join our Information Technology team in Birmingham. The Data Engineer will be involved in helping to define, build, and maintain a robust data platform and information architecture. You will be joining a team in the early stages of a large digital transformation focused on bringing improvements in data management practices to the firm.

Candidate Overview

We are looking for an organised, highly motivated and enthusiastic individual who has the ability to work under pressure and adapt to new technology. Experience in using architecture frameworks such as TOGAF and data management frameworks such as DAMA.

What can we offer you?
Join a global, innovative and forward thinking firm;
Access to training and development to refresh or enhance your current skillset;
The opportunity to work agile;
Competitive salary and benefits package, including 25 days holiday, private healthcare and contributory pension.
Firm Introduction
Pinsent Masons is an international law firm that ranks amongst the top 75 law firms globally, with a long-standing reputation for delivering high-quality legal advice rooted in its deep understanding of the sectors and geographies in which its clients operate.

We know that our culture sets us apart, and with over 1,500 lawyers operating from 24 locations throughout the UK, Europe, Asia Pacific, Africa and the Middle East, it is at the heart of our success as a leading international law firm. Our core values are Approachable, Bold and Connected and as a firm we hold these in high regard. Personally and collectively, we live them every day and our firm is a better place for it.

Pinsent Masons stands out in particular for its innovative approach to service delivery and in 2016 we were ranked among the five most Innovative Law Firms in Europe.

For any queries or for a copy of the full job description then please contact our in-house recruiter Glenn Wilshaw. Please note we only accept CVs that are logged on the Recruitment portal.

#LI-LINKEDIN",3.9,"Pinsent Masons
3.9","Birmingham, England",-1,1001 to 5000 Employees,-1,Company - Private,Legal,Accounting & Legal,$100 to $500 million (USD),-1
Data Engineer,-1,"Position: Data Engineer, Remote & 1 day onsite in Crewe

Location: Crewe / Manchester / Remote - Based onsite at our Head Office in Crewe CW1 6BD one day a week.

Radius Payment Solutions are a leading Global Fleet Management Company who offer services in the Fuel, Telematics, Telecoms and Insurance industries. Our wide range of products include Fuel Cards, Vehicle Tracking Devices and Phone Tariffs. We are a successful growing global company with offices across 15 countries.

We are looking for a driven Data Engineer to join IT Innovation Team.

Why choose Radius?

· 24th in UK Top Track 100 company;

· Rapidly expanding global company with an entrepreneurial mindset;

· Internal talent development programme;

· Secondment opportunities to work in our international offices;

· Innovative, technology driven culture.

What will you be doing as job title?

At Radius, we deal with a number of very large data sets, the largest of which is our detailed telemetry for the vehicles we track.

These vehicles cover hundreds of millions of miles per month and we record every significant piece of driver behaviour data we can capture during those journeys, as well as recording the location, speed and heading of the vehicle at regular intervals.

This data set has created the need for new tools, practices and processes. We are making use of data science, machine learning and interactive visualisations to gather insights from this data, in order to build better products and innovate for our customers. We also use these same technologies to develop our product strategy internally. We recently presented our work on using unsupervised machine learning to process our fuel station data and to visualise our market share.

Key to our success in applying these technologies to our rapidly growing, innovative organisation, are the people we employ.

What experience / skills are we looking for?

Technologies we use for our work with data include:

Cassandra

Apache Spark

ML

ActiveMQ

Python

Pandas

AWS S3, Redshift, Lambda

Tableau

What benefits do we offer?

· Newly built Global Headquarters/ Newly refurbished sales office with onsite gym, break out rooms and canteen. Other facilities include PlayStation 4, table tennis and pool table;

· Excellent training and coaching;

· Friendly & supportive team working environment that encourages opportunities for self-development;

· Fantastic opportunities for ongoing development and progression;

· Life assurance and pension;

· Local and online discounts including discounted restaurants, travel, entertainment tickets with BenefitHub;

· Employee Fuel Card (after one year);

· Employee Assistance Programme;

· Cycle to work scheme;

· Service Awards;

If you like working on challenging problems in interesting domains, with a focus on innovation, then I'd like to speak to you - call Melanie Bose on +441270 507376

Radius Payment Solutions has an in-house recruitment team who are dedicated to sourcing candidates directly and as such we do not accept speculative CV's from agencies. We do have a preferred list of suppliers who we ask to support us on roles where necessary. We do not pay agency fees where speculative and unsolicited CV's are submitted to the business, whether that is to hiring managers or to the Recruitment Team. The only way we accept CV's is through our recruitment portal under instruction from the Radius Payment Solutions Recruitment Team.

Remote Working Data Engineer Big Data Spark Data Scientist Data Engineering",3.0,"Radius Payment Solutions
3.0","Crewe, England",-1,1001 to 5000 Employees,1990,Company - Private,Financial Transaction Processing,Finance,$2 to $5 billion (USD),-1
Data Engineer,-1,"Data Engineer

https://www.templeton-recruitment.com/job-search/3160-data-engineer/big-data-analytics/uk/job2019-05-21 21:50:522022-02-19
Templeton Recruitment
Job Type Contract
Location
London
Area

UK

UK

UK

London

Sector Big Data & Analytics
Salary Market related
Start Date ASAP
Job Ref KW-29789

Description

Templeton are seeking a Data Engineer for our global client to work on an exciting, cutting edge digital/analytics project based out of their London office.

You will have the opportunity to use modern technologies and to work with a cutting-edge data science platform using Pachyderm on top of Kubernetes.

The need strong technical expertise in Data Engineering, but beyond that this is an opportunity to help a global enterprise setup a best-practice data science process, to help them determine the direction of future tooling, and to be a central part of a team that will spearhead how the company engages in Data Science.

Essential
Strong experience with Python and relevant libraries (PySpark, Pandas, etc).
The ability to work across structured, semi-structured, and unstructured data, extracting information and identifying irregularities and linkages across disparate data sets.
Meaningful experience in Distributed Processing (Spark, Hadoop, EMR, etc).
Deep understanding of Information Security principles to ensure compliant handling and management of client data.
Experience working collaboratively in a close-knit team and in clearly communicating complex solutions.
Experience in traditional data warehousing / ETL tools (SAP HANA, Informatica, Talend, Pentaho, DataStage, etc)
Experience and interest in cloud infrastructure (Azure, AWS, Google Platform, Databricks, etc) and containerisation (Kubernetes, Docker, etc).
At least 5 years of relevant experience.

Desirable
Experience programming with Julia.
Experience or interest in building robust and practical data pipelines on top of cloud infrastructure (Pachyderm, Kubeflow, etc).

To include as part of your application
Links to online profiles you use such as Github, Twitter etc.
A description of your work history (whether as a resume, or LinkedIn profile).",3.5,"Templeton & Partners
3.5","London, England",-1,51 to 200 Employees,1996,Company - Public,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Data Engineer,-1,"Our product is all about collaboration and innovation. So are our people. We’re a small team, but we’ve got a big vision: to build a brand new infrastructure for operational risk management. It’s not easy. We’re redefining the way some of the world’s biggest financial services companies and banks work with data. There are a lot of challenges – but a lot of opportunities to think and act creatively, too.

We’re growing fast. We’ve just closed our Series A funding round, led by Notion Capital – one of the world’s leading VCs – and financial information specialists Fitch Ventures. Now we want to scale our world-class team.

We’re looking for people who are energetic and curious; people who are persistent and resilient; people who like tackling problems and take pride in building best-in-class solutions to them. Being a part of the Acin team means creating the operating system for a safer financial future from scratch. We think it’s a pretty exciting prospect.

If you think the same, this could be the role for you.

The Role

We're looking for an ambitious Data Engineering to join our growing Engineering team.

Our Engineering team is split into two main disciplines - data and front end. The data team is responsible for the management of our data assets and driving business benefit from them. Working alongside our front end team who work with these data assets to deliver value to customers in an attractive, informative fashion.

In terms of tech, we primarily use Microsoft Azure components. The future tech landscape is for the team to shape - we expect to explore NLP in the near future and we're open to use of all technology as long it demonstrates value.

Our technology stack uses primarily Microsoft Azure components, but we are open to use of all technology as long it demonstrates value.

In this role, you will be responsible for:
Data Design and Modelling – defining the Acin logical and physical data structures
Data Work Flow - data development, data structuring, version management (data best practice, sql, graphing techniques)
Data Ingestion - analysis and development (python, sql, web scraping)
NLP/Matching - engine development (python)
Data insights – identification and development of new data insights (data mining and visualisation, power bi, r, python)
API - business logic development (c#, open api)
Requirements
What we are doing at Acin excites you!
You’re energised about data problems and using technology to solve them
You enjoy working with other developers and designers, leading them to great outcomes
You can demonstrate a good working knowledge of data technologies (Azure is a bonus!)
You have: strong data design and development skills; SQL, Python experience; experience with DevOps development environments
Have a passion for data centric systems or data
You have worked in an agile minded development team
You’re highly organised and have great prioritisation skills
You’ve got patience, tact, diplomacy and approachability with the ability to develop effective working relationships with employees at all levels
You possess an intellectual curiosity and bring valuable insight into the team
Benefits
25 days holiday
Medical Insurance including Dental & Optical cover
Life Insurance
Perkbox Subscription
Pension Scheme",-1,Acin,"Farnborough, Hampshire, South East England, England",-1,1 to 50 Employees,-1,College / University,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Who We Are:

Take-Two Interactive Software, Inc. is a leading developer, publisher, and marketer of interactive entertainment for consumers around the globe. For more than 25 years, our development teams have created some of the most critically acclaimed and commercially successful entertainment experiences, captivating and engaging audiences around the world. We are incredibly proud of our ability to deliver consistently the highest-quality titles, as well as our colleagues who help to create our unique culture and work environment that is inclusive, diverse, and dynamic.

While our offices are casual and inviting, we are deeply committed to our core tenets of creativity, innovation and efficiency, and individual and team development opportunities. Our industry and business are continually evolving and fast-paced, providing numerous opportunities to learn and hone your skills. We work hard, but we also like to have fun, and believe that we provide a great place to come to work each day to pursue your passions.

The Challenge:

A dynamic Python Data Engineer to join a team building a cloud-based data and analytics platform. The Data Engineer will craft, build, and maintain reliable and scalable data pipelines.
Develop data quality framework to provide transparency into data quality across systems (timeliness, accuracy, completeness, etc.) and ensure delivery of high-quality data to business teams.
Provide thought leadership and collaborate with other team members to continue to scale our architecture to evolve for the needs of tomorrow.
Maintain API based ETL/ELT processes from multi source raw data collection to reporting/visualization.
Develop and support continuous integrations build and deployment processes using Jenkins, Docker, Git, etc.
Define and implement monitoring and alerting policies for data solutions.
What You Bring:
2+ years of hands-on experience in Python.
3+ years of hands-on experience in using sophisticated SQL queries and writing/optimizing highly efficient SQL queries.
Experience integrating with 3rd party APIs.
Comfortable working with business customers to collect requirements and gain a deep understanding of varied business domains.
Experienced in testing and monitoring data for anomalies and rectifying them.
Knowledge of software coding practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations.
Preferred Qualifications:
Python (required)
SQL (required)
Git (required)
Developing solutions using Docker (required)
Data modeling for data warehousing (nice to have)
Developing microservices (nice to have)


What We Offer You:
Great Company Culture. We pride ourselves as being one of the most creative and innovative places to work, creativity, innovation, efficiency, diversity and philanthropy are among the core tenets of our organization and are integral drivers of our continued success.
Growth: As a global entertainment company, we pride ourselves on creating environments where employees are encouraged to be themselves, inquisitive, collaborative and to grow within and around the company.
Work Hard, Play Hard. Our employees' bond, blow-off steam, and flex some creative muscles – through corporate boot camp classes, our onsite Gym, company parties, our Office bar, game release events, monthly socials, and team challenges.
Benefits. Benefits include, but are not limited to Private healthcare with Bupa, Private dental with Bupa, A double matching pension policy where the employer will double match up to a 4% contribution from the employee, Employee stock purchase scheme with a 15% discount, Eye tests and vouchers towards glasses, Cycle to work scheme, Flu vouchers, Annual health checks with Bupa, 4X death in service insurance, Income protection (60% salary), 25 days holiday, + other great perks and great office facilities!
Perks. Gym reimbursement up to £25 per month, an onsite Gym, an Office bar, employee discount programs, free games & events, stocked pantries, a dog friendly workplace and the ability to earn £350+ per year for taking care of yourself and more!


Take-Two Interactive Software, Inc. (""T2"") is proud to be an equal opportunity employer, which means we are committed to creating and celebrating diverse thoughts, cultures, and backgrounds throughout our organization. Employment at T2 is based on substantive ability, objective qualifications, and work ethic – not an individual's race, creed, color, religion, sex or gender, gender identity or expression, sexual orientation, national origin or ancestry, alienage or citizenship status, physical or mental disability, pregnancy, age, genetic information, veteran status, marital status, status as a victim of domestic violence or sex offenses, reproductive health decision, or any other characteristics protected by applicable law.",3.9,"Take-Two Interactive Software, Inc.
3.9","London, England",-1,1001 to 5000 Employees,1993,Company - Public,Video Games,Media,$1 to $2 billion (USD),-1
Data Engineer,-1,"Job Number: R0084562

Data Engineer

The Challenge:

Do you find yourself constantly looking for more and better information? Do you want a job where you can use your knowledge and research skills to improve national security? More connected devices, larger storage capacity, and faster connections have resulted in an explosion of available information. The problem facing the intelligence community (IC) is no longer how to get more data – it's understanding how to turn massive amounts of data into answers. That's where you come in. With critical thinking and flexibility, you quickly seek out the accurate data sources, sift through the raw open-source data, and turn it into valuable intelligence. If you have strong analytical skills and a problem-solving mindset, we have an opportunity to use those skills to support our warfighters, protect our national security, and inform our nation's leaders.

As a Data Engineer on our team, you'll explore new data sources, including publicly available information (PAI), to create effective queries, and combine information from disparate sources to support clients and operational partners. You'll apply expertise in operations, intelligence, qualitative and quantitative analyses, and collections to enhance the client's mission. You'll find and work with available web and social media content, construct new OSINT and PAI tradecraft documents and workflows, and analyze the development of OSINT and PAI tradecraft, including integration across multiple intelligence disciplines and systems. You'll leverage knowledge of Python or R, customize tools for select acquisition of bulk PAI data, and use internet technologies and observables, including process automation.

Empower change with us.

You Have:

-5+ years experience as a Data or Software Engineer

-Experience with Python and R

-Experience in working with Big Data platforms, including Hadoop, AWS, Azure, or DataBricks

-Experience with data evaluation, and analytical tools and databases

-Ability to conduct independent analysis to support mission requirements and use enhanced search procedures and tools to support the usage of PAI

-TS/SCI clearance

-BA or BS degree

Nice If You Have:

-Experience with PAI analytic principals, including database administration, the web, geo-enabled PAI, and the Berber Hunter Tool Kit tools

-Experience with all-source intelligence processes

-Knowledge of national and service-specific OSINT policy and regulations, internet-based research, including Boolean logic, search engine, database resources, and internet sources, including social media, social networking tools, data exploitation, and commercial- and industry-based databases

-Experience with OSINT analysis, including authoring intelligence products and risk assessments

-Experience with advanced search techniques, information databases, data visualization, and related tools

-Knowledge of other intelligence disciplines, including signals intelligence (SIGINT), human intelligence (HUMINT), and geospatial intelligence (GEOINT)

-Ability to manage research and coordination for long-term projects

-MA or MS degree in International Affairs, Political Science, Foreign Area Studies, National Security Studies, Linguistics, Business, Library Science, or a related research field a plus

-Completion of OS301 Basic Open Source Intelligence Course

-Completion of OS302 Intermediate OSINT Tools and Tradecraft Course

-Completion of OS303 Advanced OSINT Tradecraft Course

Clearance:

Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; TS/SCI clearance is required.

Build Your Career:

At Booz Allen, we know the power of analytics and intelligence. When you join Booz Allen, we'll help you develop the career you want.

Challenging projects – Whether training analysts on military equipment through VR technology; developing a simulation capability to allow teams to rehearse missions together; or integrating RFID tags into mobile devices to enable data access within a geo parameter, you'll get to solve some of the world's toughest problems

Meaningful work – Use your skills to empower change. Your work will keep citizens and warfighters safe and well both at home and abroad

State-of-the-art technology – Broaden your intelligence capabilities with digital forensics, telematics, precision navigation, secure mobile operations, and advanced analytics

New skills – In-house experts and partnerships with tech leaders, like Nvidia and Splunk, mean you can get practical experience with advanced GPU technologies, cyber security, and data science

Room to grow – You'll be inspired to grow your career while making your ideas a reality thanks to new opportunities across the US and abroad, encouraging mentors, and collaborative colleagues

We’re an EOE that empowers our people—no matter their race, color, religion, sex, gender identity, sexual orientation, national origin, disability, veteran status, or other protected characteristic—to fearlessly drive change.

#LI-AH1",4.0,"Booz Allen Hamilton Inc.
4.0","Huntingdon, England",-1,10000+ Employees,1914,Company - Public,Consulting,Business Services,$5 to $10 billion (USD),-1
Software Engineer,-1,"Job Description
We are in changing times, this is an amazing time to be in technology*
We are looking for experienced and graduate software developers to be part of Tech Start up Teams
If we gave you a year **of funding**, could you build the next great tech start-up?*
What if we added in a team of designers, fellow programmers and business developers?

OK, how about if we wrapped it all up with a MSc Entrepreneurship, taught by a diverse team of marketers, investors and entrepreneurs, assembled specifically to incubate new high-growth tech businesses?
We are a new kind of tech incubator.*
Over the past three years, we have brought together over 120 people to build high-growth tech start-ups.Our first few companies, completing their two-year programme in May this year, have raised substantial investment, had over a million users and one has recently premiered on Google’s new streaming games service, Stadia.

Oh, and don’t forget Hertzian; in 2014 we piloted the programme and created what was recognised by the government last year as one of the top 5 trailblazing AI companies in the UK.

The programme is continuing to build, and the next cohort starts at the end of January 2021.
We are looking for entrepreneurs with the ambition of owning and running a start-up in a beautiful part of the UK.*
What’s in for you?*
Spend a full year building your own product, in a team of 4, alongside 30+ other companies and teams, supported by experienced mentors.
Receive a full year of financial runway for your new business; we even include a stipend to cover your basic living costs.
Gain an MSc in Entrepreneurship from Falmouth University.
Work with leading industry partners, like Amazon, BBC Studios and Greenman Gaming.
Live in amazing and inspiring surroundings in Cornwall.
Work in a beautiful purpose-built incubator with views of the sea (just!).
A full year of acceleration support, including work-space, after the first year of incubation.
What do we expect?*
You need the practical skills to be able to contribute to a team building a software product; be that back-end or front-end development, or data science. The stack that you build with now isn’t important; good programmers adapt and learn, and you’ll be doing plenty of that.
What don’t we expect?*
We don’t expect you to arrive with a business idea, but if you have one we are always interested to hear, please tell us about it! We will train you, and partner you with people to focus on the non-technical parts of the business.

We just need your aptitude, your skills and your ambition.
To find out more and to apply, visit www.falmouthlaunchpad.co.uk*
Launchpad is an innovative postgraduate incubation and acceleration programme, part funded by the European Regional Development Fund.

Benefits:

Profit sharing/share options
Work from home opportunities
Flexible working hours
Reference ID: january 21

Job Types: Full-time, Permanent

Salary: £16,000.00-£150,000.00 per year

Schedule:
Monday to Friday
COVID-19 considerations:
We are following the University guidelines to keep everyone safe in the Studio

Experience:
software development: 2 years (Preferred)
Education:
Bachelor's (Preferred)
Work remotely:
No",-1,Falmouth Launchpad,"Exeter, England",-1,-1,-1,-1,-1,-1,-1,-1
Senior Data Scientist,-1,"Are you a senior NLP specialist who wants to get in on the ground floor of a legal tech startup seeking to use technology and AI to radically expand access to justice?*
If you thrive on rapid innovation, working in a motivated, positive team, and the freedom to use all of your skills and knowledge to succeed, then we would love to hear from you.*
The Team *
Monaco Solicitors is a highly accomplished law firm, with legal work extensively featured in national media, and we are also leading the charge of tech disrupting the employment law sector.

Our in-house tech team is growing steadily and we are strengthening our data science side to help deliver the law to the people who need it most but can't afford it. Our ambition is to deliver law globally in a new and user friendly way, using the power of artificial intelligence.
The Work*
We are looking for someone who can not only think scientifically, but who has a proven track record of turning those ideas into tangible results.

You will be helping to build an entirely new market from people who are currently unable to access justice. We are hard at work developing a series of new, low-cost or free legal tools harnessing the power of data. These products currently include Virtual Lawyer and Virtual Judge.

Virtual Lawyer is an automated legal letter writing service which drafts correspondence in the style of a lawyer. The data set is our corpus of legal letters created by our extremely talented lawyers.

Virtual Judge is a case assessment tool which uses a data set of publicly available legal judgments to give the user statistical analyses of various aspects of their case, with a view to the parties reaching out-of-court settlement.

You will be working on a largely greenfield project with the freedom to use your initiative and experience to create the method needed to power these tools, and helping envision our various other data driven projects.
Skills Required: *
Practical experience across the whole of the data science pipeline.
Practical experience applying NLP to real life problems in a knowledge-based industry.
Strong knowledge across a range of industry standard data science tools, frameworks and languages such as python, BERT, NLTK (you will have a large degree of freedom in deciding the best fit for the job).
Master’s degree or professional equivalent in data science or similar from a recognised institution.
Entrepreneurial mindset and the ability to get stuck in with minimal supervision.
Nice to have: *
Interest in helping people to access justice
Legal sector / legal tech experience (getting arrested doesn’t count : -) )
Experience working in a startup environment (small team, scrum + Jira)
Project/people/supplier management experience
PhD in data science or similar from a recognised institution
Benefits*
Competitive salary
Sick pay
Copious home working, plus unlimited office working
Unique office space www.peckhamlevels.org
Gym membership
Onsite yoga classes, table football and table tennis
Social gatherings and a collaborative environment
Entrepreneurial spirit
Making a tangible difference in the world
Location*
We are based in the creative hub of Peckham Levels, a 1 minute walk from Peckham Rye station, which is 9 minutes by train from London Bridge, 15 minutes from Victoria & Clapham Junction, and 24 minutes from St Pancras.

Job Types: Full-time, Permanent

Salary: £50,000.00-£100,000.00 per year

Benefits:
Casual dress
Company events
Flexible schedule
Gym membership
Sick pay
Wellness programmes
Work from home
Schedule:
Monday to Friday
COVID-19 considerations:
Plenty of home working. Office space allows for social distancing. Hand washing and sanitising facilities provided.

Experience:
applied NLP: 1 year (Required)
Education:
Master's (Preferred)
Language:
Fluent English (Required)
Flexible Working Options Available:
Flexitime
Work from home
Work remotely:
Temporarily due to COVID-19",-1,Monaco Solicitors,"London, England",-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Description

P&G is a leading global consumer goods company whose winning brands
are built around the model of innovation. Whatever your passion is, we want to
ignite your potential to become your very best self! We hold true to our
purpose, values and principles as we seek to make a difference in the world
around us. You will engage in meaningful work that will touch the lives of
others and have a real impact.
In this role you will:
Develop and maintain scalable data pipelines
that will ingest, transform, and distribute numerous data streams and
batches in support of key R&D initiatives.
Support and collaborate with Data Scientists
developing advanced machine learning and statistical models.
Evaluate tools and develop pipelines to
capture, integrate and clean data to support edge analytics solutions.
Deliver optimal data solution architectures,
automation and technology choices starting from experimentation through
proof of concept and often through delivery.
What we Offer:

Responsibility from Day 1 you will feel the
ownership of your work from the beginning
Continuous coaching you will work with passionate
people and receive both formal training as well as day-to-day mentoring
from your manager
Dynamic and respectful work environment
employees are at the core, we value every individual and encourage
initiatives, promoting agility and work/life balance
We offer a competitive compensation and
benefits package. This includes pension, life assurance, health insurance,
flexible working, a stock ownership scheme and other social benefits. To
find more information about our benefits package take a look here: https://www.pgcareers.com/benefits


Qualifications
The Ideal Candidate:

Strong interpersonal communication and
collaboration skills.
History of working independently and
effectively multi-tasking.
Familiarity with machine learning workflows
(desirable).
Have experience with sensors and IoT cloud
architecture (desirable).
Familiarity with RESTful APIs, containers and
microservices.
Familiarity with data privacy and data
governance.
Experience with NoSQL databases.
Qualifications:

Requirements (skills / experiences) for the role:
A PhD in Computer Science, Computer or
Electrical Engineering or a related field.
Strong problem-solving skills paired with
extensive experience programming (Python, Java, C++, etc).
Strong data wrangling skills.
Hands on experience with relational databases
and the use of SQL to extract and manipulate data.
Experience with cloud services (AWS, Azure or
GCP).
At P&G #weseeequal

We are an equal opportunity employer and value diversity at our company.
Our people are all equally talented in unique ways: we come from diverse
traditions, personal experiences and points of view. And we want to include
yours. Are you ready to inspire us with your unrivalled ideas?

P&G ensure that individuals with disabilities are provided
reasonable accommodation to participate in the job application or interview
process. Please contact us to request an accommodation by clicking application
help at the top right-hand corner of the career website.",4.2,"Procter & Gamble
4.2","Reading, England",-1,10000+ Employees,1837,Company - Public,-1,-1,$10+ billion (USD),-1
Lead Linux Systems Engineer,-1,"Are you an experienced Linux Engineer who wants to join a leading cyber team within an evolving and dynamic organisation?

Due to the success of a number of strategic Gloucestershire based programmes, we are growing our team with creative and ambitious Linux engineers. With a primary focus on supporting large scale Linux deployments, your experience will cover a variety of technologies, working closely with development teams to understand complex problem sets and apply your skills to solve them.

Different thinking for a Different world
Northrop Grumman is a leading global security company providing innovative systems, products and solutions to government and commercial customers worldwide. In Northrop Grumman’s rapidly growing UK Cyber and Intelligence business, we support our customers’ work to make the UK the safest place to live and do business, both physically and online.

Working with and alongside our customers, we use modern engineering methods (Scaled Agile, Dev Sec Ops, Site Reliability Engineering, micro-service architectures) and cutting edge techniques (data science, Artificial Intelligence, Machine Learning) to tackle complex and challenging problems and deliver cost effective, reliable, supportable solutions.

Our solutions support complex analysis of substantial amounts of data, requiring state of the art ‘big data’, stream processing and cloud-based analytics, identifying and using ‘best of breed’ commercial and open source technologies and integrating them with our own software to meet customer needs quickly and efficiently.

At Northrop Grumman we pride ourselves on our ability to combine agile development with sound engineering and security practices to ensure that our solutions are robust and resilient; designed and built to start secure and stay secure against ever evolving cyber security threats. As well as designing for security, Information Assurance and legal / policy compliance, we actively assess products and services, identifying vulnerabilities and weaknesses that could be exploited by cyber attackers, and we create and run exercises to pit cyber security specialists against secure systems and each other.

We carry out research and innovation locally in the UK, with commercial and academic partners, and across our 85,000+ worldwide workforce.

How you will make a difference
For us, innovation is key and we have immediate opportunities for talented Linux engineers to join our team to help us develop, deploy, maintain and decommission a number of large scale clustered systems. We are in a phase of rapid growth and there are opportunities to develop your career with us to meet your aspirations.

You will be helping us to solve our customer’s problems within an agile team. You will have opportunities to take systems through their life cycle from requirements capture to R&D(Research & Development), implementation, automation and test in a wide range of technologies.

As a Lead Linux Systems Administrator you will have a number of key responsibilities, these are primarily around systems support and maintenance, deployment of custom software in line with release schedule, incident management, vendor escalation and supporting your software development team. Experience of working within Software Development teams, including DevOps practices would be advantageous.

Key criteria required...

Proven industry experience as a Linux engineer

Experience or knowledge of either Red Hat Enterprise Linux or CentOS 7 & 8

Experience of installing, upgrading and troubleshooting Java based applications

Experience of Linux server integration with Active Directory

Experience of building secure systems using corporate PKI solutions

Knowledge of core Networking Principals

Experience of technical leadership or team management

Also, we’d love it if you have experience of...

VMWare or Cloud-based architectures

Accumulo, Hadoop & ZooKeeper administration

Agile/Scrum methodologies using tools such as Confluence and Jira

DevOps approaches and associated tools such as BitBucket, Ansible, Jenkins & Docker

Messaging and Routing Technologies such as NiFi and Kafka

Different programming languages, such as: Bash, Perl or Python

Working with open source products

You will enjoy a growing career as we work collaboratively to innovate the world of cyber security.

Additional information for your consideration...

You must be able obtain and hold UK Government clearances

Opportunities exist across the UK to enhance your career progression

Looking for flexibility? Talk to us at the application stage about what may be possible.

Being a part of Northrop Grumman gives you the opportunity to use your skills to make a difference in our mission of enabling global security. Our company grows because of our employees' dedication and commitment to achieving our mission, something we always remember. In return for working for us you will have access to a benefits package that provides you with flexibility to balance your professional career with your personal life, health & well-being benefits, discount schemes, pension benefits and investment in your future development.

We are committed to equality and diversity in our workplace. Northrop Grumman provides equal employment opportunities to all employees and applicants without regard to an individual’s protected status, including race, ethnic origin, colour, nationality, national origin, ancestry, sex/gender, gender identity/expression, gender reassignment, sexual orientation, marriage/civil partnership, pregnancy/maternity, religion or belief, creed, age, disability, genetic information, or any other protected status or characteristic.",3.8,"Northrop Grumman UK
3.8","Cheltenham, England",-1,10000+ Employees,1939,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
Data Engineer,-1,"BGL Group are looking for an experienced Data Engineer to join our Data Solutions team. Working in an Agile environment you’ll be responsible for engineering first class technical solutions as required to support the IDO strategic agenda. You’ll contribute to the evolving culture of innovation and continuous improvement and be the voice of the customer. You'll also have a strong focus on delivering the best customer experience.

Within our digitally focussed FinTech organisation,your role will involve delivering robust solutions that meet the functional and technical requirements of the customer. You’ll show strict adherence to technical and quality standards within agreed timeframes and champion the need for a ""quality first"" approach. As an active learner you’ll be responsible for keeping up to date with developments in your technical and professional area of expertise. Your role is imperative to ensure we always have suitable performance and capacity for our key business systems.

What will it take to be successful as a Database Engineer?

Knowledge and experience of:

- SQL Server 2017/19 and writing T-SQL

- ETL/SSIS principles

- Relational database design principles

- Excellent written and oral communication skills

- Intermediate industry experience of Data Warehousing

- Experience in effectively coaching other team members

- Be a keen advocate of modern data engineering design and practice

About Us

Founded in 1992, the BGL Group has grown significantly in size and capability. From 30 to 3,000 people, we are a leading digital distributor of insurance and household financial services. We have reached 10 million customers through brands including comparethemarket.com, LesFurets.com, BGL Life, Budget Insurance & Dial Direct, as well as our partnerships business which provides insurance for some of the UK’s leading high street brands. We make a difference for our customers, colleagues and communities by working, growing and winning together. We enjoy what we do and have fun doing it!

Diversity and Inclusion

We're a diverse community of dedicated, innovative and talented professionals. With an inclusive and open workplace, we encourage our people to create and share ideas – supporting their growth and celebrating their uniqueness. We're proud to be an equal opportunity employer and stand firmly against discrimination of any kind.

Flexible working

We understand the importance of achieving a healthy lifestyle balance, whether it’s working remotely or flexibly we have an environment where people are empowered to embrace flexible working in a way that works for them and for the business.

Apply Now!",3.7,"BGL Group
3.7","Peterborough, England",-1,1001 to 5000 Employees,1992,Company - Private,Insurance Carriers,Insurance,$500 million to $1 billion (USD),-1
Software Engineer (Ruby),-1,"About Us

We want to help small businesses win. That’s why we’re here.

We connect small business owners to investors – to create jobs, help families and power economies – because we believe that people are made to do more. And we want to help them.

So, we created the leading online marketplace for small business loans. Our investors have lent £8.1 billion in 110,000 loans to 77,000 small business owners. In a single year, we unlocked 115,000 jobs and contributed £6.5 billion to the global economy. There’s never been a better time to join!

Be part of the team that changes everything. Let’s build the place where small businesses can get the funding they need to win and leave a legacy behind, forever.

This role sits within the “Tech” team. The drivers behind our platform – brilliant people working together to create, code, and build the next game changers.

About the team

The driving force behind the world’s leading platform for small business lending is our engineering team. We are a diverse group from more than 25 different countries and cultures who bring together a wide range of backgrounds and experience (from music to aerospace engineering).

We are focused entirely on using technology to provide the best experience for our borrowers and investors. We are doing this by building elegant, sustainable, and scalable solutions that can be applied globally. We work in small agile teams practicing continuous integration, TDD and are no strangers to pairing as we believe that working together is smarter than sitting in silos.

About the role

Day to Day, this role will include:

Collaborating as part of an agile cross functional team, as well as technology chapters
Building great user experiences for customers
Delivering innovation through software to automate processes that enable Funding Circle to operate at scale
Using Clojure, Kafka, React and Ruby currently and built entirely on AWS
Supporting our production systems
About You

This roles requires someone who has:

Production experience in Clojure
Fundamental programming skills (data structures, algorithms)
Familiarity developing on Unix/Linux
Good communication skills, both written and spoken
Knowledge of Agile, Scrum, BDD, TDD and CI/CD
An interest or experience in any of Functional Programming, Distributed Systems or Event-Driven Architectures

Why join us?

We’re gearing up for our biggest chapter yet – and it’s being driven by everyone.

We think of ourselves as the career launchpad. A place to develop yourself, fast. Real work. Real experience. Real opportunities to collect skills. Think big remits and huge ownership to make great things happen.

Yes, it’s target-driven and high-octane – but we like to play hard too. That’s what makes us, us. Our vibrant culture is built around potential and creating a place where you can really be you. We keep it agile and open. All voices heard. Because we believe great ideas come from everywhere.

If you show skill and are willing, we’ll back you all the way. This is the place for you to build something incredible.

It’s in our differences that we find our strengths.

We celebrate and support the differences that make you, you. So we’re building a culture where difference is valued. We’re proud to be an equal opportunity workplace and affirmative action employer. We truly believe diversity makes us better. We particularly encourage applications from applicants from underrepresented backgrounds. We welcome applicants who may want to work flexibly.

Want to Build The Incredible? We’d love to hear from you.",3.8,"Funding Circle UK
3.8","London, England",-1,501 to 1000 Employees,2010,Company - Private,Lending,Finance,$50 to $100 million (USD),-1
Data Engineer,-1,"Data Engineer ( Azure / Data Factory / Power BI )

Central London

3 Months initial (Outside IR35)

£400 – £550 per day D.O.E

Data Engineer ( Azure / Data Factory / Power BI ) is needed to work for one of our growing retail clients based in Central London for an initial 3 months engagement. Day rates of £400 – £550 depending on experience are on offer (Outside IR35).

As the Data Engineer ( Azure / Data Factory / Power BI ) you will play a pivotal part in developing the existing data platform to keep up with the rapid growth of the business and maintain the accuracy and ease of use of the system alongside this.

Essential experience required for the Data Engineer ( Azure / Data Factory / Power BI ) includes:

Strong background in Data Engineering and Architecture.
Strong understanding of Microsoft SQL Server, Azure and Power BI.
Track record that of implementing end-to-end data solutions and ELT/ETL pipeline development skills.
Maintain and optimize the Data Warehouse and Data Lake solutions to maximize performance.
Experience working with solutions in the Cloud.
Implement dashboards on Power BI for data analysis.
Strong experience with SQL.
Good documentation experience.
Ability to communicate well with key stakeholders and non-technical audiences.

Desirable experience required for the Data Engineer ( Azure / Data Factory / Power BI ) includes:

Experience in leading data engineering projects is a big plus.
Experience working with large-scale data environments in a data engineering role.
Experience in working with teams of Data Scientists.
Microsoft Azure related Certifications.
Experience working in the Retail/Ecommerce space.
Experience with GCP.
Experience working with Big Query.

A demonstrable track record in a similar role is a necessity for this business-critical role. The culture is one that promotes creativity and the ability to think outside of the box.

This is an exciting opportunity for a Data Engineer ( Azure / Data Factory / Power BI ) in search of a new challenge that will push them out of their comfort zone.

To apply for this role, please send an updated version of your CV to tom.goulding@venturi-group.com.

Venturi is a staffing business dedicated to you, differentiating ourselves in the marketplace by quality of service and candidate delivery. Our highly skilled and experienced staff operate within dedicated markets to give you the best service possible. Venturi markets include Development & Design, Business Intelligence, IT & Infrastructure Support. Venturi operates as an employment agency and employment business. No terminology in this advert is intended to discriminate on the grounds of age, and we confirm that we are happy to accept applications from persons of any age for this.",4.8,"Venturi
4.8","London, England",-1,51 to 200 Employees,2009,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
BI Data Engineer,-1,"Job Title: BI Data Engineer

Job type: Permanent

Location: London Head Office, Holborn

Reporting Relationship: Lead BI Software Engineer

Argus is a fast-growing global B2B media company providing essential information to the energy industry. Argus benchmarks are used globally throughout the energy sector for formula pricing in contracts, as a taxation reference, in investment planning and for a variety of other purposes.

Job Purpose

The BI Data Engineer is responsible for developing the Business Intelligence platform and progressively rolling out new data sets and reports. Ensuring that the solution is performant, highly available, and suitable for the consuming users and applications. This role works closely with other Engineers, the Architecture team and data team to revise and refactor our BI data models as appropriate.

This is an exciting opportunity to help shape the data strategy for the business globally in a growing team. By building new pipelines from various internal & external sources you will be helping to drive how the business are making their decisions from trusted data sources. As the build of the warehouse progresses you will be encouraged to identify innovative efficient ways of processing the data and participating in proof of concept trials for new software.

Key responsibilities
Building robust data pipelines that follow the agreed data design principles from raw through to the business views
Routine maintenance and troubleshooting of the data
Understanding and implementing data quality rulesets at various stages of the data lifecycle
Conducting UAT of new releases
Maintaining an accurate log of the technical documentation for the warehouse
Gathering business requirements from relevant stakeholders
Following and supporting of the Agile way of working
Qualifications/Experience
Proven experience as a BI Data Developer
Extensive experience with C# and/or Python
3-5 years of SQL experience in a commercial environment
Practical knowledge of API intergration
A good practical understanding of data warehousing in a cloud environment (RedShift/Snowflake)
Exposure to ETL/Data integration tools like Data Integrator, Data Stage, FiveTran, DBT, Ni-Fi
A solid understanding of how the end user can consume data with little technical expertise
Knowledge of various systems across the AWS platform and the role they play e.g. Lambda, DynamoDB, CloudFormation, Docker
Curious, self-driven, analytical and excited to play with data
About Argus Media

Argus is an independent media organisation with more than 1,000 staff. It is headquartered in London and has 25 offices in the worlds principal commodity trading and production centres. Argus produces price assessments and analysis of international energy and other commodity markets and offers bespoke consulting services and industry-leading conferences.

Companies in 140 countries around the world use Argus data to index physical trade and as benchmarks in financial derivative markets as well as for analysis and planning purposes.

Argus was founded in 1970 and is a privately held UK-registered company. It is owned by employee shareholders, global growth equity firm General Atlantic and Hg, the specialist software and technology services investor.

Benefits

Our rapidly-growing, award winning business offers a dynamic environment for talented, entrepreneurial professionals to achieve results and grow their careers. Argus recognises and rewards successful performance and as an Investor in People, we promote professional development and retain a high-performing team committed to building our success.
Competitive salary and company bonus scheme
Group pension scheme
Group healthcare and life assurance scheme
25 days holiday with annual increase up to 30 days
Subsidised gym membership
Season ticket travel loans
Cycle to work scheme
Extensive internal and external training
Apply

If this aligns with your next career move, wed love to hear from you.

Apply via our website www.argusmedia.com/en/careers/open-positions",3.2,"Argus Media
3.2","London, England",-1,501 to 1000 Employees,1970,Company - Private,Publishing,Media,$100 to $500 million (USD),-1
Data Engineer,-1,"Data engineer

We’re looking for a smart, self-motivated Data Engineer to join our team. This role will be responsible for data collection, extraction, maintaining pipelines and actively researching and verifying new data sources.

About you:

You care about getting the best possible outcome, you have a passion for what you do which you can clearly convey by your actions.
You have an eye for detail and order, being able to spot problems in code or data which others might miss or take longer to find.
You have a desire to explore and test concepts, ideas and theories.
You have a strong sense of responsibility, and the ability to breakdown, estimate and manage your workflow with stakeholders.
You have a keen interest in cloud computing (we work with AWS) and have some knowledge on cloud and data security, networking and running complex data pipelines in the cloud.

About Us:

We’re small (20+ people and growing fast), innovative and varied group, solving big problems in real estate data and analytics. We are seeking enthusiastic, creative, intelligent and fun individuals to join us in helping build the best platform on the market. In return we can offer you a fun and hard-working environment where you can clearly see your contribution to the company’s success.

What you’ll be doing:

The hire will be working with our team who are responsible for optimising data flow and collection, researching and investigating new data sources, and expanding and maintaining our existing data pipelines. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys working in a fast paced and interesting environment. The Data Engineer will support our software developers and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple product verticals. The right candidate will be excited by the prospect of supporting our next generation of products and data initiatives.

Research and assemble large, complex data sets that meet functional / non-functional business requirements.
Work with stakeholders in the wider Product and Sales teams to assist with data-related technical questions and support their data infrastructure needs.
Continually improve the infrastructure required for optimal collection, extraction and initial transformation of data from a wide variety of data sources using AWS big data processing technologies such as Glue.
Work with existing data and analytics experts to strive for greater functionality in our data systems.

Our Stack

The current data collection and extraction processes are written in Go and Python, and our processing and pipelines are written in PSQL, Spark (Python and Scala) using AWS Glue to orchestrate. We work mostly with batch data rather than streams.

Excellent SQL skills are required, and knowledge of window functions, optimising queries, geospatial queries, GIS, and general data wrangling are a must.

We are open to people from a diverse range of backgrounds and would have a preference for people with an understanding of most of the following:

Python/Go for data collection
Postgres and PostGIS
AWS Glue/S3/RDS/EC2
Spark/Scala is nice to have but not required initially

We are looking for someone with proven experience of data collection and data pipelines, and who is comfortable working with stakeholders and directly with the CTO and Product Owner. We are a relatively small team, so you must be comfortable with conversing across all aspects of development and reacting quickly to new information.",4.9,"REalyse
4.9",Remote,-1,1 to 50 Employees,2016,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Data Engineer - Permanent - Glasgow - Remote Start

Our brilliant large-scale global client is looking to recruit a Data Engineer on a permanent basis. This is a fantastic opportunity to grow your career with a highly regarded and well-established organisation.

The ideal candidate will have the following experience:
Datamodelling and Data Warehousing
Experience and familiarisation with multiple RDBMS platforms, ETL Tools, data migration approaches, and data framework design patterns.
Designing and implementing information solutions
Working on Business Intelligence and analytical projects
Experience with AWS or Azure
Demonstrable experience with ETL and/or cloud integration service capabilities.
Knowledge of programming and Scripting languages
If you think you could be a good match then apply today or email me directly on

...",4.1,"Hydrogen Group
4.1",North Lanarkshire,-1,201 to 500 Employees,1997,Company - Public,Staffing & Outsourcing,Business Services,$100 to $500 million (USD),-1
Data Engineer,-1,"Data Engineer
Overview


EF is the world leader in international education. Our mission is to break down barriers in language, culture, and geography and so far, we have helped over 15 million people learn a language, discover the world or earn an academic degree. We have 500 schools and offices in over 50 countries and employs over 52,000 staff and teachers. In today’s increasingly complex and interdependent world our mission is more relevant than ever.

The Role


This role is a crucial part of our EdTech Data Science team. We’re a lean and agile team of Data Engineers and Data Scientist focused on building modern cloud-based infrastructure to enable ML for Education. You will be contributing to our event-based streaming data platform that enables real time insights for teachers and students in the classroom or when studying remotely online. You will also help us build a world-class cloud data warehouse for our Data Scientists, Analysts and BI specialists.

Our current EdTech stack is based on AWS and includes Kubernetes, Kafka, Kinesis, Flink, Snowflake but you will also work with the wider business to develop ETL processes to move data from multiple data sources into our data lake/ warehouse.

Main Responsibilities
Create and contribute to a data platform that enables self-service analytics and creates the foundation for data science applications across our businesses
Build batch and streaming pipelines for the purpose of analysis & data science
Design, implement and maintain the data warehouse
Support and maintain existing production services
We ask that you have
AWS, GCP or Azure cloud expertise
Experience with cloud-based data warehousing (Snowflake, Redshift or similar)
Experience with Agile methodologies and practices
Experience using distributed version control systems (e.g. git, mercurial)
Experience in developing data processing applications in Java/Scala/Python
Experience working with streaming data sources (e.g. Kinesis Streams or Apache Kafka)
Experience with Kubernetes, Helm charts and Docker
Experience with real-time processing engines (e.g. Apache Flink, Apache Beam, Apache Storm)
Excellent verbal and written skills in order to effectively communicate with partner teams
Other useful skills include
Ability to write efficient SQL statements
Understand data warehouse design and ETL performance techniques
Experience with 3NF, Data Vault & Dimensional modelling
Experience with Master Data Management
Experience with Data Governance",-1,EF EdTech,"London, England",-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Come build the future of entertainment with us.
Are you interested in shaping the future of movies and television? Do you want to define the next generation of how and what Amazon customers are watching?
Prime Video is a premium streaming service that offers customers a vast collection of TV shows and movies - all with the ease of finding what they love to watch in one place. We offer customers thousands of popular movies and TV shows from Originals and Exclusive content to exciting live sports events. We also offer our members the opportunity to subscribe to add-on channels which they can cancel at anytime and to rent or buy new release movies and TV box sets on the Prime Video Store. Prime Video is a fast-paced, growth business - available in over 240 countries and territories worldwide. The team works in a dynamic environment where innovating on behalf of our customers is at the heart of everything we do. If this sounds exciting to you, please read on.

The marketing team for Amazon Prime Video in the UK, have the responsibility for driving the customer growth and engagement with this service through a very broad combination of marketing channels across EU.

As a Data Engineer in this team, you will work with a team of Data Scientist, Data Engineers and BI Analysts to build our data layer to innovate the way we do Marketing for Prime Video and understand our customers. You will work closely with the business and technical teams on many non-standard and unique business problems requiring a creative approach to problem solving.

Analytical and modeling skills will be required to work across several Amazons Business teams. The work may include working with Marketing, Business Development, Data/BI Engineers, Software Developers, Finance, and Accounting teams. The role requires interpersonal and communication skills, a keen attention to detail, ability to be hands-on as well as work with minimal direction.

The successful candidate will be able to thrive in an environment demanding data-driven decision support and business intelligence that is timely, accurate and actionable. Obsessed with solving complex problems and passionate about the potential of analytics to drive a business forward; the successful candidate will relish the prospect of driving forward Prime Video's Analytics to the next level. Mindful of dependencies, able to make sensible trade-offs, and able to be hands-on a passion for code and design, your end product is usable datasets with business value!


Basic Qualifications

· Bachelor's Degree in Computer Science or a related technical discipline.
· Experience writing high quality, maintainable SQL on large datasets.
· Ability to write code in Python, Ruby, Scala or other platform-related Big data technology.
· Exposure/Experience in big data Technologies (hadoop, spark, presto, etc.).
· Expertise in the design, creation and management of large datasets/data models.
· Experience working on building /optimizing logical data model and data pipelines while delivering high data quality solutions that are testable and adhere to SLAs.
· Experience in using various data design patterns and knows when/when not to use one.
· Excellent verbal and written communication skills.
· Ability to work with business owners to define key business requirements and convert to technical specifications.

Preferred Qualifications

· Ability to work with cross-functional teams
· Experience with Amazon Redshift
· Experience with cloud-based architecture and deployment
· Experience with AWS technologies
· Proven track record of strong verbal/written communication & data presentation skills, including an ability to effectively communicate with both business and technical teams.
·

Amazon is an equal opportunities employer. We believe passionately that employing a diverse workforce is central to our success. We make recruiting decisions based on objective criteria including your experience and skills. We value your passion to discover, invent, simplify and build. We welcome applications from all sections of society irrespective of belief colour, race, religion or belief, nationality, ethnic or national origin, gender, gender reassignment, sexual orientation, sex, marital status, disability, age or trade union membership. Please let us know if you have any special requirements in relation to this recruitment process.

All offers are conditional on references, verification of the right to work in the UK, and successful background screening check. This will include previous employment verification, qualification verification (if relevant) and a basic criminal check. Further details of this policy/procedure will be sent to you along with your conditional offer.",3.9,"Amazon
3.9","London, England",-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer,-1,"Data Engineer – Remote – 6 months - Outside IR35
Data Engineer on an initial six month contract. This role will be carried out on a fully remote basis.
Essential Requirements:

Delphi 6
ETL
C#
If this sounds like an appealing opportunity to you then get in touch with me ASAP. Naturally there could be scope for extension, due to the nature of the work.",3.2,"Opus Recruitment Solutions
3.2","London, England",-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Software Engineer,-1,"Software Engineer



Job description

Summary

We are looking for a motivated and high-achieving Software Engineer based in London to join our Product team in building a platform to optimise every business on the planet. This is a full-time placement with significant opportunities for personal development.

We offer an intellectually stimulating environment, work within an interdisciplinary team and an inclusive culture. We are a high-calibre, mission-driven team building a technology that improves our world.

Roles and Responsibilities

We are looking for exceptional and ambitious individuals to develop our Causal AI platform for time series. You will work as a software engineer in the Product team which is composed of software engineers and scientists.
The application stack includes Python, Cython, Numpy, Torch, Django, Celery, Postgres, Redis, Ansible, AWS, GCP, React and other technologies.

The Company
Current machine learning approaches have severe limitations when applied to real-world business problems and fail to unlock the true potential of AI for the enterprise. causaLens is pioneering Causal AI, a new category of intelligent machines that understand cause and effect - a major step towards true artificial intelligence. Our enterprise platform goes beyond predictions and provides causal insights and suggested actions that directly improve business outcomes for leading businesses in asset management, banking, insurance, logistics, retail, utilities, energy, telecommunications and many others.

We are committed to addressing the diversity problem in the tech industry, and that starts with making sure we have a team where everyone feels at home and can contribute as a peer.

causaLens in the News
Best Deeptech Company 2019 - Artificial Intelligence Awards
‘Meet causaLens, a Predictive AI For Hedge Funds, Banks, Tech Companies’ – Yahoo Finance
‘The U.K.’s Most Exciting AI Startups Race To Scale’ - Forbes
‘AllianzGI Taps Virtual Data Scientists amid War for Talent’ - Financial Times
‘Machine Learning Companies to watch in Europe’ - Forbes
‘Best Investment in Deeptech’ award - UK Business Angels Association awards
‘100 Most Disruptive UK Companies’ - Hotwire
‘causaLens Appoints Hedge Fund Veteran and Data Leaders to Advisory Board’ - Newswire
Benefits
The opportunity to join a fast-growing, agile, and international team passionate about innovation and making a difference
Competitive remuneration
Share option scheme
Pension scheme
32 days paid holiday allowance (incl. bank holidays)
Equipment you need to get the job done (MacBook Pro etc.)
Good work-life balance
Opportunities for continued learning and self-development, including courses, conferences and book budget
Flexible work-from-home and remote days
Cycle to work scheme
Weekly journal club and knowledge sharing presentations
Regular team outings, pizza Thursdays and annual company retreats
Fruits, snacks and soft drinks in the office
Amazing, smart, fun and inspiring colleagues, always there to support your ideas, growth and enthusiasm


Logistics

Our interview process consists of a coding test, 2 screening interviews and a ""Day 0"" which is spent with the team. Normally the Day 0 takes place on-site but for the time being they will take place online.

We will do our best to transparently communicate the process with the successful candidates.


Job requirements

This role is open for candidates of all seniorities, junior to senior.
Smart, capable and can write clean code effectively
Ability to design and architect high-performance distributed software
Development experience in at least one scripting language - preferably Python
Understanding of the full stack is preferable (REST backends and SPA frontends)
In-depth understanding of computer architecture is preferable, e.g. C, C++, Cython
Interest in machine learning/big data (prior experience is a plus)
Knowledge of the software development lifecycle (version control, tooling, testing, etc.)
Ideally you should be able to work in London or be able to commute. Candidates outside of London who are interested in relocating will be considered.",4.5,"causaLens
4.5","London, England",-1,1 to 50 Employees,2017,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Data Engineer

APPLY NOW

Data Engineer / Hadoop, Scala, Spark, Python / up to £51k, excellent work life balance, training opportunities and remote working

Are you a Data Engineer who would like to be involved in a company-wide data transformation with a globally recognised brand? Would you like to have a real say in the technical direction and ultimately provide real business benefit?

Corecom Consulting has partnered with a prestigious company based in the heart of Manchester who are rapidly growing their business offering from a data perspective. This is a fantastic time to join an ever-growing business that offer real career development opportunities, both from a career progression and technical perspective.

Their long term vision is to move everything from their data warehouse in to their newly built data lake so they can move from pure reporting to creating more interactive visualisations, whilst looking at patterns in data which will lead to predictive analytics which will allow a complete 360 view of their customers.

Their state-of-the-art offices are in the Greater Manchester Area and boast a friendly, but ambitious technology-driven environment. However, they are working from home at the moment, and have the confirmation that this can be done permanently moving forward (if required).

What can you look forward to?

Remote working
Excellent internal and external training opportunities
Progression opportunities
A chance to work on a “UK sector first” data solution
Generous holiday allowance
Strong pension
Childcare vouchers

What we need from you

Hadoop
SQL
Talend

What would be great to have

Python / R / Scala / Java
Data modelling experience

You will form part of their existing Data Analytics team as you build and maintain their Hadoop solution. The aim is to provide their customers with ownership of their journey as well as employees with the MI needed to implement business decisions. The exciting part of this role is that you will be involved in a “UK sector first” data solution which will not only offer you the scope to develop personally but will add to your current career.

I have interview slots for this role in the next couple of weeks so please apply as soon as possible to avoid disappointment!

Data Engineer / Hadoop, Scala, Spark, Python / up to £51k, excellent work life balance, training opportunities and remote working

Job Reference: 5841

Salary: Up to £51000 per annum

Salary per: Annum

Job Duration: Perm

Job Start Date: ASAP

Job Type: Permanent

Job Location: Manchester, Greater Manchester

Job Regions: North West

Job Industry: IT

Job Skill: data engineer, scala, hadoop, talend, Python, Java

Job Specialism: Business Intelligence and Data Warehousing

Apply Now

Back to my search",5.0,"Corecom Consulting
5.0","Manchester, England",-1,1 to 50 Employees,2008,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Insights Data Engineer,-1,"Job Title: Insights Data Engineer

About Railsbank

Railsbank is the world’s leading global open banking platform that gives customers “access to global financial services” with 5 lines of code.

The company was founded by serial finTech entrepreneurs who previously founded successful and award winning companies like Evolution and Currency Cloud.

Since starting in 2016 in London the company has expanded across Europe, launched in Singapore and is currently extending capabilities in SE Asia, USA and Australia.

We are now scaling the company across Europe and SE Asia and looking for exceptional people who share the same core values to join team Railsbank.

Role Description

Building on the high growth and success that Railsbank has experienced, we have exciting plans for further expansion in our Insights Data Team focusing on building out the capabilities with handling large scales of data to both run our business and super power the data-driven Insights and products for our expanding customer base.

You will be a key contributor to the design, delivery, continual assessment and improvement of strategic business enabling components and customer focused data products and delivered through our Railsbank Insights customer portal.

You will be part of a virtual team of Data Analysts, Engineers and Scientists who collaborate and work on cross-functional initiatives to deliver insights and analysis across Railsbank.

Responsibilities:
Building and managing the data ingestions, integrations, calculations, pipelines, feeds that drive our business
Collaborate with Data Analysts and Data Scientists, Engineering teams, Operations Teams, Sales and Customer Success teams to ensure the quality, accuracy and availability of data meets their needs.
Strong focus on accuracy, validation, quality and timeliness of data
Continually advance and improve our system of change management, peer-reviewed code and automated numbers testing capabilities.
Follow the policies and procedures in the Information Security Management System (ISMS) to ensure the Confidentiality, Integrity and Availability of the information that Railsbank manages
What we look for in your professional skills & key capabilities
Degree educated, ideally in a computer science, mathematical, statistical or data science related subject or strong professional experience in this area
Tools/technical skills:
Batch and streaming data pipelines and calculations in Databricks and coding in PySpark to build scalable, testable and reusable components.
Python language, skills and knowledge of packages
DevOps mindset can work with code reviews, github/gitlab integration, automated regression / numbers testing for calculations
Databricks Notebooks, DBFS, DBConnect
Ability to setup data pipelines to handle data in a wide variety of formats: the good, the bad and the ugly.
Experience in building dashboards for internal and embedded external visualisation in tools such as Looker or experience in similar tools such as Tableau, Power Bi, Sisense, Dash or similar
Highly capable at SQL (Structured Query Language)
Desirable: Snowflake database modeling and DBA, Fivetran ETL
Google Sheets and Microsoft Excel
Experience in developing for and releasing to a business critical production environment
Logical problem solver and critical thinker with a good ability to prioritise projects.
Excellent communicators who can explain technical details to people in other roles and understand other people's perspectives and priorities.
Enthusiasm for delivering excellent value for the business.
What we look for in our team members and our values

Being an integral part of the Railsbank team and sharing our values is important to us.

The environment at Railsbank is fast-paced, exciting, and dynamic. It suits people that love to collaborate and support one-another.

We are all driven by the same values and are looking to welcome new people to the team that share these values.

Our values are: excellence, accountability, work/life balance, trust, fun, inclusive, friendship, noble cause, and respect.

Equal Opportunities Employer: Railsbank is an Equal Opportunity Employer and does not discriminate on the basis of race, religion or belief, colour, sex or gender identity, sexual orientation, age, disability, national origin, marital status, or any other basis covered by appropriate law.",4.0,"Railsbank
4.0","London, England",-1,51 to 200 Employees,2016,Company - Private,Financial Transaction Processing,Finance,Unknown / Non-Applicable,-1
Data Engineer,-1,"Are you the kind of person that loves the idea of grabbing a project and running with it? Do you thrive of solving complex problems and delivering the best solutions possible?

We are working with a brand-new team that are launching a digital side of the business and they have some extremely talented Data Scientist that need an equally talented Data Engineer to help them succeed.
If you want to push the boundaries of technology and innovate and have the freedom to do so then please reach out.

Technical requirements;
ETL
Python
Puppet/ Git
PostgreSQL or relevant Database
So if this sounds like you please reach out to Todd Mills - 01223 237888 -",3.0,"The One Group
3.0","Cambridge, East of England, England",-1,1001 to 5000 Employees,-1,Company - Public,Casual Restaurants,"Restaurants, Bars & Food Services",Unknown / Non-Applicable,-1
Data Engineer,-1,"Want to do the best work of your life? With 24 million customers in 7 countries, make your mark at Europe’s leading media and entertainment brand. A workplace where you can proudly be yourself; our people make Sky a truly exciting and inclusive place to work.

Making bold decisions is a big part of our history – and with talented people like you on board, we’re confident it’s going to be a big part of our future. NOW TV is our exciting internet TV that’s revolutionising the sector with a bold approach, fresh ideas and the latest technologies. We’re transforming the way our customers view content by making Sky Movies, Entertainment and Sports available across a range of devices.

“This role contributes to a small team responsible for the delivery of robust Data Intelligence operations, creation of data marts, DevOps/change management, service management, scheduling and orchestration based on standard Google Cloud Platform tools and techniques” - Tom Dalglish, Head of Data Governance and Enablement

What you’ll do:

As a Data Engineer, you will help drive NOW TV’s Data Enablement across all products including maintenance of data marts, batch scheduling and operational support, event detection, alerts, escalation and capture of production metrics. You will be working side-by-side with the lead engineer in the design and construction of scalable data management systems.

- Work within a small team of 2 to 3 engineers to deliver the overall Data Enablement strategy.
Write code in Python and GCP tech-stack for manage our operational services
Have strong knowledge of the data sets required to run a Data Intelligence business. Deliver plans with NOW TV teams on operational capabilities, new dashboards, data distribution, Adobe product interfaces and general programming and scripting
Build real-time APIs for system integration, batch operations (Airflow, Control-M.) with in-house development teams and third-party suppliers, ensuring that developed solutions meet business requirements
API programming (REST), Python, SQL script, Unix, MS Teams. Mobile alerts and escalation management. Database table design, querying and troubleshooting
Integrate modern data management and software engineering technologies into existing data structures. Develop processes for data mining, data modelling, and data production. Create custom software components and operations
Design and build systems for Issue Detection, Notification Escalation, Triage, Resolution, Troubleshooting and Prevention

What you’ll bring:

- Ability to interpret the business needs into data requirements
Broad Experience in Google Cloud
Experience in an OTT and VOD environments Experience gathering/defining business metrics
Technical grounding across digital systems architecture, design and development and working knowledge of agile software development methodologies
Integrity: Willingness to speak up on difficult issues with own opinions, at the same time be humble and be able to ask for help
Strong interpersonal skills and leadership qualities with proven record in fast paced and quick changing environment

The rewards:

There's a reason people can't stop talking about #LifeAtSky. Our great range of rewards really are something special, here are just a few:

- Access to free NOWTV, for streaming all your favourite shows
A generous pension package
Private healthcare
Discounted mobile and broadband

Where you’ll work:

Osterley

Our Osterley campus is a 10-minute walk from Syon Lane train station. Or you can hop on one of our free shuttle buses that run to and from Osterley, Chiswick Park, Gunnersbury, Acton Town and Ealing Broadway tube stations. There’s also plenty of parking, bike shelters and showers.

On campus you’ll find six subsidised restaurants and a Waitrose. You can keep in shape at our subsidised gym, catch the latest shows and movies at our cinema, get your car washed and even get pampered at our beauty salon.

Inclusion:

Recognised as an ‘Inclusive Top 50 Employer’ and a ‘Times Top 50 Employer for Women’, we’re working hard to ensure we’re a truly inclusive place to work. This means we don’t just look at your CV. We’re more focused on who you are and the potential you’ll bring to Sky. We also know that everyone has a life outside work, so we’re happy to discuss flexible working.

And we’ll do everything we can to support you during your application. If you need us to make any adjustments to our recruitment process, speak to our recruitment team who will be happy to support you.

Why wait?

Apply now to build an amazing career and be part of a brilliant team. We can’t wait to hear from you.

To find out more about working with us, search #LifeAtSky on social media. A job you love to talk about.

Just so you know: if your application is successful, we’ll ask you to complete a criminal record check. And depending on the role you have applied for and the nature of any convictions you may have, we might have to withdraw the offer.",3.8,"Sky
3.8","London, England",-1,10000+ Employees,1989,Company - Public,TV Broadcast & Cable Networks,Media,$5 to $10 billion (USD),-1
Data Engineer,-1,"Permanent Data Engineer opportunity within the professional services industry.

Responsibilities:

Design, build, implement and maintain Data Migration processes;
Design, build, implement and maintain Data Integration and ETL/ELT pipelines;
Design, build, implement and maintain databases (Snowflake, Dynamics, PostgreSQL, MySQL/MariaDB, Oracle, Sybase);
Design, build and maintain solutions incorporating the company’s Data Lake;
Provide Business Level through to Technical Level analytical expertise for data-related aspects of IT projects;
Design, build, implement and support programs and applications for database management, data management and user interaction with various data sources;
Design and document the architectural components needed to transform raw transactional data in to a consistent and coherent dataset suitable for BI use. Ensure guidelines exist for integration, cleansing and data modelling including data warehouse structures (aggregation, federation, virtualisation);
Understand the data components needed to meet business requirements including currency, quality, granularity, velocity and structure.

Skills/Knowledge Required:-

Extensive experience designing, building and maintaining Data Migration and Integration solutions using a recognised Business Integration tool, including the use of a programming language within a tool;
Experience designing, building and maintaining databases, including procedural programming and SQL scripting on a major RDBMS;
Experience working with one of the major cloud platforms (Amazon AWS / Microsoft Azure / Google Cloud);
Experience working with event-based and streaming technologies such as Apache Kafka;
Experience working within the Scrum agile framework.

Skills/Knowledge Desired:-

Experience with Sybase ASA on Windows including replication, procedural programming and general SQL scripting;
Experience in AWS data pipeline services;
Experience with Microsoft SQL Server 5 or above;
Experience in Oracle 11g on Windows and Unix/Linux;
Experience designing and building Data Lakes;
Experience of working with NoSQL databases, e.g. MongoDB;
AWS Certified Developer (Associate) and/or AWS Certified Solutions Architect (Associate) certifications;
Certified Data Vault 2.0 Practitioner (CDVP2TM)

Qualifications

University degree or Technical diploma, preferably in an Information Technology / Information Systems subject.

Permanent Data Engineer opportunity within the professional services industry.",4.2,"Robert Walters
4.2","London, England",-1,1001 to 5000 Employees,1985,Company - Public,Staffing & Outsourcing,Business Services,$1 to $2 billion (USD),-1
Senior Data Engineer,-1,"Location

City of London, London


Contact:

Harry Hudspeth

Sector:

Investment Management

Contact email:

hhudspeth@venquis.com


Job type:

Permanent


Job ref:

BBBH15057_1604395912


Salary/Rate:

£90000.00 - £100000.00 per annum


Published:

about 4 hours ago


Startdate:

ASAP


Expiry date:

2020-12-03
* Data Engineer * Investment Management * Permanent * City of London *

We are currently working with a leading Investment Management client based in the City of London that I currently looking for a Data Engineer to join their front office performance and risk team within the business.

You will be working alongside the engineering team and portfolio managers for a large implementation project across the business, whilst also doing data research tasks with mapping, and data cleansing.

Skills:
Strong Python programming language experience with also PySpark
Experience of working within a cloud environment, either Azure or AWS
Bid Data
Strong Spark experience
Data Lake
Hadoop
If this opportunity is of interest, please contact hhudspeth@venquis.com with your latest CV please.
Apply

Go back",4.3,"Venquis
4.3","City of London, England",-1,51 to 200 Employees,2011,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Data Engineer,-1,"Let’s make passion pay

We started from one belief: that businesses deserved better. That people pouring their hearts into their passion should be paid reliably, efficiently and affordably. After all, passion, not money makes the world go round. So we decided to shake up the payments industry for good.

From humble beginnings, we’ve become one of Europe’s fastest-growing FinTech companies, winning numerous awards (including the Tech Track 100, National Business Awards and the Europe-wide Inc 5000). We pride ourselves on using smart technology and an unswerving dedication to service, leaving customers free to grow their companies. After all, doing so is hard work - taking payments shouldn’t be.

To continue innovating and leading the payments industry, we need exceptional individuals. Our success is due to our talented teams going above and beyond to make payments painless, security simple and compliance easy for our customers. Our core values of Brave, Defiant, Supportive and Honest underpin everything we do. As employees you are given the freedom to work autonomously, challenge the norm, bring new ideas and take ownership. Sound good? Then keep reading...

The Role

We have a need for an experienced data engineer to join our data team and play a key role in the formation of a new problem-focussed, multi-disciplinary “squad”.

What you’ll do...
You’ll bring your expertise in data engineering to design and build robust data pipelines and solutions that support important business processes, primarily in our finance team. Often the sources and outputs of the data are atypical so you’ll need to be resourceful and creative to find a solution.
Comprising of BI and business specialists, you’ll play a leading role in the squad, providing engineering guidance and leadership on how problems can be solved efficiently and communicating proactively on progress and best practice.
You’ll work closely with our main Data Engineering team to ensure solutions developed sit comfortably within the organisational preferences on technology and methodology.
You’ll support the wider BI team on best practice, especially in Python, git, TDD and CI/CD.
What you'll bring...
You have extensive experience developing ELT pipelines, data warehousing, data modelling and automating processes.
You are motivated by making a commercial impact through your work. You’re pragmatic and know when to use which technology.
You have got demonstrable experience in leading and developing solutions that support analysis and business processes in commercial environments. You know how to shape requirements, work productively, communicate with your stakeholders and organise resources.
You can communicate effectively within a team and with non-technical stakeholders to understand requirements.
You have got a keen eye for detail and are renowned for having high standards in your work.
Ideally you will also have experience with...
MPPs, especially BigQuery.
MSSQL, SSIS and SSAS
A scripting language such as Python and orchestrating processes with Airflow.
Dbt for transformation.
Cloud services and infrastructure, especially GCP.
Implementing and following best practices in CICD and Git in a data environment.
Some knowledge of. BI dashboarding and self-service tools, especially PowerBI and Looker would be useful.
You’re comfortable working in an agile environment.
What you will get…

We have a lively social scene including Film nights, Book Club, Cheese Club, Sports and Fitness Clubs, seasonal parties and a welcoming culture to make you feel right at home when you’re at work.

We also have 25 days annual holiday (which increases over time), discounted private healthcare, travel loans, a cycle to work scheme, subsidised gym membership, free fruit and drinks and exclusive discounts at many High Street stores.

So if you want to help make passion pay, get in touch",3.8,"PaymentSense
3.8","London, England",-1,201 to 500 Employees,2009,Company - Private,Financial Transaction Processing,Finance,$500 million to $1 billion (USD),-1
Data Engineer,-1,"Data Engineer - London


London

Apply now

Refer someone

As a Data Engineer in the Data and Analytics team, you will be working on a global initiative to take our data platforms and practice to the next level.

Using the latest technologies and techniques, you will be developing analytic reporting solutions as part of an agile team for our trading businesses. The platform is one year old and this is an opportunity to contribute to the evolution of the platform.

We are looking for an experienced data engineer. Experience in Spark and building data pipelines is a must. Containerization/Kubernetes experience is highly desirable, as is experience in application monitoring solutions such as Grafana/Prometheus.

This is a rapidly evolving area and we want people who will bring a learning mindset. Your success will be enabled by the ability to communicate effectively with a diverse set of stakeholders. If you can code, love data and want to work on innovative projects, then apply now!

The Corporate Operations Group (COG) brings together specialist support services including workplace, human resources, market operations and technology. COG's purpose is to drive operational excellence through business-aligned services with a focus on quality, cost and risk. COG comprises the following divisions: Business Improvement and Strategy, Business Services, Human Resources, Market Operations, and Technology.

Find out more about Macquarie at www.macquarie.com/about

Macquarie understands the importance of diversity and inclusion - our long history of success has come from being different. At Macquarie we value the innovation and creativity that diversity of thought brings. The one thing we all have in common is our focus on high performance. If you're capable, motivated and can deliver, we want you on our team.

Macquarie is an equal opportunities employer and does not discriminate on the grounds of age, disability, sex, sexual orientation, gender reassignment, gender identity, marriage, civil partnership, pregnancy, maternity, race (including colour and ethnic or national origins), religion or belief.",3.8,"Macquarie Group
3.8","London, England",-1,10000+ Employees,1969,Company - Public,Investment Banking & Asset Management,Finance,$5 to $10 billion (USD),-1
Data Engineer,-1,"Moneybox is growing rapidly, and our technical and data teams are no exception. We have more users, more accounts, more money invested, more features, more code, more data, and more team-members than ever before. We’re looking for a database administrator & data modeller who can take our set-up and infrastructure to the next level. In this unique role, you’ll be the interface between the cloud apps and insight teams, collating, ingesting and organizing data to drive action and results.

Our tech stack:

Microsoft Azure
GitHub
TeamCity
Terraform
Azure DevOps
Azure Application Insights
Octopus Deploy
BASH / Shell Script
Power Shell
C# / .NET Framework, .Net Core ASP.NET Web API
Sql Server
CosmosDb
Azure Service Bus
What you'll do
Working directly with the Head of Insight and Head of Cloud Apps and their teams, this role will be responsible for but not limited to the following:
Responsibilities:
Own, maintain, and improve our data processing and analytical platforms including choosing and adding new tools.
Support the insight team with more complex or novel data processing tasks (e.g. python scripting)
Act as a best practice resource for SQL query optimization and performance for the Insight and Dev Teams.
Build and maintain new integrations to ingest and integrate new sources of data
Work with moneybox dev teams and insight team to build and maintain a reliable, meaningful, and accurate core analytical data warehouse which stays up-to-date as our products grow and change
Organise core data into references and summary tables (e.g. customer segmentation) making the Insight data analysts more efficient.
Advise the senior leaders on the selection and evaluation of suitable tools including a business intelligence tool that is flexible to the future needs of the business. Lead implementation of this once selected.
Work with tech teams, and compliance to ensure that analytical data and supporting platforms are secure, appropriately restricted, and comply with policy
Stay up-to-date with industry trends and help insight and tech teams understand where new technology could pragmatically deliver value
Manage and monitor the cost, efficiency, and speed of data processing
Who you are
A driven, ambitious individual who’s looking to build their career at an exciting very- fast-growing company
Curious mindset who is motivated by improving processes and organizing information in practical ways.
Bias for action, valuing execution over complexity.
Naturally personable, great communicator who has a passion for their work and the people they work with.
Excited about being part of a fast-growing company that’s trying to make a positive mark on the world.
Knows how to have fun whilst maintaining a professional outlook
Experience and Skills
Essential skills:
Fundamentals of database administration and optimisation
Practical experience of analytical data structures, and data modelling approaches
Working with APIs, and Extract Transform Load processes
Python (or similar scripting language) for data processing
Desirable skills:
Hadoop and big data processing
Data Warehousing, Data Lakes, and master data management
Scripted data processing and visualisation (e.g R language and processing)
Cloud storage and compute systems (- particularly Azure Data Factory, Data Lakes, and Data Bricks)
BI Experience on tools such as Power BI, Tableau, Looker etc.
What's in it for you?
Opportunity to join a fast-growing, award-winning and super ambitious startup
Work with a friendly team of highly motivated individuals
Be in an environment where you are listened to and can actually have an impact
Thriving collaborative and inclusive company culture
Competitive remuneration package
Company Share options
Perkbox – selection of 200+ perks
25 days holiday + bank holidays
Please read before you apply!
By sending us your application you acknowledge and agree to Moneybox using your personal data as described below.
We collect applicants’ personal data to manage our recruitment related activities. Consequently, we may use your personal data to evaluate your application, to select and shortlist applicants, to set up and conduct interviews and tests, to evaluate and assess the results, and as is otherwise needed in the recruitment process generally.
We do not share your personal data with unauthorised third parties. However, we may, if necessary, share your personal data to carefully selected third parties acting on our behalf. This may include transfers to servers and databases outside the country where you provided us with your personal data. Such transfers may include for example transfers and/or disclosures outside the European Economic Area and in the United States of America.
If you are unsuccessful in your application, we may keep your details on file so that we can tell you about other suitable vacancies which may be of interest to you when they arise in the future. If you would rather we did not keep your details on file, you can contact us at email: DPO@moneyboxapp.com",4.4,"Moneybox
4.4","London, England",-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"We are looking for a passionate Senior Data Engineer to join us in our goal; to become the world's best print on demand consumer. We’re always on the hunt for amazing people, keen to make an impact every single day!

Our mission is simple: we aim to remove all barriers and enable entrepreneurs, brands and influencers to test and scale new product ideas and e-commerce businesses faster and further than ever before by digitalising traditional print environments stimulating the global adoption of print-on-demand.

Our platform allows clients to easily design new products and publish them instantly to the landing pages and highly customisable white-label e-commerce stores included within the Moteefe platform, or to a third-party e-commerce store solution of the client’s choice. Production is on-demand. This means that sales can be made before the item is produced. This agility transforms the economics of the supply chain.

Recognised by The Sunday Times Fast Track as one of the fastest growing tech companies in the UK and by Deloitte in 2020 as one of the fastest growing e-commerce businesses.

We truly believe in the power of human potential, that's why at Moteefe we give our employees

freedom to operate with their own entrepreneurial ambition. We strive for the best possible results by working as a team to enable partnerships across our community. These are our core values and beliefs. We encourage our employees to take as much annual leave as they need and are keen advocates in well-being with our flexible working from home policy, health is wealth! We ensure you have everything you need to do your job successfully, you can pick your own technical equipment that suits the way you work, whether that's in an office that is fully stocked with snacks to keep you going, or working from a coffee shop or from home.

What you’ll do with us:

You will be joining our Data and Insights team, and be key to transforming how the business leverages its data asset. Data and Analytics has been identified as a key enabler for the company to scale. Our vision is for decisions, investments, interventions and developments to be driven by robust measurement, analysis and insight across all business units. It’s an exciting part of our journey, and you have an opportunity to shape how we become truly ‘data-first’ as an organisation.

Working with our new data infrastructure stack, you’ll become an expert in our data sources as well as being passionate about the outcomes that we need to drive. You’ll partner with our awesome engineering teams to ensure a high quality and comprehensive data flow, integrity in our metrics logic, and provide a consumption layer where the business has access to all the data it needs.

In addition you will facilitate the wide-scale adoption for feature-testing in the business. managing the process and reporting back to senior management on what we have learnt and how we can optimise further.

In short this is a high-impact role for a technical individual who is commercially astute and wants to be close to the decision-making part of the action. It’s the opportunity to make a difference and to define the data-dna of the company that will serve us well for years to come.

Requirements

What we need from you (must have skills):
Have extensive skills in sql, both at production grade and at analytical level, gained through intensive application in a commercial business environment
Have skills in extracting, transforming and transporting data within and between data environments
Hands-on exposure to development of ‘data views’ with one or more BI tools such as PowerBI, Looker, Tableau, Microstrategy.
Thought leadership on Data Engineering best practices, and what ‘good looks like’ from a consumption-layer design perspective
Familiar with the concept of AB testing within an e-commerce environment, with a good appreciation of ‘best practice’
Strong communication and collaboration skills
Passion for delivering insights from data
Pragmatic, self-starter with a proven track record for delivering impactful work
Attention to detail
What we'd love from you (nice to have skills):
Skills gained in data governance and/or metric management
Retail/Technology sector experience
Start-up experience
What to expect when interviewing with us:

We have the flexibility to interview at the pace that is convenient for you! Our Recruitment team will reach out to you and have an in depth conversation to find out more about you, if interested we will then proceed to interview. Your recruiter will guide you through the full process.

We will send you a Tech challenge to complete, if it looks good we will have an interview to discuss this in further detail. If everything is aligned you will meet our Head of Data and our CTO to discuss further about the way we work and ask any questions you may have, followed by an Architectural design interview and code review.

*We are a truly inclusive environment and encourage anyone to apply regardless of age, cultural background, disability, gender, marital status, nationality, political belief, race, religious or sexual orientation.",3.7,"Moteefe
3.7","London, England",-1,51 to 200 Employees,2015,Company - Private,General Merchandise & Superstores,Retail,Unknown / Non-Applicable,-1
Data Engineer,-1,"London
Up to £49,000!!

A reputable organisation based in London are seeking a talented Data Engineer to design and develop complex and group-wide data solutions.

Job Duties
Plan and achieve agile sprint tasks from which the technical solutions will be created
Support the data visualisation and ETL data processing, ensuring that the services are up to date
Input into and manage our data artefacts, which will include planning, task completion, unit testing, peer review, release, meta data, data modelling and deployment
Attend DataOps Design Authority meetings to provide input to our data value delivery methods
Create and input meta data to sufficient levels, which will assist the business in understanding what they are able to do with it and give literacy
Convert user stories to technical tasks, translating the business goal to a technical one, allowing the delivery of a technical solution
Use a number of modern data platform tools set up in an agile delivery method to progress in a journey towards continuous integration and deployment of projects in the cloud
Ensure all analysis, decisions made and activity undertaken in fulfilling of this role considers the fair treatment of our customers
Skills Required
Delivering data engineering solutions including ETL development
Data Integration and advanced analytics
Modern data paradigms within the cloud in order to enable a business to maximise its value from data using technologies: Wherescape, SSIS, ADF, Jenkins, PowerBI, Tableau and MSBI
RBDMS: Oracle, T-SQL, Python
Experience using Jira
Proven data, analytics and engineering
Software Engineering
Logical and lateral thinking considering all angles in decision making
Communication to all levels of stakeholders - demonstrate the communication of complex data management issues to non-technical stakeholders using PwerPoint and Inforgraphics
Communicates clearly and logically using ""story telling techniques"" simple language and visuals to suit the audience
Continuous improvement skills with ability to streamline processes using Lean Six Sigma methodology
Within a fast-paced, technology-focused environment this role is sure to be a quick turnaround - so don't miss out!

The client are offering a competitive salary of up to £49k and offer great benefits such as discretionary bonus, private healthcare and more!

If you are looking to be part of a friendly, energetic company in London then please click the 'apply now' function or alternatively please contact Paolo.

Snowflake - PowerBI - Wherescape - SSIS - Jenkins - Tableau - ETL

Certes Computing (and all of its subsidiary companies) is committed to promoting equality and diversity in its business operations.
Published:
20th Oct 2020
Sector:
IT
Start Date:
ASAP
Type / Duration:
Permanent",2.6,"Certes
2.6","London, England",-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Company:
Telefónica S.A.
giffgaff is the commercial brand of Telefónica UK Limited, a leading digital communications company owned by Telefónica S.A. We like to do things a little differently here at giffgaff.

We may be a small company, but we like to think big and create some radical waves in the telco land. At the heart of it, we believe in simplicity. A better way to do mobile. We'd rather you stay with us because you want to, not because there's a nasty contract forcing you to. It's why we work our socks off every day to keep you and guess what? It works. We're uSwitch Network of the Year 2019.

About the Team:

The core mission of Data Engineering team is to deliver the core data infrastructure and data processing pipelines that support giffgaff’s data products and business insights. Our team works horizontally supporting all areas of the business from a data warehousing perspective and has a strong technology focus.

Your Role:

Reporting into the Data Engineering Technical Lead, the Data Engineer is expected to have deep understanding of data technologies and strong software engineering expertise, along with a deep interest in data analytics, machine learning and AI.

The role involves creating data solutions to process data at scale, both in batch and real-time pipelines, to support a wide range of data-driven projects and support our transformation into an AI-ready organisation.

Responsibilities:

The key responsibilities of the Data Engineer are:
Implement workflows to ingest data into a Snowflake data warehouse for a variety of data sources
Implement data transformation pipelines in real-time and batch environments
Support all product teams in adopting our data engineering tech stack to generate new data streams
Collaborate with Data Science and Business Intelligence teams to identify requirements and develop the necessary data workflows to deliver against those requirements
Skills & experience:
University degree in Computer Science, Software Engineering or related subjects or equivilent experience
Experienced in Java 8+ and Python
Relational and non-relational databases. Experience with Snowflake a plus.
Batch processing frameworks, such as DBT, Flink, Apache Airflow, etc.
Message brokers / stream processing technologies (Kinesis, Kafka, Storm, Spark Streaming, Flink, etc.)
Familiarity AWS, Docker, Kubernetes, Amazon EKS
Continuous Integration with Jenkins
Test-Driven Development and XP
Additional Information:

This role involves close collaboration with data scientists, data analysts and product engineers.

Note this role was previously advertised as a 12 month FTC but is now a permanent role

Grade:MPG4

Finally...

This is a chance to work for one of the most sought after UK companies, highly regarded for its community model. In return for your outstanding efforts, you’ll be rewarded with a competitive salary and excellent benefits.

We believe that hard work should be supported and recognised. This position plays an important role across the business, allowing you to work cross functionality, take on more responsibility and gain experience, which will greatly benefit you in the future.",4.2,"Telefónica
4.2",Leipzig,-1,10000+ Employees,1924,Company - Public,Telecommunications Services,Telecommunications,$10+ billion (USD),-1
Data Engineer,-1,"Are you a skilled data engineer who has helped enterprises deploy production-ready data platforms?

Are you keen to implement cutting edge cloud data services, with focus on how consumers use the platform?

Are you interested in building on your existing data and cloud experience?

About Us

We’re an innovative tech consultancy - a team of problem solvers. Since 1993 we’ve been finding better ways to solve complex technology problems for some of the world’s leading organisations and delivered solutions that millions of people use every day.

We bring together experts from diverse backgrounds and experiences in a collaborative and open culture to deliver outstanding outcomes for our clients, and a stimulating and rewarding environment for our people.

We’re looking for data specialists with experience in Data Development, ETL, Data Warehousing and dealing with large sets of structured, semi-structured and unstructured data.

About the Role

As a BJSS data engineer you’ll help our clients deploy data pipelines and processes in a production-safe manner, using the latest technologies and with a DataOps culture.

You’ll work in a fast moving, agile environment, within multi-disciplinary teams, delivering modern data platforms into large organisations.

You’ll get to work with some of the brightest and best in the industry on some of the most exciting digital programmes around.

About You

You’ll have the expertise and confidence to work collaboratively with engineers, architects and business analysts in multi-disciplinary teams on client site, and have experience in several of these areas:
Python
AWS or Azure data services (e.g. Data Factory, Synapse, Redshift, Glue, Athena etc.)
Databricks or Apache Spark.
At least one distributed NoSQL database (e.g. HBase, Cassandra).
Stream processing technologies such as Kafka, Kinesis etc.
Hadoop ecosystem exposure.
Apply Now!",3.8,"BJSS
3.8",Greater Manchester,-1,1001 to 5000 Employees,1993,Company - Private,IT Services,Information Technology,$100 to $500 million (USD),-1
Data Engineer,-1,"Who are Metapack?

We are a tech company that works with a lot of the world’s biggest ecommerce players to integrate them with over 450 carriers around the world to make delivery easy. We are a multi-tenant SaaS platform. We give them the platform to help consumers decide their delivery preference and track the parcel’s progress whilst also providing the retailer with intelligent smart decisions about how to send the parcel – all underpinned with lots of data. We work with well-known global retailers and major brands such as ASOS, Adidas, Burberry, John Lewis, Boohoo, eBay, and Zalando. In fact, we work with so many retailers and carriers it’s highly likely that you’ve interacted with us at some point when ordering goods online!

In August 2018, we were acquired by Fortune 100’s 2nd fastest growing company, stamps.com. We have super ambitious and exciting plans all centred around our tech. Metapack will play a role in shipping around 600 million parcels in 2018 and with the wider stamps.com family the number rises to 2.5bn parcels. Metapack has been growing at 40% year on year over the last 5 years and continues to grow at a rapid rate.

Our Values;

The way we work really is at the heart of Metapack, and our 4 core values are brought together to give a sense of our culture.

With Innovation and Integrity at our core, we have a flat and open culture where data & evidence, backed by honest and frank discussions, beats subjective opinion and hierarchy. We Collaborate with energy and Passion on meeting the needs of our fantastic customers and partners.

We passionately believe in forming autonomous, cross functional teams who are empowered to deliver our ambitious strategy. With stamps.com ownership comes the ability to operate largely independently away from Board meetings and old world thinking but with the financial support of a high performing tech company. Energy and passion for our business and customers is a part of the MetaPack culture – and we love working with like-minded people.

Why would I want to be a Data Engineer at Metapack?

Data is key to the Metapack’s strategy. We work at scale, pace and with the latest architecture patterns and tech. We process thousands of events per second and our massive dataset keeps growing at a staggering pace. We keep improving our data platform and data engineering stack to accommodate growth, enable novel solutions and provide the best service to our customers.

We have a flat and open engineering culture where data, & evidence beats opinion and hierarchy, backed by honest and frank discussions. We passionately believe in forming autonomous, cross functional teams who are empowered to deliver our ambitious strategy. With stamps.com ownership comes the ability to operate largely independently away from Board meetings and old world thinking but with the financial support of a high performing tech company. Energy and passion for our business and customers is a part of the Metapack culture – and we love working with like-minded people.

What would I be doing?

Contributing to the design, build and operational management of our data lake and analytics solution on top of proven AWS data technologies like S3, Athena, Lambda, Kinesis, Glue
Using state of the art technologies like Airflow and Spark to process data and get our dataset just right
Developing frameworks and solutions that enable us to acquire, process, monitor and extract value from our massive dataset
Supporting the Data Analysts and Data Scientists with automation, tooling, data pipelines and data engineering expertise
Delivering highly reliable software and data pipelines using Software Engineering best practices like automation, version control, continuous integration/continuous delivery, testing, security, etc.
Define, implement and enforce automated data security and data governance best practices within the solutions designed
Mentoring more junior colleagues and being mentored by more senior colleagues

What key skills and experience do I need?

A Software Engineering background
Experience developing and supporting robust, automated and reliable data pipelines in Python and SQL
Experience with data processing frameworks like Pandas or Spark
Experience with streaming data processing
AWS, Azure or Google Cloud experience
Continuous integration/delivery environment experience with a passion for automation
Knowledge of a Data Orchestration solutions like Airflow, Oozie, Luigi or Talend
Knowledge of both relational and non-relational database design and internals
Knowledge of how to design distributed systems and the trade-offs involved
Experience with working with software engineering best practices for development, including source control systems, automated deployment pipelines like Jenkins and devops tools like Terraform

It would be great if you also could bring

Practical understanding of GDPR and other considerations regarding data security
Knowledge and direct experience of using business intelligence and analytics tools (Tableau, Looker, Power BI, etc.)
Production experience working with very large datasets
Experience with big data cloud technologies like EMR, Athena, Glue, Big Query, Dataproc, Dataflow.
Data Science/Machine Learning know-how
A desire to constantly challenge the norm
Willing to attend conferences, webinars and meet-ups and share the learning

What are the perks?

25 days holiday, 10% bonus (paid quarterly), pension, enhanced maternity and paternity leave, group life insurance scheme, private medical healthcare
Discounted gym membership, cycle to work scheme, interest free season ticket loan
Dynamic, open culture with lots of social activities",3.9,"MetaPack
3.9","London, England",-1,201 to 500 Employees,1999,Company - Public,Computer Hardware & Software,Information Technology,$25 to $50 million (USD),-1
Data Engineer,-1,"Blis is an award-winning, global leader and technology innovator in location-based data, analytics, and advertising. We help brands such as McDonalds, Samsung, and Unilever to understand and reach their current and potential customers and drive real-world business outcomes. With 24 offices across 5 continents, and over 200 people on the team, we are a truly international company with both a global culture and scale. We’re headquartered in London, venture capital backed, financially successful and stable, and looking forward to continued growth. We’d love it if you could join us on the journey!

We are looking for brilliant, creative, curious, and experienced Data Engineers to support our Data Platform team and infrastructure. This team owns the big data plumbing and processing that power our entire business, with a remit that spans data engineering, data analysis, and data science. We process over 350gb an hour, over around 400,000 incoming events a second, and maintain petabytes of analytical storage. We use technologies like Spark, Flink, Kafka, ScyllaDB, Redshift, Druid, BigQuery, and Postgres and we’re constantly looking at how we can do things better. This is a growing team with big responsibilities and exciting challenges ahead of it, as we look to reach the next 10x level of scale and intelligence. Our employees are passionate about teamwork and technology and we are looking for someone who wants to make a difference within a growing, successful company.

At Blis, Data Engineers are a combination of software engineers, devops, and data analysts. They actively write code, typically in either Scala or Python to support new products, process massive amounts of data, or implement new machine learning models, but also help own our overall data and processing infrastructure. Their understanding of our business and the data also helps us to innovate, by discovering new opportunities or better ways of operating. They also work with our data scientists to explore, implement, improve, and maintain our algorithmic technologies. With soft boundaries between teams, you’ll have opportunities to dip into other domains as much or as little as you’d like. You’ll be someone who has a passion for delivering products that delight and astound your customers and that have an enduring impact on the business. You’ll focus on long-lasting agility in our technology and team, which almost always means practising Good Engineering and following Lean Development principles. And, of course, you’ll enjoy being part of a team that supports each other through mentoring, brainstorming, and pairing up to solve ambitious challenges.

This is a full-time, permanent position based in the UK. We’ve embraced home working and expect this to continue indefinitely, but occasional face-to-face meetings may be necessary in the future from our London/ Edinburgh engineering hub.

The Role:

Innovate, implement, support, and iterate on our batch and streaming data-processing code, ETL pipelines, and systems
Work with data scientists and other engineers to implement and optimise machine learning algorithms, pipelines, and systems
Participate in an on-call rota to support our systems in production
Support, mentor, and pair with other members of the team to advance our team’s capabilities and capacity
Help Blis identify and take advantage of new and innovative opportunities for commercial and technical growth

Required:

5+ years direct experience solving complex, large-scale data challenges
Mastery of either Python or Scala for data-intensive use cases
Experience with distributed processing using Spark, Hadoop, or similar
Familiarity with orchestration frameworks, like Luigi, Airflow, or Oozie
A full-stack understanding of production data analytics and ingestion engineering
Hands-on implementation and architectural familiarity with streaming, relational, and non-relational databases and systems
Advanced knowledge of cloud based services (AWS, GCP)
Excellent working understanding of server-side Linux
Knowledge of general engineering principles and design patterns
Degree in Computer Science, Software Engineering, or similar

Desired:

Operational familiarity with Cassandra, ScyllaDB, HBase, or similar datastores
Practical experience optimising queries and code accessing relational row and/or column stores (e.g. PostgreSQL, BigQuery, RedShift)

Key Technologies We Use (buzzword bingo, in no particular order):

Google Cloud, Cloud Composer, Dataproc, BigQuery, Spark, Solr, Elasticsearch, Druid, PostgreSQL, ScyllaDB, Redis, Kafka, Flink, Docker, Kubernetes, Kibana, Jenkins, Prometheus, Grafana, Github, Java, Spring, Python, Scala, Javascript, AngularJS, ReactJS

What Blis Can Offer

Opportunity to work with a market leader in the data technology space, with significant visibility across the business, and working with groundbreaking technology.

Blis bank-holiday - an extra bank-holiday courtesy of Blis
Free eye tests
Childcare vouchers
Cycle scheme
Day off on your birthday!
Competitive packages
Early finish Friday - because you deserve it
Pensions - saving for the future?
Some office-centric perks are being re-evaluated in light of our shift to remote working

We are an equal opportunity employer and strongly believe that diversity makes us a better company.

Role Title Synonyms: big data engineer, data systems engineer",3.4,"Blis
3.4","Edinburgh, Scotland",-1,51 to 200 Employees,-1,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
Data Engineer,-1,"£35,000 – £40,000/annum

As a data engineer within the exciting, new claims advanced analytics capability, you will be building big data solutions to solve some of the organization’s toughest problems and delivering significant business value. This is a really exciting time to join as you will be helping to shape the big data analytics architecture and technology stack within a new cloud based data lake

Responsibilities:

Shape the portfolio of business problems to solve by building detailed knowledge of data sources (internal and external)
Model data landscape, obtain data extracts and define secure data exchange approaches
Acquire, ingest, and process data from multiple sources and systems into Cloud Data Lake
Operate in fast-paced, iterative environment while remaining compliant with Information Sec policies/standards
Collaborate with data scientists to map data fields to hypotheses and curate, wrangle, and prepare data for use in their advanced analytical models
Help architect the strategic advanced analytics technology landscape
Build re-usable code and data assets

Codify best practices, methodology and share knowledge with other data engineers/scientists in the organisation

Measures:

Become expert in claims data sources
Framework set up across the company to define best practice in data engineering space
Robust data sources in the data lake with increasing proportion of data held in the lake
No unexpected issues arise
Successful delivery of cloud projects

“Single version of the truth” tables and views in the cloud that are used by a wide variety of end users providing accurate re-producible

Skills & Experience:

Meaningful experience (2+ years) with at least two of the following technologies: Python, Scala, SQL, Java
Experience and interest in Cloud platforms such as:, Azure, AWS or Databricks
The ability to work across structured, semi-structured, and unstructured data, extracting information and identifying linkages across disparate data sets
Meaningful experience in at least one database technology such as:
Distributed Processing (Spark, Hadoop, EMR)
Traditional RDBMS (MS SQL Server, Oracle, MySQL, PostgreSQL)
MPP (AWS Redshift, Teradata)
NoSQL (MongoDB, DynamoDB, Cassandra, Neo4J, Titan)
Understanding of Information Security principles to ensure compliant handling and management of data
Experience in traditional data warehousing / ETL tools (Informatica, Talend, Pentaho, DataStage)

Ability to clearly communicate complex solutions.

Please email your CV to: paul@dynamix-recruitment.co.uk",5.0,"Dynamix Recruitment Ltd
5.0","Ipswich, England",-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"H&R Talent are seeking a Data Engineer for a large-scale business located in London to join their growing team of analytics experts. You will be working within a team to ensure the company’s data processing and analytical platforms are efficient and complete. You will be developing, maintaining, and testing infrastructures for data generation. You must be self-directed and comfortable supporting the data needs of multiple teams, systems, and products.

Requirements:

Experience in cloud platforms (Google Cloud, AWS & Azure)
Strong knowledge in PowerShell
Knowledge of Docker and Kubernetes
Expert with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.",-1,H&R Talent,"London, England",-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Cloud Infrastructure Engineer,-1,"WHO WE ARE

We are Allvue Systems, a rapidly growing software company formed by the merger of AltaReturn and Black Mountain. Allvue has over 500 employees in offices throughout North America and Europe. We are the leading provider of software solutions for the Private Capital and Credit markets. Whether a client wants an end-to-end technology suite, or independently focused modules, Allvue helps eliminate the boundaries between systems, information, and people. We're looking for ambitious, smart, and creative individuals to join our team and help our clients achieve their goals. Define your own future with Allvue Systems!

What We Value
Intelligent individuals looking to apply themselves creatively
People who are comfortable speaking up, sharing ideas and driving change
Energetic and passionate teammates looking for more than just a job to pay the bills
Hard-working individuals who habitually do more than asked
What we need:
Degree in Computer Science, Engineering or related discipline or 7+ years of directly relevant work experience
Proven working experience in installing, configuring and troubleshooting Windows and Linux based environments.
Experience with infrastructure and application management considerations including backup and DR strategies, data security and encryption, resource monitoring, patch management, high availability, load balancing, etc.
Solid experience with Administration and performance tuning of application web stacks (i.e. Tomcat, Apache, IIS, etc.)
Solid understanding, troubleshooting, and installation of Enterprise Servers (Linux and Windows) and applications.
Solid Cloud (AWS, Azure AD, etc) experience is preferable
Experience with AWS products including EC2, EBS, ELB, IAM, S3, Route 53, VPCs, CloudWatch, CloudTrail, Inspector, OpsWorks, Gateways, Lambda, etc.
Experience working with Azure PaaS, Azure networking, and Azure site reliability solutions.
Experience with virtualization and containerization (e.g. VMware, Hyper-V, etc.)
Experience creating automated processes using well-known frameworks such as PowerShell, Chef, etc.
Automation software (i.e. Chef, Puppet, cfengine, Terraform) is a big plus
Scripting skills (e.g. PowerShell, Ruby, Python, etc.) a plus
Networking Knowledge (TCP/IP, WAN, LAN, DNS, Firewall) including AWS is desired
Microsoft SQL knowledge and administration are pertinent and desired


Your Responsibilities:
Manage and monitor all installed systems and infrastructure
Install, configure, test, and maintain operating systems, application software and infrastructure management tools.
Proactively ensure the highest levels of systems and infrastructure availability
Liaise with internal team(s) and other personnel to address Infra/System related problem
Provide (act as) 2nd and 3rd level escalation for internal IT/Cloud team
Play an integral role in design, test, and implement customs tools/applications that are relevant to the company needs.
Monitor and troubleshoot application performance for potential bottlenecks, identify possible solutions, and work with developers &/or DevOps to implement the fixes.
Continue identifying, maintain infrastructure security, backup, and redundancy strategies.
Write and Maintain (possible collaboration w/DevOps) custom scripts to increase system efficiency and lower the human intervention time on any tasks to include working w/Devops team.
Participate in the design of information and operational IT support systems
Implementing Network Improvement and architect for the Corporate and Cloud
Implement, administer, and troubleshoot network infrastructure devices, including wireless access points, firewall, switches, controllers, and cloud (i.e. AWS, Azure) based network platforms.
What We Offer
Fun, fast-paced work environment
Constantly evolving, cutting edge technology
The ability to make a significant impact immediately upon jumping in
An opportunity to work with some of the best firms and the best people in the financial industry
The ability to create change in the product we sell, by using the very same solution (in a very different way) to perform your daily job
Numerous team building activities, such as monthly happy hours to promote collaboration
Unlimited Annual Leave
Allvue Systems provides equal employment opportunities (EEO) for all employees and applicants for employment. We recognize the real value of bringing people together from diverse backgrounds, experiences and perspectives - we don't just accept difference, we celebrate and support it. We are committed to advancing these efforts through our strategies to hire, promote, create and support a diverse and inclusive environment throughout our workforce and workplace. It is our policy to prohibit discrimination and harassment of any type without regard to race, color, religion, marital status, age, national origin, ancestry, physical or mental disability, medical condition, pregnancy, genetic information, gender, sexual orientation, gender identity or expression, veteran status, or any other status protected under federal, state, or local law. In addition, Allvue will provide reasonable accommodations for qualified individuals with disabilities.",3.6,"Allvue Systems
3.6","London, England",-1,501 to 1000 Employees,2019,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Just Eat is searching for a Data Engineer to join the Data Systems team. You’ll have the opportunity to work with big data technologies, building scalable and reliable solutions to support real-time analytics, advanced data science and critical operational projects powered by data.

What We Do

The Data Systems team’s role is to build a transformational data platform in order to democratise data in Just Eat. Our team is built on following ideals:

Open Data: We ingest all data produced across Just Eat using batch and realtime pipelines and make it available to every employee in Just Eat. This data is then used to drive analytics, business intelligence, data science and critical business operations.

Self Service: We build tools, frameworks and processes to support self-service modelling and activation of data. Our goal is to empower our users to find, process and consume our data without barriers.

Single Truth: We build services that host all metadata about Just Eat’s data in a single store and promote governance, data culture and Single Source of Truth.

Intelligent Personalisation: We build and maintain a machine learning platform which supports data scientists in developing and deploying ML models at production scale. This allows us to deliver insights, personalisation and predictions to our customers at scale.

How We Do It

Our team is built on the following tenets:

Innovate: We are always learning, growing, inquisitive and keen on new technologies and open source tooling. We love like-minded engineers with a passion to keep our code-base and infrastructure best in class.

Build for Scale: All our tools and components are built for scale and we use Kubernetes and other tools to help us scale automatically.

Cloud based: We use serverless technologies where possible to simplify our estate, technologies like BigQuery, PubSub, Dataflow and Cloud functions allow us to move quickly. In addition, we run a Kubernetes cluster on GKE with many workloads including instances of Apache Airflow.

DevOps culture: Everyone in the team contributes to infrastructure, we have a CI/CD pipeline and we define our infrastructure as code. Our stack includes terraform, jenkins and Helm. Teams monitor their applications using prometheus, grafana and alert manager.

Collaboration & Ownership: All code is owned by the team and we have multiple avenues for collaboration - rotation, pairing and technical showcases. We also encourage team members to own their own code and promote self-governance.

We’re looking for an enthusiastic engineer to join the Self Service Tools Team within Data Systems.

Self Service Tools

Our mission is to enable all employees to be self-sufficient with data, so that data-driven decisions can be made quickly and easily. We build and maintain all of Just Eat’s data centric tools.

We use engineering to simplify tasks, reducing the technical barrier of entry to navigate, explore and consume our data. Our tools use Airflow to unlock the tasks of transformation and egress of data, making these simple functions that can be undertaken by anyone.

We support over 200 active users across the business, building Airflow backed tools that run thousands of DAGs in multiple timezones. We manage and run our own Airflow clusters on Kubernetes. We work together as a team in three countries to produce innovative products and keep data flowing.

Required skills and experience

You should apply if

You love writing well tested, readable and performant code, capable of processing large volumes of data. You’re comfortable with Python.

You love working with Cloud technologies and have experience in working with AWS, Azure or Google Cloud. We use Google Cloud with a mix of services - Kubernetes, Dataflow, PubSub etc.

You can contribute to architecture discussions and influence peers and stakeholders to make better decisions.

You have the inclination to collaborate and ability to communicate technical ideas clearly.

You understand the entire product development lifecycle, from coding to deployments, to monitoring, alerting etc... Our teams maintain all aspects of our product lifecycle, but we don’t expect everyone to be an expert in all of it.

You understand the fundamentals of computing and distributed systems.

Why work at Just Eat?

Just Eat Takeaway.com is a leading global online food delivery marketplace headquartered in Amsterdam and listed on the London Stock Exchange.

We've built our business on having the widest choice available on our platform – connecting millions of customers with over 155,000 restaurants across 23 countries - with over 100 different cuisines from local independents to globally famous restaurants, available to order via our app and website.

We provide the platform and tools to help independent restaurants move online and reach a significantly broader customer base – to generate increased orders and grow their businesses. We also provide the insights, advice, and support our growing community needs to satisfy customers and help raise standards across a vibrant takeaway sector.

We’re built to deliver behind the scenes too. To make Just Eat the great company it is, it takes a great team of people. Which is why all of our colleagues are welcomed into a diverse and inclusive workplace where they feel they can belong. We're passionate about nurturing our people and offer a full programme of training and support to our employees – helping them to develop their careers in a way that suits them.

No matter who you are, what you look like, who you love, where you are from, religious beliefs or takeaway preferences you could find your place at Just Eat. We’re a diverse and inclusive workplace that promotes a sense of belonging, allowing all of our people to bring their most colourful and complex selves to work every day.

#LI-DNI

Just Eat is an equal opportunity employer and values a diverse and inclusive workplace. All qualified candidates will receive consideration for employment without regard to age, race, colour, religion, genetic information, sex, sexual orientation, gender identity, national origin, disability status, or any other characteristic protected by law.

Just Eat is committed to working with and providing reasonable accommodation to job applicants with disabilities. If you are a qualified individual with a disability and need an accommodation or accessibility assistance to complete the online application, please contact us at talent@just-eat.com for assistance.",4.1,"Just Eat
4.1","London, England",-1,1001 to 5000 Employees,2001,Company - Public,Internet,Information Technology,$500 million to $1 billion (USD),-1
Data Engineer,-1,"About graze

graze started in 2008 as a healthy snack subscription service, delivering customised boxes of snacks directly to customers through the post. At the time, there were very few platforms to help us with such a novel idea, so we built our own: from factory machines and systems, to a subscription website and data warehouse.

Ever since those early start-up days, technology and data have always been important in driving our success. Our ability to rapidly develop and iterate tech solutions has been a vital ingredient of our launches into eCommerce and retail, helping us to establish ourselves one of the UK's healthiest snack brands!

In 2019 we were acquired by Unilever, and we're now expanding into Europe. We've already launched graze into Ireland and the Netherlands - and that's just the beginning...

The role, Data Engineer...

Were looking for a Data Engineer to provide technical leadership in our Data team. You will be responsible for managing our data warehouse platform, building and maintaining data pipelines, and designing and delivering technical solutions to business problems.

Our tech stack...

Our AWS Redshift data warehouse is populated by a custom-built batch job scheduling system, which orchestrates hundreds of ETL processes per day. The wealth of data that comes from a vertically-integrated and multi-market consumer goods business means that our pipelines are really diverse... we have processors that deal with anything from ingesting subscription website session data, to retailer sales data, to product weight data from the production lines in our factory!

Our data platform is primarily written in PHP, deployed on Docker on AWS ECS, and we rely on other AWS services like S3, RDS and SQS. Business users can download and upload data via self-serve tools in our internal web application, as well as Tableau dashboards.

Its now been 10 years since graze made our first data hire. A lot has changed in this time, and were always looking for ways to further improve our data systems. Which parts of our system continue to drive real value to the business - how can we make these better? What new tools are out there that were not yet using? Should we migrate our customer-built batch job scheduling to Airflow? We are looking for someone who is excited to get involved in answering these big questions and defining the technical direction that we move in!

What we are looking for in you
Youre curious! You have an ability to quickly learn and adapt, with fast problem-solving capabilities
You have experience in building and maintaining data platforms and pipelines
You love to write clean, efficient, maintainable, version-controlled and well-documented code
You have excellent SQL skills
You enjoy working with end users to build and deploy quality solutions that are valuable to them and the business
What we expect in the first 6 months
Gain a comprehensive understanding of the data technology stack we have at graze.
Gain enough familiarity with the existing codebase that you can comfortably make and review significant changes.
Be instrumental in scoping and specifying changes to the systems.
Be able to identify areas of improvement and progress changes.
Be able to respond to, triage and fix most operational issues.
Build strong relationships with your team and key people you work with.
Whats in it for you?
A competitive salary, BUPA private medical insurance and pension scheme
25 days holiday + 1 health day + 1 volunteering day, per year
Flexible working - throughout 2020, weve all been working from home. We will continue to offer flexible working in future, allowing for a balance between office and remote working days.
Hacker Time: one day per month dedicated to hacking away (no distractions!) on whatever youd like, learning a new language, trying out some new tech, open sourcing some code
We encourage active learning with learning lunches, networking events or more formal qualifications
Opportunities for presenting on technical subjects, in learning and conference-style environments both internally and externally
Plenty of free snacks!
Were all about inclusivity and making you feel like you belong. We are passionate about having an excellent culture with strong meaningful values so the biggest ask we have is for you to be your authentic self every day whilst doing a great job.

Powered by JazzHR",3.7,"graze.com
3.7","Richmond upon Thames, England",-1,201 to 500 Employees,2009,Company - Public,Food & Beverage Manufacturing,Manufacturing,$50 to $100 million (USD),-1
Data Engineer,-1,"Who are Metapack?

We are a tech company that works with a lot of the world’s biggest ecommerce players to integrate them with over 450 carriers around the world to make delivery easy. We are a multi-tenant SaaS platform. We give them the platform to help consumers decide their delivery preference and track the parcel’s progress whilst also providing the retailer with intelligent smart decisions about how to send the parcel – all underpinned with lots of data. We work with well-known global retailers and major brands such as ASOS, Adidas, Burberry, John Lewis, Boohoo, eBay, and Zalando. In fact, we work with so many retailers and carriers it’s highly likely that you’ve interacted with us at some point when ordering goods online!

In August 2018, we were acquired by Fortune 100’s 2nd fastest growing company, stamps.com. We have super ambitious and exciting plans all centred around our tech. Metapack will play a role in shipping around 600 million parcels in 2018 and with the wider stamps.com family the number rises to 2.5bn parcels. Metapack has been growing at 40% year on year over the last 5 years and continues to grow at a rapid rate.

Our Values;

The way we work really is at the heart of Metapack, and our 4 core values are brought together to give a sense of our culture.

With Innovation and Integrity at our core, we have a flat and open culture where data & evidence, backed by honest and frank discussions, beats subjective opinion and hierarchy. We Collaborate with energy and Passion on meeting the needs of our fantastic customers and partners.

We passionately believe in forming autonomous, cross functional teams who are empowered to deliver our ambitious strategy. With stamps.com ownership comes the ability to operate largely independently away from Board meetings and old world thinking but with the financial support of a high performing tech company. Energy and passion for our business and customers is a part of the MetaPack culture – and we love working with like-minded people.

Why would I want to be a Data Engineer at Metapack?

Data is key to the Metapack’s strategy. We work at scale, pace and with the latest architecture patterns and tech. We process thousands of events per second and our massive dataset keeps growing at a staggering pace. We keep improving our data platform and data engineering stack to accommodate growth, enable novel solutions and provide the best service to our customers.

We have a flat and open engineering culture where data, & evidence beats opinion and hierarchy, backed by honest and frank discussions. We passionately believe in forming autonomous, cross functional teams who are empowered to deliver our ambitious strategy. With stamps.com ownership comes the ability to operate largely independently away from Board meetings and old world thinking but with the financial support of a high performing tech company. Energy and passion for our business and customers is a part of the Metapack culture – and we love working with like-minded people.

What would I be doing?

Contributing to the design, build and operational management of our data lake and analytics solution on top of proven AWS data technologies like S3, Athena, Lambda, Kinesis, Glue
Using state of the art technologies like Airflow and Spark to process data and get our dataset just right
Developing frameworks and solutions that enable us to acquire, process, monitor and extract value from our massive dataset
Supporting the Data Analysts and Data Scientists with automation, tooling, data pipelines and data engineering expertise
Delivering highly reliable software and data pipelines using Software Engineering best practices like automation, version control, continuous integration/continuous delivery, testing, security, etc.
Define, implement and enforce automated data security and data governance best practices within the solutions designed
Mentoring more junior colleagues and being mentored by more senior colleagues

What key skills and experience do I need?

A Software Engineering background
Experience developing and supporting robust, automated and reliable data pipelines in Python and SQL
Experience with data processing frameworks like Pandas or Spark
Experience with streaming data processing
AWS, Azure or Google Cloud experience
Continuous integration/delivery environment experience with a passion for automation
Knowledge of a Data Orchestration solutions like Airflow, Oozie, Luigi or Talend
Knowledge of both relational and non-relational database design and internals
Knowledge of how to design distributed systems and the trade-offs involved
Experience with working with software engineering best practices for development, including source control systems, automated deployment pipelines like Jenkins and devops tools like Terraform

It would be great if you also could bring

Practical understanding of GDPR and other considerations regarding data security
Knowledge and direct experience of using business intelligence and analytics tools (Tableau, Looker, Power BI, etc.)
Production experience working with very large datasets
Experience with big data cloud technologies like EMR, Athena, Glue, Big Query, Dataproc, Dataflow.
Data Science/Machine Learning know-how
A desire to constantly challenge the norm
Willing to attend conferences, webinars and meet-ups and share the learning

What are the perks?

25 days holiday, 10% bonus (paid quarterly), pension, enhanced maternity and paternity leave, group life insurance scheme, private medical healthcare
Discounted gym membership, cycle to work scheme, interest free season ticket loan
Dynamic, open culture with lots of social activities",3.0,"Stamps.com
3.0","London, England",-1,1001 to 5000 Employees,1996,Company - Public,Computer Hardware & Software,Information Technology,$100 to $500 million (USD),-1
Data Engineer,-1,"Data Engineer

Great Ormond Street Hospital for Children

As the Data Engineer for the DRE and Genomics and Systems Medicine BRC Theme, the post holder will primarily have responsibility for developing and implementing a system of capturing and ingesting structured data from genomics reports using established healthcare industry standards.

The role may also support users in the upload and processing of their data to prepare them for data analytics.

The post holder will develop generic methods and tools for handling genetic/genomic data from reports, to facilitate data analytics and document best practice guidelines. In addition to the research platform, they will support the deployment and optimisation of other associated systems at GOSH.

Their key responsibilities are:

Development and optimisation of data integration of genomic and genetic data from clinical reports into the core DRE data model adhering to standards and ensuring data quality;
Develop data engineering methods and tools to transform such data, plus associated structured clinical data, for analytics and support individual projects and users with data provision and processing;
Develop best practice guidelines on the use of such data for projects and provide relevant user training;
Assisting with deployment and optimisation of the research platform and associated systems within the DRE in relation to use of genomic and genetic report and clinical phenomic data;
There is no requirement to undertake any bioinformatics analysis or data handling

For further details / informal visits contact:

Gemma Molyneux | Clinical Informatics Research Coordinator | DRIVE | Great Ormond Street Hospital for Children |Tel: 0207 405 9200 ext 4778 | email: gemma.molyneux@gosh.nhs.uk

Please be advised that:

The recruitment process for all admin and clerical roles at Bands 2-5 will be a two stage recruitment process whereby shortlisted candidates will undertake an online literacy, numeracy, ICT and typing test.Only those candidates who pass the competency test will proceed to a formal interview.

The closing date given is a guide only. There may be some occasions where we have to close a vacancy once sufficient applications have been received. It is therefore advisable that you submit your application as early as possible to avoid disappointment.

Only those candidates who clearly demonstrate how they meet the person specification criteria for this post will be shortlisted. Please note that where high volumes of applicants have been received, additional criteria may on occasion be used to determine the final shortlist.

Please also note that all recruitment is currently subject to restrictions on the allocation of Certificates of Sponsorship.

We are an accredited Living Wage Employer.

Please note that the Trust will shortly be introducing the TRAC recruitment system. Once the system goes live, after applying via NHS Jobs, your submitted application will be imported into TRAC. All subsequent information regarding your application will be generated from apps.trac.jobs. You will not be able to track the progress of your application or receive messages through the NHS Jobs website, and furthermore, that as an employer, we will not be able to respond to any e-mails sent to us via the NHS Jobs website. By applying for this post you are agreeing to Great Ormond Street Hospital for Children NHS Foundation Trust transferring the information contained in this application to its preferred applicant management system. If you are offered a job, information will also be transferred into the national NHS Electronic Staff Records system. Please note, all communication regarding your application will be made via email, please ensure you check your junk/spam folders as emails are sometimes filtered there.

Disclosure and Barring Service Check

This post is subject to the Rehabilitation of Offenders Act (Exceptions Order) 1975 and as such it will be necessary for a submission for Disclosure to be made to the Disclosure and Barring Service (formerly known as CRB) to check for any previous criminal convictions.

To stay safe in your job search we recommend that you visit SAFERjobs (https://www.safer-jobs.com), a non-profit, joint industry and law enforcement organisation working to combat job scams. Visit the SAFERjobs website for information on common scams and to get free, expert advice for a safer job search.",3.5,"Great Ormond Street Hospital NHS Foundation Trust
3.5","London, England",-1,1001 to 5000 Employees,1852,Hospital,Health Care Services & Hospitals,Health Care,$100 to $500 million (USD),-1
Data Engineer,-1,"About Evaluate Ltd

Evaluate provides trusted commercial intelligence for the pharmaceutical and medical device industries.

Our EvaluatePharma® online subscription services provides a seamless view of the past, present and future of the global pharmaceutical market in a single, standardised platform. Vantage – our award-winning, independent editorial team – provide thought-provoking news and insights into the current and future developments in the industry. Evaluate has been a trusted partner to industry-leading organisations for over 20 years. For more information on how we give our clients the time and understanding to drive better decisions, visit www.evaluate.com.

Requirements

Position Description: A Data Engineer is needed to support the product development team in data design and structuring, ETL processes, and pipeline generation.

Responsibilities:
Support the product development team in the creation of features for predictive ML models.
Support the product development team in the manipulation of large data sets, and the extraction of insights.
Support the product development team in the design and optimisation of database solutions that sit upstream of main production environment.
Develop & maintain data publication and synchronisation processes, supporting Tableau.
Designing robust & efficient data processes, aggregations and pipelines.
Establish industry best practices using modern tools and processes.
Productionising Tableau data transforms.
Creation of attributes for data science models.
Manipulation of large data to create aggregated analyses.
Creation of optimised upstream database systems, e.g. consolidated/standardised clinical trial or pricing database (across multiple geographies).
Pulling bespoke database extracts for hypothesis testing, and ideation.
Trend analysis.
Pulling, processing and structuring new data sets, from public and private sources, e.g. grant information.
Working Conditions:

Based in the London office with flexible working. Occasional travel to other offices, subsidiaries & partner locations. Initially 100% working from home while government travel restrictions remain in place due to Covid-19.

Required skills & qualifications:
Have a good grasp of modern data practises and apply them to complex problems.
Building services features and libraries that contribution to library code and core services.
Have a good understanding of data architecture.
Experience with AWS
Ability to write code in Python
Experience wielding large data sets in formats such as XML, JSON and CSV.
Data manipulation using ETL tools and databases (Alteryx, Matillion, Redshift/Snowflake, RDS, S3).
Knowledge of database design, consolidating and flow outputs into current/new database.
Experience with data visualisation tools such as Tableau, Power BI or QuickSight.
Experience with big data technologies.
Experience in data processing using traditional and distributed systems.
Experience designing data models
Experience in SQL, NoSQL database management systems
Bachelor degree in Computer Science, similar technical field of study or equivalent practical experience.
Expertise in the design, creation and management of large datasets/data models.
Experience working on building and optimising logical data model and data pipelines while delivering high data quality solutions that are testable and adhere to SLAs.
Experience in using various data design patterns and knowledge of when/when not to use one.
Experience of working in an Agile (Scrum) environment
Nice to have:
R or MATLAB.
Knowledge of pharmaceutical industry, in particular the stages of pharmaceutical product development.
Familiarity with research, clinical trial or patent documents.
Personal attributes:

In addition to buying into Evaluate’s values as per below candidates should display the following attributes:
Friendly approach to business
Superior communication skills with all
Innovative approach to function
Ability to grow and adapt as business does
Open and honest approach to communication
Finger on the pulse with new & emerging technologies
Values Statement

Focus on the client

Our clients’ success is our success.

We do our utmost to understand our clients and ensure they are successful in their roles.

Improve

Be better.

We strive to improve and innovate, challenging industry norms and ourselves.

Be one team

Communicate, collaborate, challenge.

We believe that two heads are always better than one; in being generous with our time, and collaborating to get the job done

Empower

Enable Success.

We empower each other to deliver, celebrate our successes and learn from our mistakes.

Be Accountable

Own it.

We take responsibility and do the right thing. Through guidance and support we hold each other accountable.",3.9,"Evaluate Group
3.9","London, England",-1,51 to 200 Employees,1996,Company - Private,Research & Development,Business Services,$25 to $50 million (USD),-1
Analytics Data Engineer,-1,"REQ ID: 45801
JOB TITLE: Analytics Data Engineer
SALARY: Competitive
POSTING END DATE: 28/11/2020
LOCATION: Coventry

Dreaming for tomorrow is about more than ideas and ambitions. We’re already building the next generation of vehicles, using repurposed and brand-new technology and techniques. We’re doing more than dream, we’re creating the future of mobility and automotive for years to come.

WHAT TO EXPECT

To meet Jaguar Land Rover ambitious global growth plans, tackle the ever-increasing challenges being faced by our business and elevate Transformation to the levels required to deliver a sustainable industry-leading organisation, Jaguar Land Rover is continuing to invest in its internal Analytics capabilities.

The Customer Service Quality team uses advanced analytics to integrate data from numerous sources throughout the vehicle’s lifecycle and run predictive analytics to identify and prioritise the root causes of product quality issues.

We are currently undergoing an ambitious transformation program that entails building a robust in-house analytics solution to handle the integration, modelling, prediction and inference of all customer quality issues utilising the best in class data analytics and machine learning tools and methods.

This new analytics team will be responsible for developing and delivering our analytics strategy, coordinating our in-house analytics capability and solving our most complex analytics problems. To do this we are assembling an expert multi-disciplinary team of analytics professionals from a wide range of backgrounds.

THE OPPORTUNITY

We are looking for outstanding problem solvers who are inquisitive and excellent with technology. They will be executing data analytics projects that are varied in nature and demand a wide spectrum of skills from data manipulation and integration through to cloud solution deployment. They will need to love working with data and to be detail orientated and methodical. Whilst existing knowledge of numerous analytics and software tools is not a prerequisite, self-motivation to learn and an ambition to become an expert in applying such technologies is essential.

The role will require working within analytics project teams and with a wide range of functional business partners. They’ll focus on the development of sophisticated data pipelines. They’ll need to have experience with coding and software development and be a strong independent problem solver capable of working through complex problems with minimal guidance following a project kick-off. The role includes supporting and mentoring junior team members with, therefore an interest in knowledge dissemination and working with junior team members is essential.

WHAT YOU WILL NEED

You will have the extensive technical knowledge with hands-on practical with software development in languages such as Python or similar (R, C#, Java, etc.) with experience implementing and maintaining complex data pipelines (SQL, Python, etc). In addition, you will have comprehensive knowledge and involvement with Cloud-based platforms (GCP or similar) and Experience with open-source software tools and languages such as SQL, Python, R, Perl, Java, and ETL tools.

Ideally, you will also possess experience with some of the following as it is highly desirable but not essential:
Test-driven development and version control (git)
Containerisation and cloud deployment (Docker)
Can effectively take a leadership role on a moderately complex project with a few (2-3) other people working on it
Helps drive a culture of continuous improvement by identifying team weaknesses and potential solutions
SO WHY US?

Bring all this to the home of premium innovation, and you’ll find the opportunities to further your career with a world-class team, a discounted car purchase and lease scheme for you and your family, membership of a competitive pension plan and performance related bonus scheme. All this and more makes Jaguar Land Rover the perfect place to continue your journey. Jaguar Land Rover is committed to equal opportunity for all.

THINK BEYOND


Jaguar Land Rover has long pushed the boundaries of technology. Now digital innovation lies at the heart of our business – because it is central to our future strategy. We are focused on the development of electric, connected and driverless cars that will reshape the whole industry. Joining us is your chance to help redefine who we are and where we’re going.
FIND OUT MORE"">>FIND OUT MORE


Find out more about working here in our JLR Life Blog:
FIND OUT MORE"">>FIND OUT MORE

We look after our employees by offering a host of benefits and investing in their talent through award-winning training.
FIND OUT MORE"">>FIND OUT MORE

OTHER OPPORTUNITIES


Can't find a suitable opportunity or interested in other options with our Suppliers and Partners?
FIND OUT MORE"" target=""_blank"">>FIND OUT MORE

Job Segment:
Analytics, Database, Engineer, Developer, Java, Management, Technology, Engineering",3.6,"Jaguar Land Rover
3.6","Coventry, England",-1,10000+ Employees,2008,Company - Private,Transportation Equipment Manufacturing,Manufacturing,$10+ billion (USD),-1
Senior Software Engineer,-1,"Are you a Software Engineer who wants to join a leading cyber team within an evolving and dynamic organisation?

Due to the success of a number of strategic Gloucestershire based programmes, we are growing our Software Development team with creative and ambitious Software Engineers. With a primary focus on Java, your experience will cover different technologies within an agile environment

Different thinking for a Different world

Northrop Grumman is a leading global security company providing innovative systems, products an solutions to government and commercial customers worldwide. In Northrop Grumman’s rapidly growing UK Cyber and Intelligence business, we support our customers’ work to make the UK the safest place to live and do business, both physically and online.

Working with and alongside our customers, we use modern software engineering methods (Scaled Agile Development, DevSec Ops, Site Reliability Engineering, micro-service architectures) and cutting edge techniques (data science, Artificial Intelligence,Machine Learning) to tackle complex and challenging problems and deliver cost effective, reliable, supportable solutions.

Our solutions support complex analysis of substantial amounts of data, requiring state of the art ‘big data’, stream processing and cloud-based analytics, identifying and using ‘best of breed’ commercial and open source technologies and integrating them with our own software to meet customer needs quickly and efficiently.

At Northrop Grumman we pride ourselves on our ability to combine agile development with sound engineering and security practices to ensure that our solutions are robust and resilient; designed and built to start secure and stay secure against ever evolving cyber security threats. As well as designing for security, Information Assurance and legal / policy compliance, we actively assess products and services, identifying vulnerabilities and weaknesses that could be exploited by cyber attackers, and we create and run exercises to pit cyber security specialists against secure systems and each other.

We carry out research and innovation locally in the UK, with commercial and academic partners, and across our 85,000+ worldwide workforce.

How you will make a difference

For us, innovation is key and we have immediate opportunities for talented software engineers to join our team to help us develop and maintain a suite of applications.. We are in a phase of rapid growth and there are opportunities to develop your career with us to meet your aspirations.

You will be helping us to solve our customer’s problems within an agile team. You will have opportunities throughout the Software Life cycle from requirements capture through to R&D(Research & Development), implementation, automation and test in a wide range of technologies.

As a Senior Software Engineer you will have had responsibility for parcels of work and should be used to working with customers. You will be able to deploy applications in a controlled, repeatable way and be developing technical specialisms in frameworks and/or tool sets. Experience of mentoring or team leading would be advantageous.

Key criteria required...

Experience in design, development, test and integration of quality software

Experience in Java and the use of object oriented design

Keen to learn a broad range of technologies on the Java stack

Also, we’d love it if you have experience of...

Agile/Scrum methodologies using tools such as Confluence and Jira

DevOps approaches and associated tools such as Ansible, Docker and Jenkins

Messaging and Routing Technologies such as NiFi and Kafka

Cloud-based architectures

Linux operating systems (Red Hat Enterprise Linux Server/CentOS)

Different programming languages, such as: Java, C, C++ and Python

Working with open source products

You will enjoy a growing career as we work collaboratively to innovate the world of cyber security.

Additional information for your consideration...

You must hold UK Government clearance

Opportunities exist across the UK to enhance your career progression

Being a part of Northrop Grumman gives you the opportunity to use your skills to make a difference in our mission of enabling global security. Our company grows because of our employees' dedication and commitment to achieving our mission, something we always remember. In return for working for us you will have access to a benefits package that provides you with flexibility to balance your professional career with your personal life, health & well-being benefits, discount schemes, pension benefits and investment in your future development.

We are committed to equality and diversity in our workplace. Northrop Grumman provides equal employment opportunities to all employees and applicants without regard to an individual’s protected status, including race, ethnic origin, colour, nationality, national origin, ancestry, sex/gender, gender identity/expression, gender reassignment, sexual orientation, marriage/civil partnership, pregnancy/maternity, religion or belief, creed, age, disability, genetic information, or any other protected status or characteristic.",3.8,"Northrop Grumman UK
3.8","Cheltenham, England",-1,10000+ Employees,1939,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
Machine Learning Data Engineer,-1,"Job details

College

College of Engineering and Technology

Responsible to

Professor of Cyber Security and AddQual Project Leader

Location

iHub, Infinity Park Way, Derby, DE4 9FU

Salary

£25,217 - £30,046 per annum

Closing date

Sunday 22 November 2020

Contract type

Fixed term contract 24 months

Post type

Full-time

Reference

0265-20

About the role

University of Derby’s College of Science & Engineering in partnership with AddQual are offering an exciting career-development opportunity to manage and deliver a challenging strategic Knowledge Transfer Partnership (KTP) project. Based at the company premises, you will be employed by the University as a KTP Associate but work under the terms and conditions of the company.

Using your knowledge and skills to support the business and achieve specific project aims, you will receive on-going support by a Company Supervisor, Academic Supervisor and Academic Lead from the University of Derby to help you deliver. A personal training and development budget will also be available for you to access, as well as receiving access to the same training opportunities and facilities as University staff.

About AddQual

AddQual supply qualification services and fast make products to the aero, power & medical sectors. Our Qualification services allow customers to understand if parts meet the component quality requirements, allowing us to advise changes required and if necessary, assist and supply parts. Our fast make service uses targeted internal capability and supply chain partners before parts are finished.

AddQual offer a range of AS9100 and NADCAP qualified services that Capture and Qualify the product through development and production, utilising the latest design tools, measurement technology, 3D printing and metallurgical methods.

The KTP Opportunity

AddQual Ltd in collaboration with The University of Derby’s College of Science & Engineering are offering an exciting opportunity to work as a Knowledge Transfer Partnership (KTP) Associate on a Research and Development project to develop digital tools to visualise the product's lifecycle capability and performance.

The Associate will be responsible to build and maintain a database to store all the data in a single place. By working with the University, they will embed new capability to perform data analytics using the latest data science and Machine Learning (ML) methods to discover useful & novel insights to help us and our clients.

The Associate will be critical to the ability of AddQual to develop data driven analysis of component processing and computation of high-volume data as well as the creation and how to disseminate knowledge. The Associate will research and develop robust algorithms for data analytics using state-of-the-art methods, design and deploy safe and secure database environment for client data as well learn to develop a web-based tools for data visualisation and access.

Further they will implement, execute, and maintain the digital tool to meet AddQual’s requirements, management of customers data and identify IP and, where feasible recognising this IP through patents. They will understand internal projects AddQual are currently working on to familiarise with market demands and plan future solutions, delivering value to existing and new clients through new innovative solutions:

University of Derby is an extraordinary educational environment and because we specialise in identifying and developing individual potential, you can be confident you'll receive all the help and encouragement you need to succeed in your role. We offer some of the best university facilities in the UK, investing more than £200 million in facilities in the last 10 years. Financially strong and seriously ambitious, achieving outstanding results for our teaching and research and with more than 34,000 people choosing to study with us every year, we depend on the dedication of a team of 2,200 academic and professional services staff.

Knowledge Transfer Partnerships - This full-time post is part-funded by the UK Government’s KTP programme. A KTP is a three-way project between a graduate, an organisation and a university. KTP is one of the UK’s largest graduate recruitment programmes and has been placing graduates on challenging, high profile projects for almost 45 years. In addition to a competitive salary and core KTP development training, you will have a dedicated budget of £4,000 for further training and career development. To find out more about the scheme visit: ktp-uk.org/graduates

Principal accountabilities
Data management
Research and implementation of data analytics
Designing and deployment of safe and secure database environment for client data
Development of a web-based Dashboard for data visualisation and access
Implementation, execution, and maintenance of the digital toolkit to meet AddQual and their client’s requirements
Data dissemination and access for other systems
Identifying IP
Under the direction of the Principal Investigator, contribute to the development of new knowledge and techniques to the research project(s)
Contribute to the determination of appropriate research methodologies for the project(s)
Contribute to the writing up of research findings and dissemination through publications or seminar and conference presentations
Support the supervision of undergraduate projects and postgraduate research students in conjunction with other staff, and provide training and limited teaching as appropriate
Where opportunities exist within the research project(s), support the development and delivery of business engagement activities, developing entrepreneurial links with external organisations
Provide guidance as required to other colleagues working on related research project(s)
Understand own development needs and formulate a personal development plan
Person specification
Essential Criteria
Qualifications
PhD in Computer science of a relevant field
Experience
Expertise in data analytics tools, R/Matlab or any other relevant tool
Proven recent experience of working in the domain of data science
Skills, knowledge & abilities
Data Analytics and Data Visualisation
Basic knowledge and Programming skills in PolyWorks
Basic Knowledge with GOM and its data output
Machine Learning
Programming skills in one of the languages, Python or C-sharp
Able to achieve deadlines in a fast-paced environment
Good work ethics
Technical competency
Confidence and Positive behaviour
Team player
Proactive and Resilient
Reliable and Independent worker
Good communication skills
Desirable Criteria
Experience
Expertise with Databases, SQL or NoSQL
Web development
Benefits

Personal development budget of £4,000 for further training and career development.

Travel and Subsistence budget for relevant events etc.

Company address: iHub, Infinity Park Way, Derby, DE4 9FU

Company Line Manager: Ben Anderson

Probation period: 6 months

Working hours: 40 hours per week

Annual leave: 22 Days + 8 Bank Holidays

Notice period: In the first year of continuous employment: 4 weeks’ notice / one week for each subsequent complete year of continuous employment up to a maximum of 12 weeks' notice.

How to apply

You can apply by submitting an online application. Once you have signed in or registered with us you will be able to begin your application. If you are creating an account for the first time, please ensure you provide an email address that you access regularly as this will be our main means of contacting you regarding your application.

If you require any assistance, including the provision of any documentation in an alternative format, please contact the Recruitment team at recruitment@derby.ac.uk.

Please note all applications must be submitted online by Midnight GMT on the closing date of the vacancy.",3.8,"University of Derby
3.8","Matlock, England",-1,1001 to 5000 Employees,-1,College / University,Colleges & Universities,Education,Unknown / Non-Applicable,-1
Data Engineer,-1,"Data Engineer

Add

Email to a friend
Share:



Sector:IT/ICTLocation:UK & IrelandSub-location:AnyCurrency:£Job Type:Any

Salary Description:
Excellent Day Rate

Posted:
27/10/2020

Ref No:
CR/104177

Data Engineer urgently required to work on 6 months + contract.

Location: London / WFH

The ideal candidate will have an in-depth back ground working as Data Engineer within Central Government / GDS, Strong automatic testing, Oracle SQL server to Microsoft Azure , Strong understanding of Microsoft SQL Server, Azure and Power BI

Essential skills required:

Strong background in Data Engineering and Architecture.

Strong understanding of Microsoft SQL Server, Azure and Power BI

Strong mentoring skills

End-to-end data solutions and ELT/ETL pipeline development skills.

Data Warehouse and Data Lake solutions.

Desirable experience

Azure / Data Factory / Power BI

Experience in leading data engineering projects is a big plus. • Experience working with large-scale data environments

Please submit updated CV to apply + call to confirm your application and to review full JD.

Michael Bailey International is acting as an Employment Business in relation to this vacancy.",4.0,"Michael Bailey Associates
4.0",United Kingdom,-1,51 to 200 Employees,1989,Company - Private,Staffing & Outsourcing,Business Services,$50 to $100 million (USD),-1
Data Engineer,-1,"We’re looking to add a full-time Data Engineer to our team and build on our strong data foundation. You'll have complete technical ownership of our data platform, the ideal person would be ambitious, strong technically and a great communicator.

You’ll be responsible for:
Developing new ETL processes to support internal analytics - e.g. for business intelligence;
On-going monitoring and maintenance for existing ETL processes.
Running queries and creating dashboards to address ad hoc reporting needs.
Being an advocate and expert technical owner for our data platform.
Supporting the business with all data and data science related initiatives.
Creating data pipelines to integrate new data sources into the data lake – e.g. from across the business and from external 3rd party data vendors;
Tech Stack:
Python to write our application code.
Docker, ECS and Kubernetes to run our services.
Django as our Web App framework.
AWS for our infrastructure.
JavaScript frameworks, React is our chosen technology for frontends.
AWS Athena, Apache Airflow, S3, Apache Spark for our Data platform
Requirements

You should apply if you:
Have shipped code in high-level languages such as Python.
Are a competent Python developer that appreciates software engineering best practices.
Are comfortable working with relational databases such as Postgres.
Can write complex SQL queries for answering management questions - i.e. be able to use efficient joins, aggregations and window functions;
Have some experience in using workflow orchestration tools such as Apache Airflow;
Are comfortable working with AWS managed services such as S3, Athena and DMS; and,
Are self-motivated and able to operate independently.
Are comfortable working in a team that deals with challenging problems.
Have a tolerance for ambiguity and a willingness to get stuck-in;
Have a demonstrable ability to work to very tight deadlines in an exciting and fast paced start-up environment.
Have studied Comp Sci or STEM to degree level.
Nice-to-Have Experiences

If would be awesome if:
You're interested in data science and machine learning;
You have hands-on experience using Docker and Kubernetes;
You have experience creating BI dashboards using tools such as Redash, Apache Superset or Tableau;
You've had some exposure to the 'PyData stack' - i.e. Pandas, NumPy, SciKit-Learn, MatPlotLib and/or Seaborn; and,
You know how to manage data and compute services on AWS using infrastructure-as-code - e.g. AWS CloudFormation templates and/or Terraform.
Benefits
Competitive compensation (base + equity);
Flexible and remote working opportunities.
A compelling mission, to simplify lending for an underserved segment of society; and
An exceptional team, bringing diverse experience from the worlds of technology, strategy consulting, banking, private equity, hedge funds and credit.",-1,LiveMore Capital,United Kingdom,-1,-1,-1,-1,-1,-1,-1,-1
Data Science Engineer,-1,"Uniper is looking to grow its data science and modelling team, with bright and adaptive problem solvers who want to take a lead on driving real change in the energy sector. By harnessing data and modelling techniques, you will build customer-centric digital solutions that help optimise and improve decision making. This is your chance to deliver the energy transition.

What we offer
At Uniper, we believe in rewarding our employees for their hard work. We offer competitive salaries, company pensions and performance related benefits. Our people can also take advantage of our extensive flexible benefits package with discounts on high street vouchers, health and dental care, holidays and more.

How we work
Our people are key to our success. Our core objective is to provide them with a supportive and entrepreneurial work environment that fosters collaboration. This allows our people to take responsibility and make optimal use of their skills. Together, we want to shape the future of energy.

What we are looking for

Working predominantly for our upstream energy trading business, you will:

Work closely with domain experts, in order to understand their problems in detail and scope out requirements to deliver.
Source and connect to relevant data sources, build mathematical and statistical models, applying the most appropriate optimisation techniques to deliver on time, to quality and to budget.
Productionise your work into a usable tool/product that can be used day-to-day by your customers, working closely with software engineers and user experience experts.
Automate, enhance and provide support for existing models or analyses.
Typically follow the principles of AGILE in the delivery of your work, taking part in stand-ups, sprint reviews and sprint planning sessions when applicable.
Peer review the code of others and recommend changes.
Actively work to build a positive customer relationship and pursue business development opportunities.
Present work to customers when needed for feedback.
Promptly raise any work concerns that impact your “well-being” to your line manager to encourage a positive outcome.
Be willing to travel overseas for short periods to meet customers and attend project meetings.",3.6,"Uniper
3.6","Nottingham, England",-1,10000+ Employees,2016,Company - Public,Energy,"Oil, Gas, Energy & Utilities",$10+ billion (USD),-1
Data Engineer,-1,"Lab49 is currently looking for a Data Engineer to help us build a strategic Risk calculation engine and associated workflows. The candidate will participate in the design and development of the platform, interacting with globally distributed Risk Officers (Market Risk, Credit Risk), Quants and IT Dev/QA team.
The successful candidate will:
Design and develop high-quality software solutions for Risk platform.
Create new modules & data flows to meet regulatory requirements (FRTB, GMETH).
Use Scala, Java or Python programming languages to build required functionality.
Implement data pipelines using big data/cloud technologies Apache Spark, Hadoop, Microsoft Azure Cloud (Data Lake, Data Factory, Batch) and Databricks.
Design and develop microservices using Spring Boot and Azure Kubernetes Service (PKS) cluster.
Profile Requirements
Expertise with Scala, Java or Python languages.
Experience with Spark, Hadoop, and Databricks (a must-have).
Experience with any of the Big-3 Cloud platforms - Azure (preferred), AWS or Google. Experience building data lakes and data pipelines in the cloud.
Experience designing high-performance, high-load systems.
Understanding of the distributed Agile SDLC model.

Preferred experiences:
Spark Developer certification is an added advantage.
Azure Data Factory, Azure Batch.
Expertise in Financial Services industry.",3.2,"ION
3.2","London, England",-1,1 to 50 Employees,-1,Unknown,-1,-1,$10 to $25 million (USD),-1
Data Engineer,-1,"Role: Data Engineer
Contracting Authority: Public Sector
Contract Length: 6 months
Location: London (work from home)
IR35: Inside

Knowledge and Experience required:

Proven experience of big data engineering techniques and concepts using the Hadoop Stack (Cloudera/EMR), including data ingestion, processing and storage using HDFS, Spark, Hive and Impala.
Extensive, hands-on experience of large complex Data Engineering projects designing and developing ETL pipelines in a cloud or on premise environment
Experience of design and implementation of data storage, including HDFS, S3, relational and NoSQL
Experience of developing/utilising programming and query languages e.g. SQL, Java, Scala
Monitoring performance and advising on any required infrastructure or changes.
A good understanding of data management, governance and quality frameworks, and how these integrate with big data solutions

Other:

This is the nice to have but not essential criteria

Strong stakeholder management skills and experience working with stakeholders across all grades and working with internal / external stakeholders to deliver results
Confident written and verbal communicator with the ability to present complex ideas in a compelling way to senior technical and non-technical audiences
Comfortable with Agile methodology and ability to manage diverse projects with changing user needs
Security Clearance will be required for this role, therefore only candidates who have continuous UK-based residence over the last 5 years will be considered",4.7,"Heat Recruitment
4.7","London, England",-1,51 to 200 Employees,2005,Company - Private,Staffing & Outsourcing,Business Services,$5 to $10 million (USD),-1
Data Engineer,-1,"About LYTT*
We are a fast-growing technology start up and our aim is to shape the future of Energy through advanced analytics. We are building an award-winning platform and Software as a Service (SaaS) solution to tackle complex energy challenges in extreme environments by designing and deploying ground-breaking technology that interprets data captured from fibre optic cables deep in the subsurface into actionable information.

We are backed by BP and have already attained a market leading position; LYTT is a recognised thought leader and innovator in the industry. We have a successful track record of deploying our technology all over the world, delivering several hundred million dollars of value to our customers.

We have a highly experienced leadership team (including support from the BP Launchpad), an agile and motivated workforce and we’re building a culture that celebrates innovation. With over 12 nationalities, a breadth and depth of expertise with a mix of interests, we are proud to bring diverse thinking to the energy industry’s most challenging problems.
Role Responsibilities*
Use your background in distributed data processing, stream processing, software engineering design, and data modelling concepts to develop reliable and scalable production systems
Support our data scientists to deploy code multiple times a day and take care of running your services in production on AWS and Azure
Contribute across the entire software delivery life cycle – concept, design, build, deploy, test, release and post implementation support
Applying good engineering practises - implement processes, systems and tools to aid and you and your team in day to day development work
We’ll need you to help build alerting systems and service status dashboards for data pipelines running models in production
Support Agile development methods and best practices
Quickly acquire new data engineering skills and work with new technologies with little support
Work with the wider development teams to ensure the spread of best practices and knowledge
Role Requirements*
Minimum 2 years’ experience with Python building data pipelines (streaming or batch)
Understanding of Object Oriented Programming concepts
Experience in an agile development team
Working experience with CI/CD & test-automation in Python
Experience with AWS & Azure cloud environments
We know that sometimes people can be put off applying for a job if they think they can’t tick every box, but we realise that the ‘perfect candidate’ doesn’t exist. If you’re excited about working with us and can do most of what we are looking for, go ahead and apply. You could be exactly what we need!
COVID-19 Update: * All members of our team will be working from home for the foreseeable future, and interviews during that time will be conducted using video calls and other tools.
Job Types: Full-time, Permanent

Salary: £40,000.00-£60,000.00 per year

Additional pay:
Bonus scheme
Benefits:
Company events
Company pension
Flexible schedule
Private medical insurance
Sick pay
Wellness programmes
Work from home
Schedule:
Monday to Friday
Work remotely:
Temporarily due to COVID-19",4.0,"LYTT
4.0","London, England",-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"We’re Chip. We’re here to make saving effortless, easy and fun. Our mission is to build the best savings app in the world.

We help people save up money automatically. In fact, we’ve automatically saved more than £150 million for tens of thousands of our savers already.

We’ve done all this by using AI, Open Banking and a disruptive approach to traditional banking.

Now, we’re helping people get better returns automatically, too.

You can open a market leading savings account in a couple of taps in Chip, as well as deposit, track and withdraw your money.

As you sit back, save and earn interest, we’ll keep going to the banks on your behalf to negotiate better rates.

This was a service that used to only be available to the super-rich, but we've done some clever things to pool Chip savers' money, so we can negotiate with banks like you're a millionaire.

Sounds pretty good, eh? And we’re just getting started.

Chip is being built by a fast-growing team of designers, developers, customer service professionals, marketers, banking experts, and entrepreneurs, with the backing of more than 11,000 investors and a huge community of Chip savers.
We’re growing fast, and we have some very exciting plans. So we need a Data Engineer to help us make them happen.

Good data should be the heart of any business and here at Chip we're striving for excellent data to empower us to make excellent decisions. Working alongside our engineering team we are looking to find a Data Engineer to help us collect, transform and store and serve that data across all sectors of the business.

We collect a lot of important data from all aspects of our business and we need engineers to help us write tools to ensure that data is accurate and consistent. Using any and all tools and languages necessary to give us the power to do everything from lending decisions to deciding which features we should develop.

What you can expect to be doing:

Develop robust ETL pipelines and automated processes for ingesting and processing data
Developing, managing and extending data warehouse and data models to provide a robust foundation for internal reporting.
Ensure best practices are followed with regard to security and infrastructure
Creating and maintaining relevant documentation
Spot opportunities for improvement on data engineering and business intelligence best practices
Advise on data modelling and reporting best practice
Working with the engineering team to ensure application design accommodates reporting and analytics requirements

What we’re really looking for

Advanced level knowledge of SQL and/or experience managing Data Warehouses
Knowledge of AWS and GCP cloud platforms
Confident getting hands-on with Python to process data and automate processes
Confident interacting with Databases and web APIs and processing data
Good understanding of reporting and data modelling best practices
Good written and verbal communication skills and an ability to translate problems into technical requirements and implement a solution.
Take requirements from someone non-technically minded, implement the solution and then explain your solution to a software engineer
Work within the Data team reporting to the Head of Data Engineering

What we’re really looking for: ✍️

Although we’re in the financial space, and under the scrutiny that comes with it, the current engineering team works well together, and even sometimes with a smile. We’re sure you’ve got the technical skills, otherwise you would have stopped reading by now, so let us be clear in what will make us want to work with you.

We want a real person, with interests outside of code, to join our work family. You could be a dancer, a gamer, a musician, a parent, a hockey fan, or even that one person that still writes Twilight fan-fiction. Doesn’t matter to us. At the interview stages will be looking for empathy, eq, fun stories, and ability to smile even when things are tough. Code monkeys need not apply.

PERKS

£45,000 - £50,000 per annum dependant on experience
Discretionary share option bonus every 6 months
Workplace pension scheme (Employer: 3% / Employee: 4% / Tax Relief: 1% / Total: 8%)
We are an equal opportunity employer and value diversity
Flexible working arrangements
Unlimited holiday (28 days contracted but policy not to count) ✈️
Free Classpass membership or gym membership
Company laptop
Based in the heart of Chancery Lane
Opportunity to have a huge impact on our product while fast-tracking your knowledge, responsibility and skills in a high growth fintech startup

Our Interview process:

Phone Screen with someone from our Talent team
Short take home test
Video interview with the hiring manager
Final Interview with HR

Note to Agencies

Chip does not accept unsolicited CVs from recruiters or employment agencies in response to any of our live roles on our career page. Chip will not consider or agree to payment of any referral compensation or recruiter fee relating to these unsolicited CVs. Chip explicitly reserves the right to hire those candidate(s) without any financial obligation to the recruiter or agency. Any unsolicited CVs, including those submitted to hiring managers, are deemed to be the property of Chip.",2.3,"Chip
2.3",Remote,-1,51 to 200 Employees,1986,Company - Private,Lending,Finance,$10 to $25 million (USD),-1
Python Data Engineer,-1,"My client based in Leeds are looking for a 3 month intiial contract Python Data Engineer. They need you to work on some hot tech projects they have just secured which include:
Building a set of data integrations to help a client become more agile with their analytics
Working on a global information sharing platform in extreme information management
Working on their SaaS product.
To be considered you must have -

AWS - Databricks, Terraform, VPCs/Networking/IAM plus strong CI/CD & automation experience or all of the above but with Azure AWS rather than AWS.

Any additional experience of SQL, data modelling and machine learning/analytics platforms is highly desirable.

Rates are negotiable.",4.0,"Talent International
4.0","Leeds, England",-1,201 to 500 Employees,1995,Company - Private,Staffing & Outsourcing,Business Services,$500 million to $1 billion (USD),-1
Data Engineer,-1,"Location: West London, however, role would support remote working

Salary details: £55,000 – £65,000 (depending on experience and qualification)

Contract: Permanent

Closing date: 10am Friday 20 November

Interviews: w/c 23 November, or as soon as suitable candidates are identified, so early application is strongly advised

Start date: Asap

About the role:

Ark Schools prides itself on having a sector-leading approach to information systems and data analysis. With ambitious plans to embed advanced analytical practices, we are looking for a Data Engineer to help us to optimise our data architecture, pipeline and flows so that they continue to support the network’s analytics and reporting needs.

This is a fantastic opportunity if you’d like to:

Take on a key role in defining and delivering Ark’s future data and analytics platform, enabling us to fully leverage the value of the data we hold for our c.28,500 students across 38 schools
Be pivotal in supporting the organisation to move towards advanced analytical practices
Work for an organisation that exists to make sure that all children, regardless of their background, have access to a great education and real choices in life

If preferred, the role would be suitable for remote/flexible working, with periodic travel to Ark’s central office in West London.

About you:

5+ years’ experience in a data engineer or similar BI role, and have attained a Graduate degree (or relevant professional experience) in Computer Science, Statistics, Informatics, Information Systems or another quantitative field
A strong understanding of best practice and emerging data systems, and demonstrable experience in these areas
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases (e.g. Postgres)
Able to demonstrate a successful history of manipulating, processing and extracting value from large, disconnected datasets
Able to quickly understand and become familiar with new data sets – particularly if new to education
Aligned with the Ark Schools' vision and values

About Ark:

Ark is an international charity, transforming lives through education. We exist to give every young person, regardless of their background, a great education and real choices in life. In the UK, we are a network of 38 schools, educating around 28,500 pupils in areas where we can make the biggest difference. We also incubate start-up programmes (Ark Ventures) that improve the education system.

We offer:

27 days annual leave plus bank holidays, rising with each year of service
We are committed to providing high-quality professional learning throughout your career with us and offer a variety of training sessions and experiences designed to meet your needs
Access to Ark Rewards scheme offering savings from over 3,000 major retailers, interest-free loans available for season tickets or a bicycle and gym discounts offering up to 40% off your local gym

How to apply

Apply with a CV and cover letter on our online recruitment portal. Applications to be submitted by 10am on Friday 20 November 2020 but please note: we will be reviewing applications on an on-going basis and this advert may close earlier than advertised depending on the level of response.

Interviews will be arranged as suitable candidates are identified, so early application is strongly advised

Ark is committed to safeguarding and promoting the welfare of children and young people; all successful candidates will be subject to an enhanced Disclosure and Barring Service check.

Ark Schools are committed to attracting, developing and retaining a diverse workforce, with a broad range of backgrounds, experiences and perspectives.",-1,Ark Schools Central,"London, England",-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Our people love the exciting and meaningful work they do, the cutting-edge resources and technology they have access to, the benefits we offer and the great community we’ve built. Want to join them?

The Senior Data Engineer is responsible for designing and developing data processing and data persistence software components for solutions which handle data at scale. Working in agile teams, Lead Data Engineers providing strong development leadership for team members and take responsibility for the quality of the codebase as well as the match to user needs.

Most of our work comes through repeat business and direct referrals, which comes down to the quality of our people. The success of our Data Engineering teams means that customers are bringing us an increasing number of exciting data projects using cutting-edge technology to solve real-world problems. We are seeking more high calibre people to join our Data & Analytics capability where you will grow and contribute to industry-leading technical expertise.

Essential Experience
Software development experience with distributed data storage and processing technologies including Hadoop and Spark and using JVM languages.
Experience of leading the development of substantial components for large-scale data processing solutions, taking responsibility for non-functional needs of ETL/ELT data processing pipelines such as robustness, performance and security. ‘Development’ incorporates design, code, test defect resolution and operational readiness, and includes setting the standards for these activities.
Coaching and mentoring experience in data development disciplines with the ability to gain the respect of a junior team.
Ability to advise architects and other stakeholder on detailed technology and development practice and on development estimates.
Ability to make effective decisions within fast-moving Agile delivery and to lead on troubleshooting.
Strong understanding of tools, design methodologies and best practice.
Ability to clearly communicate technical design both written and verbally.
Desirable Experience
Software development experience with Cloudera’s distribution of Apache Hadoop and with Python.
Experience of data visualisation and data complex data transformations, including ETL tools such as Talend.
Able to productionise machine learning algorithms.
Understanding of text processing including Natural Language Processing.
Experience with steaming and event-processing architectures including technologies such as Kafka and change-data-capture products.
Data modelling experience with data storage technology, such as document, graph, log stores and other non-relational platforms.
Open source contributor
Kainos is a professional services organisation with clients spread across the globe and we deliver projects both from client site, and from our offices. While we will attempt to base you on projects near or at your contracted office location, you need to be willing to travel to client sites and spend time away during the week if it is required.

Given the range and nature of work that we carry out for our clients, all Kainos employees are required to possesses up to date security clearance (Basic Disclosure, Access NI etc), if you do not already possess this, you will be asked to apply for it prior to joining Kainos.

Everyone who is offered a position here undergoes a background check; whether a criminal record excludes you from a career with Kainos depends on the role and the offences.

WHO YOU ARE:
Our vision is to enable outstanding people to create digital solutions that have a positive impact on people’s lives. Our values aren't abstract; they are the behaviours we expect from each other every day and underpin everything that we do. We expect everyone to display our values by being determined in how obstacles are overcome; honest when dealing with others; respectful of how you treat others; creative to find solutions to complex problems and cooperative by sharing information, knowledge and experience. These values, applied collectively, help to produce an outstanding Kainos person, team and culture.",4.1,"Kainos
4.1","Leeds, England",-1,1001 to 5000 Employees,1986,Company - Public,IT Services,Information Technology,$100 to $500 million (USD),-1
Data Engineer,-1,"We are recruiting for a Data Engineer to join our TP&A Process Team within Aviva.

Data is the lifeline of any modern organisation and Aviva is no different. The role sits within a team responsible for the data pipeline that provides Quantum Data Science Practice (covering areas like Machine Learning and AI, Pricing, Financial Crimes, Fraud and Underwriting) with the data they need to provide our customers with the best products.

This is an exciting opportunity to work within our Oracle Cloud environment, which is helping to craft the future of insurance through ground-breaking data delivery to predictive analytics and Data Science. As a team we are part of Aviva’s global Data Science Practise (Quantum) which is recognised as a centre of excellence - providing an Oracle Cloud platform that delivers the data needed to drive improved decision making and performance within Aviva.

Duties & Responsibilities:
Undertake application design, development and testing work to ensure delivery of robust Data applications, enhancements and meeting the needs of the customers.
To work closely with other members of the development team, the I.T. department and with other teams in Quantum Data Science on an ongoing basis.
To contribute during planning meetings, requirement gathering, and meetings with application stakeholders.
Tasks will also include production of relevant technical documentation to support the application.
Skills & Experience required:
Degree, diploma or Computer Science or equivalent numerate subject or equivalent relevant experience and knowledge.
Experience using SQL and PL/SQL, preferably in a financial services environment.
Good knowledge of general insurance.
Knowledge of System Design and Application Development Lifecycle.
Knowledge of other Development Languages including Python, R, Informatica would be advantageous.
Organised self-starter, with drive and commitment; able to work independently with little supervision.


What will you get for this role?
Salary of circa £25,0000 depending on skills, experience and qualifications.
Generous defined contribution pension scheme.
Annual performance related bonus and pay review.
Holiday allowance of 29 days plus bank holidays and the option to buy/sell up to 5 additional days.
Up to 40% discount for some Aviva products through “My Aviva Extras” plus discounts for Friends and Family. (Some exclusions apply).
Excellent range of flexible benefits to include a matching share save scheme.
Working at Aviva

At Aviva, we’re people with a purpose. To be with you today, for a better tomorrow.

We bring this to life by ensuring managing risk is at the heart of the way we all work. We love people who do the right thing for our customers, and our colleagues. We want people who speak up, who take responsibility, and who make good decisions.

The way we do this is important too. We always ‘Care More’. It’s our thing. We’re all about our people – that’s you – so we can be pretty flexible. If you want to work from home some of the time or change your hours so you can pick up your kids or care for someone in your family, we’re very open to that. In fact, we don’t advertise roles as either part or full time, because we know each person has different needs, just as each business area has different needs. So, it’s up to you to discuss working hours during your interview.

We care deeply about being inclusive and that means we encourage applications from people with diverse backgrounds and experiences. We want our employees to bring their whole self to work and that starts with you.

We interview every disabled applicant* that meets the minimum criteria for the job. Just send us an email once you’ve applied stating that you have a disclosed disability and we’ll make sure we interview you.

We’d love it if you could submit your application online. If you require an alternative method of applying, please give Alice Neal a call on 0121 200 5926 or send an email to alice.neal@aviva.com.

*As defined in The Equality Act 2010*. By ‘minimum criteria’ we mean you should provide us with evidence which demonstrates that you generally meet the level of competence required and have the qualifications, skills or experience defined as essential to perform the role.",3.6,"Aviva
3.6","Perth, Scotland",-1,10000+ Employees,1861,Company - Public,Insurance Carriers,Insurance,$5 to $10 billion (USD),-1
Cyber Systems Engineer,-1,"Do you have in depth understanding of Cyber Security Methodologies? Are you familiar with the information security threats facing aerospace defence contractors or Government systems?

Northrop Grumman is seeking a Cyber Systems Engineer to provide solutions designed to enhance the overall security posture of our internal and customer systems.

This is a permanent position based in our Cheltenham office but with a requirement for overseas travel

Different thinking for a Different world

Northrop Grumman Information Security supporting the Mission Systems sector is seeking a Cyber Systems Engineer to support non US locations, providing Information Security engineering services.

This individual will join our team of qualified and diverse individuals to support digital transformation. Become part of a fully engaged high performance team providing Information Security for Northrop Grumman. The qualified applicant will serve as the Northrop Grumman’s Missions Sector InfoSec Engineer, providing Information Security engineering services.

Application of system security engineering principles is required to provide realistic solutions designed to enhance the overall security posture of internal and customer systems, to include identifying threats, developing appropriate protection measures, reviewing security implications of system changes, recommending solutions and providing support for resolution of complex technical challenges.

How you will make a difference

Key responsibilities

Collaborate with engineering teams and other information security professionals to ensure strong and effective controls are in place to detect and mitigate risks across on-prem and cloud environments to meet business needs and regulatory requirements

Perform technical planning, system integration, verification and validation, balancing cost and risk, and supportability and effectiveness analysis across total systems

Work collaboratively on multiple concurrent projects, ensuring project and BAU activities remain compliant with ISO20000 & ISO27001

Perform system security analysis activities including requirements analysis, gap analysis, and analysis of alternatives

Ensure the logical and systematic conversion of security requirements into systems solutions that best mitigate cyber risks within the acknowledged technical, schedule and cost constraints, including activities such as:

secure proxy engineering

firewall policy management

messaging security engineering

remote access engineering

intrusion prevention engineering

network access compliance engineering

public key technologies

Active Directory services

Analyse and provide recommendations for improvements to and enhancements of in-house and external platforms, systems and tools

Development of system design artefacts in accordance with established architecture frameworks

Support the global team in processing and mitigating cyber threat actor activity

Collaborate effectively with information security analysts to co-ordinate a multi-tiered approach to cyber threat mitigation to deny current and future adversary actions

Undertake analytical duties in a secondary role to include host- and network-based log analysis, correlation of network threat indicators and PCAP data, analytical triage, incident response and vulnerability scanning

Research and draft Cybersecurity white papers as required, presenting findings to both technical teams and management

Person Specification
Preferred Experience

In-depth understanding and substantial application of cyber security methodologies
Experience in consulting and or working in a complex Enterprise environment
Extensive experience working with customers to elaborate requirements in often complex/uncertain environments
A proven track record of designing and developing secure solutions that meet customer requirements
Experience performing risk assessments of both internally and externally hosted solutions
Experience with ISO20000, ISO 270001, GDPR, HMG Security Policy Framework, Cyber Essentials, MCSS, etc.
Experience with network architecture, OSI model, and networking protocols
Experience with network security and penetration testing
Experience in creating and deploying cloud infrastructure solutions
Knowledge of security operations and tools
Knowledge of compliance regulations in UK, France, Germany, Italy, and other European standards
Knowledge of risk management industry principles, including use of a risk-based approach
Hands on validation of security control implementation
Institute security engineering concepts that , balance cost and risk, and supportability and effectiveness analysis across total systems
Work collaboratively on multiple concurrent projects with various program and technical stakeholders
Perform system security analysis activities including requirements analysis, gap analysis, and analysis of alternatives
Strong presentation and written skills with experience in presenting findings to executive leadership and/or technical teams
Experience of conducting analysis of electronic media, log data, and network devices in support of intrusion analysis or enterprise level information security operations
Experience with analysis and forensic tools used in a SOC or similar investigative environment
Penetration testing experience
Knowledge and/or experience in one or more of the following technologies: AD/DNS, Patch Management, PKI, HBSS, ACAS, VMware products, Splunk
Familiarity in the Risk Management Framework (RMF) Cybersecurity Lifecycle
Experience of UK and European Government working practices and proposals

Preferred Qualifications

Hold one or more of the following technical certifications (or equivalent):

o International Council on Systems Engineering (INCOSE)
o Certified Information Systems Security Professional (CISSP)
o GIAC Certified Enterprise Defender (GCED)
o GIAC Certified Incident Handler (GCIH)
o GIAC Certified Intrusion Analyst (GCIA)
o GIAC Certified Forensic Analyst (GCFA)
o GIAC Reverse Engineering Malware (GREM)
o Certified Forensic Computer Examiner (CFCE)
o OSCP Offensive Security Certified Professional
o CEH Certified Ethical Hacker
o Cloud Certifications

Competency/Skill requirements

Current and evolving familiarity with information security threats facing aerospace defence contractors or Government systems
Adept at two or more analysis and forensic tools used in a CSIRT or similar investigative environment
Able to exercise sound judgment when escalating issues
A creative thinker, particularly around remediation and countermeasures to challenging information security threats
Highly self-motivated and directed, able to effectively work autonomously and as part of a wider, virtual team
Excellent interpersonal skills, able to engage effectively with a wide range of stakeholders
Excellent PowerPoint skills, able to clearly present technical content to audiences of mixed technical backgrounds
Fluent in written and spoken English, fluency in other European languages advantageous – Italian, French, German.
Strong analytical skills, adept at trouble-shooting and problem-solving
Flexible and responsive attitude
Highly-organised and proficient at multi-tasking, working with and resolving competing priorities
Strong customer orientation
Excellent attention to detail
Advanced knowledge of technology capabilities and trends

Other requirements
Ability to travel up to 60 % within Europe, Middle East, Africa and occasional travel to US
Clearance requirements: Ability to hold and maintain relevant UK Government clearance
Looking for flexibility? Talk to us at the application stage about what may be possible.",3.8,"Northrop Grumman UK
3.8","Cheltenham, England",-1,10000+ Employees,1939,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
Data Engineer,-1,"Data Engineer

You will act as a key member of the Azure Data Team, working directly with various

stakeholders from across the business, designing stable and reliable data warehousing technology that surfaces the data our business uses, proactively monitoring the company's data warehouse and participating in the design and implementation of the associated data pipeline technology that moves data from our operational systems to the data warehouse.

PRINCIPLE DUTIES AND RESPONSIBILITIES

The responsiblities for this role will be:

● Developing the data warehouse platform

● Collaborating with operational Systems Owners to identify issues with existing pipelines

● Designing stable, reliable and effective data pipelines

● Providing data design consultancy to operational Systems Owners

● Providing expert data and domain advice to Management Information specialists

● Contributing to data technology roadmaps

● Schema design and data modelling

● Ensuring the data warehouse technology complies with operational and service management standards

● Managing data technology across distributed Azure Regions and Technology

● Escalating data problems to operational Systems Owners

● Researching and suggesting new data products, services and technologies

● Working in a 24x7 high-availability environment

● Providing on call support including out-of-hours incident support

Requirements

As an exceptional applicant, with a proven track in a similar role, you will have:

● Experience in developing, building and deploying solutions based on Microsoft Azure SQL, Databricks, Data Factory and Blob Storage

● Infrastructure as Code technologies

● Ability to produce production-quality code using git source control

● In-depth understanding of data management

● Ability to quickly understand new schemas

● Ability to convert business requirements into data pipelines

● Experience of working with MI/BI Analysts/Visualisers

● Performance tuning of Azure Data Technology

Benefits

How would you like to make business communication brilliant! Working with more than 45,000 clients, helping them to transform their mobile communication. To thrive in this role you will enjoy working in an environment of passion, integrity, ownership and innovation, where development and progression is a real focus.

With regards to benefits package, you should expect 27 days holiday and your birthday off work, to private medical cover, dental cover and bi-monthly social events! On top of this you can expect £350 of Christmas vouchers and added extras like beer o’clock and an amazing Christmas party (after Covid restrictions).

To apply contact Charlene now for information by clicking apply!

As an exceptional applicant, with a proven track in a similar role, you will have:

● Experience in developing, building and deploying solutions based on Microsoft Azure SQL, Databricks, Data Factory and Blob Storage

● Infrastructure as Code technologies

● Ability to produce production-quality code using git source control

● In-depth understanding of data management

● Ability to quickly understand new schemas

● Ability to convert business requirements into data pipelines

● Experience of working with MI/BI Analysts/Visualisers

● Performance tuning of Azure Data Technology",5.0,"Park Lane Recruitment Ltd
5.0","Nottingham, England",-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Job Title: *Data Engineer
Job Type: *Contract/ Temporary
Duration: *5 Months
Rate: *£375.94 per day
Location: *Home Based
IR35 Status: *In scope
Security Clearance: *DBS Check will be required before starting
Designs, builds and tests data products based on feeds from multiple systems using a range of different storage technologies and/or access methods.
Creates repeatable and reusable products.
Delivers data solutions in accordance with agreed organisational standards that ensure services are resilient, scalable and future-proof.
Understands the concepts and principles of data modelling and is able to produce, maintain and update relevant data models for specific business needs.
Reverse engineers data models from a live system.
Designs, codes, tests, corrects and documents simple programs or scripts under the direction of others.
Understands core technical concepts related to their role and is able to apply them with guidance.
Please ensure your submitted CV has all gaps in employment explained. So, if you were looking for employment during any gaps please state this on your CV.

Ensure your CV fully covers all the criteria stated above to maximise your chances on being successfully placed for this role.

Let us know of your availability and whether there are any specific dates if you are unavailable to attend an interview. Notifying us of any holiday dates is advantages and allows us to notify parties in advance so they can plan accordingly.

All CVs received are acknowledged and held for the job applied for. If you would like us to remove your details at anytime please do let us know in writing so we can remove all your details accordingly.

By applying to this role you are giving us your permission to represent you by submitting your CV (by way of right to represent) unless you inform us otherwise. You will also be required to confirm whether you wish to Opt-in or Opt-out of Conduct Regulations. For your protection, we will assume you are Opting-in unless you inform us otherwise.

We wish you the best in your search for an ideal role and look forward to hearing from you soon.

Please note, we try to remove roles advertised as they become unavailable in a timely manner. If you have applied for a role and it is no longer available we will inform you as soon as possible.

AJACO is an equal opportunities employer.

Contract length: 5 months

Job Types: Full-time, Temporary

Salary: £375.94 per day

Experience:
Public Sector: 1 year (Required)
Data Engineer: 1 year (Required)
Work remotely:
Yes",-1,AJACO,"London, England",-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Would you like to help create a brand-new engineering organisation? Perhaps you know what great engineering culture looks like, or you have an entrepreneurial side as well as outstanding coding skills? Whatever your aspirations, we’re trying to create the best engineering consultancy in the UK and looking for brilliant engineers to be part of the journey.

About DMW Engineering
DMW helps organisations solve their biggest, most exciting engineering problems. We’ve created banks from scratch on Kubernetes and AWS, built streaming analytics solutions that protect the country and built platforms to enable whole organisations to move to AWS and Azure, and everything in between. We do all this in a work environment where regular social events, inclusivity and an ego-free culture mean we’ve been officially voted a “Great Place to Work” for five years in a row.
We’re not interested in cutting corners and believe in helping our clients to make the right choice for the long-term. We draw on our reputation for outstanding delivery to allow our engineers to do the right thing for our clients, and not necessarily the easy thing. Innovation is in our DNA, and we encourage our engineers and consultants to work together to rethink conventional wisdom on how problems should be solved.
Location:
Based in the vibrant and modern Labs House, we are a stone’s throw away from Holborn station. Boasting coffee lounges, co-working spaces, ping pong/table tennis tables, free on-site gym and weekly yoga classes all the way through to fortnightly free breakfasts.
Here’s what you will do (Not all of it, but some of the important stuff!)
• Solve the problems others cannot
• Spend a day a week working on a combination of internal products and your own development
• Create data platforms based around modern open source products and cloud-native technologies:
• AWS, Azure and Google Cloud
• Python
• Kafka / NiFi / Flume
• DB technologies: SQL Server / PosteSQL / MySQL
• Hive/Spark/Impala
• Dataiku
• Terraform
• Kubernetes

Requirements:

The essentials?
• Experiece building data platforms using either cloud native products or commercial data analytics / data warehouse software
• Working knowledge of data pipelines & data transformation processes
• Experience creating and/or maintaining production software delivery pipelines using common CI/CD tools (e.g. Jenkins, GoCD, CircleCI)
• Demonstrable experience in automating operations tasks with one or more scripting languages
• Experience working with one or more of the main cloud providers (AWS, Azure or Google)
• Have a drive for self-improvement and learning, including learning new programming languages
• Approach solving problems pragmatically
• Experience of Hadoop big data platforms (either Cloudera / Hortonworks or cloud native equivalents)
• Experience with data reporting and visualisation tools (PowerBI, Tableau, Qlik)
• Experience productionising machine learning algorithms
• Experience with Infrastructure as Code (e.g. Terraform, Cloudformation)
• Experience supporting and operating production systems
• Familiarity with configuration management tooling (e.g. Ansible)
It would be great if you had these desirable skills • Experience of Hadoop big data platforms (either Cloudera / Hortonworks or cloud native equivalents)
• Experience with data reporting and visualisation tools (PowerBI, Tableau, Qlik)
• Experience productionising machine learning algorithms
• Experience with Infrastructure as Code (e.g. Terraform, Cloudformation)
• Experience supporting and operating production systems
• Familiarity with configuration management tooling (e.g. Ansible)

Benefits:

We’ve grown consistently over the years and offer an entrepreneurial environment within which to embark upon an exciting career path, where your contribution really counts, and we will recognise it. With personalised development opportunities, experienced colleagues and challenging client assignments, progression can be extremely rapid for high performers. We are a social bunch of people and go out as a team on a regular basis. You can also expect:
• A highly collaborative working environment and great rates of pay (including base salary and bonus potential).
• A range of flexible benefits consisting of well-being and lifestyle benefits.
• A commitment to your development & continuous growth of skills through one-to-one mentoring and wide-ranging hands-on experience.
• 25 days’ holiday and the ability to flex this to 30 days if you chose to do so.
• 2 day’s CSR volunteering days.
• Award-winning learning and development opportunities, including dedicated personal training budgets and time and a wide range of choice in training courses.
• A dedicated personal budget to choose the IT equipment of your choice.",4.7,"DMW Group
4.7","London, England",-1,51 to 200 Employees,1989,Company - Private,IT Services,Information Technology,$10 to $25 million (USD),-1
Data Engineer,-1,"My client is a great success story that grew from being a start up to one of the market leaders in their field today.
The role, the team, what you will be doing*
This team is responsible for building out the platform that powers all personalisation on site. This is a high impact team aiming to show the right product, to the right customer, at the right time.

The team use machine learning to rank search results and recommend the perfect offering to the customer base.

The team are iterating on current algorithms and are looking for someone who can bring more experience and new ideas to the team. This is the next chapter of personalisation in the business so a real opportunity to shape a core part going forwards.

They work in cross-functional teams where every data engineer is both a member of the wider Data community and fully embedded into a cross-functional team alongside engineers, data scientists and product managers.

As a data engineer within Personalisation, you’ll support the team in meeting their goals, using their priorities to build out new capabilities in the Data Platform in line with the Architectural strategy. You'll be able to build, deploy, operationalise and monitor data systems with a focus on security and reliability.

You’ll also work closely with the Data Scientists to apply Continuous Delivery and DevOps principles to model training and deployment. You'll have experience in a variety of data modelling approaches, really understand the challenges that come with working with very large data sets.

You’re comfortable working with structured, unstructured and semi-structured data, have practical knowledge of event driven approaches and tooling, and you get a real kick from performance tuning.

As part of the wider Data team, you’ll play a key role in shaping the technical direction of the platform and approach to data.

You’ll bring robust engineering practises including TDD and pair programming, along with hands-on experience of building scalable pipelines and re-usable infrastructure.

The team are evangelists of agile values and principles but each team is responsible for their own way of working.

All members of the team have the opportunity to help influence the teams’ processes through a continuous improvement mindset. Working in a fast paced, low ceremony environment and deploy multiple times a day.

They use a variety of programming languages across teams such as Ruby, C# and Python so polyglot thinking is a must.
What are they looking for?*
Working in cross-functional teams (e.g. Engineers, Product Owners, etc.) in an agile environment
Strong working knowledge of Python and R, experience of robust engineering practises including TDD and pair programming
Experience working with Data Scientists to apply DevOps principles to model training and deployment
Extensive SQL experience including performance, query optimisation and data modelling
Experience of testing and automation processes associated with big data solution development
Demonstrable history of manipulating, processing and extracting value from large disconnected datasets
Experience building data pipelines at scale using a range of tools and technologies
Experience with data lakes, message queuing, stream processing, and highly scalable big data stores
Understanding of the governance and security challenges associated with data
Commercial experience working with big data tooling from at least one major cloud vendor (AWS, Azure, GCP) including the development, setup, configuration and monitoring of solutions running on these platforms
The essentials*
Agile environment
Python and R
Experience of robust engineering practises including TDD and pair programming
Reference ID: FRC3056

Job Types: Full-time, Permanent

Salary: £50,000.00-£60,000.00 per year

Benefits:
Casual dress
Company events
Discounted or free food
Employee discount
Flexible schedule
Free or subsidised travel
Private dental insurance
Private medical insurance
Profit sharing
Work from home
Schedule:
Monday to Friday
Work remotely:
Yes",-1,Fox-Rees Consulting,"Manchester, England",-1,-1,-1,-1,-1,-1,-1,-1
Senior Data Engineer,-1,"About Birdie

Birdie is a pioneer in social innovation. Our vision is to build a society in which we all age with confidence. With a rapidly growing ageing population, overcrowded care homes and social care services under water, we’re facing a social crisis. We ’re on a mission to reinvent care so that older generations can live longer, healthier and happier in their own homes, surrounded by their families and their communities. We use digital products, cutting-edge home connected devices and AI to empower the care community to deliver better, preventative care

Launched in 2017, Birdie is a team of 55 socially motivated care, health, product and tech entrepreneurs. We were nominated one of the top 10 UK startups to watch, the SME with the best culture in the UK and was in the 2020 Business Cloud Top 50 Start Up's list.

We are building the organisation of the future that will not only improve the lives of millions of older adults but also of our team members, our communities and will protect the environment. We demonstrate our values in everything we do. We care; we succeed together; we grow individually and strive for excellence; we are smart, brave and ambitious; and we nurture fun and a little quirkiness.

Your mission

We strongly believe that data holds the key to unlock innovation in social care. It is the foundation of how we learn as a company as well as how we enable our customers to improve their services. Our applications and services generate a wealth of rich data - it is essential that we’re able to process, analyse & deliver as much of it as possible to improve the lives of older adults.

You will define & build our next-generation data platform to enable data products which
directly help our customers to improve care via the Birdie app;
help fellow Birdie colleagues understand and improve our service.
You’ll be working across various squads to make sure that the right data is available at the right time to solve real customer problems.

How you will contribute

Your objectives when joining will be to:
Design a new data architecture in-partnership with the infrastructure & product squads using the right technologies to solve today’s problems as well as the problems Birdie will face over the next 18 months:
Birdie’s data footprint doubles every quarter so we need to use scalable technologies to ensure data remains readily accessible for our customers as well as Birdie employees.
Our product architecture is becoming increasingly decentralised - it’s crucial that product services are able to reliably share datasets amongst each other.
Birdie is integrating with more and more third party health applications to download and share data so it’s important that we can support a wide range of communication protocols.
Build data infrastructure, tools & training programs enabling product squads to:
Dramatically reduce time taken to source, process, model and publish datasets.
Improve the accuracy, reliability & re-usability of datasets.
Requirements

We’d love to hear from you if

Experience and Education
At least 3 years experience working in a data engineering role.
BSc/MSc in computer science, maths, science or engineering related subject.
Profile
Strong consultancy & influencing skills - able to gather requirements from a range of stakeholders and guide the group towards the best solution for Birdie.
Passionate about enabling others with tools and training - careful not to become a single point of failure.
Outcome focused - prioritises delivering value above having the ‘perfect’ solution.
Great communicator - capable of explaining technical problems & solutions in clear, concise terms understandable to non-technical audiences.
Not afraid to challenge - will always speak up on behalf of the right solution, even if it’s against group consensus.
Quality focused - evangelises the importance of data quality, coaches teams to use best practices improving data reliability and accuracy.
Technical leader - highly curious about new technology with clear ability to rapidly learn and understand pros and cons of new tools.
Cares deeply about data privacy and security.
Technical Know-How
Cloud data warehousing (e.g. BigQuery, Snowflake, Redshift).
Data integration libraries (e.g. Flask, Connexion, SQLAlchemy).
Data lake query engines (e.g. Drill, Athena, Presto, Hive, Spark).
Streaming technologies (e.g. TCP, Apache Beam, Kafka, Kinesis, Flink).
Batch processing tools (e.g. Airflow, Google Dataflow).
Cloud infrastructure (e.g. GCP, AWS, Azure).
These are our ideal requirements, but we know some people are less likely to apply for the role unless they are 100% qualified. We promote a diverse, inclusive and empowering culture at Birdie, so please apply if you meet the majority of these competencies.

Benefits

We have put together an exciting and highly attractive package for this role.
Competitive salary up to £75k+ - dependent on skills, experience and ambition
Eligible to equity
Private health insurance + pension employer contribution
Personal learning & development budget
A flexible Wellbeing Budget
Flexible working options; we're all remote at the moment, and while we do currently have an office, we're working towards becoming a distributed-first company (for now just in the UK for permanent contracts but we hire people in other European countries as freelance contractors with the goal of moving them into full-time employees in the future)
25 days of holiday + bank holidays
A generous wellbeing leave policy
An enhanced equal parental leave policy in place from January 2021
Frequent company socials, trips and meals - believe us we have fun!
Why Birdie?

Join Birdie and seize this unique opportunity to shape the future of a transformative tech startup, to create positive social change, and develop yourself very fast in a flat, flexible, close-knit & transparent organisation.

We have a grand vision to transform how society deals with ageing, starting with radically improving the lives of 1 million older adults in the next 4 years. We dream big and speed is of the essence.

We’re all entrepreneurs at Birdie. We’re a flat organization, with no manager to tell you what to do but a community of peers and coaches to support you.

We’re highly collaborative and iterative. Everything we do is transparent to anyone, be it objectives and key results, compensation packages and equity or strategic conversations.

Growing with trust is key. Everyone sets their own development plan and gets support to learn fast, from training to books or coaches. We live by radical candour: we give honest feedback and care deeply & personally about each other.

Check our blog to get a feeling of our culture and vision. And join us now to improve the lives of millions!

Equal Opportunities Statement

We are an equal opportunity employer and we strive to reduce unconscious bias throughout our hiring process. All applicants will be considered for employment without attention to ethnicity, religion, sexual orientation, gender identity, family or parental status, national origin, veteran, neurodiversity status or disability status.

We endeavour to embrace diversity, and promote an inclusive environment for all Birdies, and actively work towards this with our Diversity & Inclusion Committee.

If you have any questions regarding the interview process, or if you need any reasonable adjustments to be made, please don’t hesitate to contact us.",5.0,"Birdie
5.0","London, England",-1,51 to 200 Employees,-1,Company - Private,Health Care Services & Hospitals,Health Care,Unknown / Non-Applicable,-1
Data Engineer,-1,"Would you like to help create a brand-new engineering organisation? Perhaps you know what great engineering culture looks like, or you have an entrepreneurial side as well as outstanding coding skills? Whatever your aspirations, we’re trying to create the best engineering consultancy in the UK and looking for brilliant engineers to be part of the journey.

About DMW Engineering
DMW helps organisations solve their biggest, most exciting engineering problems. We’ve created banks from scratch on Kubernetes and AWS, built streaming analytics solutions that protect the country and built platforms to enable whole organisations to move to AWS and Azure, and everything in between. We do all this in a work environment where regular social events, inclusivity and an ego-free culture mean we’ve been officially voted a “Great Place to Work” for five years in a row.
We’re not interested in cutting corners and believe in helping our clients to make the right choice for the long-term. We draw on our reputation for outstanding delivery to allow our engineers to do the right thing for our clients, and not necessarily the easy thing. Innovation is in our DNA, and we encourage our engineers and consultants to work together to rethink conventional wisdom on how problems should be solved.
Location:
Based in the vibrant and modern Labs House, we are a stone’s throw away from Holborn station. Boasting coffee lounges, co-working spaces, ping pong/table tennis tables, free on-site gym and weekly yoga classes all the way through to fortnightly free breakfasts.
Here’s what you will do (Not all of it, but some of the important stuff!)
• Solve the problems others cannot
• Spend a day a week working on a combination of internal products and your own development
• Create data platforms based around modern open source products and cloud-native technologies:
• AWS, Azure and Google Cloud
• Python
• Kafka / NiFi / Flume
• DB technologies: SQL Server / PosteSQL / MySQL
• Hive/Spark/Impala
• Dataiku
• Terraform
• Kubernetes

Requirements:

The essentials?
• Experiece building data platforms using either cloud native products or commercial data analytics / data warehouse software
• Working knowledge of data pipelines & data transformation processes
• Experience creating and/or maintaining production software delivery pipelines using common CI/CD tools (e.g. Jenkins, GoCD, CircleCI)
• Demonstrable experience in automating operations tasks with one or more scripting languages
• Experience working with one or more of the main cloud providers (AWS, Azure or Google)
• Have a drive for self-improvement and learning, including learning new programming languages
• Approach solving problems pragmatically
• Experience of Hadoop big data platforms (either Cloudera / Hortonworks or cloud native equivalents)
• Experience with data reporting and visualisation tools (PowerBI, Tableau, Qlik)
• Experience productionising machine learning algorithms
• Experience with Infrastructure as Code (e.g. Terraform, Cloudformation)
• Experience supporting and operating production systems
• Familiarity with configuration management tooling (e.g. Ansible)
It would be great if you had these desirable skills • Experience of Hadoop big data platforms (either Cloudera / Hortonworks or cloud native equivalents)
• Experience with data reporting and visualisation tools (PowerBI, Tableau, Qlik)
• Experience productionising machine learning algorithms
• Experience with Infrastructure as Code (e.g. Terraform, Cloudformation)
• Experience supporting and operating production systems
• Familiarity with configuration management tooling (e.g. Ansible)

Benefits:

We’ve grown consistently over the years and offer an entrepreneurial environment within which to embark upon an exciting career path, where your contribution really counts, and we will recognise it. With personalised development opportunities, experienced colleagues and challenging client assignments, progression can be extremely rapid for high performers. We are a social bunch of people and go out as a team on a regular basis. You can also expect:
• A highly collaborative working environment and great rates of pay (including base salary and bonus potential).
• A range of flexible benefits consisting of well-being and lifestyle benefits.
• A commitment to your development & continuous growth of skills through one-to-one mentoring and wide-ranging hands-on experience.
• 25 days’ holiday and the ability to flex this to 30 days if you chose to do so.
• 2 day’s CSR volunteering days.
• Award-winning learning and development opportunities, including dedicated personal training budgets and time and a wide range of choice in training courses.
• A dedicated personal budget to choose the IT equipment of your choice.",4.7,"DMW Group
4.7","London, England",-1,51 to 200 Employees,1989,Company - Private,IT Services,Information Technology,$10 to $25 million (USD),-1
Data Engineer,-1,"My client is a great success story that grew from being a start up to one of the market leaders in their field today.
The role, the team, what you will be doing*
This team is responsible for building out the platform that powers all personalisation on site. This is a high impact team aiming to show the right product, to the right customer, at the right time.

The team use machine learning to rank search results and recommend the perfect offering to the customer base.

The team are iterating on current algorithms and are looking for someone who can bring more experience and new ideas to the team. This is the next chapter of personalisation in the business so a real opportunity to shape a core part going forwards.

They work in cross-functional teams where every data engineer is both a member of the wider Data community and fully embedded into a cross-functional team alongside engineers, data scientists and product managers.

As a data engineer within Personalisation, you’ll support the team in meeting their goals, using their priorities to build out new capabilities in the Data Platform in line with the Architectural strategy. You'll be able to build, deploy, operationalise and monitor data systems with a focus on security and reliability.

You’ll also work closely with the Data Scientists to apply Continuous Delivery and DevOps principles to model training and deployment. You'll have experience in a variety of data modelling approaches, really understand the challenges that come with working with very large data sets.

You’re comfortable working with structured, unstructured and semi-structured data, have practical knowledge of event driven approaches and tooling, and you get a real kick from performance tuning.

As part of the wider Data team, you’ll play a key role in shaping the technical direction of the platform and approach to data.

You’ll bring robust engineering practises including TDD and pair programming, along with hands-on experience of building scalable pipelines and re-usable infrastructure.

The team are evangelists of agile values and principles but each team is responsible for their own way of working.

All members of the team have the opportunity to help influence the teams’ processes through a continuous improvement mindset. Working in a fast paced, low ceremony environment and deploy multiple times a day.

They use a variety of programming languages across teams such as Ruby, C# and Python so polyglot thinking is a must.
What are they looking for?*
Working in cross-functional teams (e.g. Engineers, Product Owners, etc.) in an agile environment
Strong working knowledge of Python and R, experience of robust engineering practises including TDD and pair programming
Experience working with Data Scientists to apply DevOps principles to model training and deployment
Extensive SQL experience including performance, query optimisation and data modelling
Experience of testing and automation processes associated with big data solution development
Demonstrable history of manipulating, processing and extracting value from large disconnected datasets
Experience building data pipelines at scale using a range of tools and technologies
Experience with data lakes, message queuing, stream processing, and highly scalable big data stores
Understanding of the governance and security challenges associated with data
Commercial experience working with big data tooling from at least one major cloud vendor (AWS, Azure, GCP) including the development, setup, configuration and monitoring of solutions running on these platforms
The essentials*
Agile environment
Python and R
Experience of robust engineering practises including TDD and pair programming
Reference ID: FRC3056

Job Types: Full-time, Permanent

Salary: £50,000.00-£60,000.00 per year

Benefits:
Casual dress
Company events
Discounted or free food
Employee discount
Flexible schedule
Free or subsidised travel
Private dental insurance
Private medical insurance
Profit sharing
Work from home
Schedule:
Monday to Friday
Work remotely:
Yes",-1,Fox-Rees Consulting,"Manchester, England",-1,-1,-1,-1,-1,-1,-1,-1
Senior Data Engineer,-1,"About Birdie

Birdie is a pioneer in social innovation. Our vision is to build a society in which we all age with confidence. With a rapidly growing ageing population, overcrowded care homes and social care services under water, we’re facing a social crisis. We ’re on a mission to reinvent care so that older generations can live longer, healthier and happier in their own homes, surrounded by their families and their communities. We use digital products, cutting-edge home connected devices and AI to empower the care community to deliver better, preventative care

Launched in 2017, Birdie is a team of 55 socially motivated care, health, product and tech entrepreneurs. We were nominated one of the top 10 UK startups to watch, the SME with the best culture in the UK and was in the 2020 Business Cloud Top 50 Start Up's list.

We are building the organisation of the future that will not only improve the lives of millions of older adults but also of our team members, our communities and will protect the environment. We demonstrate our values in everything we do. We care; we succeed together; we grow individually and strive for excellence; we are smart, brave and ambitious; and we nurture fun and a little quirkiness.

Your mission

We strongly believe that data holds the key to unlock innovation in social care. It is the foundation of how we learn as a company as well as how we enable our customers to improve their services. Our applications and services generate a wealth of rich data - it is essential that we’re able to process, analyse & deliver as much of it as possible to improve the lives of older adults.

You will define & build our next-generation data platform to enable data products which
directly help our customers to improve care via the Birdie app;
help fellow Birdie colleagues understand and improve our service.
You’ll be working across various squads to make sure that the right data is available at the right time to solve real customer problems.

How you will contribute

Your objectives when joining will be to:
Design a new data architecture in-partnership with the infrastructure & product squads using the right technologies to solve today’s problems as well as the problems Birdie will face over the next 18 months:
Birdie’s data footprint doubles every quarter so we need to use scalable technologies to ensure data remains readily accessible for our customers as well as Birdie employees.
Our product architecture is becoming increasingly decentralised - it’s crucial that product services are able to reliably share datasets amongst each other.
Birdie is integrating with more and more third party health applications to download and share data so it’s important that we can support a wide range of communication protocols.
Build data infrastructure, tools & training programs enabling product squads to:
Dramatically reduce time taken to source, process, model and publish datasets.
Improve the accuracy, reliability & re-usability of datasets.
Requirements

We’d love to hear from you if

Experience and Education
At least 3 years experience working in a data engineering role.
BSc/MSc in computer science, maths, science or engineering related subject.
Profile
Strong consultancy & influencing skills - able to gather requirements from a range of stakeholders and guide the group towards the best solution for Birdie.
Passionate about enabling others with tools and training - careful not to become a single point of failure.
Outcome focused - prioritises delivering value above having the ‘perfect’ solution.
Great communicator - capable of explaining technical problems & solutions in clear, concise terms understandable to non-technical audiences.
Not afraid to challenge - will always speak up on behalf of the right solution, even if it’s against group consensus.
Quality focused - evangelises the importance of data quality, coaches teams to use best practices improving data reliability and accuracy.
Technical leader - highly curious about new technology with clear ability to rapidly learn and understand pros and cons of new tools.
Cares deeply about data privacy and security.
Technical Know-How
Cloud data warehousing (e.g. BigQuery, Snowflake, Redshift).
Data integration libraries (e.g. Flask, Connexion, SQLAlchemy).
Data lake query engines (e.g. Drill, Athena, Presto, Hive, Spark).
Streaming technologies (e.g. TCP, Apache Beam, Kafka, Kinesis, Flink).
Batch processing tools (e.g. Airflow, Google Dataflow).
Cloud infrastructure (e.g. GCP, AWS, Azure).
These are our ideal requirements, but we know some people are less likely to apply for the role unless they are 100% qualified. We promote a diverse, inclusive and empowering culture at Birdie, so please apply if you meet the majority of these competencies.

Benefits

We have put together an exciting and highly attractive package for this role.
Competitive salary up to £75k+ - dependent on skills, experience and ambition
Eligible to equity
Private health insurance + pension employer contribution
Personal learning & development budget
A flexible Wellbeing Budget
Flexible working options; we're all remote at the moment, and while we do currently have an office, we're working towards becoming a distributed-first company (for now just in the UK for permanent contracts but we hire people in other European countries as freelance contractors with the goal of moving them into full-time employees in the future)
25 days of holiday + bank holidays
A generous wellbeing leave policy
An enhanced equal parental leave policy in place from January 2021
Frequent company socials, trips and meals - believe us we have fun!
Why Birdie?

Join Birdie and seize this unique opportunity to shape the future of a transformative tech startup, to create positive social change, and develop yourself very fast in a flat, flexible, close-knit & transparent organisation.

We have a grand vision to transform how society deals with ageing, starting with radically improving the lives of 1 million older adults in the next 4 years. We dream big and speed is of the essence.

We’re all entrepreneurs at Birdie. We’re a flat organization, with no manager to tell you what to do but a community of peers and coaches to support you.

We’re highly collaborative and iterative. Everything we do is transparent to anyone, be it objectives and key results, compensation packages and equity or strategic conversations.

Growing with trust is key. Everyone sets their own development plan and gets support to learn fast, from training to books or coaches. We live by radical candour: we give honest feedback and care deeply & personally about each other.

Check our blog to get a feeling of our culture and vision. And join us now to improve the lives of millions!

Equal Opportunities Statement

We are an equal opportunity employer and we strive to reduce unconscious bias throughout our hiring process. All applicants will be considered for employment without attention to ethnicity, religion, sexual orientation, gender identity, family or parental status, national origin, veteran, neurodiversity status or disability status.

We endeavour to embrace diversity, and promote an inclusive environment for all Birdies, and actively work towards this with our Diversity & Inclusion Committee.

If you have any questions regarding the interview process, or if you need any reasonable adjustments to be made, please don’t hesitate to contact us.",5.0,"Birdie
5.0","London, England",-1,51 to 200 Employees,-1,Company - Private,Health Care Services & Hospitals,Health Care,Unknown / Non-Applicable,-1
Data Engineer,-1,"Data Engineer Role!

What you’ll be doing?

· Work with the applications and database team to meet the key business strategies and objectives.

· Development of the warehouse to encompass more sources and additional datasets

· Create and maintain SQL procedures, User Defined Functions and Views to support and maintain new and existing reporting requirements.

· Proactively improve the performance, logical structure, physical structure and availability of the Data Warehouse and other reporting environments

· Issue resolution for any incoming data inconsistencies

· To support the build and maintenance of the Data Warehouse

· Work as part of the team to build and maintain the data reporting environments

· Using SQL services, SSAS and MDS to support the existing business solutions and technologies

· Work as part of the team to provide application and reporting development services/support

· To work with the team to ensure that core applications and strategies are aligned",3.1,"QA Limited
3.1",Remote,-1,1001 to 5000 Employees,1985,Company - Private,Education Training Services,Education,$100 to $500 million (USD),-1
Data Engineer,-1,"A new opportunity has arisen for an experienced Data Engineer to join a prestigious global company, as part of an impressive Data Team at an exciting time of company growth. You will be involved in an exciting transition towards a more Data focused business, by maintaining and enhancing a new Snowflake Data Warehouse, along with development of Power BI dashboards to replace existing reports.

As the Data Engineer, you will be responsible for developing dashboards and visualisations to ensure the company is getting the most out of its data. You will also be designing and developing data pipelines, using all the latest technology.

This role allows the successful candidate the opportunity to learn new skills on technologies such as Snowflake, Wherescape, Redgate and many others, particularly as the business needs change and evolve. Using these technologies, you will be largely involved in rolling out and integrating new data products within the wider company, to meet business needs.

Key skills and experience required for the Data Engineer Role:

Proven experience within a data warehouse focused role.
Strong experience of using ELT/ETL based approaches to develop solutions.
Previous experience with Snowflake is highly beneficial.
Hands on experience building data visualisation and dashboards from scratch.
Experience with using SQL.
Experience with using Power BI (Dax).
Excellent stakeholder management skills.

Data Engineer: Data, Data Engineering, BI Development, BI Developer, Dax, Wherescape, Power BI, Snowflake, Azure, SQL, Git, Jenkins, Redgate, DataOps, Data Pipelines, ELT, ETL

Location: Hove

Salary: £45,000 - £55,000 (depending on experience) + bonus + benefits (including flexi-working, work from home, private medical, pension plan)

Apply now for further details and immediate consideration.
Understanding Recruitment is acting as an employment agency for this vacancy",4.5,"Understanding Recruitment
4.5","Hove, England",-1,1 to 50 Employees,2007,Company - Private,Staffing & Outsourcing,Business Services,$1 to $5 million (USD),-1
Data Engineer,-1,"Marex Spectron is a global leader in the commodities industry, broking and trading across most asset classes. Based next to Liverpool Street station, we are a short walk from most of the tube stations and British Rail stations in the square mile as well as Shoreditch High Street on the London Overground network.

The last few years have seen our organisation grow rapidly in terms of both size and complexity. We've acquired businesses, opened offices in new locations, joined new exchanges, added new products and asset classes, all within an ever changing regulatory environment against a background of geopolitical instability.

We are currently looking for someone to join our team and scope out then lead the development of a high-availability, easily scalable data platform to be used across the business. This platform will be used to collate, organise, store and process vast amounts of structured and unstructured data, developing efficient data pipelines and allowing us to effectively and efficiently analyse our information as well as creating new heterogenous data sets for further consumption and analysis.

You will have already gained significant experience in the field, having already built large data platforms with teams of data engineers and scientists. You will be familiar with agile and scrum methodologies, used to working on organically evolving projects. Your communications skills will be highly advanced, you'll be adept at getting to the root of what is required and have the problem solving-ability to create systems that elegantly fulfill the needs of the business. In terms of technical skills, you will have experience of cloud-based enterprise solutions and will have worked with some or all of: SQL Server, Oracle, MongoDB, Data Warehouse, Data Lake, Apache Kafka, Python, Javascript/Typescript, Apache Spark and PowerBI as well as other components of the Microsoft Power Platform.

If you're looking for a role where the tools you build influence and advise strategic decision-making at the highest level in a nimble and ambitious organisation, if you thrive in complex, dynamic environments and have an innate sense W(with some corresponding experience) of the opportunities that effective data analysis can unlock, we'd love to hear from you!

#LI-MH1",3.5,"Marex Spectron
3.5","London, England",-1,501 to 1000 Employees,2006,Company - Private,Brokerage Services,Finance,$100 to $500 million (USD),-1
Data Engineer,-1,"About the Role
Would you like to work for one of the leading players in the international financial services industry?

Join SWIFT and be part of the Exploration Squad, in charge of exploring new directions to leverage data at SWIFT. You will be working within a team with a broad range of technical, business and analytical skills with initial focus on creating business insights and new data products.

Joining as a Data Engineer, you will get the opportunity to learn from professionals with extensive experience in data projects at global banks and financial institutions. You will work in an international rapidly evolving agile working environment, with many opportunities for gaining a broad range of experience and pursue an interesting and varied career growth.

Education

University degree in engineering, computer science or related field. Or equivalent work experience.

Experience

2 to 5 years experience in a data engineering or equivalent position.

Domains

We are looking for creative people with strong logical, technical and analytical skills capable of identifying and implementing data-driven solutions. The role would suit someone with a computer science background with knowledge of data extraction pipelines, data platforms and data science techniques. We are looking for an individual to contribute to the data engineering approach required for the project and support the exploration.

Working in an Agile tribe environment, the candidate is also expected to take the ownership of discussions with stakeholders across the tribe.

Projects involve working with a broad spectrum of people including product managers, data scientists, business analysts, IT development teams and internal customers.

What to Expect
You will be working on the data pipeline solution: acquisition, extraction, transformation, loading and visualisation of data
Utilising your strong data engineering skills to develop data extraction and processing pipelines, both in batch and streaming
Utilising your strong data and software engineering skills to productise models and pipelines, possibly using micro-services
Supporting data projects and statistical analyses by ensuring that relevant data sources are leveraged and supporting prototyping of candidate solutions
Actively learning new data engineering tools and environments

Key Responsibilities
Design, develop, test, install and support data pipelines in line with agreed requirements.
Produce and maintain conceptual models, prototypes and supports their implementation
Assist with the analysis of requirements and the development of recommendations as to the systems approach to follow.
Prepare specifications, codes, tests, deliverables, acceptance criteria, time frames, etc. . . and prepare and study the technical feasibility and estimates of the proposed systems solutions.
Analyze the problems, develop and propose solutions to more senior team members.
Provide technical assistance to other SWIFT colleagues and provide guidance to more junior team members in their daily work.
Develop and maintain technical documentation and prepare and give presentations to customers on systems.
Provide timing/scheduling estimates to project lead and propose corrective actions to timelines when necessary.",3.4,"SWIFT
3.4","London, England",-1,1001 to 5000 Employees,1973,Company - Private,Enterprise Software & Network Solutions,Information Technology,$500 million to $1 billion (USD),-1
SQL Data Engineer,-1,"SQL Data Engineer

Purpose and Background

Are you a capable sql data engineer who is passionate about the power of data to solve environmental issues? Our client is looking for an sql data engineer to shape delivery by collaborating with data architects and modellers to contribute to the acquisition of corporate data requirements, documenting them according to the required standards utilising the prescribed methods and Azure data tools, in order to build our centralised data platform.

This is a permanent role, with responsibility for developing, constructing, testing and maintaining architectures such as data pipelines and large-scale data processing warehouses. They will leverage industry best practice while delivering changes, such as agile backlogs, code repositories, automated builds, testing and releases. They will be responsible for ensuring data scientists can pull relevant data sets for their analyses, and implement data pipelines to connect operational systems, data for analytics and BI systems. They will re-engineer manual data flows to enable automation, scaling and repeatable use and develop data set processes for data modelling, mining and production.

The post holder will work closely with data architects (to determine what data management systems are appropriate) and data scientists (to determine which data are needed for analysis). They will provide clean, usable data to the business through the data platform in accordance with governance, and analyse, design, plan, execute and evaluate data requirements to support business activities and projects. The post holder will be central in ensuring the delivery of world-class digital products and changing the delivery culture in the company.

The Data Engineering Team’s primary remit is to improve the usability of the climate change, water, forests and cities data disclosed through robust and transparent methods. The team will create sustainable data pipelines for data quality monitoring, data cleaning, reporting and data science modelling. Harmonised data collected from external sources will enrich the data assets’ value and enhance accessibility for stakeholders. The team will produce value-adding insight delivering it through data products that help internal and external stakeholders to better understand the quantitative and qualitative results of their actions. This in turn helps stakeholders to make data-led decisions and optimise for all constraints. Through every stage the data assets are governed by the industry practice standards in a robust and transparent manner.

Key responsibilities include:

Managing the investigation of corporate data requirements, documenting them according to the required standards utilising the prescribed methods and tools
Implementing data flows to connect operational systems, data for analytics and BI systems. Re-engineer manual data flows to enable scaling and repeatable use
Working closely with data architects (to determine what data management systems are appropriate) and data scientists (to determine what data is needed for analysis).
Tackling problems associated with database integration and unstructured data sets
Ensuring that those using the data structures and associated components have a good understanding and that any queries are dealt with promptly and efficiently
In liaison with the information management or IT management functions, contributing to the development and maintenance of corporate data standards.
Ability to create efficient DW or DL structures to minimise cost of orchestration / processing and ingestion of data

Required skills and experience:

Strong technical process understanding regardless of technology
Wide range of strong technical skills (i.e. Azure Devops, Azure Data Factory, Data Bricks, SQL, python)
Core SQL Competencies – SSMS, SSIS, T-SQL, Stored Procedures
ADF Pipelines to build and populate SQL databases
Background in migrating traditional MS products to Azure
Very high attention to detail
Strong communication skills
Efficient in building ETL and ELT processes for enterprise solutions
Strong software delivery methods and knowledge
Strong performance-tuning skills

Desired skills and experience

Digital delivery – has a track record of working on DevOps delivery
Exposure in Climate Change data legislation, practices and stakeholders
Experience in Environmental related industries ie Water, Energy, Forestry related
Presentation skills
Understanding of architecting solutions taking into account wider considerations
Structured problem-solving techniques

This is a permanent full-time role, reporting to the Head of Data Engineering, which will be delivered remotely to start with. The post holder will be required to travel to the London office from time to time when it reopens.

Salary and benefits: Between £45,000 - £48,500 per annum dependent on experience, 30 days holiday excluding bank holidays, flexible working opportunities and others benefits.

Interested applicants must be eligible to work legally in the United Kingdom.",-1,Incite Insight,"London, England",-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Join one of Bristol's leading technology firms.
Renowned engineering culture.
Great package, remote working, flexi-time.

This client is building a new team as they continue to progress their technological capabilities. They are a data-driven organisation, it guides their strategic decision-making and service/product development. As a result, they need a Data Engineer to support the integration of various systems.

What you'll be doing

As the Data Engineer, you will support the integration of client source systems using streaming technologies.

This role requires a range of data engineering activities including; prototyping, ETL pipelines, real-time streaming and more.

What experience you'll need to apply

Minimum of 1 years' experience in data or software engineering
Solid ETL pipelining experience
Scala/Java/Python development experience
Experience with Airflow/Dataflow/Kinesis/Kafka etc.

What you'll get in return for your experience

A base salary of up to £55,000 with excellent bonuses and benefits package including remote working. The expectation is 1 -day p/week in the office post-covid measures.

What's next?

Please get in touch with Scott with an up to date CV today. Don't hesitate to email/call to discuss the job in further detail.",4.9,"ADLIB
4.9","Bristol, England",-1,1 to 50 Employees,2000,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Data Engineer,-1,"Position: Data Engineer, Remote & 1 day onsite in Crewe

Location: Crewe / Manchester / Remote - Based onsite at our Head Office in Crewe CW1 6BD one day a week.

Radius Payment Solutions are a leading Global Fleet Management Company who offer services in the Fuel, Telematics, Telecoms and Insurance industries. Our wide range of products include Fuel Cards, Vehicle Tracking Devices and Phone Tariffs. We are a successful growing global company with offices across 15 countries.

We are looking for a driven Data Engineer to join IT Innovation Team.

Why choose Radius?

· 24th in UK Top Track 100 company;

· Rapidly expanding global company with an entrepreneurial mindset;

· Internal talent development programme;

· Secondment opportunities to work in our international offices;

· Innovative, technology driven culture.

What will you be doing as job title?

At Radius, we deal with a number of very large data sets, the largest of which is our detailed telemetry for the vehicles we track.

These vehicles cover hundreds of millions of miles per month and we record every significant piece of driver behaviour data we can capture during those journeys, as well as recording the location, speed and heading of the vehicle at regular intervals.

This data set has created the need for new tools, practices and processes. We are making use of data science, machine learning and interactive visualisations to gather insights from this data, in order to build better products and innovate for our customers. We also use these same technologies to develop our product strategy internally. We recently presented our work on using unsupervised machine learning to process our fuel station data and to visualise our market share.

Key to our success in applying these technologies to our rapidly growing, innovative organisation, are the people we employ.

What experience / skills are we looking for?

Technologies we use for our work with data include:

Cassandra

Apache Spark

ML

ActiveMQ

Python

Pandas

AWS S3, Redshift, Lambda

Tableau

What benefits do we offer?

· Newly built Global Headquarters/ Newly refurbished sales office with onsite gym, break out rooms and canteen. Other facilities include PlayStation 4, table tennis and pool table;

· Excellent training and coaching;

· Friendly & supportive team working environment that encourages opportunities for self-development;

· Fantastic opportunities for ongoing development and progression;

· Life assurance and pension;

· Local and online discounts including discounted restaurants, travel, entertainment tickets with BenefitHub;

· Employee Fuel Card (after one year);

· Employee Assistance Programme;

· Cycle to work scheme;

· Service Awards;

If you like working on challenging problems in interesting domains, with a focus on innovation, then I'd like to speak to you - call Melanie Bose on +441270 507376

Radius Payment Solutions has an in-house recruitment team who are dedicated to sourcing candidates directly and as such we do not accept speculative CV's from agencies. We do have a preferred list of suppliers who we ask to support us on roles where necessary. We do not pay agency fees where speculative and unsolicited CV's are submitted to the business, whether that is to hiring managers or to the Recruitment Team. The only way we accept CV's is through our recruitment portal under instruction from the Radius Payment Solutions Recruitment Team.

Remote Working Data Engineer Big Data Spark Data Scientist Data Engineering",3.0,"Radius Payment Solutions
3.0","Crewe, England",-1,1001 to 5000 Employees,1990,Company - Private,Financial Transaction Processing,Finance,$2 to $5 billion (USD),-1
Data Engineer,-1,"Company Description

Yoyo is on a mission to modernise the in-store buying experience for the masses. The scale of opportunity ahead of us is immense, with new market entry and international expansion firmly in our sights.

Job Description

We are looking for an experienced Data Engineer to join our Product Data Team and assist us in creating reliable, re-usable and leading-edge reporting and analytics solutions. You will be responsible for aggregating Data from dispersed sources and collating information to develop world class reporting and analytics dashboards. You will also be responsible for developing functional applications to debug, monitor and troubleshoot BI tools. You will form part of a team of Data experts who are motivated, energetic and strive to deliver remarkable reporting and analytics solutions to Yoyo clients.

Minimum Requirements

Experience
2 years + of building commercial Business Intelligence solutions
Experience with Python
Data Warehouse design. Ideally with experience on AWS Redshift
Data lake and the development thereof
Database Management Systems and OLAP technologies
Amazon Web Services
Relational Databases, preferably PostgreSQL
ELT, ETL and the development thereof
CDC (Change Data Capture) functions and procedures in the context of RDMS (Relational Database Management Systems), ORDBMS (Object-Relational Database Management Systems) and NoSQL Data sets
Proficient in Object-Oriented Programming Language: Java
Advantageous
Proficient in MongoDB; MySQL
Bonus: Experienced with RESTful API's and the development thereof (GraphQL advantageous)
Experienced with Tableau, Sisense or QuickSight
Experienced with Scripting Programming Language: JavaScript or Python
Apache Airflow
NoSQL
Qualifications

University Degree in Computer Science, Information Systems, or Information Technology.

Additional Information

Company Values
Be passionate: Spiral up, be positive, bring momentum, and energy to those around you
Be an owner: Be accountable and take responsibility. Find solutions, learn from your mistakes and own tasks to completion
Be world class at speed: Delivering world leading solutions at speed
Be curious and creative: Constantly innovating, exploring, learning, stretching yourself, pushing the boundaries and thinking out of the box
Be a team player: Leave ego at the door, be teachable, engaged, inclusive, and transparent. Bring the best of yourself and the best out of others, rallying behind a larger team mission",3.3,"Yoyo Wallet
3.3","London, England",-1,51 to 200 Employees,2013,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Data Engineer

https://www.templeton-recruitment.com/job-search/3160-data-engineer/big-data-analytics/uk/job2019-05-21 21:50:522022-02-19
Templeton Recruitment
Job Type Contract
Location
London
Area

UK

UK

UK

London

Sector Big Data & Analytics
Salary Market related
Start Date ASAP
Job Ref KW-29789

Description

Templeton are seeking a Data Engineer for our global client to work on an exciting, cutting edge digital/analytics project based out of their London office.

You will have the opportunity to use modern technologies and to work with a cutting-edge data science platform using Pachyderm on top of Kubernetes.

The need strong technical expertise in Data Engineering, but beyond that this is an opportunity to help a global enterprise setup a best-practice data science process, to help them determine the direction of future tooling, and to be a central part of a team that will spearhead how the company engages in Data Science.

Essential
Strong experience with Python and relevant libraries (PySpark, Pandas, etc).
The ability to work across structured, semi-structured, and unstructured data, extracting information and identifying irregularities and linkages across disparate data sets.
Meaningful experience in Distributed Processing (Spark, Hadoop, EMR, etc).
Deep understanding of Information Security principles to ensure compliant handling and management of client data.
Experience working collaboratively in a close-knit team and in clearly communicating complex solutions.
Experience in traditional data warehousing / ETL tools (SAP HANA, Informatica, Talend, Pentaho, DataStage, etc)
Experience and interest in cloud infrastructure (Azure, AWS, Google Platform, Databricks, etc) and containerisation (Kubernetes, Docker, etc).
At least 5 years of relevant experience.

Desirable
Experience programming with Julia.
Experience or interest in building robust and practical data pipelines on top of cloud infrastructure (Pachyderm, Kubeflow, etc).

To include as part of your application
Links to online profiles you use such as Github, Twitter etc.
A description of your work history (whether as a resume, or LinkedIn profile).",3.5,"Templeton & Partners
3.5","London, England",-1,51 to 200 Employees,1996,Company - Public,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Data Engineer,-1,"DATA ENGINEER – BIRMINGHAM

Role Overview

We are currently recruiting for an Data Engineer to join our Information Technology team in Birmingham. The Data Engineer will be involved in helping to define, build, and maintain a robust data platform and information architecture. You will be joining a team in the early stages of a large digital transformation focused on bringing improvements in data management practices to the firm.

Candidate Overview

We are looking for an organised, highly motivated and enthusiastic individual who has the ability to work under pressure and adapt to new technology. Experience in using architecture frameworks such as TOGAF and data management frameworks such as DAMA.

What can we offer you?
Join a global, innovative and forward thinking firm;
Access to training and development to refresh or enhance your current skillset;
The opportunity to work agile;
Competitive salary and benefits package, including 25 days holiday, private healthcare and contributory pension.
Firm Introduction
Pinsent Masons is an international law firm that ranks amongst the top 75 law firms globally, with a long-standing reputation for delivering high-quality legal advice rooted in its deep understanding of the sectors and geographies in which its clients operate.

We know that our culture sets us apart, and with over 1,500 lawyers operating from 24 locations throughout the UK, Europe, Asia Pacific, Africa and the Middle East, it is at the heart of our success as a leading international law firm. Our core values are Approachable, Bold and Connected and as a firm we hold these in high regard. Personally and collectively, we live them every day and our firm is a better place for it.

Pinsent Masons stands out in particular for its innovative approach to service delivery and in 2016 we were ranked among the five most Innovative Law Firms in Europe.

For any queries or for a copy of the full job description then please contact our in-house recruiter Glenn Wilshaw. Please note we only accept CVs that are logged on the Recruitment portal.

#LI-LINKEDIN",3.9,"Pinsent Masons
3.9","Birmingham, England",-1,1001 to 5000 Employees,-1,Company - Private,Legal,Accounting & Legal,$100 to $500 million (USD),-1
Data Engineer,-1,"Futureheads are partnered with one of the fastest growing Fintech’s in Europe and supporting the growth of their data engineering function. Having helped scale their business over the past five years, they are now experiencing another surge in growth so need to bolster their team with capable data engineers at a range of levels.

We are looking to bring in data engineers who can design and build robust data pipelines and solutions that support key business processes. These challenges can be very complex so require individuals with a creative approach to finding solutions and an attention to detail that allows for precision in a market space where there is little room for error.

The organisation and team pride themselves on having a great culture and have a blend of freelance and permanent staff currently in place. We are looking for individuals who are keen to contribute on projects and work in a progressive environment, hopefully picking up new skills in the process.

To be considered for this position you will need to be able to display the following:

Knowledge of BigQuery
MSSQL, SSIS and SSAS
Programming experience with one or more of the following: Go, Scala, Python, Java
Cloud services and infrastructure, preferably GCP
Best practice in CI/CD and Git in a data environment
Agile
Strong communication and attention to detail

These are mission critical hires for the business, so please apply now to be considered.",4.4,"Futureheads Recruitment
4.4","London, England",-1,1 to 50 Employees,-1,Company - Private,Staffing & Outsourcing,Business Services,$5 to $10 million (USD),-1
Backend Software Engineer,-1,"We are looking for a Backend Software Engineer to join our Engineering team in London.

The world is changing.
We all want something different.
At Luno, we see you as individuals.

Together, we are upgrading the world of work to unleash the potential within and empower you to become the best possible version of yourself.

Upgrading the entire planet to a new financial system is a challenge of epic proportions. Like the first moon landing, it requires a special kind of people working together with unusual skill, focus and determination. We're changing the financial landscape, and to do so, well we need the best team on board for our mission. In short, to achieve our goals, we need rockstars. As simple as that.

A little about us:
We make it safe and easy to buy, store and learn about cryptocurrencies like Bitcoin and Ethereum.
We currently have over 5 million customers across 40 countries.
We're part of the Digital Currency Group, a group of companies driving progress in the cryptocurrency and blockchain space that includes Grayscale, Genesis, Coindesk and Foundry Services.
Our platform has processed over $14 billion to date.
We're proud to be one of the world's most international cryptocurrency teams from 43 different nationalities — working across South Africa, Indonesia, the United Kingdom, Malaysia, Nigeria and Singapore.

How we work


Our engineering team (currently ~100 engineers) is split into organisations which we call Fleets. Each Fleet focuses on a core customer journey (onboarding, security, payments, support, new business, growth and marketing etc.). Each of these fleets contains multiple smaller teams called Pods, each of which focuses on a specific aspect of the product.

Pods will include a product owner, product designer, back-end engineers, Android, iOS and Web developers, who each bring a unique perspective to the problem you are all contributing towards.

We're agile, use scrum, continuous integration and continuous delivery, deploying to production every single day.

We're building teams to help us succeed in our mission to upgrade the world to a better financial system. You'll be joining a group of highly motivated software engineers who you'll work collaboratively with across our pods.

As a fast-growing company with offices around the world, you'll immediately see how your contributions directly impact both our internal users and client experience. Many of the problems we are solving result in trail blazing solutions which can't be found on Stack Overflow; so we're looking for engineers who flourish working in a complex domain.

In your first six months, you will:


...start at Luno by learning our processes, meeting the wider team and starting our engineering on-boarding program. After getting comfortable with the basics, you'll start learning our idiomatic patterns in a safe, easy-to-follow way - by building your own toy micro services. You'll get to practice how we do design docs, code reviews, deployments, events, logging and monitoring.

You'll meet the Pod(s) you'll be working with and quickly align on the teams' current OKRs and product roadmap. We succeed as a team, so we will provide you with regular feedback from your manager and peers and will encourage you to do the same.

Your mission will involve:
Build distributed microservices that are accessed by 2.5m customers from across the globe.
Design, build and maintain advanced applications services.
Collaborate with cross-functional teams to define, design, and ship new features.
Write testable, maintainable code for robustness and reliability.
Work on bug fixing and improving application performance.
Write code that directly affects users, the company and the Bitcoin ecosystem.
The ideal candidate for this role will have:
A passion for blockchain and cryptocurrencies (this is a new industry so we'll help you learn about how the blockchain works and the technicals).
A proven background in computer science in areas such as algorithms, data structures, and software design.
Extensive programming experience in at least one language such as Go, Java, C++, C#, Python, etc.
A continuous improvement mindset.
BSc/MSc/PhD in computer science or other technical discipline, or equivalent working experience
A passion for software development, mobile technology and Bitcoin
To be friendly, transparent, articulate and driven to succeed
A work permit for the UK if you are not a British citizen
Don't be put off if you don't tick all of the boxes – they're a guide based on what we'd love to see but we appreciate that excellent software engineers have diverse backgrounds.

Remote Life at Luno


If you're looking to work on something truly global and disruptive with a forward-thinking and ambitious team that highly values diversity, teamwork, and the continuous quest for excellence, then this is an opportunity for you.

Like the majority of the companies, Luno is currently working remotely to keep our employees safe, which means you will not be physically, but virtually onboarded for now!
Live long and prosper. We've got you covered with excellent private medical insurance.
Generous maternity / paternity and even (yes, you are reading it correctly) paw-ternity for your furry friend..
Annual Inspiration Day.. like that pottery course you've always been meaning to do!
Work with a diverse team of hardworking, ambitious and friendly people on something that will truly revolutionise the financial world.
We are a social bunch of people, we have virtual quarterly activities and drinks Fridays for whoever wants to join!
We have virtual cooking, dancing, drawing and house planting classes hosted by our Lunauts Monthly to break up your day and work that other part of your brain.
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. You'll need to hold the legal right to work in the United Kingdom already as we cannot provide visa sponsorship.

Be part of the change!",4.6,"Luno
4.6","London, England",-1,201 to 500 Employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Job Title:

Data Engineer

Job Type:

Permanent

Location:

London or Nuneaton

Hours:

37.5

Salary:

Competitive market rate

The Role
We are building a modern cloud-based data infrastructure in AWS. We assembled a team of experienced engineers and we started ingesting data from legacy systems to develop a central repository and trusted logical data entites to support all our reporting, analytics and machine learning needs. The next step in our evolution is the demise of legacy systems and developing in-house stream-based systems. These streams need to be processed and collected for near-real-time reporting, analytics and decision-making. You will join the Data Engineering team working on topics ranging from ingesting and demising legacy databases, adopting event-based processing, and ML automation. You will work alongside experienced engineers in this effort.

The Person
You take pride in your work and building long-lasting reliable systems. You enjoy exploring new technologies, working independently at times as well as in cross-functional teams with Data Scientists and BI Developers.

Skills and experiences:
Scala
Spark or Flink
Kafka (beneficial)
Cloud stack, ideally AWS
Software Engineering practices and tools
Essential distributed computing and architecture principles
Undergraduate degree in CS, IT, or related fields
Professional experience in a comparable role
#LI-NP1

The Company
Holland & Barrett is one of the nation's most loved and trusted brands, known for offering quality health food, vitamins and supplements all sold by highly trained and qualified advisors.

Bucking the current trend of high street retailers, we forecast significant growth and expansion plans in the coming years, with considerable investment going into all areas of the business. We certainly embrace change and drive speed in everything we do. Every day presents a different challenge, but every day is also filled with fun, teamwork and passion to succeed and surpass every expectation.

Join us and see how far you can go…",3.0,"Holland & Barrett Retail
3.0","London, England",-1,5001 to 10000 Employees,-1,Subsidiary or Business Segment,Drug & Health Stores,Retail,Unknown / Non-Applicable,-1
Data Engineer (Remote),-1,"Cloudbeds is a travel SaaS technology company that works to make the world a more welcoming place. Heavily leveraging Amazon Web Services (AWS), we build advanced cloud-based hospitality software for hotels, hostels, vacation rentals, and groups that manages reservations and guests, distributes room availability, sells inventory, and collects payments. Our hundreds of team members are globally distributed across over 40 countries and, altogether, we speak 20+ languages. How do we do it? On a #remotefirst platform that allows every member of our team to work from wherever they are around the globe. Were looking for people who want to disrupt the travel industry and love to travel as much as we do.

As a Data Engineer at Cloudbeds, you will implement our company-wide data strategy across all teams and departments to deliver a best in class data experience to our customers and partners in over 150 countries, as well as internally within Cloudbeds. You will work closely with our Business Intelligence, Reporting, and Infrastructure teams to progress and optimize our data lake architecture and drive the data transformation lifecycle to process terabytes of platform and industry data from multiple databases and origins in an automated and serverless fashion. The right candidate will be very experienced using Amazon Web Services (AWS) tools enabling data lake, warehousing, and processing capabilities. As a Data Engineer at Cloudbeds, you will have endless opportunities to innovate and drive the industry leading, comprehensive, and global data experience for travel.

Location: Europe (Remote)

What You Will Do:
Code ETL data transformations in PySpark/Spark.
Design and manage processing pipelines via AWS Glue and/or EMR clusters.
Manage ingestion and replication via DBMS from cloud MySQL databases.
Process external sources like Salesforce via Appflow or kaggle datasets.
Manage AWS Athena views and endpoints for consumption.
Creation, modification, and maintenance of data infrastructure (Redshift [with Spectrum], S3 Parquet data, DBMS, Notebooks, etc.)
Implement logging and debugging approaches in a standardized fashion.
Collaborate with Business Intelligence, Analytics, and Infrastructure teams on a daily basis.
Develop a framework for future extensions through standardized modern workflows.
Youll Succeed With:
Bachelors degree in computer science or related field, or equivalent experience.
3+ years experience as a Data Engineer.
2+ years experience working with Amazon Web Services.
Expert knowledge and experience developing efficient ETL data pipelines having multiple sources using PySpark/Spark and DataFrames.
Strong knowledge and experience developing workflows with AWS Glue, EMR, Redshift, Athena, and LakeFormation.
Strong knowledge of modern data lake, data warehousing, and ETL/ELT concepts.
Strong knowledge of how to compose and implement structural data models.
Experience molding fresh environments into efficient mature data platforms.
Experience with performance optimization for processing and storage via data partitioning and indexing techniques.
Ability to take a consultative approach to data strategy.
Ability to work in an Agile Scrum environment.
Ability to thrive in a fast-paced environment.
Ability to work remotely and manage your own time in an international team.
Exceptional written and verbal communication in English.
Our company culture supports flexible working schedules with an open PTO policy and the opportunity to travel and work remotely with great people. To make it easy for our team to travel we offer 2 corporate apartment accommodations near our San Diego and Sao Paulo offices. At Cloudbeds we dedicated to your personal and professional development. You will have access to over 10,000 courses within LinkedIn Learning when you join our team for your unique individual growth! If you think you have the skills and passion, well give you the support and opportunity to thrive in your career. If you would like to be considered for the role, we would love to hear from you!

Company Awards to Check Out!
Best Startup Employers in 2020 | Forbes
Best Places to Work | HotelTechReport (2018, 2019, 2020)
Deloittes North America Technology Fast 500 (2019)
Inc. 500 Fastest Growing Companies (2018 & 2019)
Inc. Best Places to Work (2017 & 2018)
Best Places to Work | Inc Magazine (2017 & 2018)
Start-Ups to Watch in 2018 | Forbes
Connect MIP Award (Technology)
Powered by JazzHR",4.6,"Cloudbeds
4.6","London, England",-1,201 to 500 Employees,2012,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Data Engineer

A Data Engineer is required on a contract basis to work for a global bank based in London.

The ideal candidate will have previously worked with Big Data eco systems and have hands on experience with Hortonworks/Cloudera platforms. You will have expertise and understanding of development using querying tools on top of Hive, Spark (PySpark). The Data engineer will have a strong programming background and be an expert with python. The candidate will have previously experience in the financial services sector and ideally have banking business knowledge.

The client will pay up to £610 (PAYE) a day dependent on experience. This is a great opportunity to join a leading client and further enhance existing skills.

Essential skills and qualifications:

Previously have worked with Big Data Eco Systems.

Proven experience with programming languages such as; Python, Scala, Hive and Spark

Have worked in a financial services environment and have banking business knowledge.

If this role could be of interest to you, please apply with an up to date version of your CV.

Eames Consulting is acting as an Employment Business in relation to this vacancy.",4.0,"Eames Consulting
4.0","London, England",-1,51 to 200 Employees,2002,Company - Private,Staffing & Outsourcing,Business Services,$50 to $100 million (USD),-1
System Engineer Fighter Radar with focus on Test and Integration (f/m/d) - Relocation to Germany,-1,"HENSOLDT is a leading global provider of premium sensors for security and surveillance missions. The company is world market leader among others missile warning systems and submarine periscopes. In addition, HENSOLDT is strongly represented in the markets for radars, optronics and electronic protection systems.

With our company, we represent over 100 years of German technology tradition by continuing the work of renowned predecessor companies such as Airbus, Telefunken, Dornier, Siemens Sicherheitstechnik or Carl Zeiss Optronics. HENSOLDT currently has around 4,000 employees and annual sales of around € 1 billion.

We are passionate pioneers to develop competitive and excellent electronics products. Our core competence is to recognize dangers and to protect our customers from them. We make a valuable contribution to the protection of people and nations.

For the department ""Fighter Radar Engineering"" we are looking for a

System Engineer Fighter Radar with focus on Test and Integration (f/m/d)

at the location Ulm. The department is responsible for the system technical support of existing on-board radar systems for flying platforms such as Eurofighter Typhoon, Panavia Tornado, NFH Sea Lion or Airbus A400M. In addition, the department carries out systems engineering for the planning and design of future on-board radar systems, provides technical support for the acquisition of new development projects and manages the technical implementation of these projects. The tasks of the systems department are characterized by interdisciplinary approaches, close contact with national and international customers and users as well as scientific research institutions and cooperation partners.
Your Tasks
The complex test and integration requirements for the ECRS Mk1 radar are significantly supported by corresponding radar environment and target simulators. These simulators generate their data in real time and thus allow realistic integration and behavior analysis.
This includes:
Support the recording of customer requirements and their implementation in system requirements
Cooperation in the creation of system concepts and derivation of the corresponding system designs
Simulation and estimation of system performance parameters
Creation of system documentation and definition of subsystem components
Planning and implementation of development and sub-projects or study projects
Working closely with national and international partners and customers
Support of subsystem and system integration through analysis
Support of testing programs at platform level
Support for acquisition tasks
Your Profile
Degree in electrical engineering, physics, mathematics or comparable
Experience in requirements engineering and systems engineering
Knowledge in radar system design, signal processing and algorithms
Experience with the technical simulation tool Matlab
Experience in leading software teams
Experience in the creation of test equipment
Sure handling of MS-Office software products
Willingness to work interdisciplinarily
Joy of intercultural challenges
Independent, goal-oriented and structured way of working
Distinctive team spirit and customer orientation
High commitment and motivation
Business-fluent in German and good English skills
What we offer you
Central location in the city area with free parking garage and own company restaurant, café bar and snack shop
Fitness studio incl. Physiotherapy and other health offers
Childcare and holiday care close to the location
Working in an innovative environment with exceptional high-tech products at the limits of physics
Attractive remuneration (metal and electrical industry tariff)
Company pensions and much more
Flexible working time models (mobile working, flextime and part-time models, sabbatical etc.)
Individual development and training opportunities
You feel enthusiastic about technology and you are ready to take responsibility within fascinating projects in a cooperative working atmosphere? You want to be a pioneer and grow with us? Then you are our perfect candidate to join our team!

Please apply online for this vacancy at our careers site with your detailed application (with CV and references attached).

Be the pioneer of our future!
We look forward to receiving your application!

Apply now
https://hensoldt.wd3.myworkdayjobs.com/External_Career_Site/job/Ulm/Systemingenieur-Fighter-Radar-mit-dem-Schwerpunkt-Test-und-Integration--w-m-d-_JR-5443-1/apply

In case you have any further questions, please do not hesitate to contact our Talent Resourcing Team:

Frau Iris Nussbaumer and Josephine Dehn

E-Mail: jobs@hensoldt.net

You can find more jobs on our website at www.hensoldt.net/career.

HENSOLDT is committed to achieving workforce diversity and creating an inclusive working environment. We welcome all applications irrespective of social and cultural background, age, gender, disability, sexual orientation or religious belief.",4.4,"Hensoldt
4.4",United Kingdom,-1,1001 to 5000 Employees,2017,Company - Private,Aerospace & Defense,Aerospace & Defense,$1 to $2 billion (USD),-1
Data Engineer,-1,"Data Engineer

This is a fantastic opportunity to come and work for a leading UK retailer. Our client's business is fast-paced, innovative and fun, they truly believe it's their people that make the difference and have been voted one the Best Places to Work in Europe!

Data Engineer responsibilities

Develop, maintain and improve our cloud data platform and help plan, design, monitor, communicate and execute data projects
Assist the analytics teams in the implementation of their machine learning use-cases
Evangelize about our data platform, products and Data Engineering capabilities with other departments in order to bring more relevant data into our eco-system and develop future data-products that solve real business problems.
Coach others within the team

Data Engineer requirements

Cloud experience (ideally GCP)
Python
Data Warehouse; BigQuery, Spanner, Snowflake, Redshift etc
Ingesting and processing streaming data - RabbitMQ, Kafka, PubSub etc
Strong understanding of the end-to-end deployment process of data products

Keywords: Data Engineer, GCP, Google Cloud Platform, AWS, Azure, Big Query, Spanner, Snowflake, Redshift, Python

Lawrence Harvey is acting as an employment agency in regards to this position.",4.4,"Lawrence Harvey
4.4","London, England",-1,51 to 200 Employees,2002,Subsidiary or Business Segment,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Remote Contract role - Data Engineer

This is a SC cleared project (Outside if IR35) which will require the data engineer to be a British Citizen or held permanent residence in the UK for the last 5 years as a minimum. You don't need to hold a current clearance the client will sponsor this.

The client require a Data Engineer to work alongside their lead data scientist on the discovery and buildout of a document processing system built around NLP utilising NER. Really exciting project that will be building a sytem to (eventually) handle millions of documents across a huge business area.

Strong Python skills are essential as this is very much a hands on coding role building out the back end of the system and allowing seamless integration with other systems. Elasticsearch would be useful as well as experience with AWS. Experience with spaCy would also be highly advantageous.

Key Skills:
Python
Elasticsearch
AWS
Desirable:
NLP / NER
Experience with document processing systems
spaCy
Location:
Fully Remote

Duration:
8 Weeks initial with likely extension

Hours:
3 Days per week which could increase to 4 - this is NOT a Full time role initially

Rate:
Circa £400 / Day - Appreciate this is not the highest rate in the world for these skills - the client do not necesarily need someone who has been doing it for 10 years plus rather someone who is excited about the opportunity and getting more exposure to data science generally and specifically NLP.

Start Date:
After SC vetting completed (4-6 weeks)

Quite a unique role in that is is fully remote and 3 days per week - this would suit a contractor who maybe has some other committments or personal projects that aren't full time and is happy to work on a part time basis.

If this role sounds of interest please submit your CV via the link and someone will be in touch with you to discuss further.",3.0,"Emtec Ltd
3.0","London, England",-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Depop is the fashion marketplace where the next generation buy, sell and get inspired. We are headquartered in London, UK with locations in New York and LA. We have more than 20 million registered users in 147 countries. In the UK, 1 in 3 Gen Z/Millennials are registered and in the US we have grown 300% over two years. We are also the only European player to have recently entered the top 25 shopping apps by daily active users.

Our mission is to empower the next generation to transform fashion, and our team of nearly 200 people are dedicated to serving the needs of our global community.

We operate on three pillars:

Community: Our buyers, sellers and employees are inclusive, diverse and accessible. We are committed to empowering diversity within the fashion community.
Entrepreneurship: We support our community and help them build their business with Depop. We thrive on supporting innovation by shaping an environment where creators, makers or hustlers can thrive.
Sustainability: Depop helps extend the life of garments and reduce waste, we care about the world and want to make a positive change within the fashion industry.

The Role

Data is at the heart of what we do.

Depop is looking for a Data Engineer to join our growing team! Our platform receives 10,000's of requests every second; we're looking to cut through the noise, leverage this vast data, and find value.

We're building scalable and robust systems to harvest, process and analyse the vast data within our tech ecosystem. With an increasing demand to service other areas of the business, and ultimately our 16 million users, you'll be at the forefront of pioneering Data-as-a-Service.

Want to find out more about Depop & our engineering team?

We write about technology, people and smart engineering right here -https://engineering.depop.com/

Responsibilities:

You'll be...

building out our data infrastructure, in terms of scalability and availability, with an additional focus on ensuring data integrity
working on projects centred around real-time streaming, data lake optimisation and a novel user-tracking and personalisation system
continuously developing Data and Software Engineering knowledge and best practices
interacting with internal members of the Depop team to solve business problems

Requirements:

You have…

software development experience using either Scala or Python, and understanding of SDLC best practices
a deep understanding of the importance of testing
experience working with distributed systems
knowledge around data processing and warehousing systems (batch or stream), through leveraging the latest data engineering technologies (e.g. Spark and Kafka)
a willingness to deliver user value quickly

Technologies and Tools:

Airflow
Kubernetes
Scala
Python
Terraform
Kafka
Spark

Benefits

Learn and Grow: We want to give our people the opportunity to learn. We sponsor and run a myriad of programs, conferences and meet-ups to upskill our employees and enhance their journey with us, just ask!
Wellbeing: We care about our employees wellbeing. We offer a cycle to work scheme, healthy fruit and snacks in the office, breakfast every Tuesday, eyecare vouchers and a discounted gym membership at Nuffield Health.
Mental Health: Our employees mental health is a top priority. We offer subsidised counseling appointments with a qualified therapist through SelfSpace, we have trained mental health first aiders and we also run yoga, meditation and more.
Work/life balance: We have 25 days of holiday with the opportunity to buy or sell 5 more, a day off for activism to allow you the opportunity to make a difference and we offer sabbaticals for our long serving employees
Family life: We offer flexible working (based on the team you will be joining), generous maternity/paternity and parental leave policies which includes adoption and paid time off for fertility treatments. Also, all of our offices are dog-friendly! Do your best work with your best friend.
Fun: We love to hang out with each other at Depop. On Friday we finish an hour early to socialise with free food, and have amazing Winter and Summer Parties to celebrate our successes. We also host internal employee socials such as quiz night, games night, movie night and more...we've taken this virtual for now!

Equality and Diversity Monitoring

Depop is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.

Depop recognises the benefits of a diverse workforce which reflects the wider population and welcomes applications from all sections of the community. Under the Equality Act (2010), Depop must demonstrate that their recruitment processes are fair and that we are not discriminating against or disadvantaging anyone because of their age, disability, gender reassignment status, marriage or civil partnership status, pregnancy or maternity, race, religion or belief, sex or sexual orientation. We need to ask applicants some questions to make sure that no one is being unfairly discriminated against or disadvantaged.

We collect this information only for anonymised monitoring purposes to help the organisation look at the profile of individuals who apply, are shortlisted for and appointed to each vacancy. In this way, we can check that we are complying with the Equality Act (2010).

Under the Equality Act 2010 the definition of disability is if you have a physical or mental impairment that has a 'substantial' and 'long-term' adverse effect on your ability to carry out normal day to day activities. Further information regarding the definition of disability can be found at: www.gov.uk/definition-of-disability-under-equality-act-2010

Reasonable adjustments will be made available should you be invited to interview.

GDPR Statement

When you apply to a job on this site, the personal data contained in your application will be collected by Depop Ltd, 08316342 (""Controller""), 9th Floor 107 Cheapside, London, United Kingdom, EC2V 6DN (""We"", ""Us"") and can be contacted by emailing people@depop.com.

Your personal data will be processed for the purposes of managing Controller's recruitment related activities, which include setting up and conducting interviews and tests for applicants, evaluating and assessing the results thereto, and as is otherwise needed in the recruitment and hiring processes. Such processing is legally permissible under Art. 6(1)(f) of Regulation (EU) 2016/679 (General Data Protection Regulation) as necessary for the purposes of the legitimate interests pursued by the Controller, which are the solicitation, evaluation, and selection of applicants for employment.

Your personal data will be shared with Greenhouse Software, Inc., a cloud services provider located in the United States of America and engaged by Controller to help manage its recruitment and hiring process on Controller's behalf. Accordingly, if you are located outside of the United States, your personal data will be transferred to the United States once you submit it through this site. Because the European Union Commission has determined that United States data privacy laws do not ensure an adequate level of protection for personal data collected from EU data subjects, the transfer will be subject to appropriate additional safeguards under [either the standard contractual clauses or the Privacy Shield]. You can obtain a copy of the standard contractual clauses by contacting us at people@depop.com.

Your personal data will be retained by Controller as long as Controller determines it is necessary to evaluate your application for employment. Under the GDPR, you have the right to request access to your personal data, to request that your personal data be rectified or erased, and to request that processing of your personal data be restricted. You also have to right to data portability. In addition, you may lodge a complaint with an EU supervisory authority.",-1,Careers at Depop,"London, England",-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"As a data engineer in the Data Systems Development team, you'll work closely with analysts in other teams by providing guidance and support as they develop new data pipelines. You will manage the scrum development process for these users, helping to unblock barriers and encouraging progress. You will also use your technical skills to personally deliver new system features that are robust, resilient and aligned to user-needs. As we are a small team there will be plenty of scope for you to work with senior engineers to help shape the overall system design.

This role is available in London or Bristol. If based in Bristol you will be expected to visit London two days a week under normal circumstances.

Pay Enhancement

If the successful candidate is an existing member of a government analytical profession (GORS, GES, GSR or GSG), they will qualify for a pay enhancement of £4245 rising to £6000 for those with a relevant masters. Non-members will be supported to apply for membership once in post if appropriate.

Responsibilities
We are looking for someone with skills and interest in data engineering who enjoys working with people with a range of technical experience. The points listed below are relevant for the role; you should ensure that you cover as many of these points as possible in your statement of suitability.

Essential data engineering experience:

• Good programming skills including at least one of Python or SQL

• Understanding of relational databases

• Extract, Transform and Load (ETL) processes

• Dissemination of data and analysis in a variety of formats

• Development using version control (preferably Git)

• Monitoring data quality and developing processes for automated and/or manual interventions to improve data quality

Other essential experience:

• Excellent people skills and enthusiasm for working with and helping others

• Ability to communicate technical concepts to a non-technical audience

• Ability and desire to work collaboratively as part of a team while also negotiating and accepting individual responsibilities

Desirable experience:

• Working in an agile development environment

• Highly numerate with an analytics/informatics background

• Working in a statistical environment

We take the development of our people very seriously, equipping and enabling them to make an impact by ensuring high quality evidence and analysis is at the heart of the policy-making process. We are committed to good management and the professional development of staff.

Technical Skills

You will be assessed on the following Technical Skills at Sift and/or Interview

1) Technical Skills Example (250 words)

Please give one or more examples of where you have worked with others to develop new data pipelines. Your answer should cover your personal roles and responsibilities and how you supported others to change their ways of working.

2) All candidates will be tested against the following Technical Criteria:
You can re-engineer manual data flows into reproducible pipelines to enable scaling, testing and for quality assurance.
You can respond to problems in databases, data processes, data products and services as they occur. You can determine the appropriate remedy and assist with implementation of it as well as preventative measures.
Members of the four main government analytical professions who are applying on promotion will additionally also need to demonstrate they meet the SEO level competencies for their profession. The outcome of this extra assessment will not influence who the job is offered to – it is purely to facilitate timely promotion of badging for internal applicants.
Behaviours

We'll assess you against these behaviours during the selection process:

Working Together
Managing a Quality Service
Technical skills

We'll assess you against these technical skills during the selection process:

Please give one or more examples of where you have worked with others to develop new data pipelines. Your answer should cover your personal roles and responsibilities and how you supported others to change their ways of working.
Technical Criteria including but not limited to; re-engineer manual data flows; and respond to problems in databases, data processes, data products and services as they occur.

We only ask for evidence of these technical skills on your application form:

Please give one or more examples of where you have worked with others to develop new data pipelines. Your answer should cover your personal roles and responsibilities and how you supported others to change their ways of working.
Benefits
BEIS offers a competitive mix of benefits including:

A culture of flexible working, such as job sharing, homeworking and compressed hours.
Automatic enrolment into the Civil Service Pension Scheme.
A minimum of 25 days of paid annual leave, increasing by 1 day per year up to a maximum of 30.
An extensive range of learning & professional development opportunities, which all staff are actively encouraged to pursue.
Access to a range of retail, travel and lifestyle employee discounts.",-1,"UK Government - Department for Business, Energy & Industrial Strategy","London, England",-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We are looking for an experienced Data Engineer to join our team. This is the first hire in this newly formed Data Engineering team and you will have the opportunity to help shape this function working with the management team. We are looking for someone to build scalable, reliable and secure cloud data warehouse solutions and data integration and processing pipelines and you will need to have experience with a range of technologies to do this.

Data Analytics forms a key part of our strategy this year. Ideally you will be familiar with AWS and you will use various methods and services available to transform raw data into a single customer view. Overall, you’ll strive for efficiency by aligning data systems with business goals.

We are at the early stages of our journey and, as a Data Engineer, you will have a lot of opportunity to influence the technical and strategic direction of the team. You will also have the opportunity to take ownership of parts of the existing platform and new greenfield development. This is a position that would suit someone who has got some experience industry and exposure to a number of technologies in the field but is now looking to kick their career into the next phase.

To succeed in this Data Engineering position, you should have strong analytical skills and the ability to combine data from different sources. If you are detail-oriented, with excellent organizational skills and experience in this field, we’d like to hear from you.

Responsibilities
Develop, maintain and improve our cloud data platform and help plan, design, monitor, communicate and execute data projects
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using a range of technologies and environments (SQL, ETL tools, Kafka, Spark, Scala, AWS)
Prepare data for prescriptive and predictive modeling
Build algorithms and prototypes
Explore ways to enhance data quality and reliability
Identify opportunities for data acquisition
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Work with business and technical stakeholders to assist with data-related technical issues and support their data infrastructure needs
Ensure data is reliably stored and secured
Create data tools for analytics and data scientist team members that assist them in building and optimizing our data product
Look for opportunities to tactically build solutions that deliver real value, while balancing the opportunities to implement longer term strategic solutions
Strong liaisons with the internal Tech teams
Requirements
Demonstrable experience of working with and designing a cloud-based analytical platform including best practices around data ingestion (batch and streaming ETL/ELT) and turning data science/machine learning algorithms into production-grade products
Solid knowledge of data modelling and structures, and experience with data laking and warehousing tools and techniques (BigQuery, Spanner, Snowflake, Redshift etc.)
Strong software development skills (particularly in Python) – object oriented and/or functional design, coding, and testing patterns, the relevant DevOps principles, and the ability to document in a clean manner
Experienced software engineer and keen to pursue the challenges of extracting knowledge from data and driven to understand the insights that data can bring
Technical expertise with data models, data mining, and segmentation techniques
Solid knowledge of data modelling and structures, and experience with data laking and warehousing tools and techniques (BigQuery, Spanner, Snowflake, Redshift etc.)
Solid hands-on experience with SQL, ETL/ELT tooling, Kafka, Spark, Python, Scala, ELK
Great numerical and analytical skills
Great communication and relationship development skills
The passion, drive and commitment to succeed in a fast-moving, highly pressured environment
Pro-active, self-starter attitude
Works with minimal supervision
Exposure to retail and online/digital commerce use-cases is a plus
Data Engineering certification (e.g IBM Certified Data Engineer) is a plus
Benefits
City centre location
Brand new office fit out
Team lunch and drinks on Fridays
23 days annual leave, plus one for each year served (capped at 26)
Birthday leave
Flexible start hours 06:30 - 10:30am
Health and wellbeing support
Training and conference budget
Share options – take ownership of your role and our direction",-1,Airtime Rewards Limited,"Manchester, England",-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Our client are going through a huge growth stage at the moment, specifically within their Data team. They have plans in place to work on some of the most cutting edge and innovative projects and are paying extremely aggressively to hire top talent - especially candidates with strong Industry experience.

They're well under way with their Data Science journey, however are looking for a key player who can help shape the direction of this journey. They have a vast amount of data and are extremely keen to find insights and answer difficult commercial questions using this data.

If you are looking to have a huge impact, work with big data then it would be a great time to join the team, especially while they are small and agile enough to implement findings quickly into production.

Our client is looking for an exceptional Data Engineer in Manchester.

Role Purpose:

We are looking for a full stack data engineer to join a diverse and friendly team; building dataflows into a data lake and data warehouse from a wide range of sources.

You will help steer the development of efficient data structures that will enable sophisticated analysis and data science.

You will:

Collaborate with data analysts and data scientists on a regular basis to plan and translate requirements into solutions and ensure delivery of successful business outcomes.
Connect APIs, flat files, databases and data streams to our data lake (ELT).
Shape data from our data lake and form into a Kimball data warehouse (ETL).
Build containers for data model endpoints.
Ensure that appropriate data quality, integrity and alerting is built in to all solutions.
Be comfortable working with an on-premise Microsoft BI stack, including SSIS, SQL Server and Power BI.
Be comfortable working with an AWS-based BI stack, including Lambda, Redshift, Snowflake and Matillion.
Be comfortable learning and building simple data visualisations in Power BI.
Be comfortable working in an Agile Kanban workflow to safely code, review, test and deploy solutions, using source control to manage changes.
Assist with managing the DevOps processes for Data, and any tooling that guides the processes.
Ensure environments are stable and available.
Contribute to the architecture of the data warehouse and data lake

You:

Are comfortable with ETL tools like SQL, SSIS, AWS, Lambda and Python.
Are comfortable with data warehouse concepts, including Kimball methodology.
Have experience with SQL Server and Redshift management.
Have experience with visualisation development using tools like Cognos, SSRS, Power BI or Business Objects.
Are an enthusiastic problem solver, with a logical and curious mind.
Are a good communicator and able to develop engaging relationships with colleagues.
Have a positive, enthusiastic and methodical attitude to development, business intelligence and data science.

1",5.0,"Scope Personnel
5.0","Manchester, England",-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Data Engineer | Dunstable | Permanent

We have an exciting opportunity for a Data Engineer within our Support Centre in Dunstable. Can you take commercial data and turn it into actionable insights? Harness the full potential of bleeding-edge technologies, while enabling business stakeholders to understand complex data? If so, then we would love to hear from you!

Whitbread is the UK's leading hospitality company in the FTSE 100 including brands such as Premier Inn and Beefeater. By the end of 2020, our goal is to increase the number of Premier Inn UK rooms to an incredible 85,000. All while creating around 3,000 UK jobs a year and continuing to expand our presence worldwide. There has never been a more exciting time to Whitbread!

About the role:

Our data engineering team here at Whitbread are facing an exciting period of growth and there is a real opportunity to have a huge impact in delivering business-value to stakeholders.

You will deliver data projected across:

Premier Inn - Automated Trading Engine
Premier Inn and Restaurants - Customer Hub

We are proud of our tech stack, where you will have the opportunity to work with Azure Data Factory, Data Bricks, Data Synapse, CosmosDB, Python.

What you’ll be doing:

Delivers across the entire software delivery life cycle – concept, design, build, deploy, test, release into post implementation support.
Ensures work is of the highest quality and performs code/peer reviews within the team and across teams.
Specifies user/system interfaces and translates logical designs into physical designs taking account of target environment, performance requirements and existing systems.
Ensures all deliverables are well documented, re-usable, tested and conform to agreed architecture design patterns and coding standards.
Undertakes analytical activities required to support the development and maintenance of systems.
Provides support on key products should there be an incident / problem related to a product that’s now live and requires a development fix.
Supports the relevant project/backlog delivery events; planning / user story estimation, daily stand-ups, sprint reviews/ demos & retrospectives.
Supports / collaborates with the team and takes ownership of driving forward relevant stories (updating the ticket on the Kanban board & Jira).
Jointly responsible with the team for converting the Product backlog into ‘Done’ potentially releasable increments.

What you’ll need:

Azure Data Services (Data Factory, Databricks, Synapse Analytics)
Microsoft BI experience (SSAS, SSIS, SSRS, Power Platform)
Solid experience of T-SQL (stored procedures, functions)
Integration and ETL experience
Experience of Tableau or Power BI
Experience with relational and multi-dimensional databases and data modelling
Experience with NoSQL databases (Cosmos preferred)
Able to conduct requirements gathering and train business users",3.5,"Whitbread
3.5","Dunstable, England",-1,10000+ Employees,1742,Company - Public,Casual Restaurants,"Restaurants, Bars & Food Services",Unknown / Non-Applicable,-1
Senior Data & Analytics Engineer - 2 Year FTC,-1,"AstraZeneca is a global biopharmaceutical business that focuses on the discovery, development and commercialisation of prescription medicines for some of the world's most serious diseases. At AstraZeneca, we're proud to have a workplace culture that inspires innovation and collaboration. Here, you would express diverse perspectives, contribute to an energised environment and provide creative ideas - and be rewarded for this.

We are recruiting for engineers to be based at our Central Cambridge site. As an engineer you will support solution development, provide technical leadership, and take responsibility for delivery. You have a broad range of knowledge and experience across data & analytics. You will work almost exclusively on our AWS data platform. You will join a team that has delivered cloud solutions, such as the development of auto-scaling containerised ETL. Similarly, we have built an automated ETL test harness which integrates with our evolving CI/CD processes.

This role will be focused on working with our Global Business Services division. We have a significant backlog of work including: industrialising our data science output, building industrialised scalable data feeds, and data provisioning to support business insights.

You'll be part of a team of engineers who work closely with IT colleagues in Chennai. You would be the technical point of reference on projects. You would need a collaborative delivery approach to be successful. We prefer to use Agile but choose the appropriate approach for the project. So, experience of a variety of delivery management approaches will come in useful. You will provide technical leadership throughout our software development lifecycle, from the initial development of a technical design based on a blueprint, right through to hypercare. Do you have a real passion for delivering well engineered data and analytics solutions? Because this will make you stand out from other applicants.

Essential skills and experience
Experience of big data, ETL & cloud techniques and tools (we currently use Talend. Redshift (inc. Spectrum), Glue, EMR, HIVE, PIG, Spark, S3, SQS, SNS),
You will be able to demonstrate an ability to understand business needs and translate them into a solution,
You will be able to design and document development best practices,
You must have strong analytical and data manipulation ability,
You will need great interpersonal skills & a collaborative approach to delivery.
Desirable skills and experience
You have experience of technical leadership in data and analytics,
You are very likely to have experience of Agile practices, especially being a SCRUM Master,
You will have delivery experience across key elements of the data & analytics domain,
Experience of visualisation technologies (we are focused on OBIEE and Microstrategy).
We can also offer this position on a part time basis also.

AstraZeneca is an equal opportunity employer. AstraZeneca will consider all qualified applicants for employment without discrimination on grounds of disability, sex or sexual orientation, pregnancy or maternity leave status, race or national or ethnic origin, age, religion or belief, gender identity or re-assignment, marital or civil partnership status, protected veteran status (if applicable) or any other characteristic protected by law.",4.1,"AstraZeneca
4.1","Cambridge, East of England, England",-1,10000+ Employees,1913,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$10+ billion (USD),-1
Machine Learning Engineer,-1,"We are Zego, a global insurtech scale-up providing cover that creates possibilities. In an ever-changing world, insurance is struggling to keep up. Through the power of emerging technologies, we are creating fairer products designed for the 21st century.

In 2019, we closed our series B funding round, raising $42M from top-tier investors that will fuel our growth into new territories and the expansion of our product portfolio. We were also listed in the Fintech 50 and placed number 7 in the Startups 100. More recently, we were accepted into the Tech Nation Future 50 2020 cohort and medium-sized and a Tech Company of the Year 2020 finalist - solidifying our place as one of the UK’s most exciting and influential tech companies.

Overview of our Data Science Team:

The Data Science & Pricing Team is responsible for all the aspects related to data, including making data available, data cleaning, extraction, problem formulation and definition of success metrics, designing, implementing and testing models, and productionising new exciting tools and algorithms.

Purpose of the Role:

We are looking for a Machine Learning Engineer to join our team. You will multiply our capability by getting up to speed quickly, taking ownership of key projects and making a strong business impact. You will be given the support and backing you need to excel as a key member of our team.
You will play a central role in architecting, creating and improving Zego’s cutting edge Data Science / Machine Learning systems.
You will work closely with the Data Science and Engineering teams to design, develop, deploy and maintain industry guiding pricing models and technology.
You will dive into the heart of Zego and its data to build an intuitive knowledge of the business.
You will help forge Zego’s core data platform.
What you will be working on:
You will design systems that enable rigorous reproducible research practices at a fast pace.
You will advocate a data-driven approach as you partner with stakeholders of different seniority showcasing your inclination as an outstanding contributor and develop into other senior roles.
You will build relationships with the wider Engineering organisation, speaking the language of experts and engineers equally.
You will combine prior art, open source and innovative original solutions to create best in class technologies.

What you will need to be successful in the Role:
You have BSc in Mathematics, Statistics, Engineering, Computer Science or similarly quantitative disciplines.
You have knowledge in Data Science and Machine Learning, covering systems engineering, MLOps and model deployment.
You are an expert in Python and can write robust and scalable code.
You are comfortable using cloud infrastructure as code to build data pipelines and model deployment services.
You are strongly proficient with Docker and Kubernetes.
You are well-versed in modern machine learning tools and libraries such as Scikit-learn, Tensorflow, Caffe2, PyTorch and Theano.
You have enthusiasm for reproducible research techniques including version control (geg. Git & Github etc.).
You have the ability to engage with a variety of stakeholders and build a consensus.
You are a lifelong learner; as technologies and techniques are constantly evolving, you are proactively pushing yourself to develop your skills and knowledge.
What's it like to work at Zego?

Zego has a truly international and inclusive team, unified by great ideas and collaborative thoughtfulness. Our people are the most important part of our story and everyone plays an essential role in our journey. We look for people who have expertise, enthusiasm and who are motivated by change. There’s plenty of room to learn and grow, as part of our ongoing training programmes or directly from other experts. You’ll work alongside a talented group of people who respect each other's differences and seek to understand fresh perspectives.",4.5,"Zego
4.5","London, England",-1,51 to 200 Employees,2016,Company - Private,Insurance Agencies & Brokerages,Insurance,Unknown / Non-Applicable,-1
Data Engineer,-1,"Job Title

Data Engineer

Location

The Equinox, Glasgow - Glasgow, G2 6QQ UK
The Meridian, Manchester - Manchester, M3 4AL UK
The Observatory, Reigate - Reigate, RH2 0SG UK (Primary)

Organisational Unit

esure -> Head Office -> Information Technology

Salary

Competitive

Job Type

Full-time

Category

Data

Career Level

Experienced (Non-Manager)

Job Description

esure Group are currently recruiting for a Data Engineer to join our rapidly expanding, innovative Data team.

The team are building a cutting-edge Data Analytics Platform using modern tools like Databricks and AWS. The platform will allow users to gain access to analytics data to ensure our business can unlock maximum value and operate effectively.

What you can expect as a Data Engineer:

The successful candidate will develop and manage the Data Engineering stack at esure. The role holder will be responsible for data design, development of data pipelines, loading of the data lake and data warehouses and building reports and visualisations.

What you’ll do:
Design and build technical products / platforms to meet the needs of esure’s internal staff
Assist the technical lead, Product Managers and Architects to define the technical direction for the products you are supporting
Implement data pipelines to ingest data into datastores for internal reporting and analytics
Managing the data stores to ensure data quality and availability
Taking part in 2nd-line support of pipelines and platforms, including occasional support outside of office hours
Support the adoption of Agile within the technical teams for use in delivery projects and support tasks.
Share knowledge of tools and techniques with the wider team, both developers and non-developers
Identify opportunities and areas for improvement around technical quality of the product

Job Requirements

What we are looking for:

Essential:
Strong, hands-on experience of developing a cloud-based Data Platform, preferable AWS
Knowledge of the following AWS tools: Redshift, Lambda, Kinesis, Glue, Athena
Ability to write enterprise grade Python code
Working knowledge of producing Data pipelines using Spark
Desirable:
Knowledge of Data Pipeline orchestration
Visualisation tools – Tableau
What we will offer to you in return:
Opportunity for remote working
Dress for your day (casual and formal business dress depending on your day)
25 days holiday plus bank holidays
25% discount on esure & Sheila’s Wheels insurance (10% for immediate family) or a guarantee to beat any other insurer’s renewal quote on both home and car insurance
15% Discount on esure and Sheila’s Wheels Travel Insurance (7.5% for family)
Discretional bonus
Festive Bonus
Free daily shuttle bus to and from our Reigate office to Redhill train station
BUPA - Private medical cover for eligible colleagues
Flu Jabs and Eye Care - Free flu jabs every winter, free eye tests every two years and £50 towards VDU glasses
esure are members of easitSURREY, for a membership of £5.05 per year you can be eligible for a wide range of travel discounts including:
15% on rail travel with Southern
20% discount for single and return bus journey on certain routes
A number of cycling related offers including 10%-20% off at Halfords
To ensure the safety and wellbeing of all candidates and colleagues and that the social distancing guidelines set out by the government during the current Covid-19 outbreak are adhered to, esure Group will be conducting all interviews via a video conferencing platform until further notice.

Closing Date

30/10/2020",5.0,"esure Services
5.0","Reigate, England",-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer,-1,"Pharmatelligence is searching for a highly motivated Data Engineer to help architect, build, and scale a software platform that transforms and serves healthcare data.

*Opportunities*

· Further a career in data engineering

· Work with a large collection of modern technologies

· Work in a small team of highly motivated experienced individuals

*Must have experience*

· Fact and dimension based data modelling

· Data Warehousing (ideally Microsoft Azure Synapse Analytics)

· Modern API technologies (ideally GraphQL)

*Bonus experience*

· Meteor JS, React, Apollo, Apache Spark, Databricks

*Must have skills*

· Ability to write efficient T-SQL (or similar)

· Understanding of development frameworks and package management

*General skills*

· Self-motivated

· Precise

· Organised

· Excellent attention to detail

*Job responsibilities*

· Architect approaches to data transformation

· Model data for high performance

· Combine and transform data using modern techniques

· Exposing software platform to modern data analysis services

· Work closely within a team to achieve objectives and timelines

*Company brief*

Pharmatelligence is a healthcare data consultancy which specialises in the analysis of independent real-world evidence for healthcare services and the pharmaceutical industry. We have over 20 years of specialist knowledge and operational experience enabling us to deliver real-world evidence to improve understanding of treatment effectiveness and safety and guide better decision-making in healthcare. We have published more than 200 papers and abstracts in peer-reviewed journals and have supported numerous applications to reimbursement authorities including the National Institute for Health and Care Excellence (NICE). We are an expert supplier of research services using the Clinical Practice Research Datalink, the UK’s leading healthcare data source.

Job applications will be processed to comply with the Pharmatelligence recruitment privacy policy. A copy is available upon request.

Application deadline: ongoing

*Salary: * Based on skills experience

*No recruitment agencies*

Job Types: Full-time, Permanent

Salary: £40,000.00-£60,000.00 per year

Schedule:
* Monday to Friday

Work remotely:
* Yes",-1,Pharmatelligence,"Cardiff, Wales",-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Job Title: Data Engineer
Contract Length: Initial 3 Months (possible extension)
Rate: Up to 250 per day
Location: Chartres, France

Acorn is working in a recruitment partnership with a UK based IT Solutions provider to support a major project of theirs in Chartres France. We are searching for several experienced Data Engineers with experience installing Cat 7 network infrastructure to work on an initial 3-Month project with possible extensions. They will provide safe travel to the site and can provide assistance with accommodation and living costs while on project.

The project will involve implementing a new WIFI and network infrastructure for a major global organisation. To be successful you will ideally have exposure to fibre / network installations within large factory environments. It is essential that you have undertaken Manual Handling & Working at Height accreditations within the last 12 months. Any French language skills would be highly desirable.

We are ideally looking for:
Exposure to installing network / wifi infrastructure within large factory environments.
Understanding Cat 7 standards and Principles.
Up to date Manual Handling and Working at Height accreditations (Within last 12 Months).
Ability to work away from home.
French language skills are highly desirable.
Benefits:
Day rate up to 250 per day.
Safe travel to site.
Assistance with accommodation and living costs while on project.
Acorn Recruitment Ltd is acting as an Employment Business in relation to this vacancy.",3.6,"Acorn Recruitment Limited
3.6","Birmingham, England",-1,201 to 500 Employees,1992,Company - Private,Staffing & Outsourcing,Business Services,$100 to $500 million (USD),-1
Market Data Engineer,-1,"Market Data Engineer
Millennium Management LLC is a global hedge fund with more than 3000 employees and offices in North America, Europe and Asia. We pursue a global multi-strategy approach to investing, seeking to achieve above-average risk-adjusted returns. Our global investment strategies include: Relative Value Fundamental Equity, Statistical Arbitrage, Fixed Income, Merger Arbitrage, Futures/Currency, and Options among others.
We are currently seeking a Market Data Engineer to work across both high & low-latency trading.
Expert knowledge of the design, engineering, and operations of direct feed market data infrastructures.
Strong knowledge of the LINUX operating system, including system administration, optimization, and troubleshooting. An in-depth knowledge of low-latency technologies preferred but not required.
Advanced ability in a scripting language such as bash, Python, or Perl.
Strong knowledge of various network protocols such as TCP/IP, UDP, multicast.
Expert in Refinitiv TREP middleware and other similar middleware technologies such as Kafka
Experience working with European real-time consolidated and direct feeds
Experience working with leading real-time market data providers in a low latency
Familiar with configuring ITRS or other monitoring systems
Confident working in common operating systems such as Linux and Windows.
Non-Technical:
Degree in Computer Science or equivalent
Excellent listening, and communication (both oral and written) skills
Self-starter and critical thinker, takes ownership of own projects and makes improvement suggestions for the entire infrastructure.
Proactive, assertive and attentive to details.
Can work independently and in a collaborative environment.
Can handle several projects with different priorities at the same time in a fast-paced environment.
Excellent self-management and problem-solving skills.
Quick learner
Ability to work in a trading environment under pressure

Preferable but not essential:
Cloud experience with AWS, GCP or Azure
Familiarity with quantitative finance and electronic trading concepts.
Broad understanding of equities, derivatives, futures, FX, or other financial-services instruments
Ability to understand and discuss requirements from portfolio managers.
Experience operating and monitoring both high- and low-latency trading environments.
Experience with containerization and orchestration technologies (e.g. Docker / Kubernetes)
Experience with open source DevOps projects
Cloud DevOps experience with AWS, GCP or Azure
Proficiency in at least one of the following: C/C++, Java, Scala, or C#",3.8,"Millennium
3.8","London, England",-1,1001 to 5000 Employees,1989,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1
Data Engineer,-1,"Summary


Salary:
Competitive
Team:
Information Technology
Location:
Malmesbury - United Kingdom

About us

At Dyson, we demand
the highest standard of performance from the technologies we engineer. Our
people expect the same from the technology that supports them. We are a
community that appreciates and advocates better engineering. A community of
pioneers. We're looking for a Data Engineer to join Dyson's Global
Data Services team.

This team ensures that the various parts of
Dyson's business are able to leverage rich, accurate, and timely data to
generate insights and make better decisions. As a part of IT, the team has the
resources and the remit to keep up with Dyson's impressive global growth.

Building our
analytical capabilities is a core pillar of Dyson's new global data strategy.
As more consumers engage with Dyson, via more types of products, and across
more markets, the volume and diversity of data will greatly increase.
Understanding how to use this data to improve everything from customer
experiences to product development will be key to Dyson's success.

About the role


What you'll be doing:
As a Data Engineer
you will be responsible for developing, industrialising, and optimising Dyson's
big data platform running on GCP. You will ingest new data sources, write data
pipelines as code, and transform and enrich data using the most efficient
methods.
Working with data from
across Dyson’s global data estate, you will understand the best way to serve up
data at scale to a global audience of analysts. You will work closely with data
architects, data scientists and data product managers on the team to ensure
that we are building an integrated, performant solutions.
About you


You'll have:
Strong programming skills in languages such as Python (preferred)/Java/Scala including building, testing and releasing code into production
Strong SQL skills and experience working with relational/columnar databases (e.g. BigQuery, SQL Server, Postgres, Oracle, Presto, Hive, etc.)
Knowledge of data modelling techniques and integration patterns
Practical experience writing data analytic pipelines
Experience integrating/interfacing with REST APIs / Web Services
Experience handling data securely
Experience with agile software delivery and CI/CD processes
A willingness to learn and find solutions to complex problems
We'd also like to see:
Experience migrating from on-premise data stores to cloud solutions
Experience of designing and building real/near real time solutions using streaming technologies (e.g. Dataflow/Apache Beam, Fink, Spark Streaming, etc.)
Hands-on experience with cloud environments (GCP & AWS preferred)
Experience building API's and apps using Python/JavaScript or an alternative language
Practical experience with traditional Big Data stacks (e.g. Spark, Flink, Hbase, Flume, Impala, Hive etc)
Experience with non-relational database solutions (e.g. Big Query, Big Table, MongoDB, Dynamo, HBase, Elasticsearch)
Experience with AWS data pipeline, Azure data factory or Google Cloud Dataflow
Working with containerization technologies (Docker, Kubernetes etc…)
Experience working with data warehouse solutions including extracting and processing data using a variety of programming languages, tools and techniques (e.g. SSIS, Azure Data Factory, T-SQL, PL-SQL, Talend, Matillion, Nifi, AWS Data Pipelines)
Benefits
27 days holiday plus eight statutory bank holidays
Pension scheme
Performance related bonus
Life assurance
Sport centre
Free on-site parking
Subsidised café and restaurants
Discounts on Dyson machines
Interview guidance


We are following the government guidelines regarding COVID19. At this time all interviews will be conducted via video or telephone. We’re taking these precautionary measures to protect both our employee and candidate wellbeing. Our Talent Acquisition team will work with you and provide further information as appropriate.
Posted: 04 August 2020

Apply",2.9,"Dyson
2.9","Malmesbury, England",-1,10000+ Employees,1993,Company - Private,Electrical & Electronic Manufacturing,Manufacturing,$100 to $500 million (USD),-1
Data Engineer,-1,"Reference:
VG/OMJ/DATAENG/MIG
Industry Sector:
Government
Location:
London - REMOTE
Job Type:
Contract
Salary:
£550 - £575 Per Day INSIDE IR35 UMBRELLA
Agency Name:
Nationwide People Limited
Contact:
Vincent Galea
Telephone:
01628 918 490
Email:
cvs.vincent.galea@nationwidepeople.com

Data Engineer / Architect - Azure, Data Factory, Power BI with Automated Testing skills

My Government client based in London seeks a dynamic and technically astute Data Engineer expert who can Engineer/Architect and migrate data from old legacy platfrom to Azure Cloud. The ideal candidate must also have strong Automation Testing skills and be able to up-skill/train team members. Strong Data background with strong AZURE CLOUD / DATA FACTORY / POWER BI / SQL focus needed! Description: Designing, constructing and testing data transformation routines to translate source data into valid loadable data files for the target system. Identifying, managing and supporting the resolution of gaps and data quality issues and represent the Team at project meetings. Determine the scope and detail of the data required to be migrated to the target system. Must have Automated Testing skills also and and be able to up-skill/train team members

Essential experience required for the Data Engineer ( Azure / Data Factory / Power BI ) includes:

• Strong background in Data Engineering and Architecture.
• Strong understanding of Microsoft SQL Server, Azure and Power BI
. • Track record that of implementing end-to-end data solutions and ELT/ETL pipeline development skills.
• Maintain and optimize the Data Warehouse and Data.
• Strong background in Data Engineering and Architecture.
• Strong understanding of Microsoft SQL Server, Azure and Power BI.
• Track record that of implementing end-to-end data solutions and ELT/ETL pipeline development skills. Vacancy Validation Template v1 1 st June 2018
• Maintain and optimize the Data Warehouse and Data Lake solutions to maximize performance.
• Experience working with solutions in the Cloud. • Implement dashboards on Power BI for data analysis.
• Strong experience with SQL. • Good documentation experience. • Ability to communicate well with key stakeholders and non-technical audiences and some automation testing.",-1,Nationwide People Limited,"London, England",-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"As the Data Engineer for this amazing corporate Insurance company, you will utilise your Data Warehousing, ETL development, advanced analytics and data visualisation skills to provide the organisation with high quality business intelligence & actionable insights from their major data sources.

The Data Engineer will build, maintain and extend their fast-growing Cloud Data Warehousing Platform using Wherescape for automation, developing ETL’s using SSIS, utilise ADF & Jenkins, whilst Power BI, Tableau and MSBI will be used for visualisations.

Working beyond just the data to improve processes and provide solutions to common problems, the Data Engineer will provide technical leadership, champion automation, and work with other team members to translate high level requirements into epics, stories and tasks.

The Data Engineer will have the benefit of working directly with senior stakeholders, whilst also being part of the organisations wider group of Data Engineers who hold weekly stand ups. Good communication skills are therefore expected.

Although specific experience with Snowflake or Wherescape is beneficial, Data Engineers with good SQL & ETL skills and other Data Warehousing technologies are also highly suitable for this role.

Responsibilities Include:

Planning and achieving Agile sprint tasks from which the technical solutions will be created.
Supporting the data visualisation and ETL data processing, ensuring that the services are up to date
Provide input into and manage the data artefacts, which includes planning, task completion, unit testing, peer review, release, meta data, data modelling and deployment.
Partaking in DataOps Design Authority meetings to provide input to data value delivery methods
Creating and inputting meta data to sufficient levels
Converting user stories to technical tasks, translating the business goal into a technical one, allowing the delivery of the technical solution
Using modern data platform tools set up in an agile delivery method to progress in a journey towards CI/CD of projects in the cloud
Ensuring all analysis, decisions made and activity undertaken in fulfilling of this role considers the fair treatment of customers
Skills:

Data Warehousing - Delivering data engineering solutions including ETL development
Data Integration and Advanced Analytics
Use of modern data paradigms within the cloud in order to enable a business to maximise its value from data using Wherescape, SSIS, ADF, Jenkins, Power BI, Tableau and MSBI
RDBMS: Oracle, TSQL, Python
Experience with Jira
Proven data, analytics & engineering skills
Software engineering
Logical and lateral thinking considering all aspects in decision making
Communication to all levels of stakeholders - communicating complex data management issues to non-technical stakeholders
Continuous improvement skills with the ability to streamline processes using Lean Six Sigma methodology
Interested Candidates seeking a role with exciting, ongoing challenges need to apply now and can expect initial feedback on their application within 72 hours.",4.9,"Jenrick Group
4.9","Brighton, England",-1,1 to 50 Employees,1967,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Data Engineer,-1,"Costain helps to improve people’s lives with integrated, leading edge, smart infrastructure solutions across the UK’s energy, water, transportation and defence markets. We help our clients improve their business performance by increasing capacity, improving customer service, safeguarding security, enhancing resilience, decarbonising and delivering increased efficiency. Our vision is to be the UK’s leading smart infrastructure solutions company. We will achieve this by focusing on blue chip clients whose major spending plans are underpinned by strategic national needs, regulatory commitments, legislation or essential performance requirements. We offer our clients leading edge solutions that are digitally optimised through the following five services which cover the whole lifecycle of their assets: future-shaping strategic consultancy; consultancy and advisory; digital technology solutions; asset optimisation and complex programme delivery. Our culture and values underpin everything we do.
We are looking for a Data Engineer on a Business Intelligence project that is building a Reporting/Dashboarding solution and Data Virtualisation layer through the use of SAP’s latest cloud platforms for BI/Reporting and Data Integration.
This is an exciting opportunity to be working with a leading edge team who are digitally transforming operations within Central Government.
To be successful in this role, these are the key capabilities that we are looking for:
Be agile in learning.
Be intuitive to think outside the box when solving problems.
Can quickly understand the fundamentals of an industry and how it works.
Data Intuition - Contextualize and translate a data to provide insights.
.

As an experienced Data Engineer, you will help to model and design the Data Virtualisation layer required to support specific Dashboards as well as design a number of staging databases to be used to transform and store the data retrieved from source systems.
The role may be extended to support the integration with those source systems using ETL and/or API based design patterns.

Must have experience:
- Business Analysis and Data Analysis
- BI/Reporting/Dashboarding Development
- Conceptual and Logical Data Model Design
- Physical Data Model / Relational Database Design
- Relational Database Management System (e.g. SQLServer, AzureSQL, Oracle) Design and Configuration
- Data Integration Design and Development – ETL, Views, SQL queries, Data Warehousing
- Systems Integration Design and Development - Middleware, Web Services/APIs (e.g. SOAP, REST, OData)
Ideally have experience with:
- SAP HANA database
- Data Virtualisation
- SAP Cloud Platform (SCP)
- SAP Cloud Platform Integration (CPI)
- Azure Data Factory
Additional experience that would be beneficial:
- Software Development
- System/Integration Test Preparation and Execution
- SAP Analytics Cloud (SAC)
- Older, equivalent SAP products/technologies, e.g. SAP BO, SAP BW
- Data Science (analytics, modelling, machine learning, AI)

We listened to our employees so our Core Benefits are funded by us and include a Group Pension Scheme, Employee Assistance Programme, Life Assurance, Income Protection and funded membership to a Professional Institute. In addition to this we also offer a Private Healthcare Scheme, Private Dental Scheme, Cycle to Work, Volunteering Days and Save as You Earn Scheme.
At Costain we aim to be an accessible, diverse and inclusive organisation to continue to meet our customers’ needs. We will be industry leading in our approach and people from all backgrounds will be proud to work for Costain. Our goal is to have a workforce that is representative of society.
We actively encourage applications from candidates who have a relationship with the armed forces community whether as a currently serving member or reservist, ex-military or wounded personnel or as a member of a service family.",3.5,"Costain
3.5","Maidenhead, England",-1,1001 to 5000 Employees,-1,Company - Public,Construction,"Construction, Repair & Maintenance",$1 to $2 billion (USD),-1
Data Engineer,-1,"Greenfield Data Pipeline Projects
Data pipelines built in Python/PySpark
AWS, S3, Glue, Athena

A Data Engineer with Python/PySpark and AWS experience is sought by a software solutions provider based in London, paying up to £70,000 + benefits

Working as a Data Engineer for a market-leading Fintech company located in London you'll earn a very competitive salary with heaps of benefits to suit your flexible working lifestyle. You'll have the opportunity to work with a creative and passionate team on Greenfield data projects where you will get the chance to learn new skills as the company embark on a major Data Engineering programme on the back of a AWS migration.

We are looking for Data Engineers with a genuine interest in rich data, who also have an desire to learn new tools; so if you have a proven track record of building data pipelines, loading data into data lakes and data warehouses running in the cloud, this Data Engineer role could be the one for you.

The technology and skills involved in this Data Engineer role:

Building complex data pipelines/ETL/ELT scripts
Python/PySpark as their Data pipelines will be built in PySpark
AWS and components such as S3, Glue, Athena, RDS
Data Warehouse databases like Redshift/Snowflake/BigQuery
Implementing Rest APIs
Using and integrating BI tools such as Looker, Qlik, Power BI, Tableau

After a substantial investment from a leading private equity group, this company has become a major disruptor of the fintech world with their award-winning cloud-based product. It's a great time to be joining a strong, expanding business and would be a smart step for any Data Engineer wanting to make a career-defining change. They'll provide you with a great work-life-balance environment, a positive, inclusive and mission-driven culture and plenty of coffee and snacks.

Please get in touch with us today or refer a friend?

Think IT Recruitment is acting as an employment agency for this vacancy under UK Government regulations CEAEBR 2003",-1,Think IT Recruitment Limted,"London, England",-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Location
Newport, London, Fareham
About the job
Summary
Do you want to help analysts answer the questions of the day by providing them with the data they require? Do you want to play your part in the transformation of how statistics are produced to help Britain make better decisions?

The Office for National Statistics (ONS) is the UK’s largest producer of official statistics, covering a range of key economic, social and demographic topics. These include measuring changes in the value of the UK economy, estimating the size, geographic distribution and characteristics of the population, and providing indicator of price inflation, employment, earnings, crime and migration.
Job description
There are 3 posts available. 1 post is until the 31/07/2023 and also offers a permanent contract, 1 post is funded util the 31/07/2022 and another until the 31/03/2022.

Responsibilities
There are roles available across two teams.

2021 Census and Social Survey Transformation
These teams are responsible for the processing of data from the 2021 Census, the Covid Infection Survey and other ONS Social Surveys. The work of the different teams is similar even though the underlying data vary; you could work in any one of these areas. The type of activities you will be involved with are:
• Working with subject matter experts to design, build, teat and implement processing solutions that will provide high quality data for analysis. This will include working with Data Architecture to ensure data are reference to core reference datasets.
• Working collaboratively with the relevant experts in ONS to ensure corporate standards are understood and implemented in all development activity.
• Work with Data Architecture to ensure data are fully documented using corporate tools and standards.
• Coordination of activities within the team, internal delivery partners within ONS and end users of the data.
• Possibly carry out the line management of staff, this may involve matrix management.
• Ensure that business continuity is considered within the day to day work.

Data Architecture
The Data Architecture Division provide the standards and core capabilities used by the office for the management of its statistical data. One of these capabilities is the ability to reference information collected via our surveys or the Census to standard occupation and industry classifications. The type of activities you will be involved with are:
• Working with subject matter experts to implement within a coding tool the strategies for referencing data (RDMF)
• Development and building of RDMF
• Matching and linking data sources for the development of one of the RDMF index
• Working as a core part of the SIC SOC development, managing the backlog and help schedule next iterations of the tool
• Working to the SIC and SOC experts to ensure that the tool is fit for purpose
• Reviewing the performance of the tool, identifying and implementing improvements that reduce run time. Identify any issues with implementation of the tool in different pipelines. Identify and recommend next steps of the tool development.
• Evaluate, identify and streamline ETL processes associated with the SIC SOC coding tool
• Work with multiple business areas to support the embedding of the tool into productionised pipelines
• Coordination of activities within the team, internal delivery partners within ONS and end users of the data.
• Possibly carry out the line management of staff, this may involve matrix management.
• Ensure that business continuity is considered within the day to day work.

Person Specification

Essential Skills:
• Intermediate to advance understanding of SQL particularly in the context of analysing data in Hive and Impala
• An intermediate or higher understanding of Python
• Familiarity with data tools such as Spark
• Demonstrable experience of structure and linking within and across very large administrative, Census or survey datasets.
• Knowledge (theoretical or practical) knowledge of data science models implementations within the context of ETL pipelines
Behaviours
We'll assess you against these behaviours during the selection process:
Managing a Quality Service
Delivering at Pace
Making Effective Decisions
Communicating and Influencing
Technical skills
We'll assess you against these technical skills during the selection process:
Coding Experience
Working with Data Sets
Benefits
The Office for National Statistics is part of the Civil Service, and as such we share a number of key benefits with other departments, whilst also having our own unique offerings to support our 5000+ valued employees across the business.

Whether you are hearing about us for the first time or already know a bit about our organisation, we hope that the benefits pack attached (bottom of page) will give you a great insight into the benefits and facilities available to our employees, and our fantastic working culture.

We are an organisation that takes the well-being of its employees seriously and lives and breathes the desire to modernise the workplace of the future. Everyone, from our office-based staff in Newport, London and Titchfield, to our field interviewers and airports and ports passenger survey staff, are part of a diverse and inclusive family.

Inclusion & Accessibility

At ONS we're always looking to attract the very best people from the widest possible talent pool, and we are proud to be an inclusive, equal opportunities employer. As a member of the Business Disability Forum and a Disability Confident Leader we’re committed to ensuring that all candidates are treated fairly throughout the recruitment process.

As part of our application process, you will be prompted to provide details of any reasonable adjustments to our recruitment process that you need. If you would like to discuss any reasonable adjustments before applying, please contact the recruitment team in the first instance.

If you would like an accessible version of any of the attachments or recruitment documents below or linked to in this advert, please contact the recruitment team who will be happy to assist.
Things you need to know
Security
Successful candidates must pass a disclosure and barring security check.
Successful candidates must meet the security requirements before they can be appointed. The level of security needed is security check.
People working with government assets must complete basic personnel security standard checks.
Selection process details
This vacancy is using Success Profiles, and will assess your Behaviours, Experience and Technical skills.
Assessment at application stage will be based on your personal statement.

Your personal statement should be no longer than 1250 words. You should use this space to provide evidence for each essential criteria within the person specification. As the criteria are scored, we would recommend that you give clear examples for each including the impact of your actions. Success Profiles Behaviour examples are not required at this stage.

ONS Recruitment will be running regular webinars to support candidates with advice on the application and assessment process. To sign up and join the next session please follow THIS LINK to our Eventbrite page.

In cases where there is a high number of applications the sift pass mark may be adjusted and candidates will be invited to interview in merit order, i.e. those scoring the highest.

Should you be invited to interview, you will be assessed using various assessment techniques aligned to the new Civil Service Success Profiles, where you'll be assessed against all the behaviours outlined in the advert.

Currently all interviews are being conducted by Video Conference.

Our main locations are Newport (South Wales), Titchfield and London but we are currently home working

A reserve list may be held for a period up to 12 months from which further appointments may be made.

Applicants who are placed on reserve list (near misses) for this specific role may be offered an alternative role at a lower grade. This opportunity will allow you to develop your skills and experience to progress your career within ONS.

The Sift will be conducted from 05/11/2020
Interviews will be conducted from 23/11/2020

For the full terms and conditions of the post, please see attachment.

If you need help with any part of the application process or completing your CV or personal statement please contact our Recruitment Team at ons.resourcing@ons.go.uk or call us on 01633 455556, one of the team will be happy to help you.

Feedback will only be provided if you attend an interview or assessment.
Nationality requirements
Open to UK, Commonwealth and European Economic Area (EEA) and certain non EEA nationals. Further information on whether you are able to apply is available here.
Working for the Civil Service
The Civil Service Code sets out the standards of behaviour expected of civil servants.

We recruit by merit on the basis of fair and open competition, as outlined in the Civil Service Commission's recruitment principles.
The Civil Service embraces diversity and promotes equal opportunities. As such, we run a Disability Confident Scheme (DCS) for candidates with disabilities who meet the minimum selection criteria.
Apply and further information
Once this job has closed, the job advert will no longer be available.
You may want to save a copy for your records.
Contact point for applicants
Job contact :
Name : Carolyn Watson
Email : carolyn.watson@ons.gov.uk

Recruitment team :
Email : tom.partleton@ons.gov.uk
Further information
If you feel your application has not been treated in accordance with the Recruitment Principles and you wish to make a complaint, in the first instance, you should contact Paul Cudmore, Office for National Statistics, Government Buildings, Cardiff Road, Newport NP10 8XG. If you are not satisfied with the response you receive from the Department, you can contact the Civil Service Commission at http://civilservicecommission.independent.gov.uk/civil-service-recruitment/complaints/
Attachments
ONS_External_Vacancy_Terms - Fixed Term Only Opens in new window (pdf, 107kB)
ONS_External_Vacancy_Terms - Post 31072023 Perm Contract Opens in new window (pdf, 38kB)
ONS_External_Vacancy_Terms Opens in new window (pdf, 19kB)",4.2,"Office for National Statistics
4.2","London, England",-1,1001 to 5000 Employees,1996,Government,Federal Agencies,Government,Unknown / Non-Applicable,-1
Big Data Engineer,-1,"Job Title: Big Data Engineer

Location: London

Corporate Title: Assistant Vice President

Opening Date : 10/08/2020

Closing Date: 08/09/2020

Salary: Competitive

Full-Time

You will be joining an agile feature team responsible for building Deutsche Bank’s Risk Management Platform. As a software engineer, you will create working, tested code that delivers value to our common platform. You will be required to apply your depth of knowledge and expertise to all aspects of the software development lifecycle, as well as partner and collaborate with stakeholders from across Information Technology and business divisions.

You will act as a big data engineer and help in Big Data development practices. You will work on challenging software build outs to persist, process and distribute data at very large scale.

What we’ll offer you

A healthy, engaged and well-supported workforce are better equipped to do their best work and, more importantly, enjoy their lives inside and outside the workplace. That’s why we are committed to providing an environment with your development and wellbeing at its center.

You can expect:

Competitive salary and non-contributory pension
30 days’ holiday plus bank holidays, with the option to purchase additional days
Life Assurance and Private Healthcare for you and your family
A range of flexible benefits including Retail Discounts, a Bike4Work scheme and Gym benefits
The opportunity to support a wide ranging CSR programme + 2 days’ volunteering leave per year

Your key responsibilities

You will participate in the backlog grooming and provision high quality scalable designs
You will cooperate with our quality assurance team to ensure the quality of all changes to the platform
You will participate in iteration planning and sprint review ceremonies and engage with your feature team in the Scaled Agile Program Increment planning process
You will ensure successful code quality via code reviews
You will help to deliver on the Risk Finder vision via a commitment to code quality and architectural improvement

Your skills and experience

Experience of leading software development teams
Extensive experience of Big Data technology using Hadoop, including Hadoop Distributed File System, Hive, Spark, and Impala
Demonstrable solution design experience at large scale using Hadoop technology (Cloudera preferred), distributed data processing, and Relational Database Management System (Oracle preferred)
Core development experience in Java, with significant exposure to Scala, including Simple Built Tool
Significant experience of Spark development, including Data Frames

How we’ll support you

Focused professional development supports via formal training, coaching and support from experts in your team
Open communication with colleagues is encouraged at every level of the organisation and we value diverse opinions and acknowledge individual contribution
A well-defined, mature, highly structured career path for software professionals
Flexible working to assist you balance your personal priorities

About us and our teams

Deutsche Bank is the leading German bank with strong European roots and a global network. Click here to see what we do.

Our values define the working environment we strive to create – diverse, supportive and welcoming of different views. We embrace a culture reflecting a variety of perspectives, insights and backgrounds to drive innovation. We build talented and diverse teams to drive business results and encourage our people to develop to their full potential. Talk to us about flexible work arrangements and other initiatives we offer.
We promote good working relationships and encourage high standards of conduct and work performance. We welcome applications from talented people from all cultures, countries, races, genders, sexual orientations, disabilities, beliefs and generations and are committed to providing a working environment free from harassment, discrimination and retaliation.",3.7,"Deutsche Bank
3.7","London, England",-1,10000+ Employees,1870,Company - Public,Banks & Credit Unions,Finance,$10+ billion (USD),-1
Data Engineer,-1,"Data Engineer/Data Warehouse Developer
Glasgow based
Permanent
Salary of £35-40k pro rata, depending on experience, participation in company bonus scheme and a wide range of other benefits including private health care.
McCurrach is a successful, award-winning business-to-business organisation that is now expanding its IT and Data function as part of its next digital and data transformation plans. As a result, we are recruiting a number of permanent and fixed terms roles during this exciting time.
This fantastic new role has been created for a Data Engineer/Data Warehouse Developer who has a strong expertise within Data Warehousing and a solid understanding in SSAS, SSIS, MDX, OLAP. A self-starter that enjoys working in challenging projects delivering to a high standard within the Microsoft BI stack.
This is a perfect opportunity for an experienced Data Engineer/Data Warehouse Developer to join McCurrach to be part of a significant data science transformation project, migrating to a new business intelligence infrastructure and reporting platform.
If you thrive in a fast-moving environment, enjoy working with a variety of stakeholders and are driven to succeed, then we would love to hear from you.
The key aspects of the role include:
Strong capabilities in Report design/information/database design skills
High level of competence in all aspects of data visualisation
Responsible for leading the design, development and maintenance of data warehouse and analytics architecture to meet and enterprise’s business analysis and reporting needs
Working with key stakeholders, architects and business partners to establish the technical vision for applications in customer data warehouses
Gathering business requirements and creating architectural designs
Designing, developing and supporting new and current processes employing industry standards and best practices
Providing support to the business intelligence & data transformation team and support non-technical MI analysts
Documentation of technical needs for processes ensuring optimal technical infrastructure is utilised
Work as part of a team to review, analyse, modify, create new processes including debugging, testing, functionality, integration and implementation
Monitoring, tuning and performance analysis
Reporting to the project sponsor
To be successful in this role, we are looking for the following:
Significant experience in a similar role performing data warehouse architecture development and management
Strong experience in technologies SQL Server, SSRS, SSIS, Stored procedures….
Strong experience in Azure solutions relating to business intelligence
Strong understanding of Business intelligence best practices
Several years’ experience working with reporting, business intelligence and analytical tools desirable including Power BI, QlikView, QlikSense and other related tools
Experience in testing for quality assurance
Excellent written and oral communication skills
If this sounds like the perfect role for you, don't miss out - apply now!",3.0,"McCurrach
3.0","Glasgow, Scotland",-1,1001 to 5000 Employees,1898,Company - Private,Staffing & Outsourcing,Business Services,$50 to $100 million (USD),-1
Data Engineer,-1,"COVID -19 update

We’re actively looking for people to join our teams and we’re committed in protecting your health and wellbeing during every step of our recruitment process.

If you’re successful in securing a role with us you’ll find we’ll be doing things a little bit differently and it may mean you’ll initially join our team by working from home.

During this time we’ll work with you to make sure you have the tools and equipment you need and that you feel part of our amazing DLG team!

Green Flag are at the beginning of a very exciting digital transformation journey, which includes the re-platforming of their services. Delivered using SaFE throughout our sites in both Bromley and Leeds using complete server-less micros services architecture on AWS cloud.

Using leading development paradigm we are fully committed to the development of our team members to build a spectacular working environment.

What we’re looking for:

Will you help us revolutionise the digital experience? We are looking for a Data Engineer able to help us deliver our new AWS platform, using your strategic understanding of platforms and creating a scalable environment that can grow as we do.

We need you to lead on the creation of processes for data deployment and integration to give our data analysts and data scientists the information they need when they need it to deliver the best service for our customers.

In Green Flag we will challenge conventions, continuously improve & innovate to deliver business values for Direct Line Group.

Who you’ll be working with:

This is a key role sitting within our creative Green Flag Department, we have a start-up mentality and embrace the true scaled agile development processes. You will be working as part of a Scrum team aimed at delivering fast results in an Agile environment.

This is a career defining opportunity and a chance to be involved in the rescue industry, changing programme of work. You will be part of a wider technical team where you will work with some of the best in the business. You will have the opportunity to learn and grow whilst helping us deliver a companywide technology transformation project.

What you’ll be doing:
Using Python3 and your strong data modelling experience you will create production ready code, always striving to find the easiest and most direct solutions to connect and query our data.
Use your good understanding of data architecture to and deliver logical data structures at enterprise or programme level.
Bring your experience developing and analysing both SQL and NoSQL databases.
Foster and cultivate an Agile culture so that it will enable the smooth and rapid transitioning of prototype data products into robust product assets.
Using commercial awareness, influence and communicate across multiple business areas and partners to promote new opportunities for data to be used effectively.
What we’ll give you:

Come join us and you’ll find yourself in the middle of one of the most on-the-go teams in the business, with autonomy and exposure to industry leaders on huge household brand names. We are always encouraging internal development and you’ll have access to loads of learning opportunities, events and conferences to build your industry knowledge.

We also know that your Life/Work balance may mean that ‘normal’ working hours are not always the right fit for you! But just contact our team, we're always happy to chat through your requirements and see what is doable.

If during the recruitment process you require any reasonable adjustments, please just let us know.",3.7,"Direct Line Group
3.7","Bromley, England",-1,10000+ Employees,1985,Company - Public,Insurance Carriers,Insurance,$2 to $5 billion (USD),-1
Data Engineer,-1,"Location
1 Victoria Street London, 2 Rivergate Temple Quay Bristol
About the job
Summary
Are you interested in UK energy data, climate change and building a sustainable future? Do you enjoy working with others to people to establish new data pipelines and ways of working to create excellent statistics that shape the Government’s policies for achieving Net Zero emissions by 2050? If so, now is great time to join the Energy Statistics team in BEIS.

This post will complete recruitment of the new Data System Development team. We are a small central team in the division, providing technical advice and support to around 40 other analysts. The team’s main current goal is to design and deliver a transformation programme to radically improve the pipelines of data ingest, processing and dissemination used for the production of around 100 official statistics a year.

This transformation programme is replacing manual data processes with SQL databases and reproducible pipelines. The team uses Python and SQL, with Git for collaboration and version control. We are prioritising delivering a system that is easy for other analysts to use and maintain, with clear metadata and documentation. This work will significantly improve productivity and quality assurance across the division, and thereby enhance the published statistics that drive national energy strategy.
Job description
As a data engineer in the Data Systems Development team, you'll work closely with analysts in other teams by providing guidance and support as they develop new data pipelines. You will manage the scrum development process for these users, helping to unblock barriers and encouraging progress. You will also use your technical skills to personally deliver new system features that are robust, resilient and aligned to user-needs. As we are a small team there will be plenty of scope for you to work with senior engineers to help shape the overall system design.

This role is available in London or Bristol. If based in Bristol you will be expected to visit London two days a week under normal circumstances.

Pay Enhancement

If the successful candidate is an existing member of a government analytical profession (GORS, GES, GSR or GSG), they will qualify for a pay enhancement of £4245 rising to £6000 for those with a relevant masters. Non-members will be supported to apply for membership once in post if appropriate.

Responsibilities
We are looking for someone with skills and interest in data engineering who enjoys working with people with a range of technical experience. The points listed below are relevant for the role; you should ensure that you cover as many of these points as possible in your statement of suitability.

Essential data engineering experience:


• Good programming skills including at least one of Python or SQL

• Understanding of relational databases

• Extract, Transform and Load (ETL) processes

• Dissemination of data and analysis in a variety of formats

• Development using version control (preferably Git)

• Monitoring data quality and developing processes for automated and/or manual interventions to improve data quality

Other essential experience:


• Excellent people skills and enthusiasm for working with and helping others

• Ability to communicate technical concepts to a non-technical audience

• Ability and desire to work collaboratively as part of a team while also negotiating and accepting individual responsibilities

Desirable experience:


• Working in an agile development environment

• Highly numerate with an analytics/informatics background

• Working in a statistical environment

We take the development of our people very seriously, equipping and enabling them to make an impact by ensuring high quality evidence and analysis is at the heart of the policy-making process. We are committed to good management and the professional development of staff.

Technical Skills

You will be assessed on the following Technical Skills at Sift and/or Interview

1) Technical Skills Example (250 words)

Please give one or more examples of where you have worked with others to develop new data pipelines. Your answer should cover your personal roles and responsibilities and how you supported others to change their ways of working.

2) All candidates will be tested against the following Technical Criteria:
You can re-engineer manual data flows into reproducible pipelines to enable scaling, testing and for quality assurance.
You can respond to problems in databases, data processes, data products and services as they occur. You can determine the appropriate remedy and assist with implementation of it as well as preventative measures.
Members of the four main government analytical professions who are applying on promotion will additionally also need to demonstrate they meet the SEO level competencies for their profession. The outcome of this extra assessment will not influence who the job is offered to – it is purely to facilitate timely promotion of badging for internal applicants.
Behaviours
We'll assess you against these behaviours during the selection process:
Working Together
Managing a Quality Service
Technical skills
We'll assess you against these technical skills during the selection process:
Please give one or more examples of where you have worked with others to develop new data pipelines. Your answer should cover your personal roles and responsibilities and how you supported others to change their ways of working.
Technical Criteria including but not limited to; re-engineer manual data flows; and respond to problems in databases, data processes, data products and services as they occur.
We only ask for evidence of these technical skills on your application form:
Please give one or more examples of where you have worked with others to develop new data pipelines. Your answer should cover your personal roles and responsibilities and how you supported others to change their ways of working.
Benefits
BEIS offers a competitive mix of benefits including:

A culture of flexible working, such as job sharing, homeworking and compressed hours.
Automatic enrolment into the Civil Service Pension Scheme.
A minimum of 25 days of paid annual leave, increasing by 1 day per year up to a maximum of 30.
An extensive range of learning & professional development opportunities, which all staff are actively encouraged to pursue.
Access to a range of retail, travel and lifestyle employee discounts.
Things you need to know
Security
Successful candidates must pass a disclosure and barring security check.
People working with government assets must complete basic personnel security standard checks.
Selection process details
This vacancy is using Success Profiles, and will assess your Behaviours, Experience and Technical skills.
As part of the application process you will be asked to complete a CV and personal statement. Your personal statement (maximum 750 words) should outline your suitability for the role based on the job description. You do not need to repeat material covered in the technical skills question. Please also indicate in your response if you are a member of one of the four main government analytical professions (GORS, GES, GSR or GSG), and if so, your current badged grade. Further details around what this will entail are listed on the application form.

Candidates will be sifted on a personal statement, and any technical skills required.

Expected Timeline subject to change

Sift Dates: w/c 9th or 16th November 2020
Interview dates: w/c 16th or 23rd November 2020
Interview location: MS Teams

Candidates are asked to note the above timetable, exercising flexibility through the recruitment and selection process.

The interview will consist of behaviour and technical questions.

There will be an interview presentation required for candidates who are an existing member of a government analytical profession (GORS, GES, GSR or GSG) looking to promote their analytical badging. This will be used only to confirm the level of pay enhancement they qualify for, and will be separate to the scoring process and merit list. More details will follow at interview stage, where applicable.

Pay Enhancement

If the successful candidate is an existing member of a government analytical profession (GORS, GES, GSR or GSG), they will qualify for a pay enhancement of £4245 rising to £6000 for those with a relevant masters. Non-members will be supported to apply for membership once in post if appropriate.

Reasonable adjustment

If a person with disabilities is put at a substantial disadvantage compared to a non-disabled person, we have a duty to make reasonable changes to our processes.

If you need a change to be made so that you can make your application, you should:

• Contact Government Recruitment Service via beisrecruitment.grs@cabinetoffice.gov.uk as soon as possible before the closing date to discuss your needs.

• Complete the “Assistance required” section in the “Additional requirements” page of your application form to tell us what changes or help you might need further on in the recruitment process. For instance, you may need wheelchair access at interview, or if you’re deaf, a Language Service Professional.

Further Information

If you are experiencing accessibility problems with any attachments on this advert, please contact the email address in the 'Contact point for applicants' section.

If successful and transferring from another Government Department a criminal record check maybe carried out.

In order to process applications without delay, we will be sending a Criminal Record Check to Disclosure and Barring Service on your behalf. However, we recognise in exceptional circumstance some candidates will want to send their completed forms direct. If you will be doing this, please advise Government Recruitment Service of your intention by emailing Pre-Employment.Checks@cabinetoffice.gov.uk stating the job reference number in the subject heading.

New entrants are expected to join on the minimum of the pay band.

Applicants who are successful at interview will be, as part of pre-employment screening subject to a check on the Internal Fraud Database (IFD). This check will provide information about employees who have been dismissed for fraud or dishonesty offences. This check also applies to employees who resign or otherwise leave before being dismissed for fraud or dishonesty had their employment continued. Any applicant’s details held on the IFD will be refused employment.

A candidate is not eligible to apply for a role within the Civil Service if the application is made within a 5 year period following a dismissal for carrying out internal fraud against government.

Any move to the Department for Business, Energy and Industrial Strategy will mean you will no longer be able to carry on claiming childcare vouchers. You will however have access to the governments Tax Free Childcare scheme.

A reserve list will be held for a period of 12 months from which further appointments can be made.

Please note terms and conditions are attached. Please take time to read the document to determine how these may affect you.

BEIS does not normally offer full home working (i.e. working at home); but we do offer a variety of flexible working options (including occasionally working from home).

Please note that BEIS does not hold a licence to sponsor visa applications.

Feedback will only be provided if you attend an interview or assessment.
Nationality requirements
Open to UK, Commonwealth and European Economic Area (EEA) and certain non EEA nationals. Further information on whether you are able to apply is available here.
Working for the Civil Service
The Civil Service Code sets out the standards of behaviour expected of civil servants.

We recruit by merit on the basis of fair and open competition, as outlined in the Civil Service Commission's recruitment principles.
The Civil Service embraces diversity and promotes equal opportunities. As such, we run a Disability Confident Scheme (DCS) for candidates with disabilities who meet the minimum selection criteria.
Apply and further information
Once this job has closed, the job advert will no longer be available.
You may want to save a copy for your records.
Contact point for applicants
Job contact :
Name : Paul Olsson
Email : Paul.Olsson@BEIS.gov.uk

Recruitment team :
Email : beisrecruitment.grs@cabinetoffice.gov.uk
Further information
Appointment to the Civil Service is governed by the Civil Service Commission’s Recruitment Principles. If you feel that your application has not been treated in accordance with the recruitment principles, and wish to make a complaint, then you should contact in the first instance BEISRecruitment.GRS@cabinetoffice.gov.uk. If you are not satisfied with the response that you receive, then you can contact the Civil Service Commission. For further information on bringing a complaint to the Civil Service Commission please visit their web pages: Click here to visit Civil Service Commission/Complaints
Attachments
BEIS Leaflet March 2018 Opens in new window (pdf, 3521kB)
BEIS Story Opens in new window (pdf, 105kB)
BEIS T&Cs Opens in new window (doc, 88kB)",4.0,"Department for Business, Energy & Industrial Strategy
4.0","London, England",-1,1001 to 5000 Employees,-1,Government,-1,-1,Less than $1 million (USD),-1
Manufacturing & Controls Engineer,-1,"Manufacturing & Controls Engineer


August 18, 2020 | Runcorn, England
Role overview

Husco provides individuals the opportunity to pursue a career within a fast-paced, industry leading and entrepreneurial organization. The Manufacturing & Controls Engineer II is responsible for technical support for large scale projects – typically, new product lines, development and/or implementation of new manufacturing technology in support of new product lines or major improvements in existing product lines with a focus on software, process and machine controls, data acquisition and analytics, and Industry 4.0 methodologies. This role actively supports and/or implements continuous improvement philosophies and techniques and participates in the training and development of training materials for the equipment and processes they are responsible for. The key to success in this position is problem solving and utilizing technical knowledge to get to the root cause of a problem rather than simply identifying symptoms using a collaborative teamwork approach. A successful Manufacturing & Controls Engineer II is self-motivated and a natural trouble-shooter who can react quickly under pressure, prioritize workload, and manage several tasks concurrently.

PERFORMANCE OBJECTIVES

Support New Product Development. Create and develop manufacturing system concepts to fulfill business needs. Work with design engineers and production to quote, specify, order, debug, receive, install, and runoff new production equipment. This includes, but is not limited to, assembly stations, work cells, test stations, material handling equipment, and packaging for new products/new processes. Be able to write and edit labview programs. Integrate new or replacement hardware into the labview code (e.g. Data Acq, cameras). Work with the IT department and SQL databases to integrate process data collection. Support the new product development process through PFMEA, DFM, and CAPP activities to ensure safety, quality, delivery, and cost targets are met. Document procedures, processes, and best practices to support the new equipment.
Maximize Operations Production and Efficiency. Maintain the current systems and equipment through analysis, troubleshooting and improvement. Perform the work needed to maximize production and efficiency. Implement/modify manufacturing processes to fulfill business needs. Work with production employees to continually improve production operations, system maintenance and design concepts through coaching, equipment design/modification/selection, training, and participation in PPI activities. Communicate and assist the manufacturing aspects of the current production operations. Assign and/or perform the work needed to maximize production and efficiency. May supervise Engineering Technicians and ME Interns.
Upgrade Material and Equipment. Work with advanced engineering and equipment suppliers to determine designs and configurations for new equipment and upgrades in conformance with company specifications and quality standards. Preparation of financial analysis for capital expenditures for tooling and equipment needed in support of existing product lines or processes. Monitor and control all phases of new equipment construction from design approval through implementation on factory floor and control equipment costs during this process.
Demonstrate Project Management and Technical Expertise. Demonstrate your technical expertise in project management including, but not limited to; scheduling, tracking, team assignments, allocation of resources, status reports, facilitate effective problem solving, “selling” of new and innovative concepts. Technical resource for specific manufacturing methods and/or philosophies.Contribute significant technical support for large scale projects and existing manufacturing operations.
Collaborate with Other Departments. Interface between Design and Production to ensure designs are acceptable for manufacturing, equipment is designed in accordance with the designs presented and the equipment will work with the equipment we currently have. Work with peers and other support personnel with specifics to training on production equipment, problem solving, and preventive maintenance.
Strong Team Player and Contributor. Able to work well with colleagues and produce results within a fast-paced and high pressure atmosphere. Combine strong attention to detail with an orientation towards results/execution.

ADDITIONAL DETAILS:

MINIMUM QUALIFICATIONS

B.Eng in Manufacturing or related Engineering required.
Relevant experience working in a production environment.
Proficiency in philosophy and techniques of several of the following: cellular manufacturing, self-directed work teams, problem solving, 5S, pull systems, mistake proofing, SMED, Kaizen, change management, ergonomics, TQM, learning organizations.
Working knowledge of Statistical Process Control techniques.
Proficiency of electrical and mechanical machining equipment, is able to read blueprints, wiring diagrams, and schematics, and is capable of setting up and monitoring preventive maintenance systems. Also capable of troubleshooting and performing minor repairs to equipment.
Effective problem solving, judgment, and independent thinking skills for troubleshooting, repair, and recognition of acceptable or unacceptable product quality.
Must have strong interpersonal skills to effectively communicate with other functional areas as follows: Quality Assurance, Design Engineering, Purchasing and Inventory Control, Scheduling, and Shipping/Receiving.
Able to handle frequent interruptions, meet tight deadlines, and handle conflict in an effective manner.
Experience with Microsoft Office products.
Experience in PLC programming i.e. Allen Bradley , Siemens, Modicon, Mitsubishi is advantageous",3.5,"HUSCO International
3.5","Runcorn, England",-1,1001 to 5000 Employees,1985,Company - Private,Transportation Equipment Manufacturing,Manufacturing,$100 to $500 million (USD),-1
Data Engineer,-1,"Data Engineer – Negotiable Salary – Plus Benefits – London – J9198

If you love working with big data and wish to influence product decisions, look no further.
This opportunity has arisen for a formidable game changing organisation which has touched all walks of life with no signs of abating.

Role and Responsibilities
• Manage data warehouse plans for a product or a group of products.
• Build data expertise and own data quality
• Define and manage SLA for all data sets
• Strong communication skills
• Design, build and launch new data models
• Undertake allocated areas of ownership.
• Identify and communicate data driven insights.
• Identify deliverables
• Identify gaps and inconsistencies
• Work with internal clients
• Work with data infrastructure

Qualifications, Experience & Skills Required
• Educated to degree in a numerate subject i.e. Computer Science or Mathematics.
• Experience in the data warehouse space
• Experience with programming languages, Python advantageous
• Ability to write efficient SQL
• Ability to analyse data
• Design, build and launch new data extraction
• Hands on and deep experience with schema design
• Able to managing and communicating data warehouse plans
• Dimensional data modelling experience

If you fit the above job description please contact Roisin McCarthy on 01256 314 660 or email her on rmccarthy@datatech.org.uk. Please be advised that we can only accept candidates who have the right to work in the UK.

Alternatively, you can refer a friend or colleague by taking part in our fantastic referral schemes! If you have a friend or colleague who would be interested in this role, please refer them to us. For each relevant candidate that you introduce to us (there is no limit) and we place, you will be entitled to our general gift/voucher scheme.",-1,Datatech Analytics,"London, England",-1,-1,-1,-1,-1,-1,-1,-1
Invivo Lead Engineer,-1,"AstraZeneca is currently looking for a lead engineer whose passion for modern development practises is used on a daily basis driving a global team of engineers forward while working in a sophisticated DevOps environment covering a wide range of user experiences (physical and virtual).

An outstanding opportunity for a skilled lead with a passion for modern software development practices (CI/CD/automated testing/deployment) to advance the development practices in a science field where IT has not yet been fully realised to build a bespoke integrated software framework (client based/cloud/compute/COTS) to enable scientists to study diseases in revolutionary new ways!

At AstraZeneca, we put patients first and strive to meet their unmet needs worldwide. To help with this goal we are looking for a strong individual to lead our engineers in a platform team within Solutions Delivery in Early Sciences. You must also enjoy influencing and engaging with teams in multiple continents and doing the right thing but understanding other teams have different priorities!

This role requires someone that can and has coded daily, is self-motivated, and has a passion for how you do software development as well as what you build. Well rely on you to bring your technical acumen to help the team continue to deliver elite solutions but also to grow regards development and delivery methodologies. If you are swift to action, confident to lead, willing to collaborate, and curious about what science can do, then youre our kind of person.

Instrumental in building up a world class IT environment to support this business area as well as working closely with scientists and platform members to enable technology covering animal welfare, experiment planning, data capture (both rich meta data & raw data), data analysis and data exposure to AI/DL. Information will have to be continually gathered and managed as users move along the work chain and be exposed outside of the platform as the need arises. As lead engineer, accountable to ensure we have the right technology to enable all these business functions to function efficiently and accurately by crafting a modular, expandable and flexible framework (covering both systems and information) to cope with the fast scientific changes that occur in this field.

You will progress from engineering a number of siloed solutions to a complete integrated ecosystem and continually adding new capabilities. It must fit the business needs by using technology that best fits the solution and building it so that it is operationally sustainable in the long term, even when they add new requirements each year. This science field will involve real time data capture and doing the experiment later will not be an option so robustness is critical.

What youll do

As part of our global development team working seamlessly with the new DevOps lead manager in Chennai and helping them to push to a DevOps CI/CD automated testing & delivery model by bringing ideas, working practices and technology that you know works. A key driver and enabler in that transition.
Working with stakeholders and team members to understand and estimate requirements. You should practice your own high standards with regards software development practices. The software ecosystem will contain significant custom development, but also existing in house solutions and COTS. You will push forward an API centric approach removing software duplication to deliver IT efficiency but also a seamless approach to information creation by the users. Responsible to ensure COTS systems are seamlessly integrated into our IT ecosystem from an end user perspective, ensuring full integration and ensuring you get the benefits of available solutions (we need to keep current science progressing) as well as enhancing the user experience with custom solutions.
Skill and Capabilities:-


We consider individuals in this role to be our world-class Software Engineers. At this level a software engineer is capable of working in multiple spaces and is likely to be the most experienced and skilled engineer on the team. Learning new technology is also a key part of this role. However, you must have deep technical skills. The person who joins us will have the following skills
Strong proficiency in multiple software programming languages like Java, .NET, C, as well as scripting languages like Python, VBA Script.
Experience with process tools like GIT, JIRA, Confluence and CI/CD tools
A drive to raise the bar regards automated software delivery and testing
Experience with working with multiple databases Oracle, My SQL, SQL Server
Experience of containerisation and cloud computing services like AWS.
Experience with Rest API and services, general API design inc. tools like swagger, and multiple application integration
Experience of delivering and supporting software in a DevOps environment
Experience leading teams, delivering and supporting solutions
Experience with Monitoring tools like Splunk and AppDynamics Experience with ITSM toolsets like ServiceNow, BMC Remedy or similar
Exposure to analytics tools like Spotfire, Power BI
Exposure to commercial off the shelf systems like LIMS, eLN
Excellent Problem solving and adaptability
Passion to learn and drive forward with new technologies
Working with fast-moving research and informatics environments
Why AstraZeneca?

At AstraZeneca when we see an opportunity for change, we seize it and make it happen, because any opportunity no matter how small, can be the start of something big. Delivering life-changing medicines is about being entrepreneurial - finding those moments and recognising their potential. Join us on our journey of building a new kind of organisation to reset expectations of what a bio-pharmaceutical company can be. This means were opening new ways to work, pioneering cutting edge methods and bringing unexpected teams together. Interested? Come and join our journey.

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, sex, gender, gender expression, sexual orientation, age, marital status, veteran status, or disability status. We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform crucial job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.",4.1,"AstraZeneca
4.1","Macclesfield, England",-1,10000+ Employees,1913,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$10+ billion (USD),-1
"Data Engineer, Application",-1,"Our Technology team is one of the best in the business and is the fuel behind Adthena’s platform. From patented machine learning methods, to developing an award-winning application, our Technology team is continuously innovating and enabling technology to solve real problems for our customers. We are looking for a proficient Data Scientist who is excited about working with some of the most talented data scientist in the industry to build amazing technologies and develop their career to be the best at what they do.
Minimum Qualifications
Bachelor degree in Computer Science, similar technical field of study or equivalent practical experience.
Commercial experience developing Spark Jobs using Scala
Commercial experience using Java and Scala (Python nice to have)
Experience in data processing using traditional and distributed systems (Hadoop, Spark, AWS - S3)
Experience designing data models and data warehouses.
Experience in SQL, NoSQL database management systems (PostgreSQL and Cassandra)
Preferred qualifications
Commercial experience using messaging technologies (RabbitMQ, Kafka)
Experience using orchestration software (Chef, Puppet, Ansible, Salt)
Confident with building complex ETL workflows (Luigi, Airflow)
Good knowledge working cloud technologies (AWS)
Good knowledge using montinoring software (ELK stack)
Motivated problem-solving skills, ability to bring ideas forward and adapt solutions to complex engineering challenges
Responsibilities
Builds services/features/libraries that serve as a definitive examples for new engineers and makes major contributions to library code or core services
Design low risk Spark process and write effective complex Spark jobs (data processes, aggregations, pipeline)
Design low risk APIs and write complex asynchronous, highly parallel low latency APIs and processes
Work as part of Agile team to maintain, improve, monitor Adthena's data collection processes using Java and Scala
Write high quality, extensible and testable code by applying good engineering practices (TDD, SOLID) using Adthena's Engineering Practices
Understand and apply modern technologies, data structures and design patterns to solve real problems efficiently
Understand the Adthena's data architecture and uses appropriate design patterns and designs complex database tables
Support TA and Data Science team to help deliver and productionise their backlog/prototypes
Take ownership and pride in the products we build and always make sure they are of highest standard
Be empathetic towards team members and customers
Technologies We Use
Languages: Java, Scala, JavaScript (React, Backbone), SQL and scripting using Bash and Python
Frameworks: DropWizard, React, Akka and Play Framework (Scala)
Databases: PostgreSQL, AWS(S3), Redshift, Redis, MongoDB, Cassandra
Technologies: RabbitMQ (messaging), Quartz scheduling, Docker and Kubernetes
CI/CD: TeamCity, Jenkins
Source Control: Git (GitHub)
Other Tools: IntelliJ IDEA, Jira, Grafana
About the Data Team
Athena's data team is a market leader in developing complex ETL and machine learning solutions.
With published authors and award winning data scientists who contribute some of the major machine learning and distributed data technologies such as Apache Spark, we are a friendly, passionate group of engineers making a career out of building great software for our customers.

The Adthena data team is dealing with hundreds of millions of data points every day, generated from over two thousand data processes running through workflows, huge distributed computations in spark, streaming data coming in twenty-four hours a day at hundreds of times a second.

As a Data Engineer, you will be working across our entire stack, so a real passion to drive the product and technology forward is something that we value. Your responsibilities will include helping with a vision for the future architecture of this complex data system, adding innovative ideas that use the latest cutting edge technology. You will work closely with Web and Data Science teams to deliver user-centric solutions to our customers and become an expert in developing high quality technical solutions.

Our engineering culture is underpinned by sharing knowledge, coaching and growing together. You will have the opportunity to explore / innovate new technologies, mentor engineers and lead Technology initiatives. You will enjoy this role if you love writing code, learning cutting edge new technologies, solving problems and winning as a team.

About Adthena
Adthena’s mission is a world of search transparency where precise ads connect marketers to consumers. This statement is key to our ethos here at Adthena and is backed by our Whole Market View technology, a dynamic, AI-driven, data model that is unique for each advertiser, representing their entire relevant search landscape. Powered by our patented machine learning technology, Whole Market View provides the comprehensive data scope and quality required by the world’s leading advertisers to precisely assess competitive opportunities at scale across their entire market, without limitations. We index information hourly, processing over 10TB of new data, 500 million adverts and 200 million keywords across 15 different languages each day. The segmented data is presented in an intuitive format, helping digital marketers to understand their landscape and acquire more customers. The technology has also won a number of awards for its ease of use and value added to clients including: Best Search Software Tool at the UK Search Awards 2016, Technical Innovation of the Year at the Drum Search Awards 2017, Best Search Technology of the Year at the Biddable Media Awards 2017 and Best Tech Platform at the DADI awards 2017. Adthena was founded by Ian O’Rourke and is backed by Mel Morris, the entrepreneur behind Candy Crush and former chairman of King.com.

Vision Statement
A world of search transparency where precise ads connect marketers to consumers

Mission Statement
Empower marketers to optimally reach, acquire, and retain consumers with unique data-driven search intelligence.

Core Values
Deliver Remarkable Quality
Get Shit Done!
Freedom with Responsibility
Smart and Always Improving

Things that make Adthena Unique
Machine-Learned Whole Market View
AI-Driven Data Segmentation
Automated trend detection & monitoring technology
Built for Client Value and Outcomes
World Class Customer Success",4.4,"Adthena
4.4","London, England",-1,51 to 200 Employees,2012,Company - Private,Enterprise Software & Network Solutions,Information Technology,$10 to $25 million (USD),-1
Data Engineer,-1,"Data Engineer (Data Edge)*
Location – client sites or remote
Day rate – market rate
Clearance – SC or DV Clearance
Outside IR35
Contract period – initially 6 months with extensions or options to become permanent
You will need to have or be eligible for the appropriate security clearances. This is a contract role outside of IR35. Initial expected deliverables are estimated to take 6 months to deliver.

We are looking for a Data Alchemist to join our client, an exciting and fast-growing startup who already have some great contracts in place, on a contract or permanent basis.

This is a brilliant opportunity to join a team of individuals who are dedicated and passionate about what they do. Embracing VR and modern tech. Big data,and they're after you!

The foundation to their success is the incredible value they unlock for their customers. They iterate fast, always work directly with the end user and build an intimate understanding of their customers' risks and requirements. That’s where you come in. You will be working right at the coal face, and become an essential member of the team. As a Data Alchemist you will enable their customers to make gold from lead.

The work is deeply technical and always changing. You will be using, customising and extending their products, integrating the best of open source and helping every customer solve their unique problems in a unique fashion.

You will do this while learning general lessons and developing and prototyping products that make them even better value for the next customer!

They are a fully remote organisation but their most important work happens face to face with their customers. You will represent them to the customer and as a valued member of the team you will be their advocate, guiding leadership and the off-site devs in what the customers need.

You will also be contributing your own valuable expertise to solving those problems. They make solving their customers' problems their problem and the kind of work you will get involved in will be profoundly rewarding and satisfying.

Most customer facing work is onsite at the client sites in London. This will make up 50-75% of your work. Otherwise, they are a virtual and fully remote organisation. They meet in person often, because they enjoy each other’s company.

You must be based in the UK. Customer-facing work must be during normal office hours but the rest of it can be whenever you like. They do not expect employees to be on phones, chat or to respond to emails before 0830 or after 1730, Monday to Friday.

The desirables
They don’t care about qualifications. They need engineers who get things done. Who solve problems without creating new ones. You are a pragmatic technologist who is comfortable creating structure in always complex, always massive, and sometimes chaotic environments. You make Big Data look like small data.

The essentials
You need to be comfortable with a wide range of technical skills and able to learn new ones as required. To give you a flavour, some of the specific technologies that are often relevant include:
Typescript, ES6, ES7, Node
Elasticsearch, Postgresql
Python
Java
Unix
RabbitMQ, Kafka
Docker
AWS Services
Test-driven development and CI
Software craftsmanship
Reference ID: AMRDATA01

Contract length: 6 months

Job Types: Full-time, Contract

Salary: £500.00-£700.00 per day

Schedule:
10 hour shift
Experience:
Typescript: 2 years (Preferred)
Work remotely:
Yes",-1,COMXPS,"London, England",-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"We are working with a Data Analytics Software house who are now expanding their team with a Senior Data Engineer to join and have an influence on some of their new projects coming up.

Key Tasks:

Working within an Agile environment with 3 week sprints delivering quality data enhancements.
Design, develop & maintain scalable insightful data-marts and tables which will in turn provide data model, dashboards & reports.
Working with product, development, & scrum teams
Provide accurate & timed data that is trusted and understood by the business.

Key skills required:

Strong SQL experience (5+ years)
Experience with NOSQL DBs, both Elastic and Cosmos currently in use.
Worked within in an Agile/Scrum environment
Previous experience working for a SAAS (desirable)

If you want to hear more please apply and let's set up a confidential chat

1647",-1,Maxwell Bond,"Manchester, England",-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Data Engineer | London | £40,000 – £55,000

Jonothan Bosworth Recruitment Specialists are currently looking for a Data Engineer to join a leading Global IT company to sit within their Digital team.

This is a great job opportunity to join a company who invest in their staff offering technology forum and discussions, benefits package, pension scheme along with a friendly working environment.

You must be eligible for SC Clearance for this role

As Data Engineer you will sit within the Analytics Practice that helps clients with all aspects of analytics from developing a client’s insights-driven strategy, through to designing and implementing systems of insight to deliver the strategy.

The data engineering teams apply a range of techniques in the development, delivery and on-going management of analytics services and solutions that solve complex business issues though predictive analytics and machine learning, advanced visualisation, data warehousing, big data and business intelligence.

Data Engineer | BI Developer Job responsibilities:

You will build data fabrics that gather, assess, integrate, prepare, manage and assure the quality of data to support analytics and other workloads and patterns

Work in multi-disciplinary teams, assist with developing system requirements, designing, prototyping, and testing custom technology solutions, and supporting system implementation

Participate in business development providing technical input and meeting with clients to secure new business

Design and develop proof of concepts and deliver client demonstrations

Support the development of client bids and presentations of proposals

Pre-requisites for Data Engineer | BI Developer:

You will have around 3 years of industry experience of: developing data pipelines using ETL and data preparation tools; and data warehouses/data marts

Experience of building data pipelines with SQL Server Integration Services (SSIS), Azure Data Factory, Azure Logic Apps, Azure Event Hubs, and Azure IoT Hubs

Experience in writing advanced queries and transformations with Transact-SQL (T-SQL)

Experience with Dimensional Data modelling for data warehouses, data marts and other analytical stores, plus table structures, and logical and physical database design

Experience with designing and developing data cleansing routines

You will have a Degree level or equivalent

Experience of SDLC processes and methodologies

Microsoft BI (Business Intelligence) certification is desirable along with Power BI experience

*** This role has SC clearance as mandatory due to the nature of the work. To apply, you must be willing and able to undergo the UK’s vetting process. Non-UK nationals applying for vacancies where a security clearance is a mandatory requirement, must meet the UK’s 5 year residency criteria in order for their application to be considered. ***

If you are interested, please send a copy of your CV to Claire at Jonothan Bosworth for more information.",5.0,"Jonothan Bosworth
5.0","London, England",-1,1 to 50 Employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Your role at a glance

The Data Engineer role has been created to design, create, develop, troubleshoot data pipelines through ETL and ELT and streaming which feeds our advance analytics processes. As well as to supply visualisations that provide knowledge to the organisation.

What you'll be doing
Plan and achieve sprint tasks from which the technical solutions will be created. These solutions will mean that the business can identify commercial opportunities or understand why they are needed
Support the data visualisation and data pipelines, ensuring that the services are up to date and the business can rely on them
Input into and manage our data artefacts, which will include planning, task completion, unit testing, peer review, release, meta data, data modelling and deployment. This will ensure that the right controls have been applied whilst maintaining the accuracy of our process’s and controls to maintain quality of work
Attend DataOps Design Authority meetings to provide input to our data value delivery methods. This will enable operational efficiency and foster collaboration
Responsible for the creation and input of meta data to sufficient levels, which will assist the business in understanding what they are able to do with it and give literacy
To convert user stories to technical tasks, translating the business goal to a technical one, allowing the delivery of a technical solution
To use a number of modern data platform tools set up in an agile delivery method to progress in a journey towards continuous integration and deployment of projects in the cloud
What we're looking for
Degree or higher education qualification in relevant subjects will be an advantage
Proven track record of delivering data engineering solutions including ETL development, data streaming, data Integration and analytics
Ability to communicate to all levels of stakeholders is essential
Ability to demonstrate the communication of complex data management issues to non-technical stakeholders a prerequisite
Knowledge of modern data paradigms within the cloud in order to enable a business to maximise its value from data
Wherescape, SSIS, ADF, Snowflake, PowerBI, Tableau, RBDMS: Oracle, MSSQL, Postgress , Databricks, Kafka, DataIQ and QuerySurge, Jenkins
Proven data, analytics and engineering experience
Demonstrates logical and lateral thinking considering all angles in their decision making
Communicates clearly and logically using ""story telling techniques"" simple language and visuals to suit the audience
Benefits

Whatever your role, we reward ability, performance and attitude with a package that looks after all the things that are important to you. Our employees have a wide range of benefits including a generous pension scheme, life assurance, 25 days’ holiday, private medical insurance, discretionary performance related bonuses, paid overtime, a variety of share schemes, discounts at both a huge range of high street stores and our own great products, your hard work will be rewarded when you join us.

About L&G

As a company, to be one of the world's largest Asset Managers, homebuilders, pension providers and insurances brands, we are diverse by our very nature. And we're a company that wants to use our diversity and influence to make society better in the long term - for everyone. To do this we need to be a company that welcomes everyone, where everyone can succeed. That means we're committed to building an inclusive culture in L&G where we can all perform at our best, no matter who we are, what we do or where we do it. So whoever you are, wherever you are, whatever your story, we'd love to hear from you.

About the business area

At Legal & General Insurance we look after our customers throughout life, death and everything in between so that you know that everything that’s important to you is protected. With over 180 years’ experience in providing Insurance policies, our customers trust us to be there and to do the right thing.

We are an equal opportunities employer and welcome applications from all suitably qualified persons regardless of their race, sex, disability, religion/belief, sexual orientation, gender identity or age.

For further information please contact Anastasia Jurcenko on Anastasia.Jurcenko@landg.com.

No agencies.",3.9,"Legal & General Group Plc.
3.9","Cardiff, Wales",-1,5001 to 10000 Employees,1836,Company - Public,Insurance Carriers,Insurance,$1 to $2 billion (USD),-1
Data Engineer,-1,"10x Future Technologies Services Limited (10x) is a B2B technology company that provides banks with a cloud-native core banking platform. Our aim is to transform banking - we believe in making banking 10x better for customers, banks and society. At the heart of our platform is the 10x SuperCore™. With its transformational end-to-end architecture, everything has been designed from first principles to bring forward a new way of banking. We enable our client banks to engage their customers with more timely, relevant and personalised experiences when it comes to managing money.

To support the achievement of our aim, we are looking for highly talented individuals to join our fast-growing team.

About the role

Data & Analytics is a first-class citizen of the SuperCore™ platform, designed from the earliest stages to be tightly integrated with the data infrastructure implemented by all the core services. This means, as a Senior Data Engineer working on the team, you’ll have the opportunity to design and develop an innovative system unlike anything else in the industry.

From day one you’ll be working on improving the capabilities of our data platform and providing value to our clients. From exposing data to analysts through data visualisation user interfaces to engineering our real-time machine learning pipeline, super-charging workflows for data scientists. We embrace the use of open-source software to achieve this, much of it at the bleeding edge of development.

In addition to writing and deploy software for the Data & Analytics platform, you will play an active role in the coaching and mentoring of junior team members. The role will also require your design input by supporting the Data and Analytics Team Lead through offering your domain expertise in data engineering to solve challenging problems. We are looking for a self-starter who looks for new ways of working, explores best practices and delivers imaginative approaches to communication challenges.

Requirements

Essential
Professional experience programming in Java.
Professional experience with big data technologies
Professional experience with Kafka (or another similar messaging system) within recent career history.
Professional experience with AWS or other cloud platforms
Has been responsible for code running in production in recent career history.
Fundamental understanding of database systems & trade-offs between different styles of database
Demonstrable high levels of integrity and desire to make a positive impact within the business and society
Working knowledge of microservice base architectures and able to have an in-depth technical discussion about its benefits and drawbacks
Desirable
Good understanding of machine learning concepts
Has experience of working within an agile environment
Benefits
25 days holiday and an extra day off on your birthday plus Bank/Public Holidays
Pension scheme
Private Health Care via AXA PPP, with the option to add your family
Life Assurance
Income Protection
Flexible benefits to suit your lifestyle via salary sacrifice
Enhanced parental policies, dependent on tenure
Regular company-funded socials
All the latest tech you need to enable you to deliver excellent output
You will also be eligible for any additional employee benefits that the Company may introduce in the future
More About 10x
Our home is in London but our 10x teams work around the UK and Australia provide our clients with deep and relevant experience amassed from multi-billion-dollar businesses, challenger brands, disruptors and start-ups.
At 10x you work alongside innovators and leaders in banking and financial services, big-technology and consumer-focused industries – proven practitioners who understand how to meet the evolving needs of businesses and consumers. Our engineers, product specialists and developers are leaders too, drawing on experience from within and outside financial services to deliver transformational new digital solutions. They work across API development, security, cloud-native engineering and payments technology and include UI and UX designers, technical architects and data experts.
We are driven by the belief that whatever we do as a business has to be done in the right way. Our three core values amid this are fundamental to our 10x approach: Transformation, Integrity and Impact.
Learn more at www.10xbanking.com

Equal Opportunities for All
Equality, Diversity and Inclusion are priorities for us here at 10x – we welcome and promote diversity amongst our people and if we are to solve the legacy problems for our clients and their customers around the world, our team has to represent the people we serve. We are committed to ensuring that all job applicants are treated equally. All applicants will be treated fairly and will be considered for employment without discrimination because of ethnicity, race, religion or belief, sex, sexual orientation, gender identity or gender reassignment, family or parental status, pregnancy or maternity, marital or civil partner status, national origin, age, veteran, neurodiversity status or disability status.
As part of the application process we may ask you to voluntarily provide information relating to your personal attributes for the purposes of reporting and monitoring only. The capture of this information will not influence the hiring process but will help us monitor progress against our diversity and inclusion ambitions.",4.0,"10x Future Technologies Services Limited
4.0","London, England",-1,201 to 500 Employees,2016,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Science Engineer,-1,"Echobox has access to very large granular private data sets and is currently only using a small part of this in end user products. You will work closely with our CTO to help push the boundaries of what the Echobox Artificial Intelligence is capable of achieving with this data.

Key Responsibilities
You will contribute to the development of prototypes that can be turned into end user products by the core development team.
You will assist in the customisation of the product for new customers and trial data analyses where required.
You will stay up to date with the latest advances in ML and AI.
About Echobox

We are a fast-growing, research-driven company building an artificial intelligence that helps online publishers overcome the challenges they face every day. Using novel machine learning techniques, we are revolutionising the publishing industry and have a track record of building things that others have ruled out as impossible. Leading names from around the world rely on our product every day, including The Times, Le Monde, The Guardian, Vogue and many more.

Our team is our best asset. We work with extremely smart and talented individuals, who all enjoy a high degree of responsibility and independence in structuring their work. To get a better insight into the kind of work we do, check out our open-source project on Github, our data showcases and our YouTube content on Microservices.

Do you think you have what it takes to be part of Echobox? We'd love to hear from you.

Requirements:

Minimum Academic Qualifications
2.1 degree in a STEM subject from a top tier university.
Required Skills and Experience
Fluent written and spoken English
A very strong understanding of classical statistics
A basic knowledge of different ML and AI methodologies and the desire to become an expert
Strong background in a programming language suitable for analyses (e.g. R, Python, Java, C#, C++)
A familiarity with Java (SE7+) and a desire to become an expert
An ability and desire to learn new skills quickly
Genuine passion for making the impossible possible
Preferred Skills
Strong knowledge or experience in one area of ML and AI.
Experience developing software as part of a team, e.g. DVCS, open source software projects.
Working knowledge of big data architectures, i.e. NoSQL, Hadoop etc.
Benefits:

Our employees enjoy free breakfast every day, coffee, drinks and snacks all day, everyday. Every Wednesday, we order food for our weekly team lunches where everyone gets together for an hour of fun. We have monthly team events (dinner, bowling, karting, poker nights, board-games etc.) for our team to get to know each other outside of work. Professionally, we host in-house conferences and an annual summer camp for all our global employees who are flown to and hosted in London. We ensure that all our employees also get pension contributions, the latest tech, generous annual leave and an amazing office with a balcony overlooking Notting Hill.",4.5,"Echobox
4.5",London,-1,1 to 50 Employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"I'm on the lookout for a Data Engineer who is working in an AWS environment, programming in Python, sounds like you?

Well… you have a chance to be joining an award-winning Insurtech company who are going through a very exciting digital transformation journey. They have different brands that specialise in different parts of insurance and they want to make those digital leaders in the industry. One brand is even being estimated at half a billion by 2022, which is focussed on machine learning and AI, sounds interesting, right?

You'll be getting the best of both worlds, you have the name of a large organisation but working in a start-up mentality.

You'll have the opportunity to work and scale their forever growing AWS platform, Using Python3 and your strong data modelling experience to create production ready code, analysing both SQL and NoSQL databases and using your Data architecture experience to deliver logical data structures at enterprise and programming level.

They are very forward thinking and even onboarding remotely due to the current climate.

If you're interested in hearing further details, please apply below or give me a call on 07441391334.",3.7,"Linux Recruit
3.7","London, England",-1,1 to 50 Employees,-1,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Senior Data Engineer,-1,"Position: Senior Data Engineer

Reporting to: Director of Data

Contract type: Full Time, Permanent

About Cera

We are part of a rapidly growing ageing population that lacks a sustainable care infrastructure to support us to live longer, healthier, better lives to the end. At Cera Care, our mission is to empower people to live longer, healthier, better lives in their own homes. We don’t just care more, we care better. We want to be the UK leader in revolutionising affordable care for the better, for our care clients and society and the perfect coordination across care practice, data, science and technology is how we’ll get there.

About Data at Cera

Data has a critical role to play in two distinct areas. First, data about our operations, covering everything from hiring carers to the delivery of care, helps us to observe and understand how we are performing, what is working and what we could do to better deliver care. Second, data about client health, covering everything from their conditions to the health outcomes resulting from those conditions, helps us to observe and understand their experience but more importantly, it helps us to predict and prevent health deteriorations for those in our care.

About You at Cera

As an engineer in the Data Platform Team, you’ll help us realise the value of data in both of the areas above. You’ll contribute to Cera’s mission by ensuring that if there exists data that helps improve the delivery of care or the health of our clients, that we can create or acquire it and make it easy to consume by people or product features as needed to realise it’s value.

This is the first senior data engineering hire in the team. As the team and capability grows, there’s an opportunity for you to mentor others, take an active interest in their development and be promoted into a leadership or principal engineer role (depending on your interests and capabilities).

What You'll Do

You’ll work with software engineers and system owners to understand and document where and how the data is created, influencing upstream to ensure quality and integrity at source where possible
You’ll engineer pipelines to collect and protect data from multiple sources sources (e.g. APIs, Google Drive, event delivery pipelines), into a single persistent storage solution that enables everything from simple reporting to ML-backed products
You’ll work with the CTO and Director of Data to make the data architecture and technology decisions needed to deliver in the present and set us up for the future by articulating our challenges, establishing selection criteria and evaluating options before opening for comment with other engineers and tech leads (e.g. via an RFC)
You’ll implement engineering operational excellence /site reliability best practices for your data pipelines, including defining and instrumenting SLIs and setting SLOs that become a part of our team OKRs
You’ll drive your own development, and will be supported in doing so, ensuring steady progress on your path to mastery as a data engineer

Who you are

You’re committed. You’re committed to developing our ability to collect and protect data, making it easy to consume by people and our products, always ensuring it’s a source of value for the people in care operations and for the people in our care. You’re bold but thoughtful, able to thrive in a fast paced, complex data environment.
You’re a creator. You’ll apply your skills as a developer and aptitude for technology to innovate and find the right solutions for our data platform needs, challenging the status quo - there must be a better way. If it can be imagined, you make it possible.
You’re a connector. You work across product, engineering and operations to scope datasets and services that are critical to achieving our mission. You keep our carers and clients in mind, connecting their operational needs and health needs with your delivery pipeline.
You’re purpose driven. You care about the value your skills have to contribute to tackling one of societies greatest challenges: affordable care.

What you’ll need

5+ years experience developing data pipelines in a cloud based data storage and processing environment (e.g. Hadoop, Amazon AWS, Google GCP) including scheduling and orchestration (e.g. Airflow, Luigi or Celery for)
Ideally 2+ years developing event-based back end services for consumer facing features (e.g. Google PubSub, AWS SNS/SQS)
A high executional capacity in basic data engineering languages such python, NoSQL, bonus if experience in a big data language such as Scala
Experience working collaboratively with software engineers, product managers and designers in a product environment to establish what data to collect and how to collect it, to enable the insights and production features downstream
Bonus if you have a strong command of Domain-Driven Design principles, with experience applying it to software or data design at an enterprise scale
Passion for change

What’s it like to be part of the Cera team?

Our team is made up of academics, innovators, start-up accelerators and care experts, all connected by a vision to build a better future for care through the combination of best-in-class carers, empowered by technology.

You have the opportunity to join a purpose-driven company at the tipping point of transformation. You’ll play a key part in the evolution of Cera and make a real impact, now and in the future.",4.5,"Cera Care
4.5","London, England",-1,1001 to 5000 Employees,-1,Company - Private,Health Care Services & Hospitals,Health Care,Unknown / Non-Applicable,-1
Data Engineer,-1,"Data Engineer/ Data Science Engineer/ Analytics Engineer/ Insights Engineer/ Data/ Elasticsearch/ Elastic Search/ ELK/ Kibana/ AWS/ Amazon Web Services/ London
A well-established health-care organisation we partner with, have reached out to me advising me they're on the lookout for a Data Engineer to join their growing London office, on a permanent basis.
You will be reporting directly into the CTO working on exciting projects. You will become part of a small agile team within a well profitable and established business. You will be a key member of the team taking the company to the next level helping build the world leading management platform.
Details;
London based (part time remote available)
£45,000 - £50,000 p/a
Free health-care insurance
Company bonus scheme (10% salary)
Other benefits included
Skills;
Strong knowledge and experience with Elastic stack best practises
Elasticsearch API experience
Experience working with Kibana and being able to create advanced searches, visualisations, and dashboards
Experience working with AWS
Experience working within Agile environment
Collaborative team member with strong communications skills
If you feel this would be of interest, please send me over the latest version of your profile and I will give you a call asap. If this is not of interest, but are looking please send me over the latest version of your CV and I will give you a call-in regard to other opportunities.
Data Engineer/ Data Science Engineer/ Analytics Engineer/ Insights Engineer/ Data/ Elasticsearch/ Elastic Search/ ELK/ Kibana/ AWS/ Amazon Web Services/ London",3.8,"Explore Group
3.8","London, England",-1,51 to 200 Employees,2005,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Big Data Engineer,-1,"Big Data Engineer ( Spark / Python / Machine Learning )

Big Data Engineer is required to join a fast-paced large non-corporate company based in a stunning Central London office. This opportunity is for a Python / Spark Big Data Engineer, with an interest in machine learning to join one of the most prestigious companies in their industry. You will be using your Big Data skills to process large amounts of static and real-time data, including analysis and dashboarding.

What’s in it for you as the Big Data Engineer:

The Big Data Engineer will have a competitive salary of up to £95,000 plus benefits.

Exposure to a cutting-edge machine learning environment and latest technologies
Fast-tracked career opportunities and a personal development budget
Flexible working once you’re settled in
An unrivalled benefit and bonus scheme, including private healthcare

Key Skills and Responsibility of the Big Data Engineer:

The ability to handle and manage both real-time and static data
Highly skilled in the Hadoop ecosystem, Spark and Hadoop
Strong programming experience with Python and associated libraries (pandas, numpy, scipy, scikit-learn)
Worked extensively on SQL and a variety of database technologies.
Working with APIs such as REST or MQTT
Excellent communication and team-working skills

The following would be a great plus, but not essential:

Programming experience with Scala, Java
Previous experience with AWS systems
Knowledge of Machine learning solutions, deep learning
IoT experience
Client-facing experience

This is an unrivalled opportunity to join an innovative organisation in a tech driven company as a Big Data Engineer.

To apply for this position please send a recent CV to: georgia.bright@venturi-group.com

Keywords – Big Data Engineer, Machine Learning, Data Modelling, Hadoop, Python, Scala, AWS, Spark, Amazon, Cloud AI, PIG, Big Data Engineer, Hadoop Machine Learning, Data Modelling, Python, Scala, AWS, Spark, Hadoop, Amazon, Cloud AI, PIG, IoT, Big Data Engineer, Machine Learning, Data Modelling, Python, Scala, AWS, Spark, Amazon, Cloud AI, PIG, Big Data Engineer, Machine Learning, Data Modelling, Python, Scala, AWS, Spark, Amazon, Cloud AI, PIG, IoT, Big Data Engineer, Machine Learning, Hadoop, Data Modelling, Python, Scala, AWS, Spark, Amazon, Cloud AI, PIG, IoT, Big Data Engineer, Machine Learning, Data Modelling, Python, Scala, AWS, Spark, Hadoop, Amazon, Cloud AI, PIG, IoT

Venturi (TVGL Inc.) is an equal opportunity employer and does not discriminate on the basis of age, color, sex (including pregnancy), gender, gender identity, genetic information, marital status, military/veteran status, national origin, ancestry, race, creed, religion, sexual orientation, transgender status, non-disqualifying physical or mental disability, domestic violence victim status, criminal or arrest record, unemployment status, or any other basis protected by applicable law.",4.8,"Venturi
4.8","London, England",-1,51 to 200 Employees,2009,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Lead Software Engineer,-1,"Are you an experienced Software Engineer who wants to join a leading cyber team within an evolving and dynamic organisation?

Due to the success of a number of strategic Gloucestershire based programmes, we are growing our Software Development team with creative and ambitious Software Engineers. With a primary focus on Java, your experience will cover different technologies within an agile environment

Different thinking for a Different world

Northrop Grumman is a leading global security company providing innovative systems, products and solutions to government and commercial customers worldwide. In Northrop Grumman’s rapidly growing UK Cyber and Intelligence business, we support our customers’ work to make the UK the safest place to live and do business, both physically and online.

Working with and alongside our customers, we use modern software engineering methods (Scaled Agile Development, DevSec Ops, Site Reliability Engineering, micro-service architectures) and cutting edge techniques (data science, Artificial Intelligence, Machine Learning) to tackle complex and challenging problems and deliver cost effective, reliable, supportable solutions.

Our solutions support complex analysis of substantial amounts of data, requiring state of the art ‘big data’, stream processing and cloud-based analytics, identifying and using ‘best of breed’ commercial and open source technologies and integrating them with our own software to meet customer needs quickly and efficiently.

At Northrop Grumman we pride ourselves on our ability to combine agile development with sound engineering and security practices to ensure that our solutions are robust and resilient; designed and built to start secure and stay secure against ever evolving cyber security threats. As well as designing for security, Information Assurance and legal / policy compliance, we actively assess products and services, identifying vulnerabilities and weaknesses that could be exploited by cyber attackers, and we create and run exercises to pit cyber security specialists against secure systems and each other.

We carry out research and innovation locally in the UK, with commercial and academic partners, and across our 85,000+ worldwide workforce.

How you will make a difference

For us, innovation is key and we have immediate opportunities for talented software engineers to join our team to help us develop and maintain a suite of applications.. We are in a phase of rapid growth and there are opportunities to develop your career with us to meet your aspirations.

You will be helping us to solve our customer’s problems within an agile team. You will have opportunities throughout the Software Life cycle from requirements capture through to R&D(Research & Development), implementation, automation and test in a wide range of technologies.

As a Lead Software Engineer you will have had responsibility for the design and delivery of parcels of work;leading teams and should be used to working with customers. You will be able to deploy applications in a controlled, repeatable way and be developing technical specialisms in frameworks and/or tool sets. Experience of mentoring or line management would be advantageous.

Key criteria required...

Experience in design, development, test and integration of quality software

Experience in Java and the use of object oriented design

Keen to learn a broad range of technologies on the Java stack

Experience of technical leadership

Also, we’d love it if you have experience of...

Agile/Scrum methodologies using tools such as Confluence and Jira

DevOps approaches and associated tools such as Ansible, Docker and Jenkins

Messaging and Routing Technologies such as NiFi and Kafka

Cloud-based architectures

Linux operating systems (Red Hat Enterprise Linux Server/CentOS)

Different programming languages, such as: Java, C, C++ and Python

Working with open source products

Supporting business development through contributions to customer proposals and R&D projects

You will enjoy a growing career as we work collaboratively to innovate the world of cyber security.

Additional information for your consideration...

You must be able hold UK Government clearances

Opportunities exist across the UK to enhance your career progression

Being a part of Northrop Grumman gives you the opportunity to use your skills to make a difference in our mission of enabling global security. Our company grows because of our employees' dedication and commitment to achieving our mission, something we always remember. In return for working for us you will have access to a benefits package that provides you with flexibility to balance your professional career with your personal life, health & well-being benefits, discount schemes, pension benefits and investment in your future development.

We are committed to equality and diversity in our workplace. Northrop Grumman provides equal employment opportunities to all employees and applicants without regard to an individual’s protected status, including race, ethnic origin, colour, nationality, national origin, ancestry, sex/gender, gender identity/expression, gender reassignment, sexual orientation, marriage/civil partnership, pregnancy/maternity, religion or belief, creed, age, disability, genetic information, or any other protected status or characteristic.",3.8,"Northrop Grumman UK
3.8","Cheltenham, England",-1,10000+ Employees,1939,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
"Data Engineer, France",-1,"Core Group are looking for 2 x Data Engineers for ongoing work in France.
Duration: Initial duration is 2-3 weeks work but further assignments afterwards.
Duties: Cat6a installation. Terminating, Testing cabinets.
Package: Up to £220 per shift, accommodation & travel paid for. £20 food allowance daily.
Must have: ECS Card, Tools, Driving Licence and valid passport for travel.
Call 01628362652 for more information.
ASAP STARTS!",5.0,"Core Group Ltd
5.0","Milton Keynes, England",-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Senior Data Engineer,-1,"Location
Coventry CV1 2WT, Darlington DL1 5QE, Sheffield S1 2FJ
About the job
Summary
The Education and Skills Funding Agency (ESFA) brings together the existing responsibilities of the Education Funding Agency (EFA) and Skills Funding Agency (SFA), creating a single funding agency accountable for funding education and training for children, young people and adults.

The ESFA:

• is accountable for £58 billion of funding for the education and training sector, providing assurance that public funds are properly spent, achieve value for money for the tax payer and deliver the policies and priorities set by the Secretary of State.

• regulates academies, FE colleges, employers and training providers, intervening where there is risk of failure or where there is evidence of mismanagement of public funds.

• delivers major projects and operate key services in the education and skills sector, such as the National Careers Service, the apprenticeship service and the National Apprenticeship Service.

ESFA’s Data Science Service provides end-to-end data services including data capture, data management, governance and data visualisation, analytics and modelling and digital insight to the ESFA, DfE and wider Education sector. As an organisation, we are committed to developing our people and the next generation of data and technology leaders.
Job description
Our Data Engineers innovate to design and deliver data products and services, integrating them into systems and business processes within the agency in adherence to Data Governance and architecture protocols.

You will be user focused, understand the importance of data, data management, data quality, lead on providing effective stakeholder service management, develop audit and metric reporting and have a drive for continuous improvement.

You will use your technical skills to design and implement data management solutions. You will work to deliver automated services that are reliable and secure, working with data architects, data stewards, Business Analysts and data scientists.

As a Senior Data Engineer, you will lead and inspire data engineers in finding more innovative ways to improve service operations continuously challenging approaches for optimum delivery of solutions.

Responsibilities
• Collaborate and implement data management systems that link data from multiple systems and platforms.

• Implement appropriate technologies to deliver resilient, scalable and future-proof data solutions, data integration and data process-flow systems to ensure secure operation, integrity of systems and availability. Ensure the data infrastructure remains performant, available and secure at all times, developing contingency and failsafe platform solutions.

• Design, write and iterate code from prototype to production-ready states, managing relationships with subject matter experts to make sure content is accurate and of quality.

• Collaborate with others to review and challenge specifications and where appropriate promoting the best solution design.

• Use agreed standards and tools to design, code, test, correct and document moderate to complex programs and scripts from agreed specifications and subsequent iterations.

• Implement industry recognised data modelling patterns and standards and where necessary reverse engineer data models from a live system.

• Take a lead role in facilitating collaboration and lead effective communication with all stakeholders to support design, build and delivery to meet the user needs

• Effectively translate and accurately communicate across technical and non-technical stakeholders as well as facilitating discussions within a multidisciplinary team.

• Provide constructive feedback to your colleagues to improve everyone’s skills and working relationships.

• Mentoring and guiding more junior members of the team.

• Support the data engineering as a profession within DataOps and the wider department

Skills and Experience

It is essential that you have:

• the ability to use advanced SQL and SISS (or ETL): queries, stored procedures, design, write and iterate code through to deployment and optimisation

• use of concepts such as, metadata, indexing, modelling and master data management

• experience in communicating complex language and processes and making them simple to understand to a non-technical audience

• experience in negotiating requirements: design, build and test data products that are complex or large-scale

• knowledge and/or experience in data profiling and system analysis and presenting insights to support the end use of the data, using for eg Power Bi

• experience in defining and applying quality and key performance indicators and user feedback to define and improve data and data management systems.

It is desirable that you have:

• working knowledge with Azure SQL databases
• SSAS and DAX (you will have the opportunity to gain exposure to SSAS, DAX, Data Warehousing, cubes analysis and Dimensional Modelling)
• certification in data management or similar industry professional certification.
• an understanding of data protection legislation eg. GDPR
• an understanding of agile approaches and experience of working in agile teams
• experience in developing or engaging with professional communities
• knowledge of best-practice data engineering standards and maintaining those standards

Desirable skills and experience will only be considered in the event of a tie, in order to make an informed decision.
Benefits
Applicants currently holding a permanent post in the Civil Service should note that, if successful, their salary on appointment would be determined by the Department’s transfer / promotion policies.

As a member of the DfE, you will be entitled to join the highly competitive Civil Service Pension Scheme, which many experts agree is one of the most generous in the UK.

You will have 25 days leave, increasing by 1 day every year to a maximum of 30 days after five years’ service. In addition, all staff receive the Queen’s Birthday privilege holiday and 8 days’ bank and public holidays.

We offer flexible working arrangements, such as job sharing, term-time working, flexi-time and compressed hours.
As an organisation, which exists to support education and lifelong learning, we offer our staff excellent professional development opportunities.
Things you need to know
Security
Successful candidates must pass a disclosure and barring security check.
People working with government assets must complete basic personnel security standard checks.
Selection process details
This vacancy is using Success Profiles, and will assess your Strengths and Experience.
Application

This vacancy is using Success Profiles, and will assess your Strengths, Experience and Skills.
Candidates successful at sift will be invited to a video interview.

We will assess your experience in your CV and personal statement based on the essential skills and experience in the advert outlined in the responsibilities section.

Interview

We will assess you against the essential skills and experience in the responsibilities section with strengths also being considered at interview.

Sift and interview dates to be confirmed

Other Information

If successful and transferring from another Government Department a criminal record check maybe carried out.

In order to process applications without delay, we will be sending a Criminal Record Check to Disclosure and Barring Service on your behalf. However, we recognise in exceptional circumstance some candidates will want to send their completed forms direct. If you will be doing this, please advise Department of Education of your intention by emailing Pre-Employment.Checks.DFE@education.gov.uk stating the job reference number in the subject heading.

Department for Education do not cover the cost of travel to your interview/assessment unless otherwise stated.

A reserve list may be held for a period of 6 months from which further appointments can be made.
Candidates will be posted in merit order based upon location preference. Where more than one location is advertised you will be asked to state your preferred location.

New entrants are expected to join on the minimum of the pay band. Applicants who are successful at interview will be, as part of pre-employment screening subject to a check on the Internal Fraud Database (IFD). This check will provide information about employees who have been dismissed for fraud or dishonesty offences. This check also applies to employees who resign or otherwise leave before being dismissed for fraud or dishonesty had their employment continued. Any applicant’s details held on the IFD will be refused employment.

Terms and conditions of candidates transferring from ALBs and NDPBs

Bodies that are not accredited by the Civil Service Commission and are not able to advertise at Across Government on Civil Service jobs will be treated as external new starters and will come into DfE on modernised terms and conditions with a salary at the band minimum.

Bodies that are accredited by the Civil Service Commission but do not have civil service status will be offered modernised terms and will not have continuous service recognised for leave or sickness benefits. Salaries should be offered at band minimum, but there is some flexibility where this would cause a detriment to the individual.

Bodies that are accredited by the Civil Service Commission and do have Civil Service status will be treated as OGD transfers. Staff appointed on lateral transfer will move on to pre-modernised DfE terms (unless they were on modernised terms in their previous organisation). Staff appointed on promotion will move on to modernised DfE terms. Staff will transfer over on their existing salary (on lateral transfer) and any pay above the DfE pay band maximum will be paid as a mark time allowance. Staff moving on promotion will have their salaries calculated using the principles set out in the attached OGD transfer supplementary information.

Reasonable adjustment

If a person with disabilities is put at a substantial disadvantage compared to a non-disabled person, we have a duty to make reasonable changes to our processes. If you need a change to be made so that you can make your application, you should:
Contact Department of Education via centralrecruitment.operations@education.gov.uk soon as possible before the closing date to discuss your needs. - Complete the “Assistance required” section in the “Additional requirements” page of your application form to tell us what changes or help you might need further on in the recruitment process. For instance, you may need wheelchair access at interview, or if you’re deaf, a Language Service Professional.
Any move to Department for Education (DfE) will mean you will no longer be able to carry on claiming childcare vouchers.

Feedback will only be provided if you attend an interview or assessment.
Nationality requirements
Open to UK, Commonwealth and European Economic Area (EEA) and certain non EEA nationals. Further information on whether you are able to apply is available here.
Working for the Civil Service
The Civil Service Code sets out the standards of behaviour expected of civil servants.

We recruit by merit on the basis of fair and open competition, as outlined in the Civil Service Commission's recruitment principles.
The Civil Service embraces diversity and promotes equal opportunities. As such, we run a Disability Confident Scheme (DCS) for candidates with disabilities who meet the minimum selection criteria.
Apply and further information
Once this job has closed, the job advert will no longer be available.
You may want to save a copy for your records.
Contact point for applicants
Job contact :
Name : Data Science Recruitment Team
Email : ds.pmo@education.gov.uk

Recruitment team :
Email : advertsrecruitment.dfe@education.gov.uk
Further information
The Department for Education’s recruitment processes are underpinned by the Civil Service Commissioners Recruitment Principles, which outlines that selection for appointment is made on merit based on fair and open competition. If you feel your application has not been treated in accordance with the values in the Civil Service Code and/or if you feel the recruitment has been conducted in such a way that conflicts with the Civil Service Commissioners Recruitment Principles, you may make a complaint, by contacting the Central Recruitment Team at the following address CentralRecruitment.Operations@education.gov.uk If you are not content with the outcome of your complaint you have the right to complain to the Civil Service Commissioners.
We encourage diverse candidates
Attachments
DfE Appeals Process.docx Opens in new window (pdf, 42kB)
DfE Terms & Conditions.docx Opens in new window (pdf, 55kB)
OGD Transfer Supplementary Information.docx Opens in new window (pdf, 132kB)",4.3,"Department for Education
4.3",United Kingdom,-1,1001 to 5000 Employees,-1,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Science Engineer,-1,"About Roke

Roke imagines a more secure world. A world where technology protects, rather than exposes. A world where expert engineers, consultants and business support staff collaborate to protect what matters most to our clients.

We are a friendly and flexible team with a culture of ‘time, trust and freedom’. The role may give the opportunity to work on client site, from the office, in shared workspaces or from home as necessary. We pride ourselves on listening to each other’s aspirations and accommodating wherever possible.

The Opportunity

Roke have a wide range of exciting opportunities for experienced Software Engineers with proven track record in Data Science, to join our Defence or National Security Business Units in the Hampshire area.

This role will expand your abilities through working alongside our wealth of specialist Data Scientists and Software Engineers on various projects, from rapidly prototyped research right through to high grade enterprise systems.

You could be developing data science solutions within one or more of our client side teams around the UK or working on our ground-breaking projects within the scenic grounds of our Romsey site.

If you'd like, you could also provide technical leadership to junior member, as well as, interacting with stakeholders during the development cycle. Just let us know your interests.

Our data analytics work encompasses all types of data, including structured and unstructured data (such as text and image). We use a variety of software, picking the best approach to suit the customers’ needs. For example, you might exploit your software expertise to solve big data or data streaming challenges using open source technologies.

Alternatively, you might use your statistical background to develop machine-learned models to classify data. Perhaps, you will specialise in data visualisation techniques in order to enable our customers to easily access the required information from their data.

Regardless, your projects will be diverse – working with varying clients, across a number of sectors, using a range of skills. Consequently, we are looking for individuals able to work flexibly across projects in different domains. You might apply your skills to rapidly prototype new approaches & solutions. Equally, you may apply them to complement or advance existing solutions.

Why We Want You

You will have data science expertise; however, as this is such a broad area we would consider experience in a subset of any of the following:

Large scale (‘big data’) data ecosystems, cloud infrastructure and analytic frameworks.
Machine learning and Deep Neural Net technologies
Techniques and toolkits for data cleansing, data preparation, data processing, fusion and analysis
Techniques and toolkits for combining data or analysing data streams in real time
Programming languages and techniques for visualising data

You enjoy growing your skills and those of your team by regularly learning about new technologies. Most importantly, you judge your achievements by the success and happiness of your team and its customers.

Roke also operates in the fields of network communications, network connectivity, autonomy and cyber and your familiarity with underpinning concepts in one or more of these areas would be beneficial but not essential.

Beyond your technical skills, you will be proactive and able to communicate effectively with a variety of internal and external stakeholders. You will work well alone or as part of a team. You will be curious and seek out the best approach/solution/tool for the job at hand.

Why You Should Join Us

We have a competitive salary and access to a number of additional flexible benefits, which will cover Health and Wellbeing, Savings and Protection & Life, Leisure and Entertainment.

Roke has a great community of groups with shared interests. These enable people to share ideas and be passionate about tools, technologies & techniques, which interest them.

We are committed to a policy of Equal Opportunity, Diversity and Inclusion. Our working environment is friendly, creative and inclusive. We will consider flexible working arrangements and support a diverse work-force and those with additional needs.

Security Information

Due to the nature of this position, we require you to be willing and eligible to achieve a minimum of DV clearance. To qualify, you should be a British Citizen and have resided in the UK for the last 5 years for SC and 10 years for DV. For more information about clearance eligibility, please see https://www.gov.uk/guidance/security-vetting-and-clearance.

High level clearance bonus is available and will be considered on application.",3.9,"Roke
3.9","Romsey, England",-1,201 to 500 Employees,1956,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"The OVO Group's purpose is to drive progress towards net zero carbon living. To reach Plan Zero, we need everyone to come together - not just as customers buying energy, but as members with a common goal. As part of this ambitious plan, our goal is to become the 'Best Employer in the UK' by 2030. If you think you could be the talent we're looking for, then come and join the adventure!

We launched in 2009 with a mission to change energy for the better. Since then, we've welcomed over a million members, planted a million trees, and set our sights on helping save the planet.

As a Group, we're working to become a net zero carbon business by 2030, while helping our OVO Energy members halve their carbon footprints at the same time.

Green energy and technology are great tools to fight the climate crisis with. But it's people power that will rewrite history.

So we're building a zero carbon team inside and out. Of people who share our values, feel inspired by our mission, and want to make change happen. When you work for OVO, it's not just a job. It's the work of a lifetime. And we want the sharpest minds to help.

Up for the challenge?

Where in the world of OVO will I be working?

Following OVO's acquisition of the SSE Retail Energy company earlier this year, the two companies are working hard to integrate their operations. Essential to this is the integration and rationalisation of their technical systems and data processing.

As a Software Engineer you will work closely with OVO and SSE Product, Tech, Data and Analytics, and Data Platform teams. You will be tasked with identifying the right SSE datasources, mapping these into OVO's data model and then implementing solutions using streaming technologies to transform and publish data onto OVO's Data Platform for use by downstream operational and analytical teams.

This role is fundamental to realising solutions that deliver the successful integration of the two organisations, in line with OVO's Data Strategy.

For more information on some of the technical challenges with integrating OVO and SSE's data platforms why not read the excellent blog post written by Katie Russell entitled Eating the Data Elephant.

What will I be doing?
Designing and Implementing solutions that extract high volumes of data from a wide variety of source systems and making it available on OVO's streaming data platform.
Working with technologies including Kafka and Kafka Connect to stream data into Kafka as well as Scala, Kafka Streams, KSQL and microservice architectures to process and transform data streams.
You will form part of an Agile development team responsible for delivering high quality solutions iteratively into OVO's production systems using XP and CI/CD best practices.
Helping to ensure good engineering practices are adopted and used within the team.
Working closely with stakeholders to understand the various source systems including details of their interfaces, data models and capabilities in order to design appropriate solutions to extract and transform the data.
Assisting in the evaluation of appropriate tools and technologies that will shape the design of the SSE / OVO data migration and integration strategy.
Is this the job for me?
Experience designing and building large-scale streaming data pipelines that utilize streaming technologies (e.g. Kafka Streams, Amazon Kinesis or similar) with an emphasis on the sourcing and transformation of data is essential.
You are a software engineer with an interest in the data domain (data modelling, data transformation, etc.).
You are comfortable working in an agile development environment that employs continuous integration and continuous delivery best practices, and have experience of pair programming, BDD/TDD, CI/CD and deployment strategies.
You are a strong advocate for engineering best practices including unit testing, integration testing, static code analysis and code reviews.
You are motivated by fast-paced environments where teams have high degrees of autonomy.
Experience with Scala would be an advantage but if you have an appetite to learn new technologies and a drive for continual improvement we'd love to talk to you.
From us you'll get*
4% of your salary to spend on flexible lifestyle benefits
5% matched employer contribution to your pension
25 days holiday + 1 for your birthday
An annual discretionary bonus
And many more...

(*) Please note that certain benefits kick-in once you have passed probation which can be up to 6 months after your start date.

We want the best people

At OVO, we empower our people to have choice around where and when they work - flexible working arrangements can be discussed for all of our roles. Please speak to the Talent Acquisition team for more info.

We're keen to meet people with varied backgrounds - our view is the more inclusive we are, the better our work will be. We want to build teams which represent a variety of experiences, perspectives and skills, and we recognise talent on the basis of merit and potential.

We understand some people may not apply for jobs unless they tick every box. If you're excited about joining us and think you have much of what we're looking for, even if you're not 100% sure… we'd love to hear from you.

Learn more about working in the OVO family of companies on our careers page and Glassdoor. We're also delighted to have received a Top Employers certificate in 2018, 2019 and 2020!",-1,OVO External,"Bristol, England",-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer (Python),-1,"We're seeking a Python Data Engineer to come in to work as part of a Global team based in Central London for an initial 9 month contract.

You will be working as part of a Scrum Development team and will be collaborating with other engineers to design and build automated data visualisations that provide insight into the ever changing and evolving AWS cloud estate. You will also be developing and refining ETL pipelines and transforming them into AWS hosted Python scripts.

Skills Required -

-3 + years Python

-Alteryx understanding of clean code architecture

-Test Driven Development (TDD)

-AWS Deployments

-API's (REST)

-SQL

-Agile environment experience

-Google sheets or Excel

If you feel this is a good fit then please submit your CV in response to this advert.

Python - AWS - Data - ETL - TDD",3.7,"Linux Recruit
3.7","London, England",-1,1 to 50 Employees,-1,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer –,-1,"Data Engineering, Technology

London, UK

Permanent

£55,000 - £60,000 per annum + bonus

1210

Data Engineer | London | £55,000 – £60,000 per year

Do you want to be working with some of the most sought-after technologies in the Data Engineering market at the moment?

I am working with an up and coming organisation who work with businesses to evaluate, develop, and deploy end-to-end data solutions across Business Intelligence, Analytics, Data Warehousing, Data Science, ETL/ELT and more.

They have recently teamed up with best in class SaaS providers, Matillion, which means you’ll have the chance to gain experience with this exciting tool.

My client is looking for 2 X Data Warehouse Engineers who have previously worked in a cloud environment, ideally Snowflake, to help them grow and develop their existing Data Warehouse and work with their clients on developing further solutions.

What are they looking for from you?

Experience is key to my client – they are not after “X years of experience”. It is what you’ve done during that time that is important.
Exposure to Cloud Technologies – AWS, GCP or Snowflake
Strong dimensional modelling
You will have worked in a Data Engineering / Data Warehousing environment

What should you expect in return?

If you are not already certified in specific technologies, my client will send you on expert courses to gain certifications.
Work alongside other data ninjas who have worked super hard to get where they need to be in the world of data!
You can get your hands on some pretty cool tech like – MatillionETL, Tableau, Looker

As well as this, you can expect between £50,000 to £55,000 as a basic salary plus some other decent benefits.

If this sounds like an opportunity you’d like to pursue, I’d get in touch with myself or one of the KDR experts here and we’ll talk you through this unique role! Don’t worry if you’re CV isn’t made up yet, we’ll happily talk over email.",4.4,"kdr Recruitment
4.4","London, England",-1,1 to 50 Employees,2003,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"As a WovenLight Data Engineer you will support the development and deployment of analytics models at WovenLight portfolio companies. This work will include:
- Working with a range of portfolio company stakeholders to understand, assess and map the company's data landscape
- Collaborating with data science colleagues to map data fields to hypotheses in order to curate, wrangle, and prepare data for use in advanced analytical models
- Acquiring, ingesting, and processing data from multiple sources and systems
- Building modular pipelines to construct features and modelling tables

You must be passionate about learning and improving ways of working at WovenLight. To this end you will collaborate with our investment team and product engineering group (product managers, software engineers, designers) to build analytics product technology that can help us deliver impact faster and more efficiently.
The successful candidate should have the following attributes:
Passion and expertise in applying data and analytics to deliver commercial impact (2+ years)
Good communication skills - able to explain complex analytical concepts to individuals from other fields
Expertise with core analytic technologies (Python, Scala, SQL, Java),
Ability to work with a range of database technologies including most of: distributed processing (e.g. Spark), traditional RDBMS (e.g. PostgreSQL), MPP (e.g. AWS Redshift), NoSQL (e.g. MongoDB) and ETL tooling
Expertise with cloud platforms such as AWS, Azure, Google Could Platform and Databricks
Our core team is based in London and plans to move into a central London office as soon as it is safe to do so. For the moment we are working remotely. For roles in our deployment team we are looking for candidates who are based in or near to London.

Interviews for this role will be conducted by phone and/or video-conference.

WovenLight is committed to equal employment opportunity regardless of sex, race, religion, ethnicity, nationality, disability, age, sexual orientation, gender identity or any other basis as protected by applicable law.",-1,WovenLight,"London, England",-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Location
London - Bedford Avenue

Contract type
Full-time

Job description
Do you see the big picture clearly, even in an unclear and ever-changing world? Do you want to work with large and complex data sets to play a key role in the future of William Hill? If so, we have a number of opportunities in our Data Science and Advanced Analytics Team ,working with the latest technology at an exciting time in our digital transformation.

About us

Working with us you’ll be at heart of the technological revolution of one the world’s most trusted betting and gaming companies. We deal with projects ranging from widgets, desktop or mobile casinos and betting sites… just to name a few. We process 500 online Sportsbook bets per second each Saturday, that’s the same as orders processed by Amazon UK, on its busiest day of the year. We deal with more than 20 million users and 160 terabytes of data daily. Impressed? You can be sure there are many more challenges waiting for you.

Your role in the team

Here at William Hill, we're building a market leading Econometrics team. We're looking for someone passionate about building the foundations to access numerous datasets required to build best in class Econometrics capability.

As a mid-level Data Engineer/Developer you will be building and maintaining DataMart’s, tools, and front end and back end process using our cloud-based platform that will be used to power the insight from our specialist in-house Econometrics team. You will diagnose any technical faults on our associated data platforms, whilst putting automated processes in place for continual data feeds as we look to ramp up speed of delivery.

There will be an opportunity to get hands-on in Econometrics modelling in addition to building and maintaining front end dashboards and tools as the Econometric capability matures.

If you have a keen eye for detail, are open to broadening your statistical knowledge, and enjoy working in a fast-paced environment then this could be the role for you.

Your responsibilities will include:
Owning the relationship with Data Architecture and the Econometrics team relating to requirements and best practice approach to structuring data assets required to provide the most robust insight.
Improving and automating existing processes, as well extensive data quality QA across numerous large and complex data sources and transformations.
Documentation of all process and implementations to allow for auditing and posterity as well as experience in writing well designed, testable, efficient code which follows good coding standards.
Diagnosing technical faults on big data platform services which are bit on numerous platforms like AWS, Snowflake, & Databricks to name a few.
You will have:

It's essential that you have advanced level of technical skills in an array of coding languages like SQL, R, Python as well as Excel and Power BI. You have proven experience in a similar data-driven role, backed up by a numerate or data related degree level qualification. You're an expert in driving improvements in KPI’s (code quality, defects, performance, and resilience).

You have the ability to understand complex data structures and systems, but you're also able to communicate in a simple concise manner to a non-technical audience. You have a high degree of drive, energy, self-confidence, commitment and experience of working in a fast-paced operation environment. You will also enjoy working in a team and building strong relationships with other departments.

Previous experience working in Gaming and Gambling is not essential, but it would help if you're familiar with the typical nuances of data and structures that are part and parcel of the industry. It would be useful if you've supported statistical teams in data delivery and had some exposure to statistics and /or Econometrics. Knowledge of JIRA or other project management tools would be an advantage.

If you want to combine your passion and knowledge for data and analytics with the chance to work in a fast paced and dynamic business, where you can grow and develop, we would love to hear from you.

What we offer

We take the safety and wellbeing of our employees seriously, especially at this challenging time. We have put in place robust Covid19 measures and are supporting our new employees with a smooth onboarding and training programme and making you feel welcome and part of our team.

We’ll welcome you on-board with 25 days holiday (not to mention 8 bank holidays and an extra day for your birthday), a rewarding bonus scheme, healthcare (or a cash alternative), an attractive pension package, life assurance, healthy gym discounts and a flexible benefits scheme. Plus, our season ticket loan and handsomely discounted Zone 1-6 Oyster card will save you money getting to work and getting around town. And if you see the journey to work as part of your fitness regime, you’ll just love our Cycle to Work scheme.

William Hill in London

Our brand-new central London office has a vibrant, fun and collaborative start-up feel. We couldn’t be closer to the action. A 2-minute walk from Tottenham Court Road station, around the corner from Soho and Oxford Street means you’ll never be short of anywhere to go for a lunchtime stroll or a post-work drink. There’s plenty of green space too with Regent’s Park and Hyde Park not far away at all.

Join us #behindthebet",2.8,"William Hill
2.8","London, England",-1,10000+ Employees,1934,Company - Public,Gambling,"Arts, Entertainment & Recreation",$2 to $5 billion (USD),-1
Senior Data Engineer,-1,"Who we are:

Nested is redefining estate agency in the UK. For too long, sellers have been subjected to unresponsive agents and broken processes. With a combination of groundbreaking technology and expert local agents, Nested is fixing the whole moving experience one problem at a time.

Today, estate agents get away with doing half a job, getting a seller under offer before leaving them to navigate the rest of the process by themselves. Nested is built for movers, the first estate agent to support both the selling and buying process, for no extra fee. We can even make sellers chain-free, with our groundbreaking cash advance securing their ideal home before they sell.

We are a pioneering team, backed by Europe’s top VCs and led by an experienced, hands-on founding team. We're all contributing remotely to build a new era for home movers, with plans to optionally work from home 3 days of the week in the future when we can spend some time in our Farringdon office again. When work is over, there’s always been plenty of socialising, from film nights to sports days or more socially distanced activities in the park.

If redefining an entire industry is something that motivates you, come and join the team at Nested.

The data team:

Our team mission is that data is a superpower for Nested, from powering our customer-facing digital products through to enabling a data-led organisation. We’re a small cross-functional team (engineers & analysts) looking to have an outsized impact for Nested. Our goal is to be a trusted partner for driving new insights and commercial opportunities, and to empower our users (customers and colleagues) to make the best possible choices.

Requirements

We’re looking for an experienced software/data engineer with a keen interest in data and data-processing technologies, to help us fix the broken process of buying and selling homes in the UK. You’ll be joining the data team at an exciting juncture, focusing on:
Modern technologies: our team works within a modern, modular data stack using GCP infrastructure, and follow software engineering best practices
Enabling self-serve: For our customers to make the right choices, they need to be data-led. Our self-serve data platform enables this, and our data engineers take responsibility for the reliable and timely ELT processes and data pipelines which sit behind our Looker platform.
Building product capabilities: our data engineers work closely with product engineering teams to understand data requirements in our digital products, and turn these requirements into a delivered solution
Having a big impact: the success of our data engineers and our team is the business value we create, which means focusing on impactful areas and problems
The candidate:
First and foremost, you’re an established senior software engineer with many years of experience, well versed in agile engineering best practices, including version control, test-driven development and continuous integration
You write clean, performant and well-documented code
You have a strong understanding of Python and SQL, and are comfortable using them daily
You’ve plenty of experience (and get a kick out of) mentoring more junior developers, and perhaps managing people
You can compose simple solutions to complex problems
It’s helpful, but not required, if you have hands-on experience working with data infrastructure and tooling
It’s helpful, but not required, if you know a bit of statistics or machine learning
If the above describes you, then you should apply if:
You’re excited by what Nested is doing!
You enjoy data & solving data problems
You'd like to have ownership of the reliable and timely delivery of data for an organisation
You’re curious, and love digging into business and product problems
You’re an avid learner who enjoys picking-up new technologies, sharing knowledge with teammates, and is always developing as a person
You’re comfortable working on open-ended questions and turning these to actionable outcomes, and are capable of self-direction
You care about impact and working on the things which will ‘move-the-needle’ and make a startup successful
Benefits
Great salary, with regular performance reviews
Generous options grant
4% employer pension contribution
Private health insurance with gym discounts & more
27 days holiday + bank holidays
Work From Home 3 days a week, and flexible working hours
£1,000 personal development budget per year
Generous maternity and paternity packages
Kitchen stocked with breakfast, coffee and snacks, & catered Friday lunches including dietary options
Monthly team social events
We are striving to build an inclusive team, but we recognise there is always more to be done. In the last year, we’ve focussed on running workshops in collaboration with tech bootcamps, promoting self-education through our anti-racism reading list, and building diversity into the engineering growth framework. If you would like to talk to us about these efforts, or have suggestions for how we can do better, we would love to hear from you.

Nested is proud to be an equal opportunities employer:At Nested we embrace diversity and see it as a benefit to our company. That's why we're committed to hiring top talent regardless of race, religion, colour, national origin, sex, sexual orientation, gender identity, age or status as an individual with a disability.

We’re a growing team and happy to make any accommodations we can for individual needs. If you have an additional accessibility or other requirement we haven’t considered, we will do our best to adapt and make sure your needs are met.
Nested GDPR Compliance - Please take 2 minutes to read our Nested Privacy Notice for Recruitment and learn how we will process your data.",4.7,"Nested
4.7","London, England",-1,51 to 200 Employees,2015,Company - Private,Real Estate,Real Estate,Unknown / Non-Applicable,-1
Software Engineer – Security Data Platform,-1,"G-Research is Europe’s leading quantitative finance research firm. By using the latest scientific techniques, we produce world-beating predictive research and build advanced technology to analyse the world’s data. We hire the brightest minds in the world to tackle some of the biggest questions in finance. We pair this expertise with machine learning, big data, and some of the most advanced technology available to predict movements in financial markets.

The role

The Security Data Engineering team forms part of the Security Detection and Response function in G-Research, supporting the Security Operations Centre in detecting and responding to malicious activity that could negatively impact the organisation. The team is responsible for developing the end-to-end capability required to perform a range of monitoring and response capabilities across the physical, personnel and cyber domains. We also support and provide data services to other parts of the organisation to support compliance and operational management.

Our Software Engineers have strong computer science backgrounds and are comfortable working cooperatively across a range of different teams.

Key responsibilities of the role include:
Contributing to the development of the Security Data Platform
Building and maintaining scripted run-books, security dashboards and visualisations to support the SOC in its day-to-day work
Supporting the wider security team in maintaining a view of our security estate for both operational and compliance purposes
Onboarding new data sources to the security monitoring environment
Generating meaningful anomaly detection alerting (alongside the SOC and data science teams)
Deploying anomaly detection and correlation alerting into production
Key to this role is our ability to engage with partners and build on open source technologies. As such, our engineers have access to a range of training in the full set of big data technologies as well as access to the leading global conferences relating to data, data science and security.

Who are we looking for?

The ideal candidate will:
Have excellent academics. Candidates should have achieved a 2:1 or above in Computer Science or Computer Science with Mathematics from a top tier University, or be able to demonstrate the appropriate level of relevant experience
1+ years’ proven software engineering experience
Be highly computer literate with the ability to learn new skills quickly
Be competent in scripting and coding, ideally in JavaScript, Python or Java
Have a strong understanding of software engineering, operating systems, networks, SQL and NoSQL technologies and data structures
Have the ability to work autonomously, understanding initial requirements, building and supporting data pipelines and ensuring the finished product is fit for purpose
Have an open mind, be willing to explore new technologies and be able to demonstrate a commitment to continuous personal development
Advantageous experience and skills include:
Experience working with big data or analytics technologies, notably Hadoop, Spark, Splunk, Kibana or Tableau
Programming in either Java or Scala
Why should you apply?
Highly competitive compensation plus annual discretionary bonus
Informal dress code and excellent work/life balance
Comprehensive healthcare and life assurance
25 days holiday
9% company pension contributions
Cycle-to-work scheme
Subsidised gym membership
Monthly company events
Central London office close to 5 stations and 6 tube lines",4.8,"G-Research
4.8","London, England",-1,501 to 1000 Employees,2001,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Engineer,-1,"Data Engineer

My client is a highly dynamic and successful Business Intelligence and Datawarehousing Consultancy with a strong presence across the UK.

They currently have an opportunity for a Data Engineer to join them in Manchester to work on the design and development/build of data solutions for clients.

The role:
Multi skilled across the entire technical data management landscape and has experience at varying levels in all aspects of an ecosystem such as Data Storage, Data Ingestion, Data Integration, Data Store technologies and concepts, Data Preparation and Cloud Infrastructure. The individual should have a wider understanding of the business problems that manifest into data solutions and be able to concisely articulate to stakeholders and interested parties in layman’s terms.
You will also have a wider understanding of how their role and delivery contributes to wider business outcomes and be able to concisely articulate to stakeholders and interested parties their role and solutions in a way that can be easily understood.
You will have either have actual Consulting experience or have good stakeholder management skills and want to grow into a consultant.

Technical skills:
Python, spark, nosql or Kafka experience
Any cloud data engineering experience in GCP, Azure and AWS
Any R, Tableau or streamsets experience would be an advantage
THESE ROLES REQUIRE TRAVEL THROUGHOUT UK TO WORK ON CLIENT SITE. YOU HAVE TO HAVE A VALID UK PASSPORT OR VISA TO APPLY FOR THE ROLE, NO SPONSORSHIP IS AVAILABLE*
-- *
Reference ID: DF1

Job Types: Full-time, Permanent

Salary: £40,000.00-£60,000.00 per year

Schedule:
Monday to Friday
Work remotely:
Temporarily due to COVID-19",-1,Odin Consultancy & Recruitment Ltd,"Manchester, England",-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Our client currently requires a team of 1x Data Engineer and 1x Mate/Cable Puller for a large data installation in Huntingdon, Cambridgeshire. We are looking for candidates to start immediately to work for around 3 weeks. Candidates must be experienced with data installations on large commercial projects. All work is at height so you must also hold a valid IPAF License.

£30 per hour for the team

If interested please apply within or contact Ryan at MEP on 07741888402

Reference ID: DE/HNT

Contract length: 3 weeks

Expected Start Date: 26/10/2020

Job Types: Full-time, Temporary

Salary: £30.00 per hour

Schedule:
8 hour shift
Work remotely:
No",-1,MechElec Personnel Ltd,"Huntingdon, England",-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Data Engineer/ Data Science Engineer/ Analytics Engineer/ Insights Engineer/ Data/ Elasticsearch/ Elastic Search/ ELK/ Kibana/ AWS/ Amazon Web Services/ London
A well-established health-care organisation we partner with, have reached out to me advising me they're on the lookout for a Data Engineer to join their growing London office, on a permanent basis.
You will be reporting directly into the CTO working on exciting projects. You will become part of a small agile team within a well profitable and established business. You will be a key member of the team taking the company to the next level helping build the world leading management platform.
Details;
London based (part time remote available)
£45,000 - £50,000 p/a
Free health-care insurance
Company bonus scheme (10% salary)
Other benefits included
Skills;
Strong knowledge and experience with Elastic stack best practises
Elasticsearch API experience
Experience working with Kibana and being able to create advanced searches, visualisations, and dashboards
Experience working with AWS
Experience working within Agile environment
Collaborative team member with strong communications skills
If you feel this would be of interest, please send me over the latest version of your profile and I will give you a call asap. If this is not of interest, but are looking please send me over the latest version of your CV and I will give you a call-in regard to other opportunities.
Data Engineer/ Data Science Engineer/ Analytics Engineer/ Insights Engineer/ Data/ Elasticsearch/ Elastic Search/ ELK/ Kibana/ AWS/ Amazon Web Services/ London",3.8,"Explore Group
3.8","London, England",-1,51 to 200 Employees,2005,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Science Engineer,-1,"The role

We are looking for a Data Science Engineer to help build and improve the tooling and frameworks developed and used by our growing Data Science team, as we bring the models we develop to production.

The role would require someone with a strong background in Python development, as well as experience in CI/CD processes.

What you’ll do
Collaborating with an interdisciplinary team
Recognising pain-points and scope for automation in the development and deployment of data science models
Performance profiling and tuning of models
Rapidly developing ideas and iterating towards production
Specifying and communicating solutions to colleagues
Assisting our Engineering team to build products using the models we have developed

Who you are

Required Skills:

Master’s degree in Mathematics, Physics, Engineering, Statistics, Machine Learning, or another discipline with significant numerical, statistical and/or computational content
2 years of Python programming experience
Git experience
Experience with computational models, statistical algorithms and/or machine learning
A track record of working together with an interdisciplinary team
A strong capacity for sharing complicated concepts with non-experts
Ability to learn new concepts and strong problem solving skills

Preferred Skills:

Experience working with software to the market
Experience with relational or non-relational databases
Experience with CI/CD tools and practices
Prior experience in at least one of the following subjects: - developing mathematical, statistical and/or computational models of industrial processes and equipment; - machine learning; - mathematical modelling in mineral processing or control systems design; -programming high-performance numerical or mathematical software
Proficiency in a language other than English would be a plus, particularly Spanish, Portuguese or Russian
Desire to work outside of your comfort zone
What you’ll get
Flexible working hours
Performance bonus
Unlimited annual leave
The opportunity to make your mark in an innovative industry using the Internet of Things, Big Data and AI

Come and help us tell the story of industrial data to the world!

To apply, click the button below.",-1,IntelliSense.io,"Cambridge, East of England, England",-1,1 to 50 Employees,2014,Company - Private,Mining,Mining & Metals,Less than $1 million (USD),-1
Data Engineer - Test,-1,"We’re Sky, Europe’s biggest
entertainment brand. Think top-quality shows. Breaking news. Innovative tech.
Must-have products. Careers here mean the freedom and support you need to make
an impact – pushing boundaries, creating solutions, hitting targets. And as
part of our close-knit team, you’ll enjoy plenty of benefits. Plus, experiences
you’ll only find at Sky.

“We are leading the way in many areas of data, from delivering business critical reporting, to providing an essential analytics platform to an elite team of data scientists and analysts. Our solutions are essential to hundreds of users, providing key insights on Sky’s customers, products and viewing content and a whole lot more. Delivering innovative solutions for new products and initiatives is what we do, every single day. We are the team responsible for bringing together thousands of data feeds from hundreds of systems, into our state-of-the-art cloud platform” - SNR Data Engineering Manager Test – Clive DTA

Do you want to be part of a team that is pushing aside boundaries and
bursting out into the Cloud? If you thrive in an environment where no two days
are the same, want to influence, create and work with exciting cutting-edge
technologies, then this role could be for you.

Data, Technology & Analytics (DTA) at Sky is on
a mission to bring customers more of what they love by unlocking the power of
data and make Sky more relevant.  We are working with the
rest of Sky to build innovative data products that bring even more value to our customers.

To be part of the team that is responsible for instilling good governance principles and practices within Sky to drive the benefits: trust, performance & value.

The Perks

Sky Q, a generous
pension and private health care. Access to over 12,000 LinkedIn Learning
courses to support your development. And if that’s not enough, our
award-winning Osterley campus boasts six subsidised restaurants, a cinema, gym,
and much more.

To find out more about working with us, search
#LifeatSky on LinkedIn, Twitter or Instagram.

You Will
Produce
clear and concise documentation of test coverage as agreed with
Stakeholders
Define,
estimate, plan, script and execute tests
Document
and validates all test risks, issues, assumptions and dependencies
Identify,
code and maintain automated scripts for regression and integration tests
or data creation
Provide
accurate test estimates to support planning of path to production
Initiate
and implement improvements of test process and appropriate tooling
Work
with and assist other teams within the department, providing technical
& domain input
Assist
with the mentoring of associate testers and colleagues


You’ll Have:

Comprehensive
Cloud migration experience
In
depth understanding of large scale data, such as data warehouses and their
best practice and principles of managing them
Experience
of ETL technical design, development and support
Exceptional
communication and interpersonal skills and a proven ability to influence
technical decisions in a fast-moving commercial environment
Excellent
SQL skills
Experience
of Unix and python scripting
Comfortable
with developing testing capability in automation frameworks
Technology
background that includes as many of the following as
possible Selenium, Cucumber, LeanFT, Java, Maven, Jenkins, Git,
Netezza, Oracle.
So, what are you waiting for? Apply now for a
chance to forge your own career path and be brilliant as part of a bright,
talented team.

Just so you know: if your application is successful,
your appointment will be subject to receiving a positive outcome from your criminal
record check.

We’re happy to discuss flexible working.

It’s our
people that make Sky Europe’s leading entertainment company. That’s why we work
hard to be an inclusive employer, so everyone at Sky can be their best.

A job you
love to talk about

We’re Sky, Europe’s biggest
entertainment brand. Think top-quality shows. Breaking news. Innovative tech.
Must-have products. Careers here mean the freedom and support you need to make
an impact – pushing boundaries, creating solutions, hitting targets. And as
part of our close-knit team, you’ll enjoy plenty of benefits. Plus, experiences
you’ll only find at Sky.

“We are leading the way in many areas of
data, from delivering business critical reporting, to providing an essential
analytics platform to an elite team of data scientists and analysts. Our
solutions are essential to hundreds of users, providing key insights on Sky’s
customers, products and viewing content and a whole lot more. Delivering innovative
solutions for new products and initiatives is what we do, every single day. We
are the team responsible for bringing together thousands of data feeds from hundreds
of systems, into our state-of-the-art cloud platform” - SNR Data Engineering
Manager Test – Clive DTA

Do you want to be part of a team that is pushing aside boundaries and
bursting out into the Cloud? If you thrive in an environment where no two days
are the same, want to influence, create and work with exciting cutting-edge
technologies, then this role could be for you.

Data, Technology & Analytics (DTA) at Sky is on
a mission to bring customers more of what they love by unlocking the power of
data and make Sky more relevant.  We are working with the
rest of Sky to build innovative data products that bring even more value to our customers.

The Perks

Sky Q, a generous
pension and private health care. Access to over 12,000 LinkedIn Learning
courses to support your development. And if that’s not enough, our
award-winning Osterley campus boasts six subsidised restaurants, a cinema, gym,
and much more.

To find out more about working with us, search
#LifeatSky on LinkedIn, Twitter or Instagram.

You Will:
Produce
clear and concise documentation of test coverage as agreed with
Stakeholders
Define,
estimate, plan, script and execute tests
Document
and validates all test risks, issues, assumptions and dependencies
Identify,
code and maintain automated scripts for regression and integration tests
or data creation
Provide
accurate test estimates to support planning of path to production
Initiate
and implement improvements of test process and appropriate tooling
Work
with and assist other teams within the department, providing technical
& domain input
Assist
with the mentoring of associate testers and colleagues
You’ll Have:
Comprehensive
Cloud migration experience
In
depth understanding of large scale data, such as data warehouses and their
best practice and principles of managing them
Experience
of ETL technical design, development and support
Exceptional
communication and interpersonal skills and a proven ability to influence
technical decisions in a fast-moving commercial environment
Excellent
SQL skills
Experience
of Unix and python scripting
Comfortable
with developing testing capability in automation frameworks
Technology
background that includes as many of the following as
possible Selenium, Cucumber, LeanFT, Java, Maven, Jenkins, Git,
Netezza, Oracle.
So, what are you waiting for? Apply now for a
chance to forge your own career path and be brilliant as part of a bright,
talented team.
Just so you know: if your application is successful,
your appointment will be subject to receiving a positive outcome from your criminal
record check.

We’re happy to discuss flexible working. It’s our people that make Sky Europe’s leading entertainment company. That’s why we work hard to be an inclusive employer, so everyone at Sky can be their best.

A job you love to talk about",3.8,"Sky
3.8",Greater London,-1,10000+ Employees,1989,Company - Public,TV Broadcast & Cable Networks,Media,$5 to $10 billion (USD),-1
Data Engineer,-1,"Who are Metapack?

We are a tech company that works with a lot of the world's biggest ecommerce players to integrate them with over 450 carriers around the world to make delivery easy. We are a multi-tenant SaaS platform. We give them the platform to help consumers decide their delivery preference and track the parcel's progress whilst also providing the retailer with intelligent smart decisions about how to send the parcel all underpinned with lots of data. We work with well-known global retailers and major brands such as ASOS, Adidas, Burberry, John Lewis, Boohoo, eBay, and Zalando. In fact, we work with so many retailers and carriers it's highly likely that you've interacted with us at some point when ordering goods online!

In August 2018, we were acquired by Fortune 100's 2nd fastest growing company, stamps.com. We have super ambitious and exciting plans all centred around our tech. Metapack will play a role in shipping around 600 million parcels in 2018 and with the wider stamps.com family the number rises to 2.5bn parcels. Metapack has been growing at 40% year on year over the last 5 years and continues to grow at a rapid rate.

Our Values;

The way we work really is at the heart of Metapack, and our 4 core values are brought together to give a sense of our culture.

With Innovation and Integrity at our core, we have a flat and open culture where data & evidence, backed by honest and frank discussions, beats subjective opinion and hierarchy. We Collaborate with energy and Passion on meeting the needs of our fantastic customers and partners.

We passionately believe in forming autonomous, cross functional teams who are empowered to deliver our ambitious strategy. With stamps.com ownership comes the ability to operate largely independently away from Board meetings and old world thinking but with the financial support of a high performing tech company. Energy and passion for our business and customers is a part of the MetaPack culture and we love working with like-minded people.

Why would I want to be a Data Engineer at Metapack?

Data is key to the Metapack's strategy. We work at scale, pace and with the latest architecture patterns and tech. We process thousands of events per second and our massive dataset keeps growing at a staggering pace. We keep improving our data platform and data engineering stack to accommodate growth, enable novel solutions and provide the best service to our customers.

We have a flat and open engineering culture where data, & evidence beats opinion and hierarchy, backed by honest and frank discussions. We passionately believe in forming autonomous, cross functional teams who are empowered to deliver our ambitious strategy. With stamps.com ownership comes the ability to operate largely independently away from Board meetings and old world thinking but with the financial support of a high performing tech company. Energy and passion for our business and customers is a part of the Metapack culture and we love working with like-minded people.

What would I be doing?
Contributing to the design, build and operational management of our data lake and analytics solution on top of proven AWS data technologies like S3, Athena, Lambda, Kinesis, Glue
Using state of the art technologies like Airflow and Spark to process data and get our dataset just right
Developing frameworks and solutions that enable us to acquire, process, monitor and extract value from our massive dataset
Supporting the Data Analysts and Data Scientists with automation, tooling, data pipelines and data engineering expertise
Delivering highly reliable software and data pipelines using Software Engineering best practices like automation, version control, continuous integration/continuous delivery, testing, security, etc.
Define, implement and enforce automated data security and data governance best practices within the solutions designed
Mentoring more junior colleagues and being mentored by more senior colleagues
What key skills and experience do I need?
A Software Engineering background
Experience developing and supporting robust, automated and reliable data pipelines in Python and SQL
Experience with data processing frameworks like Pandas or Spark
Experience with streaming data processing
AWS, Azure or Google Cloud experience
Continuous integration/delivery environment experience with a passion for automation
Knowledge of a Data Orchestration solutions like Airflow, Oozie, Luigi or Talend
Knowledge of both relational and non-relational database design and internals
Knowledge of how to design distributed systems and the trade-offs involved
Experience with working with software engineering best practices for development, including source control systems, automated deployment pipelines like Jenkins and devops tools like Terraform
It would be great if you also could bring
Practical understanding of GDPR and other considerations regarding data security
Knowledge and direct experience of using business intelligence and analytics tools (Tableau, Looker, Power BI, etc.)
Production experience working with very large datasets
Experience with big data cloud technologies like EMR, Athena, Glue, Big Query, Dataproc, Dataflow.
Data Science/Machine Learning know-how
A desire to constantly challenge the norm
Willing to attend conferences, webinars and meet-ups and share the learning
What are the perks?
25 days holiday, 10% bonus (paid quarterly), pension, enhanced maternity and paternity leave, group life insurance scheme, private medical healthcare
Discounted gym membership, cycle to work scheme, interest free season ticket loan
Dynamic, open culture with lots of social activities",-1,Metapack Careers,"London, England",-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"DATA ENGINEER

£40,000 - £50,000

MANCHESTER

Are you a data engineer who wants to make an impact in the world of sports? This exciting opportunity allows you to do just that whilst being hands on in building out a new data platform in Azure and Spark.

THE COMPANY:

This role is within a Sports devoted company based in Manchester. They have a strong analytics function and a large data platform used by multiple teams. The data platform has previously been a BI infrastructure but is now based around Spark, Data Bricks.

THE ROLE:

The successful candidate will sit in the Data & Analytics department and deal with large scale data in an advanced sports offering. You will be working on the development of the new Data Bricks platform.

In particular, this role will involve:

The maintenance and development of the Data Platform using Data Bricks and Azure.
Gathering large amounts of data for analytics.
Programming in Python.
Using a software engineering mindset for writing pipelines rather than scripting.

YOUR SKILLS & EXPERIENCE:

Relevant tech stack including Python for programming, Apache Spark or Data bricks.
Commercial experience with cloud technologies, ideally Azure - data factory.
An interest in sports.
Software engineering skill set.
Knowledge of BI tools (ideally Tableau and Power BI).

THE BENEFITS:

The selected candidate will receive a salary between £40,000 - £50,000 depending on their experience and requirements.

HOW TO APPLY:

Please register your interest by sending your CV to Holly Neeves via the Apply link on this page.",4.1,"Harnham
4.1","Manchester, England",-1,51 to 200 Employees,2006,Company - Private,Staffing & Outsourcing,Business Services,$25 to $50 million (USD),-1
Data Engineer,-1,"30/09/2020
Location: Reading
Salary: Competitive
Job Reference: DE2020
Job Description:

Livingstone Group, we have a new opportunity for a Data Engineer to join our growing team. The post is to play an active part in the success of Livingstone Group. The Data Engineer will take responsibility in building new solutions for software and Cloud cost optimisation technology platform. Collect, analyse, format and present new data sources for customer software and Cloud investments driving optimisation recommendations and value-based data insights. Using our LUCE platform to configure new solutions in line with the business and client requirements.
Full Description:

We are looking for a candidate with a wealth of experience in Data Engineering, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.

Extensive experience of using an object-orientated software language to obtain, extract and manipulate data, such as Python, C#, Java or equivalent

Strong daily experience of querying relational databases (SQL Server specifically) as well as a working familiarity with other database systems

Analytical skills related to working with a mixed variety of both structured and unstructured datasets, finding relationships in the data

A successful history of manipulating, processing and extracting value from large disconnected datasets

Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement

Building automated processes and workflows supporting data transformation, data processing, and restructuring for reporting and dashboards

Strong project management and organizational skills

Experience supporting and working with cross-functional teams in a dynamic environment

Skills in using software languages to call APIs, extract, manipulate, and shape the data in such a way that it can be interpreted accurately, and insights revealed

To apply for this role please send your CV with a covering letter to careers@livingstone-tech.com",3.8,"Livingstone Technologies
3.8","Reading, England",-1,51 to 200 Employees,2011,Company - Private,Enterprise Software & Network Solutions,Information Technology,$10 to $25 million (USD),-1
Data Engineer,-1,"Job Description

Data Engineer - 6 months - Cambridgeshire - £750 - DV Cleared

Urgent Requirement for a Data Engineer who holds DV Clearance to be based in Cambridgeshire for a 6-month contract. Our client is looking for a confident Data Engineer to provide technical support.

The successful candidate will have experience providing technical support and be comfortable working within a large team.
The successful candidate will be required to hold current DV Clearance..
Key Skills:

Strong technical ability with ElasticSearch and Kibana.
Apache NiFi.

Desirable Skills:

Geospatial data.
Docker or Kubernetes.
Python and ML frameworks including SciKit-Learn, Keras, TensorFlow or PyTorch.",-1,Eurobase People,"Cambridge, East of England, England",-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Role: Data Engineer*
Location: *Remote as of now due to Covid / Location is London.
Start Date: * Immediate
About the Job: *
This is a Contract to Hire position with one of our prestigious clients. You will be joining NJC Labs and work with our client for first 6 months.

Our client is a leader in Integration Space with revenue over 300 million USD.

We are looking for a Data Engineer for one of our prestigious clients to expand and optimise our data and data pipeline architecture, as well as optimizing data flow and collection for cross-functional teams.

The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The right candidate will be excited by the prospect of optimizing or even re-designing our team’s data architecture to support our next generation of products and data initiatives.
What you’ll achieve: *
Create and maintain optimal data pipeline architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Keep our data secure
Work with data and analytics experts to strive for greater functionality in our data systems.
What you’ll need to be successful: *
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Experience with relational SQL including MySQL and Aurora.
Job Types: Full-time, Contract, Permanent

Benefits:
Work from home
Schedule:
8 hour shift
Experience:
work: 1 year (Preferred)
total work: 1 year (Preferred)
Education:
Preferred",-1,NJC Labs,"London, England",-1,-1,-1,-1,-1,-1,-1,-1
Data Engineer,-1,"Remote Contract role - Data Engineer

This is a SC cleared project (Outside if IR35) which will require the data engineer to be a British Citizen or held permanent residence in the UK for the last 5 years as a minimum. You don't need to hold a current clearance the client will sponsor this.

The client require a Data Engineer to work alongside their lead data scientist on the discovery and buildout of a document processing system built around NLP utilising NER. Really exciting project that will be building a sytem to (eventually) handle millions of documents across a huge business area.

Strong Python skills are essential as this is very much a hands on coding role building out the back end of the system and allowing seamless integration with other systems. Elasticsearch would be useful as well as experience with AWS. Experience with spaCy would also be highly advantageous.

Key Skills:

Python
Elasticsearch
AWS
Desirable:

NLP / NER
Experience with document processing systems
spaCy
Location: Fully Remote

Duration: 8 Weeks initial with likely extension

Hours: 3 Days per week which could increase to 4 - this is NOT a Full time role initially

Rate: Circa £400 / Day - Appreciate this is not the highest rate in the world for these skills - the client do not necesarily need someone who has been doing it for 10 years plus rather someone who is excited about the opportunity and getting more exposure to data science generally and specifically NLP.

Start Date: After SC vetting completed (4-6 weeks)

Quite a unique role in that is is fully remote and 3 days per week - this would suit a contractor who maybe has some other committments or personal projects that aren't full time and is happy to work on a part time basis.

If this role sounds of interest please submit your CV via the link and someone will be in touch with you to discuss further.",3.8,"Emtec Ltd
3.8","London, England",-1,501 to 1000 Employees,1995,Company - Private,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (USD),-1
Senior Data Engineer,-1,"Redkite helps businesses to unlock value from their data.

We work in close partnership with senior business leaders to provide end-to-end, full stack data expertise from strategy to design to build. We help their high-potential organisations to set up their data to enable better, faster decision-making and accelerated performance.

These partners range from industry-leading public companies to innovative, high-growth startups. They cover industries like fashion, media, beverages and gaming. We solve some of their hardest problems, accelerating their growth and adding directly to their bottom line.

Our team consists of product managers, analysts, data architects, data engineers, operations experts, data governance specialists and developers. We have a range of backgrounds spanning top consultancies, hyper-growth companies, and data functions in large, consumer-oriented organisations.

We’re growing fast and want excellent people to join our team and grow with us. You can find out more about Redkite on our homepage and more about our people and culture on our careers page.

The Role

Data engineers at Redkite are responsible for delivering high-quality data outcomes via modern data sourcing, integration and modelling techniques. You will work as part of a small Redkite delivery team and often be semi-embedded within a client team as well.

You will bring a mix of technical and non-technical skills, such as:

Technical
Python & SQL: The ability to design and implement well designed code. These should follow industry best practice and be easily scalable and human readable.
Data modelling: The ability to design well structured tables that are at the correct grain and structured for widespread use (i.e. using Kimball modelling).
Software engineering mindset: The ability to automate tasks and deploy production standard code (with unit testing, continuous integration, versioning etc.)
Non-technical
Stakeholder influence: The ability to clearly communicate your work and ultimately provide confidence in order to drive change in a business.
Business insight: The ability to understand complex business processes and break down fuzzy requirements into actionable segments.
Coaching and training: The ability to collaborate effectively with both the client and Redkite teams - sharing your experience and helping others to grow their skillset.
We’re tool agnostic, but often work with either the latest Azure or AWS stacks, where experience with at least one is essential.

The founders, Henry Crawford and Jon Tippell, firmly believe that continual training is vital to Redkite’s growth, so will ensure that you’re well supported and set up to succeed.

Requirements
Expertise in most of the skill areas listed above.
Commercial expertise in building end-to-end data products.
A passion for building high-quality products which drive change for businesses.
Expertise in using modern data tools including but not limited to Spark, Kafka, Python.
A results-oriented mindset with an eye for detail.
Comfort with some travel to clients.
Right to work in the UK (we can’t sponsor visas).

Nice to have:
Training or degree in a STEM subject.
Experience managing teams of data or BI engineers.
Experience building effective CI/CD tools and processes.
Experience of effective data architecture.
Experience with Azure, AWS, Snowflake, or other modern cloud tools.
Experience working with an engineering mindset (i.e. Agile development, Git, Jira).
Experience building applications with languages such as C#.
Benefits
Exposure to a genuinely exciting range of clients, all of whom are trying to solve large problems.
High impact in your role - many of our team can claim credit for driving large changes and saving millions for their clients.
Training and exposure to best in class ways of working - we want to set the gold standard for how companies use data.
Small, friendly and highly-talented team, with limited bureaucracy and hierarchy.
Excellent remuneration.
A great company reflects the wonderful diversity of the world in which we live. We have no judgement on any of the things that make you you - be that your religion, sexuality, race, gender or even if you once believed that tabs were better than spaces.",5.0,"Redkite
5.0","London, England",-1,1 to 50 Employees,2018,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer (Consulting),-1,"The Applied Intelligence business of BAE Systems delivers solutions which help to protect and enhance the connected world. Our solutions combine large scale data exploitation, ‘intelligencegrade’ security and complex services and solutions integration. We operate in four key domains of expertise: Cyber Security, Financial Crime, Communications Intelligence and Digital Transformation. Today, we have staff across the UK and Europe, the Americas, Asia Pacific and the Middle East.

Our people apply intelligence to protect and enhance national and organisational assets so that they can grow and prosper – from improving the health and efficiency of leading corporations to protecting critical infrastructures, safeguarding vulnerable people and catching criminals. Together, we make the world a safer place. Make everyday matter.

About the Role:

To work as part of a client side team that defines and resolves complex data collection and data integration issues ( i.e. ETL - Extract, Transform and Load design and development ) to make data and information available to decision makers, internal and external interfaces and real time decision procedures with operation systems and delivery channels.

The Consultant Data Engineer specialises in helping clients within large scale projects and programmes to help shape specific solutions. However, they will also need to develop a holistic view of the organisation.

Consultant Data Engineers will often work closely with Enterprise Data Architects.

Key Responsibilities:
Designs, develops, tests and supports data collection, data integration and ETL applications to make information and data available to key client stakeholders and technical interfaces.
Understands where the need for tight data controls arises to ensure seamless data flows around the organisation and to minimise future change.
Models data requirements, data sources and data flows to bring order and structure to programmes of work.
Defines how and where data is created, mastered and destroyed to ensure proper control over the lifecycle of corporate data assets.
Understands how to add value to data – for example through data cleansing.
Understands categories of products (and individual examples) that can be used to collect, integrate, store, visualise and govern data and metadata.
Defines metadata to provide searchability and governance (including Records Management) for unstructured data.
Designs ETL frameworks and standards for specific ETL programmes and projects.
Identifies the required toolset (development and testing) for specific ETL programmes and projects.
Designs and implements the hardware environment required by ETL programmes and projects.
Develops and tests the re-usable components of an ETL framework for specific ETL programmes and projects.
Undertakes the role of lead developer, ensuring the quality and assurance of all ETL code and testing.
Can undertake the role of delivery lead ensuring that project timescales and quality are met.
Ensures that the configuration and release management procedures are applied for specific ETL programmes and projects.
Maintains and applies up to date, specialist knowledge of database concepts (including unstructured, NoSQL and ”big data” platforms), object and data modelling techniques.
Builds a detailed knowledge of the full range of database and data persistence architectures, software and facilities available (e.g. streams).
Takes account of industry specific requirements (e.g. geocoding, for geographic information systems).
Can utilise a number of ETL tools including Informatica, Ab Initio, Oracle ODI and a number of the Big Data / Open Source Applications
Understands data-related performance issues.
Understands data services, data security issues, “privacy by design” and Information Assurance principles.
Understands master data management patterns and can advise on the right choices for each client.
Defines metadata structures and population techniques that can be used with Enterprise Content Managment solutions in conjuction with organisational policies.
What we are looking for:
ETL Tool capabilities
Ab Initio, Informatica and Oracle ODI
Big Data / Open Source ETL Tools
Database Management Systems
Application Testing Tools
Configuration Management and Version Control Tools
Testing strategies and tools
Infrastructure design
About BAE Systems Applied Intelligence

We use our intelligence-led insights to help defend Governments, Nations and Societies from cyber-attacks and financial crime. Our customers depend on our evolving capabilities to help them safely grow their organisations. Our unprecedented access to threat intelligence, world-leading analysts and market-leading technology means we can help them to adapt, evolve and stay ahead of the criminals.

Division overview: Capabilities

At BAE Systems Applied Intelligence, we pride ourselves in being a leader in the cyber defence industry, and Capabilities is the engine that keeps the business moving forward. It is the largest area of Applied Intelligence, containing our Engineering, Consulting and Project Management teams that design and implement the defence solutions and digital transformation projects that make us a globally recognised brand in both the public and private sector.

As a member of the Capabilities team, you will be creating and managing the solutions that earn us our place in an ever changing digital world. We all have a role to play in defending our clients, and this is yours.

Diversity and inclusion are integral to the success of BAE Systems Applied Intelligence. We are proud to have an organisational culture where employees with varying perspectives, skills, life experiences and backgrounds – the best and brightest minds – can work together to achieve excellence and realise individual and organisational potential. We also welcome discussions about flexible working.

About BAE Systems Applied Intelligence

We use our intelligence-led insights to help defend Governments, Nations and Societies from cyber-attacks and financial crime. Our customers depend on our evolving capabilities to help them safely grow their organisations. Our unprecedented access to threat intelligence, world-leading analysts and market-leading technology means we can help them to adapt, evolve and stay ahead of the criminals.

Division overview: Capabilities

At BAE Systems Applied Intelligence, we pride ourselves in being a leader in the cyber defence industry, and Capabilities is the engine that keeps the business moving forward. It is the largest area of Applied Intelligence, containing our Engineering, Consulting and Project Management teams that design and implement the defence solutions and digital transformation projects that make us a globally recognised brand in both the public and private sector.

As a member of the Capabilities team, you will be creating and managing the solutions that earn us our place in an ever changing digital world. We all have a role to play in defending our clients, and this is yours.

Diversity and inclusion are integral to the success of BAE Systems Applied Intelligence. We are proud to have an organisational culture where employees with varying perspectives, skills, life experiences and backgrounds – the best and brightest minds – can work together to achieve excellence and realise individual and organisational potential. We also welcome discussions about flexible working.",3.8,"BAE Systems
3.8","Guildford, England",-1,10000+ Employees,1999,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
Senior Data Engineer,-1,"Location
Coventry CV1 2WT, Darlington DL1 5QE, Sheffield S1 2FJ
About the job
Summary
The Education and Skills Funding Agency (ESFA) brings together the existing responsibilities of the Education Funding Agency (EFA) and Skills Funding Agency (SFA), creating a single funding agency accountable for funding education and training for children, young people and adults.

The ESFA:

• is accountable for £58 billion of funding for the education and training sector, providing assurance that public funds are properly spent, achieve value for money for the tax payer and deliver the policies and priorities set by the Secretary of State.

• regulates academies, FE colleges, employers and training providers, intervening where there is risk of failure or where there is evidence of mismanagement of public funds.

• delivers major projects and operate key services in the education and skills sector, such as the National Careers Service, the apprenticeship service and the National Apprenticeship Service.

ESFA’s Data Science Service provides end-to-end data services including data capture, data management, governance and data visualisation, analytics and modelling and digital insight to the ESFA, DfE and wider Education sector. As an organisation, we are committed to developing our people and the next generation of data and technology leaders.
Job description
Our Data Engineers innovate to design and deliver data products and services, integrating them into systems and business processes within the agency in adherence to Data Governance and architecture protocols.

You will be user focused, understand the importance of data, data management, data quality, lead on providing effective stakeholder service management, develop audit and metric reporting and have a drive for continuous improvement.

You will use your technical skills to design and implement data management solutions. You will work to deliver automated services that are reliable and secure, working with data architects, data stewards, Business Analysts and data scientists.

As a Senior Data Engineer, you will lead and inspire data engineers in finding more innovative ways to improve service operations continuously challenging approaches for optimum delivery of solutions.

Responsibilities
• Collaborate and implement data management systems that link data from multiple systems and platforms.

• Implement appropriate technologies to deliver resilient, scalable and future-proof data solutions, data integration and data process-flow systems to ensure secure operation, integrity of systems and availability. Ensure the data infrastructure remains performant, available and secure at all times, developing contingency and failsafe platform solutions.

• Design, write and iterate code from prototype to production-ready states, managing relationships with subject matter experts to make sure content is accurate and of quality.

• Collaborate with others to review and challenge specifications and where appropriate promoting the best solution design.

• Use agreed standards and tools to design, code, test, correct and document moderate to complex programs and scripts from agreed specifications and subsequent iterations.

• Implement industry recognised data modelling patterns and standards and where necessary reverse engineer data models from a live system.

• Take a lead role in facilitating collaboration and lead effective communication with all stakeholders to support design, build and delivery to meet the user needs

• Effectively translate and accurately communicate across technical and non-technical stakeholders as well as facilitating discussions within a multidisciplinary team.

• Provide constructive feedback to your colleagues to improve everyone’s skills and working relationships.

• Mentoring and guiding more junior members of the team.

• Support the data engineering as a profession within DataOps and the wider department

Skills and Experience

It is essential that you have:

• the ability to use advanced SQL and SISS (or ETL): queries, stored procedures, design, write and iterate code through to deployment and optimisation

• use of concepts such as, metadata, indexing, modelling and master data management

• experience in communicating complex language and processes and making them simple to understand to a non-technical audience

• experience in negotiating requirements: design, build and test data products that are complex or large-scale

• knowledge and/or experience in data profiling and system analysis and presenting insights to support the end use of the data, using for eg Power Bi

• experience in defining and applying quality and key performance indicators and user feedback to define and improve data and data management systems.

It is desirable that you have:

• working knowledge with Azure SQL databases
• SSAS and DAX (you will have the opportunity to gain exposure to SSAS, DAX, Data Warehousing, cubes analysis and Dimensional Modelling)
• certification in data management or similar industry professional certification.
• an understanding of data protection legislation eg. GDPR
• an understanding of agile approaches and experience of working in agile teams
• experience in developing or engaging with professional communities
• knowledge of best-practice data engineering standards and maintaining those standards

Desirable skills and experience will only be considered in the event of a tie, in order to make an informed decision.
Benefits
Applicants currently holding a permanent post in the Civil Service should note that, if successful, their salary on appointment would be determined by the Department’s transfer / promotion policies.

As a member of the DfE, you will be entitled to join the highly competitive Civil Service Pension Scheme, which many experts agree is one of the most generous in the UK.

You will have 25 days leave, increasing by 1 day every year to a maximum of 30 days after five years’ service. In addition, all staff receive the Queen’s Birthday privilege holiday and 8 days’ bank and public holidays.

We offer flexible working arrangements, such as job sharing, term-time working, flexi-time and compressed hours.
As an organisation, which exists to support education and lifelong learning, we offer our staff excellent professional development opportunities.
Things you need to know
Security
Successful candidates must pass a disclosure and barring security check.
People working with government assets must complete basic personnel security standard checks.
Selection process details
This vacancy is using Success Profiles, and will assess your Strengths and Experience.
Application

This vacancy is using Success Profiles, and will assess your Strengths, Experience and Skills.
Candidates successful at sift will be invited to a video interview.

We will assess your experience in your CV and personal statement based on the essential skills and experience in the advert outlined in the responsibilities section.

Interview

We will assess you against the essential skills and experience in the responsibilities section with strengths also being considered at interview.

Sift and interview dates to be confirmed

Other Information

If successful and transferring from another Government Department a criminal record check maybe carried out.

In order to process applications without delay, we will be sending a Criminal Record Check to Disclosure and Barring Service on your behalf. However, we recognise in exceptional circumstance some candidates will want to send their completed forms direct. If you will be doing this, please advise Department of Education of your intention by emailing Pre-Employment.Checks.DFE@education.gov.uk stating the job reference number in the subject heading.

Department for Education do not cover the cost of travel to your interview/assessment unless otherwise stated.

A reserve list may be held for a period of 6 months from which further appointments can be made.
Candidates will be posted in merit order based upon location preference. Where more than one location is advertised you will be asked to state your preferred location.

New entrants are expected to join on the minimum of the pay band. Applicants who are successful at interview will be, as part of pre-employment screening subject to a check on the Internal Fraud Database (IFD). This check will provide information about employees who have been dismissed for fraud or dishonesty offences. This check also applies to employees who resign or otherwise leave before being dismissed for fraud or dishonesty had their employment continued. Any applicant’s details held on the IFD will be refused employment.

Terms and conditions of candidates transferring from ALBs and NDPBs

Bodies that are not accredited by the Civil Service Commission and are not able to advertise at Across Government on Civil Service jobs will be treated as external new starters and will come into DfE on modernised terms and conditions with a salary at the band minimum.

Bodies that are accredited by the Civil Service Commission but do not have civil service status will be offered modernised terms and will not have continuous service recognised for leave or sickness benefits. Salaries should be offered at band minimum, but there is some flexibility where this would cause a detriment to the individual.

Bodies that are accredited by the Civil Service Commission and do have Civil Service status will be treated as OGD transfers. Staff appointed on lateral transfer will move on to pre-modernised DfE terms (unless they were on modernised terms in their previous organisation). Staff appointed on promotion will move on to modernised DfE terms. Staff will transfer over on their existing salary (on lateral transfer) and any pay above the DfE pay band maximum will be paid as a mark time allowance. Staff moving on promotion will have their salaries calculated using the principles set out in the attached OGD transfer supplementary information.

Reasonable adjustment

If a person with disabilities is put at a substantial disadvantage compared to a non-disabled person, we have a duty to make reasonable changes to our processes. If you need a change to be made so that you can make your application, you should:
Contact Department of Education via centralrecruitment.operations@education.gov.uk soon as possible before the closing date to discuss your needs. - Complete the “Assistance required” section in the “Additional requirements” page of your application form to tell us what changes or help you might need further on in the recruitment process. For instance, you may need wheelchair access at interview, or if you’re deaf, a Language Service Professional.
Any move to Department for Education (DfE) will mean you will no longer be able to carry on claiming childcare vouchers.

Feedback will only be provided if you attend an interview or assessment.
Nationality requirements
Open to UK, Commonwealth and European Economic Area (EEA) and certain non EEA nationals. Further information on whether you are able to apply is available here.
Working for the Civil Service
The Civil Service Code sets out the standards of behaviour expected of civil servants.

We recruit by merit on the basis of fair and open competition, as outlined in the Civil Service Commission's recruitment principles.
The Civil Service embraces diversity and promotes equal opportunities. As such, we run a Disability Confident Scheme (DCS) for candidates with disabilities who meet the minimum selection criteria.
Apply and further information
Once this job has closed, the job advert will no longer be available.
You may want to save a copy for your records.
Contact point for applicants
Job contact :
Name : Data Science Recruitment Team
Email : ds.pmo@education.gov.uk

Recruitment team :
Email : advertsrecruitment.dfe@education.gov.uk
Further information
The Department for Education’s recruitment processes are underpinned by the Civil Service Commissioners Recruitment Principles, which outlines that selection for appointment is made on merit based on fair and open competition. If you feel your application has not been treated in accordance with the values in the Civil Service Code and/or if you feel the recruitment has been conducted in such a way that conflicts with the Civil Service Commissioners Recruitment Principles, you may make a complaint, by contacting the Central Recruitment Team at the following address CentralRecruitment.Operations@education.gov.uk If you are not content with the outcome of your complaint you have the right to complain to the Civil Service Commissioners.
We encourage diverse candidates",4.2,"The Department for Education (UK)
4.2","Coventry, England",-1,5001 to 10000 Employees,1992,Government,Federal Agencies,Government,Unknown / Non-Applicable,-1
Senior Data Engineer,-1,"FanDuel Group is a world-class team of brands and products all built with one goal in mind — to give fans new and innovative ways to interact with their favorite games, sports, teams, and leagues. That's no easy task, which is why we're so dedicated to building a winning team. And make no mistake, we are here to win, but we believe in winning right. That means we'll never compromise when it comes to looking out for our teammates. From our many opportunities for professional development to our generous insurance and paid leave policies, we're committed to making sure our employees get as much out of FanDuel as we ask them to give.

FanDuel Group is based in New York, with offices in California, New Jersey, Florida, Oregon and Scotland. Our brands include:
FanDuel — A game-changing real-money fantasy sports app
FanDuel Sportsbook — America's #1 sports betting app
TVG — The best-in-class horse racing TV/media network and betting platform
FanDuel Racing — A horse racing app built for the average sports fan
FanDuel Casino & Betfair Casino — Fan-favorite online casino apps
FOXBet — A world-class betting platform and affiliate of FanDuel Group
PokerStars — The premier online poker product and affiliate of fanDuel Group
THE POSITION

Our roster has an opening with your name on it

FanDuel Group is looking for an experienced Senior Data Engineer with deep understanding of large-scale data handling and processing best practices in a cloud environment to help us build scalable systems. As our data is a key component of the business used by almost every facet of the company, including product development, marketing, operations, and finance. It is vital that we deliver robust solutions that ensure reliable access to data with a focus on quality and availability.

Our competitive edge comes from making decisions based on accurate and timely data and your work will provide access to that data across the whole company. Looking ahead to the next phase of our data platform we are keen to do more with real time data processing and working with our data scientists to create machine learning pipelines

THE GAME PLAN

Everyone on our team has a part to play
Participating in a continuous improvement feedback loop with the business
Creating cost-effective data warehouse solutions with data that is modelled to suit our users' needs
Working on real time data processing from both operational databases and 3rd party APIs
Working with our data scientists to create machine learning pipelines
Managing data integration solutions from multiple platforms
Designing and implementing complex data pipelines required in the data warehouse and data lake
Delivering complex data modeling and views
Implementing integration solutions including custom solutions needed for our unique industry
Providing design approaches of data pipelines, modeling, testing, and automation tool build
Building automated performance monitoring capability and fine-tuning necessary data and infrastructure changes
Leading a small team of developers who will require mentoring
THE STATS

What we're looking for in our next teammate
Proven working SQL knowledge and experience working with relational databases
Build processes supporting data transformation, data structures, metadata, dependency, and workload management
Mastery of ETL/ELT technologies and concepts
Knowledge of data integrity and relational rules
Experience in a large data warehouse environment
Ability to quickly learn new technologies is critical
Proficiency with agile or lean development practices
Expertise with writing Python scripts
THE CONTRACT

We treat our team right

Competitive compensation is just the beginning. As part of our team, you can expect:
An exciting and fun environment committed to driving real growth
Opportunities to build really cool products that fans love
Mentorship and professional development resources to help you refine your game
Flexible vacation allowance to let you refuel
Hall of Fame benefit programs and platforms
FanDuel Group is an equal opportunities employer. Diversity and inclusion in FanDuel means that we respect and value everyone as individuals. We don't tolerate bias, judgement or harassment. Our focus is on developing employees so that they reach their full potential.",4.0,"FanDuel
4.0","Edinburgh, Scotland",-1,501 to 1000 Employees,2009,Company - Private,Sports & Recreation,"Arts, Entertainment & Recreation",$100 to $500 million (USD),-1
Data Engineer,-1,"Data Engineer - Edinburgh

My client is a highly dynamic and successful Business Intelligence and Datawarehousing Consultancy with a strong presence across the UK.

They currently have an opportunity for a Data Engineer to join them to work on the design and development/build of data solutions for clients.

The role:
You will be multi skilled across the entire technical data management landscape and has experience at varying levels in all aspects of an ecosystem such as Data Storage, Data Ingestion, Data Integration, Data Store technologies and concepts, Data Preparation and Cloud Infrastructure.

You should have a wider understanding of the business problems that manifest into data solutions and be able to concisely articulate to stakeholders and interested parties in layman's terms.

You will also have a wider understanding of how their role and delivery contributes to wider business outcomes and be able to concisely articulate to stakeholders and interested parties their role and solutions in a way that can be easily understood.

You will have either have actual Consulting experience or have good stakeholder management skills and want to grow into a consultant.

Technical skills:
Python, spark, nosql or Kafka experience -
Any cloud data engineering experience in GCP, Azure and AWS
Any R, Tableau, or streamset experience would be an advantage

For more information, please get in touch for a confidential chat",4.7,"Claremont Consulting
4.7","Edinburgh, Scotland",-1,1 to 50 Employees,2002,Company - Private,Staffing & Outsourcing,Business Services,$10 to $25 million (USD),-1
Principal Software Engineer,-1,"At Zoopla we want to help everyone make intelligent home buying decisions. We are building a team that will have the once in a career opportunity to re-imagine our industry.
You will be used to working across an organisation using your capability, charisma, and gravitas to build alignment around a single vision and forging multiple stakeholders and teams into a mutually supportive cohesive group.
You will have spent lots of quality time with your IDE of choice, deeply learning the powerful idioms and important idiosyncrasies of multiple programming languages and their ecosystems. We like to code mostly in Golang, C# (.Net and .Net Core), Python, Node.js / JavaScript and Perl here, but we’re open to all.
You will ideally know AWS as well as you know your best friend, although it’s great if you’re good friends with other cloud services, too.
You will have diligently practiced your engineering craft, mastering your skills in techniques such as test first thinking, refactoring, clean code and pair programming.
You will have implemented organisation-wide CI pipelines and automation, championed the quality and deployment benefits of both to others.
The product(s) you’ve built will have delighted users (perhaps millions of them!) while being stable, performant, observable and supportable. You know the product(s) delighted users because you instrumented, evaluated and iterated on them to be sure.
You will have played key roles in designing and implementing new architectures and technical strategies, while also looking after existing technology real estate.
Importantly, you will have achieved many of the things above while also teaching others, and maybe even sharing your journey and knowledge publicly.
Why Zoopla…
We're serious about tech but we don't take ourselves too seriously.
We are spiritually agile, not religiously agile.
We strongly believe in the value of good design. We believe it is a primary differentiator in an increasingly crowded marketplace.
We believe in the value of data. We run a team that is data informed. We think being data-driven is soulless and dangerous. Clean, confident, clear data combined with the insights of the team is what drives our decisions.
We want to build small, collaborative, cross-functional teams that push each other to create elegant, simple solutions to difficult customer problems.
No matter what the role we want everyone to be obsessed with getting inside the minds of our customers.
How do you know we’re the best place for you?
You strive to set the standard and are always looking to raise the bar and want to be surrounded by others who do so as well
You enjoy knowing your customer
You want to build things together, collaboratively with your team
You want to own it; to have ownership and accountability for the outcomes of your effort
You value sharing and committing to discussions and debates with your teammates
And if you want to come help us re-imagine an industry",3.7,"Zoopla
3.7",United Kingdom,-1,501 to 1000 Employees,2007,Company - Private,Internet,Information Technology,$100 to $500 million (USD),-1
Data Engineer,-1,"Data Engineer, Data and Software Business based in Warwick, Salary circa £25,000 to £35,000 dependent on experience, 25 days holiday plus bank holidays.*
The Company: *
We are an award winning data and software business which has created a market leading property information platform called Nimbus® Maps which not only gives users easy access to a massive aggregated and tremendously useful datasets of property intelligence (from 1000+ data sources) but also invests heavily in training the users on how to get the most from the information.

We believe that every person with an interest in property, be it personally or professionally, can create greater economic and social benefits using our data and technology, and we want to show them how.

We are now looking for a Data Engineer to join our growing team, to take our ETL processes to the next level and play a key role in ensuring the Company has the most accurate and up to date property information in the UK. You will report directly to the Technical Director.

This is a full-time permanent position, 37.5 hours per week Monday to Friday.
Data Engineer Main Duties: *
Being involved in all things Data throughout the business.
Includes data collection, cleansing and management for multiple areas of the business from the various products themselves to the linkage with the customer support software.
Undertaking any other additional duties required by the business from time to time.
Data Engineer Necessary Skills, Qualifications and Experience: *
Previous experience in a similar role.
Previous experience writing ETL processes, ideally using Python or C#.NET is essential.
High understanding of data schemas is essential.
Experience and ability producing business intelligence reports is essential.
Experience integrating third party software such as CRM/Email Marketing etc. and working with GIS/spatial data is desirable.
A high technical aptitude and strong attention to detail.
Excellent communication skills, both verbally and written.
Excellent organisation skills, with the ability to multitask, work under pressure and prioritise work.
Ability to use own initiative and work as part of a team and independently.
Once you have submitted your CV, please complete the comments box and tell us why you think you are the perfect candidate for this position.

While we would like to contact all our candidates, unfortunately, this is not possible so if you haven’t heard from us a week after the closing date, your application has not been successful.

We do not accept applications from recruitment agencies.

Reference ID: NIM09102020

Application deadline: 06/11/2020

Job Types: Full-time, Permanent

Salary: £25,000.00-£35,000.00 per year

Benefits:
Company pension
Schedule:
Monday to Friday
Experience:
producing business intelligence reports: 2 years (Required)
writing ETL processes ideally using Python or C#.NET: 2 years (Required)
similar role: 2 years (Required)
Work remotely:
No",-1,Nimbus Maps,"Warwick, West Midlands, England",-1,-1,-1,-1,-1,-1,-1,-1
Senior Electrical Engineer,-1,"SPW Renewable UK, Ltd

Location:

Glasgow, Glasgow, GB

#job-location.job-location-inline {
display: inline;
}

Facility:

Scottish Power HQ

Company


Company

Iberdrola is a global energy leader, the number one producer of wind power, and one of the world's biggest electricity utilities in terms of market capitalisation. The group supplies energy to almost 100 million people in dozens of countries including Spain, the United Kingdom (ScottishPower), the United States (AVANGRID), Brazil (Neoenergia), Mexico, Germany, Portugal, Italy and France, with a workforce of more than 35,000 people.

Iberdrola is leading the transition towards a sustainable energy model through its investments in renewable energy, smart grids, large-scale energy storage and digital transformation, to offer its customers the most advanced products and services. Thanks to its commitment to clean energy, Iberdrola is one of the companies with the lowest emissions and an international benchmark for its contribution to sustainability and the fight against climate change.

Company
ScottishPower is part of the Iberdrola Group, one of the world’s largest integrated utility companies and a world leader in wind energy. ScottishPower is the first integrated energy company in the UK to generate 100% green electricity. Our focus is on wind energy, smart grids and driving the change to a cleaner, electric future and we’re investing over £7m every working day to make this happen. We’re committed to speeding up the transition to cleaner electric transport, improving air quality and over time, driving down bills.
Purpose
The Senior Electrical Engineer is a key role within the Offshore Renewables Business reporting to the Electrical Systems Manager.

The Senior Electrical Engineer will be responsible for managing the required main electrical equipment engineering design and implementation activities for all stages of development and delivery of offshore renewable energy projects with a focus on HVDC grid connections. Focus shall be required to produce robust and cost-effective engineering strategies, plans and specifications to support the tendering, negotiation, management and execution of offshore supply, installation and maintenance contracts.
Responsibilities
Scope, tender and appoint the requisite electrical design activities to develop and support a robust electrical design basis appropriate for the necessary stages of project development;
Manage the provision of main electrical equipment design data for input into electrical design studies and other design activities e.g. offshore and onshore substations;
Ensure that all main electrical equipment is specified, designed, manufactured, tested, stored, delivered to site, installed and commissioned to meet project requirements and industry best practice;
Ensure that all assessments, advice and recommendations are fully documented in accordance with all internal procedures and industry best practice, and that sufficient technical and commercial due diligence (whether internal or external) exists to support those business decisions;
Maintain full awareness of the latest technical and commercial developments and identify suitable new technology that has the potential to reduce cost and/or risk or improve safety.
Skills and Requirements
Proven experience in electrical design engineering and management for large scale electrical generation plant construction projects, preferably offshore renewables.
A strong understanding of power systems design, main equipment specification, testing, installation, operation and analysis is preferred.
To be successful in this role you will need to demonstrate as a minimum:
Educated to Degree level in relevant engineering discipline;
Substantial postgraduate experience with significant experience in a relevant field (Electrical Power System Design, HVAC substation design, offshore wind or oil and gas preferable);
Experience with EHV/HV systems design / installation/ operation / analysis;
Good appreciation of health & safety associated with offshore/marine construction projects;
Flexible to travel around the UK and overseas.
What we Offer
This is a Permanent contract. Salary for this role will be from £48,080 per annum for Glasgow based employees and £51,440 for London based employees. Other benefits for this role include a performance related bonus up to 15% and single cover health care.
As part of our commitment to a supportive and inclusive place to work, we recognise that our employees have different personal circumstances and want a suitable work-life balance. We are working hard to support flexible and alternative ways of working where possible including: Flexible Working, Shared Parental Leave, Career Breaks, Wellbeing / Employee Assistance Programme. You will also have access to our flexible benefits programme where you can decide what is important for you.

‘Happy to talk flexible working’
Our Selection Process
Process they will follow: Behavioural Based Interview
Behaviours of Individual Contributor: Empower to grow, Collaborate and share and Be agile
Other
Location: London or Glasgow
Closing date: 10th November 2020

Inclusion and diversity fosters innovation and creativity and brings us closer to the communities we serve. At ScottishPower, we want to attract and hire diverse talent whilst developing a workplace that is supportive and open to everyone.

Job Segment:
Power Systems, Offshore Oil, Wind Energy, Energy",3.9,"ScottishPower
3.9","Glasgow, Scotland",-1,5001 to 10000 Employees,1998,Company - Private,Energy,"Oil, Gas, Energy & Utilities",Unknown / Non-Applicable,-1
Data Engineer / Data Scientist,-1,"My client are based in Newport, South Wales, and are seeking a Data Scientist for a 6 month full time contract. The position will be remote working for the foreseeable.

As a Data Scientist at this organisation, you can expect your analysis to be hitting the headlines on a regular basis and being used by decision makers at the highest level.

Required Skills

Strong proficiency with a general purpose programming language (preferably Python, Scala or C).
Experience of Web Scraping/Data Mining/Data Cleaning
Experience in using programming languages to manipulate and analyse large datasets.
Has significant experience building data pipelines at scale using a range of tools
and technologies and can advise on data engineering best practices across industry.
Experience in data engineering concepts (e.g. optimisation methods, data models and structures, algorithms).
Able to listen to the needs of technical and business stakeholders and interpret between them. Able to manage stakeholders' expectations and be flexible, is capable of proactive and reactive communication.
Driven to developing high quality solutions.

The organisation also support flexible working and strive to ensure the best work-life balance possible for their people.

This will be a 6 month contract initially, with the possibility of a transition into a permanent post. The rate of pay is 24.30 per hour (37 hours per week). This is equivalent to around a 36,000 salary.

BBBH35075_160398642365028",4.2,"Concept Resourcing
4.2","Newport, Newport, Wales",-1,51 to 200 Employees,2000,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Principal Data Engineer,-1,"Your new role

As a Principal Data Engineer you will bring passion and creativity to help Highways England better understand, leverage and ‘demystify’ data, to make it more meaningful to non-technical staff, and to build data capability across our organisation. In this role you will work with a wide range of people across the organisation on an array of projects and be responsible for ensuring that all data captured, generated, stored, retained and distributed is modelled and managed appropriately. You will help to lead the specification, design and implementation of the next generation of data solutions within Highways England to support the development of the next Road Investment Strategy (RIS). You will help us to better understand what data we own, manage, and use. You will extract insight from data to understand how we can better connect the country. You will discover opportunities for data acquisition and be in control of innovative new data products in order to help us engage the supply chain and our stakeholders. As Principal Data Engineer will also own key parts of our ‘Data-as-a-Service’ platform, including our Azure cloud architecture for data analysis and reporting.

This is a newly created position and a great opportunity for you to come into an organisation and growing team that is heavily investing in an IT transformation that will allow you to professionally develop and use your experience to improve data efficiency and reliability driving the toward automated, reliable and secure services.

We are happy to accommodate flexible working arrangements, and welcome discussion around how we can make working for Highways England work for you.

What you’ll be leading on
Responsible for the design and implementation of numerous complex data flows to connect operational systems, data for analytics and BI systems.
Define and lead verification and validation activities to provide assurance that data flows are designed, upgraded, managed, de-commissioned and archived in compliance with data policy across the full data life cycle
Responsible for the whole life management data flow models
Responsible for recognising and sharing opportunities to re-use existing data flows
Responsible for the design and build of data pipelines and data streaming systems
Coordinate teams and set data engineering best practice best practice and standards, and champion data engineering across the business, industry & government.
To be successful
Experience of communicating between technical and non-technical staff and suppliers.
Data profiling and conforming to data models in the public cloud.
Understanding and experience of enterprise-scale data integration in the public cloud.
Previous experience of lifecycle management of cloud platforms including infrastructure-as-code, CI/CD, DevOps, and testing.
Exceptional communication skills to convey complex information with enthusiasm to a wide audience.
Ability and proven experience in making effective decisions using data.
Ability to see the big picture, meeting wider public needs, and developing long term strategies.
A bit about us

The Information and Technology Directorate is a growing and vibrant team and there has never been a better time to join us as we go through our transformation programme. We are helping to transform the way Highways England operates by delivering digital, data and technology services from frontline to back office, in a modern and efficient way. Our vision is to develop integrated information and technology that empowers our colleagues and provides real time information to our customers, integration with intelligent vehicle and transport systems as they develop, to improve journey safety and reliability.

Want to know more?

If you would like a copy of the job profile please email recruitment@highwaysengland.co.uk quoting HIG04179.

Interviews are planned to take place mid November 2020.

Why you should join us

At Highways England we believe in a connected country. We are passionate about creating a culture where colleagues feel connected, included and enjoy greater wellbeing to achieve this. We’re proud that as an organisation we are continually striving to do better and actively encourage and support our colleagues to do the same with their careers.

So, if you put safety first, take ownership of your work, show passion for what you do, work effectively in a team, and demonstrate integrity in how you do it – then you’ll be a great fit for our organisation.

And finally

We reserve the right to close before the advertised closing date, so we recommend completing your application as soon as possible.",3.7,"High­ways Eng­land
3.7","Birmingham, England",-1,5001 to 10000 Employees,1994,Government,Construction,"Construction, Repair & Maintenance",Unknown / Non-Applicable,-1
Big Data Engineer,-1,"Duties and Responsibilities:

Help design and deliver the target cloud infrastructure for the Hadoop stack.
Analysis, authoring of user stories and detailed design.
Development of code, scripts, configuration and build automation.
Provide specialist Hadoop and Big Data expertise.
Engage with all members of the scrum team to ensure the technology meets the user needs.
Prototype and prove concepts quickly.
Identify and mitigate risks in development and technology.

Salary for each post: £ 32,000- £36,000 per annum.

c. Skill/experience/qualifications:

Experience in using emerging Big Data tools and technology such as Hive / Hadoop would be a significant advantage in addition to the above.
Experience in Hadoop and its components like HDFS, Apache Pig, Hive, Sqoop.

Experience on Spark Core and Spark SQL.

Experience in importing and exporting data using SQOOP from HDFS to Relational

Database Systems and vice-versa.

Load data in to the HIVE tables.

Experience in analysing data using HiveQL, Pig Latin.

Implemented Spark RDD Transformations and Actions.
Demonstrable experience of infr astructure as code.

Closing date: 04/11/2020

Job Type: Permanent

Salary: £32,000.00-£36,000.00 per year

Work remotely:
No",-1,RELIQ IT LTD,"Didcot, England",-1,-1,-1,-1,-1,-1,-1,-1
AWS Data Engineer,-1,"The Ocean Partnership has been engaged to recruit an exciting opportunity to join a growing global Investment management company based in London. This is a fantastic opportunity for an experienced hands-on AWS Data Engineer to play a pivotal part in the development of the cloud native big data platform.

As the AWS Data Engineer, you will be coding in Python and working with Hadoop in an AWS environment. In addition, you will come from a strong background in working on big data projects and have the ability to work with developers and end users.

Our client values diversity in the workplace and welcomes applications from everyone. If you have a disability and need help with the application process please tell us.

Key remits:
Define requirements, technical architecture and solutions
Develop, document and maintain data
Play a key role in all stages of the ETL life cycle
Communicate with other technology based teams in order to build out data lake components
Support of the production environment
Configuration of lower environments

Experience:
Strong AWS Development experience
Strong programming background in Python
Experience across the Hadoop ecosystem
ETL development and testing in Big Data
An understanding of CI/CD

The Ocean Partnership is a recruitment and inclusion consultancy dedicated to the investments industry. Our mission is to lead the recruitment of diverse talent and champion the adoption of more inclusive working cultures to help the industry innovate.",-1,The Ocean Partnership,"London, England",-1,51 to 200 Employees,-1,Nonprofit Organization,-1,-1,Less than $1 million (USD),-1
AWS Data Engineer,-1,"The Ocean Partnership has been engaged to recruit an exciting opportunity to join a growing global Investment management company based in London. This is a fantastic opportunity for an experienced hands-on AWS Data Engineer to play a pivotal part in the development of the cloud native big data platform.

As the AWS Data Engineer, you will be coding in Python and working with Hadoop in an AWS environment. In addition, you will come from a strong background in working on big data projects and have the ability to work with developers and end users.

Our client values diversity in the workplace and welcomes applications from everyone. If you have a disability and need help with the application process please tell us.

Key remits:
Define requirements, technical architecture and solutions
Develop, document and maintain data
Play a key role in all stages of the ETL life cycle
Communicate with other technology based teams in order to build out data lake components
Support of the production environment
Configuration of lower environments

Experience:
Strong AWS Development experience
Strong programming background in Python
Experience across the Hadoop ecosystem
ETL development and testing in Big Data
An understanding of CI/CD

The Ocean Partnership is a recruitment and inclusion consultancy dedicated to the investments industry. Our mission is to lead the recruitment of diverse talent and champion the adoption of more inclusive working cultures to help the industry innovate.",-1,The Ocean Partnership,"London, England",-1,51 to 200 Employees,-1,Nonprofit Organization,-1,-1,Less than $1 million (USD),-1
Data Engineer / Analyst,-1,"""Our Client will be interviewing and onboarding remotely during COVID-19""

Our client is a highly successful organisation located in Manchester, they are looking to grow their well-established team over the next 3- 6 months.

The Data Engineer will be supporting the business objectives and strategy. You will join an established team; building dataflows into data lake and data warehouses from a wide range of sources.

You will collaborate with data analysts and data scientists on a regular basis to plan and translate requirements into solutions and ensure delivery of successful business outcomes.

Responsibilities and Skills:

Connect API’s, flat files, databases and data streams to the data lake (ETL)
Shape data from the data lake and form a Kimball data warehouse
Ensure that appropriate data quality, integrity and alerting is built into the system.
Comfortable working on the BI Stack, SSIS, SQL server and Power BI
Comfortable working with an AWS-based BI Stack including Lambda, Redshift, Snowflake and Matillion.
Experience with visualisation tools like Cognos, Power BI, SSRS or Business Objects
SQL Server and Redshift management
ETL tools like SQL, SSIS, AWS, Lambda and Python
Good communications skills.

The company will offer a competitive salary plus flexible working.

Data Engineer / Analyst – Manchester",4.6,"Adria Solutions
4.6","Manchester, England",-1,1 to 50 Employees,2004,Company - Private,Staffing & Outsourcing,Business Services,Less than $1 million (USD),-1
Senior Software Engineer,-1,"Description

CORONAVIRUS UPDATE: Hiring at Made Tech continues as usual. Our team are now all working remotely so all interviews will be facilitated remotely too. Hopefully this will still be a good experience for candidates. (feedback welcome)
We're even setup to on-board any new starters remotely should we need to. All our projects are setup to continue remotely as well :)

---------------------------

NOTE: We currently have no open roles at this level for Manchester at this time. We review our requirements frequently and would encourage you to register your interest for this role. You will receive a response from and we'll keep you posted on upcoming live roles at this level :)

Salary range is £45,900 - £63,000 per annum plus a range of excellent benefits. Apply below.

Our Senior Software Engineers are senior contributors to digital, data and technology outcomes that improve society. They do this by delivering and architecting software, and coaching others to do so in public sector organisations, while constantly striving to be nice humans :)

What does the job entail?

We primarily write and deliver custom software for the public sector. We work across central and local government, as well as in health, and our past lies in the technology startup world. Technical excellence for us isn’t about delivering to feature lists. We place a strong emphasis on outcome-based delivery; ensuring our customer’s goals are understood and achieved with the technology we deploy.

Senior Software Engineers find themselves working on a variety of different problems from monoliths to microservices, upskilling colleagues and customers, always finding themselves learning from others, while constantly striving to be nice humans :)

Our teams have used Ruby with Rails and Sinatra, ES6 with React and Angular 2, C# with .NET Core. We don’t limit ourselves as a company and we expect all our Engineers to be keen on learning new technologies. Automation is important to our teams, so we make sure there is a CD pipeline set up to build, test, and release many times per day.

High performing software delivery teams need to be empowered to iteratively and rapidly deliver changes all the way through to production. To do this we combine our extensive cloud automation knowledge with DevOps culture.

We've been using AWS from the start and as Advanced Partners are go to experts within the public sector. We use a range of IaaS, PaaS and FaaS depending on the needs of our users, in this case software teams, such as EC2, Lambda, ECS, Kubernetes, Heroku, CloudFoundry, Azure App Services, and more. We use VPC and PrivateLink for connecting to on-premise, legacy systems. We also use API Gateway, S3, CloudFront, SQS, SNS, SES, RDS, and many other services provided by AWS.

We ensure we document our architecture and infrastructure as code, using technologies such as Terraform and OpenAPI. Containerisation is a big part of empowering our teams to develop, deploy and scale their applications, but so too is using AWS Lambda and avoiding the complexity of stateful services altogether. Right tool for the job.

For us, DevOps is about culture rather than roles and titles. Even though this role is for someone with strong DevOps experience, the biggest impact you will have is coaching and helping teams use the platforms you build. You won't be building infrastructure in isolation or charged with deploying other peoples work into production. You'll empower teams with the mantra: you build it, you run it!

We grow a team of polyglot programmers, which you might already consider yourself to be, who are versed in a mix of paradigms such as object-oriented, functional, declarative, event-based and aspect-oriented. To create this environment our Senior Software Engineers need to embrace sharing their knowledge and skills with others, and they need to keep an open mind – we’d love to hear some examples of mentoring, coaching and growing team members. Maybe you will have written some blog posts about your discipline, or perhaps even delivered a talk or two.

Requirements

What experience are we looking for?

While we will look for you to have experience in these things, if you don’t have one of these don’t let that stop you applying.
Written code with tests
Delivered in an agile environment
Worked with more than one programming language
Worked with databases
Worked with APIs
Debugging experience in a range of systems
Evidence of self-development – we value keen learners
Drive to deliver outcomes for users
Desire to mentor others
Empathy and people skills
Optional experience

Don’t forget to mention any of the experience listed below. While it’s optional, it’s all highly desired!
Consultancy
Working directly with customers and users
Working within multidisciplinary teams with product, design, and technology working within the same cycles
Showcasing and presentation skills
Agile practices such as Scrum, XP, and/or Kanban
Pair programming – we pair around 50% of the time
Writing code with test-driven development
Component-based design techniques such as using pattern libraries, styled-components, CSS-in-JS, BEM, and/or SUIT CSS
Debugging infrastructure
The React ecosystem including a test-driven approach
Infrastructure as code technology like Terraform and Cloud Formation
Familiarity with architectural and design patterns
Use of architectural decision records
Writing blog posts and giving talks
What we will provide you

Balancing life and work:
✈️ Flexible Holiday – We trust you to take as much holiday as you need
️ Flexible Working Hours – We are flexible with what hours you work
️ Flexible Working Days – We are flexible to the amount of days you work in a week
Flexible Parental Leave – We provide flexible parental leave options
‍ Remote Working – We offer part-time remote working for all our staff
Paid counselling – We offer paid counselling as well as financial and legal advice
️ Paid anniversary break – We celebrate your 3 and 5 year anniversary with us by buying your family a holiday
Making work as fabulous as possible:
Work Ready – We'll buy you a Macbook, ergonomic equipment, books, conferences, training, and more
Learn Tech – We spend every Friday afternoon learning rather than working
️ Friday Lunches – We randomly match up 8 colleagues every Friday and pay for lunch
Friday Drinks – We pay for social drinks on a Friday
Compensating you fairly:
Transparent Salary Bands – We publish salary bands so you know you're being fairly compensated
Annual Salary Reviews – We review your salary on an annual basis
⛷️ Pension Scheme – We provide a pension scheme so you can save for your future and we'll contribute to it
Season Ticket Loan – We provide loans to help you pay for your travel
Cycle To Work Scheme – We offer the cycle to work scheme to help pay for your bicycle
Expenses Paid – Taxi to a meeting? Want to take a customer to lunch? Expenses are no hassle!
Salary

This role has a salary of £45,900 - £63,000 depending on experience.",4.6,"Made Tech
4.6","Manchester, England",-1,51 to 200 Employees,2010,Company - Private,IT Services,Information Technology,$1 to $5 million (USD),-1
Software Engineer,-1,"Our Software Engineers are exceptional problem solvers who love working in code. The language isn't important to us, we're interested in seeing how you create code blocks and turn these into tangible products

At Concentra, everyone within our Engineering Team is a Software Engineer at their core, they just happen to specialise in different technologies and disciplines. As a result, when it comes to hiring, we’re not constrained by the tech-stack that you’ve historically used, rather by the way that you approach problems.

What you will be doing
Creating products that delight our customers
Continually developing and improving our code, technology
Working on developing small scale code into full production
Going above and beyond to support your peers where needed
Working as part of a diverse team to solve deep technical problems
Understanding your priorities and how these align to the wider team targets
Contributing to the Engineering culture, through the adoption of best practice
What technologies you’ll use


Our stack here is: JavaScript (React) on the Frontend and Scala on the Backend, but even if you haven’t used these technologies previously, we’re still interested in speaking with you! If you have the core Software Engineering background, picking up new tech should be an exciting challenge!

Requirements

What we look for
Bachelor's degree in Engineering, Computer Science or equivalent practical experience.
Strong understanding of architecture, design patterns and Software Engineering best practises
Ability to work within a start-up environment or a growth business.
Ability to proactively anticipate challenges and obstacles.
Ability to comfortably handle ambiguity.
Our Career Paths


How can I Develop?

We’ve invested time into building a structure within our Technical Teams, where everyone has the same core programming skills, so that no matter what the problem is that we’re looking to solve, we have agile technical talent that is able to work on problems across the entire business.

This is great for you because it means there are clear routes to progress, not just vertically, but also between management and technical expertise, due to the team’s core skillset of Software Engineering.

Our Interview Process


Just so you know what to expect, here are the different stages of our interview process, the stages may change slightly, but you will not only have the opportunity to find out all about the role, but meet the members of our team too:
Talent Acquisition Phone Screen
Hiring Manager Skype Call
Take Home Technical Task
Onsite Interview with Team and HM
About Concentra


Concentra Analytics is a fast-growth SaaS product company with an award-winning, enterprise solution for workforce analysis and modelling.

In 2008, Rupert Morrison, CEO, and his core team of management consultants from A.T. Kearney joined with a software development house, Concentra Consulting, to form what became Concentra Analytics.

Fundamental to the company’s vision is the creation of a suite of SaaS-based products to disrupt the market. These solutions allow business leaders to visualise, analyse, model and address operational challenges through people analytics (OrgVue) and data warehousing (DataPlus).

Fast-forward to 2018, Concentra Analytics completes a £41 million growth equity investment to accelerate its international expansion and support the development of its market-leading, workforce analysis and planning product, OrgVue. Central to securing this investment is the aggressive growth of annuity sales of OrgVue licenses, globally.

Concentra employs 220+ employees and operates from London (HQ), Netherlands, Philadelphia and recently opened offices in Hong Kong and Australia. Concentra has partnerships for coverage in the Middle East, South Africa and other regions. Concentra also partners with the leading management consulting firms who have used OrgVue in over 500 consulting projects.

Benefits",3.7,"Concentra Analytics
3.7","London, England",-1,201 to 500 Employees,2008,Company - Private,Computer Hardware & Software,Information Technology,$10 to $25 million (USD),-1
Senior Machine Learning Engineer,-1,"Company: *
R.grid is an early-stage start-up that streamlines medical research administration using machine learning tools.
Job Overview: *
We are looking for a Machine Learning Engineer with several years of commercial skills in Natural Language Processing.

The job responsibilities include working with a team of software engineers building.

You should have a strong python skills, understand how to test code for commercial production, problem-solving ability and a background in mathematical modelling and statistical analysis. You should be self-motivated, consistent, disciplined and able to deliver to deadlines. If you’re also able to align our products with our business goals, we’d like to meet you.
Responsibilities and Duties: *
Build and expand NLP algorithms, analytic systems, and other predictive models
Plan and manage data projects
Collaborate with a team of software engineers and data scientists
Data mining and collection procedures
Ensure data quality and integrity
Interpret and analyse data problems
Conceive, plan and prioritise data projects
Test performance of data-driven products
Visualise data and create reports
Experiment with new models and techniques
Align data projects with organisational goals
Requirements: *
Authorised to work in the UK without needing host sponsorship (or have a good runway until your current visa runs out)
Proven experience as an NLP Engineer, Data Scientist, Machine Learning Engineer
Solid understanding of machine learning and neural networks
Knowledge of data management and visualisation techniques
Expertise in statistical analysis and predictive modelling
Good knowledge of Python, R, and MATLAB
Experience with AWS
Strong organisational and leadership skills
Excellent communication skills
A business mindset
Degree in Computer Science, Data Science, Mathematics, Statistics or similar field
Benefits:
Semi-flexible pay (Bi-weekly or Monthly)
Business casual dress
Small team
Start-up environment
Job Types: Full-time, Permanent

Salary: £48,000.00-£55,000.00 per year

Benefits:
Store discounts
Schedule:
Monday to Friday
Experience:
AWS: 2 years (Required)
Data Science: 2 years (Required)
Data Visualisation: 2 years (Required)
Start Up: 2 years (Preferred)
Statistical Analysis and Predictive Modelling: 2 years (Required)
Python: 2 years (Required)
NLP: 2 years (Required)
Team Leading: 2 years (Preferred)
Machine Learning: 2 years (Required)
Code Review: 2 years (Required)
Education:
Master's (Preferred)
Location:
London, Greater London (Preferred)
Work remotely:
Temporarily due to COVID-19",-1,Research Grid Ltd,"London, England",-1,-1,-1,-1,-1,-1,-1,-1
Senior Database Engineer,-1,"We bring together a modern edit of over 700 established and new generation designers. Founded over 30 years ago as a brick and mortar store, we transitioned online in 2012. In 2017, APAX Partners acquired a majority stake in MATCHESFASHION, fuelling our expansion. We now ship to 176 countries, have millions of site visits monthly and 98% of our sales are online with the majority of sales made internationally.
We have a global website, mobile apps, retail stores, private shopping, VIP events and 24/7 customer care and MyStylist teams. We have offices in the UK and Hong Kong. In London, our head office is based in The Shard, our brand new creative hub is in Here East.
We lead the way, moving our industry forward, and we are always looking for talented individuals to come in and inspire the world with us.

OUR COMMITMENT TO DIVERSITY AND INCLUSION

Diversity and Inclusion is a priority for MATCHESFASHION – we delight customers around the world and so it’s important that our team represents our customers.

We want to attract the very best talent and create an inclusive environment that celebrates the diversity of our people and enables them to do the best work of their careers. We recognise the world is not a perfect place and that bias exists, which is why we take a focused approach in this area and are are committed to ensuring that all our people processes are equitable.

A Senior Database Engineer is required to join an existing Data team to design and build upon the Enterprise Data-Warehouse and Data-Lake implementation, as well as extend and support Data feeds and Data Services for the business. This will entail data ingestion and transformation of data within the Data Warehouse (SQL Server including dimensional modelling) and Data Lake (AWS & Databricks) and executed using best practice development lifecycle practices via automated CI release pipelines and test-driven development (TDD).

Requirements
Designing, Developing and supporting Data Warehouse, Data Lake and Data Feed pipelines.
Designing, Developing and supporting SQL Server SSIS packages (SSIS) covering the ETL for the Data Warehouse.
Designing, Developing and supporting integration between Data Warehouse and Data Lake (SSIS, Databricks - Python/pyspark).
Designing, Developing and supporting Data Feed pipelines to and from internal and external APIs.
Support DevOps and good software engineering standards delivering quality software products.
Work with other Data Team members (BI Analysts, Data Engineers, Data Scientists) as part of an agile team using Scrum (using JIRA).
Coach and mentor other members of the team through technical leadership, supporting on code reviews and design.
ABOUT YOU

You are a passionate and expert Database Developer and have a proven track record in delivering Data Warehouse and ETL solutions. You have extensive experience with using Python for data wrangling. Ownership of the full software development life-cycle is important to you – from understanding requirements and analysis, TDD, design, development, deploying, releasing, and then support.
Expert Database Developer using SQL Server 2016 and above covering the full SQL Stack (excellent SSIS & good SQL Server administration).
Expert in ETL and Data Warehouse development skills including a very good understanding and practical application of dimensional modelling.
Experienced Python Developer using Python to develop data processing systems.
Experienced in using version control tools, SSDT, using CI tools and automation of the SDLC.
Experienced with using a test driven development (TDD) approach.
Good and proven ability to develop efficient code factoring cost and performance into development.
Excellent data analysis skills, able to trouble shoot and problem solve effectively.
Excellent verbal, written communication skills with an ability to converse appropriately with business users and technical teams.
Good understanding of data privacy and security considerations.
Agile / Scrum background.
Desirable:
Exposure/knowledge of Spark (with Databricks a bonus)
C# programming experience and/or R, Scala, Java.
Retail background exp.
Exposure to a main BI tool advantageous (e.g. MicroStrategy or other main platform)
Exposure/knowledge or appetite to work with other database technologies (NoSQL & Big Data Technologies)
Exposure to Cloud landscapes (AWS but Azure/GCP relevant also) specifically for database development
Exposure or appetite to work in Data Engineering area. An opportunity to cross skill into our other technology stacks exists. E.g. Apache Spark, Scala and streaming technologies.",2.7,"MATCHESFASHION
2.7","London, England",-1,501 to 1000 Employees,1987,Company - Private,"Department, Clothing, & Shoe Stores",Retail,$50 to $100 million (USD),-1
Data Engineer,-1,"Data Science

Zuhlke Engineering is an international consultancy that helps companies achieve success by turning ideas into real-life results. To do this, we provide interdisciplinary teams, currently across Europe and Asia, to work closely with our customers to deliver solutions. In the UK, we support digital innovation and embedded software. Across the group, we cover digital systems, Internet-connected devices, and physical product design (embedded and mechatronics).

Our clients range from the largest multinationals to start-ups: what they have in common is the need for a partner who can be trusted to deliver effectively.

Your job will involve working in small teams, communicating closely with our clients to design, develop, test, and ship systems that deliver value. You will be looking both to contribute to the company and to grow personally.

Our reputation is fundamental to our business, so our culture emphasizes quality, reliability and respect. As a privately-held company owned by past and present employees, and run by engineers, Zuhlke takes a long-term view.

Your continuous education is essential for us! We know how important life-long and fast learning is, which is why we invest 10% of our turnover in developing skills and services in an agile way – matching your needs and those of the company. We strongly believe in developing one's skills ""on the job"" and we encourage this approach in particular. In addition, Zühlke offers a range of complementary training courses tailored to the needs of the company and its employees. And we regularly take advantage of coaching and mentoring.

As part of our longer-term view, we believe that diversity in the workplace benefits all, we have ethical guidelines about which client industries we will work for, and we have an initiative to become carbon neutral during 2020.

Your job will include:
As a Data Engineer you master the big data world and help our customers to make their own data fit for business or operational purpose - whether in the Cloud or in their own data centre.
You develop, test and monitor distributed data processing pipelines.
You work closely with data scientists on the development of machine learning models.
You extrapolate versatile data sets and sources in a performant and repeatable way.
You prepare performance and cost estimates for various use cases.
You develop and create compelling dashboards to visualize the processed data.
You work collaboratively with colleagues and clients, be it onsite, in the Zuhlke office, or from home.
You keep yourself technically sharp and get things done.
You occasionally travel to other Zuhlke locations, e.g. in mainland Europe, for project work or for developing competencies across the Zuhlke group.
Skills & Requirements:
You have a degree in computer science or mathematics, or a comparable qualification.
You have a rich experience of professional data engineering experience, implementing projects in industry and services, ideally in client facing contexts.
You are familiar with big data infrastructures (e.g. Hadoop/Spark ecosystem) and concepts for storing and processing large and/or heterogeneous data volumes.
You have practical knowledge of handling varied types of data (text, tabular, graph, time-series, geospatial, image, etc.).
You have excellent programming skills in Python, Java and SQL as well as hands-on experience with databases (relational/NoSQL), containerisation, and Cloud environments such as AWS or GCP.
You are familiar with business intelligence, data analytics and data visualisation frameworks.
Information security knowledge is a plus.

Our work is mainly at or within an hour's travel from our Shoreditch office.

And Why Zühlke?
✅ Culture of collaboration and teamwork
✅ Variety of impactful and challenging projects
✅ Professional training and development benefits
✅ Strong ethics with a focus on sustainability & inclusion
✅ Sensible work-life balance
✅ Freedom to take over responsibility

Would you like to find out more? Read our Success Stories and join the conversation on our Zühlke Blog.

If you're interested in joining us, send us your CV and start your first step into realising your career goals at a company that values talent and cares about its employees. We are an equal opportunity employer and value diversity at our company.

Diversity & Inclusion at Zuhlke

Being welcome & respected for who you are.
Being heard & appreciated for your perspective.
Being valued, no matter your background.

We welcome people from all backgrounds, regardless of their gender, personality, national origin, race, religion, colour, sexual orientation, gender identity, age, marital status, disability or veteran status.

Covid-19 Notice: We are hiring for this role despite the current circumstances in relation to Covid-19. To protect our employees’ and candidates’ health and safety, we have implemented fully remote interview and onboarding processes for candidates and new joiners until further notice. We are closely monitoring the evolving situation and appreciate your flexibility with any related changes to our interviewing process.
permanent
100%
London

Naomi Smethurst
Talent Acquisition Specialist
naomi.smethurst@zuehlke-careers.com",4.5,"Zühlke
4.5","London, England",-1,1001 to 5000 Employees,1968,Company - Private,IT Services,Information Technology,$100 to $500 million (USD),-1
Data Engineer - Test,-1,"Henderson Scott
https://www.hendersonscott.com/

Are you a Tester within Data who has worked on Data Warehouse projects looking for a role in Greater London (Hounslow)?

Then this is your chance to work at true Scale with huge volumes of Data as a Test SME within Data / ETL / Data Warehousing projects.

You will work end to end on testing, working with stakeholders in the Data Engineering team, creating Documentation, Creating Scripts, using sensible Automation (Test Regression, Integration Tests, Automating Data Creation), Test Plans, Test Delivery, Test Validation. You will follow market trends and offer your insights and opinions on how to continual improve testing within Data Engineering.

This offers:
Testing work within Data that is second to none, true Big Data across a variety of projects
Modern Tech Stack, great relationships with the major vendors that allow for quick tech adoption
Encouraged to learn, grow, achieve your own goals
Progression route to Senior, looking for someone who wants to take advantage of that and take their next career step with them
You will:
Be a Tester on Data Projects / ETL Tester / Data Warehouse Tester (can’t be considered without the data background)
Have to have worked on enterprise level data projects, you will be dealing with 100’s of millions of records
Understand Data Warehouses and worked with ETL before
Strong SQL skills is a must, technical questions on SQL is part of the interview process
Worked on multiple end-to-end Data Test projects
Want to work on Full Test Development Lifecycle and have experience of such roles that cover test documentation, test scripts, test requirements, regression test scripts, test automation
Nice to have:
Selenium, Cucumber, LeanFT, Java, Maven, Jenkins, Git, Netezza, Oracle, Control-M
Worked on Ab Initio or Informatica projects in the past as a test analyst / test engineer / tester
Unix Scripting preferred
Python Scripting
Understand the varied data sources and the movement of data
Cloud experience
You will be an integral part of a Test Team specifically within Data Engineering where your personal development and career development will be supported with your continuous learning encouraged.",4.4,"Henderson Scott
4.4","London, England",-1,51 to 200 Employees,1999,Company - Private,Staffing & Outsourcing,Business Services,$25 to $50 million (USD),-1
Data Engineer,-1,"My Client, a large insurance company based in London are seeking a Data Engineer to help implement some new innovative machine learning applications.

The Data Engineer will work with cutting edge technology and rich data sets to help shape the new data science projects.

The ideal candidate must have:

Experience as a Data Engineer
Big data experience with technologies such as Hadoop
SQL Server experience
Experience with Python
Data pipe-lining experience
Machine learning experience
Agile methodology experience
Experience with AWS
Experience of working within insurance or financial services organisations.
*Please apply if you have the above skill-set **
McGregor Boyall is an equal opportunity employer and do not discriminate on any grounds.

The Data Engineer will work with cutting edge technology and rich data sets to help shape the new data science projects.

The ideal candidate must have:

Experience as a Data Engineer
Big data experience with technologies such as Hadoop
SQL Server experience
Experience with Python
Data pipe-lining experience
Machine learning experience
Agile methodology experience
Experience with AWS
Experience of working within insurance or financial services organisations.
*Please apply if you have the above skill-set **
McGregor Boyall is an equal opportunity employer and do not discriminate on any grounds.

"", ""image"": ""https://www.mcgregor-boyall.com/uploads/mcgr_logo.png"", ""employmentType"": ""Permanent"", ""industry"": """", ""hiringOrganization"" : { ""@type"":""Organization"", ""name"":""McGregor Boyall-Delivering Talent"", ""url"":""https://www.mcgregor-boyall.com/"", ""logo"":""https://www.mcgregor-boyall.com/uploads/mcgr_logo.png"" }, ""jobLocation"": { ""@type"": ""Place"", ""address"": { ""@type"": ""PostalAddress"", ""addressLocality"": ""London"", ""addressRegion"": ""London"", ""postalCode"": ""London"", ""streetAddress"": ""London"" } }, ""baseSalary"" : { ""@type"": ""MonetaryAmount"", ""currency"": ""GBP"", ""value"": { ""@type"": ""PropertyValue"", ""value"": ""50000"", ""unitText"": ""YEAR"" } }, ""url"": ""https://www.mcgregor-boyall.com/jobs/london/data-and-analytics/data-engineer/22513"" }",4.4,"McGregor Boyall
4.4","London, England",-1,51 to 200 Employees,1987,Company - Private,Staffing & Outsourcing,Business Services,$50 to $100 million (USD),-1
Reference Number SMED0744 - Data Engineer,-1,"Are you a self-starter who loves working collaboratively, problem solving and making a difference to health data research and innovation? Do you get really excited by BIG data, innovative data engineering and the potential to deliver and catalyse new research into pragmatic solutions for better health outcomes? If so, you could be working with the Health Informatics Centre team (HIC - https://www.dundee.ac.uk/hic/) at the University of Dundee.

HIC are looking to recruit a Data Engineer for a new and interesting large, 18-month, health data project. The multi-disciplinary project team led by HIC will deliver a UK-wide health data analysis platform for rapid research, linkage and innovation. The outputs of the project will enable the delivery of insights from a comprehensive range of data partners and custodians including key support to government. The team will be looking to curate a standardised dataset accessed across a UK-wide platform for health data and associated datasets.",4.3,"University of Dundee
4.3","Dundee, Scotland",-1,1001 to 5000 Employees,1967,College / University,Colleges & Universities,Education,$100 to $500 million (USD),-1
Data Warehouse Engineer,-1,"""Our Client will be interviewing and onboarding remotely during COVID-19""

Adria Solutions has an exciting opportunity for two Data Warehouse Engineers to join a company that is experiencing rapid growth based in Manchester. As Data Warehouse Engineer you will design, create, maintain data warehouse and analytics architecture and physical components for enabling better use and wider consumption of our client’s data.

The duties of the Data Warehouse Engineer will include:

Work with other members of the Data Engineering team to assist in the definition and development of processes and technical solutions that support secure and efficient data storage, access, and querying
Develop solutions that support a variety of on and off-premise high volume and throughput data sources to enable the effective storage and modeling of data, ensuring it is optimized for storage and to meet requirements for business and technical use cases.
Support new and existing ETL processes, employing industry standards and best practices to enhance the loading of data from and into the different source and target systems
Provide analytical skills into understanding and communicating design specifications to facilitate technical development, including the creation of both high level and detailed design documentation and impact estimation
Fulfill the role of a subject matter expert in data warehousing best practice and implement those practices

The ideal candidate will have:

Strong analytical skills, with the ability to adopt a logical approach to solving problems
Expert data warehouse design, implementation, and optimization
Strong data modeling skills
Excellent SQL scripting
Strong skills in developing code, testing for quality assurance, administrating, and monitoring of databases
Experience in Azure SQL Data Warehouse and Azure Analysis Services
Knowledge of Power BI
Ability to create and maintain sets of reference architecture documentation

This is a fantastic opportunity for two Data Warehouse Engineers to join an award-winning company, where you will work in an innovative and dynamic environment and play a vital part in the company’s transformational journey. For your hard work you will be rewarded with a generous benefits package:

Competitive Salary
Flexible working hours with the opportunity for some home working
An additional day off for your birthday!
Company pension scheme and group life assurance

Data Warehouse Engineers x 2 – Manchester – Competitive Salary",4.6,"Adria Solutions
4.6","Manchester, England",-1,1 to 50 Employees,2004,Company - Private,Staffing & Outsourcing,Business Services,Less than $1 million (USD),-1
"Data Engineer, Internal facing Data Intelligence,",-1,"The UKDI data team continues to grow the UK Enterprise Data Platform (EDP). The team is modernising its data engineering practice and technology. This role is a vital part of that transformation and the successful candidate can expect to contribute to the growth of the in-house capability to build and operate a modern data platform. Candidates will need to be flexible and multi-skilled, clearly able to evidence technology pathfinding and mentoring skills that enable them to lead and develop others whilst also demonstrating flexibility and willingness progress work at all levels to a final deliverable. Candidates will be able to evidence a significant background in the “traditional” Microsoft data stack (SSIS, SSAS, SSRS, etc.) but must also have recent experience of the technologies associated with “big data” such as using Spark based platforms and data lakes in ETL/ELT solutions, such that they can clearly communicate how their own experience profile supports the transition described above.

PwC offers a fantastic work environment with offices throughout the UK and bases in all major regions. The team is highly distributed and team members enjoy world-class collaboration facilities which support staff to be productive whether they work from home or office.

Essential Skills

4 months’ experience developing data pipelines on a spark based platform such as Databricks with languages such as Python/PySpark (preferred), R or Scala and libraries such Pandas (or Koalas).

18 months’ commercial experience working with the Microsoft Azure data engineering platform...Azure Data Factory (v1-v2), Azure Data Lake (Gen1 & Gen2), Azure Blob Storage, Azure SQL Server, ADF Integration Runtime and SSIS IR.

5 years’ commercial experience developing developing SQL server database solutions using declarative development in Visual Studio and skills in T-SQL, SSIS, JSON, Powershell and C#

3 years’ experience of acting as a lead/senior data developer across at least 3 distinct projects with responsibility for overseeing/mentoring junior developers.

3 years’ commercial experience on logical and physical data modelling and strong knowledge of techniques such as dimensional modelling

Use of GIT and Azure DevOps (VSTS) with good understanding of code merges, pull requests, unit tests, branching strategies, build and release pipelines within a CI/CD DevOps model

Familiarity working within an Agile (Kanban/Scrum) environment in a product based development approach. In particular the definition, estimation, tracking and refinement of work items, acceptance criteria, identification of the MVP, approaches to vertical slicing and breaking work into manageable deliverables aligned to commercial value.

Personal Qualities

Candidates will be…

Demonstrating leadership and gravitas and able to evidence operating in a technology leadership/consultative mode, as against simply a developer working to specs

Flexible, responsible and self-starting, willing to “get stuck in” to get the job done, whatever task is needed from mundane to strategic and architectural

Experienced with clear evidence of successful assignments.

Excellent written and oral communication skills

Able to work independently but judge when to seek guidance and authority

Tenacious, able to work in and understand the issues associated with both mature and developing environments e.g. code-drift, management of legacy objects and tech-debt, balancing user-demand and platform growth

Demonstrate the ability to mentor technically and to “pathfind” with new technologies with a willingness to share knowledge and learn from others.

Beneficial skills

Candidates possessing the core skills will be particularly attractive where they can demonstrate the following (as commercial experience where stated) in addition to core skills.

6+ months experience working with NoSQL data sources such as Mongo DB, CosmosDB and/or JSON/XML payloads from REST APIs

6 month experience of developing or supporting the deployment of machine learning models

Experience of Data Vault 2

Commercial experience working on Azure SQL Data Warehouse

Authoring BIML and BIML script in automated development cycles or similar (T4)

VBA development

SAP ECC data use through SAP BW and/or HANA

Commercial experience of alternate cloud platforms e.g. AWS/GC

Commercial experience of the Hadoop ecosystem

Familiarity working within controlled application lifecycles and regulated industries.

Familiarity with the use of Google office productivity,

Experience of working with distributed teams, colleagues and stakeholders

The use of formal change control procedures, in particular use of the Service Now platform",3.8,"PwC
3.8","Leeds, England",-1,10000+ Employees,1998,Company - Private,Accounting,Accounting & Legal,$5 to $10 billion (USD),-1
Data Engineer,-1,"Further Job Details


Position Description


This is great, unique opportunity for someone currently operating at a Data Engineer level, who is looking to take a step up into a more senior role, in a new role and new team.

As British Insurance Awards 2019 winners of General Insurer of the Year, this role is a great opportunity to start your career in one of the UK’s top insurance businesses to shine as a data expert at Allianz.

At Allianz, there’s a growing focus on data and data-driven decision-making and in this senior level Data Engineer role, you will be part of a new team, Data Engineering, in the newly established Office of the Chief Data Officer (OCDO). As a Data Engineer based in our Head Office in Guildford, you will have responsibility for line managing and developing/teaching two graduate data engineers as well as getting the chance to expand your knowledge of different data technologies and explore new and exciting capabilities.

Data engineering is an enabler and is about getting the right data to the right place at the right time. Key tasks for you will include: the integration of data from source systems, other internal datasets and external data sources. You will be responsible for designing and building our ETL pipelines, constructing domain warehouses and the Enterprise Data Warehouse (EDW). We are using Azure technologies on our Global Data Platform.

You will work closely with the Information Data Governance team, instilling best practice. Other key customers include: data scientists and Business Intelligence teams.We increasingly work in a fast-paced, agile, and continuous delivery environment. The right candidate for this position will be motivated by this challenge and will help to develop our future ways of working.


Skills & Experience


You will be looking to move to this level after having a number of years experience in a more junior role. You will have a degree, MSc or PhD in a numerate or scientific discipline (e.g. Computer Science, Physics, Mathematics etc), as well as the following:

• Previous line management , including training and developing junior members of the team
• A good understanding of data warehousing concepts, including data warehouse technical architectures, infrastructure components, ETL/ELT and reporting/analytic tools
• Azure experience, including expert understanding of Azure Data Lakes
• Strong experience in the extraction of data from SQL servers
• Strong in some programming languages, like Python, R and Scala
• Ideally will worked in the wider financial services or insurance sector
• High level of accuracy and attention to detail and the ability to simplify problems into component parts and deal with them systematically
• Desirable but not essential - understanding of Meta-data driven data ingestion using Kafka
• Desirable but not essential - understanding of Postgres databases
• Desirable but not essential - experience of data visualization tools (QlikSense etc)


What we can offer you


Recognised and rewarded for a job well done, we have a range of flexible benefits for you to choose from - including retail discounts and insurance cover - so you can pick a package that’s perfect for you. We also offer flexible working options and global career development opportunities across the wider Allianz Group. That’s on top of enjoying all the benefits you’d expect from the world’s number one insurance brand, including:

• Flexible buy/sell holiday options
• Competitive bonus scheme
• Generous pension contributions
• Development days
• A discount up to 50% on a range of insurance products including car, home and pet
• Retail discounts


About Us


At Allianz we want everyone to bring their full self to work, so we invest in our people’s personal and professional development. This helps us build the high performing workforce of tomorrow, but don’t just take our word for it – at the British Insurance Awards we won seven awards, including General Insurer of the Year and Commercial Lines Insurer of the Year.

We’re at a pivotal moment in our history following the purchases of the LV= General Insurance Group and the General Insurance division of Legal & General, making us the second biggest general insurer in the UK. We’re building our future together, and we’re excited about the possibilities ahead – interested in being part of the team?


Additional Requirements


At Allianz we believe that the difference in our people makes the difference to our business. We’re committed to removing any barriers in our recruitment process so if you’re having difficulties with your online application or any other stage, please email us at hr-recruitment@allianz.co.uk

For external applicants only –
Please be aware that we will require satisfactory pre-employment evidence to include DBS, Financial Probity and Fraud checks, before you can commence employment with us.",3.7,"Allianz Insurance
3.7","Guildford, England",-1,1001 to 5000 Employees,-1,Company - Public,Insurance Carriers,Insurance,$500 million to $1 billion (USD),-1
Data Engineer,-1,"We want to make you one of our Specialist Data EngineerConsultants.

What is Data Engineering? FULLY-FUNDED REMOTE TRAINING UK BASED. (WFH)

The world of Data is growing at an extremely rapid pace and the skills needed to work within this space are growing at a similar rate.

Working within Data roles requires transitional skill sets, such as numerical and analytical skills, but it is now expanding into managing data in a variety of storage systems (e.g. databases, data warehouses, data lakes) using programming skills in languages like SQL and Python. As businesses store and handle more and more data, skills in Big Data technologies like Hadoop and Spark are increasingly relevant.

Strong communication skills are vital in transforming data to be used by different parts of the business effectively. This could mean ensuring that the data is transformed into the correct format for the data analysts or working closely with the data scientists to ensure that their data pipeline can support their algorithms. Don’t worry, you’re not expected to know how to do all of this already, that’s where we come in.

We want to help you grow into someone that can deal with everything from visualization tools to big data handling and everything in between. By training in one of our world-class academies, we will make you a specialist consultant who will then work with our clients to help them realize their business needs.

Essential Skills:

Excellent team player
A love for technology and its application
Prioritization and organizational skills
Clear and transparent communication
Critical Thinking and Problem Solving
Decision Making
Adaptability
Presentable, professional and punctual
Able to travel throughout the UK

Desirable but absolutely not essential – If you know them, great; If you don’t, we’ll teach you.

SQL
Scripting skills – Bash / Python / Similar tools
Ability to query large data-sets
Able to create ETL data pipelines
Big Data Platforms
Cloud platform technologies
We like STEM degrees, but we consider all applicants",3.9,"Sparta Global
3.9","Birmingham, England",-1,201 to 500 Employees,2014,Private Practice / Firm,IT Services,Information Technology,$25 to $50 million (USD),-1
4th Line Software Support Engineer,-1,"4th Line Software Support Engineer

Company


Graphnet

Location


Milton Keynes

Overview


Graphnet are a software development company that provides solutions to the healthcare IT market and we are seeking a talented and experienced 4th Line Software Support Engineer to join our support team based in Milton Keynes.

The successful candidate will be working for a dedicated team involved in the support, deployment and BAU function across our user base including our Azure customer platform. The ideal person will be familiar with operating in a regulated environment with a strong focus on retaining maximum uptime, data quality and integrity, and have an appreciation for security and information governance.

This role will require experience in supporting, troubleshooting, and resolving issues with software that runs on-prem and within an Azure App Service environment. The candidate will be comfortable analysing code and making changes to code to address issues, working closely with the development, QA and DevOps team. The candidate will also be involved with developing tools and processes to help support the day to day tasks of the Operations team.

This role will also include shift work over weekends and evenings. The person we are looking for will need to have 4+ years commercial 4th line support experience who can demonstrate a real passion for resolving programming issues, with a flexible and creative attitude, good communication skills and a strong work ethic.

Personal attributes
Able to work well as an individual and as part of a team
Able to mentor junior members of the team
Comfortable in taking part in technical discussions with both technical and non-technical people
Keen to progress a career in software support with a focus on development and tooling
Able to self-manage and self-motivate
An eye for detail to identify and resolve issue with code
Good English language skills, written and verbal
Able to work under pressure
Experience and skills required
Practical experience with C#, with an in-depth knowledge of the .NET framework
Experienced with using the Visual Studio development environment
An excellent understanding of web development concepts and technologies including:
ASP.Net MVC
XML and JSON
HTML / CSS / Javascript / JQuery
RESTful APIs
A good understanding of relational / transactional databases, SQL Server and SQL Azure
IIS
Azure App Service
Scalability and Deployment
Azure Functions and Logic Apps
Azure Redis Cache and Azure Storage
Azure API Management
Experience with the following
Active Directory including Azure AD and Azure B2B / B2C
SQL Server
MS Servers
Networks
Azure
O365
Experience in analysing data pipelines including
Azure Logging and Monitoring (Log Analytics / App Insights)
Messaging concepts at enterprise scale e.g. service bus, event hubs
MSMQ
Advantageous but not essential
Integration Engines (BizTalk, Rhapsody)
Raven DB NOSQL Document DB
Healthcare software development
Knowledge of HL7 data and other healthcare messaging standards
Knowledge of ETL methodologies
Qualifications in one or more of the following
A degree in IT, Computer Science or related discipline
Microsoft certification in web development or Azure based certification
CompTIA certifications in networks
Applications


Please apply in writing, sending a covering letter & CV to hrrecruitment@systemc.com",4.4,"System C Healthcare
4.4","Milton Keynes, England",-1,201 to 500 Employees,1983,Company - Private,Computer Hardware & Software,Information Technology,$25 to $50 million (USD),-1
Data Engineer - Tech Analyst,-1,"We’re Sky, Europe’s biggest entertainment brand. Think top-quality shows. Breaking news. Innovative tech. Must-have products. Careers here mean the freedom and support you need to make an impact – pushing boundaries, creating solutions, hitting targets. And as part of our close-knit team, you’ll enjoy plenty of benefits. Plus, experiences you’ll only find at Sky.

“We are leading the way in many areas of data, from delivering business critical reporting, to providing an essential analytics platform to an elite team of data scientists and analysts. Our solutions are essential to hundreds of users, providing key insights on Sky’s customers, products and viewing content and a whole lot more. Delivering innovative solutions for new products and initiatives is what we do, every single day. We are the team responsible for bringing together thousands of data feeds from hundreds of systems, into our state-of-the-art cloud platform” – SNR Data Engineering Manager – Michelle Rhodie

Do you want to be part of a team that is pushing aside boundaries and bursting out into the Cloud? If you thrive in an environment where no two days are the same, want to influence, create and work with exciting cutting-edge technologies, then this role could be for you.

Data, Technology & Analytics (DTA) at Sky is on a mission to bring customers more of what they love by unlocking the power of data and make Sky more relevant.  We are working with the rest of Sky to create innovative data products that are going to change Sky and bring value to our customers.

The Perks:

Sky Q, a generous pension and private health care. Access to over 12,000 LinkedIn Learning courses to support your development. And if that’s not enough, our Scotland offices have a subsidised canteen, free shuttle bus service, on-site gym and much more.

You will:

– Collaborate with our many stakeholders and business areas to understand the business issues and data challenges, thereafter developing requirements, specifications and recommendations related to a proposed solution

– Design of Data Models and ETL pipelines to meet the business requirements in the most efficient manner

– Work effectively across the DTA team to playback the business challenges and proposed changes, to ensure we collectively have full understanding of the impact and retain a close relationship throughout, to ensure that the requirements are met

– Contribute towards defining analysis best practice and standards and ensuring consistency of delivery across the team

– Mentoring and coaching other members of the team, acting as a role model

– Supporting & deputising with line Manager where necessary

You’ll have:

– Comprehensive Cloud migration experience

– Proven experience of delivery of analysis across large scale data warehousing projects applying principles in terms of dimensional modelling and ETL pipeline design

– Experience of translating diffuse and complex business requirements into user stories covering functional, non-functional, security and acceptance criteria

– Excellent SQL skills enabling large scale data transformation and analysis

– Experience in cloud based ETL environments, preferably Google Cloud Platform.

– Exceptional communication and interpersonal skills and a proven ability to influence technical decisions in a fast-moving commercial environment

– Effective management of multiple priorities and conflicting requests

So, what are you waiting for? Apply now for a chance to forge your own career path and be brilliant as part of a bright, talented team.

Just so you know: if your application is successful, your appointment will be subject to receiving a positive outcome from your criminal record check.

We’re happy to discuss flexible working.

It’s our people that make Sky Europe’s leading entertainment company. That’s why we work hard to be an inclusive employer, so everyone at Sky can be their best.

A job you love to talk about",3.8,"Sky
3.8","Livingston, Scotland",-1,10000+ Employees,1989,Company - Public,TV Broadcast & Cable Networks,Media,$5 to $10 billion (USD),-1
Business Intelligence Data Engineer,-1,"The Business Intelligence Engineer role is a demanding role in a fast-paced environment. It involves managing and monitoring data across multiple data-warehouses and responding to a vast range of requests for reporting purposes and ensuring data accuracy. You will work as part of a flexible software delivery team working in a variety of styles, including Agile.

The softwares/languages the team are currently utilising include SharePoint 2013, Microsoft SQL Server 2005/2013, SSIS 2005, SSRS 2005/2013, SSAS 2005, T-SQL, Oracle-SQL, MDX.

The team are heavily involved in work relating to DVLA’s legacy estate, and we are looking for an enthusiastic individual to join us. This is an interesting and dynamic role in a high-profile organisation, so you will need to have experience in data warehousing, analytics and reporting.

Responsibilities
Role responsibilities

Your duties will include but are not limited to:

• Working on technical implementation of applications. On larger projects working within a technical framework of the project to meet customer requirements.
• Software development using both recognised and/or specialist programming languages and technologies.
• Conducting Unit Testing of developed applications against agreed standards.
• Participating in Continuous Improvement and defect fixes that can be carried out to improve Application performance.
• Supporting the creation of standardised documentation following the agreed standards and processes.
• Staying up to date with latest technologies.

For more information, please see the attached Role Profile.

Would you like to find out more about the role, the team and what it’s like to work at DVLA? If so, we are organising a familiarisation session where you can virtually 'meet the team' on Wednesday 11th November 2020 at 10am, please email ITSRecruitment@dvla.gov.uk to book on.

About you

An ideal candidate would have a basic understanding of data engineering. You will have awareness of T-SQL or other programming languages and be able to demonstrate the competencies to rapidly acquire or improve on these skills.

You will have experience of working with large amounts of data, ideally in a database environment and excellent written communication skills to communicate effectively to customers at all levels of the business. We are looking for someone who is reliable, pro-active, logical and possesses good problem-solving skills. We need someone who can work well under pressure, adapt to different demands and data requests and work to tight deadlines.

Additional Skills and Experiences

• Good analytical skills
• Working collaboratively as part of a team

Please note, the role profile mentions a Computer Science Degree or a recognised IT qualification. These qualifications are not a requirement of the role.

If you would like to read more about the great opportunities at DVLA please click the link here

To find out more about what it is like to work for DVLA, please click on the following linkInside DVLA Blog
Behaviours

We'll assess you against these behaviours during the selection process:

Changing and Improving
Delivering at Pace
Technical skills

We'll assess you against these technical skills during the selection process:

SFIA – Programming/Software Development PROG - Level 3
SFIA - System Design DESN - Level 2
SFIA - Application Support ASUP - Level 3
Benefits
Being part of our brilliant Civil Service means you will have access to a wide range of fantastic benefits. We offer generous annual leave, attractive pension options, flexible working, inclusive working environments and much more to support a healthy work/life balance.

If you would like to read more about the great opportunities and benefits of working at DVLA visit our Careers website.",4.0,"UK Government - Driver and Vehicle Licensing Agency
4.0","Swansea, Wales",-1,5001 to 10000 Employees,2002,Government,Federal Agencies,Government,$100 to $500 million (USD),-1
Python Data Engineer,-1,"An international company that are currently engaged with over 75 million people worldwide are looking for a Data Engineer with Python coding skills.

You'll collaborate with other scrum team members to design and build automated data visualisations which will provide insight into an ever-evolving Google Cloud Platform (GCP) estate. The focus of your work will be on test-driven development and building automated code tests. In addition, you will develop and refine prototype Alteryx ETL pipelines and transform them into Python processes that can be hosted on Google Cloud Platform (GCP).

To do so, you'll extract data from a wide variety of sources using APIs such as REST, converting prototyped ETL pipelines in Alteryx to Python code to power visualisations. Your experience with Google Cloud tools such as BigQuery and Dataflow will be crucial, as the fully automated Python-based ETL pipelines you create will be hosted on Google Cloud Platform.

Sound interesting? Get in touch with your CV and code portfolio.",3.7,"Linux Recruit
3.7","London, England",-1,1 to 50 Employees,-1,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Data Engineer (UK/Spain),-1,"Based: Either in our London or Madrid office, or remotely anywhere in the UK or Spain

Salary: £45k - £55k

The company and our mission:

BridgeU was founded with the belief that talent is equally distributed across the globe, but opportunity is not. We take pride in helping students discover and explore the best pathways available to them - wherever those opportunities may be. We help universities to discover and attract the schools and students that will contribute to their vibrant, diverse and successful programs and courses.

In the fast-changing world of education, and in the ‘new normal’ in the wake of Covid-19, we believe BridgeU had never been more important to help students, schools and universities discover new opportunities globally and connect at a distance.

Today, BridgeU is the market leading provider of university and careers guidance software to international and globally-minded secondary schools. BridgeU is proud to work with secondary schools in over 300 cities across 119 countries. And, we partner with a quickly-growing number of leading universities, currently in 8 countries, to connect recruitment and admissions teams to the largest community of international schools available on one platform.

BridgeU has the approach and pace of a start-up, where there are always opportunities to try something new and grow, with, since early 2020, the support and stability of being part of Kaplan International, part of one of the world’s largest and most diverse education providers.

Who you’ll be working with:

Our teammates are talented people that come from a variety of backgrounds. We’re committed to building an inclusive culture based on trust and kindness, which creates a good work environment that helps enrich both the product and the support we provide to our customers.

We currently have offices in London, Madrid and Hong Kong as well as fully remote employees. Since March 2020, due to the Covid-19 pandemic, BridgeU’s whole team has become a fully remote workforce, and we are aiming to continue a remote-first culture even when our offices do re-open. This role could be office-based or fully remote, and could be based anywhere in either the UK or in Spain.

In normal times we aim to travel regularly between our offices to have face-to-face time with other team members to bond, work together and have some fun. We’re aiming to get back to this in a post-Covid world as soon as is feasible. In the meantime, we’ve been socialising, playing games, hosting quizzes, and other things, online so that we stay connected to one another.

What’s the opportunity?

We are looking for a smart and enthusiastic new member to join our data team. The distinction between Data Scientists and Engineers can often be a bit blurred, particularly when working in a startup, and our ideal candidate would be happy working in both areas. If you’re looking for a role where you’ll be solving challenging engineering problems one day, and have the opportunity to develop a new ML model the next, then this job might be perfect for you.

What you’ll be doing…

Life in a startup is naturally very varied, and in a small data team you’ll have opportunities to do both Data Science and Engineering. The following are all areas we have been particularly involved with in the last two years, so you can expect to work on several of the below:
Improving our university and course recommendations, using machine learning to find best-fit higher education options for students.
Building the infrastructure that enables us to standardise university data from a wide range of sources, and automate keeping everything up to date.
Creating a platform for school analytics, enabling schools to understand the factors that impact their students’ success.
Developing new techniques that make use of various data sources to link students’ degrees and interests with potential jobs and career pathways.
Writing and reviewing production code (mostly in Python). Our data team is responsible for gathering and cleaning raw university and course data, running our recommendations services, and developing models.
Building models to help the Customer Success team predict the ‘health’ of school accounts, based on site usage, and account data.
10% Investment time - working on anything that you think might add to BridgeU’s appeal / improve our working processes. This can include studying topics of interest and learning from or educating the rest of the team.
Creatively solving a variety of other business problems - you will be working in a small team of four people in a fast growing, data-informed Startup, so will have regular and varied challenges. Every day ends up being a bit different!
We have created an environment where collaboration and learning are highly encouraged, trusting each others’ decisions and empowering autonomy. Our development process involves paired programming sessions and code reviews that give us the opportunity to learn something new and bring useful discussions every day. We are committed to supporting the movement towards a fully remote, distributed team and the way we communicate with each other reflects this long-term goal.

Requirements

What you’ll bring:
Strong programming skills (particularly Python, SQL, Git), and the ability (and desire) to work as part of a development team.
Experience working with real world data. You don’t have to be a Data Scientist, but you should understand the complexities of dealing with and cleaning messy data.
Some familiarity with using data and machine learning packages in Python (Numpy, Pandas, Scikit-Learn etc.).
Understanding of cloud-based ETL / data pipelining architectures is a big plus (we currently use Google DataFlow, BigQuery and Apache Beam, but understanding of alternatives is fine).
Experience with the Data Science process / applying Machine Learning models is a big plus, although not required if you are a strong data engineer.
Pragmatism. There is always lots of important stuff to do, and whilst we always want to produce work of the highest quality, the ability to balance this with the needs of a fast moving startup is crucial.
Creativity. Often the ideal data isn’t available, or there are limitations that prevent the use of standard approaches. You will need the ability to come up with novel solutions to problems, and go out in search of data or knowledge that we may not already have.
Enthusiasm and positivity! The friendly culture at BridgeU is very important to us, and we believe that a positive attitude goes a long way.
Benefits

What the company provides:
Competitive salary based on your experience
Personal development: the company can fund books, courses and conferences that can help you learn and grow.
Investment time: every two weeks on Friday we spend time learning or collaborating on projects that can benefit the company or the community.
Opportunities for flexible working hours, encouraging everyone to have a healthy work-life balance and striving to create an environment that is inclusive for everyone, including working parents
Annual offsite: we organise a retreat once a year where the whole company gets together (we did this remotely this year)
Regular socials with the whole team
A comfortable and Covid-secure office space in Angel, N1, or in Madrid, should you wish to use it
Career progression and development
Employer’s pension scheme
An open and democratic work culture where everyone can contribute, learn and teach
Equal Opportunities

We are a global team with a global mindset, cherishing and protecting diversity as one of our core values. We are always looking to diversify the talent in our team and with that in mind would especially encourage applications from female candidates, and any candidates from an ethnic minority background.

Applications from individuals are encouraged regardless of age, disability, sex, gender reassignment, sexual orientation, pregnancy and maternity, race, religion, belief, marriage or civil partnership.",3.9,"BridgeU
3.9","London, England",-1,1 to 50 Employees,2014,Company - Private,Colleges & Universities,Education,Unknown / Non-Applicable,-1
AWS Data Engineer,-1,"AWS Data Engineer

AWS, Data Engineering, Python, Lambda, ECS, EMR, Glue, Glue-ETL, IAM, Cloudformation, Pyspark, Data pipelining, Cloud, Big Data, Spark, CI/CD, Data Warehousing

An excellent contract opportunity has arisen for an AWS Data Engineer to work for a leading Asset Management organisation on a Data lake implementation project. This contract is inside ir35 (PAYE) and is an initial 6 month term.

The role is London based, but will initially be remote.

Key skills/experience required:
Strong AWS development experience using services such as: EMR, S3, ECS, IAM policies, Glue (data catalog and ETL), CloudFormation, Lambda, Step Functions, CloudWatch, KMS, SNS and Service Catalog
Strong commerial experience across the Hadoop ecosystem: Spark, HDFS, YARN, Hive, Presto, etc. Strong Spark experience is a significant advantage
Strong programming background (3+ years) in Python
An understanding of continuous integration and deployment (CI/CD). Experience with Bamboo is a plus
Data Warehousing design and data modelling, ETL development and testing experience in Big Data technologies including SQL
Experience with support and application maintenance knowledge with the ability to resolve system issues, data issues and bug fixes
Experience of handling data in various file types; JSON, XML, Parquet, data frames, etc.
Experience with Atlassian tools: Jira, Confluence and Bamboo alongside GIT (or similar)
Please respond with an up to date CV for further information - ncarolan@mcgregor-boyall.com

McGregor Boyall is an equal opportunity employer and do not discriminate on any grounds.",4.4,"McGregor Boyall Associates
4.4","London, England",-1,51 to 200 Employees,1987,Company - Private,Staffing & Outsourcing,Business Services,$50 to $100 million (USD),-1
Senior DevOps Engineer,-1,"Senior DevOps Engineer

Belfast, Northern Ireland

Congruity360 is headquartered in the Boston metropolitan area with major offices in New York City, Los Angeles, and Belfast Northern Ireland. The recent EDM Consultancy acquisition is requiring rapid expansion of Congruity360’s Belfast team, which is our corporate Research & Development Center of Excellence. Candidates will be given opportunities to work on cutting edge machine learning (ML), natural language processing (NLP) and data modeling technologies as well as more common full stack development and UI/UX projects.

The Congruity360 flagship product, Classify360, enables clients to reduce their financial and data risk by increasing their data understanding, classification, and security, allowing clients to meet all of the current, new, and changing laws, regulations, and business drivers. In other words, making intelligent business decisions.

We have an immediate need for a talented Senior DevOps Engineer to add to our growing Classify360 engineering team. Please contact us immediately if you want to challenge yourself by working in a startup team within an established company.

SUMMARY OF POSITION:

Congruity360 is seeking an experienced DevOps Engineer for our market leading Classify360 SaaS solution who will work alongside development, design, UX, automation and operations in order to identify and eliminate constraints in the product life cycle. Bring your superior skills, expertise, and knowledge for deploying 100+ billion data record systems, and we will challenge you with exciting work!

ESSENTIAL DUTIES AND RESPONSIBILITIES:

Candidates will be expected to perform a variety of tasks, including:

· Facilitate collaboration, sharing, and cross-pollination of skills with other engineers, product owners, designers, testers, and business units in order to overcome challenges, increase product quality, and optimize workflows.

· Develop solutions encompassing technology, process and people.

· Maintain strong expertise and knowledge of current and emerging processes, techniques and tooling.

· Work closely with UX, design, development, automation and operations teams to ensure that solutions are designed with customer user experience, scalability, performance and operability in mind.

· Effectively manage and assign projects as necessary while lending support to the team.

· Actively troubleshoot any issues that arise during testing and production, catching and solving issues before they launch.

· Stay current with industry trends and knowledge, always looking for ways to help business improve.

· Deploy updates as required while implementing integrations when they arise.

· Test our system integrity, implemented designs, application developments and other processes related to infrastructure, making improvements as needed.

· Other duties as assigned.

· Any other duties delegated by the Classify360 Development or Company management team.

ORGANIZATIONAL RELATIONSHIPS:

Candidate will report directly to the VP of Development and works with the Classify360 team resources and other Company teams as necessary.

Qualifications

· 4+ years of experience in DevOps, SRE, Software Development or an equivalent field.

· A history of collaboration with development, operations, UX, design and business units within an organization.

· 4+ years experience working with Azure. Also working with AWS is a plus.

· Experience working with Jenkins. Other CI/CD tools and pipelines such as Buildkite, TravisCI, Concourse CI, or equivalent are a plus.

· Experience working with Terraform. Other infrastructure tools such as Azure ResourceManager, AWS CloudFormation, or equivalent are a plus.

· Experience working with Kubernetes. Other Docker and Docker orchestration tools such as Docker Compose are a plus.

· Knowledge of version control software, Bitbucket is preferred.

· Proficiency with Linux.

· Excellent oral and written communication skills.

· Azure certifications are a BIG PLUS. AWS certifications are a bonus.

FUNCTIONAL SKILL REQUIREMENTS:

Having any of the following industry and functional skills or knowledge would be a plus:

· Information Governance (IG), records management, enterprise search, data classification, compliance, eDiscovery

· GDPR, CCPA, and other privacy acts

· Information security, data security, cyber security

· Financial services, Healthcare, Pharmaceutical, Consumer Good industries

EDUCATIONAL AND EXPERIENCE REQUIREMENTS:

A University degree is required with a major in Computer Science, Mathematics or Physics. Candidates must have 7-10+ years total technology related experience with 3+ in an actual DevOps role. Great communications skills, attention to detail, self-motivated, and the ability to work well with people are essential. Some minor inter-office travel may be required.

Special notes:

We are an equal opportunities employer. Please visit our website to review our diversity and inclusion statement. All considerations will be made on merit. Applicants should note that Congruity360 will complete AccessNI background checks on all candidates offered a position.
Due to hiring velocity, Congruity360 requires a current and valid UK work permit. Visa sponsorships will NOT be considered. Congruity360 has an internal recruiting team and does not accept agency candidates. If you want to join our team, get in touch with us directly!*
Job Types: Full-time, Permanent

Pay: £40,000.00-£65,000.00 per year

Schedule:
8 Hour Shift
Experience:
DevOps: 4 years (Preferred)
Location:
Belfast, County Antrim (Preferred)
Work remotely:
Temporarily due to COVID-19",-1,Congruity360,"Belfast, Northern Ireland",-1,-1,-1,-1,-1,-1,-1,-1
Senior Data Engineer,-1,"London

3-month initial contract

Daily rate: £500-£650 based on experience

Immediate start

Senior Data Engineer ( ETL / Python / Data Pipelines ) with significant experience in ETL design, Python and data pipelines is sought for working with one of Europe’s fastest growing independent companies.

Working in an experienced team of Data Scientists, Product Managers and Machine Learning Engineers the successful applicant will work on the existing data pipelines, ensuring they run smoothly and efficiently.

The successful Senior Data Engineer ( ETL / Python / Data Pipeline ) will need the following skills:

Experience maintaining and improving data-pipelines.
Experience using ETL.
Extensive knowledge of building and expanding data warehouses.
Programming experience with Python.
An interest in mentoring junior positions.
Knowledge of cloud architectures such as AWS and Redshift.
BSc in Computer Science or similar.

Benefits of working with this company include:

Flexible working hours.
10% of working time to improve and learn new skills or work on personal projects.
A great social environment including weekly team events and socials.

To apply for this Senior Data Engineer ( ETL / Python / Data Pipelines ) role, please apply by sending a CV to cara.janes@venturi-group.com.

Keywords for search: SQL, ETL, Python, Data Pipeline, Warehouse, AWS, Amazon Web Services, Extract, Transform, Load, Data Warehouse, Structured Query Language, NoSQL, Redshift, Airflow, Snowplow, neo4j, MongoDB, Docker, Data Engineer, Kinesis, Lambda, Azure, Microsoft, Machine Learning, Engineering, Data.

Venturi is a staffing business dedicated to you, differentiating ourselves in the marketplace by quality of service and candidate delivery. Our highly skilled and experienced staff operate within dedicated markets to give you the best service possible. Venturi markets include Business Intelligence, Development, Legal IT, Infrastructure, Security and other similar IT specifics. Venturi operates as an employment agency and employment business. No terminology in this advert is intended to discriminate on the grounds of age, and we confirm that we are happy to accept applications from persons of any age for this role",4.8,"Venturi
4.8","London, England",-1,51 to 200 Employees,2009,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Apple Media Products (AMP)- Big Data Engineer - Core Marketing,-1,"Posted: Oct 27, 2020
Weekly Hours: 35
Role Number:
200202210
The Apple Media Products Engineering team is one of the most exciting examples of Apple’s long-held passion for combining art and technology. These are the people who power the App Store, Apple TV, Apple Music, Apple Podcasts, and Apple Books. And they do it on a massive scale, meeting Apple’s high expectations with high performance to deliver a huge variety of entertainment in over 35 languages to more than 150 countries.

These engineers build secure, end-to-end solutions. They develop the custom software used to process all the creative work, the tools that providers use to deliver that media, all the server-side systems, and the APIs for many Apple services.

Thanks to Apple’s unique integration of hardware, software, and services, engineers here partner to get behind a single unified vision. That vision always includes a deep commitment to strengthening Apple’s privacy policy, one of Apple’s core values. Although services are a bigger part of Apple’s business than ever before, these teams remain small, nimble, and cross-functional, offering greater exposure to the array of opportunities here.
Key Qualifications
Language: Java or Scala
Solid understanding on the following distributed data processing platforms: Required: Spark, Hadoop
Great if you also know: Cassandra, Kafka
Algorithms: You will be working on developing new algorithms to process large scale data efficiently. We expect you to know:
Computer Science algorithms and Data Structures
Distributed Algorithms to process and mine data, e.g. Map Reduce Algorithm
Phenomenal but not required if you also know about : Graph, Data classification and clustering algorithms in distributed environment
Good debugging, critical thinking, and communication skills
Knowledge in engineering machine learning, feature engineering systems is a plus.
Able to capture cross-functional requirements and translate them into practical engineering tasks
Experience developing large-scale data warehousing , mining or analytic systems
Strong object-oriented design skills, coupled with a deep knowledge of data structures and algorithms
Description
AMP Analytics Engineering is looking for an outstanding Big Data engineer to develop analytics systems that will generate insights for our marketing teams.

This is a new team we are setting up to focus on developing analytics systems and services that will help improve our marketing initiatives for products such as the Video, Music, Fitness, Apple Arcade, Podcasts etc.

Our Analytics Data Engineering team is responsible for building analytics platforms, datasets and processes required in Apple for analyzing and enhancing the product experience. This means that we build computation platforms and datasets to empower our product, marketing, features, analytics and data science. Given the size and complexity of our datasets this is not a trivial task. Our business, analysts and product teams depend on this data, and as a member of this team you would be at the center of product innovation.

We are looking for a data engineer who can partner with our marketing teams, business, data scientists & engineering to deliver data engineering solutions to improve efficiency of our marketing initiatives through data.

You will be working on cross functional projects with other online marketing engineering teams, marketing leads and analytics leaders to build insights, metrics and data pipelines to power marketing features like push notifications.

Whether you develop new patterns and algorithms for efficient processing of datasets with billions of records or delivers new insights for Marketing Analytics, you will have the opportunity to lead innovation.

The projects you will be working on will be truly impactful. You will have freedom to innovate as you work closely with our partners to see the big picture, and determine innovative ways to deliver the results.

The best person will be an individual with outstanding software development skills with hands on experience in Data Engineering. You pay close attention to details and care about data quality. You are also a team player -- ready to contribute during design sessions, and able to give and receive constructive code reviews. Your curiosity drives you to explore new technologies and apply creative solutions to problems.
Education & Experience
BS, MS or PhD in Computer Science, or equivalent meaningful experience

- Build large scale data processing, mining and analysis projects and features, ensuring robust & maintainable solutions are implemented with special attention to data quality, performance and usability details.
- Effectively demonstrate feature prototypes to executives
- Develop, advocate for, and build consensus on, coding best practices.
- Ability to effectively work with cross functional teams to understand requirements and identify design and engineering impacts
- Experience with architecting big data and analytical applications that scale to petabytes highly preferred.
Apple’s most important resource, our soul, is our people. Apple benefits help further the well-being of our employees and their families in meaningful ways. No matter where you work at Apple, you can take advantage of our health and wellness resources and time-away programmes. We’re proud to provide stock grants to employees at all levels of the company, and we also give employees the option to buy Apple stock at a discount — both offer everyone at Apple the chance to share in the company’s success. You’ll discover many more benefits of working at Apple, such as programmes that match your charitable contributions, reimburse you for continuing your education and give you special employee pricing on Apple products. Apple benefits programmes vary by country and are subject to eligibility requirements.
Apple is an equal opportunity employer that is committed to inclusion and diversity. We take affirmative action to ensure equal opportunity for all applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, Veteran status, or other legally protected characteristics. Apple is committed to working with and providing reasonable accommodation to applicants with physical and mental disabilities.
Apple is a drug-free workplace We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform crucial job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.",4.2,"Apple
4.2",Greater London,-1,10000+ Employees,1976,Company - Public,Computer Hardware & Software,Information Technology,$10+ billion (USD),-1
Machine Learning Engineer,-1,"Founded in mid-2015 to make consumer research simple and accessible for anyone, anywhere, Attest is a fast-growing scaleup backed by investors including Silicon Valley leader NEA. Attest is striving toward a world in which anyone can put consumers and data at the heart of every decision, to create and deliver better, more useful services, products and experiences for real people and communities worldwide.

In 2019, our team tripled to nearly 100 people, and together we achieved huge commercial, technical and people success. Our plans for 2020 and beyond are big and exciting, and our team is growing fast.

A robust set of shared values unites our team. We invest in each other to ensure every Attester has the opportunity, support and encouragement to realise their full potential. We strongly believe everyone should have the autonomy to freely explore new ideas and have a voice in shaping the future of Attest, whilst making sure that the work we do genuinely makes a difference.

About the Data Science team

Data Scientists join us for the technical challenges we overcome and stay for the incredible culture we create and grow, from organising and talking at meetups such as the quarterly MancML (organised by our Head of Data Science) to contributing regularly to open source software.

The Data Science team sits within the R&D Team of Attest and is currently made up of 5 Data Scientists and 1 Machine Learning Engineer. We work cross-functionally in squads with engineering, design and product and split our time between accomplishing squad goals and building core data science capabilities.

Our aim as a team is to research, develop and implement novel techniques to enable our clients to (1) obtain higher quality data through better designed surveys and quality checks and (2) to automate the insights discovery from large amounts of unstructured survey data. To achieve this we work with a number of techniques within data science and machine learning. We, in particular, focus on language modeling with deep learning, unsupervised data mining techniques, active learning and explainable AI.

We have worked very hard to build our state-of-the-art machine learning infrastructure which enables us to easily pull data, train and deploy our models at scale. This allows our team to focus on building new capabilities without dealing with data or deployment issues.

We use a variety of technologies but primarily work with Python, PyTorch, Numpy, Pandas, Scikit-learn, MLFlow, Jupyter, Voila, Streamlit, Kubernetes, Terraform, Dagster, SQL, Redshift, EC2, S3 and various other AWS services. Outside of the Data Science team, the primary technologies are Go, Java and Vue.js.

About the role

We're looking for a Machine Learning Engineer to join our Data Science team. As a Machine Learning Engineer you will be responsible for designing, building and owning the infrastructure required to productionise and run complex machine learning models in a real-time environment. This includes the model store and versioning, the model training, logging and inference infrastructure, the model validation and testing setup as well as the data pipeline and store.

Your focus will be

> To further develop and design the Data Science model infrastructure in close collaboration with the rest of the Data Science team
> To take ownership of model deployment, monitoring and validation and to champion best practices for model testing
> To expand and operate the data pipeline that serves the needs of both the Data Science and Business Intelligence teams
> To help and assist other teams in using the Data Science infrastructure

What you'll bring to Attest

> Strong Python developer with solid understanding of software design and architecture principles
> Hands-one experience with DevOps and/or MLOps - in particular, AWS and Kubernetes
> Experience of working with Machine Learning models in a production environment
> A good understanding of data pipelines and database technologies
> An understanding of the mathematical foundations of modern machine learning techniques
> Excellent interpersonal and communication skills enabling you to clearly communicate complex ideas to peers as well as the wider business

It would also be great, but not essential if you have

> Experience with a second programming language, like C++, GO, Java, R
> Hands-on experience with developing and building machine learning models
> A good grasp of statistics
In return, we’ll give you…

Our benefits and perks are designed with a focus on the wellbeing, engagement, and growth of our Attesters. In addition to the below overview, we publish details on all benefits available, including location-specific benefits, openly and transparently on our Notion pages.

>A competitive salary - that fairly recognises your experience and potential;
>25 days (UK) or 23 days (US) paid holiday (+public holidays) per year - we care about our team’s wellbeing, so we make sure you have time to fully switch off, rest, and recharge;
>Up to 2 additional full company days off annually for Attest's Christmas 'office closure'. These are set by Attest, and are usually the days of Christmas Eve and New Years Eve to the extent they fall on business days. We will let everyone know in advance which days will these will be.
>Flexible working hours and remote working - whether you have parental responsibilities, just need some headspace, or prefer to structure your working balance a bit differently, we value responsible autonomy and default to trust; we’ll support you in making your work and personal life a manageable blend. We're currently working fully remotely due to covid-19; you can read more about how we approach that in our Guide to fully remote working at Attest.
>10% time - to invest in charitable activities, your growth and development, and/or side projects for Attest;
>10 fully-paid sick days per year - mental health and physical health are treated equally at Attest and apply regardless of location. Whether you’ve been knocked out with the flu, are having an operation, or need some time off to manage anxiety, stress or depression, for example, we encourage all our Attesters to rest up and come back when they’re feeling more like themselves;
> £/$500 per person annual Growth & Development fund - we care deeply about your personal and professional growth and development, so in addition to other structured Growth & Development initiatives we offer throughout the year, we also provide every Attester with £/$500 via Sunlight.is annually, to spend on courses, books and further development of your choosing.
>Sanctus - Remote coaching sessions with fully qualified coaches 2 x per month through Sanctus. Sessions are private to you and your coach, and a space for you to use as you see fit. As coaches are usually UK based, we ask all Attesters to be mindful of booking afternoon slots where morning slots are available, to be considerate of our international colleagues who may only be able to make use of slots that fall later in the day.
> 24/7 Employee Assistance Programme (EAP) - all Attesters have access to Employee Assistance Programmes, including accessing confidential telephone counselling 24/7, advice on debt, housing, and beyond.
>High-quality Equipment - we’ll invest to provide you with the right tools and set-up to help you do your best work;
>A values-led working environment - that encourages putting people first, honesty, curiosity and leadership.
> A Dog Friendly work environment - during coronavirus, we've gone fully remote. But in our previous office and in future offices, we're a dog-friendly bunch!

Is this role not quite the right fit for you? Or, have you not seen a suitable position available on our careers site? We’re always on the look-out for curious, motivated and bright people to join our team. Connect with us, and we’ll let you know if and when we have new opportunities.

Diversity at Attest

Everyone's welcome at Attest, regardless of what you look like, where you come from or what you’re curious about. Our product is for everyone, globally, and so is our work space. The more diverse our range of perspectives in our business, the more we all thrive, together. So tell us about your background, personal experiences and perspective on the world and help us further enrich our offering to enable better made decisions to make the world a better place.

Do let us know if there are any adjustments you’d like us to make to ensure the most inclusive interview process we can - we’re learning too, so we’re more than happy to adapt and accommodate whenever possible.

Attest aims to change the way decisions are made, and to help people understand the data that responds to their curiosity. Our mission is to put data at the heart of decisions. Everything we do at Attest is driven by curiosity, honesty, responsible autonomy and collaboration. Our team is growing - will you be next to join the adventure?",4.9,"Attest
4.9","London, England",-1,1 to 50 Employees,2015,Company - Private,Research & Development,Business Services,Unknown / Non-Applicable,-1
Data Engineer Amazon Prime Video,-1,"Amazons Prime Video is a premium on-demand video entertainment service that offers customers the greatest choice in what to watch from popular Prime Original TV shows (made by Amazon Studios) such as The Grand Tour, Tom Clancys Jack Ryan and the recent Golden Globe winning The Marvelous Mrs. Maisel to Prime Original Movies like the Oscar-winning Manchester by the Sea and The Salesman. The service also offers TV shows that are exclusively available for Prime members in each country such as American Gods, Mr Robot and Outlander, and more recently live sport including the US Open tennis from 2018 and Premier League games from 2019. Beyond this content exclusivity, the service further differentiates from other video-on-demand services by offering Prime members the opportunity to subscribe to 60+ channels like Discovery, Starz, Eurosport Player and hayu and hundreds of thousands of additional titles to watch instantly with no extra apps to download or long term contracts. Prime Video is at the forefront of the entertainment industry and growing fast - now available in more than 240 countries and territories worldwide and we work in a dynamic, and exciting environment where innovating on behalf of our customers is at the heart of everything we do. If this sounds exciting to you, please read on.

Prime Video Finance Business Intelligence team seeks a Data Engineer to help the business leverage data better to produce new insights and enable smarter decision making. You will design, create and maintain large datasets that feed into high level global business reporting, and can also be used by analytics teams globally as a source for deep dives. You will be responsible for maintaining the performance of Amazon Redshift clusters that are used by worldwide finance teams, ensuring cluster resources are optimized so that data can be extracted quickly.

The successful candidate will thrive in a data driven environment that seeks business intelligence that is timely, accurate and actionable to aid decision support. Obsessed with solving complex problems and passionate about the potential of analytics to drive a business forward, the successful candidate will relish the prospect of driving forward Prime Video's Analytics to the next level. Mindful of dependencies and able to make sensible trade-offs, you will be hands-on with a passion for code and design. Your end product is usable datasets with business value!


Basic Qualifications



· Bachelor's Degree in Computer Science or a related technical discipline.
· Experience writing high quality, maintainable SQL on large datasets.
· Ability to write code in Python, Ruby, Scala or other platform-related Big data technology.
· Experience with reporting tools such as Tableau or QuickSight.
· Exposure/Experience in Bigdata Technologies (hadoop, spark, presto, etc.).




Preferred Qualifications

· Able to work in a diverse team
· Ability to work with business owners to define key business requirements and convert to technical specifications
· Experience with Amazon Redshift and AWS technologies
· Experience in using various data design patterns and knows when/when not to use one

Amazon is an equal opportunities employer. We believe passionately that employing a diverse workforce is central to our success. We make recruiting decisions based on objective criteria including your experience and skills. We value your passion to discover, invent, simplify and build. We welcome applications from all sections of society irrespective of belief colour, race, religion or belief, nationality, ethnic or national origin, gender, gender reassignment, sexual orientation, sex, marital status, disability, age or trade union membership. Please let us know if you have any special requirements in relation to this recruitment process.

All offers are conditional on references, verification of the right to work in the UK, and successful background screening check. This will include previous employment verification, qualification verification (if relevant) and a basic criminal check. Further details of this policy/procedure will be sent to you along with your conditional offer.",3.9,"Amazon
3.9","London, England",-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Data Engineer,-1,"The Applied Intelligence business of BAE Systems delivers solutions which help to protect and enhance the connected world. Our solutions combine large scale data exploitation, ‘intelligencegrade’ security and complex services and solutions integration. We operate in four key domains of expertise: Cyber Security, Financial Crime, Communications Intelligence and Digital Transformation. Today, we have staff across the UK and Europe, the Americas, Asia Pacific and the Middle East.

Our people apply intelligence to protect and enhance national and organisational assets so that they can grow and prosper – from improving the health and efficiency of leading corporations to protecting critical infrastructures, safeguarding vulnerable people and catching criminals. Together, we make the world a safer place. Make everyday matter.

About the Role:

To work as part of a client side team that defines and resolves complex data collection and data integration issues ( i.e. ETL - Extract, Transform and Load design and development ) to make data and information available to decision makers, internal and external interfaces and real time decision procedures with operation systems and delivery channels.

The Consultant Data Engineer specialises in helping clients within large scale projects and programmes to help shape specific solutions. However, they will also need to develop a holistic view of the organisation.

Consultant Data Engineers will often work closely with Enterprise Data Architects.

Key Responsibilities:
Designs, develops, tests and supports data collection, data integration and ETL applications to make information and data available to key client stakeholders and technical interfaces.
Understands where the need for tight data controls arises to ensure seamless data flows around the organisation and to minimise future change.
Models data requirements, data sources and data flows to bring order and structure to programmes of work.
Defines how and where data is created, mastered and destroyed to ensure proper control over the lifecycle of corporate data assets.
Understands how to add value to data – for example through data cleansing.
Understands categories of products (and individual examples) that can be used to collect, integrate, store, visualise and govern data and metadata.
Defines metadata to provide searchability and governance (including Records Management) for unstructured data.
Designs ETL frameworks and standards for specific ETL programmes and projects.
Identifies the required toolset (development and testing) for specific ETL programmes and projects.
Designs and implements the hardware environment required by ETL programmes and projects.
Develops and tests the re-usable components of an ETL framework for specific ETL programmes and projects.
Undertakes the role of lead developer, ensuring the quality and assurance of all ETL code and testing.
Can undertake the role of delivery lead ensuring that project timescales and quality are met.
Ensures that the configuration and release management procedures are applied for specific ETL programmes and projects.
Maintains and applies up to date, specialist knowledge of database concepts (including unstructured, NoSQL and ”big data” platforms), object and data modelling techniques.
Builds a detailed knowledge of the full range of database and data persistence architectures, software and facilities available (e.g. streams).
Takes account of industry specific requirements (e.g. geocoding, for geographic information systems).
Can utilise a number of ETL tools including Informatica, Ab Initio, Oracle ODI and a number of the Big Data / Open Source Applications
Understands data-related performance issues.
Understands data services, data security issues, “privacy by design” and Information Assurance principles.
Understands master data management patterns and can advise on the right choices for each client.
Defines metadata structures and population techniques that can be used with Enterprise Content Managment solutions in conjuction with organisational policies.
What we are looking for:
ETL Tool capabilities
Ab Initio, Informatica and Oracle ODI
Big Data / Open Source ETL Tools
Database Management Systems
Application Testing Tools
Configuration Management and Version Control Tools
Testing strategies and tools
Infrastructure design
About BAE Systems Applied Intelligence

We use our intelligence-led insights to help defend Governments, Nations and Societies from cyber-attacks and financial crime. Our customers depend on our evolving capabilities to help them safely grow their organisations. Our unprecedented access to threat intelligence, world-leading analysts and market-leading technology means we can help them to adapt, evolve and stay ahead of the criminals.

Division overview: Capabilities

At BAE Systems Applied Intelligence, we pride ourselves in being a leader in the cyber defence industry, and Capabilities is the engine that keeps the business moving forward. It is the largest area of Applied Intelligence, containing our Engineering, Consulting and Project Management teams that design and implement the defence solutions and digital transformation projects that make us a globally recognised brand in both the public and private sector.

As a member of the Capabilities team, you will be creating and managing the solutions that earn us our place in an ever changing digital world. We all have a role to play in defending our clients, and this is yours.

Diversity and inclusion are integral to the success of BAE Systems Applied Intelligence. We are proud to have an organisational culture where employees with varying perspectives, skills, life experiences and backgrounds – the best and brightest minds – can work together to achieve excellence and realise individual and organisational potential. We also welcome discussions about flexible working.

About BAE Systems Applied Intelligence

We use our intelligence-led insights to help defend Governments, Nations and Societies from cyber-attacks and financial crime. Our customers depend on our evolving capabilities to help them safely grow their organisations. Our unprecedented access to threat intelligence, world-leading analysts and market-leading technology means we can help them to adapt, evolve and stay ahead of the criminals.

Diversity and inclusion are integral to the success of BAE Systems Applied Intelligence. We are proud to have an organisational culture where employees with varying perspectives, skills, life experiences and backgrounds – the best and brightest minds – can work together to achieve excellence and realise individual and organisational potential. We also welcome discussions about flexible working.",3.3,"BAE Systems Applied Intelligence
3.3","Gloucester, England",-1,1001 to 5000 Employees,1971,Subsidiary or Business Segment,Enterprise Software & Network Solutions,Information Technology,$500 million to $1 billion (USD),-1
Business Intelligence Data Engineer,-1,"Location
Swansea, Wales, SA6 7JL
About the job
Summary
We welcome and encourage applications from everyone, including groups currently underrepresented in our workforce. We pride ourselves on the positive impact diversity has and promote inclusivity and equality of opportunity for all.

Would you like the opportunity to contribute to the development and support of new Driver and Vehicle Licensing Agency (DVLA) IT services (ITS)?

If so, we are looking for Business Intelligence Engineers to join us at DVLA and we would love to hear from you.

Salary: £26,126.
Location: Swansea
Job description
The Business Intelligence Engineer role is a demanding role in a fast-paced environment. It involves managing and monitoring data across multiple data-warehouses and responding to a vast range of requests for reporting purposes and ensuring data accuracy. You will work as part of a flexible software delivery team working in a variety of styles, including Agile.

The softwares/languages the team are currently utilising include SharePoint 2013, Microsoft SQL Server 2005/2013, SSIS 2005, SSRS 2005/2013, SSAS 2005, T-SQL, Oracle-SQL, MDX.

The team are heavily involved in work relating to DVLA’s legacy estate, and we are looking for an enthusiastic individual to join us. This is an interesting and dynamic role in a high-profile organisation, so you will need to have experience in data warehousing, analytics and reporting.

Responsibilities
Role responsibilities

Your duties will include but are not limited to:

• Working on technical implementation of applications. On larger projects working within a technical framework of the project to meet customer requirements.
• Software development using both recognised and/or specialist programming languages and technologies.
• Conducting Unit Testing of developed applications against agreed standards.
• Participating in Continuous Improvement and defect fixes that can be carried out to improve Application performance.
• Supporting the creation of standardised documentation following the agreed standards and processes.
• Staying up to date with latest technologies.

For more information, please see the attached Role Profile.

Would you like to find out more about the role, the team and what it’s like to work at DVLA? If so, we are organising a familiarisation session where you can virtually 'meet the team' on Wednesday 11th November 2020 at 10am, please email ITSRecruitment@dvla.gov.uk to book on.

About you

An ideal candidate would have a basic understanding of data engineering. You will have awareness of T-SQL or other programming languages and be able to demonstrate the competencies to rapidly acquire or improve on these skills.

You will have experience of working with large amounts of data, ideally in a database environment and excellent written communication skills to communicate effectively to customers at all levels of the business. We are looking for someone who is reliable, pro-active, logical and possesses good problem-solving skills. We need someone who can work well under pressure, adapt to different demands and data requests and work to tight deadlines.

Additional Skills and Experiences

• Good analytical skills
• Working collaboratively as part of a team

Please note, the role profile mentions a Computer Science Degree or a recognised IT qualification. These qualifications are not a requirement of the role.

If you would like to read more about the great opportunities at DVLA please click the link here

To find out more about what it is like to work for DVLA, please click on the following linkInside DVLA Blog
Behaviours
We'll assess you against these behaviours during the selection process:
Changing and Improving
Delivering at Pace
Technical skills
We'll assess you against these technical skills during the selection process:
SFIA – Programming/Software Development PROG - Level 3
SFIA - System Design DESN - Level 2
SFIA - Application Support ASUP - Level 3
Benefits
Being part of our brilliant Civil Service means you will have access to a wide range of fantastic benefits. We offer generous annual leave, attractive pension options, flexible working, inclusive working environments and much more to support a healthy work/life balance.

If you would like to read more about the great opportunities and benefits of working at DVLA visit our Careers website.
Things you need to know
Security
Successful candidates must meet the security requirements before they can be appointed. The level of security needed is security check.
People working with government assets must complete basic personnel security standard checks.
Selection process details
This vacancy is using Success Profiles, and will assess your Behaviours, Experience and Technical skills.
We are closely monitoring the situation regarding the coronavirus, and will be following central Government advice as it is issued. There is therefore a risk that recruitment to this post may be subject to change at short notice. In addition, where appropriate, you may be invited to attend a video interview.

Please continue to follow the application process as normal and ensure that you check your emails regularly as all updates from us will be sent to you this way.

The sift is due to take place 25th November 2020.

Interviews will be held week commencing 7th December 2020.

This interview will be conducted via a video interview, details of which will be provided to you should you be selected for interview. We will try to meet the dates set out in the advert.

There may be occasions when these dates will change. You will be provided with sufficient notice of the confirmed dates.

We are following government guidelines and the majority of IT staff are currently working from home. This is likely continue until at least early 2021. Once it is possible to do so the current expectation is that IT staff will be located in the Swansea office to allow for ongoing support, development and collaboration with colleagues.

How to Apply

For your CV and personal statement, please provide detailed evidence of your experience of the following:

• Awareness of using T-SQL or other programming languages, working with large amounts of data, ideally in a database environment.
• Being pro-active and reliable, logical and possessing good problem-solving skills.
• Working under pressure, working to tight deadlines, adapting to different demands and data requests.

Please note that any part of the Job Profile could be tested at sift/interview.
If invited to interview, this may consist of a range of question types. These could include questions around behaviours and how you would respond in any situation as well as specific examples of things you have done.

The selection process will be designed specifically for the role. As a result, your assessment could include:
• an interview

You’re encouraged to become familiar with the role profile, as you may be assessed against any of the criteria recorded within.

The Department for Transport alongside other Government Departments recruit using Success Profiles. This means for each role we consider what you will need to demonstrate in order to be successful. This gives us the best possible chance of finding the right person for the job, drives up performance and improves diversity and inclusivity.

For further information on Success Profiles visit our Careers website.

Further Information

To learn more about applying for a role within the Department for Transport, visit the Application Process page of our Careers website.

Before submitting your application, we encourage you to visit our Things You Need to Know page for further information about applying for a role within the Department for Transport and the Civil Service.

Throughout this job advert there are links to the DfT Careers website, which provides you further information to support your application. Should you be unable to access the information on our website, please email DRGComms@dft.gov.uk for assistance.

Feedback will only be provided if you attend an interview or assessment.
Nationality requirements
Open to UK, Commonwealth and European Economic Area (EEA) and certain non EEA nationals. Further information on whether you are able to apply is available here.
Working for the Civil Service
The Civil Service Code sets out the standards of behaviour expected of civil servants.

We recruit by merit on the basis of fair and open competition, as outlined in the Civil Service Commission's recruitment principles.
The Civil Service embraces diversity and promotes equal opportunities. As such, we run a Disability Confident Scheme (DCS) for candidates with disabilities who meet the minimum selection criteria.
Apply and further information
Once this job has closed, the job advert will no longer be available.
You may want to save a copy for your records.
Contact point for applicants
Job contact :
Name : ITS Recruitment
Email : ITSRecruitment@dvla.gov.uk

Recruitment team :
Email : dftrecruitment.grs@cabinetoffice.gov.uk
Further information
If you feel your application has not been treated in accordance with the Recruitment Principles and you wish to make a complaint, in the first instance, you should contact Government Recruitment Services via email: dftrecruitment.grs@cabinetoffice.gov.uk If you are not satisfied with the response you receive from the Department, you can contact the Civil Service Commission: Click here (https://civilservicecommission.independent.gov.uk/) to visit Civil Service Commission
Attachments
Role Profile BI Data Engineer Opens in new window (pdf, 144kB)
SFIA V6 framework-reference Opens in new window (pdf, 557kB)
Candidate Guidance for CV and Personal Statement Opens in new window (pdf, 405kB)
Candidate Notes Opens in new window (pdf, 823kB)",3.6,"Driver and Vehicle Licensing Agency
3.6","Swansea, Wales",-1,5001 to 10000 Employees,-1,Government,-1,-1,Less than $1 million (USD),-1
Data Architect / Data Engineer,-1,"Who are we?
Afiniti is the world’s leading applied artificial intelligence and advanced analytics provider. Afiniti Enterprise Behavioral Pairing™ uses artificial intelligence to identify subtle and valuable patterns of human interaction in order to pair individuals on the basis of behavior, leading to more successful interactions and measurable increases in enterprise profitability. Afiniti operates throughout the world, and has measurably driven billions of dollars in incremental value for our clients.

Purpose
Working within the Advanced Analytics team, you will be a key member who enjoys rolling up their sleeves to solve complex business questions through data. You will be able to partner with and build strong relationships with client partner teams including business owners, marketing, IT and other teams as well as internal Afiniti business analytics, artificial intelligence and IT teams to develop and deliver analytic work product. Proactively identify, prioritize and conduct analysis that drives meaningful insight on target objectives.

Key Responsibilities
Afiniti Advanced Analytics Data Engineers provide support across new products development, insights, analytics, and data management tasks.
The ideal candidate will have
7-10 years relevant experience in software engineering or data engineering
Can work with multiple data models and business domains to generalize and standardize ETL scrips, deployment processes.
The go-to person regarding a client’s data process, business reflection on data, or metrics/features built for ML models.
Developer skills (Python, Scala, Java, SQL)
Experience in Data Pipelines (Spark, Airflow, Hive, Big Query) and machine learning (feature engineering)
Experience in Cloud Architecture (GCP)
Understanding of ML concepts like feature engineering model building, testing, and running.
Masters ETL/ELT techniques.
Education & Qualifications
Bachelor’s Degree in Marketing, Economics, Statistics, Psychology, Engineering, Computer Science, Mathematics or Finance

Salary & Package

As well as a competitive base salary dependent on the number of years of experience, we also offer generous stock options, an annual discretionary bonus plus Corporate benefits.",3.6,"Afiniti
3.6","London, England",-1,501 to 1000 Employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,$50 to $100 million (USD),-1
Big Data Engineer,-1,"Who are we?

Pixalate helps Digital Advertising ecosystem become a safer and more trustworthy place to transact in, by providing intelligence on bad actors using our world class data. Our products provide benchmarks, analytics, research and threat intelligence solutions to the global media industry. We make this happen by processing terabytes of data and trillions of data points a day across desktop, mobile, tablets, connected-tv that are generated using Machine Learning and Artificial Intelligence based models.

We are the Worlds #1 decision making platform for Digital Advertising. And dont just take our word for it -- Forrester Research consistently depends on our monthly indexes to make industry predictions. We are looking for a Big Data Engineer to join our London team.

What does the media have to say about us?
http://pixalate.com/press
Harvard Business Review
Buzz Feed
Forbes
NBC News
CNBC
Business Insider
AdAge
AdAge
CSO Online
Mediapost
Mediapost
The Drum
Mediapost
Mediapost
How is it working at Pixalate?
We believe in Small teams that produce high output
Slack is a way of life, short emails are encouraged
Fearless attitude holds high esteem
Bold ideas are worshipped
Chess players do really well
Titles dont mean much, you attain respect by producing results
Everyones a data addict and an analytical thinker (you wont survive if you run away from details)
Collaboration, collaboration, collaboration
What will you do?
Support existing processes running in production
Design, develop, and support of various big data solutions at scale (hundreds of Billions of transactions a day)
Find smart, fault tolerant, self-healing, cost efficient solutions to extremely hard data problems
Take ownership of the various big data solutions, troubleshoot issues, and provide production support
Conduct research on new technologies that can improve current processes
Contribute to publications of case studies and white papers delivering cutting edge research in the ad fraud, security and measurement space
What are the minimum requirements for this role?
Bachelors, Masters or Phd in Computer Science, Computer Engineering, Software Engineering, or other related technical field.
A minimum of 3 years of experience in a software or data engineering role
Excellent teamwork and communication skills
Extremely analytical, critical thinking, and problem solving abilities
Proficiency in Java
Very strong knowledge of SQL and ability to implement advanced queries to extract information from very large datasets
Experience in working with very large datasets using big data technologies such as Spark, BigQuery, Hive, Hadoop, Redshift, etc
Ability to design, develop and deploy end-to-end data pipelines that meet business requirements.
Strong experience in AWS and Google Cloud platforms is a big plus
Deep understanding of computer science concepts such as data structures, algorithms, and algorithmic complexity
Deep understanding of statistics and machine learning algorithms foundations is a huge plus
Experience with Machine Learning big data technologies such as R, Spark ML, H2O, Mahout etc is a plus
What do we have to offer?

This position is based in London. We focus on doing things differently and we challenge each other to be the best we can be. We offer:
Experienced leadership and founding team
Casual environment
Flexible hours
High performing team who wants to win and have fun doing it
Extremely Competitive Compensation
OPPORTUNITY (Pixalate will be what you make it)
Powered by JazzHR",3.3,"Pixalate, Inc.
3.3","London, England",-1,1 to 50 Employees,2012,Company - Private,Computer Hardware & Software,Information Technology,$10 to $25 million (USD),-1
Data Engineer | PM Analytics,-1,"Job Description


About Liquidnet

Liquidnet is the global institutional trading network where more than 800 of the world’s top asset managers and other like-minded investors come to execute their large trades with maximum anonymity and minimum market impact. As the global leader in large block trading, Liquidnet provides access to unique trading opportunities in 44 markets across five continents. Liquidnet approaches every market with the same bold vision to provide a better, more efficient way to trade on a massive scale. It is this focus on size, combined with the strength of its network, disruptive technology, and commitment to transparency, that is revolutionizing the way equities and corporate bonds are traded.

About the Team

The data engineering team works to develop and deploy our data science models efficiently and at scale. We leverage cloud technologies to streamline deployment and delivery of our software and have a wealth of experience maximizing database performance to process large data sets quickly. As part of the broader IA vertical at Liquidnet, we occupy the boundary between data science and development, and work with all parts of the business to rapidly deliver new features.

About the Role

We are seeking a talented programmer looking for a role within a growing team with a track record of creating great software. The ideal candidate will have a passion for technology and building software, with attention to detail and strong analytical skills. In this role you will write applications that are deployed in production and used by investment managers across the globe.

This role will be focused on back-end engineering supporting development and deployment of existing and new data science models. You will work with product designers, users, and the rest of the software development team to deliver high quality solutions in a dynamic environment.

Our products leverage the latest techniques in machine learning, statistical analysis, natural language generation and real-time streaming to provide traders and investment managers with industry-leading data analytics that drive trading decisions.

Qualifications / Skills

Required
Strong technical skill, able to design and implement efficient and robust technical solutions
Ability to quickly understand and employ new technologies
Ability to communicate clearly and work well as part of a team
A passion for writing maintainable, correct code
Desirable
Experience writing production-quality code in Python
Knowledge of AWS services, including CloudFormation and Lambda
Experience developing on Linux, using tools such as Make, Git and Docker
Experience working with SQL databases (specifically PostgreSQL)",2.9,"Liquidnet
2.9","London, England",-1,201 to 500 Employees,2001,Company - Private,Brokerage Services,Finance,$100 to $500 million (USD),-1
Big Data Engineer,-1,"THE COMPANY

Leading telecommunication company who are looking to improve their Data Engineering function. My client is looking for a data engineer to join their team of world class engineers and Data Scientists to build end-to-end applications that make use of large volumes of source data from the operational systems.

THE ROLE

On a daily basis you will be:

Utilise the appropriate development, data engineering (ETL & ELT, stream processing), test and release model(s) and be flexible with your approach
Apply the appropriate standards and principles when delivering data ingestion and data transformation into target data models
Convert algorithms, models and features created by data scientists, analysts and designers from prototypes/designs into production solutions
Deliver, cost effective, appropriate capabilities for the business.
Create Data Lakes & Data Pipelines

SKILLS AND EXPERIENCE

An engineer with a passion for delivering solutions to customers
Someone who likes to roll up their sleeves and enjoys learning
An understanding of data modelling, access an storage
Self-driven and constantly striving to improve your skills
Advocate of agile/lean delivery methodologies
Programming in one or more languages within our data eco-system e.g. Java, Scala, Python.

THE BENEFITS

Competitive pension scheme
Up to 60k Salary

HOW TO APPLY

Please register your interest by sending your CV to Daniel Moss via the Apply link on this page",4.1,"Harnham
4.1","Glasgow, Scotland",-1,51 to 200 Employees,2006,Company - Private,Staffing & Outsourcing,Business Services,$25 to $50 million (USD),-1
Big Data Engineer,-1,"We are looking for an experienced Big Data Engineer to work on a large scale data platform on an exciting new project on a contract basis.

You will be working for a company who are known for their digital innovation, getting involved in building a cloud based platform in a passionate and cross-functional data team.

You will be responsible for building a large scale cloud based platform, integrating data stores with Hadoop, Hive, Scala, Kafka, Spark and Elasticsearch working within a DevOps focus with a focus on Continuous Integration and Continuous Deployment.

We are looking for someone who has extensive experience working with service oriented architecture within a data focused environment on a long term innovative project.

The ideal person for this position is looking to make a difference in a talented, technology focused and agile team, ready to hit the ground running on one of the biggest data projects in the UK.

Please note that no terminology in this advert is intended to discriminate on the grounds of age, and we confirm that we will gladly accept applications from Big Data Engineers of any age for this role. LinuxRecruit are a leading open source specialist and provides services as an agency and an employment business",3.7,"Linux Recruit
3.7","London, England",-1,1 to 50 Employees,-1,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Machine Learning Engineer,-1,"ACTIVELY INTERVIEWING (remotely) & HIRING FOR THIS POSITION DURING COVID-19 - Apply now

Who are we?

We're Tractable - a $50M backed Series C startup (and 'Startup of the Year 2020') solving a real world problem with our mission to use AI technology to help people after an accident or natural disaster.

We're looking for a Software Engineer who thrives on ownership & autonomy. The way we build our product is by putting a team together with all the skills and context it needs to be able to solve real world problems. We believe strongly in collaboration between the product team and engineers, and we work in small lean teams comprised of Engineers, a Product Manager and Product Designer.

The project you will be working on:

The Claim Assessment Team aims to deliver at least human-level performance, real-time, and cost-effective assessments. This could include complex visual tasks to assess damage of a vehicle to simple, yet effective rule-based systems to extract insight from the claim data. We enable other teams to create $ value for the customer by finding leakage or fraud in an estimate. We achieve this goal by creating new AI intellectual properties packaged in reliable, easy-to-use interfaces.

We work in a team with a product manager, software engineers, applied researchers and data scientists with different degrees of software engineering and machine learning experience. We believe in the principle of ""You build it you run it"". We do not hand off our code to someone else to deploy/operate. We make the best of feedback and experiences brought in by everyone and we look forward to hearing about what you can bring!

You will be:

You'll play a key role in developing our platform, as part of a small but high-performing team. You will influence the scope and technical direction of the product and continuously pursue clean code practices and contribute towards overall platform architecture collaborating with our wider Engineering and Product teams. Specifically you will be:
Working with data scientists in the life-cycle of Machine Learning / rule-based models, from ideation & prototyping to productionisation & monitoring
Extending platform capabilities to allow efficient and flexible deployment of various kinds of models
Building toolings to collect labels / data for analysis to enable efficient on-boarding of new customers
Solving scalability problems as we scale up in production volumes
Adopting open-source technologies to best leverage our in-house resources
Promoting engineering best practices throughout the team
Suggesting, collecting and synthesising requirements and creating effective feature roadmap with Product Manager
Tech Stack:

We rely heavily on the following tools and technologies below but you don't need to have prior experience in all of these technologies.
Python/Tensorflow for running ML models; we also use Typescript/Node.js to manage asynchronous and non-compute intensive tasks
PostgreSQL for persistent data storage
Kafka for our asynchronous message queue
DCOS and Docker to schedule and run our services (soon Kubernetes)
Jenkins to run our testing and deployment pipelines
AWS for our infrastructure
React / GraphQL for our tooling suite
What we're looking for

A strong ML Engineer who enjoys solving problems by pairing Software Engineering and Machine Learning techniques. You would have solid Software Engineering background and experience delivering ML models in the real world. A few things we are particularly interested in seeing from you:
Great communication skills and collaborative mindset
Strong programming experience, from self-contained algorithms to complex object modelling design
Extensively worked with Python in a professional environment
Numerical computing experience
Experience working with GPUs / tensorflow / ML frameworks
Bonus if you have trained a few deep learning models
Able to design good system architecture and compare trade-offs (distributed system experience a plus)
Cares about team practices / pairing / advocate of CICD
Company benefits
Competitive salary & 6 month salary reviews
Visa sponsorship if required
Equity
Pension scheme
Flexible Working
Free & unlimited Coursera subscription
Learning and Development budget
Competitive maternity + paternity leave
Daily snacks & soft drinks
Regular company events such as Games Nights, Movie Nights, Lunch & Learns, Monthly Brunch and more
Location - Old Street, City of London (remote for the time-being until COVID-19 clears)",4.9,"Tractable
4.9","London, England",-1,51 to 200 Employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
Big Data Engineer,-1,"Description
Big Data Engineer – Central London - £70,000 - £100,000 + Benefits
We are working with a leading start-up that is quickly becoming a well-known global name. Working in collaboration with groundbreaking research facilities, our client develops software solutions that solve problems across various industries using advance machine learning, deep learning and deep reinforcement learning.
This role would be entering their growing London site and will focus on two main elements. Firstly, you will be building data processing systems by exploring storage solutions, modelling database schemas or model storage, designing data processing pipelines among other responsibilities. Secondly you will be integrating machine learning models and connecting ML models to data processing systems. You will also provision appropriate infrastructure for ML pipelines.

Requirements:

Strong domain modelling, database programming (SQL)
Modern distributed software architectures
Ideally experience with various coding skills (e.g. Python, Golang)
Modern ML frameworks (Tensorflow/Keras, Pytorch)
Cloud computing (AWS or Google Cloud Platform)
Relational databases
Experience boiling and optimizing “big data” pipelines, architectures and data sets
We are looking for someone that has 5+ years of experience in a data engineer or related role following on from a degree in Computer Science, Statistics, Informatics or another quantitative field.

Required tool experience
Big data tools – Hadoop, Spark, Kafka etc
SQL and NoSQL databases, including Postgres and Cassandra
Data pipeline and workflow management tools: Azkaban, Luigi, Airflow etc
Cloud services preferred – AWS or GCP
We are an equal opportunity employer and value diversity. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",-1,Cubiq Recruitment,"London, England",-1,-1,-1,-1,-1,-1,-1,-1
Principal Software Engineer,-1,"While most of Team Bulb are working from home at this time, our Covid-secure offices are open for team members who need to use them. We’ve hired and onboarded more than 150 people virtually during the pandemic and have developed our ways of working to make sure new joiners feel part of our team. This includes virtual socials, lunch time 'Insights' from a range of internal and external speakers, and live streaming whole company meetings. If you'd like to read more about how we've adapted over the last few months, head over to our blog, and you can let us know about your specific requirements as part of the recruitment process.

About the team

Bulb is here to help our members cut their energy bills and reduce their carbon emissions. Our product teams make that happen. We’re developing products that will deliver the future of energy - from using AI to read energy meters, to making carbon offsetting fun and simple, from finding out how to get the most from Smart Meter data to helping people get paid for their solar energy. We also power the sign-up journey that helped us become the fastest growing company in the UK last year and the internal tools that let us deliver a an excellent Trust Pilot score.

The following pods are hiring Principal Engineers:

Experience

Covers member web and mobile apps as well as tooling that support our Energy Specialists to deliver #1 member experience. Experience in bringing productivity improvements for internal teams is very beneficial.

Requires genuine full-stack skills and experience, nice to see integrations with 3rd parties predominantly for helpdesk, telephony, chat.

Requirements

At Bulb we want to hire people with the experiences necessary to get going quickly, but who are also interested in learning new things and are comfortable working in a changing environment.
Expert level knowledge in multiple technologies
Work with CTO to define long term technical strategy, guidelines and principles, and align multiple teams spanning 20+ engineers across multiple pods
Take ownership for large projects stretching beyond quarterly planning ensuring successful delivery, but don’t shy away from harder tactical improvements
Identifies and plans strategic improvements across operation of multiple pods / organisation
Help us hire and onboard senior and specialist roles and support the growth of engineers across multiple pods.
Bootstraps new pods ensuring technical alignment at an early stage.
Tech Stack

At Bulb we use a wide variety of technologies. While we have core technologies that we work with, we're always trying to pick the best tool for the job, and are always looking at what's on the horizon.

Our stack currently includes, but is not limited to:
Node, Typescript, Koa, GraphQL React, React Native, Webpack, Babel
CircleCI, Kubernetes, Docker and Google Cloud Platform
Ideally, you would be familiar with these technologies or similar patterns; notably, Typescript/Javascript coupled with React is a core technology for us. But we’re more interested in your broad experience of software development than of specific tools or libraries. You should be comfortable getting up-to-speed quickly in new tools and platforms. You should be pragmatic and experienced enough to know when a different choice of technology would be more suitable, and comfortable leading explorations into new technologies.

Team Structure

Teams at Bulb are cross-functional, self-organized and autonomous pods. The key features of this structure are:
You’ll be working within a growing cross functional team composed of specialists with backgrounds in DevOps, Engineering and Security.
We practice Scrum/Kanban and work lean.
Work is not siloed, you’re able to commit across the stack, and you have a view of all the features the team are working on.
We use data to drive continuous improvement in our development process and we review this data in our fortnightly retrospectives.
Benefits
Be part of a growing technology startup and help shape the future of energy
Collaborative, flexible, and friendly environment
Competitive salary, discretionary share options and bonus
33 days holiday a year (including bank holidays) and the option to buy up to 5 more
12 weeks of full pay for maternity, paternity or adoption leave
Healthcare with Vitality after passing probation, life insurance, and a pension plan with employer contributions
Cycle to work scheme
One month sabbatical leave after your first year",3.2,"Bulb
3.2","London, England",-1,501 to 1000 Employees,2014,Company - Private,Energy,"Oil, Gas, Energy & Utilities",Unknown / Non-Applicable,-1
Data Engineer - Hampshire & West Sussex,-1,"DATA ENGINEER Hampshire & West Sussex Start: 16.11.2020 Must have CSCS/ECS Card Duration: ongoing 45hrs/week £135.00/day Umbrella/Ltd company £102.97/day PAYE Working on a commercial project, new build works as a Data Engineer you will be working on CAT5 & CAT6 installation, termination and testing work. Candidates must be eligible to live and work in the UK. In order to apply please forward your CV or call Gary Polkinghorne at Fusion People Recruitment on 01489 865200. - Fusion People are committed to promoting equal opportunities to people regardless of age, gender, religion, belief, race, sexuality or disability. We operate as an employment agency and employment business. You'll find a wide selection of vacancies on our website.",4.4,"Fusion People Ltd
4.4","Fareham, England",-1,201 to 500 Employees,2004,Company - Private,Staffing & Outsourcing,Business Services,$100 to $500 million (USD),-1
Operational Analytics Engineer,-1,"Kick-start your career in the online gaming world and experience the very latest in technology and innovation.

Do you see yourself as one of those “out-of-the-box thinkers”, “Technical masterminds”, “Outstanding creatives”, or “Mind-boggling number crunchers”? If so, we want to welcome you to the Betway family and celebrate what makes you unique!

Our global customer base is exploding and we need your skills to support us on this exciting journey! Don’t look back and submit your application before the opportunity passes you by..

Job Title: Operational Analytics Engineer

Reporting to: Operational Analytics Manager

Department: Technology – Operational Analytics

The Department:

Technology creates and innovates the software needed to run our global online B2C gaming operations, including systems for Customer Service, Marketing, CRM, brand website development, DWH/BI, web analytics and the supporting frameworks and tools for one of the largest global online gaming groups. Our dynamic environment is fast paced, using Agile and self-organizing principles for our teams to deliver the highest quality new products.

The Team:

The Operational Analytics team are responsible for running the data systems and services that monitor and report on the operational infrastructure. We are heavily dependent on Elasticsearch for our operational intelligence and are embracing Azure tools as the department migrates applications to the cloud.

Purpose of the role:

The purpose of the role is to deploy, maintain and enhance the tools used by the department to deliver services to users throughout the business. We currently use the Elastic stack extensively (Elasticsearch, Logstash, Kibana, Beats) but have plans to investigate and deploy other tooling to meet business requirements.

This is an opportunity for a talented individual to become a key member of an expanding team. We are looking for an individual who is passionate about technology and looking to work in a diverse, fast paced team. You will be working in a mixed team with a variety of skill sets, so it’s important to be a self-starter and to be capable of learning new skills quickly.

You will be responsible for:

The position will involve the following areas of responsibility:
Deploy, maintain and enhance the systems used by the team (mainly the Elastic Stack but this could expand in the future)
Maintain and enhance the Logstash data pipelines that load data into Elasticsearch
Answer ad-hoc information requests using Kibana/Timelion or other tools as appropriate
Maintain the packages used to collect data from web servers
Troubleshoot and resolve technical issues as they arise
Ensure all servers and applications are patched and upgraded in a timely manner
Continuously look for ways of improving both what and how services are delivered by the department
Keep up to date with the latest technical advances in the areas of Elasticsearch, Azure and Operational Analytics
This is not intended to be an exhaustive list of responsibilities. The job holder may be required to complete any other reasonable duties in order to achieve business objectives.

You will have:
Good working knowledge of the Elastic stack (Elasticsearch, Logstash, Kibana, Beats) inc. Painless scripting
Demonstrable Linux administration experience – Red Hat/CentOS preferred
Experience of writing scripts – bash, Powershell or Python preferred
Experience of successfully leading and delivering BAU projects
It would be a bonus if you also had:
Elasticsearch Certification
SQL Database experience (MS SQL Server)
Some experience of working with Microsoft Azure
Any experience of Apache Kafka, Azure Event Hubs or other messaging platforms
Experience of administration of Windows servers (2012 R2/2016)
An understanding of virtualisation (VMWare)
Some development knowledge including experience with common toolsets used such as Git, Chef, Azure Devops etc.
Person Specification:
Self-starter and able to work with minimum supervision
Passionate about technology
Thorough attention to detail, consistently producing high quality work outputs
Be willing to learn new technologies
Comfortable working to tight deadlines
Patient and calm under pressure
Enjoy working with a team
Must be willing to do reasonable after-hours standby and support when required
Excellent communication skills - both to a technical and non-technical audience
Our Perks:
Flexible working
Competitive package
Great social and charity events
Health and well being weeks
Free fruit and a heavily discounted Barista
Tickets to events via sponsorships etc
Season Ticket Loan
Win Technologies (UK) Limited provides support services to Betway and is a proud member of the Betway Group

Should you not hear from us within 2 weeks, please assume your application has not been successful.",3.5,"Betway Group
3.5","London, England",-1,501 to 1000 Employees,2006,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1
Data Engineer,-1,"Data Engineer

A Data Engineer is required by Whitehall Resources for our end user client based in Hertfordshire.

Our client is looking for an experienced Data Engineer to support the progression of their transformation programme. The successful candidate will be responsible for designing and delivering the correct technical implementation of a cloud-based data management and BI platform across the business.

Do you have?
Data Engineering experience?
Strong knowledge of data warehousing, and extract, transform and load both at a software & hardware level?
Vendor application experience? Such as Talend, Snowflake or other DM tools
Experience in using cloud platforms (AWS) including core data services?
Strong experience with SQL?
Knowledge of ETL, Python or Agile?
First class communication skills?
Do you want?
To have a clearly defined career development path?
Gain new skills & experience?
Have a good work life balance?
If so, please apply!

Data Engineer | Talent | Snowflake | Redshift | Spectrum| Master Data Management | SQL | Data Engineering

All of our opportunities require that applicants are eligible to work in the specified country/location, unless otherwise stated in the job description.",4.1,"Whitehall Resources Ltd
4.1","Hatfield, East of England, England",-1,51 to 200 Employees,2007,Company - Private,Staffing & Outsourcing,Business Services,$50 to $100 million (USD),-1
Data Engineer - DV Cleared,-1,"Job ref:

1169445/001_1603969678

Location:

Huntingdon, Cambridgeshire

Sector:

ICT

Job type:

Contract

Salary:

£650 - £750 per day

Contact:

Jamie Kenward

Email:

jkenward@cbsbutler.com

Published:

5 days ago

Duration:

6 Months +

Start date:

ASAP

Consultant:

Jamie Kenward

Data Engineer - DV Cleared

Company: Global IT Consultancy
Location: Cambridgeshire
Duration: 6 months
Rate: Negotiable to £750 a day

+++ Please note that this is a DV Cleared role +++

Data Engineer: Using your ElasticSearch and Kibana skills you will support an Agile development project which is building bespoke algorithms and applications for a Defence customer. The project aims to provide technical support to the clients' innovation and data science capability, as part of a growing programme of work relating to artificial intelligence, algorithm development and machine learning.

You will design, build and integrate data from various resources to enable a team of data scientists to rapidly leverage those data sets.

Your skills and experience:
strong technical ability with ElasticSearch and Kibana.
good level of familiarity with Apache NiFi.
Desirable:
prior experience with Geospatial data.
familiarity with: Docker, Kubernetes.
prior experience with Python and ML frameworks including (e.g) SciKit-Learn, Keras, TensorFlow, PyTorch.
Apply now and I will call you to discuss this role in more depth",3.9,"CBSbutler
3.9","Huntingdon, England",-1,51 to 200 Employees,2003,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Big Data Software Engineer,-1,"About SEKAI

Sekai is an enterprise software company that builds developer tools for digital twins in the energy and manufacturing industry. We build a cloud-agnostic SDK solution called the SEKAI platform.

SEKAI also provides managed infrastructure to run SEKAI on behalf of customers. Our platform is a proprietary solution for large enterprises to deploy in their own datacenter, as well as custom infrastructure for private cloud deployments.

We work with different size companies ranging from small, mid-size to public-listed companies, and Fortune 500s.
About the role

Skills: Data engineering, ETL, Big data, Java, Scala, Git, DevOps, GraphQL

Hi there!

We're looking for a Big Data ETL Software Engineer to join the cloud engineering team at SEKAI. We build distributed, highly scalable data technology using semantic and game tech in an industrial SDK for creating highly interactive, collaborative multi-user systems for assets like factories, ships, power stations and cities.

We are simplifying the lives of developers and providing an incredible technology that can be integrated into any enterprise IT environment as easily as possible. SEKAI is already powering many Apps, including PC, VR, Web and Mobile AR based tools.

We skew heavily towards candidates who have professional experience with big data, ETL and data engineering - however if you don't have experience but feel up to the challenge, please do apply!

About You


You love building new things. You love tinkering with new technologies. You love creating realistic open worlds. You love helping developers be more productive. You love devops. You love automation. You love helping customers solve problems.

Your work could be on big data ETL pipelines, GraphQL API, tools development, DevOps, Kafka, Camel or Spark development and optimization or any areas in between.

We love tinkering with new bleeding edge technologies like Kaniko, Pulumi and not so new but new to the big data world such as game engines and machine learning. We encourage you to do the same!

Things You Might Do


You'll have a primary focus on the cloud based ETL pipeline based development in Apache Camel, Kafka, Spark and airflow, though we may need to improve and tweak the automated infrastructure from time to time. The SEKAI platform is built on modern technologies like Java, Go, C++, Scala, JavaScript, React, GraphQL, Kubernetes, Postgres and Neo4j.

SEKAI is a small, fast-growing, and remote-first company, so you'll likely get experience on many different projects across the organisation. That said, here are some things you'll focus on:
Work on developer tools.
Help scale a fast-growing and unique system.
Prototype new features and functionally,
Monitor and improve infrastructure for SEKAI and our customers.
Refactor a feature in Java and Scala
Working with geo based tools such as GIS data,
Developing cross platform applications features exposed via GraphQL API,
Building Camel connectors,
Plan and build product features - directly impact how our customers can be more productive.
Improve our developer platform - directly impact the way developers integrate SEKAI into their IT environments.
Experiment: this is a startup so engineering innovations can change.
Youll also have the opportunity to travel onsite to many parts of the world to help customers (corona permitting), attend conferences and meet new people. You also have the option of working from an office, co-working space, from a beach, or anywhere you like!

The Whole Package


Location: Anywhere on the planet with a reliable Internet connection!

If you want to work remote, that's great.

Compensation:
Competitive salary.
20 days vacation.
Work with a loving team that treats everyone as family.
How to Apply


Fill out the form below or send an email [jobs (at) sekai.io] to us with your resume, and a cover letter highlighting why you'd like to join SEKAI.",4.7,"SEKAI
4.7",Remote,-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Test & Finishing Technician/Engineer,-1,"The position requires a competent and highly motivated hands-on team player to ensure that the Company’s products are tested and validated against specific requirements. These include compliance with Functional Design Specifications (FDS’s), Test Plans, internal quality procedures, industry and legislative standards and against specific contractual requirements. The ability to work in accordance with procedures and to fully support excellent working practices (including health, safety and environmental excellence) are essential. This position includes direct customer liaison which requires an extremely positive and “can do” attitude.

Requirements:
Experience in the field of testing of PLC / HMI / SCADA System Hardware and Software are essential. This will include the knowledge of the various communication PLC / HMI / SCADA protocols and an understanding of PLC / HMI / SCADA testing techniques and methods.
Ability to interpret electrical drawing and excellent fault diagnostic skills.
Commercial awareness.
Health and Safety awareness.
Excellent IT skills.
Educated to a minimum of an ONC in Electrical Engineering (or equivalent).
Official / prior certifications, such as NICEIC.
18th Wiring Regulations.
Educated to a minimum of an ONC in Electrical Engineering (or equivalent).
Tasks and responsibilities (but not limited to)*
The key objectives of the appointment are to:
Review all the relevant documentation contained in the “Test Package” – including, but not limited to: The FDS; I/O Schedule; System Architecture, and Software Application Revision. Ensure that the Internal Factory Acceptance Test (IFAT) commences in accordance with agreed procedures and schedule.
Diligently and safety perform the IFAT, thoroughly undertaking system functionality checks and testing as specified by the FDS / Test Plan / specific requirements. ‘Negative testing’ will be carried out in order to validate the robustness of the system.
Fully and accurately complete all relevant documentation in line with Company procedures and the requirements of the Project / customer.
When correct to do so, sign-off the FDS / Test Plan / Specification, Correction and Omission Sheet(s) and any other relevant documentation.
Investigate any non-compliance and repair (if possible) and / or liaise with the System Integration Team in order to remedy all faults identified. Corrections must be tested and verified using established procedures / documentation.
Following the successful completion of the IFAT, in consultation with the customer / customer’s representative, perform the Customer Factory Acceptance Test (CFAT). This may take place at any location as specified by the Project / Contract.
Liaise with other departments and personnel to ensure the smooth and efficient progress of the project throughout the entire test phase.
With responsibility for the completion and accuracy of test documentation, liaise with colleagues from other departments to ensure that all certification and QA / QC requirements are adequately met / completed.
Advise stakeholders of progress and any potential problems at the earliest opportunity.
Ensure that the Test Area (wherever located) is exceptionally clean, orderly and house kept. In particular, ensure that test equipment, apparatus and cabling does not present a hazard.
Ensure that during testing, the area is cornered off / arranged in accordance with Company procedures and only those persons authorised and competent are present.
Demonstrate strong and effective inter-personal and communication skills and the ability to interact professionally with a diverse group of clients and personnel.
Attend customer’s sites whenever required always upholding the Company’s Culture and Values.
Lead excellent working practices, including:
Health, safety & environmental compliance.
Data protection & information security.
Customer focus.
Team Behaviour.
Housekeeping.
Continuous improvement.
Compliance with the Company’s Business Assurance System.
STRICTLY NO AGENCIES*
Job Types: Full-time, Permanent

Benefits:
Childcare
Company events
Company pension
Life insurance
On-site parking
Sick pay
Wellness programmes
Schedule:
Monday to Friday
Overtime
COVID-19 considerations:
This is a manufacturing business, and is Covid-Secure.

Experience:
Manufacturing : 1 year (Required)
Electrical Testing: 2 years (Required)
Education:
Certificate of Higher Education (Required)
Work remotely:
No",2.6,"Lintott Control Systems
2.6","Norwich, England",-1,51 to 200 Employees,1970,Company - Private,Electrical & Electronic Manufacturing,Manufacturing,Unknown / Non-Applicable,-1
Data Engineer - Azure,-1,"Data Engineer
Scotland/Remote/UK Wide
Permanent
£50k - £60k per annum

I am currently on the lookout for a Data Engineer to join a client of mine based in the UK. They are looking for a Data Engineer to assist them in delivering to a range of clients around the UK. You will be required to travel to their main sites when required (London, Manchester, Edinburgh), but they anticipate most of the work to be in Scotland.

You will be required to liaise with both technical and non-technical staff and to understand technical complex requirements and challenges. Alongside this, you will be required to work on both solo and in digital squads to deliver larger projects of work.

Key Skill Requirements:

Commercial experience working with one or more of the following Azure flatforms as PAAS technology - Azure Data Factory, Azure Data Lake Store, Azure Databricks , Azure DevOps, Azure LogicApps
Data Migration Project Experience
Database Skills (SQL Server)
SQL

Desirable:

ETL Development (IBM Datastage)
C# Development
Python
API Development
BI Reporting
MDM

Please apply below to be considered.

Capita IT Resourcing is acting as an Employment Agency in relation to this vacancy.",-1,Capita IT Resourcing,"Edinburgh, Scotland",-1,-1,-1,-1,-1,-1,-1,-1
Lead Software Engineer,-1,"Description

CORONAVIRUS UPDATE: Hiring at Made Tech continues as usual. Our team are now all working remotely so all interviews will be facilitated remotely too. Hopefully, this will still be a good experience for candidates. (feedback welcome)
We're even set up to onboard any new starters remotely should we need to. All our projects are set up to continue remotely as well :)

---------------------------

Salary range is £63,900 - £81k per annum plus a range of excellent benefits. Apply below.

Our Lead Engineers lead teams to deliver digital, data and technology outcomes that improve society. They do this by establishing and leading teams to deliver software in public sector organisations.

What does the job entail?

We primarily write and deliver custom software for the public sector. We work across central and local government, as well as in health, and our past lies in the technology startup world. Technical excellence for us isn’t about delivering to feature lists. We place a strong emphasis on outcome-based delivery; ensuring our customer’s goals are understood and achieved with the technology we deploy.

Lead Software Engineers combine technical excellence, drive to deliver, and coaching, to achieve outcomes for our customers and their users, and to establish strong engineering cultures within our customer's organisations. They find themselves working on a variety of different problems from monoliths to microservices, upskilling colleagues and customers, always finding themselves learning from others, while constantly striving to be nice humans :)

Depending on our customers' needs our Lead Software Engineers may play one or more roles. Sometimes the role is very hands-on and you'll be the most senior engineer on the team delivering software, other times you will play more of a technical architect within a single team.

We need flexible individuals who enjoy a varied workload, are happy to switch between being more and less hands-on, but don't see themselves stepping away from code any time soon. It might be that you're stronger as a Tech Lead or as a Tech Architect, or only have experience in one area, that's okay as long as you have an interest and willingness to broaden your expertise.

Our teams have used Ruby with Rails and Sinatra, ES6 with React and Angular 2, C# with .NET Core. We don’t limit ourselves as a company and we expect all our Engineers to be keen on learning new technologies. Automation is important to our teams, so we make sure there is a CD pipeline set up to build, test, and release many times per day.

High performing software delivery teams need to be empowered to iteratively and rapidly deliver changes all the way through to production. To do this we combine our extensive cloud automation knowledge with DevOps culture.

We've been using AWS from the start and as Advanced Partners are go-to experts within the public sector. We use a range of IaaS, PaaS and FaaS depending on the needs of our users, in this case, software teams, such as EC2, Lambda, ECS, Kubernetes, Heroku, CloudFoundry, Azure App Services, and more. We use VPC and PrivateLink for connecting to on-premise, legacy systems. We also use API Gateway, S3, CloudFront, SQS, SNS, SES, RDS, and many other services provided by AWS.

We ensure we document our architecture and infrastructure as code, using technologies such as Terraform and OpenAPI. Containerisation is a big part of empowering our teams to develop, deploy and scale their applications, but so too is using AWS Lambda and avoiding the complexity of stateful services altogether. The right tool for the job.

For us, DevOps is about culture rather than roles and titles. Even though this role is for someone with strong DevOps experience, the biggest impact you will have is coaching and helping teams use the platforms you build. You won't be building infrastructure in isolation or charged with deploying other peoples work into production. You'll empower teams with the mantra: you build it, you run it!

We grow a team of polyglot programmers, which you might already consider yourself to be, who are versed in a mix of paradigms such as object-oriented, functional, declarative, event-based and aspect-oriented. To create this environment our Senior Engineers need to embrace sharing their knowledge and skills with others, and they need to keep an open mind – we’d love to hear some examples of mentoring, coaching and growing team members. Maybe you will have written some blog posts about your discipline, or perhaps even delivered a talk or two.

Requirements

What experience are we looking for?

While we will look for you to have experience in these things, if you don’t have one of these don’t let that stop you applying.
Working directly with customers and users
Working within multidisciplinary teams with product, design, and technology working within the same cycles
Agile practices such as Scrum, XP, and/or Kanban
Showcasing and presentation skills
Written code with test-driven development
Worked with many programming languages
Worked with many databases
Worked with APIs
Experience in influencing architecture and teams
Debugging experience in a range of systems
Evidence of self-development – we value keen learners
Drive to deliver outcomes for users
Desire to mentor others
Empathy and people skills
Optional experience

Don’t forget to mention any of the experience listed below. While it’s optional, it’s all highly desired!
Consultancy
Pair programming – we pair around 50% of the time
Component-based design techniques such as using pattern libraries, styled-components, CSS-in-JS, BEM, and/or SUIT CSS
Debugging infrastructure
The React ecosystem including a test-driven approach
Infrastructure as code technology like Terraform and Cloud Formation
Use of architectural decision records
Writing blog posts and giving talks
What we will provide you

Balancing life and work:
✈️ Flexible Holiday – We trust you to take as much holiday as you need
️ Flexible Working Hours – We are flexible with what hours you work
️ Flexible Working Days – We are flexible to the amount of days you work in a week
Flexible Parental Leave – We provide flexible parental leave options
‍ Remote Working – We offer part-time remote working for all our staff
Paid counselling – We offer paid counselling as well as financial and legal advice
️ Paid anniversary break – We celebrate your 3 and 5 year anniversary with us by buying your family a holiday
Making work as fabulous as possible:
Work Ready – We'll buy you a Macbook, ergonomic equipment, books, conferences, training, and more
Learn Tech – We spend every Friday afternoon learning rather than working
️ Friday Lunches – We randomly match up 8 colleagues every Friday and pay for lunch
Friday Drinks – We pay for social drinks on a Friday
Compensating you fairly:
Transparent Salary Bands – We publish salary bands so you know you're being fairly compensated
Annual Salary Reviews – We review your salary on an annual basis
⛷️ Pension Scheme – We provide a pension scheme so you can save for your future and we'll contribute to it
Season Ticket Loan – We provide loans to help you pay for your travel
Cycle To Work Scheme – We offer the cycle to work scheme to help pay for your bicycle
Expenses Paid – Taxi to a meeting? Want to take a customer to lunch? Expenses are no hassle!
Salary

This role has a salary of £63,900 - £81k depending on experience.",4.6,"Made Tech
4.6","Manchester, England",-1,51 to 200 Employees,2010,Company - Private,IT Services,Information Technology,$1 to $5 million (USD),-1
Data Warehouse Engineer,-1,"Summary


Salary:
£Competitive + bonus
Team:
Information Technology
Location:
Malmesbury - United Kingdom

About us

Dyson's Global Data Service team ensures that the various parts of Dyson's business are able
to leverage rich, accurate, and timely data to generate insights and make
better decisions, while also supporting the strategic migration towards the Google
Cloud Platform (Big Query). As a part of IT, the team has the resources
and the remit to keep up with Dyson's impressive global growth. Building our
analytical capabilities is a core pillar of Dyson's new global data strategy.
As more consumers engage with Dyson, via more types of products, and across
more markets, the volumes of data will greatly increase. Understanding how to
use this data to improve everything from customer experiences to product
development will be key to Dyson's success.

We're looking for a Data Warehouse Engineer to join the team.

About the role

What you'll be doing:
Monitor and manage background processes to
ensure continuity of service
Investigate and resolve issues in a timely
manner and to a high standard
Provide support, training and advice to
end-users of existing BI systems
Work with a team of DBAs to help define
hardware requirements and sizing Maintain & enhance existing data warehouse
functionality and capabilities
Specify, Design, Develop, Test and Deploy
solutions utilising the full SQL Server stack
Work with cross functional teams to gather and
understand business requirements
About you

You’ll need to have:
Strong SQL / T-SQL skills are essential
Undergraduate degree in a computing, science,
math or engineering discipline
Solid experience on SQL Server Data
Warehousing projects.
Significant proven expertise in developing
T-SQL on SQL Server 2008 R2 or above
Experience of both normalised relational and
dimensional data modelling methodologies
Significant proven experience with SSIS
including development of full DW ETL solutions
Experience with Reporting Services (SSRS) and
data visualisation
Experience with centralised and
distributed version control software e.g. TFS / GIT
Experience with agile tools & methodologies e.g. Kanban boards
An understanding of Database Administration processes & methodologies.
We’d also like to see:
Working knowledge of Python / C# would be advantageous but not essential
Understanding of cloud platforms (AWS, GCP)
Benefits
27 days holiday plus eight statutory bank holidays
Pension scheme
Performance related bonus
Life assurance
Sport centre
Free on-site parking
Subsidised café and restaurants
Discounts on Dyson machines
Interview guidance


We are following the government guidelines regarding COVID19. At this time all interviews will be conducted via video or telephone. We’re taking these precautionary measures to protect both our employee and candidate wellbeing. Our Talent Acquisition team will work with you and provide further information as appropriate.
Posted: 14 October 2020

Apply",2.9,"Dyson
2.9","Malmesbury, England",-1,10000+ Employees,1993,Company - Private,Electrical & Electronic Manufacturing,Manufacturing,$100 to $500 million (USD),-1
Realtime Transport Data Engineer (remote),-1,"Citymapper makes cities usable, helping people move through urban spaces, getting people from A to B.

We have launched in more than 60 cities so far. We've found that having a broad and deep set of data on the transportation options in that city is key to ensuring a great experience for our users.

We are launching many new cities to bring Citymapper to users everywhere.

We provide essential information for millions of users, letting them know when the next bus is arriving, which trains are disrupted, and what time they should leave to get home. We need engineers to help build and maintain the systems that do that.

Good transport data, especially realtime information, is why our users love our app.

What you’ll do
Add and maintain sources of realtime departure information in new and existing cities. Lots of feeds and cities require non-trivial and unique strategies in order to reliably show the correct departure times to the user. ""When does my bus arrive?""
Find ways to turn disruption messages from agencies into useful notifications and re-routing for our users. Check out what we did in NYC. ""Is the metro blue line running?""
Integrate private transport operators into our data streams. Public transport is being complemented by private transport operators in most of the cities we cover - bikes, moped, scooters, cars, etc... ""Where's the nearest electric bike to rent?""
Improve the monitoring and operational systems necessary to keep these 100s of realtime data feeds working. ""Why are we not showing trains in Lyon?""
Fun projects we recently took on
Deployed a real time monitoring system to help commuters in Hong Kong navigate complex route diversions
Built a system to approximate TfL train predictions based on sparse data
Added real time crowdedness information to help users decide which vehicle to use
Requirements

Ultimately we don’t have hard requirements beyond needing you to be smart, curious, and keen to get stuck in. However we are looking for candidates with at least 1 year of professional software engineering experience within a team. Attention to detail and experience wrangling data (especially transport data) is a plus.

This is a remote contracting position for a 3-6 month full time contract position

Our stack for transport data
Tech: main language Python 3
Tooling: GitHub, AWS, SQL, Linux
Best practices: code reviews, tests, CI
Benefits
Contractor position in a remote-first team
Working on something interesting and meaningful - help to make cities usable
Company provided Macbook & needed equipment
Working with a not-too-big, diverse engineering team
Arcane public transport knowledge with which to dazzle your friends",2.4,"Citymapper
2.4",United Kingdom,-1,51 to 200 Employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Data Visualisation Engineer,-1,"Data Visualisation Engineer

Would you like to join a team doing outstanding things with data visualisation? Are you passionate about making data clear and engaging to our colleagues? Do you want to continuously be challenged by innovating and learn new techniques?

As a key member of the Expedia Group Data Visualisation team the Data Visualisation Engineer will play a pivotal role in supporting our key partners, ensuring they are able to effectively and quickly turn data into insights, driving business decisions and strategy.

What youll do:
Develop visualisation products that improve the insight and analytical capabilities of the group
Support the broader analytics teams with visualisations and insights
Develop an understanding of the data sources used, to be able to explain limitations and propose viable solutions based on the requirements
Collaborate with other teams developing lasting solutions and improvements to drive efficiency
Who you are:
You are starting your career or in an analytical role with an emphasis on communicating data insight
Intermediate knowledge of Tableau
Experience with SQL
You have a keen interest in the field of data visualisation and are passionate about helping others understand their data
Broad knowledge base of statistics and statistical interpretation of quantitative data
You have a dedicated and pragmatic approach towards business problems and process improvements
Willingness to learn and come up with creative solutions
Excellent interpersonal skills and ability to work with all levels of management, across different organizations
Have great attention to detail and a commitment to data integrity
Why join us?

Expedia Group recognizes our success is dependent on the success of our people. We are the world's travel platform, made up of the most knowledgeable, passionate, and creative people in our business. Our brands recognize the power of travel to break down barriers and make people's lives better that responsibility inspires us to be the place where exceptional people want to do their best work, and to provide them the tools to do so.

Whether you're applying to work in engineering or customer support, marketing or lodging supply, at Expedia Group we act as one team, working towards a common goal; to bring the world within reach. We relentlessly strive for better, but not at the cost of the customer. We act with humility and optimism, respecting ideas big and small. We value diversity and voices of all volumes. We are a global organization but keep our feet on the ground so we can act fast and stay simple. Our teams also have the chance to give back on a local level and make a difference through our corporate social responsibility program, Expedia Cares.

If you have a hunger to make a difference with one of the most loved consumer brands in the world and to work in the dynamic travel industry, this is the job for you.

Our family of travel brands includes: Brand Expedia®, Hotels.com®, Expedia® Partner Solutions, Egencia®, trivago®, Vrbo®, Orbitz®, Travelocity®, Wotif®, ebookers®, CheapTickets®, Hotwire®, Expedia® Media Solutions, CarRentals.com, Expedia Local Expert®, Expedia® Cruise® and SilverRail Technologies, Inc. For more information, visit www.expediagroup.com.

Expedia is committed to creating an inclusive work environment with a diverse workforce. All qualified applicants will receive consideration for employment without regard to race, religion, gender, sexual orientation, national origin, disability or age.",3.9,"Expedia Group
3.9","London, England",-1,10000+ Employees,1996,Company - Public,Internet,Information Technology,$5 to $10 billion (USD),-1
Data Warehousing Engineer,-1,"DATA WAREHOUSING ENGINEER
GAMBLING AND GAMING (ONLINE)
CENTRAL LONDON
£65,000

An online gambling and gaming company who specialise in markets outside of the UK and are a rapidly expanding startup are looking for talented analysts and engineers to join the team as they're bringing together all of their data in a centralised hub based in London.

THE COMPANY

This company is around 3 years and focus their efforts abroad In expanding markets. They have been very successful and are already investing more in their data team to enable more informed business decisions across different business areas.

THE ROLE

As a Data Warehousing Engineer you would be responsible for :

Working closely with the database team based in Malta to transform and effectively platform their data to support current BI dashboards and self-service reporting
Capturing data effectively from rich user profiles and generating and leveraging more data streams from their apps
Maintaining and improving the robustness of their ETL

SKILLS AND EXPERIENCE

A successful Data Warehousing Engineer will have:

Excellent SQL coding ability and a good knowledge of data warehousing principles
Experience developing ETL pipelines (either in Azure or SQL Server environments) and ideally having ingested data from API's
A knowledge of data warehousing and OLAP as well as other core concepts and strategies
Experience of cloud based data warehouses and Python would be useful
Excellent communication skills and being able to gather requirements

HOW TO APPLY

Please register your interest by sending your CV to Eoin Pierce or clicking on the link",4.1,"Harnham
4.1","London, England",-1,51 to 200 Employees,2006,Company - Private,Staffing & Outsourcing,Business Services,$25 to $50 million (USD),-1
Machine Learning Engineer,-1,"We're helping a young, dynamic biotech business in Cardiff to hire a Machine Learning Engineer to help influence the company performance, which is literally helping to change lives.

Their work is technically challenging but hugely rewarding. You'll be joining a small, specialist team made up of a diverse range of nationalities, personalities and skill sets.

As part of the core team, you will have great opportunity to architect our AI-powered discovery platform on GCP. From data processing workflows to CI/CD implementations we have plenty of exciting avenues to explore!

We're after someone ambitious who wants to take on big problems and help drive a company towards success with unprecedented speed.

There will be lots of pure research, but you may also get involved in key business activities like talking to stakeholders, driving collaborations and contributing to funding applications or publications.

Skills:

Python / C# / C++ (any are fine)
TensorFlow
GCP / AWS / Azure (we use GCP)
CNNS's highly desirable
If you've previously worked in biology / biochemistry / chemistry / medicine it's a huge bonus

To find out more, contact James Dyson from Evolution Recruitmet",4.4,"Evolution Recruitment Solutions
4.4","Cardiff, Wales",-1,51 to 200 Employees,2000,Company - Private,Staffing & Outsourcing,Business Services,$1 to $5 million (USD),-1
Senior Software Engineer,-1,"Business Unit:
Cubic Mission Solutions
Company Details:
Cubic offers an opportunity to provide innovative technology for government and commercial customers around the globe, helping to solve their future problems today. We’re the leading integrator of payment and information technology and services for intelligent travel solutions worldwide, and the leading provider of realistic combat training systems, secure communications and networking and highly specialized support services for military and security forces of the U.S. and allied nations. If you have an entrepreneurial spirit and thrive in an innovative environment, we want to talk to you about your next role at Cubic! We are seeking employees inspired by technology, and motivated by the rewards of hard work, commitment, teamwork, quality, integrity, and respect. We invite you to explore opportunities with Cubic.
Job Details:


Job Summary:

To provide innovative technology for government and commercial customers around the globe, helping to solve their future problems today. Developing high quality software to run on embedded products.

The job holder will be joining a small and dynamic R&D team. The role is primarily focused on embedded C++ development, concerning VoIP and LTE network technologies, with future opportunities to work across a wide range of areas. This role provides the opportunity to work on an exciting and expanding code base, contributing to the continual improvement of the software and the technologies in use.

Essential Job Duties and Responsibilities:
Develop, design and test high-quality software to meet stake holder requirements
Utilise software development best practices to ensure code is well structured, unit tested and easy to maintain
Review functional requirements and translate into a clear design, prototyping as required
Embedded Linux Application Development using popular cross development tools
Work within an agile team to ensure minimum viable product development and seek early feedback from customers and stake holders
Able to lead projects and clearly report on their status
Participate in design and development reviews across the whole code base
Able to work collaboratively and contribute constructively to team meetings and design discussions
Contribute new ideas and tools for continuous improvement of the team development practices
Provide mentorship to junior/associate engineers
Comply with Cubic’s values and adherence to all company policy and procedures. In particular comply with the code of conduct, quality, security and occupational health, safety and environmental policies and procedures
In addition to the duties and responsibilities listed, the job holder is required to perform other duties assigned by their manager from time-to-time, as may be reasonably required of them.
Minimum Job Requirements:

Skills knowledge and experience:

Essential:
Strong C/C++ experience, preferably in embedded systems
Able to analyse and solve complex software engineering problems
Experience writing unit tests and using unit test frameworks
Good knowledge of data structures, memory utilisation, multi-threading concepts and related best practices
Desirable:
Experience of embedded Linux device driver development
Experience using Yocto
Experience of debugging in an embedded environment
Experience of networking and VoIP technologies
Experience of mobile and LTE technologies
Experience working with web user interface technologies and frameworks, such as HTML, JavaScript/Node.js and PHP
Experience of scripting languages such as Bash and Python
Experience with tools & applications such as JIRA, Jenkins, Confluence, SVN and Git
Education and qualifications

Essential:
BA / BSc or master’s degree in computer science, computer engineering or other related technical discipline
Personal Qualities:
A driven and self-starting individual, with a desire to write quality, effective software
Good analytical skills, with a passion for finding simple solutions to complex problems
Able to prioritize work and complete tasks to deadline
Good communication skills and ability to clearly convey complex ideas
May occasionally be required to travel domestically and internationally to include working odd hours, in-line with customer requirements
The description provided above is not intended to be an exhaustive list of all job duties, responsibilities and requirements. Duties, responsibilities and requirements may change over time and according to business need.

Worker Type:
Employee",3.2,"Cubic
3.2","Chippenham, South West England, England",-1,5001 to 10000 Employees,1951,Company - Public,Aerospace & Defense,Aerospace & Defense,$1 to $2 billion (USD),-1
Data Analytics Engineer (Contract),-1,"Adria Solutions has an exciting contract opportunity for an experienced Data Analytical Engineer. As a Data Analytical Engineer, you will be responsible for developing business requirements and specifying and developing reporting solutions.

The duties of the Data Analytics Engineer will include but not be limited to:

Work with other members of the Data Engineering team to assist in the definition and development of processes and business intelligence solutions that provide secure and efficient data reporting, visualization, and analytics
Develop solutions that connect to a variety of on and off-premise data sources, ensuring data is optimized to meet requirements for business and technical use cases.
Present information for business and technical users through engaging and interactive reports and visualizations
Apply business and logic rules to derive new measures, new dimensions, and aggregated values.
Design, build and deploy reporting tools
Secure and publish reports and dashboards for use via desktop, web, and mobile

The ideal candidate will have:

Expert data reporting and visualization using Power BI
Strong query and DAX Skills
Strong data modeling skills
Dimensional model design and implementation
Tools and techniques for ensuring data quality, security, validation, and recovery",4.6,"Adria Solutions
4.6","Manchester, England",-1,1 to 50 Employees,2004,Company - Private,Staffing & Outsourcing,Business Services,Less than $1 million (USD),-1
Software & Data Engineer,-1,"Join us as a Software & Data Engineer

This is an opportunity for a technically minded individual to join us as a Software & Data Engineer
You’ll be working with new and innovative technology to deliver high impact solutions
Hone your existing software engineering skills and advance your career in this critical role

What you'll do

You’ll apply widely agreed software engineering principles and methodologies to design, develop, test and maintain applications and services to achieve the stated business and technology goals within required budgets and timelines. We’ll also look to you to oversee the quality of work, making sure that it meets the technical standards for all services output.

As a proactive team member, you'll be responsible for delivering against a prioritised workstack, as directed by senior engineers and team leads.

You’ll also:

Design and develop reusable libraries and application programming interfaces for use across the bank
Design and develop software that is amenable for a greater automation of build, release testing and deployment process on all environments
Support the reuse and sharing of platform components and technologies within the software engineering teams
Deliver software components to enable the delivery of platforms, applications and services
Write unit and integration tests, in automated test environments to ensure code quality

The skills you'll need

You’ll need a background in software engineering, software design or database design and architecture, as well as experience of developing software in a SOA or micro-services paradigm. You should also have development experience in a programming language, experience of using industry recognised frameworks and development tooling, and a background of implementing programming best practice, especially around scalability, availability and performance.

In addition, we'll look to you to have commercial software development experience, including Scale and Java, coupled with a baseline understanding of a number of core technologies, such as Kafka, Zeppelin, Hadoop and Spark.

You’ll also need:

Experience of test-driven development alongside the use of automated test frameworks, mocking and stubbing and unit testing tools
Knowledge of the key phases of software delivery lifecycle and established software development methodologies
Experience of working in an environment where products must be delivered to specific timescales
An understanding of how to translate product and business requirements into technical solutions
The ability to understand and support, modify and maintain systems and code developed by other engineering teams

If you need any adjustments to support your application, such as information in alternative formats or special requirements to access our buildings, or if you’re eligible under the Disability Confident Scheme please contact us and we’ll do everything we can to help.",3.9,"NatWest Group
3.9","London, England",-1,10000+ Employees,1727,Company - Public,Banks & Credit Unions,Finance,$10+ billion (USD),-1
Machine Learning Engineer,-1,"Interesting Computer Vision use cases for global clients.
A fast-growing company working with state-of-the-art innovative technology.
Great time to join this rapidly growing team.

I am currently working with a very exciting start-up here in Bristol who are looking for a Machine Learning Engineer to join their growing team and help support the development of their products and drive their ML capabilities further.

What you’ll be doing
You will be using Machine Learning models to help this company develop AI products to support their ambitious growth plans. Primarily looking at extracting features from images you will be automating these features and deploying models to give consistent outputs across a range of backgrounds and settings.
This is just one of many use cases they are looking at and this is the perfect opportunity for a knowledgeable and motivated ML engineer to come in and make their mark.

What you’ll need to apply

At least 3 years’ experience working on Machine Learning algorithms and large data sets through either purely commercial or a mixture of commercial and academic work.
Demonstratable experience of using machine learning to solve Computer Vision problems looking at image classification, object detection and segmentation.
A degree in a technology related field (e.g. Computer Science, STEM or Engineering etc.)
Technical skills with Python ideally using frameworks and libraries like OpenCV, Tensorflow, PyTorch and Scikit-learn.
Communication skills are key in this one as you’ll be working with clients across the globe as well as the ability to work well both in a team and alone.

What you’ll get in return for your experience
The salary on this one is up to £50K alongside a range of benefits including, the opportunity to join a growing company from the start, support for training and upskilling, the opportunity to travel to projects and clients across the globe and more. They are headquartered in Central Bristol but are open to candidates based anywhere in the UK and can support working remotely.

What’s next?
Please get in touch with Adam with an up-to-date CV today. Don’t hesitate to email/call to discuss the finer details.",4.9,"ADLIB
4.9","Bristol, England",-1,1 to 50 Employees,2000,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Data Engineer - ELK | DV Cleared,-1,"Job ref:

1169445/001_1603970981

Location:

Huntingdon, Cambridgeshire

Sector:

ICT

Job type:

Contract

Salary:

£650 - £750 per day

Contact:

Jamie Kenward

Email:

jkenward@cbsbutler.com

Published:

5 days ago

Duration:

6 Months +

Start date:

ASAP

Consultant:

Jamie Kenward

Data Engineer - DV Cleared

Company: Global IT Consultancy
Location: Cambridgeshire
Duration: 6 months
Rate: Negotiable to £750 a day

+++ Please note that this is a DV Cleared role +++

Data Engineer: Using your Elasticsearch and Kibana skills you will support an Agile development project which is building bespoke algorithms and applications for a Defence customer. The project aims to provide technical support to the clients' innovation and data science capability, as part of a growing programme of work relating to artificial intelligence, algorithm development and machine learning.

You will design, build and integrate data from various resources to enable a team of data scientists to rapidly leverage those data sets.

Your skills and experience:
strong technical ability with ElasticSearch and Kibana.
good level of familiarity with Apache NiFi.
Desirable:
prior experience with Geospatial data.
familiarity with: Docker, Kubernetes.
prior experience with Python and ML frameworks including (e.g) SciKit-Learn, Keras, TensorFlow, PyTorch.
Apply now and I will call you to discuss this role in more depth",3.9,"CBSbutler
3.9","Huntingdon, England",-1,51 to 200 Employees,2003,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Data Engineer (Contract role),-1,"At Cervest data is the connective tissue that runs through the whole organisation and our product offering. The domain we work in of climate, climate change and its impact on every single physical asset in the world, is represented by a complex data ecosystem.

We are looking for a Data Engineer with experience of working with Geospatial data to join the team, and help us develop our data platform. The role offers a unique opportunity to join an exciting, early-stage, highly mission-driven team where you’ll have the ability to make a significant impact on our company and our users.

This is a contract role likely to extend for approximately 3 months.

Main responsibilities
Working closely with our scientists, engineers and product designers to build the core components of our data platform that satisfies a set of cross functional requirements.
Work with senior leaders throughout Cervest to make sure that what we are building is best in class for what we are trying to achieve today as well as 12 months from now.
Supporting the delivery of tactical requirements both internal and external as and when they occur
Build and grow the Data Engineering team at Cervest and unify the culture of data usage across the organisation.
Requirements
Experience of developing data engineering pipelines and services using Geospatial data
Knowledge of cloud native architectures and Big Data frameworks
Working knowledge of some of the following domains:
Machine Learning
BI and Reporting Analytics
Graph Technology
Benefits

Opportunities to learn, grow and thrive with support from talented and empathetic team mates

We are a remote first company and, given the time frame for this role, we are anticipating that it will be fully remote. We are looking for candidates who would be able to come to our office in London (once travel is sensible) once a quarter using more sustainable transport methods (we'll help with that) so generally within one time zone of the UK.

Fuller list of benefits on our main career page - we’re an early stage startup and currently reviewing our benefits in light of becoming a remote-first company. We are committed to ensuring that we support our team in developing in line with their aspirations and talents as well as continuing to develop our culture in line with our values.",5.0,"Cervest
5.0","London, England",-1,1 to 50 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Cloud Messaging Engineer,-1,"Overview

Technology

Full Time

Closes 25/11/20

Manchester

Full Time

Closes 25/11/20

Who we are looking for

A Cloud Messaging Engineer who will support and develop collaboration, messaging and cloud based solutions in support of bet365 users.

You will contribute to the engineering discipline (and architecture) by utilising your knowledge, this will include planning and building new environments and making them operational.

You will work and partner with other teams to proactively monitor system performance, addressing any issues before they become problems and resolving issues when they occur. The role will ensure service availability is maintained/improved leading to an improved user experience.

You will contribute to planning discussions on IT investments, ensuring solutions and systems are delivered in line with Information Security and Governance requirements.

Preferred skills and experience

Strong experience in developing, supporting and operating enterprise level products such as Microsoft Exchange, Skype for Business, Anti-Virus products and web conferencing solutions.

Practical knowledge with email and web security appliances such as Cisco ESA and Proofpoint Email Security.

Solid experience with cloud technologies including Azure, Teams, O365, AWS and other Cloud Technologies.

Experience performing migrations to Cloud platforms; not just assisting others troubleshooting.

Working knowledge of Mobile Device Management (MDM).

Experience with on premise and Cloud based archiving system such as Veritas Enterprise Vault, Source One and Global Relay.

Stakeholder management and ability to collaborate with people from different disciplines.

Self-motivated, with ability to use initiative and prioritise proactively.

Outcome focused, delivering at pace and successfully to hit deadlines.

Excellent time management, planning and resource planning skills.

Read more

Read less

Main Responsibilities

Providing 3rd line support and developing existing Technology solutions, including resolution of incidents and requests.

Contributing to a technology roadmap and strategy for improvement of services, including the adoption of Cloud Technology solutions. Ensuring best use of technology to improve the user experience.

Working closely with key stakeholders to help define and deliver customer satisfaction.

Keeping up to date with technology, vendors and solutions assisting with developing and identifying improvement opportunities.

Producing and managing continuous service improvement plans, based on the use of data, management information and service targets defined and developed.

Building strong relationships across a broad set of technology teams.",3.5,"Bet365
3.5","Manchester, England",-1,1001 to 5000 Employees,2000,Company - Private,Internet,Information Technology,$2 to $5 billion (USD),-1
Cloud Data Engineer,-1,"We are looking for an experienced and intellectually curious individual, who is hungry for success, to join our growing company in this key role within the Data Practice on a Permanent or Contract basis.

Our people are our company and we work hard to give them a satisfying, fulfilling and rewarding experience. We have a large number of FTSE 100, FTSE 250 and public sector clients and are looking to expand our portfolio significantly.
Rewards*
As well as a competitive salary, the successful candidate will be eligible for additional rewards including profit share scheme, contributory pension and flexible working.
Are you*
Highly motivated, intellectually curious and a forward thinker?
Quality focussed with excellent attention to detail?
Able to build excellent client and internal relationships?
Committed to your own development and willing to undertake relevant development opportunities?
Flexible in your approach to work in order to deliver?
If the answer to these questions is yes and you are interested in this role, please read on.
The Role*
Working as part of the data practice you will work on design & implementation of data solutions for customers across a variety of sectors. The work covers a wide range of data activities including application development, data centre & cloud migrations, and some BI/ETL & analytical projects.

This job requires travel to client sites and other company offices.
Main Responsibilities*
Contribute to the scope & design phase of cloud data platform solutions
Implement & deliver cloud data solutions
Provide consultancy & advice to specific scenarios & problems within the data space
Define and communicate complex data concepts to technical and non-technical people
Contribute to design, code review & test processes
Stay current with industry and competitive research and information
Requirements*
Essential *
Expert in at least one RDBMS implementation
Experience designing & implementing data stores in a variety of technologies & paradigms including Relational/SQL, Key Value/Document & Object/File stores
Experience of working in cloud & hybrid cloud environments
Ability to extend existing knowledge of data systems to new technologies, implementations & languages at pace
Working knowledge of general IT principles (Server Configuration, Networking, Security, Directory Services, DNS, Encryption etc etc)
Experience of one of more scripting & automation languages (PowerShell, Bash, Python etc)
Excellent communication and presentational skills, confident and methodical approach, and able to work within a team environment
Desirable *
Associate Tier Certifications (E.G. AWS Developer Associate, MCSA SQL Server 2016)
Experience in Infrastructure as Code paradigms, ideally CloudFormation, AzureRM and associated CLI Tool
Experience in the automated testing of data solutions
Experience of project delivery including large, complex projects
Exposure to data and analytics application build processes at all stages of the software development lifecycle
Job Types: Contract, Permanent

Salary: Up to £50,000.00 per year

Schedule:
Monday to Friday
Work remotely:
Temporarily due to COVID-19",3.3,"Alscient Limited
3.3","Leeds, England",-1,51 to 200 Employees,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Machine Learning Engineer,-1,"Company Description

A Technology Company with a Passion for Innovation

CGG is a pioneering Technology Company providing world-class fully integrated Geoscience services within the global energy sector. We employ in excess of 5,300 people worldwide, who bring a unique blend of talent and energy through working together to deliver unrivalled innovative solutions to our customers.

Through our cutting-edge Technology in Geoscience and customer focus, we have achieved outstanding leadership with a strong focus on innovation and a commitment to delivering the best sustainable solutions to our clients' energy challenges. We bring our clients a unique range of technologies and services, designed to generate stunning 3D images, geological data and remote sensing information of the Earth’s subsurface structures.

Job Description

Become Part of our Team

We are looking for experienced and talented individuals to joinour largest European centre, based in South-East England, operating across a diverse global market with high profile international customers.

As a Machine Learning engineer, you’ll play a vital role in the continual development of our geoscience analytic techniques. You will work closely with researchers, the software development group and the scientists in our geoscience teams to implement machine learning and deep learning solutions. You will be working with our Geoscientists to validate the potential opportunities for machine learning techniques, prepare data for training and testing, designing the model, training the model and deploying in production. As an integral member of our team, we highly encourage the contribution of ideas and drive in the generation of new concepts, to maintain our outstanding leadership position for technology and service delivery in the market place.

Qualifications

You are likely to be educated to a PHD degree level in any of the following disciplines but a combination of education and experience will be considered; Computer Science, Mathematics, Physics or similar.

Key Skills & Competencies
A passion and aptitude for programming, technology and enthusiasm for analytical and problem solving challenges
Strong experience in developing and debugging in Python and preferably at least one of other main languages (C/C++/ java)
Proven experience with deep learning frameworks and usage of DL libraries (TensorFlow/Pytorch)
Proficiency to design, build, test and support innovative solutions
The ability to define and manage project deadlines
The ability to balance workloads across a wide variety of projects
To keep all stakeholders regularly informed on progress
To innovate and have fun through collaboration and generation of ideas which lead to enhancements of our workflows
An enthusiastic attitude towards learning and flexibility to adapt to new challenges or changes in direction
Additional Information

We ask that you submit a CV and Covering Lettering as part of your application.

Learning and Development

Our culture of learning and complementary approach to supported or self-guided career development, enables the design of tailored courses to suit specific needs of each individual to aid personal growth in areas related to technical, commercial and personal skills, via an extensive suite of CGG developed courses, managed through our own CGG University platform.­

Benefits Package
Competative starting salary.
Highly attractive bonus scheme
Initially 22 days holiday with future increases, complemented by a flexible buying and selling holiday program
Company contributory pension plan
Accommodation assistance program
Flexible Private Medical & Dental care programs, tailored to suit individual or family needs
Employee Assistance Program to support our staff
We Care about our Staff and Environment

We recognise the importance of work life balance for our employees, which is supported through our flexible working and relaxed dress code policies.

We recognise and actively support the wellbeing of our staff through many different initiatives;
Onsite exercise classes and promoting active lifestyles
Our restaurant, offering great food and a highly effective social and work space
Regular social club events, spontaneous reward events throughout the year
Many discounts schemes, including Gym membership and a cycle purchase scheme
We encourage and actively support a strong sense of community, through volunteering and various company initiatives, as well as a strong company commitment to protecting our environment through sustainable solutions, energy saving and waste reduction enterprises.",3.9,"Sercel
3.9","Crawley, West Sussex, South East England, England",-1,501 to 1000 Employees,1956,Company - Private,Utilities,"Oil, Gas, Energy & Utilities",$100 to $500 million (USD),-1
Backend Software Engineer (Python),-1,"We are looking for a Backend Software Engineer to join our talented, dynamic, and rapidly growing global team. The position is based out of our London office situated in the heart of London’s tech community in Shoreditch. All employees have the option to work entirely or partially remote through June 2021.
Company Description*
OpenAsset is the leading Digital Asset Management solution for the Architecture, Construction, Engineering and Real Estate industries. We help our customers be more productive in storing, finding, using and sharing their large volumes of digital assets and associated data.

We have over 600 clients and 15 years experience of delivering value. We are a smart, friendly and motivated group of individuals who are relentlessly focused on building great software, delighting our clients and finding new ones!

Both our London and New York offices have very calm, fun, and welcoming environments.
Position Overview*
As Backend Software Engineer, you will join our growing and talented engineering team that is split across our London and New York offices. Our team is fun, progressive and diligent, and candidates should fit right in!

Our team is friendly, fun, down to earth, and very welcoming!
Responsibilities*
Design and develop services that will support and add new functionality to our core product, OpenAsset.
Take a central role in the creation of software services from the design phase through to production.
Take ownership of deployment, testing and integration pipelines.
Maintain and build upon existing infrastructure.
Adopt and ensure industry best practices are followed.
Have a good awareness and understanding of new technologies and how they may be applied.
Share knowledge and mentor junior members of the team.
Skills and Experience*
3+ years of experience working with Python in a commercial environment
Experience in cloud infrastructure platforms (we use AWS)
Experience using infrastructure-as-code tooling (Terraform preferred)
Microservices architecture experience
Creating and maintaining APIs
Test driven development
Continuous Integration (GitHub actions, CircleCi)
Databases; relational (PostgreSQL, MySQL) and non-relational (DynamoDB)
Confident with Git version control and code reviews.
Are receptive to feedback and are always looking to learn and improve.
Excellent communication skills and comfortable in collaborative environments.
Curiosity and confidence to debate customer value and impact.
Technologies we use*
AWS
Terraform
Python
Go
Docker
Databases (PostgreSQL, MySQL and DynamoDB)
CircleCI
Github (and Github actions)
ElasticSearch
GraphQL
Benefits*
Competitive salary
25 paid vacation days
8 bank holidays
SSP
Bike storage/shower facilities in building
Pension program
_This position is not eligible for visa sponsorship._

_Axomic Ltd. is an Equal Opportunity Employer. We base our employment decisions entirely on business needs, job requirements, and qualifications—we do not discriminate based on race, gender, religion, health, parental status, personal beliefs, veteran status, age, or any other status. We have zero tolerance for any kind of discrimination, and we are looking for candidates who share those values. Applications from women and members of underrepresented minority groups are welcomed._

Job Type: Full-time

Benefits:
Casual dress
Company events
Company pension
Discounted or free food
Sick pay
Schedule:
Monday to Friday
COVID-19 considerations:
All employees have the option to work entirely or partially remote through June 2021.

Work remotely:
Temporarily due to COVID-19",-1,OpenAsset,"Shoreditch, England",-1,-1,-1,-1,-1,-1,-1,-1
Temporary Data Engineer ITSE,-1,"Data Engineer

Information Management Technology

Up to £32,234 per annum

(Temporary appointment for 6 months)

Would you like to be part of team of specialists involved in the design, development and operation of our data warehouse and analytics platform?

Depending on your skills and experience your role might include:
designing and constructing data management solutions and databases
building high performance algorithms, prototypes and predictive models
building and maintaining data pipelines
Norfolk County Council is keen to continue the progress it has made in the use of data to achieve operational efficiencies, improved strategic insight and decision making.

This is a great opportunity for a Data Engineer to be involved in Norfolk County Council’s COVID-19 response, based in Norwich in our Data Services Team.

Experience in Microsoft SQL Server and ETL programming is required. Knowledge of the Microsoft Business Intelligence stack would be a real benefit.

You will need to be flexible, highly motivated and able to work collaboratively with customers, partners, suppliers and colleagues in the Information Management & Technology, Intelligence & Analytics and Public Health services.

You will be required to work weekends, however we can be flexible about other working days.

For an informal discussion, please contact Matt Blanch on 01603 306842 or Tim Hudson on 01603 222720.

All our office-based roles are currently working from home as part of our Smarter Working plans and to support the health and safety of all our colleagues. We anticipate that working remotely will be a key feature of this role and when offices re-open your office base will be County Hall, Norwich.

Our technology platform and equipment is first class enabling you to connect and collaborate remotely. We ask that you have in place good Broadband connectivity.

To view further information regarding the vacancy please click on the link below:

Data Engineer Job Description and Person Spec.docx

Closing date: 03 November 2020

Interviews will take place via video technology, where you will have the opportunity to discuss these working arrangements.",3.8,"Norfolk County Council
3.8","Norwich, England",-1,5001 to 10000 Employees,-1,Government,Federal Agencies,Government,$100 to $500 million (USD),-1
Data Engineer / Remote Working (UK Based) / Up to £51k,-1,"Data Engineer / Remote Working (UK Based) / Up to £51k
APPLY NOW
Data Engineer / Hadoop, Scala, Spark, Python / up to £51k / Remote working (Uk Based)
Are you a Data Engineer who would like to be involved in a company-wide data transformation with a globally recognised brand? Would you like to have a real say in the technical direction and ultimately provide real business benefit?
Corecom Consulting has partnered with a prestigious company based in the heart of Manchester who are rapidly growing their business offering from a data perspective. This is a fantastic time to join an ever-growing business that offer real career development opportunities, both from a career progression and technical perspective.
Their long term vision is to move everything from their data warehouse in to their newly built data lake so they can move from pure reporting to creating more interactive visualisations, whilst looking at patterns in data which will lead to predictive analytics which will allow a complete 360 view of their customers.
Their state-of-the-art offices are in the Greater Manchester Area and boast a friendly, but ambitious technology-driven environment. However, they are working from home at the moment, and have the confirmation that this can be done permanently moving forward (if required).
What can you look forward to?
Remote working
Excellent internal and external training opportunities
Progression opportunities
A chance to work on a “UK sector first” data solution
Generous holiday allowance
Strong pension
Childcare vouchers
What we need from you
Hadoop
SQL
Talend
What would be great to have
Python / R / Scala / Java
Data modelling experience
You will form part of their existing Data Analytics team as you build and maintain their Hadoop solution. The aim is to provide their customers with ownership of their journey as well as employees with the MI needed to implement business decisions. The exciting part of this role is that you will be involved in a “UK sector first” data solution which will not only offer you the scope to develop personally but will add to your current career.
I have interview slots for this role in the next couple of weeks so please apply as soon as possible to avoid disappointment!
Data Engineer / Hadoop, Scala, Spark, Python / up to £51k / Remote working (Uk Based)
Job Reference: 5894
Salary: Negotiable
Salary per: Annum
Job Duration:
Job Start Date: ASAP
Job Type: Permanent
Job Location: Manchester, Greater Manchester
Job Regions: North West
Job Industry: IT
Job Specialism: Business Intelligence and Data Warehousing",5.0,"Corecom Consulting
5.0","Manchester, England",-1,1 to 50 Employees,2008,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1
Senior Data Engineer,-1,"CCP London is looking for a smart and inspired Senior Data Engineer

As a Senior Data Engineer you will be a key player in designing and building a data platform and leverage big data solutions to deliver insights across the company. You will develop solutions to retrieve information from various sources, build and optimize distributed processing solutions along with designing data models and maintaining data quality. To thrive in this position, you are excited about data and emerging technologies related to the field. You are also comfortable collaborating with engineers, producers, analysts and other product owners.

Your tasks:

Create and maintain systems that load and transform large data sets from various sources
Architect and implement data warehouse structure and table schemas
Develop data models to enable end users to effectively analyze data
Optimize and tune data warehouse for query performance and analytical workloads
Take part in designing and leading the implementation of Cloud data architecture strategy
Work with our Data analysts to create data-driven insights and reports for stakeholders and senior management
Maintain and improve on existing data infrastructure and ETL processes

Your profile:

A degree in Computer Science, Software Engineering or a similar field
4+ years of experience in Data Platform Administration/Engineering/Architecture
Minimum of 3 years’ experience working in the gaming industry
Advanced experience with one or more programming languages such as Spark, Python, or Scala
Deep level understanding and implementation experience across AWS Data Services such as Glue, Kinesis, SQS, Redshift, VPC, IAM, EC2, RDS, SNS, CloudWatch, Step Functions, Lambda, EMR.
Substantial Experience in ETL / Data application development
Experience in Architecting and building data pipelines for cloud data assets.
Expertise in database technologies such as Redshift, PostgreSQL, Aurora, Athena and working with large sets of data
Substantial Experience with some of the Big Data ecosystem such as Hadoop, Hive, Spark and Presto
Collaborative individual who excels in working within a team and with business partners identify, develop and deliver innovative data solutions.

What we can offer you:

The inspiring challenge of working on pioneering ambitious projects with amazingly smart and creative co-workers
An opportunity to mentor and guide other more junior team members and co-workers
A multicultural and international work environment that encourages growth, creativity and innovation
Discretionary performance sharing plan
Free lunches, drinks and snacks
A family friendly work environment with flexible work hours
Employer contributory pension plan
Life Insurance
Private medical and Dental
Annual Transportation grant
Annual Sports grant",1.3,"CCP
1.3","London, England",-1,1 to 50 Employees,-1,Franchise,-1,-1,Less than $1 million (USD),-1
Data and ML Engineer,-1,"At Amazon Web Services (AWS), were hiring highly technical cloud computing architects and engineers to collaborate with our customers and partners on key engagements. Our consultants will develop and deliver proof-of-concept projects, technical workshops, and support implementation projects. These professional services engagements will focus on customer solutions such as Machine Learning, Data and Analytics, HPC and more.

In this role, you will work with our partners, customers and focus on our AWS Analytics and ML service offerings such Amazon Kinesis, AWS Glue, Amazon Redshift, Amazon EMR, Amazon Athena, Amazon SageMaker and more. You will help our customers and partners to remove the constraints that prevent them from leveraging their data to develop business insights.

AWS Professional Services engage in a wide variety of projects for customers and partners, providing collective experience from across the AWS customer base and are obsessed about customer success. Our team collaborates across the entire AWS organization to bring access to product and service teams, to get the right solution delivered and drive feature innovation based upon customer needs.


In our Global Specialist Practice, you will also have the opportunity to create white papers, writing blogs, build demos and other reusable collateral that can be used by our customers, and, most importantly, you will work closely with our Solution Architects, Data Scientists and Service Engineering teams.

The ideal candidate will have extensive experience with design, development and operations that leverages deep knowledge in the use of services like Amazon Kinesis, Apache Kafka, Apache Spark, Amazon Sagemaker, Amazon EMR, NoSQL technologies and other 3rd parties.
Excellent business and communication skills are a must to develop and define key business questions and to build data sets that answer those questions. You should be able to work with business customers in understanding the business requirements and implementing solutions.

Basic Qualifications

· Bachelors degree, or equivalent experience, in Computer Science, Engineering, Mathematics or a related field
· 5+ years experience of Data platform implementation, including 3+ years of hands-on experience in implementation and performance tuning Kinesis/Kafka/Spark/Storm implementations.
· Ability to think strategically about business, product, and technical challenges in an enterprise environment.
· Experience with analytic solutions applied to the Marketing or Risk needs of enterprises
· Basic understanding of machine learning fundamentals.
· Ability to take Machine Learning models and implement them as part of data pipeline
· Highly technical and analytical, possessing 5 or more years of IT platform implementation experience.
· Understanding of Data Analytics ecosystem. Experience with one or more relevant tools ( Flink, Spark, Sqoop, Flume, Kafka, Amazon Kinesis ).
· Experience developing software code in one or more programming languages (Java, JavaScript, Python, etc).
· Current hands-on implementation experience required
· Ability to travel to client locations to deliver professional services when needed.

Preferred Qualifications

· Masters or PhD in Computer Science, Physics, Engineering or Math.
· Hands on experience working on large-scale data science/data analytics projects.
· Ability to lead effectively across organizations.
· Hands-on experience with Data Analytics technologies such as AWS, Hadoop, Spark, Spark SQL, MLib or Storm/Samza.
· Implementing AWS services in a variety of distributed computing, enterprise environments.
· Proficiency with at least one the languages such as C++, Java, Scala or Python.
· Experience with at least one of the modern distributed Machine Learning and Deep Learning frameworks such as TensorFlow, PyTorch, MxNet Caffe, and Keras.
· Experience building large-scale machine-learning infrastructure that have been successfully delivered to customers.
· Experience defining system architectures and exploring technical feasibility trade-offs.
· 3+ years experiences developing cloud software services and an understanding of design for scalability, performance and reliability.
· Experience working on a code base with many contributors.
· Ability to prototype and evaluate applications and interaction methodologies.
· Experience with AWS technology stack.
· Written and verbal technical communication skills with an ability to present complex technical information in a clear and concise manner to a variety of audiences.
Amazon is an Equal Opportunity-Affirmative Action Employer Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation.",3.9,"Amazon
3.9","London, England",-1,10000+ Employees,1994,Company - Public,Internet,Information Technology,$10+ billion (USD),-1
Senior Data Engineer,-1,"MAG is the country’s largest airport group. We own Manchester, Stansted and East Midlands Airports as well as having MAG USA, a large Airport Services business based in Chicago. MAG-O is our digital business, driven by data and created to take the Group on the next leg of its digital journey. Utilising advanced MI, digital platforms, and new and emerging technologies, this is a fast-moving, agile engine house of ideas and innovation. We are a globally focused business, and pride ourselves on being the number one airport-centric travel company; defining how airports increase their non-aero revenues and delivering our class leading e-commerce services to airport clients across the world.

Do you want to see the office? Click the link below:

https://www.youtube.com/watch?v=0pYS_ghtWSU&t=81s

The Role:

This Senior Data Engineer position is a key component in the growth of the Data Science team. Supporting the existing team of data scientists, and wider business with usable analytics. This role will help provide the glue that enables the team to capitalise on the data assets the business has, and drive value from the insight we extract. We develop advanced and actionable data-driven insight to increase the efficiency of our marketing and ecommerce, increase customer lifetime value, improve customer experience, and open new business opportunities.

This role offers an opportunity to work at scale with data from MAG’s 3 airports, marketing leading distribution companies (that we own) MAG USA and our numerous global clients. MAG’s customers alone number 60 million passengers per year, 70,000 car parking spaces, and digital properties attracting 30 million visitors per year. The projects supported are also varied, including forecasting, revenue management, support to the CRM team with optimization, customer experience, and recommender systems, with increasing interest in real-time solutions.

Typical duties will include:
To structure, develop, and support ETL tools for use by the Data Science team
Accountable for ensuring that data is made available when required
Development and maintenance of and MAG-O-specific data warehouse
Leading the acquisition and extraction of relevant data sets
Responsible for the development of production-level code to support active Insights products, such as API-driven interactions with CRMs
Creation of adequate test harnessing and log capture to ensure we track the performance of the data science models implemented.
Leading the team and the wider business on ensuring solutions are secure, reliable, fault-tolerant and efficient
You!

As the successful individual, you will have experience working as a Data Engineer, ideally in the direct support of data science activities, be a genuine self-starter, and eager to support our business in tackling real world strategic business and customer problems. You will join our established Data Science team, working together to help increase productivity, push forward our tools and pipelines, and grow and help govern our data lake and warehouse.

You will have in-depth practical experience with AWS and will be comfortable leveraging services such as EC2, Redshift, Lambda, Kinesis, and Batch. Further, you’ll be able to help shape our evolving data science environment. You will have expert experience with Python, detailed SQL knowledge, and be used to dealing with API services to ingest and process data. Experience of supporting data users working with R is advantageous.

You must be naturally inquisitive and unafraid to offer solutions in a supportive and collaborative manner. You will need to be able to deal with multiple tasks simultaneously and be a supporting team player. As a growing team within MAG-O, you will have the opportunity to help shape how we operate, work with the latest technologies, and grow your skills, experience, and responsibilities.

Equal Opportunities:

MAG is a values led organisation and we are committed to providing equal opportunities in all areas of work and business. We want people to achieve their best, which will in turn positively impact on our customers and the communities in which we live and work. At MAG we empower people to be themselves within an inclusive and supportive environment, enabling everyone to achieve their full potential in line with their abilities and career aspirations.

Reasonable Adjustments

As an inclusive employer, MAG wants to see every candidate performing at their best throughout the job application process, interview process and whilst at work. We therefore encourage you to inform us of any reasonable adjustments you might need to enable this to happen.

Please apply today as interviews will commence immediately

Job Segment:
Database, Warehouse, Engineer, SQL, Revenue Management, Technology, Manufacturing, Engineering, Finance",3.1,"Manchester Airport Group
3.1",Greater Manchester,-1,5001 to 10000 Employees,1928,Government,Airlines,Travel & Tourism,$500 million to $1 billion (USD),-1
Data Engineer - Agile - Investment Management,-1,"Location

City of London

Sector:

Big Data and Business Intelligence, Data Science & Engineering

Job type:

Permanent

Salary:

£65000 - £85000 per annum

Consultant:

Richard Twumasi

Contact email:

richard.twumasi@harringtonstarr.com

Job ref:

RT/13196_1601920324

Startdate:

ASAP

Email:

richard.twumasi@harringtonstarr.com

Data Engineer - Agile - Investment Management

Harrington Starr are currently working with a world leading investment management firm who are seeking an imaginative and creative Data Engineer to join their team and bring your fresh ideas to solving problems to their current team.

The team is a high performing team who work in an open and collaborative agile framework, they share ideas and solve problems with overall common purpose and they are looking for an engineer who has expertise in system assessments, design, development, and implementation of applications and databases for client/server-, Web-, and/or PC-based software or middleware.

Your role will primarily assist in keeping internal innovation improving at pace, by either building new software or optimising current products, your role will be not just to participate but take ownership via designing, coding and testing throughout the whole process of a products lifecycle.

You'll identify issues, explain solutions, translate technical specifications, use software development techniques to ensure test automation.

So what technical skills are our client looking for:

As a Data Engineer you will have:

5 Years+ Experience in Development or System Analysis with strong knowledge of Software Development Practices, with a proven track record
Knowledge of Investment Management
Strong technical skills in relational databases (Oracle, SQL Server, Microsoft VB, .Net, C#)
Experience customising and integrating to vendor/3rd party products

If you have the above skills and are interested in working for a world renowned and leading organisation in Investment Management, then please get in touch.",4.2,"Harrington Starr
4.2","London, England",-1,51 to 200 Employees,2010,Company - Private,Staffing & Outsourcing,Business Services,$1 to $5 million (USD),-1
ML Engineer / Data Scientist,-1,"Machine Learning Engineer (Data engineering/ Data Science)

ML Engineer / Data Scientist is required for a tech-driven company in a stunning London location. This is a diverse opportunity for a data scientist / machine learning engineer to join a fantastic company, who are global leaders in their industry. You’ll be working on an exciting data-centric product and have exposure to the entire lifecycle of the product.

What’s in it for you as the ML Engineer / Data Scientist:

The ML Engineer / Data Scientist will have a competitive salary of up to £65,000

Being part of an award winning, tech driven company
Gym membership
Generous holidays, plus your birthday
Healthcare and eyecare benefits
Being part of a data – driven and dynamic team
Working with a modern tech stack
New stylish office location

What you’ll be doing in this ML Engineer/ Data Scientist:

You will be applying NLP and other machine learning techniques to large amounts of data and performing analysis
You will be required to be consultative, and explain complex ideas to non-technical audiences
You will be focused on production (not only researching)
You’ll be implementing prototypes and working in a Big Data environment

Essential skills of the ML Engineer/ Data Scientist:

2 years of commercial experience
Exposure to NLP
Good experience with machine learning and Data Science
Great programming skills in Python, R, Java or Scala
Very good communicative skills
Ability to work well in a close-knit team
Practical Knowledge of SQL/Nosql databases
Relevant Bachelor’s degree in ML, Computer Science, Mathematics, statistics etc

Beneficial skills of the ML Engineer/ Data Scientist

Experience with deep learning, text mining or neural nets
Exposure to technologies such as tensorflow, decision trees, spark
Masters or PHD in relevant subject

As you can see this is a well-rounded and diverse opportunity to improve skills in all areas and join an innovative data-driven company.

To apply for this position please send a recent CV to: georgia.bright@venturi-group.com

Keywords for search – Big Data, NLP, Machine Learning, Python, Data Scientist, Numpy, Scipy, Sklearn, ML, tensorflow, decision trees, computer science, statistics, spark, scala, R, neural nets, deep learning, SQL, NoSQL, Java, Big Data, NLP, Machine Learning, Python, Data Scientist, Numpy, Scipy, Sklearn, ML, tensorflow, decision trees, computer science, statistics, spark, scala, R, neural nets, deep learning, SQL, NoSQL, Java, Big Data, NLP, Machine Learning, Python, Data Scientist, Numpy, Scipy, Sklearn, ML, tensorflow, decision trees, computer science, statistics, spark, scala, R, neural nets, deep learning, SQL, NoSQL, Java, Big Data, NLP, Machine Learning, Python, Data Scientist, Numpy, Scipy, Sklearn, ML, tensorflow, decision trees, computer science, statistics, spark, scala, R, neural nets, deep learning, SQL, NoSQL, Java, Big Data, NLP, Machine Learning, Python, Data Scientist, Numpy, Scipy, Sklearn, ML, tensorflow, decision trees, computer science, statistics, spark, scala, R, neural nets, deep learning, SQL, NoSQL, Java, Big Data, NLP, Machine Learning, Python, Data Scientist, Numpy, Scipy, Sklearn, ML, tensorflow, decision trees, computer science, statistics, spark, scala, R, neural nets, deep learning, SQL, NoSQL, Java, Big Data, NLP, Machine Learning, Python, Data Scientist, Numpy, Scipy, Sklearn, ML, tensorflow, decision trees, computer science, statistics, spark, scala, R, neural nets, deep learning, SQL, NoSQL, Java, Big Data, NLP, Machine Learning, Python, Data Scientist, Numpy, Scipy, Sklearn, ML, tensorflow, decision trees, computer science, statistics, spark, scala, R, neural nets, deep learning, SQL, NoSQL, Java, Big Data, NLP, Machine Learning, Python, Data Scientist, Numpy, Scipy, Sklearn, ML, tensorflow, decision trees, computer science, statistics, spark, scala, R, neural nets, deep learning, SQL, NoSQL, Java

Venturi (TVGL Inc.) is an equal opportunity employer and does not discriminate on the basis of age, colour, sex (including pregnancy), gender, gender identity, genetic information, marital status, military/veteran status, national origin, ancestry, race, creed, religion, sexual orientation, transgender status, non-disqualifying physical or mental disability, domestic violence victim status, criminal or arrest record, unemployment status, or any other basis protected by applicable law.",4.8,"Venturi
4.8","London, England",-1,51 to 200 Employees,2009,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Machine Learning Engineer,-1,"Machine Learning Engineer (Data engineering/ Data Science)

ML/ Data engineer/ Scientist is required for an innovative and well-funded start-up company based in a central London location. This is a diverse opportunity for a data scientist with machine learning and data engineering experience to join a company that changes the way we think about data, and what we can do with it!

You will be using your engineering skills to build data pipelines and design algorithms to manage huge amounts of data.

What’s in it for you as the ML Engineer / Data Scientist:

The ML Engineer / Data Scientist will have a competitive salary of up to £55,000

Equity shares in the business
Being part of an award winning, tech driven company
Being part of a tech driven and dynamic team
Working with a modern tech stack
New stylish office location
Flexible working hours

Key Skills and Responsibility of the ML Engineer/ Data Scientist:

Strong knowledge of algorithms and building data pipelines
Experience with classic Machine Learning technologies
Excellent knowledge of Python
Great skills with pandas, numpy, scipy and sklearn
2 years commercial experience
BSc or higher in a STEM subject

Nice to have but not essential

Experience using R, Deep learning, NPL

As you can see this is a well-rounded and diverse opportunity to improve skills in all areas and join an innovative organisation in the machine learning industry as a Machine Learning Engineer.

To apply for this position please send a recent CV to: georgia.bright@venturi-group.com

Keywords – Big Data Engineer, Machine Learning, Python, Data Scientist, Numpy, Scipy, Sklearn, ML, Big Data Engineer, Machine Learning, Python, Data Scientist, Numpy, Scipy, Sklearn, ML, Big Data Engineer, Machine Learning, Python, Data Scientist, Numpy, Scipy, Sklearn, ML, Big Data Engineer, Machine Learning, Python, Data Scientist, Numpy, Scipy, Sklearn, ML, Big Data Engineer, Machine Learning, Python, Data Scientist, Numpy, Scipy, Sklearn, ML.

Venturi (TVGL Inc.) is an equal opportunity employer and does not discriminate on the basis of age, colour, sex (including pregnancy), gender, gender identity, genetic information, marital status, military/veteran status, national origin, ancestry, race, creed, religion, sexual orientation, transgender status, non-disqualifying physical or mental disability, domestic violence victim status, criminal or arrest record, unemployment status, or any other basis protected by applicable law.",4.8,"Venturi
4.8","London, England",-1,51 to 200 Employees,2009,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
GCP Data Engineer- London - 475-500pd,-1,"My London based client is looking for an experienced Data Engineer who is proficient in building and maintaining data pipelines on GCP stack. Proficient in ETL/ELT process, data migration from on-premise to GCP.
Dedicated, self-sufficient, experience to work independently.
· Experience in ETL/ELT process
· Experience in data visualisation
· Experience with NIFI tool
· Experience in writing and maintaining data pipelines using DataFlow (Apache Beam)
·
· Hands-on experience working with Data stack on GCP:
· Pub/Sub
· GCS
· Data Flow
· Data Composer (Airflow)
· BigQuery
· Ability to write and modify templates for DataFlow written in Java (is a must)
· Experience in writing complex SQL queries
· Experience in modifying jobs in Jenkins (on developer level, not a DevOps)
· Ability to read and modify Terraform templates ( developer level, not a DevOps)

GCS Computer Recruitment Services is acting as an Employment Business in relation to this vacancy.",4.2,"GCS Recruitment Specialists Ltd
4.2","London, England",-1,51 to 200 Employees,1991,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Data Software Engineer,-1,"The Position:

• Develop, implement and maintain software solutions that enable business operations to realise company goals and objectives.
• Analyse, design, code, debug, test and support software application systems.
• Provide mentoring and guidance to less experienced peers.
• Assign work tasks and review the work products of others.
• Assist the department manager/director in developing processes and standards.

Job Responsibilities:

Experience requirements and skills:

• Excellent analytical, problem solving and organisational skills.
• Practiced in the theoretical and practical applications of software engineering methods and techniques.
• Experience of developing solutions in C# and SQL Server using Visual Studio
• Proficient in SQL querying.
• Knowledge of source code change management and related tools.
• Knowledge of using agile software development principles.
• Required knowledge and skills would typically be acquired through a bachelor’s degree in a numerate subject or equivalent experience.

Required Skills/Experience:

• Some exposure to finance (particularly insurance) a bonus.
• Experience of building financial models desirable.
• Technology based qualifications advantageous.

Desired Skills/Experience:

• Required knowledge and skills would typically be acquired through a bachelor’s degree in Computer Science, a related field or equivalent experience.
• Ideally some exposure to insurance (particularly Lloyd’s and London Market)

Education:

• Required knowledge and skills would typically be acquired through a bachelor’s degree in a numerate subject or equivalent experience.
• Some exposure to finance (particularly insurance) a bonus.
• Experience of building financial models desirable.
• Technology based qualifications advantageous.
• 3 or more years of professional experience.",-1,Arch Europe Insurance Services Ltd,"Manchester, England",-1,-1,-1,-1,-1,-1,-1,-1
Machine Learning Engineer,-1,"OakNorth is the next-generation credit and monitoring platform that provides banks and lending institutions with the insight and foresight needed to create a better borrowing experience for the Missing Middle – the growth business who are the backbones of communities and economies globally but who have been in banking’s blind spot for decades.

The business was founded in 2015 by Rishi Khosla and Joel Perlman, who previously co-founded Copal Amba and grew it to 3,000 employees over 12 years, before selling it to Moody’s (NYSE: MCO) in 2014, returning 125 times capital to seed investors.

Since its inception, OakNorth has secured over $1bn from several investors, including: Clermont Group, Coltrane, EDBI of Singapore, GIC, Indiabulls, NIBC, Toscafund, and SoftBank’s Vision Fund.

The Platform has been deployed at various banks across North America, Europe, and Asia, and in the UK where OakNorth lends off of its own balance sheet via OakNorth Bank. The platform has helped OakNorth Bank become the fastest-growing business in Europe according to the Financial Times FT 1000 (2020), profitably lending over £4bn to date. In terms of the impact this has had on the economy, OakNorth Bank’s loans have directly helped with the creation of 13,000 new homes and 17,000 new jobs in the UK, as well as adding several billion pounds to the economy.

With offices in London, New York, Manchester, Singapore, Hong Kong, Shanghai, Istanbul, Gurgaon and Bangalore, the global team across the OakNorth Holdings group is over 800 people.

SMEs are crucial in the global economy. Although they account for 99% of business in the UK/US, their financing need is increasingly difficult to be met by major banks, due to higher risk of default and the diversity of different sectors in that make up ""SME"".

To solve this problem, OakNorth is building a platform to improve productivity of SME lenders. From credit appraisal, to loan monitoring, the OakNorth Machine Learning team has identified multiple key areas that can be optimised by recent advances in Machine Learning (ML), Natural Language Processing (NLP), Computer Vision (CV), and Information Retrieval (IR).

We are looking for passionate scientists and/or software engineers who will be joining the fastest growing and profitable fintech in London as a Machine Learning Engineer. You enjoy solving challenging tasks and creating impactful and data-driven products with innovative techniques.
We expect you are:
Experienced in Machine Learning, Computer Vision, NLP, Information Retrieval, or related fields
A PhD / MSc or equivalent industrial experience
Able to quickly learn new technologies and comprehend academic literatures independently.
We would love to see:
Experience with modern deep learning frameworks (e.g. PyTorch, Tensorflow, Jax)
Experience working on distributed software system (e.g. Spark, Hadoop, ElasticSearch)
Publications in related academic venues (e.g. ACL, CVPR, EMNLP, ICML, KDD, NeurIPS)
You will:
Work with domain experts to shape the future of our platform.
Research and evaluate techniques that can improve/solve a concrete business workflow/problem.
Convert research findings into production-level software systems.
Publish findings in top-tier academic venues.
Thank you very much for your interest in OakNorth. We are happy to consider you for roles within our group of companies. If we can identify a match between your skill set and our immediate recruiting needs, please expect to hear from us very soon. If we are unable to identify a fit in the near term, please note that we intend to retain the data you send to us so we may contact you in the future.",4.1,"OakNorth Bank
4.1","London, England",-1,51 to 200 Employees,2015,Company - Private,Lending,Finance,Unknown / Non-Applicable,-1
"Data Scientist / BI Engineer - Cirencester, UK",-1,"Corin, an orthopaedic medical device business, is currently looking for a Data Scientist / BI Engineer to support our Digital Transformation across all business functions with insights gained from analysing company data and delivery of data models and tools. This is a key role to establish our Digital Centre of Excellence supporting both our Digital Health offering and our business process digitalization.

You will based in our global head office in Love Lane, Cirencester, Gloucestershire reporting into the Group IT Director and working alongside the Chief Transformation Officer.

The ideal Data Scientist / Business Intelligence Engineer will be adept at using large data sets to find opportunities for product and process optimization and building and implementing models to test the effectiveness of different courses of action.

You must have a proven experience in driving business results with your data-based insights using data mining, data tools and data analysis, as well as using and creating algorithms and developing and running simulations.

You must be comfortable working with a wide range of stakeholders and functional teams and have a genuine passion for discovering solutions hidden in data sets. You must have a strong drive, be a self-starter and be ready to work pragmatically towards business deliverables.

Corin provides a progressive and dynamic work environment where you can take control of your career, be accountable and drive positive change. Corin is going through an exciting period of growth with our investment partner Permira committed to driving global technological / robotic advancements in the implant of hip and knee surgery which in turn delivers better patient and surgical outcomes.

The key responsibilities of the Data Scientist / BI Engineer are to:

Establish and lead Data Science at Corin:
Work with the management team and key stakeholders throughout Corin to identify opportunities for leveraging company data to drive value creation and effective decision making.
Make a difference to our business, our Customers, and our Patients, by solving real life problems and delivering insights to improve health outcomes.
Be key in developing and driving a data hub of digital graduates for future talent succession growth.
Deliver expert solutions, working alongside our CIO, Data engineers and architects:
Build and maintain reference datasets and pipelines
Mine and analyse data from company databases. Develop custom data models, time-series forecasting and predictive algorithms to apply to data sets.
Generate analytical insights and develop solutions to drive optimization and improvement of business strategies, commercial excellence, operational efficiency, and digital product development (i.e. Clinical Insights / Digital Health solutions)
Requirements

The ideal Data Scientist / BI Engineer will have;
A Degree, Masters or PHD in Computer Science, Data Science or Analytics, Engineering or Physics, Mathematics or Statistics and / or operational research
Knowledge and experience in statistical, machine learning, modelling and data mining techniques: Multi-variate analysis (MVA), GLM/Regression, Clustering, Random Forest, Boosting, Trees, text mining, social network analysis, neural networks, etc.
Experience querying databases and using statistical computer languages: R, Python, SQL, etc., to manipulate data and draw insights from large data sets.
Experience working and creating data architectures ideally in MS SQL server.
Experience of MS Azure platform tools such as Datafactory, Databricks, synapse Analytics would be beneficial
Experience visualizing/presenting data for stakeholders using: Power BI, Dundas BI, Tableau, etc.
Strong coding knowledge and adept at programming with several languages: C#, .net framework C, C++, Java, JavaScript etc.
Clear experience in building and managing roadmaps, balancing sprint vs. ad/hoc effort. Demonstrated knowledge of the data lifecycle, including experience with data modelling and data quality
Ability to share solutions and ideas with a broad scope of stakeholders across business functions and lead by influence.
A drive to learn and master new technologies and techniques.
Strong problem-solving skills with an emphasis on product development.
Excellent written and verbal communication skills for coordinating across teams.
Preferably, time served experience with a clinical, healthcare, orthopaedic, or pharmaceutical business, manipulating their data sets and building statistical models.
Benefits

You will receive a competitive salary and annual bonus as well as;
25 days holiday plus bank holidays.
Excellent pension – up to 9.7% provided by Corin when you contribute 4%
Life assurance (6x basic salary).
Private medical insurance with BUPA for you and your family.
Subsidised canteen and gym membership.
Free car parking - close to Swindon, A419, Cheltenham, Gloucester and Stroud.
Friendly and collaborative working environment",2.8,"Corin
2.8","Cirencester, England",-1,201 to 500 Employees,1985,Company - Public,Health Care Products Manufacturing,Manufacturing,$100 to $500 million (USD),-1
Big Data Engineer / Developer,-1,"Big Data Engineer / Developer ( Spark / S3 / Hive )

London

January 2019

A thriving transport organisation based in Central London is looking to expand their Big Data team, in readiness for a new and exciting Big Data Ingestion Project to commence early January 2014.

They are looking for an experienced Big Data Engineer / Developer ( Spark / S3 / Hive ) to enter an agile environment, building data pipelines that will impact both existing customers and drive new business.

The right candidate will enter a passionate team of Data Engineers and Developers, using cutting-edge technologies to implement the ETL Pipelines.

The Big Data Engineer / Developer ( Spark / S3 / Hive ) will work closely with the Product Manager and business staff, using their own initiative to take responsibility when required.

Essential skills for the Big Data Engineer / Developer ( Spark / S3 / Hive ) include :

Expert understanding and knowkedge of Apache Spark
S3
Amazon
Hive
MapReduce
Expert knowledge in at least one programming language (Python / Scala / Java)

Desirable skills for the Big Data Engineer / Developer ( Spark / S3 / Hive ) include :

Experience in using AWS Stack and scalable relational databases such as (Redshift / Teradata)
Understanding of Apache Nifi
Sound knowledge of Apache Kafka
Masters degree in Mathematical Sciences or statistical related subject

Key Responsibilities for the Big Data Engineer / Developer ( Spark / S3 / Hive ) include :

Ensuring smooth implementation of code into cloud environment
The ability to share knowledge with team members and provide support when needed

Why you should consider the Big Data Engineer / Developer ( Spark / S3 / Hive ) role :

Competitive salary on offer
Great work benefits, including regular lunches out and events with team members
Opportunity to attend worldwide conferences and Big Data events

If this sounds like you, send your updated CV to Olivia on olivia.ferris@venturi-group.com or ring on 02031377005

Interviews for the Big Data Engineer / Developer ( Spark / S3 / Hive ) will take place over the next few weeks, with a view to commence project in January.

Venturi is a staffing business dedicated to you, differentiating ourselves in the marketplace by quality of service and candidate delivery. Our highly skilled and experienced staff operate within dedicated markets to give you the best service possible. Venturi markets include Business Intelligence, Development IT & Legal IT. Venturi operates as an employment agency and employment business. No terminology in this advert is intended to discriminate on the grounds of age, and we confirm that we are happy to accept applications from persons of any age for this role",4.8,"Venturi
4.8","London, England",-1,51 to 200 Employees,2009,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
PySpark Data Engineer,-1,"PySpark Data Engineer ( Python / Spark / ML )

3 months

£550 – £600

Central London

A PySpark Data Engineer ( Python / Spark / ML ) is required to join a prestigious consultancy to support a multinational telecommunications provider. The project is three months in length and will be based in Central London.

My client is looking for a skilled PySpark Data Engineer ( Python / Spark / ML ) with experience of productionising and transcoding machine learning models to start on an immediate basis.

Essential Skills for the PySpark Data Engineer ( Python / Spark / ML ) include:

Very strong experience in Python
Very strong experience in Spark
2 years+ of firm Big Data project experience, more specifically as a Data Engineer
Commercial experience of productionising/transcoding machine learning models that have been prototyped by a data scientist

Desired Skills for the PySpark Data Engineer include:

Sufficient experience in Scala
Sufficient experience in Kafka
A sufficient understanding of NoSQL databases, including: HBase, Cassandra and MongoDB
*The more Big Data Experience the better!**
Pre-Requisite:

You must have the legal right/permit to work in the UK

If you would like to be considered for the PySpark Data Engineer ( Python / Spark / ML ) role, please click Apply.

The ideal candidate must be able to start immediately.

Venturi is a staffing business dedicated to you, differentiating ourselves in the marketplace by quality of service and candidate delivery. Our highly skilled and experienced staff operate within dedicated markets to give you the best service possible. Venturi markets include Business Intelligence, Development IT & Legal IT. Venturi operates as an employment agency and employment business. No terminology in this advert is intended to discriminate on the grounds of age, and we confirm that we are happy to accept applications from persons of any age for this role.

PySpark Data Engineer ( Python / Spark / ML )

3 months

£550 – £600

Central London

A PySpark Data Engineer ( Python / Spark / ML ) is required to join a prestigious consultancy to support a multinational telecommunications provider. The project is three months in length and will be based in Central London.

My client is looking for a skilled PySpark Data Engineer ( Python / Spark / ML ) with experience of productionising and transcoding machine learning models to start on an immediate basis.

Essential Skills for the PySpark Data Engineer ( Python / Spark / ML ) include:

Very strong experience in Python
Very strong experience in Spark
2 years+ of firm Big Data project experience, more specifically as a Data Engineer
Commercial experience of productionising/transcoding machine learning models that have been prototyped by a data scientist

Desired Skills for the PySpark Data Engineer include:

Sufficient experience in Scala
Sufficient experience in Kafka
A sufficient understanding of NoSQL databases, including: HBase, Cassandra and MongoDB
*The more Big Data Experience the better!**
Pre-Requisite:

You must have the legal right/permit to work in the UK

If you would like to be considered for the PySpark Data Engineer ( Python / Spark / ML ) role, please click Apply.

The ideal candidate must be able to start immediately.

Venturi is a staffing business dedicated to you, differentiating ourselves in the marketplace by quality of service and candidate delivery. Our highly skilled and experienced staff operate within dedicated markets to give you the best service possible. Venturi markets include Business Intelligence, Development IT & Legal IT. Venturi operates as an employment agency and employment business. No terminology in this advert is intended to discriminate on the grounds of age, and we confirm that we are happy to accept applications from persons of any age for this role.",4.8,"Venturi
4.8","London, England",-1,51 to 200 Employees,2009,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Machine Learning Engineer,-1,"SteadyPay is an award-winning London based FinTech start-up, designed specifically for those paid by the hour, shift or task being first of its kind income smoothing and protection provided to the gig economy. SteadyPay's vision is to become the lifetime financial partner of gig-economy workers globally.

SteadyPay's app enables gig economy workers to enjoy regular income even when they work irregular hours (due to such factors as reduced shifts, fewer bookings, time off sick and holidays). Using the SteadyPay mobile app, customers securely link to their bank via open banking. When our customers earn below average, we provide a top-up, advancing money straight to the customer's bank to bring their income back. We challenge banks and traditional lenders by not charging interest or any other fees - we are a subscription credit service, think Netflix for credit.

Given our exceptionally strong growth up to date and overwhelmingly positive feedback from our customers, we are looking to accelerate our development roadmap and looking for a Machine Learning Engineer to assist us in this effort.

Tasks
Create code to import data from Kafka to reside on a cloud data warehouse (BigQuery or cloud platform agnostic)
Transform data as required
Discuss the hypothesises and result requirements with the business team
Develop, train and test models using a cloud platform agnostic solution
Create code to present and visualise results of the new model vs. existing / previous ones
Integrate machine learning models with our credit risk platform
Prepare and maintain related documentation
Requirements
Strong understanding and experience using of cloud platforms agnostic Machine Learning frameworks such as PyTorch and TensorFlow
Experience of using cloud-hosted solutions and data warehouses
Experience of building, training and testing Machine Learning models
Ability to hypothesise business problems and possible solutions using existing datasets
Results-orient problem solver, who thrives in challenging situations
Team player - enjoys working with and mentoring other developers to solve difficult problems, while at the same time working with other areas of the businesses
You are very hands-on and a self-starter who wants to work hard and doesnt need much supervision
You are fun and keen on working in an exciting start-up environment, being a part of the core team on the way to scaling up
Right to work in the UK
Good to have
Experience with Kubernetes
Experience with Kafka, Cassandra and ElasticSearch
Experience with CI/CD
Experience with Java
Experience with web application development with at least jQuery, Angular or React JS
The role is based in our office in Notting Hill with flexible working hours we are focused on getting the job done rather than watching the clock!",-1,SteadyPay,"London, England",-1,-1,-1,-1,-1,-1,-1,-1
Machine Learning Engineer,-1,"Salary will be completely negotiable and dependent on relevant background and experience and will include company benefits/significant bonuses.

*The client, a growing technology business with lots of opportunity to develop a career and based in central Manchester are seeking a Machine Learning Engineer to join their team at this exciting time of growth. *

*Purpose of the role: *

In this role you will:

• architect solutions for Data Science projects

• productise and optimise ML code

• build and maintain ML pipelines

• work closely with other team members on delivering projects

*Requirements & Experience *

*Essential Skills: *

• strong coding skills (Python, Scala, etc)

• demonstrable experience in productising ML solutions

• demonstrable experience in designing cloud solutions

• knowledge and experience of CI/CD

• excellent SQL skills

• AWS knowledge

• ability to work well under pressure

*Desirable (none essential) Skills: *

• AWS certification

• experience with workflow tools (Airflow, Luigi, etc)

*This is a fantastic opportunity to join an already successful business as it continues to grow, and you can be a big part of that journey.*

Job Types: Full-time, Permanent

Salary: £40,000.00-£55,000.00 per year

Additional pay:
* Bonus scheme",-1,Marstep Resourcing Solutions,"Manchester, England",-1,-1,-1,-1,-1,-1,-1,-1
Permanently Remote Data Engineer - Python / ETL / Pipeline,-1,"Data Engineer - Python / ETL / Pipeline
Warehouse management system
Permanently Remote or Cambridge
Salary dependent on experience

The Role

As a Data Engineer you will work to build and improve the tools and infrastructure that the Data Scientists use for working with large volumes of data and that power user-facing applications. You will work on a nascent data pipeline with plenty of scope to guide its direction and growth, and regularly collaborate with both the Data Scientists and data providers in the wider business to understand their needs. You will build and customise open-source components to create a pipeline that will drive decision making and process improvement. You will create and maintain the ETL infrastructure on our own OpenStack private cloud, and work with Data Scientists to help them turn their models and analysis into production systems.

The Person
You will be a problem solver above all else, open to using new technologies and have an R&D mind-set. Strong academics help.

The Requirements

Have at least 5 years experience working in software development.
Be expert in Python. Ideally also be comfortable working in other languages when the need arises.
Be skilled in common tools such as Puppet and Git, or equivalents
Have experience working with PostgreSQL (or other relational database system)
Be comfortable developing for distributed systems
Have a keen interest in learning and a desire to help educate those around them in new technology
Work effectively with a distributed team and in an agile environment

The Team

The brightest in the industry, location not being a factor they have gathered great problem solvers, mathematicians and scientist to work on this greenfield project.

The Project

Large logistics / warehouse solutions

The Location

Remote, 1 day fortnightly in the Cambridge Office.

GCS Computer Recruitment Services is acting as an Employment Agency in relation to this vacancy.",4.2,"GCS Recruitment Specialists Ltd
4.2","Cambridge, East of England, England",-1,51 to 200 Employees,1991,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Senior Data Engineer,-1,"Senior Data Engineer/Data Base Administrator – Negotiable Salary – Plus Benefits – London – J10502

This senior role involves working within an existing team of Data Scientists demonstrating direct experience in proposition development and commercial exploitation of data, good working knowledge of SQL, Python and data base administration. These vital skills are required by an international organisation working across the public and private sectors, solving the complex challenges of their clients.

Role & Responsibilities
• Implement complex multi/hybrid cloud based big data projects.
• Collect, manage, analyse and visualizing large sets of data to turn information into insights.
• Be passionate about working with cutting edge technologies.
• Develop prototypes using different open source tools for selected solutions.
• Help lead end-to-end execution of data engineering initiatives.
• Work with other teams to decide on needed infrastructure architecture and software design.
• Lead the design, implementation, and continuous delivery of pipelines
• Support data processing initiatives across batch and streaming datasets.
• Responsible for development using Scala, Python languages and Big Data Frameworks
• Identify, evaluate and implement cutting edge big data pipelines
• Deliver data engineering solutions to optimize both the cost and existing solution

Experience & Skills Required.
• Educated to Bachelor's Degree or higher in Computer Sciences or similar
• Have extensive Software Industry experience
• Have hands-on knowledge of all phases in building large-scale cloud based distributed data processing systems and applications.
• Be able to understand how a secure big data cloud environment is architected to gain real insights faster.
• Be comfortable with Apache Spark and NoSQL Implementation.
• Extensive working knowledge in different programming or scripting languages like Scala, Java, Linux, Shell, SQL, Python.
• Knowledge on Visualization and Data Science Tools advantageous.

.
If you fit the above job description, please contact Olivia Ross on 01256 314 660 or email her on oross@datatech.org.uk. Please be advised that we can only accept candidates who have the right to work in the UK.

Alternatively, you can refer a friend or colleague by taking part in our fantastic referral schemes! If you have a friend or colleague who would be interested in this role, please refer them to us. For each relevant candidate that you introduce to us (there is no limit) and we place, you will be entitled to our general gift/voucher scheme.",-1,Datatech Analytics,"London, England",-1,-1,-1,-1,-1,-1,-1,-1
Senior Data Engineer,-1,"As a WovenLight Senior Data Engineer you will support the development and deployment of analytics models at WovenLight portfolio companies. This work will include:
- Working with a range of portfolio company stakeholders to understand, assess and map the company's data landscape
- Collaborating with data science colleagues to map data fields to hypotheses in order to curate, wrangle, and prepare data for use in advanced analytical models
- Acquiring, ingesting, and processing data from multiple sources and systems
- Building modular pipelines to construct features and modelling tables

Alongside your technical capabilities, we are looking for someone with excellent communication skills and a collaborative nature - enabling you to interact successfully with a wide range of 'data' stakeholders within the portfolio company (e.g. IT, InfoSec, data source / system owners, CTO, CIO).

You must be passionate about learning and improving ways of working at WovenLight. To this end you will collaborate with our investment team and product engineering group (product managers, software engineers, designers) to build analytics product technology that can help us deliver impact faster and more efficiently.
The successful candidate should have the following attributes:
Passion and expertise in applying data and analytics to deliver commercial impact (4+ years)
Strong communication skills - able to explain complex analytical concepts to individuals from other fields
Expertise with core analytic technologies (Python, Scala, SQL, Java),
Ability to work with a range of database technologies including most of: distributed processing (e.g. Spark), traditional RDBMS (e.g. PostgreSQL), MPP (e.g. AWS Redshift), NoSQL (e.g. MongoDB) and ETL tooling
Expertise with cloud platforms such as AWS, Azure, Google Could Platform and Databricks
Our core team is based in London and plans to move into a central London office as soon as it is safe to do so. For the moment we are working remotely. For roles in our deployment team we are looking for candidates who are based in or near to London.

Interviews for this role will be conducted by phone and/or video-conference.

WovenLight is committed to equal employment opportunity regardless of sex, race, religion, ethnicity, nationality, disability, age, sexual orientation, gender identity or any other basis as protected by applicable law.",-1,WovenLight,"London, England",-1,-1,-1,-1,-1,-1,-1,-1
Data Software Engineer,-1,"DATA SOFTWARE ENGINEER

(Fixed term 3 yrs)

Inverness

£33,215 - £39,077 per annum REF: ANF/VAS/009/20

SRUC is unique in Scotland and one of the largest organisations of its kind in Europe. Our ambitious and exciting vision is to work at local, national and international levels, leading innovation and sustainable development in agriculture and rural sectors.

The Northern Faculty of Scotland’s Rural College (SRUC) conducts a wide range of research in applied agriculture, including soil and crop science, animal health and production, and aquaculture. Researchers have access to a wide range of data sets, including some from long-term, large-scale field experiments, the scope of which is unique in Scotland and rare in the UK.

We are now seeking a Database and Software Developer to participate in the integration and curation of these data sets to enhance their utility to SRUC students and researchers, as well as our scientific collaborators. This individual will work with a team of scientists and other developers to establish optimal approaches for handling, storing, maintaining, and accessing experiment data.

The major elements of the role are to:

Design and develop relational databases for data from ongoing research projects, animal health surveillance systems, and long-term agricultural experiments, and devise approaches to integrate data from a variety of sources
Develop custom software solutions for processing experimental data and populating relational databases
Integrate newly developed approaches for data processing into an existing system that makes use of automated data handling
Adapt, update, and further develop existing code, developed largely in C++ and SQL, to maintain and enhance existing data processing capabilities
Configure and integrate multiple applications, including server software and relational databases, to provide a seamless experience for researchers and other customers
Work with researchers to provide solutions for provision of data for analytical purposes as needed
Assist in the automation of updating data sources and data handling applications
Provide periodic assistance to other data management and research staff as needed
The post-holder will perform additional duties as directed from time to time by the Line Manager.

The post holder will have experience and/or training in data management, including data inspection, cleaning, quality assessment, and transformation. The post holder must have experience with relational database design, as well as SQL and related scripting languages. Experience and/or training in software development and object-oriented programming is also required. Experience with applied research agriculture, life science, or a related field is highly desirable.

The post holder will need to become familiar with established systems, software, and computer code, and must be willing to explore and support new and developing technologies relevant to the core mission of SRUC. The post holder must be able to work well in a multidisciplinary, dynamic, service- and team-oriented environment to promote applied interdisciplinary research SRUC.

This is a full time fixed term role for 3 years.

Further details on the requirements of this role can be found in the Job Particulars document which you must read before applying for this role. This is downloadable when you click the link below.",3.1,"Scottish Agricultural College
3.1","Inverness, Scotland",-1,1001 to 5000 Employees,-1,College / University,Colleges & Universities,Education,Less than $1 million (USD),-1
"Data Engineer, Data Warehouse",-1,"Location: Swindon Head Office
Salary: Competitive
Contract Type: Permanent
Ref: R002500185
Closing Date: 06 November 2020

Nationwide has recently launched a new data strategy which will transform the way the society thinks about, values and manages its data. As part of this new strategy the data & analytics community, and more specifically, the data solutions team has a number of exciting new roles to help deliver on the promises of reducing the number of legacy data stores, simplifying the architectural landscape and treating data as a valued asset.

This role will focus on delivering reporting and analytical solutions onto the society's enterprise data platform (Hadoop big data ecosystem and Teradata appliance) in support of both small Agile and larger scale project and user delivery.

Combining responsibilities for technical delivery alongside continuous improvement, innovation and automation, this exciting new role will provide the opportunity to work with some cutting-edge technologies.

What you’ll be doing

As a minimum requirement you’ll:

Have at least 1 years’ experience of data lake and/or data warehouse delivery
Experience of associated technologies, such as Python, R, Spark, HIVE, Scala
Experience in data warehouse delivery
Be a technical innovator with a curious mindset and a thirst for knowledge and be able to demonstrate a drive for continual improvement
Be a strong team player who enjoys and thrives on collaboration across colleagues and teams
Have excellent stakeholder management and influencing skills

It would be nice if you also had:

Experience of working in an Agile environment using SCRUM/Kanban
Hands-on experience of working within a DevOps environment with tooling such as Jenkins, Docker, Cucumber etc
About you

Reporting to a Snr Data Engineer, you will form a key part of a team of engineers responsible for the implementation of data solutions onto the new IM estate in support of our strategy objective of simplifying our data landscape and delivery of insight and innovation. Working directly with business and IT stakeholders you will help to deliver best practise, innovation and automation in the industrialisation of complex strategic IT initiatives alongside smaller user driven demand.

You will bring a high level of motivation and innovation to the team, always looking for ways to expand your own skill set and searching for ways to do things better, quicker & cheaper.

The extras you’ll get

Our people’s success isn’t based on how long they spend at their desk. While you’ll have contracted hours, we want to offer a flexible environment where possible. That might be working from home, logging on from other offices across the UK, or working part time or compressed hours.

We’ve let you know about the flexibility available for this role at the start of the advert. This means you can quickly decide if it suits how you’d like to work.

Remove above paragraphs if flexible working isn’t possible, for example operational areas.

There are all sorts of employee benefits available at Nationwide, including:

A personal pension – if you put in 7% of your salary, we’ll top up by a further 16%
Up to 2 days of paid volunteering a year
Life assurance worth 8x your salary
A great selection of additional benefits through our salary sacrifice scheme
Access to an annual performance related bonus
Access to training to help you develop and progress your career
25 days holiday
Why work at Nationwide

We’re a building society founded by ordinary people, our members, who came together to help each other get the most from their money, buy homes and save for their futures. For over 130 years, we’ve supported each other and our communities, and we’ve done the right thing for wider society too.

If you come to work here at Nationwide, you’ll be part of that. Part of something a bit different. And something really quite special.

What’s more, we have a strong ethic of care for each other and our members. We recognise that our employees feel most appreciated when their thoughts and values are respected and considered. We’re committed to creating a culture that recognises and truly values our individual differences and identities. So if you’d like to be a part of an inclusive workplace where you can be yourself, where your talents are nurtured, and you feel empowered to contribute, then please apply and help us in building society, nationwide.

What to do next

If this role is for you, please click the ‘Apply Now’ button. You’ll need to attach your up to date CV and answer a few quick questions for us.

We respond to everyone, and so we will be in contact shortly after the closing date to let you know the outcome of your application.

Data Engineer, Data Warehouse

Related Opportunities

You may also be interested in theses",3.9,"Nationwide Building Society
3.9","Swindon, Wiltshire, South West England, England",-1,10000+ Employees,1846,Company - Private,Banks & Credit Unions,Finance,$5 to $10 billion (USD),-1
Lead Systems Engineer (Intelligence and Security),-1,"Introduction:
Boeing Defence UK Ltd have an exciting opportunity for a Lead Systems Engineer within their Cyber, Intelligence and Analytics team. The role will involve working directly with a National Security customer to support and influence the shape of solutions that are of national importance. As a Systems Engineer you will be at the leading edge of our operational work, collaborating closely in multi-function teams to design and assure solutions to their technology, process or service based problems. This role can be based in either Cheltenham or Central London.
The Team:
As a successful candidate you will join an established Boeing team of like-minded peers, from all business Functions, who will support your development in your new role, to make sure you are successful and in your career with the Boeing Company. Though very much part of the Boeing team, you will also find yourself in the privileged position of working directly with our customer, at the core of an integrated programme or project team, addressing problems and opportunities of importance to the nation. Whether you are looking for rapid career growth, stability within a supportive team, or intellectual challenge, we will do our utmost to develop you to ensure you have the opportunity to enjoy a full career with the Boeing Company.
At Boeing we’re committed to rewarding excellence and fostering an inclusive environment where team members are seen, heard, valued, respected and fully engaged. This is particularly relevant in the Government Services Team which encapsulates all of the advantages of being a small agile Business Unit but with the security and opportunities of working for one of the world’s largest corporations.
The Role:
As a Principal Boeing Systems Engineer you will be working very closely with our National Security customer to help them design and assure solutions to complex problems and to deliver change while it is relevant to national issues. This will involve working directly with the operational practitioner, supported by a multi-function Boeing team of Business Analysts, Project Managers, Security and Data Analytic experts, to understand, define, model and capture the design for change and to manage the verification and validation of the final solution.
To achieve this the ideal candidate will expected to:
Own the engineering process across the full extent of the “Systems Engineering V” and drive excellence into all stages from Requirements elicitation and capture to solution validation
Work confidently in the technology space with Agile practices and beside Business Analysts as they define the required user experiences (UX), the writing of user stories and the sketching of wireframes.
Undertake stakeholder engagement alone and to own relationships with the Business Client
Build relationships with customers and other members of the team and influence the direction of projects to ensure the desired aims are achieved and underpinned by Engineering Excellence
Work collaboratively with third parties to deliver effective change while managing changing user needs within a project life cycle
Provide mentoring and guidance to junior engineers within the programme, project or wider team
Preferred Qualifications:
Experience in Model Based Systems Engineering
Degree in Engineering, Software or wider STEM discipline OR significant experience working in Engineering Design supported by a recognised qualification
Problem solving skills
Excellent interpersonal skills
Experience in Model Based Systems Engineering (such as MODAF/Archimate CCISSP)
Knowledge of Agile Methodologies, Scrum Management, Epic and Sprint, MPV Management
Experience in Cyber, Security, Policing, Commercial Cyber Solutions
Work Authorisation: This requisition is for a locally hired position in the UK. Candidates must have current legal authorisation to work immediately in the United Kingdom. Boeing will not attempt to obtain Immigration and labour sponsorship for any applicants. Benefits and pay are determined at the local level and are not part of Boeing U.S. based payroll.
Security Clearance: This position requires the ability to obtain a UK Security Clearance for which the UK Government requires UK citizenship
Visa Status and Relocation: This requisition is for a locally hired position in the UK. Relocation benefits are not available. Successful candidates must have existing / ability to obtain legal authorisation to work in the UK for continued employment.",3.7,"BOEING
3.7","Bristol, England",-1,10000+ Employees,1916,Company - Public,Aerospace & Defense,Aerospace & Defense,$10+ billion (USD),-1
Data Software Engineer,-1,"• Develop, implement and maintain software solutions that enable business operations to realise company goals and objectives.
• Analyse, design, code, debug, test and support software application systems.
• Provide mentoring and guidance to less experienced peers.
• Assign work tasks and review the work products of others.
• Assist the department manager/director in developing processes and standards.

Experience requirements and skills:
• Excellent analytical, problem solving and organisational skills.
• Practiced in the theoretical and practical applications of software engineering methods and techniques.
• Experience of developing solutions in C# and SQL Server using Visual Studio
• Proficient in SQL querying.
• Knowledge of source code change management and related tools.
• Knowledge of using agile software development principles.
• Required knowledge and skills would typically be acquired through a bachelor’s degree in a numerate subject or equivalent experience.



• Some exposure to finance (particularly insurance) a bonus.
• Experience of building financial models desirable.
• Technology based qualifications advantageous.


• Required knowledge and skills would typically be acquired through a bachelor’s degree in Computer Science, a related field or equivalent experience.
• Ideally some exposure to insurance (particularly Lloyd’s and London Market)

• Required knowledge and skills would typically be acquired through a bachelor’s degree in a numerate subject or equivalent experience.
• Some exposure to finance (particularly insurance) a bonus.
• Experience of building financial models desirable.
• Technology based qualifications advantageous.
• 3 or more years of professional experience.",3.6,"Arch
3.6","Manchester, England",-1,1001 to 5000 Employees,2000,Company - Public,Insurance Carriers,Insurance,$10+ billion (USD),-1
Cloud Data Engineer,-1,"Cloud Data Engineer

Location: London

Salary: £45,000- £55,000

Career Level: (Accenture will be recruiting at the following levels: Snr Analyst, Consultant)

Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. With our thought leadership and culture of innovation, we apply industry expertise, diverse skill sets and next-generation technology to each business challenge.

We believe in inclusion and diversity and supporting the whole person. Our core values comprise of Stewardship, Best People, Client Value Creation, One Global Network, Respect for the Individual and Integrity. Year after year, Accenture is recognized worldwide not just for business performance but for inclusion and diversity too.

Across the globe, one thing is universally true of the people of Accenture: We care deeply about what we do and the impact we have with our clients and with the communities in which we work and live. It is personal to all of us. Julie Sweet, Accenture CEO

As a team:
We have exciting opportunities for a Cloud Data Engineer to join our Data & AI practice, part of larger Cloud First Group. We deliver scalable, business critical and end-to-end solutions for our client - from data strategy/governance to Core Engineering, enabling them to transform and work in Cloud Technologies.

You'll learn, grow and advance in an innovative culture that thrives on shared success, diverse ways of thinking and enables boundaryless opportunities that can drive your career in new and exciting ways

If youre looking for a challenging career working in a vibrant environment with access to training and a global network of experts, this could be the role for you. As part of our global team, you'll be working with cutting-edge technologies and will have the opportunity to develop a wide range of new skills on the job.


In our team you will learn:
How to grow your skills working on challenging and innovative solutions
Work on new technologies with demanding clients and grow your expertise
Work in highly skilled teams advising and supporting our clients through the data and technology revolution
As a Cloud Data Engineer, you will:
Work with client teams to design and implement modern, scalable data solutions using a range of new and emerging technologies
Work with Agile and DevOps techniques and implementation approaches in the delivery
Using good communication skills to understand and deliver client requirements
Bring your experience and ideas to innovative engineering, design and strategy
Mentor and upskill fellow group members
Contribute to our internal networks and special interest groups
We are looking for experience in the following skills:
Experience in either one or more major cloud (AWS, GCP, Azure) platform architecture, developing data engineering pipelines.
Experience in Spark (Scala/Python/Java) and Kafka.
Experience working in a client-facing / consulting environment to build trusted relationships with client stakeholders and act as a trusted adviser.
Excellent communication (written and oral) and interpersonal skills.
Ability to apply analytical and creative thought process.
Proven success in contributing in a multi-location team-oriented environment.
Proven ability in delivering high-quality deliverables to tight timescales.
Set yourself apart:


Experience delivering projects within an agile environment.
Experience in MDM, Metadata Management, Data Quality and Data Lineage tools.
E2E Data Engineering and Lifecycle (including non-functional requirements and operations) management.
Regulatory and Compliance work in Data Management
E2E Data Architecture and Lifecycle (including non-functional requirements and operations) management.
E2E Solution Design skills - Prototyping, Usability testing and data visualization literacy.
Experience with SQL and NoSQL modern data stores
Whats in it for you

At Accenture in addition to a competitive basic salary, you will also have an extensive benefits package which includes 30 days vacation per year, gym subsidy, private medical insurance and 3 extra days leave per year for charitable work of your choice!


Flexibility and mobility are required to deliver this role as there will be requirements to spend time onsite with our clients and partners to enable delivery of the first-class services we are known for.


About Accenture


Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. We combine unmatched experience and specialized capabilities across more than 40 industries powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. With 509,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises. Visit us at www.accenture.com

Accenture is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, citizenship, marital, domestic or civil partnership status, sexual orientation, or gender identity, or any other basis as protected by applicable law.

Closing Date for Applications 31/12/2020

Accenture reserves the right to close the role prior to this date should a suitable applicant be found.",3.9,"Accenture
3.9",United Kingdom,-1,10000+ Employees,1989,Company - Public,Consulting,Business Services,$10+ billion (USD),-1
Data Engineer - Python - AWS - Permanent,-1,"Data Engineer London
Permanent

My client is one of the worlds fastest pet supplement businesses and they are looking to hire an experienced Data Engineer who has a passion for working with mass amounts marketing data. The company are looking for passionate forward thinking Data Engineer who want to work on a rapidly evolving product that has exciting growth plans.
You will have;
Role:
A solid understanding of business strategy and infrastructure
Identify, design, and implement internal process improvements with a focus on automation
Re-design and build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics
Work with all internal teams to ensure their Data needs are met
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader
Skills:
3-5 years hands on Data Engineering experience (Modelling)
Degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.
Strong SQL database knowledge
Development background in Python
Experience working in the AWS cloud space using tools such as S3 is essential.
Great knowledge of data flows (Pipelining and Streaming)
This is a great opportunity to join a rapidly growing business that will allow you build from the ground up.

The client are looking to interview next week. If you are interested email me a copy of your latest CV (Sam.jeffreys@opusrs.com) Or Apply",3.2,"OPUS
3.2","London, England",-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer - Demand Analytics,-1,"Why apply for this role?

It’s an exciting time to join the Demand Analytics Squad. You’ll be part of a specialist team of data engineers, data and commercial analysts and data scientist supporting the digital transformation agenda within retail interactions.

Together, you’ll support the development of a holistic customer interaction data model that can be used for monitoring, measuring and predicting customer behaviour. You’ll also focus on digital adoption and the effectiveness of key initiatives in the digital transformation programme.

And it’s not just the variety of this role. You’ll be part of a great team too.

What you’ll be doing
Collaborating with other areas to communicate an accurate, single view – based on the available data and methodologies
Supporting other members of the Demand Analytics squad to deliver quantity and quality output and strategic objectives
Identifying and supporting cross functional initiatives to drive forward Demand Analytics strategy
Facilitating better customer relationships and exceeding client’s expectations
Supporting others to actively manage new business opportunities and improve service quality and processes
What we’re looking for
Expert knowledge of SAS, Oracle, MS SQL Server and a detailed understanding of querying and manipulating data using SQL
Experience of Big Data, Hadoop, Hive and Impala to make use of new data streams and sources
Must be a problem solver with the ability to think outside the box
Excellent analytical and numerical skills with proven past experience in an analytical function
Good communication skills (both verbal and written) with the ability to translate difficult technical ideas simple understandable concepts
Experience of the use of a programming language for data processing would be ideal ( VBA/VB Script, R, Python, Scala), as well as experience of extracting data from API’s
What else you need to know

Given the recent impact of the Coronavirus outbreak we will be conducting all interviews via telephone or video-conference where possible.

This is a 12 month Fixed-Term contract which can be based in either Carlton Park or Milton Keynes.

How we’ll reward you

As well as a competitive salary, you’ll enjoy a benefits package that you can tailor to your needs.
Eligible for a discretionary performance-related annual bonus
Pension with generous contributions of up to 12.5% from Santander, depending on your own contribution and length of employment with us
30 days holiday plus bank holidays, with the option to purchase up to 5 contractual days per year
£6,000 car allowance per year
Company funded individual private medical insurance
Voluntary healthcare benefits at discounted rates such as private medical insurance for your family, dental insurance, healthcare cash plan and health assessments
Benefits supporting you and your family, such as death-in-service benefit, income protection, and voluntary life assurance and critical illness cover
Share in Santander’s success by investing in our Sharesave and Partnership shares plans
contract roles, your salary, bonus (where eligible) and certain benefits will be prorated to reflect your working hours / contract duration.
For more information about our wide range of benefits and family friendly policies visit our website.

Why Santander?

At Santander, with only a small action or a simple idea, you can achieve great things. You can improve the daily life of more than 140 million people. You can collaborate with a friendly team of more than 200,000 employees.

It doesn’t stop there. You’ll also be part of a vibrant organisation that’s been reinventing itself for more than 160 years. One that invests millions of pounds in training its people every year. One that helps more than 2 million people every year with social programmes.

We call it #TheSantanderEffect.

Equal Opportunities

Santander are an equal opportunities employer. When we talk about diversity, we don’t just want to pay lip service. Our customers come from a wide range of backgrounds, and so do our people. It’s important to us that we create an inclusive culture where everyone counts, and we particularly welcome applications from different underrepresented groups.

For more information on our commitment to equal opportunities, please visit our diversity page here.

What to do next

If this sounds like a role you’re interested in, then please apply on the link below.

Application closing date: 30th October 2020

Due to high volume of applications we may need to close this role earlier than the advertised date, so recommend submitting an application as soon as possible.",3.7,"Santander
3.7",East Midlands,-1,10000+ Employees,1856,Company - Private,Banks & Credit Unions,Finance,$10+ billion (USD),-1
Data Warehouse Engineer,-1,"Data Warehouse Engineer

London - Remote - Flexible

£75,000

This gaming company are moving their operations to London to develop a cutting edge Data Platform using Azure, PowerBI and Google Analytics. They are looking for an experienced developer to be the catalyst of their data engineering capability in London. In this role, you lead the evolution of the Azure SQL/Synapse based cloud data warehouse to embrace new technologies and deliver real business impact to key stakeholders in the business.

Requirements

To qualify for this Data Warehouse Engineer role role, you will require:

Excellent Programming skills in SQL
Experience with Azure (Data Factory, Data Lakes, Analysis Services)
Data Scripting experience with Python or R
Stakeholder Management Expertise
SQL Database Engineering/management
Deep understanding of OLAP and data warehousing concepts

Salary and Benefits

A successful candidate will receive:

A salary of up to £75,000
The opportunity to lead the strategic growth of a cutting edge data platform

HOW TO APPLY:

Please register your interest to this Data Warehouse Engineer role by applying via this website. For more information on this role or other roles in the Business Intelligence market, reach out to Tom Brammer at Harnham.

Please note that our client is currently running a fully remote interview process, and able to on-board and hire remotely as well.",4.1,"Harnham
4.1","London, England",-1,51 to 200 Employees,2006,Company - Private,Staffing & Outsourcing,Business Services,$25 to $50 million (USD),-1
"Azure Big data Engineer - Azure databricks, Azure Stack",-1,"Big data Engineer - Azure databricks

Key Skills: Azure Databricks experience is required. At least 3 years production experience

Preference: Microsoft SQL Server Integration Services, SQL Server ODS/Raw, SQL Server DWH, SQL Server Analysis Services.

They are keen on someone who has worked historically within the DWH/ETL/SQL space (Someone used to working in traditional data).

*Knowledge in big data cloud architectures with proven experience working with Microsoft Azure big data technologies e.g. data lakes, data factory etc.

*Experience of several programming languages such as Python, Scala or Java

*Experience in data warehousing, within a data platform

*Strong background in data processing, software engineering design and data modelling concepts

*Good understanding of application life cycle management ideally using TFS or Visual Studio Online

*Strong communication skills to effectively partner with data scientists and engineering stakeholders

*Very good experience in gathering and analysing business requirements and translating them into solutions

*A track record of delivering solutions against challenging timescales with quality

*Ability to pick up new languages and technology quickly

GCS Computer Recruitment Services is acting as an Employment Business in relation to this vacancy.",4.2,"GCS Recruitment Specialists Ltd
4.2","Newport, Newport, Wales",-1,51 to 200 Employees,1991,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Data Engineer (Consulting),-1,"The Applied Intelligence business of BAE Systems delivers solutions which help to protect and enhance the connected world. Our solutions combine large scale data exploitation, ‘intelligencegrade’ security and complex services and solutions integration. We operate in four key domains of expertise: Cyber Security, Financial Crime, Communications Intelligence and Digital Transformation. Today, we have staff across the UK and Europe, the Americas, Asia Pacific and the Middle East.

Our people apply intelligence to protect and enhance national and organisational assets so that they can grow and prosper – from improving the health and efficiency of leading corporations to protecting critical infrastructures, safeguarding vulnerable people and catching criminals. Together, we make the world a safer place. Make everyday matter.

About the Role:

To work as part of a client side team that defines and resolves complex data collection and data integration issues ( i.e. ETL - Extract, Transform and Load design and development ) to make data and information available to decision makers, internal and external interfaces and real time decision procedures with operation systems and delivery channels.

The Consultant Data Engineer specialises in helping clients within large scale projects and programmes to help shape specific solutions. However, they will also need to develop a holistic view of the organisation.

Consultant Data Engineers will often work closely with Enterprise Data Architects.

Key Responsibilities:
Designs, develops, tests and supports data collection, data integration and ETL applications to make information and data available to key client stakeholders and technical interfaces.
Understands where the need for tight data controls arises to ensure seamless data flows around the organisation and to minimise future change.
Models data requirements, data sources and data flows to bring order and structure to programmes of work.
Defines how and where data is created, mastered and destroyed to ensure proper control over the lifecycle of corporate data assets.
Understands how to add value to data – for example through data cleansing.
Understands categories of products (and individual examples) that can be used to collect, integrate, store, visualise and govern data and metadata.
Defines metadata to provide searchability and governance (including Records Management) for unstructured data.
Designs ETL frameworks and standards for specific ETL programmes and projects.
Identifies the required toolset (development and testing) for specific ETL programmes and projects.
Designs and implements the hardware environment required by ETL programmes and projects.
Develops and tests the re-usable components of an ETL framework for specific ETL programmes and projects.
Undertakes the role of lead developer, ensuring the quality and assurance of all ETL code and testing.
Can undertake the role of delivery lead ensuring that project timescales and quality are met.
Ensures that the configuration and release management procedures are applied for specific ETL programmes and projects.
Maintains and applies up to date, specialist knowledge of database concepts (including unstructured, NoSQL and ”big data” platforms), object and data modelling techniques.
Builds a detailed knowledge of the full range of database and data persistence architectures, software and facilities available (e.g. streams).
Takes account of industry specific requirements (e.g. geocoding, for geographic information systems).
Can utilise a number of ETL tools including Informatica, Ab Initio, Oracle ODI and a number of the Big Data / Open Source Applications
Understands data-related performance issues.
Understands data services, data security issues, “privacy by design” and Information Assurance principles.
Understands master data management patterns and can advise on the right choices for each client.
Defines metadata structures and population techniques that can be used with Enterprise Content Managment solutions in conjuction with organisational policies.
What we are looking for:
ETL Tool capabilities
Ab Initio, Informatica and Oracle ODI
Big Data / Open Source ETL Tools
Database Management Systems
Application Testing Tools
Configuration Management and Version Control Tools
Testing strategies and tools
Infrastructure design
About BAE Systems Applied Intelligence

We use our intelligence-led insights to help defend Governments, Nations and Societies from cyber-attacks and financial crime. Our customers depend on our evolving capabilities to help them safely grow their organisations. Our unprecedented access to threat intelligence, world-leading analysts and market-leading technology means we can help them to adapt, evolve and stay ahead of the criminals.

Division overview: Capabilities

At BAE Systems Applied Intelligence, we pride ourselves in being a leader in the cyber defence industry, and Capabilities is the engine that keeps the business moving forward. It is the largest area of Applied Intelligence, containing our Engineering, Consulting and Project Management teams that design and implement the defence solutions and digital transformation projects that make us a globally recognised brand in both the public and private sector.

As a member of the Capabilities team, you will be creating and managing the solutions that earn us our place in an ever changing digital world. We all have a role to play in defending our clients, and this is yours.

Diversity and inclusion are integral to the success of BAE Systems Applied Intelligence. We are proud to have an organisational culture where employees with varying perspectives, skills, life experiences and backgrounds – the best and brightest minds – can work together to achieve excellence and realise individual and organisational potential. We also welcome discussions about flexible working.

About BAE Systems Applied Intelligence

We use our intelligence-led insights to help defend Governments, Nations and Societies from cyber-attacks and financial crime. Our customers depend on our evolving capabilities to help them safely grow their organisations. Our unprecedented access to threat intelligence, world-leading analysts and market-leading technology means we can help them to adapt, evolve and stay ahead of the criminals.

Division overview: Capabilities

At BAE Systems Applied Intelligence, we pride ourselves in being a leader in the cyber defence industry, and Capabilities is the engine that keeps the business moving forward. It is the largest area of Applied Intelligence, containing our Engineering, Consulting and Project Management teams that design and implement the defence solutions and digital transformation projects that make us a globally recognised brand in both the public and private sector.

As a member of the Capabilities team, you will be creating and managing the solutions that earn us our place in an ever changing digital world. We all have a role to play in defending our clients, and this is yours.

Diversity and inclusion are integral to the success of BAE Systems Applied Intelligence. We are proud to have an organisational culture where employees with varying perspectives, skills, life experiences and backgrounds – the best and brightest minds – can work together to achieve excellence and realise individual and organisational potential. We also welcome discussions about flexible working.",3.3,"BAE Systems Applied Intelligence
3.3","London, England",-1,1001 to 5000 Employees,1971,Subsidiary or Business Segment,Enterprise Software & Network Solutions,Information Technology,$500 million to $1 billion (USD),-1
Data Engineer 3 months 25 per hour INSIDE IR35 Remote,-1,"Data Engineer 3 months 25 per hour INSIDE IR35 Remote

Parity Group are delighted to partner with our client, a prestigious public sector organisation, who is looking to recruit a Data Engineer on an initial 6-month contract basis, this role will be working remotely.

You will receive a competitive hourly rate of 25 and the contract will see you INSIDE IR35.

What will you be doing?

Qualifying and assessing the quality of data
Understanding user use cases and workflow to understand potential development value
Transforming the Data and Metadata and publishing
Develop ways to enhance the uses search for data
Enhance the users understanding of the data through visualisation techniques
Investigate data auto-ingestion solutions

I would love to hear from you if you have relevant experience in a data engineering role within a large organisation and skills including:

A passion for data engineering, possess strong development skills and have the enthusiasm for building data pipelines with supporting infrastructure for reliability and resilience.
DevOps experience is core to the role coupled with data analysis and basic DBA-type skills.
An interest in finding new and innovative ways that technology can be used to make data meaningful for everyone.
Ability to communicate technical concepts to non-technical people.
Stakeholder communication and management; including influencing, facilitation & negotiation across organisational, technical and political boundaries.
Bring a clear focus on continuous improvement, proposing changes in procedures and processes.

If this sounds like the role for you then do not hesitate to get in touch with me, Kirsty Dallas, for more information or simply click on the apply button.

Parity - Better Decisions : Better People

Parity Group plc acts in the capacity of an Employment Agency when providing contract recruitment services.

We welcome applications from all sections of society and applicants will be considered on the basis of their suitability for the position

At Parity, we are committed to protecting your privacy, we will process and hold your CV and use the information you have provided lawfully and in accordance with our Terms and Conditions and our Privacy Policy.

J301_160226266239748",4.4,"Parity Professionals
4.4","Newport, Newport, Wales",-1,51 to 200 Employees,1971,Company - Public,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
"Data Scientist / BI Engineer - Cirencester, UK",-1,"Corin, an orthopaedic medical device business, is currently looking for a Data Scientist / BI Engineer to support our Digital Transformation across all business functions with insights gained from analysing company data and delivery of data models and tools. This is a key role to establish our Digital Centre of Excellence supporting both our Digital Health offering and our business process digitalization.

You will based in our global head office in Love Lane, Cirencester, Gloucestershire reporting into the Group IT Director and working alongside the Chief Transformation Officer.

The ideal Data Scientist / Business Intelligence Engineer will be adept at using large data sets to find opportunities for product and process optimization and building and implementing models to test the effectiveness of different courses of action.

You must have a proven experience in driving business results with your data-based insights using data mining, data tools and data analysis, as well as using and creating algorithms and developing and running simulations.

You must be comfortable working with a wide range of stakeholders and functional teams and have a genuine passion for discovering solutions hidden in data sets. You must have a strong drive, be a self-starter and be ready to work pragmatically towards business deliverables.

Corin provides a progressive and dynamic work environment where you can take control of your career, be accountable and drive positive change. Corin is going through an exciting period of growth with our investment partner Permira committed to driving global technological / robotic advancements in the implant of hip and knee surgery which in turn delivers better patient and surgical outcomes.

The key responsibilities of the Data Scientist / BI Engineer are to:

Establish and lead Data Science at Corin:

Work with the management team and key stakeholders throughout Corin to identify opportunities for leveraging company data to drive value creation and effective decision making.
Make a difference to our business, our Customers, and our Patients, by solving real life problems and delivering insights to improve health outcomes.
Be key in developing and driving a data hub of digital graduates for future talent succession growth.

Deliver expert solutions, working alongside our CIO, Data engineers and architects:

Build and maintain reference datasets and pipelines
Mine and analyse data from company databases. Develop custom data models, time-series forecasting and predictive algorithms to apply to data sets.
Generate analytical insights and develop solutions to drive optimization and improvement of business strategies, commercial excellence, operational efficiency, and digital product development (i.e. Clinical Insights / Digital Health solutions)

Requirements

The ideal Data Scientist / BI Engineer will have;

A Degree, Masters or PHD in Computer Science, Data Science or Analytics, Engineering or Physics, Mathematics or Statistics and / or operational research
Knowledge and experience in statistical, machine learning, modelling and data mining techniques: Multi-variate analysis (MVA), GLM/Regression, Clustering, Random Forest, Boosting, Trees, text mining, social network analysis, neural networks, etc.
Experience querying databases and using statistical computer languages: R, Python, SQL, etc., to manipulate data and draw insights from large data sets.
Experience working and creating data architectures ideally in MS SQL server.
Experience of MS Azure platform tools such as Datafactory, Databricks, synapse Analytics would be beneficial
Experience visualizing/presenting data for stakeholders using: Power BI, Dundas BI, Tableau, etc.
Strong coding knowledge and adept at programming with several languages: C#, .net framework C, C++, Java, JavaScript etc.
Clear experience in building and managing roadmaps, balancing sprint vs. ad/hoc effort. Demonstrated knowledge of the data lifecycle, including experience with data modelling and data quality
Ability to share solutions and ideas with a broad scope of stakeholders across business functions and lead by influence.
A drive to learn and master new technologies and techniques.
Strong problem-solving skills with an emphasis on product development.
Excellent written and verbal communication skills for coordinating across teams.
Preferably, time served experience with a clinical, healthcare, orthopaedic, or pharmaceutical business, manipulating their data sets and building statistical models.

Benefits

You will receive a competitive salary and annual bonus as well as;

25 days holiday plus bank holidays.
Excellent pension – up to 9.7% provided by Corin when you contribute 4%
Life assurance (6x basic salary).
Private medical insurance with BUPA for you and your family.
Subsidised canteen and gym membership.
Free car parking - close to Swindon, A419, Cheltenham, Gloucester and Stroud.
Friendly and collaborative working environment",-1,Corin,"Cirencester, England",-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Senior Software Engineer (Data),-1,"About DueDil

DueDil provides real-time insights on every company, helping financial services providers to give small businesses the products they need to thrive.

Reliance on manual checks makes it harder for SMEs to open an account, take out a loan or get insurance cover. It also makes it harder for the companies providing those products to carry out ongoing Know Your Business checks.

DueDil's KYB for Life platform transforms how providers work with SMEs. We analyse billions of data points on millions of companies to provide unique insights via our API.

In the last three years, DueDil has grown rapidly in the UK and Ireland and we're now expanding into mainland Europe. We have over 400 clients across the Financial Services, Insurance and Fintech sectors, including Santander, Tide and Metro Bank.

Our Values

We're driven by three core values, the characteristics that define the members of our team are grit, authenticity, and team spirit. These values factor into the way we hire, promote, and reward every member of our team. Put simply, we're looking for ambitious people who take ownership and responsibility - if this sounds like you then you're in the right place! You can read more about our values and how they impact our culture day to day here: https://www.duedil.com/about-duedil/who-we-are

The Role

Critical to achieving DueDil's vision is our ability to combine multiple disparate data sources from different providers into a unified view of companies and the people who run them. This requires us to develop web crawlers, automated matching algorithms, machine learning models and complex ETL processes to tie all these components together.

As a Senior Software Engineer, you'll help enhance and expand our data processing and distributed systems toolsets to support our international expansion effort, while maintaining quality and reliability of our existing data products and services. This will mean dealing with challenges such as order of magnitude increase in data volumes, assessing quality of data from multiple suppliers and building pipelines and services using modern cloud tools to match and extract valuable insight from these datasets. We value DevOps culture so you will take full ownership of your solutions from prototyping all the way to production, and you'll do that working in a team of experienced Software Engineers and Data Scientists building next generation tools and transforming the Fintech industry.

We are looking for
Proven track record leading complex ETL and Data Infrastructure projects, as well as designing and building data intensive applications and services in both batch and streaming environments
Demonstrable experience working with high volume heterogeneous data with distributed systems such as Hadoop or Spark
At least 5 years commercial experience with one or more JVM-based languages. Python experience is a big plus.
Strong understanding of data structures and algorithms
Familiarity with Unix systems, common command line tools e.g. grep, awk, source control tools e.g. git and containerisation tools such as Docker
Experience working with cloud environments such as GCP or AWS a big plus
Our Tech Stack
Infrastructure: GCP (BigQuery, Dataproc, Google Kubernetes Engine)
Languages: Python, Scala, Kotlin
Databases: PostgreSQL, Elasticsearch
Other: Kafka, Spark, Airflow, Tinkerpop
What DueDil can offer you
The opportunity to work for a dynamic disruptor in the data market. We challenge our staff to be innovative and encourage outside-the-box-thinking.
24 days holiday per year (excluding bank and public holidays) plus Christmas and New Year's break.
Bike to work scheme
Pension scheme
Private healthcare
Optional childcare vouchers
Dedicated '10% time' for product and engineering teams to work on experimental projects or pursue learning opportunities of your choosing.
Generous allowance of professional development platform (Learnerbly)
MacBooks as standard, but we're happy to get you whatever equipment you need to get your job done.
Free lunch Fridays and regular beer o'clock. Friday lunch is one of the perks we enjoy the most, and take very seriously!
Regular team and company events in and out of the office
Super cool office based in Moorgate.
Please note, while we are going through the COVID-19 pandemic, the whole company is working from home and we are doing our best to help our employees get all the equipment needed to make working from home as comfortable as possible. On top of that, we are able to onboard new employees remotely during this time.

All successful applicants will be subject to enhanced background checks.",4.5,"DueDil
4.5","London, England",-1,51 to 200 Employees,2011,Company - Private,Enterprise Software & Network Solutions,Information Technology,$1 to $5 million (USD),-1
Data Engineer - Demand Analytics,-1,"Why apply for this role?

It’s an exciting time to join the Demand Analytics Squad. You’ll be part of a specialist team of data engineers, data and commercial analysts and data scientist supporting the digital transformation agenda within retail interactions.

Together, you’ll support the development of a holistic customer interaction data model that can be used for monitoring, measuring and predicting customer behaviour. You’ll also focus on digital adoption and the effectiveness of key initiatives in the digital transformation programme.

And it’s not just the variety of this role. You’ll be part of a great team too.

What you’ll be doing
Collaborating with other areas to communicate an accurate, single view – based on the available data and methodologies
Supporting other members of the Demand Analytics squad to deliver quantity and quality output and strategic objectives
Identifying and supporting cross functional initiatives to drive forward Demand Analytics strategy
Facilitating better customer relationships and exceeding client’s expectations
Supporting others to actively manage new business opportunities and improve service quality and processes
What we’re looking for
Expert knowledge of SAS, Oracle, MS SQL Server and a detailed understanding of querying and manipulating data using SQL
Experience of Big Data, Hadoop, Hive and Impala to make use of new data streams and sources
Must be a problem solver with the ability to think outside the box
Excellent analytical and numerical skills with proven past experience in an analytical function
Good communication skills (both verbal and written) with the ability to translate difficult technical ideas simple understandable concepts
Experience of the use of a programming language for data processing would be ideal ( VBA/VB Script, R, Python, Scala), as well as experience of extracting data from API’s
What else you need to know

Given the recent impact of the Coronavirus outbreak we will be conducting all interviews via telephone or video-conference where possible.

This is a 12 month Fixed-Term contract which can be based in either Carlton Park or Milton Keynes.

How we’ll reward you

As well as a competitive salary, you’ll enjoy a benefits package that you can tailor to your needs.
Eligible for a discretionary performance-related annual bonus
Pension with generous contributions of up to 12.5% from Santander, depending on your own contribution and length of employment with us
30 days holiday plus bank holidays, with the option to purchase up to 5 contractual days per year
£6,000 car allowance per year
Company funded individual private medical insurance
Voluntary healthcare benefits at discounted rates such as private medical insurance for your family, dental insurance, healthcare cash plan and health assessments
Benefits supporting you and your family, such as death-in-service benefit, income protection, and voluntary life assurance and critical illness cover
Share in Santander’s success by investing in our Sharesave and Partnership shares plans
contract roles, your salary, bonus (where eligible) and certain benefits will be prorated to reflect your working hours / contract duration.
For more information about our wide range of benefits and family friendly policies visit our website.

Why Santander?

At Santander, with only a small action or a simple idea, you can achieve great things. You can improve the daily life of more than 140 million people. You can collaborate with a friendly team of more than 200,000 employees.

It doesn’t stop there. You’ll also be part of a vibrant organisation that’s been reinventing itself for more than 160 years. One that invests millions of pounds in training its people every year. One that helps more than 2 million people every year with social programmes.

We call it #TheSantanderEffect.

Equal Opportunities

Santander are an equal opportunities employer. When we talk about diversity, we don’t just want to pay lip service. Our customers come from a wide range of backgrounds, and so do our people. It’s important to us that we create an inclusive culture where everyone counts, and we particularly welcome applications from different underrepresented groups.

For more information on our commitment to equal opportunities, please visit our diversity page here.

What to do next

If this sounds like a role you’re interested in, then please apply on the link below.

Application closing date: 30th October 2020

Due to high volume of applications we may need to close this role earlier than the advertised date, so recommend submitting an application as soon as possible.",3.7,"Santander
3.7",East Midlands,-1,10000+ Employees,1856,Company - Private,Banks & Credit Unions,Finance,$10+ billion (USD),-1
"Azure Big data Engineer - Azure databricks, Azure Stack",-1,"Big data Engineer - Azure databricks

Key Skills: Azure Databricks experience is required. At least 3 years production experience

Preference: Microsoft SQL Server Integration Services, SQL Server ODS/Raw, SQL Server DWH, SQL Server Analysis Services.

They are keen on someone who has worked historically within the DWH/ETL/SQL space (Someone used to working in traditional data).

*Knowledge in big data cloud architectures with proven experience working with Microsoft Azure big data technologies e.g. data lakes, data factory etc.

*Experience of several programming languages such as Python, Scala or Java

*Experience in data warehousing, within a data platform

*Strong background in data processing, software engineering design and data modelling concepts

*Good understanding of application life cycle management ideally using TFS or Visual Studio Online

*Strong communication skills to effectively partner with data scientists and engineering stakeholders

*Very good experience in gathering and analysing business requirements and translating them into solutions

*A track record of delivering solutions against challenging timescales with quality

*Ability to pick up new languages and technology quickly

GCS Computer Recruitment Services is acting as an Employment Business in relation to this vacancy.",4.2,"GCS Recruitment Specialists Ltd
4.2","Newport, Newport, Wales",-1,51 to 200 Employees,1991,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Data Engineer (Consulting),-1,"The Applied Intelligence business of BAE Systems delivers solutions which help to protect and enhance the connected world. Our solutions combine large scale data exploitation, ‘intelligencegrade’ security and complex services and solutions integration. We operate in four key domains of expertise: Cyber Security, Financial Crime, Communications Intelligence and Digital Transformation. Today, we have staff across the UK and Europe, the Americas, Asia Pacific and the Middle East.

Our people apply intelligence to protect and enhance national and organisational assets so that they can grow and prosper – from improving the health and efficiency of leading corporations to protecting critical infrastructures, safeguarding vulnerable people and catching criminals. Together, we make the world a safer place. Make everyday matter.

About the Role:

To work as part of a client side team that defines and resolves complex data collection and data integration issues ( i.e. ETL - Extract, Transform and Load design and development ) to make data and information available to decision makers, internal and external interfaces and real time decision procedures with operation systems and delivery channels.

The Consultant Data Engineer specialises in helping clients within large scale projects and programmes to help shape specific solutions. However, they will also need to develop a holistic view of the organisation.

Consultant Data Engineers will often work closely with Enterprise Data Architects.

Key Responsibilities:
Designs, develops, tests and supports data collection, data integration and ETL applications to make information and data available to key client stakeholders and technical interfaces.
Understands where the need for tight data controls arises to ensure seamless data flows around the organisation and to minimise future change.
Models data requirements, data sources and data flows to bring order and structure to programmes of work.
Defines how and where data is created, mastered and destroyed to ensure proper control over the lifecycle of corporate data assets.
Understands how to add value to data – for example through data cleansing.
Understands categories of products (and individual examples) that can be used to collect, integrate, store, visualise and govern data and metadata.
Defines metadata to provide searchability and governance (including Records Management) for unstructured data.
Designs ETL frameworks and standards for specific ETL programmes and projects.
Identifies the required toolset (development and testing) for specific ETL programmes and projects.
Designs and implements the hardware environment required by ETL programmes and projects.
Develops and tests the re-usable components of an ETL framework for specific ETL programmes and projects.
Undertakes the role of lead developer, ensuring the quality and assurance of all ETL code and testing.
Can undertake the role of delivery lead ensuring that project timescales and quality are met.
Ensures that the configuration and release management procedures are applied for specific ETL programmes and projects.
Maintains and applies up to date, specialist knowledge of database concepts (including unstructured, NoSQL and ”big data” platforms), object and data modelling techniques.
Builds a detailed knowledge of the full range of database and data persistence architectures, software and facilities available (e.g. streams).
Takes account of industry specific requirements (e.g. geocoding, for geographic information systems).
Can utilise a number of ETL tools including Informatica, Ab Initio, Oracle ODI and a number of the Big Data / Open Source Applications
Understands data-related performance issues.
Understands data services, data security issues, “privacy by design” and Information Assurance principles.
Understands master data management patterns and can advise on the right choices for each client.
Defines metadata structures and population techniques that can be used with Enterprise Content Managment solutions in conjuction with organisational policies.
What we are looking for:
ETL Tool capabilities
Ab Initio, Informatica and Oracle ODI
Big Data / Open Source ETL Tools
Database Management Systems
Application Testing Tools
Configuration Management and Version Control Tools
Testing strategies and tools
Infrastructure design
About BAE Systems Applied Intelligence

We use our intelligence-led insights to help defend Governments, Nations and Societies from cyber-attacks and financial crime. Our customers depend on our evolving capabilities to help them safely grow their organisations. Our unprecedented access to threat intelligence, world-leading analysts and market-leading technology means we can help them to adapt, evolve and stay ahead of the criminals.

Division overview: Capabilities

At BAE Systems Applied Intelligence, we pride ourselves in being a leader in the cyber defence industry, and Capabilities is the engine that keeps the business moving forward. It is the largest area of Applied Intelligence, containing our Engineering, Consulting and Project Management teams that design and implement the defence solutions and digital transformation projects that make us a globally recognised brand in both the public and private sector.

As a member of the Capabilities team, you will be creating and managing the solutions that earn us our place in an ever changing digital world. We all have a role to play in defending our clients, and this is yours.

Diversity and inclusion are integral to the success of BAE Systems Applied Intelligence. We are proud to have an organisational culture where employees with varying perspectives, skills, life experiences and backgrounds – the best and brightest minds – can work together to achieve excellence and realise individual and organisational potential. We also welcome discussions about flexible working.

About BAE Systems Applied Intelligence

We use our intelligence-led insights to help defend Governments, Nations and Societies from cyber-attacks and financial crime. Our customers depend on our evolving capabilities to help them safely grow their organisations. Our unprecedented access to threat intelligence, world-leading analysts and market-leading technology means we can help them to adapt, evolve and stay ahead of the criminals.

Division overview: Capabilities

At BAE Systems Applied Intelligence, we pride ourselves in being a leader in the cyber defence industry, and Capabilities is the engine that keeps the business moving forward. It is the largest area of Applied Intelligence, containing our Engineering, Consulting and Project Management teams that design and implement the defence solutions and digital transformation projects that make us a globally recognised brand in both the public and private sector.

As a member of the Capabilities team, you will be creating and managing the solutions that earn us our place in an ever changing digital world. We all have a role to play in defending our clients, and this is yours.

Diversity and inclusion are integral to the success of BAE Systems Applied Intelligence. We are proud to have an organisational culture where employees with varying perspectives, skills, life experiences and backgrounds – the best and brightest minds – can work together to achieve excellence and realise individual and organisational potential. We also welcome discussions about flexible working.",3.3,"BAE Systems Applied Intelligence
3.3","London, England",-1,1001 to 5000 Employees,1971,Subsidiary or Business Segment,Enterprise Software & Network Solutions,Information Technology,$500 million to $1 billion (USD),-1
"Data Scientist / BI Engineer - Cirencester, UK",-1,"Corin, an orthopaedic medical device business, is currently looking for a Data Scientist / BI Engineer to support our Digital Transformation across all business functions with insights gained from analysing company data and delivery of data models and tools. This is a key role to establish our Digital Centre of Excellence supporting both our Digital Health offering and our business process digitalization.

You will based in our global head office in Love Lane, Cirencester, Gloucestershire reporting into the Group IT Director and working alongside the Chief Transformation Officer.

The ideal Data Scientist / Business Intelligence Engineer will be adept at using large data sets to find opportunities for product and process optimization and building and implementing models to test the effectiveness of different courses of action.

You must have a proven experience in driving business results with your data-based insights using data mining, data tools and data analysis, as well as using and creating algorithms and developing and running simulations.

You must be comfortable working with a wide range of stakeholders and functional teams and have a genuine passion for discovering solutions hidden in data sets. You must have a strong drive, be a self-starter and be ready to work pragmatically towards business deliverables.

Corin provides a progressive and dynamic work environment where you can take control of your career, be accountable and drive positive change. Corin is going through an exciting period of growth with our investment partner Permira committed to driving global technological / robotic advancements in the implant of hip and knee surgery which in turn delivers better patient and surgical outcomes.

The key responsibilities of the Data Scientist / BI Engineer are to:

Establish and lead Data Science at Corin:

Work with the management team and key stakeholders throughout Corin to identify opportunities for leveraging company data to drive value creation and effective decision making.
Make a difference to our business, our Customers, and our Patients, by solving real life problems and delivering insights to improve health outcomes.
Be key in developing and driving a data hub of digital graduates for future talent succession growth.

Deliver expert solutions, working alongside our CIO, Data engineers and architects:

Build and maintain reference datasets and pipelines
Mine and analyse data from company databases. Develop custom data models, time-series forecasting and predictive algorithms to apply to data sets.
Generate analytical insights and develop solutions to drive optimization and improvement of business strategies, commercial excellence, operational efficiency, and digital product development (i.e. Clinical Insights / Digital Health solutions)

Requirements

The ideal Data Scientist / BI Engineer will have;

A Degree, Masters or PHD in Computer Science, Data Science or Analytics, Engineering or Physics, Mathematics or Statistics and / or operational research
Knowledge and experience in statistical, machine learning, modelling and data mining techniques: Multi-variate analysis (MVA), GLM/Regression, Clustering, Random Forest, Boosting, Trees, text mining, social network analysis, neural networks, etc.
Experience querying databases and using statistical computer languages: R, Python, SQL, etc., to manipulate data and draw insights from large data sets.
Experience working and creating data architectures ideally in MS SQL server.
Experience of MS Azure platform tools such as Datafactory, Databricks, synapse Analytics would be beneficial
Experience visualizing/presenting data for stakeholders using: Power BI, Dundas BI, Tableau, etc.
Strong coding knowledge and adept at programming with several languages: C#, .net framework C, C++, Java, JavaScript etc.
Clear experience in building and managing roadmaps, balancing sprint vs. ad/hoc effort. Demonstrated knowledge of the data lifecycle, including experience with data modelling and data quality
Ability to share solutions and ideas with a broad scope of stakeholders across business functions and lead by influence.
A drive to learn and master new technologies and techniques.
Strong problem-solving skills with an emphasis on product development.
Excellent written and verbal communication skills for coordinating across teams.
Preferably, time served experience with a clinical, healthcare, orthopaedic, or pharmaceutical business, manipulating their data sets and building statistical models.

Benefits

You will receive a competitive salary and annual bonus as well as;

25 days holiday plus bank holidays.
Excellent pension – up to 9.7% provided by Corin when you contribute 4%
Life assurance (6x basic salary).
Private medical insurance with BUPA for you and your family.
Subsidised canteen and gym membership.
Free car parking - close to Swindon, A419, Cheltenham, Gloucester and Stroud.
Friendly and collaborative working environment",-1,Corin,"Cirencester, England",-1,Unknown,-1,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer 3 months 25 per hour INSIDE IR35 Remote,-1,"Data Engineer 3 months 25 per hour INSIDE IR35 Remote

Parity Group are delighted to partner with our client, a prestigious public sector organisation, who is looking to recruit a Data Engineer on an initial 6-month contract basis, this role will be working remotely.

You will receive a competitive hourly rate of 25 and the contract will see you INSIDE IR35.

What will you be doing?

Qualifying and assessing the quality of data
Understanding user use cases and workflow to understand potential development value
Transforming the Data and Metadata and publishing
Develop ways to enhance the uses search for data
Enhance the users understanding of the data through visualisation techniques
Investigate data auto-ingestion solutions

I would love to hear from you if you have relevant experience in a data engineering role within a large organisation and skills including:

A passion for data engineering, possess strong development skills and have the enthusiasm for building data pipelines with supporting infrastructure for reliability and resilience.
DevOps experience is core to the role coupled with data analysis and basic DBA-type skills.
An interest in finding new and innovative ways that technology can be used to make data meaningful for everyone.
Ability to communicate technical concepts to non-technical people.
Stakeholder communication and management; including influencing, facilitation & negotiation across organisational, technical and political boundaries.
Bring a clear focus on continuous improvement, proposing changes in procedures and processes.

If this sounds like the role for you then do not hesitate to get in touch with me, Kirsty Dallas, for more information or simply click on the apply button.

Parity - Better Decisions : Better People

Parity Group plc acts in the capacity of an Employment Agency when providing contract recruitment services.

We welcome applications from all sections of society and applicants will be considered on the basis of their suitability for the position

At Parity, we are committed to protecting your privacy, we will process and hold your CV and use the information you have provided lawfully and in accordance with our Terms and Conditions and our Privacy Policy.

J301_160226266239748",4.4,"Parity Professionals
4.4","Newport, Newport, Wales",-1,51 to 200 Employees,1971,Company - Public,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Software Development Engineer - Stress Simulation Software,-1,"Overview
Silvaco, Inc. is a global company with a leading position among providers of EDA and SIP. The company is headquartered in Santa Clara, California, with offices in North America, Europe, and Asia. Silvaco is undergoing substantial growth driven by AI, IoT, display and big data, and is looking for key talent to join this rapidly expanding company. Silvaco is a privately held company, measuring itself to the highest ethical standards and world class performance.
Position Description and Responsibilities
Silvaco is looking for a software engineer to join our process simulation team in one of the company's offices in Europe. Working at the very center of the TCAD group, you would be working on stress simulation aspects (mechanical stress as well as viscous stress and its effects). As a Software Developer, you will help Silvaco develop and deliver high quality products and services.
As a member of the TCAD group, you will design, implement, evaluate, and improve numerical methods, physical models and simulation methodologies. The successful candidate will be an experienced software engineer with expertise in simulating mechanical and/or viscous stress effects, whereby software development experience is at least as good as the knowledge of using software packages for simulating these kinds of problems. Since solving stress simulation problems often goes along with challenges in creating good simulation meshes, experience in that area or at least understanding his/her relevance and impact will be very beneficial. As an integral member of a team of highly trained and experienced engineers, the successful candidate must also be able to:
Responsibilities include:
Develop, support, test, and maintain existing simulation software.
Identify and understand limitations of existing software components.
Improve and develop simulation methodologies.
Develop and provide software solutions for physical models.
Understand and improve numerical schemes relevant for stress simulation problems.
Rely on experience and judgment to plan and accomplish goals.
Communicate complex ideas and testing results effectively; both orally and written
Must be able to work independently and solve the problems on his/her own initiative.
Provide accurate and effective written documentation.
Good communication and organization skills, with a logical approach to problem solving, good time management, and task prioritization skills.
The personality
Displays strong analytical abilities both quantitative and qualitative.
Strong Organization and time management skills.
Relies on experience and judgment to plan and accomplish goals.
Performs a variety of complicated tasks - certain degree of creativity and latitude is required.
A key requirement of this role is being the master of all details.
Ability to multi-task and handle matters with little supervision and with excellent follow up.
Must be able work alongside dynamic individual team members as a day-to-day partner in moving the business forward, holding reports accountable for forecasts and other business objectives.
A strong entrepreneurial and can-do mindset, undaunted by shifting priorities, uncertainty, and a “figuring it out as we go” environment.
Enough courage to say, “I don’t know”.
Desirable Qualifications
PhD in Physics, Engineering, or related field
Strong proficiency in C++ or equivalent object-oriented programming language
Extensive experience in software design
Experience in software development within teams (code sharing)
Experience in simulating stress related problems including validation of simulation results
Strong knowledge in solid-state physics, mechanics of materials and theory of elasticity
Good presentation skills, communication skills and technical writing skills desired
Working knowledge of Microsoft PowerPoint and Excel",3.2,"Silvaco
3.2","London, England",-1,51 to 200 Employees,1984,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1
Senior Software Engineer (Data),-1,"About DueDil

DueDil provides real-time insights on every company, helping financial services providers to give small businesses the products they need to thrive.

Reliance on manual checks makes it harder for SMEs to open an account, take out a loan or get insurance cover. It also makes it harder for the companies providing those products to carry out ongoing Know Your Business checks.

DueDil's KYB for Life platform transforms how providers work with SMEs. We analyse billions of data points on millions of companies to provide unique insights via our API.

In the last three years, DueDil has grown rapidly in the UK and Ireland and we're now expanding into mainland Europe. We have over 400 clients across the Financial Services, Insurance and Fintech sectors, including Santander, Tide and Metro Bank.

Our Values

We're driven by three core values, the characteristics that define the members of our team are grit, authenticity, and team spirit. These values factor into the way we hire, promote, and reward every member of our team. Put simply, we're looking for ambitious people who take ownership and responsibility - if this sounds like you then you're in the right place! You can read more about our values and how they impact our culture day to day here: https://www.duedil.com/about-duedil/who-we-are

The Role

Critical to achieving DueDil's vision is our ability to combine multiple disparate data sources from different providers into a unified view of companies and the people who run them. This requires us to develop web crawlers, automated matching algorithms, machine learning models and complex ETL processes to tie all these components together.

As a Senior Software Engineer, you'll help enhance and expand our data processing and distributed systems toolsets to support our international expansion effort, while maintaining quality and reliability of our existing data products and services. This will mean dealing with challenges such as order of magnitude increase in data volumes, assessing quality of data from multiple suppliers and building pipelines and services using modern cloud tools to match and extract valuable insight from these datasets. We value DevOps culture so you will take full ownership of your solutions from prototyping all the way to production, and you'll do that working in a team of experienced Software Engineers and Data Scientists building next generation tools and transforming the Fintech industry.

We are looking for
Proven track record leading complex ETL and Data Infrastructure projects, as well as designing and building data intensive applications and services in both batch and streaming environments
Demonstrable experience working with high volume heterogeneous data with distributed systems such as Hadoop or Spark
At least 5 years commercial experience with one or more JVM-based languages. Python experience is a big plus.
Strong understanding of data structures and algorithms
Familiarity with Unix systems, common command line tools e.g. grep, awk, source control tools e.g. git and containerisation tools such as Docker
Experience working with cloud environments such as GCP or AWS a big plus
Our Tech Stack
Infrastructure: GCP (BigQuery, Dataproc, Google Kubernetes Engine)
Languages: Python, Scala, Kotlin
Databases: PostgreSQL, Elasticsearch
Other: Kafka, Spark, Airflow, Tinkerpop
What DueDil can offer you
The opportunity to work for a dynamic disruptor in the data market. We challenge our staff to be innovative and encourage outside-the-box-thinking.
24 days holiday per year (excluding bank and public holidays) plus Christmas and New Year's break.
Bike to work scheme
Pension scheme
Private healthcare
Optional childcare vouchers
Dedicated '10% time' for product and engineering teams to work on experimental projects or pursue learning opportunities of your choosing.
Generous allowance of professional development platform (Learnerbly)
MacBooks as standard, but we're happy to get you whatever equipment you need to get your job done.
Free lunch Fridays and regular beer o'clock. Friday lunch is one of the perks we enjoy the most, and take very seriously!
Regular team and company events in and out of the office
Super cool office based in Moorgate.
Please note, while we are going through the COVID-19 pandemic, the whole company is working from home and we are doing our best to help our employees get all the equipment needed to make working from home as comfortable as possible. On top of that, we are able to onboard new employees remotely during this time.

All successful applicants will be subject to enhanced background checks.",4.5,"DueDil
4.5","London, England",-1,51 to 200 Employees,2011,Company - Private,Enterprise Software & Network Solutions,Information Technology,$1 to $5 million (USD),-1
Azure Data Engineer,-1,"Azure Data Engineer ( Azure / SQL Server / DevOps )
Woking
3 Months Initially

An Azure Data Engineer is required to join my prestigious client based in Guildford; you will be responsible for re-designing the data ingestion process to work in the cloud whilst also moving other existing on-prem projects to an Azure environment.

The client is looking for somebody who has extensive experience within Microsoft SQL Server both on premise and in the cloud (SSAS, SSIS, SSRS).

The role of an Azure Data Engineer requires recent experience with Azure as well as constantly developing technical skills and knowledge using the latest Azure technologies.

You will also be comfortable working in a collaborative environment as part of a team and will have proven experience of working well in Data Engineering teams to successfully deliver projects.

Essential Experience required for the successful Azure Data Engineer ( Azure / SQL Server / DevOps ) include:

Exposure to On-prem and cloud versions of SQL Server, SSAS, SSIS, SSRS.
Experienced in using SSDT with respect to SQL Server database, SSIS, and SSAS projects and their deployment in relation to stories and tasks.
Experience of parameter driven deployment
Unit testing using tSQLt or a similar framework
Strong TSQL skills across all database objects, to such an extent that one is also able to reverse engineer requirements if need be.
SSAS knowledge of MDX for creation of calculated measures and dimension members, dynamically processing cube based on delta movement.
Creation of SSIS packages using BIML and metadata stored in a central repository.
Storage and execution of SSIS packages for on-prem.
Experience in the creation of pipelines to orchestrate the ELT/ETL delivery.
Experience of their delivery using metadata would be nice to have.
Storage and execution of SSIS packages
Azure SQL database

Desirable Experience for the successful Azure Data Engineer ( Azure / SQL Server / DevOps ) include:

ARM templates development and deployment to create services and pipelines.
Databricks notebooks exposure in conjunction with Python/Scala.
DevOps exposure with SQL Server and Azure.
CI/CD exposure

This collaborative environment is one that promotes creativity and the ability to work well within a team. To apply for this role please urgently send an update of your CV to deren.ridley@venturi-group.com

Venturi is a staffing business dedicated to you, differentiating ourselves in the marketplace by quality of service and candidate delivery. Our highly skilled and experienced staff operate within dedicated markets to give you the best service possible. Venturi markets include Business Intelligence, Development IT & Legal IT. Venturi operates as an employment agency and employment business. No terminology in this advert is intended to discriminate on the grounds of age, and we confirm that we are happy to accept applications from persons of any age for this role.",4.8,"Venturi
4.8","Guildford, England",-1,51 to 200 Employees,2009,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1
Big Data Engineer- Contract- Remote -£450 per day,-1,"Big Data Engineer- Contract- Remote Interviews & On-Boarding available

You will work within the company's Enterprise Data Flow Team, and will be responsible for helping to populate data into the data lake, and onto AWS. The Data Lake stores the Big Data for the company, so it is a critical component!

What do I need as a Big Data Engineer?

Experience in Java, Spark and Python scripting, Linux, Batch processing, Hadoop

Experience architecting enterprise software applications

CI/CD experience

What’s in it for me?

Contract until March 2021- but could run to end of 2021

£400+ per day

Start in 2-3 weeks

Interested? Get in touch today with Emma to hear more about the Big Data Engineer!

Education Level Required

See Description",3.9,"realTime
3.9","Belfast, Northern Ireland",-1,51 to 200 Employees,-1,Subsidiary or Business Segment,IT Services,Information Technology,Less than $1 million (USD),-1
Data Software Engineer,-1,"Location:
Telford / London
An overview of your role
Here at Capgemini we are looking to recruit an experienced Data Engineer who will work across the design, development, testing and support of our client’s data and analytics software solutions. We offer the opportunity for everyone to get involved in many different areas of delivery using pre-built solutions, innovative best practices, proven technologies for reliability, and cost-effective models that increase value. We are building solutions that align to the type of work we are doing now and in the future.

This role falls within the “Data and Analytics” delivery centre where the centre provides a wide range of data and analytics solutions in support of the client’s business priorities. The Data Engineer will work primarily with product owner, scrum master, solutions architects, software architects and fellow software engineers, though there will be client and key stakeholder interaction as necessary.
What you’ll do
• Work as part of an Agile software delivery team; typically delivering within an Agile Scrum framework.
• You will work on the full range of software engineering and solutions development activity; covering requirements gathering and analysis, solutions design, software coding and development, testing, implementation and live support.
• You will contribute to the software engineering communities by providing your ideas for innovation and process improvement and coaching and mentoring junior team members.
Why You?
• Software engineer delivering within large scale and complex data solutions.
• Technical expertise in our technologies (Pentaho is preferred) : Pentaho DI / Pentaho BA, Talend / Denodo / AWS /Azure
• Ability to operate at all stages of the software engineering lifecycle
• Background in Agile Scrum based delivery
• Personal drive, enthusiasm, willingness to learn
• Applicants mut be eligible for SC Clearance
Why Us?
Capgemini is a place where different people with a variety of expertise and skills come together as one team, work creatively and deliver results. It is a culture where people like to learn from each other and be part of a world class software engineering community. While we’re a global consultancy, we’re made up of supportive, close-knit communities. Everyone wants to get the best solutions for our clients and create the best working environment.
We invest in doing things right and have plenty to say on the subject. We’re active on social media and for those that want to find out more, take a look at our blogs – written by engineers, for engineers: http://capgemini.github.io/

Learning and development
Capgemini recognise that an individual’s career is in their own hands and our ambition is to provide them with all the support they need to be successful in developing their skills & building their network. There’s an endless amount to learn at Capgemini, and an endless number of ways to do so. Collaboration is encouraged across all teams and your opinion counts, and ideas are valued.

Work-life balance
We understand that everyone has varied lives and we want you to have a great work-life balance. So, where possible, our Work Life Harmony policy will help you to work flexibly and juggle your work and home life.

Diversity Statement
Capgemini positively encourages applications from suitably qualified and eligible candidates regardless of sex, race, disability, age, sexual orientation, gender identity, religion or belief, marital status, or pregnancy and maternity. We are committed to hiring, developing and retaining the best people to deliver innovative, world-class solutions for our clients. We foster an inclusive culture that enables everyone to achieve their full potential and enjoy a fulfilling career with us. Our comprehensive flexible benefits package and lifestyle policies enable our employees to balance their individual, family and work-life needs.
About Capgemini
Capgemini is a global leader in consulting, digital transformation, technology and engineering services. The Group is at the forefront of innovation to address the entire breadth of clients’ opportunities in the evolving world of cloud, digital and platforms. Building on its strong 50-year+ heritage and deep industry-specific expertise, Capgemini enables organizations to realize their business ambitions through an array of services from strategy to operations. Capgemini is driven by the conviction that the business value of technology comes from and through people. Today, it is a multicultural company of 270,000 team members in almost 50 countries. With Altran, the Group reported 2019 combined revenues of €17billion.

Discover more about what Capgemini can offer you. Visit:

https://twitter.com/Capgemini and https://www.glassdoor.co.uk/Reviews/Capgemini-Reviews-E3803.htm",4.3,"Capgemini
4.3",West Midlands,-1,10000+ Employees,1967,Company - Public,Enterprise Software & Network Solutions,Information Technology,$10+ billion (USD),-1
Sr. Software Engineer,-1,"Responsibilities
Developing and supporting Cloud Services in AWS and Azure
Experience of developing Spring boot based cloud SaaS solutions
Working on pipelines involving containers/deployment to containerized platforms
A good understanding of agile software development techniques and test automation processes
Needs to have
5+ years commercial development experience with Java
Commercial development experience with cloud or data centre hosted Spring boot applications
Experience of fault-finding on, and the monitoring and supporting of, java based hosted services
Significant experience of Agile Development Processes, TDD/BDD and test automation
Proficient with source control systems ( git ) and good familiarity with CI/CD pipelines
Experience of using Docker and Kubernetes would be helpful
Experience working with Terraform would be helpful
Familiarity with the Linux command-line environment and shell scripts
Experience of web development technologies using modern Web frameworks especially ReactJS
Solid Unit Testing
Knowledge of monitoring and logging tools",3.5,"Barracuda Networks Inc.
3.5","Nottingham, England",-1,1001 to 5000 Employees,2004,Company - Private,Computer Hardware & Software,Information Technology,$100 to $500 million (USD),-1
Computer Vision Software Engineer,-1,"About The Position
AnyVision Research is a world leading team of scientists and engineers that creates AI for the Real World. With deployments and clients spanning the globe, we are recognized as leaders in the fields of Face recognition, Object recognition, Object detection, and Visual Target Tracking.
AnyVision provides a diverse and flexible work environment so that we can recruit and retain the best talent. Working for AnyVision you will:
Be a part of a diverse, multinational and inclusive team
Receive challenging work and assignments
Receive world class training and experience on cutting edge systems and complex projects
Be supported by a flexible and supportive work environment
As we grow in scope and ambition into 2020/21, we are looking for highly motivated C++ Computer Vision engineers to join our Research Engineering team.
You are:
A talented and motivated engineer with a strong interest in development and building software systems. You are also passionate about the impact that AI is having in the world and you want to be part of it. You have completed a degree in a scientific or engineering discipline. You can adapt to new environments and solve new problems quickly. You are adept at producing innovative solutions based on real-world product requirements. You have strong communication and teamwork skills.
You will:
As a member of the Research team you will develop software that ensures robust and reliable execution of our cutting-edge AI portfolio. This could include algorithm implementation, hardware optimization, pipelining and proof of concept prototyping. Working at AnyVision offers the opportunity to help deliver world leading AI technology. We offer unique opportunities and challenges to learn new technologies and be at the very bleeding edge of the computer vision and machine/deep learning industry. Within the research engineering team, projects include:
Developing and optimizing machine/deep learning and computer vision algorithms
Producing reference implementations of state-of-the-art artificial intelligence algorithms that have been developed by our machine/deep learning researchers
Integrating deep learning components into robust pipelines.
Creating tools and tool sets (custom kernels, APIs, test systems/suites, etc.) for state-of-the-art hardware
Research and development into emerging heterogeneous languages (Halide, TVM, OpenCL)
Prototyping new hardware specific deep learning inference engines and pipelines (e.g. TensorRT, OpenVino, Qualcomm SNPE, ARM NN)
Integrating computer vision components within the GStreamer multimedia framework.


Requirements:
Requirements
Required Skills/Experience:
A bachelors degree or higher in a relevant engineering or mathematical field
Experience of at least one of the machine learning inference frameworks:TensorRT, Caffe, OpenVino, SNPE, ARM NN OR at least one GPGPU frameworks: OpenCL/CUDA/C++AMP/other OR experience developing GStreamer components/pipelines with a broad understanding of video codecs, colour-space/pixel-formats and streaming protocols.
Strong knowledge and experience of C++11 onwards
Experience developing robust, maintainable, efficient and testable code for secure and reliable systems
Minimisation of memory footprints, data movements, allocations and de-allocations
Development of fast, scalable and correct concurrent programs
Cross-platform (Linux, Android and/or Windows) development
Profiling and optimisation of performance and memory system usage
Experience with software development practices e.g. debug tools, agile, design patterns
Experience with source control and collaborative development tools
Excellent communication and teamwork skills
Minimum 1 year industry experience
Desirable Skills/Experience:
A PhD in a relevant engineering or mathematical field or equivalent experience
Computer vision experience
Experience developing for hardware devices such as DSPs, FPGAs, embedded Linux
Clang/LLVM compiler projects
Knowledge/experience of domain specific languages (e.g. Halide/TVM)
OpenVX
Benefits:
Highly competitive salary and regular salary reviews
Technical training
Contributory pension scheme
Private healthcare
Flexible working
Regular company social events and activities


Location::
UK, London or Belfast


Salary range::
Competitive Salary + Benefits",4.0,"AnyVision
4.0","Belfast, Northern Ireland",-1,201 to 500 Employees,2015,Company - Private,Aerospace & Defense,Aerospace & Defense,Unknown / Non-Applicable,-1
"Data Engineer, Leeds or Manchester",-1,"Would you like to help create a brand-new engineering organisation? Perhaps you know what great engineering culture looks like, or you have an entrepreneurial side as well as outstanding coding skills? Whatever your aspirations, we’re trying to create the best engineering consultancy in the UK and looking for brilliant engineers to be part of the journey.

About DMW Engineering

DMW helps organisations solve their biggest, most exciting engineering problems. We’ve created banks from scratch on Kubernetes and AWS, built streaming analytics solutions that protect the country and built platforms to enable whole organisations to move to AWS and Azure, and everything in between. We do all this in a work environment where regular social events, inclusivity and an ego-free culture mean we’ve been officially voted a “Great Place to Work” for five years in a row.

We’re not interested in cutting corners and believe in helping our clients to make the right choice for the long-term. We draw on our reputation for outstanding delivery to allow our engineers to do the right thing for our clients, and not necessarily the easy thing. Innovation is in our DNA, and we encourage our engineers and consultants to work together to rethink conventional wisdom on how problems should be solved.

Location:

We offer two locations for this: Leeds or Manchester. Both locations are based right in the heart of the city centre next to Leeds station and Manchester Piccadilly. The offices are relaxed, modern coworking spaces with plenty of private and shared areas.

Here’s what you will do (Not all of it, but some of the important stuff!)
Solve the problems others cannot
Spend a day a week working on a combination of internal products and your own development
Create data platforms based around modern open source products and cloud-native technologies:
AWS, Azure and Google Cloud
Python
Kafka / NiFi / Flume
DB technologies: SQL Server / PosteSQL / MySQL
Hive/Spark/Impala
Dataiku
Terraform
Kubernetes
Requirements

The essentials?
Experiece building data platforms using either cloud native products or commercial data analytics / data warehouse software
Working knowledge of data pipelines & data transformation processes
Experience creating and/or maintaining production software delivery pipelines using common CI/CD tools (e.g. Jenkins, GoCD, CircleCI)
Demonstrable experience in automating operations tasks with one or more scripting languages
Experience working with one or more of the main cloud providers (AWS, Azure or Google)
Have a drive for self-improvement and learning, including learning new programming languages
Approach solving problems pragmatically
Experience of Hadoop big data platforms (either Cloudera / Hortonworks or cloud native equivalents)
Experience with data reporting and visualisation tools (PowerBI, Tableau, Qlik)
Experience productionising machine learning algorithms
Experience with Infrastructure as Code (e.g. Terraform, Cloudformation)
Experience supporting and operating production systems
Familiarity with configuration management tooling (e.g. Ansible)
It would be great if you had these desirable skills
Experience of Hadoop big data platforms (either Cloudera / Hortonworks or cloud native equivalents)
Experience with data reporting and visualisation tools (PowerBI, Tableau, Qlik)
Experience productionising machine learning algorithms
Experience with Infrastructure as Code (e.g. Terraform, Cloudformation)
Experience supporting and operating production systems
Familiarity with configuration management tooling (e.g. Ansible)
Benefits

We’ve grown consistently over the years and offer an entrepreneurial environment within which to embark upon an exciting career path, where your contribution really counts, and we will recognise it. With personalised development opportunities, experienced colleagues and challenging client assignments, progression can be extremely rapid for high performers. We are a social bunch of people and go out as a team on a regular basis. You can also expect:
A highly collaborative working environment and great rates of pay (including base salary and bonus potential).
A range of flexible benefits consisting of well-being and lifestyle benefits.
A commitment to your development & continuous growth of skills through one-to-one mentoring and wide-ranging hands-on experience.
25 days’ holiday and the ability to flex this to 30 days if you chose to do so.
2 day’s CSR volunteering days.
Award-winning learning and development opportunities, including dedicated personal training budgets and time and a wide range of choice in training courses.
A dedicated personal budget to choose the IT equipment of your choice.",4.7,"DMW Group
4.7","Leeds, England",-1,51 to 200 Employees,1989,Company - Private,IT Services,Information Technology,$10 to $25 million (USD),-1
Data Engineer (Clojure),-1,"Role Title: Data Engineer (Clojure)
Location: Paddington, London
Job Type: Permanent

Employer's note: some flexibility

Let's step back a second - how do we say our name? Well, it sounds like 'view'. It's also a lot shorter than saying 'Viewed Impressions for Out of Home'. We're making it easy to sell and buy digital out of home (OOH) inventory. Our premium marketplace is connecting buyers and sellers, across the globe, simply.

We are working to transform the industry and we believe it's important to connect OOH and digital advertising to deliver brand experiences and more meaningful outcomes for agencies and advertisers.

Join us as we build out the leading, global out of home (OOH) marketplace. Simply put, it's our mission to make it easy to buy and sell OOH inventory.

Role OverVIOOH

We are looking for an experienced engineer to join our growing Data engineer team.

Data is at the core of our company and this is an opportunity for you to work on shaping and building our data platform. This year we have keys components which are being released such as our data lake and our data gateway based on Kafka which already ingest billions of events a day.

You will be involved in the design and construction of the data lake ground up. This is a unique opportunity to influence key architectural decisions at early stages.

As well as building the data platform, you will work with data scientists to guide them through productionising data science workflows.

Collaborating with other teams you will define transformations and build the VIOOH data platform which allows our micro services to react in real time to events. Our data platform also provide data to our data scientists to build models and reports.

We believe that owning the components we build - from development to operational release - allows us to design better distributed systems (increasing performance and maintainability).

What we expect from you
Strong computer science background
Experience with Clojure, and/or any of the following languages, Java Scala, as well as functional programming concepts
A proactive engineer
Data oriented engineer, attentive to details.
Key Skills Include
Experience with functional programming and distributed systems
Experience with streaming technologies, preferably Kafka
Experience with Amazon AWS platform (Athena, S3, DynamoDB,...)
Experience with Terraform, Docker, Kubernetes
Experience with REST APIs
Experience with KeyValue stores database design
Experience with integration of data from multiple data sources
Experience in building or integrating Monitoring Tools (Kibana, Grafana, Prometheus)
VIOOH is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, citizenship, marital, domestic or civil partnership status, sexual orientation, or gender identity or any other basis as protected by applicable law.",3.9,"VIOOH
3.9","London, England",-1,51 to 200 Employees,2018,Company - Private,-1,-1,Less than $1 million (USD),-1
Data Engineer- Developer,-1,"Want to do the best work of your life? With 24 million customers in 7 countries, make your mark at Europe’s leading media and entertainment brand. A workplace where you can proudly be yourself; our people make Sky a truly exciting and inclusive place to work.

Data, Technology & Analytics (DTA) at Sky is on a mission to bring customers more of what they love by unlocking the power of data to make Sky even more relevant. We are working with the rest of Sky to build innovative data products that bring even more value to our customers.

What you’ll do:

– Develop and deliver technical solutions in an agile manor which satisfy our stakeholders
– Produce detailed deliverable’s that follow the development standards and principles, on time
– Strive for excellence, challenge assumptions and bring solutions
– Ensure that quality is maintained at all stages of the SDLC and that processes are followed in a timely and thorough manner
– Work with and assist the other teams within the department and provide technical & domain input
– Share knowledge and collaborate with colleagues during the project life-cycle

What you’ll bring:

– Cloud experience, GCP or AWS useful, with in depth understanding of large-scale data, data warehouses, data pipelines and/or data streaming
– Excellent SQL skills and understanding of RDMS, experience of Google BigQuery, Netezza or other MPP system useful
– Skills in Shell scripting and/or a programming language such as Python, Java or Spark
– An attention to detail, a desire to improve and an attitude to deliver
– Exceptional communication and interpersonal skills and a proven ability to influence technical decisions in a fast-moving commercial environment
– SOA/SOP and micro-services based data solutions, would be advantageous
– Experience of the full software development life-cycle including IaC, TDD and CI/CD

To be part of the team that is responsible for instilling good data governance principles and practices within Sky to drive the benefits: trust, performance & value

The Rewards:

There’s a reason people can’t stop talking about #LifeAtSky. Our great range of rewards really are something special, here are just a few:

– Sky Q, for the TV you love all in one place
– A generous pension package
– Private healthcare
– Discounted mobile and broadband

Where you’ll work:

Osterley:

Our Osterley campus is a 10-minute walk from Syon Lane train station. Or you can hop on one of our free shuttle buses that run to and from Osterley, Chiswick Park, Gunnersbury, Acton Town and Ealing Broadway tube stations. There’s also plenty of parking, bike shelters and showers.

On campus you’ll find six subsidised restaurants and a Waitrose. You can keep in shape at our subsidised gym, catch the latest shows and movies at our cinema, get your car washed and even get pampered at our beauty salon.

Inclusion:

Recognised as an ‘Inclusive Top 50 Employer’ and a ‘Times Top 50 Employer for Women’, we’re working hard to ensure we’re a truly inclusive place to work. This means we don’t just look at your CV. We’re more focused on who you are and the potential you’ll bring to Sky. We also know that everyone has a life outside work, so we’re happy to discuss flexible working.

And we’ll do everything we can to support you during your application. If you need us to make any adjustments to our recruitment process, speak to our recruitment team who will be happy to support you.

Why wait?

Apply now to build an amazing career and be part of a brilliant team. We can’t wait to hear from you.

To find out more about working with us, search #LifeAtSky on social media. A job you love to talk about.

Just so you know: if your application is successful, we’ll ask you to complete a criminal record check. And depending on the role you have applied for and the nature of any convictions you may have, we might have to withdraw the offer.

#LI-Tech",3.8,"Sky
3.8","Isleworth, England",-1,10000+ Employees,1989,Company - Public,TV Broadcast & Cable Networks,Media,$5 to $10 billion (USD),-1
Data Migration Engineers,-1,"The Data Migration Team is part of the Technical Support Team supporting the MOD.
Our aim is to derive creative cost-effective migration strategies and solutions for a multitude of platforms, in a variety of technical environments.

Job Description - Technical Support Team Migration
Evaluate, formulate, test and document end to end Migration processes and procedures for use during large scale deployments for various Customers. To integrate and interact with the Technical/Architectural and Discovery/Design teams in order to deliver large scale deployments. In addition to the proprietary IT skill-set listed below you will also be able to “think outside the box” when circumstances dictate. You will test, evaluate and implement migration methodologies. This will include troubleshooting and support of migration tools and processes where necessary. Carry out end to end live and live-like testing. Engage with internal teams, external organisations and directly with the customer where necessary. This is a rewarding opportunity with a chance to integrate with all areas of technical delivery, infrastructure teams and partners within the consortium. Occasional travel will be required and may extend to time away from home.

Essential qualifications, skills and other requirements for this position are as follows:

Highly Motivated
Able to work on your own initiative
Excellent technical knowledge of Microsoft Product Suite, to include
Knowledge of NT4, 2000, 2003 Server
Knowledge of NT4, 2000, XP Workstation
Knowledge of Active Directory
MS Exchange 2003, 2000 and 5.5
Knowledge of other/legacy mail systems (Exchange pre-2003, GroupWise, Lotus Notes etc.)
Knowledge of scripting (batch-files), VB Skills, Robocopy, Excel, LDAP
Excellent knowledge or practical experience of data migration tools (Robocopy, Exmerge, FSMT)
Working knowledge/experience of Windows Shared Services & Sharepoint Team Server (WSS & STS)
Good practical experience of large scale data migration and issues related to such migrations
Good knowledge of WAN, LAN, TCP-IP, DNS, DHCP, WINS
Knowledge of Quest windows management products for user and data migration
Familiarity with NetWare and UNIX
Familiarity or experience with SharePoint
Excellent communication skills
Good presentation skills
Able to talk to large groups of people in confidence
Able to work well in a team environment
Able to make suggestions and improve current processes and procedures
Knowledge of the Business and Delivery processes, lifecycle, change management
Excellent at creating and manipulating documentation to standards
Full driving license
Security clearance or willing to undergo clearance
Independent Computing offers you an opportunity to accelerate and excel beyond your boundaries, supporting you along the way.

We are convinced you will enjoy our culture and working ethics.

You will be challenged and inspired like you have never been before!

If you are interested in this opportunity, please e-mail your CV and a covering letter to: opportunities@independentcomputing.co.uk",4.1,"Independent Computing
4.1","London, England",-1,51 to 200 Employees,1988,Company - Private,IT Services,Information Technology,$10 to $25 million (USD),-1
Azure Data Engineer,-1,"What to expect*
About the role *
We are looking for a Microsoft Azure Data Engineer to be a key member of the Azure Data Team, working directly with various stakeholders from across the business, designing stable and reliable data warehousing technology that surfaces the data our business uses, proactively monitoring the company's data warehouse and participating in the design and implementation of the associated data pipeline technology that moves data from our operational systems to the data warehouse.
About Commify*
We make business communication brilliant! We work with more than 45,000 companies, helping them to transform their mobile communication with their customers and employees. Our success is the result of hundreds of talented people pulling together to achieve a common goal. Join our team and be part of our success story.

You will thrive in an environment of passion, integrity, ownership and innovation, where development and progression is a real focus. We’d like to think we have everything you’d expect from a benefits package, from 27 days holiday and your birthday off work, to private medical cover, dental cover and bi-monthly social events! On top of this you can expect £350 of Christmas vouchers and added extras like beer o’clock and an amazing Christmas party.
What you’ll be doing*
As Microsoft Azure Data Engineer you will be responsible for:
Developing the data warehouse platform, testing, improving and maintaining new and existing pipelines, and working closely with operational systems owners to ensure data consistency
Collaborating with operational systems owners to identify issues with existing pipelines, to develop changes to existing pipelines and to design and build new pipelines
Designing stable, reliable and effective data pipelines
Providing data design consultancy to operational systems owners to ensure the data they hold in their systems is optimised for use in the data warehouse
Providing expert data and domain advice to Management Information specialists, Analysts and Data Visualisers such that their understanding of the data within the data warehouse is suitable for their work
Contributing to data technology roadmaps including key items such as upgrades, technical refreshes and new versions
Schema design and data modelling
Ensuring the data warehouse technology complies with our operational and service management standards
Troubleshooting potentially inefficient pipelines and optimising them
Managing data technology across distributed Azure Regions and Technology
Maintaining all relevant documentation and knowledge bases
Escalating data problems to operational systems owners to assure the quality of the data within the data warehouse
Researching and suggesting new data products, services and technologies
Working in a 24x7, high-availability environment
Providing on call support including out-of-hours incident support
What we’re looking for*
We’re interested in hearing from candidates with experience in the following areas:
Developing, building and deploying solutions based on Microsoft Azure SQL, Databricks, Data Factory and Blob Storage
Infrastructure as Code technologies such as Microsoft ARM templates or Terraform and the tools to automate their deployment
Producing production-quality code using git source control and completing with internal documentation
In-depth understanding of data management (e.g. permissions, recovery, security and monitoring)
Ability to quickly understand new schemas (including in technology other than Microsoft SQL Server i.e. MSSQL, NoSQL, API-Based)
Converting business requirements into data pipelines by working with operational systems owners to understand their data and extract it from their systems
Working with MI/BI Analysts/Visualisers to understand their requirements
Performance tuning of Azure Data Technology
It would be great if you also had:
High Availability in a Microsoft Azure Data Environment
Security in a Microsoft Azure Data Environment
Powershell for scripting automations
Azure SQL Data Warehouse/Azure Synapse
Azure Cosmos DB
Azure Stream Analytics
Tableau Report Design
Experience/knowledge of working in an agile environment and experience with agile methodologies such as TDD, Scrum, Kanban
Reference ID: VAC190

Application deadline: 25/10/2020

Job Types: Full-time, Permanent

Salary: £42,000.00-£52,000.00 per year

Benefits:
Casual dress
Company pension
Life insurance
Private dental insurance
Private medical insurance
Profit sharing
Sick pay
Work from home
Schedule:
Monday to Friday
Work remotely:
Temporarily due to COVID-19",3.4,"Commify UK Ltd
3.4","Nottingham, England",-1,51 to 200 Employees,2001,Company - Public,-1,-1,Less than $1 million (USD),-1
Data Engineer (Analytics),-1,"ANALYTICS DATA ENGINEER*
Curious about a position with MHR? You've come to the right place. MHR has been changing the industry for years, and now you can too.

MHR offers HR, Payroll and Analytical expertise to help our customers work smarter. Our strength is in the development of our own technology based upon the market and future trends to ensure our customers have solutions that fit their needs today and grow with them in the future.

Today we're powered by a world-class team of over 700 people working with us across four products, a multitude of services and three continents. We’re driven by organic growth, a significant achievement in our industry. We pride ourselves on being a financially independent family-owned company on a journey to completely transform the world of work for organisations of all shapes and sizes. We have over 1,000 customers, serving organisations across the public, private and non-profit sectors.

Our mission is to constantly strive to understand and improve the world of work, technology and people, enabling us to create market-leading platforms and services and we'll need creative individuals like you to help continue this success.

Our philosophy for the last 35 years and moving forward remains resolute - one vision, one strategy - one MHR.
Want to be part of something incredible? #OneMHR*
Role Responsibilities*
Due to continued growth, MHR Analytics are recruiting for an Analytics Data Engineer, who is experienced in data modelling principles; to plan, develop, implement and maintain Analytics solutions and services across the MHR customer base.
Core Skillset should be able to demonstrate: *
Depth in data modelling and database design
Conversed in established and emerging data technologies
Core areas of BI development will consist of the following technology stack and disciplines;*
Breadth in Enterprise Data warehousing and working with Data lakes in current technologies
Fully conversed in software project management approaches, requirements, design and test technique
SQL Development, database administration
Columnar and NoSQL database expertise
Working with Structured/Unstructured big data sets
Experience in predictive modelling and AI technologies (e.g. SAP Predictive analytics/ Cognos Watson Analytics/ SAAS/ Azure ML/ R)
Experience in platform development and services (SAP Cloud Platform, Microsoft Azure)
Knowledge of SAP/ Microsoft BI and visualization technologies (SAP Business Objects, PowerBI)
Meta Data and Multi-Dimensional Design
SAP Business Objects Enterprise/Edge/Suite, including Crystal Reports, Dashboards (Xcelcius), Design Studio
Microsoft BI stack, including PowerBI, SSIS, SSAS
Experience in Apache Airflow and other modern pipeline/Orchestration tools advantageous
Experience in working with MS Azure Beneficial
Multiple Sector Experience (Particularly HR/Payroll)
Key Skills*
Database Architecture
SQL
SSIS
SAP Data Services
SAP Business Objects
Open Source ETL (e.g. Airflow)
Data Warehousing Methodology
Microsoft Azure
Python
Microsoft Analytics (PowerBI, SAAS)
Capturing and defining business requirements
Stakeholder management
Change management & version control
Take design concepts to Commercial propositions
Internal and External customer presentations
Our Rewards*
Market competitive salaries.
We contribute to a full company pension scheme to help you plan for your future.
We offer life assurance (x4 salary, with option to increase up to x8 salary).
An employee assistance programme is included.
Our sites all come with a subsidised restaurant and cafe on-site, with delicious new meals on offer from our chefs each day.
We offer Vodafone discounts, making it cheaper and easier to catch up with your favourite people.
Personal development plays a big part in helping our people to reach their potential, this is why we offer over 60 internal training courses and support our people with external qualifications.
Why us?*
What makes MHR a great place to work, isn’t novelties or gimmicky job titles, it’s our down to earth approach working with people who want to do a job they’re proud of.
We invest for the long term, providing fantastic careers for our people and the best software and services to meet the needs of our customers now and in the future.
With over 35 years’ experience in the industry, our ethos has been to keep investing and moving forward with the changing world of work, and we can only do that by supporting our people. We’ve invested £20 million in a huge building expansion project to provide the best environment for our people, to give them the space they need to excel and grow. And by investing 20% of our turnover into our own research and development, our people shape the future of our products and services to support changing requirements on both a local and global scale.
We’re flexible, we embrace change and as we’re still owned by the original founders. We’re incredibly proud of what we we’ve built, evolving from a small business into one of the biggest and best in the industry.
Be part of something special, become part of the MHR family.*
Apply here!*
Job Types: Full-time, Permanent

Benefits:
Childcare
Company events
Company pension
Discounted or free food
Employee discount
Flexible schedule
Gym membership
Life insurance
On-site parking
Private dental insurance
Private medical insurance
Sick pay
Store discounts
Wellness programmes
Work from home
Schedule:
Monday to Friday
Experience:
Data Modelling: 3 years (Preferred)
Work remotely:
Yes",3.7,"MHR
3.7","Nottingham, England",-1,501 to 1000 Employees,1984,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1
BI Engineer,-1,"Capital on Tap believes that the future is all about the impact that small businesses can have in the world. As such we are on a mission to help them thrive – cash flow shouldn't be a barrier to success.

Since launching our business credit card and business loans in 2017 we have been taking off like a rocket! We are one of the fastest growing companies in the UK (Sunday Times Fast Track 100 in 2017, 2018 and 2019) while still posting a profit to fund our future growth. 2020 has been a challenging time for many businesses; our passion for collaborating and helping small businesses thrive has increased as a result of this. This means the work from here on out is only going to get even more interesting and we are looking for a diverse and talented team to join us on our journey moving forward.

Our people (and our office dogs) really are the best thing about working at Capital on Tap. We have built a dynamic, fun and vibrant culture where your opportunities for growth are as big as your ambitions.

The Role

The BI Engineer is a business-side role responsible for expanding, maintaining and optimising our data delivery architecture, optimising data flow and managing our data platform from design through to on-going administration. You will be focused on giving seamless access to data throughout the organisation

The BI Engineer will support the end users of our data in all our platforms including Snowflake, Looker, various ETL tools, DBT and SQL Server. Our BI Analysts, data analysts and data scientists will receive optimal data delivery architecture consistently throughout ongoing projects. They are self-directed and comfortable supporting the data needs of multiple teams, systems and products.

With responsibility for all business side data infrastructure and delivery, this is a ""hands-on"" position requiring solid technical skills, as well as excellent interpersonal and communication skills.

What you'll be doing?
Own the flow of data through Cloud Data Warehouse and component parts
Create and maintain optimal data pipeline architectures.
Ensure our data is always accurate, timely and consistent for our end users
Assemble large, complex data sets that meet business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimising data delivery etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from and to a wide variety of data sources using SQL, Azure and Snowflake 'big data' technologies.
Work with stakeholders including the Executive, Product, Data and Development teams to assist with data-related issues
Keep our data efficient and consistent at a global level, maintaining our warehouse environments over multiple regions
Create and manage tools for our team of analysts and data scientists that assist them in building and optimizing our product.
Document the company's data environment, constructing physical and logical diagrams (including data dictionaries)
What do we require?
Expert SQL skills required
Experience supporting and working with cross-functional teams in a dynamic environment
Experience working with a Cloud Data Warehouse (we work with Snowflake)
Experience with Python required
Experience with ETL tools and components
Familiarity with Scripting (powershell/TSQL etc) and source control experience is desirable
Familiarity with Looker is preferable. (Any data analysis platform such as PowerBI, Tableau is acceptable)
Familiarity with analytics workflow tool is required (DBT is our preferred option)
Familiarity with Python is desirable
Strong analytical skills - analysts will be your customers
What you get in return

We also try not to take ourselves too seriously (all the time) so we make sure our office is decked out with a pool table, arcade machine, beer tap, and a couple of office dogs thrown in for good measure. In addition to a great environment in a buzzing location in Shoreditch we also offer:

A competitive salary
An opportunity to grow and develop – we give every employee £1,000 a year to grow their skills outside the company
Private healthcare
28 days paid holiday
Travel card loan and/or cycle to work scheme
Free breakfast and snacks daily
Anniversary rewards, including a 4 week paid sabbatical when you reach 4 years",4.6,"Capital on Tap
4.6","London, England",-1,51 to 200 Employees,2012,Company - Private,Lending,Finance,Unknown / Non-Applicable,-1
